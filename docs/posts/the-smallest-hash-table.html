<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://orlp.net/blog/worlds-smallest-hash-table/">Original</a>
    <h1>The Smallest Hash Table</h1>
    
    <div id="readability-page-1" class="page"><article>

<time datetime="2023-03-04">2023-03-04</time>
<p>This December I once again did the <a href="https://adventofcode.com/">Advent of Code</a>,
in Rust. If you are interested, <a href="https://github.com/orlp/aoc2022/">my solutions</a>
are on Github. I wanted to highlight one particular solution to the <a href="https://adventofcode.com/2022/day/2">day 2
problem</a> as it is both optimized completely
beyond the point of reason yet contains a useful technique. For simplicity we’re
only going to do part 1 of the day 2 problem here, but the exact same techniques
apply to part 2.</p>
<p>We’re going to start off slow, but stick around because at the end you should
have an idea what on earth this function is doing, how it works, how to make one
and why it’s the world’s smallest hash table:</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub </span><span>fn </span><span>phf_shift(x: </span><span>u32</span><span>) -&gt; </span><span>u8 </span><span>{
</span><span>    </span><span>let</span><span> shift = x.wrapping_mul(</span><span>0xa463293e</span><span>) &gt;&gt; </span><span>27</span><span>;
</span><span>    ((</span><span>0x824a1847</span><span>u32 </span><span>&gt;&gt; shift) &amp; </span><span>0b11111</span><span>) as </span><span>u8
</span><span>}
</span></code></pre>
<h2 id="the-problem"><a href="#the-problem" aria-label="Anchor link for: the-problem">The problem</a></h2>
<p>We receive a file where each line contains <code>A</code>, <code>B</code>, or <code>C</code>, followed by
a space, followed by <code>X</code>, <code>Y</code>, or <code>Z</code>. These are to be understood as choices in
a game of <a href="https://en.wikipedia.org/wiki/Rock_paper_scissors">rock-paper-scissors</a> as such:</p>
<pre><code><span>A = X = Rock
</span><span>B = Y = Paper
</span><span>C = Z = Scissors
</span></code></pre>
<p>The first letter (<code>A</code>/<code>B</code>/<code>C</code>) indicates the choice of our opponent, the second
letter (<code>X</code>/<code>Y</code>/<code>Z</code>) indicates our choice. We then compute a score, which has two
components:</p>
<ol>
<li>
<p>If we picked Rock we get 1 point, if we picked Paper we get 2 points, and 3 points if we picked Scissors.</p>
</li>
<li>
<p>If we lose we gain 0 points, if we draw we gain 3 points, if we win we get 6 points.</p>
</li>
</ol>
<p>As an example, if our input file looks as such:</p>
<pre><code><span>A Y
</span><span>B X
</span><span>C Z
</span></code></pre>
<p>Our total score would be <code>(2 + 6) + (1 + 0) + (3 + 3) = 15</code>.</p>
<h2 id="an-elegant-solution"><a href="#an-elegant-solution" aria-label="Anchor link for: an-elegant-solution">An elegant solution</a></h2>
<p>A sane solution would verify that indeed our input lines have the format <code>[ABC] [XYZ]</code>, before extracting those two letters. After converting these letters to
integers <code>0</code>, <code>1</code>, <code>2</code> by subtracting either the ASCII code for <code>&#39;A&#39;</code> or <code>&#39;X&#39;</code>
respectively we can immediately calculate the first component of our score as <code>1 + ours</code>.</p>
<p>The second component is more involved, but can be elegantly solved using <a href="https://en.wikipedia.org/wiki/Modular_arithmetic">modular arithmetic</a>.
Note that if Rock = 0, Paper = 1, Scissor = 2 then we always have that choice ${k + 1 \bmod 3}$
beats $k$. Alternatively, $k$ beats ${k - 1}$, modulo 3:</p>
<p><img src="https://orlp.net/blog/worlds-smallest-hash-table/rock-paper-scissors-mod3.png" alt="Diagram showing modulo 3 arithmetic."/></p>
<p>If we divide the number of points that Advent of Code expects for a loss/draw/win by
three we find that a loss is $0$, a draw is $1$ and a win is $2$ points. From
these observations we can derive the following modular equivalence</p>
<p>$$1 + \mathrm{ours} - \mathrm{theirs} \equiv \mathrm{points} \pmod 3.$$</p>
<p>To see that it is correct, note that if we drew, <code>ours - theirs</code> is zero and we
correctly get one point. If we add one to <code>ours</code> we change from a draw to a
win, and <code>points</code> becomes congruent with $2$ as desired. Symmetrically, if
we add one to <code>theirs</code> we change from a draw to a loss, and <code>points</code> once
again becomes congruent with $0$ as desired.</p>
<p>Translated into code we find that our total score is</p>
<pre data-lang="rust"><code data-lang="rust"><span>1 </span><span>+ ours + </span><span>3 </span><span>* ((</span><span>1 </span><span>+ ours + (</span><span>3 </span><span>- theirs)) % </span><span>3</span><span>)
</span></code></pre>

<h2 id="a-general-solution"><a href="#a-general-solution" aria-label="Anchor link for: a-general-solution">A general solution</a></h2>
<p>We found a neat closed form, but if we were even slightly less fortunate it might
not have existed. A more general method for solving similar problems would be nice.
In this particular instance that is possible. There are only $3 \times 3 = 9$
input pairs, so we can simply hardcode the answer for each situation:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> answers = HashMap::from([
</span><span>    (</span><span>&#34;A X&#34;</span><span>, </span><span>4</span><span>),
</span><span>    (</span><span>&#34;A Y&#34;</span><span>, </span><span>8</span><span>),
</span><span>    (</span><span>&#34;A Z&#34;</span><span>, </span><span>3</span><span>),
</span><span>    (</span><span>&#34;B X&#34;</span><span>, </span><span>1</span><span>),
</span><span>    (</span><span>&#34;B Y&#34;</span><span>, </span><span>5</span><span>),
</span><span>    (</span><span>&#34;B Z&#34;</span><span>, </span><span>9</span><span>),
</span><span>    (</span><span>&#34;C X&#34;</span><span>, </span><span>7</span><span>),
</span><span>    (</span><span>&#34;C Y&#34;</span><span>, </span><span>2</span><span>),
</span><span>    (</span><span>&#34;C Z&#34;</span><span>, </span><span>6</span><span>),
</span><span>]);
</span></code></pre>
<p>Now we can simply get our answer using <code>answers[input]</code>. This might feel as a
bit of a non-answer, but it is a legitimate technique. We have a mapping
of inputs to outputs, and sometimes the simplest or fastest (in either
programmer time or execution time) solution is to write it out explicitly and
completely rather than compute the answer at runtime with an algorithm.</p>
<h2 id="perfect-hash-functions"><a href="#perfect-hash-functions" aria-label="Anchor link for: perfect-hash-functions">Perfect Hash Functions</a></h2>
<p>The above solution works fine, but it pays a cost for its genericity. It uses
a full-fledged string hash algorithm, and lookups involve the full codepath for
hash table lookups (most notably hash collision resolution).</p>
<p>We can drop the genericity for a significant boost in speed if we were to use a
<a href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hash function</a>. A
perfect hash function is a specially constructed hash function on some set $S$
of values such that each value in the set maps to a different hash output,
without collisions. It is important to note that we only care about its behavior
for inputs in the set $S$, with a complete disregard for other inputs.</p>
<p>A <em>minimal</em> perfect hash function is one that also maps the inputs to a dense
range of integers $[0, 1, \dots, |S|-1]$. This can be very useful because you
can then directly use the hash function output to index a lookup table. This
effectively creates a hash table that maps set $S$ to anything you want.
However, strict minimality is not necessary for this as long as you are okay
with wasting some of the space in your lookup table.</p>
<p>There are fully generic methods for constructing (minimal) perfect hash
functions, such as the <a href="https://link.springer.com/chapter/10.1007/978-3-642-04128-0_61"><em>“Hash, displace and compress”</em></a> algorithm by Belazzougui
et. al., which is implemented in the <a href="https://crates.io/crates/phf">phf crate</a>.
However, they tend to use lookup tables to construct the hash itself. For small
inputs where speed and size is absolutely critical I’ve had good success <strong>just
trying stuff</strong>. This might sound vague—because it is—so let me walk you
through some examples.</p>
<h3 id="reading-the-input"><a href="#reading-the-input" aria-label="Anchor link for: reading-the-input">Reading the input</a></h3>

<p>As a bit of a hack we can note that each line of our input from the Advent of
Code consists of exactly four bytes. One letter for our opponent’s choice, a
space, our choice, and a newline byte. So we can simply read our input as a
<code>u32</code>, which simplifies the hash construction immensely instead of dealing with
strings.</p>
<p>For example, consulting the <a href="https://en.wikipedia.org/wiki/ASCII">ASCII table</a>
we find that <code>A</code> has ASCII code <code>0x41</code>, space maps to <code>0x20</code>, <code>X</code> has code
<code>0x58</code> and the newline symbol has code <code>0x0a</code> so the input <code>&#34;A X\n&#34;</code> can also
simply be viewed as the integer <code>0x0a582041</code> if you are on a
<a href="https://en.wikipedia.org/wiki/Endianness">little-endian</a> machine. If you are
confused why <code>0x41</code> is in the last position remember that we humans write numbers with the
least significant digit on the right as a convention.</p>
<p>Note that on a big-endian machine the order of bytes in a <code>u32</code> is flipped, so
reading those four bytes into an integer would result in the value <code>0x4120580a</code>.
Calling <code>u32::from_le_bytes</code> converts four bytes assumed to be little-endian to
the native integer representation by swapping the bytes on a big-endian machine
and doing nothing on a little-endian machine. Almost all modern CPUs are
little-endian however, so it’s generally a good idea to write your code such
that the little-endian path is fast and the big-endian path involves a
conversion step, if a conversion step can not be avoided.</p>
<p>Doing this for all inputs gives us the following desired integer →
integer mapping:</p>
<pre><code><span>Input       LE u32      Answer
</span><span>-------------------------------
</span><span> A X       0xa582041       4
</span><span> A Y       0xa592041       8
</span><span> A Z       0xa5a2041       3
</span><span> B X       0xa582042       1
</span><span> B Y       0xa592042       5
</span><span> B Z       0xa5a2042       9
</span><span> C X       0xa582043       7
</span><span> C Y       0xa592043       2
</span><span> C Z       0xa5a2043       6
</span></code></pre>
<h3 id="example-constructions"><a href="#example-constructions" aria-label="Anchor link for: example-constructions">Example constructions</a></h3>
<p>When I said I just try stuff, I mean it. Let’s load our mapping into Python
and write a test:</p>
<pre data-lang="python"><code data-lang="python"><span>inputs =  [</span><span>0xa582041</span><span>, </span><span>0xa592041</span><span>, </span><span>0xa5a2041</span><span>, </span><span>0xa582042</span><span>,
</span><span>           </span><span>0xa592042</span><span>, </span><span>0xa5a2042</span><span>, </span><span>0xa582043</span><span>, </span><span>0xa592043</span><span>, </span><span>0xa5a2043</span><span>]
</span><span>answers = [</span><span>4</span><span>, </span><span>8</span><span>, </span><span>3</span><span>, </span><span>1</span><span>, </span><span>5</span><span>, </span><span>9</span><span>, </span><span>7</span><span>, </span><span>2</span><span>, </span><span>6</span><span>]
</span><span>
</span><span>def </span><span>is_phf(h, inputs):
</span><span>    </span><span>return </span><span>len({h(x) </span><span>for </span><span>x </span><span>in </span><span>inputs}) == len(inputs)
</span></code></pre>
<p>There are nine inputs, so perhaps we get lucky and get a minimal perfect
hash function right away:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [x % </span><span>9 </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>0</span><span>, </span><span>7</span><span>, </span><span>5</span><span>, </span><span>1</span><span>, </span><span>8</span><span>, </span><span>6</span><span>, </span><span>2</span><span>, </span><span>0</span><span>, </span><span>7</span><span>]
</span></code></pre>
<p>Alas, there are collisions. What if we don’t have to be absolutely minimal?</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; next(m </span><span>for </span><span>m </span><span>in </span><span>range(</span><span>9</span><span>, </span><span>2</span><span>**</span><span>32</span><span>)
</span><span>...      </span><span>if </span><span>is_phf(</span><span>lambda </span><span>x: x % m, inputs))
</span><span>12
</span><span>&gt;&gt;&gt; [x % </span><span>12 </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>9</span><span>, </span><span>1</span><span>, </span><span>5</span><span>, </span><span>10</span><span>, </span><span>2</span><span>, </span><span>6</span><span>, </span><span>11</span><span>, </span><span>3</span><span>, </span><span>7</span><span>]
</span></code></pre>
<p>That’s not too bad! Only three elements of wasted space. We can make our first
perfect hash table by placing the answers in the correct spots:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>make_lut(h, inputs, answers):
</span><span>    </span><span>assert </span><span>is_phf(h, inputs)
</span><span>    lut = [</span><span>0</span><span>] * (</span><span>1 </span><span>+ max(h(x) </span><span>for </span><span>x </span><span>in </span><span>inputs))
</span><span>    </span><span>for </span><span>(x, ans) </span><span>in </span><span>zip(inputs, answers):
</span><span>        lut[h(x)] = ans
</span><span>    </span><span>return </span><span>lut
</span></code></pre>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; make_lut(</span><span>lambda </span><span>x: x % </span><span>12</span><span>, inputs, answers)
</span><span>[</span><span>0</span><span>, </span><span>8</span><span>, </span><span>5</span><span>, </span><span>2</span><span>, </span><span>0</span><span>, </span><span>3</span><span>, </span><span>9</span><span>, </span><span>6</span><span>, </span><span>0</span><span>, </span><span>4</span><span>, </span><span>1</span><span>, </span><span>7</span><span>]
</span></code></pre>
<p>Giving the simple mapping:</p>
<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>LUT</span><span>: [</span><span>u8</span><span>; </span><span>12</span><span>] = [</span><span>0</span><span>, </span><span>8</span><span>, </span><span>5</span><span>, </span><span>2</span><span>, </span><span>0</span><span>, </span><span>3</span><span>, </span><span>9</span><span>, </span><span>6</span><span>, </span><span>0</span><span>, </span><span>4</span><span>, </span><span>1</span><span>, </span><span>7</span><span>];
</span><span>
</span><span>pub </span><span>fn </span><span>answer(x: </span><span>u32</span><span>) -&gt; </span><span>u8 </span><span>{
</span><span>    </span><span>LUT</span><span>[(x % </span><span>12</span><span>) as </span><span>usize</span><span>]
</span><span>}
</span></code></pre>
<h4 id="compressing-the-table"><a href="#compressing-the-table" aria-label="Anchor link for: compressing-the-table">Compressing the table</a></h4>
<p>We stopped here on the first modulus that works, which is honestly fine in this
case because only three bytes of wasted space is pretty good. But what if we
didn’t get so lucky? We have to keep looking. Even though
modulo $m$ has $[0, m)$ as its
<a href="https://en.wikipedia.org/wiki/Codomain"><em>codomain</em></a>, when applied to our set of
inputs its <a href="https://en.wikipedia.org/wiki/Image_(mathematics)"><em>image</em></a> might
span a smaller subset. Let’s inspect some:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [(m, max(x % m </span><span>for </span><span>x </span><span>in </span><span>inputs))
</span><span>...  </span><span>for </span><span>m </span><span>in </span><span>range(</span><span>1</span><span>, </span><span>30</span><span>)
</span><span>...  </span><span>if </span><span>is_phf(</span><span>lambda </span><span>x: x % m, inputs)]
</span><span>[(</span><span>12</span><span>, </span><span>11</span><span>), (</span><span>13</span><span>, </span><span>11</span><span>), (</span><span>19</span><span>, </span><span>18</span><span>), (</span><span>20</span><span>, </span><span>19</span><span>), (</span><span>21</span><span>, </span><span>17</span><span>), (</span><span>23</span><span>, </span><span>22</span><span>),
</span><span> (</span><span>24</span><span>, </span><span>19</span><span>), (</span><span>25</span><span>, </span><span>23</span><span>), (</span><span>26</span><span>, </span><span>21</span><span>), (</span><span>27</span><span>, </span><span>25</span><span>), (</span><span>28</span><span>, </span><span>19</span><span>), (</span><span>29</span><span>, </span><span>16</span><span>)]
</span></code></pre>
<p>Unfortunately but also logically, there is an upwards trend of the maximum
index as you increase the modulus. But $13$ also seems promising, let’s take a look:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [x % </span><span>13 </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>3</span><span>, </span><span>6</span><span>, </span><span>9</span><span>, </span><span>4</span><span>, </span><span>7</span><span>, </span><span>10</span><span>, </span><span>5</span><span>, </span><span>8</span><span>, </span><span>11</span><span>]
</span><span>&gt;&gt;&gt; make_lut(</span><span>lambda </span><span>x: x % </span><span>13</span><span>, inputs, answers)
</span><span>[</span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>4</span><span>, </span><span>1</span><span>, </span><span>7</span><span>, </span><span>8</span><span>, </span><span>5</span><span>, </span><span>2</span><span>, </span><span>3</span><span>, </span><span>9</span><span>, </span><span>6</span><span>]
</span></code></pre>
<p>Well, well, well, aren’t we lucky? The first three indices are unused, so we can
shift all the others back and get a minimal perfect hash function!</p>

<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>LUT</span><span>: [</span><span>u8</span><span>; </span><span>9</span><span>] = [</span><span>4</span><span>, </span><span>1</span><span>, </span><span>7</span><span>, </span><span>8</span><span>, </span><span>5</span><span>, </span><span>2</span><span>, </span><span>3</span><span>, </span><span>9</span><span>, </span><span>6</span><span>];
</span><span>
</span><span>pub </span><span>fn </span><span>answer(x: </span><span>u32</span><span>) -&gt; </span><span>u8 </span><span>{
</span><span>    </span><span>LUT</span><span>[(x % </span><span>13 </span><span>- </span><span>3</span><span>) as </span><span>usize</span><span>]
</span><span>}
</span></code></pre>
<p>In my experience with creating a bunch of similar mappings in the past, <strong>you’d
be surprised to see how often you get lucky</strong>, as long as your mapping isn’t too
large. As you add more ‘things to try’ to your toolbox, you also have more
opportunities of getting lucky.</p>
<h4 id="fixing-near-misses"><a href="#fixing-near-misses" aria-label="Anchor link for: fixing-near-misses">Fixing near-misses</a></h4>
<p>Another thing to try is fixing near-misses. For example, let’s take another look
at our original naive attempt:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [x % </span><span>9 </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>0</span><span>, </span><span>7</span><span>, </span><span>5</span><span>, </span><span>1</span><span>, </span><span>8</span><span>, </span><span>6</span><span>, </span><span>2</span><span>, </span><span>0</span><span>, </span><span>7</span><span>]
</span></code></pre>
<p>Only the last two inputs give a collision. So a rather naive but possible way
to resolve these collisions is to move those to a different index:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [x % </span><span>9 </span><span>+ </span><span>3</span><span>*(x == </span><span>0xa592043</span><span>) - </span><span>3</span><span>*(x == </span><span>0xa5a2043</span><span>) </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>0</span><span>, </span><span>7</span><span>, </span><span>5</span><span>, </span><span>1</span><span>, </span><span>8</span><span>, </span><span>6</span><span>, </span><span>2</span><span>, </span><span>3</span><span>, </span><span>4</span><span>]
</span></code></pre>
<p>Oh look, we got slightly lucky again: both are using the constant 3, which can be
factored out. It can be quite addictive to try out various permutations of
operations and tweaks to find these (minimal) perfect hash functions using as
few operations as possible.</p>
<h2 id="an-interlude-integer-division"><a href="#an-interlude-integer-division" aria-label="Anchor link for: an-interlude-integer-division">An interlude: integer division</a></h2>
<p>So far we’ve just been using the modulo operator to reduce our input domain to a
much smaller one. However, integer division/modulo is rather slow on most
processors. If we take a look at <a href="https://www.agner.org/optimize/">Agner Fog’s instruction
tables</a> we see that the 32-bit <code>DIV</code>
instruction has a latency of 9-12 cycles on AMD Zen3 and 12 cycles on Intel Ice
Lake. However, we don’t need a fully generic division instruction, since our
divisor is constant here. Let’s take a quick look at what the compiler does for
mod 13:</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub </span><span>fn </span><span>mod13(x: </span><span>u32</span><span>) -&gt; </span><span>u32 </span><span>{
</span><span>    x % </span><span>13
</span><span>}
</span></code></pre>
<pre data-lang="asm"><code data-lang="asm"><span>example::mod13:
</span><span>        </span><span>mov     </span><span>eax, edi
</span><span>        </span><span>mov     </span><span>ecx, edi
</span><span>        </span><span>imul    </span><span>rcx, rcx, </span><span>1321528399
</span><span>        </span><span>shr     </span><span>rcx, </span><span>34
</span><span>        </span><span>lea     </span><span>edx, [rcx + </span><span>2</span><span>*rcx]
</span><span>        </span><span>lea     </span><span>ecx, [rcx + </span><span>4</span><span>*rdx]
</span><span>        </span><span>sub     </span><span>eax, ecx
</span><span>        </span><span>ret
</span></code></pre>
<p>It translates the modulo operation into a multiplication with some shifts / adds / subtractions instead.
To see how that works let’s first consider the most magical part: the multiplication by $1321528399$ followed
by the right shift of $34$. That magical constant is actually $\lceil 2^{34} / 13 \rceil$ 
which means it’s computing</p>
<p>$$q = \left\lfloor \frac{x \cdot \lceil 2^{34} / 13 \rceil}{2^{34}}\right\rfloor = \lfloor x / 13 \rfloor.$$</p>
<p>To prove that is in fact correct we note that $2^{34} + 3$ is divisible by $13$ allowing us
to split the division in the correct result plus an error term:</p>
<p>$$\frac{x \cdot \lceil 2^{34} / 13 \rceil}{2^{34}} = \frac{x \cdot (2^{34} + 3) / 13}{2^{34}} = x / 13 + \frac{3x}{13\cdot 2^{34}}.$$</p>
<p>Then we inspect the error term and substitute $x = 2^{32}$ as an upper bound
to see it never affects the result after flooring:</p>
<p>$$\frac{3x}{13\cdot 2^{34}} \leq \frac{3 \cdot 2^{32}}{13\cdot 2^{34}} \leq \frac{3}{13 \cdot 4} &lt; 1/13.$$</p>
<p>For more context and references I would suggest <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8258644/"><em>“Integer division by constants:
optimal bounds”</em></a> by
Lemire et. al.</p>
<p>After computing $q = \lfloor x/13\rfloor$ it then computes the actual modulo we
want as $m = x - 13q$ using
the identity $$x \bmod m = x - \lfloor x / m \rfloor \cdot m.$$
It avoids the use of another (relatively) expensive integer multiplication by using
the <code>lea</code> instruction which can compute <code>a + k*b</code>, where <code>k</code> can be a constant
1, 2, 4, or 8. This is how it computes $13q$:</p>

<pre><code><span>Instruction                  Translation     Effect
</span><span>lea     edx, [rcx + 2*rcx]   t := q + 2*q    t = 3q
</span><span>lea     ecx, [rcx + 4*rdx]   o := q + 4*t    o = (q + 4*3q) = 13q
</span></code></pre>
<h2 id="bit-mixing"><a href="#bit-mixing" aria-label="Anchor link for: bit-mixing">Bit mixing</a></h2>
<p>We have seen that choosing different moduli works, and that compilers implement
fixed-divisor modulo using multiplication. It is time to cut out the
middleman and go straight to the good stuff: integer multiplication.
We can get a better understanding of what integer multiplication actually does
by multiplying two integers in binary using the schoolbook method:</p>
<pre><code><span>4242 = 0b1000010010010
</span><span>4871 = 0b1001100100111 = 2^0 + 2^1 + 2^2 + 2^5 + 2^8 + 2^9 + 2^12
</span><span>
</span><span>          Binary                    Decimal
</span><span>               1000010010010   |   4242 * 2^0
</span><span>              1000010010010    |   4242 * 2^1
</span><span>             1000010010010     |   4242 * 2^2
</span><span>          1000010010010        |   4242 * 2^5
</span><span>       1000010010010           |   4242 * 2^8
</span><span>      1000010010010            |   4242 * 2^9
</span><span>   1000010010010               |   4242 * 2^12
</span><span>-------------------------------|---------------- +
</span><span>   1001110110100100111111110   |   20662782
</span></code></pre>
<p>There is a beautiful property here we can take advantage of: all of the upper
bits of the product $x \cdot c$ for some constant $c$ depend on most of the bits
of $x$. That is, for good choices of the constants $c$ and $s$, <code>c*x &gt;&gt; s</code> will
give you a result that is wildly different even for small differences in $x$. It
is a strong <em>bit mixer</em>.</p>
<p>Hash functions like bit mixing functions, because they want to be unpredictable.
A good measure of unpredictability is found in the <a href="https://en.wikipedia.org/wiki/Avalanche_effect">avalanche
effect</a>. For a true random oracle
changing one bit in the input should flip all bits in the output with 50% probability.
Thus having all your output bits depend on the input is a good property for
a hash function, as a random oracle is the ideal hash function.</p>
<p>So, let’s just <strong>try something</strong>. We’ll stick with using modulo $2^k$
for maximum speed (as those can be computed with a binary AND instead of
needing multiplication), and try to find constants $c$
and $s$ that work. We want our codomain to have size $2^4 = 16$ since that’s the
smallest power of two bigger than $9$. We’ll use a $32 \times 32 \to 32$ bit multiply
since we only need 4 bits of output, and the top 4 bits of the multiplication
will depend sufficiently on most of the bits of the input. By doing a right-shift
of $28$ on a <code>u32</code> result we also get our mod $2^4$ for free.</p>

<pre data-lang="python"><code data-lang="python"><span>import </span><span>random
</span><span>random.seed(</span><span>42</span><span>)
</span><span>
</span><span>def </span><span>h(x, c):
</span><span>    m = (x * c) % </span><span>2</span><span>**</span><span>32
</span><span>    </span><span>return </span><span>m &gt;&gt; </span><span>28
</span><span>
</span><span>while </span><span>True</span><span>:
</span><span>    c = random.randrange(</span><span>2</span><span>**</span><span>32</span><span>)
</span><span>    </span><span>if </span><span>is_phf(</span><span>lambda </span><span>x: h(x, c), inputs):
</span><span>        print(hex(c))
</span><span>        </span><span>break
</span></code></pre>
<p>It’s always a bit exciting to hit enter when doing a random search for a magic
constant, not knowing if you’ll get an answer or not. In this case it instantly
printed <code>0x46685257</code>. Since it was so fast there are likely many solutions, so
we can definitely be a bit greedier and see if we can get closer to a minimal
perfect hash function:</p>
<pre data-lang="python"><code data-lang="python"><span>best = float(</span><span>&#39;inf&#39;</span><span>)
</span><span>while </span><span>best &gt;= len(inputs):
</span><span>    c = random.randrange(</span><span>2</span><span>**</span><span>32</span><span>)
</span><span>    max_idx = max(h(x, c) </span><span>for </span><span>x </span><span>in </span><span>inputs)
</span><span>    </span><span>if </span><span>max_idx &lt; best and is_phf(</span><span>lambda </span><span>x: h(x, c), inputs):
</span><span>        print(max_idx, hex(c))
</span><span>        best = max_idx
</span></code></pre>
<p>This quickly iterated through a couple of solutions before finding a constant that gives a minimal perfect hash function,
<code>0xedc72f12</code>:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; [h(x, </span><span>0xedc72f12</span><span>) </span><span>for </span><span>x </span><span>in </span><span>inputs]
</span><span>[</span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>, </span><span>1</span><span>, </span><span>4</span><span>, </span><span>7</span><span>, </span><span>0</span><span>, </span><span>3</span><span>, </span><span>6</span><span>]
</span><span>&gt;&gt;&gt; make_lut(</span><span>lambda </span><span>x: h(x, </span><span>0xedc72f12</span><span>), inputs, answers)
</span><span>[</span><span>7</span><span>, </span><span>1</span><span>, </span><span>4</span><span>, </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>, </span><span>6</span><span>, </span><span>9</span><span>, </span><span>3</span><span>]
</span></code></pre>
<p>Ironically, if we want the optimal performance in safe Rust, we still need to
zero-pad the array to 16 elements so we can never go out-of-bounds. But if you
are <strong>absolutely certain</strong> there are no inputs other than the specified inputs,
and you wanted optimal speed, you could reduce your memory usage to 9 bytes with
unsafe Rust. Sticking with the safe code option we’ll get:</p>
<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>LUT</span><span>: [</span><span>u8</span><span>; </span><span>16</span><span>] = [</span><span>7</span><span>, </span><span>1</span><span>, </span><span>4</span><span>, </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>, </span><span>6</span><span>, </span><span>9</span><span>, </span><span>3</span><span>,
</span><span>                       </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>];
</span><span>
</span><span>pub </span><span>fn </span><span>phf_lut(x: </span><span>u32</span><span>) -&gt; </span><span>u8 </span><span>{
</span><span>    </span><span>LUT</span><span>[(x.wrapping_mul(</span><span>0xedc72f12</span><span>) &gt;&gt; </span><span>28</span><span>) as </span><span>usize</span><span>]
</span><span>}
</span></code></pre>
<p>Inspecting the assembly code using the <a href="https://rust.godbolt.org/z/KvP4v187P">Compiler
Explorer</a> it is incredibly tight now:</p>
<pre data-lang="asm"><code data-lang="asm"><span>example::phf_lut:
</span><span>        </span><span>imul    </span><span>eax, dword ptr [rdi], -</span><span>305713390
</span><span>        </span><span>shr     </span><span>rax, </span><span>28
</span><span>        </span><span>lea     </span><span>rcx, [rip + .L__unnamed_1]
</span><span>        </span><span>movzx   </span><span>eax, byte ptr [rax + rcx]
</span><span>        </span><span>ret
</span><span>
</span><span>.L__unnamed_1:
</span><span>        .asciz  </span><span>&#34;\007\001\004\002\005\b\006\t\003\000\000\000\000\000\000&#34;
</span></code></pre>
<h2 id="the-world-s-smallest-hash-table"><a href="#the-world-s-smallest-hash-table" aria-label="Anchor link for: the-world-s-smallest-hash-table">The World’s Smallest Hash Table</a></h2>
<p>You thought 9 bytes was the world’s smallest hash table? We’re only just getting
started! You see, it is actually possible to have a small lookup table without
accessing memory, by storing it in the code.</p>

<p>A particularly effective method for storing a small lookup table with small
elements is to store it as a constant, indexed using shifts. For example, the lookup
table <code>[1, 42, 17, 26][i]</code> could also be written as such:</p>
<pre data-lang="rust"><code data-lang="rust"><span>(</span><span>0b11010010001101010000001 </span><span>&gt;&gt; </span><span>6</span><span>*i) &amp; </span><span>0b111111
</span></code></pre>
<p>Each individual value fits in 6 bits, and we can easily fit $4\times 6 = 24$
bits in a <code>u32</code>. In isolation this might not make sense over a normal lookup
table, but it can be combined with perfect hashing, and can be vectorized as
well.</p>
<p>Unfortunately we have 9 values that each require 5 bits, which doesn’t fit in
a <code>u32</code>… or does it? You see, by co-designing the lookup table with the
perfect hash function we could theoretically <em>overlap</em> the end of the bitstring
of one value with the start of another if we directly use the hash
function output as the shift amount.</p>
<p><strong>Update on 2023-03-05</strong>: As tinix0 rightfully <a href="https://www.reddit.com/r/programming/comments/11i3hfy/the_worlds_smallest_hash_table/jazrwok/">points out on
reddit</a>,
our values only require 4 bits, not 5. I’ve made things unnecessarily harder for
myself by effectively prepending a zero bit to each value. That said, you would
still need overlapping for fitting $4 \times 9 = 36$ bits in a <code>u32</code>.</p>

<p>We are thus looking for two 32-bit constants <code>c</code> and <code>d</code> such that</p>
<pre data-lang="rust"><code data-lang="rust"><span>(d &gt;&gt; (x.wrapping_mul(c) &gt;&gt; </span><span>27</span><span>)) &amp; </span><span>0b11111 </span><span>== answer(x)
</span></code></pre>
<p>Note that the magic shift is now 32 - 5 = 27 because we want 5 bits of output to feed into the
second shift, as $2^5 = 32$.</p>
<p>Luckily we don’t have to actually increase the search space, as we can construct
<code>d</code> from <code>c</code> by just placing the answer bits in the indicated shift positions.
Doing this we can also find out whether <code>c</code> is valid or not by detecting conflicts
in whether a bit should be $0$ or $1$ for different inputs. Will we be lucky?</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>build_bit_lut(h, w, inputs, answers):
</span><span>    zeros = ones = </span><span>0
</span><span>
</span><span>    </span><span>for </span><span>x, a </span><span>in </span><span>zip(inputs, answers):
</span><span>        shift = h(x)
</span><span>        </span><span>if </span><span>zeros &amp; (a &lt;&lt; shift) or ones &amp; (~a % </span><span>2</span><span>**w &lt;&lt; shift):
</span><span>            </span><span>return </span><span>None  </span><span># Conflicting bits.
</span><span>        zeros |= ~a % </span><span>2</span><span>**w &lt;&lt; shift
</span><span>        ones |= a &lt;&lt; shift
</span><span>    
</span><span>    </span><span>return </span><span>ones
</span><span>    
</span><span>def </span><span>h(x, c):
</span><span>    m = (x * c) % </span><span>2</span><span>**</span><span>32
</span><span>    </span><span>return </span><span>m &gt;&gt; </span><span>27
</span><span>
</span><span>random.seed(</span><span>42</span><span>)
</span><span>while </span><span>True</span><span>:
</span><span>    c = random.randrange(</span><span>2</span><span>**</span><span>32</span><span>)
</span><span>    lut = build_bit_lut(</span><span>lambda </span><span>x: h(x, c), </span><span>5</span><span>, inputs, answers)
</span><span>    </span><span>if </span><span>lut is not </span><span>None </span><span>and lut &lt; </span><span>2</span><span>**</span><span>32</span><span>:
</span><span>        print(hex(c), hex(lut))
</span><span>        </span><span>break
</span></code></pre>
<p>It takes a second or two, but we found a solution! </p>
<pre data-lang="rust"><code data-lang="rust"><span>pub </span><span>fn </span><span>phf_shift(x: </span><span>u32</span><span>) -&gt; </span><span>u8 </span><span>{
</span><span>    </span><span>let</span><span> shift = x.wrapping_mul(</span><span>0xa463293e</span><span>) &gt;&gt; </span><span>27</span><span>;
</span><span>    ((</span><span>0x824a1847</span><span>u32 </span><span>&gt;&gt; shift) &amp; </span><span>0b11111</span><span>) as </span><span>u8
</span><span>}
</span></code></pre>
<pre data-lang="asm"><code data-lang="asm"><span>example::phf_shift:
</span><span>        </span><span>imul    </span><span>ecx, dword ptr [rdi], -</span><span>1537005250
</span><span>        </span><span>shr     </span><span>ecx, </span><span>27
</span><span>        </span><span>mov     </span><span>eax, -</span><span>2109073337
</span><span>        </span><span>shr     </span><span>eax, cl
</span><span>        </span><span>and     </span><span>al, </span><span>31
</span><span>        </span><span>ret
</span></code></pre>
<p>We have managed to replace a fully-fledged hash table
with one that is so small that it consists of 6
(vectorizable) assembly instructions without any
further data.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="Anchor link for: conclusion">Conclusion</a></h2>
<p>Wew, that was a wild ride. Was it worth it? Let’s
compare four hash-based versions on how long they take to process
ten million lines of random input and sum all answers.</p>
<ol>
<li>
<p><code>hashmap_str</code> processes the lines properly as newline
delimited strings, as in the <a href="https://orlp.net/blog/worlds-smallest-hash-table/#a-general-solution">general solution</a>.</p>
</li>
<li>
<p><code>hashmap_u32</code> still uses a hashmap, but reads the lines and does lookups
using <code>u32</code>s like the perfect hash functions do.</p>
</li>
<li>
<p><code>phf_lut</code> is the earlier defined function that feeds a perfect
hash function into a lookup table.</p>
</li>
<li>
<p><code>phf_shift</code> is our world’s smallest hash function.</p>
</li>
</ol>
<p>The complete test code can be found <a href="https://gist.github.com/orlp/fdc27b86e658c3b6df709c68ab477a14">here</a>. On my 2021 Apple M1 Macbook Pro
I get the following results with <code>cargo run --release</code> on Rust 1.67.1:</p>
<table><thead><tr><th>Algorithm</th><th>Time</th></tr></thead><tbody>
<tr><td><code>hashmap_str</code></td><td>262.83 ms</td></tr>
<tr><td><code>hashmap_u32</code></td><td>81.33 ms</td></tr>
<tr><td><code>phf_lut</code></td><td>2.97 ms</td></tr>
<tr><td><code>phf_shift</code></td><td>1.41 ms</td></tr>
</tbody></table>
<p>So not only is it the smallest, it’s also the fastest, beating the original
string-based <code>HashMap</code> solution by over 180 times. The reason <code>phf_shift</code> is
two times faster than <code>phf_lut</code> on this machine is because it can be fully
vectorized by the compiler whereas <code>phf_lut</code> needs to do a lookup in memory
which is either impossible or relatively slow to do in vectorized code,
depending on which SIMD instructions you have available.</p>
<p>Your results may vary, and you might need 
<code>RUSTFLAGS=&#39;-C target-cpu=native&#39;</code> for <code>phf_shift</code> to autovectorize.</p>

</article></div>
  </body>
</html>
