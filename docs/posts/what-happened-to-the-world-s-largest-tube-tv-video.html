<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.youtube.com/watch?v=JfZxOuc9Qwk">Original</a>
    <h1>What happened to the world&#39;s largest tube TV? [video]</h1>
    
    <div id="readability-page-1" class="page"><div>

<details>
  <summary>Blast from the past</summary>
<p>Stephen and I wrote this paper for last year’s
<a href="https://sigbovik.org/" rel="external" target="_blank">SIGBOVIK</a>,
a satirical computer science conference that takes place
around April 1 each year.
You can find the PDF version in the <a href="https://www.sigbovik.org/2024/proceedings.pdf" rel="external" target="_blank">2024 proceedings</a>,
or in <a href="https://github.com/cceckman/fractal-farlands" rel="external" target="_blank">the repository</a>.</p>
<p>While brainstorming 2025 submissions,
I decided to give this a little refresher.
The inline images are now interactive, thanks to the magic of
<a href="https://webassembly.org/" rel="external" target="_blank">WebAssembly</a>.</p>
<p>I’ve made some minor textual edits,
and re-generated all figures from scratch.
Minor figure differences from the paper
come from missing parameters (we didn’t write them down);
the major changes are footnoted for figures 10<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
and 11<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
</details>
<h2 id="abstract">Abstract</h2>
<p>As erstwhile rock stars, the authors have intentionally applied distortion to certain 1-D signals for aesthetic effect.
Sometimes this distortion comes from saturating the signal (overdrive); other times, it comes from a more subtle
transformation, such as vacuum tube or transistor amplification. Some of the authors’ peers use <a href="https://www.fractalaudio.com/artists/" rel="external" target="_blank">“fractal audio processing”</a> for distortive effects.</p>
<p>In this paper, we explore another dimension, and investigate how different ways of representing small numbers distort the world differently. To get a vibe check on numerical imprecision, we rendered two fractals using various numeric formats.</p>
<figure>
<fractal-overdrive name="Figure 1" original="teaser.png" x="304924415867450" y="115639204659165" window="16067102519808" scale="803355125990400" resolution="1024" numeric="MaskedFloat&lt;3,50&gt;" iterations="128"></fractal-overdrive>
<figcaption>Figure 1: We meant to do that.</figcaption>
</figure>


<blockquote>
<p><a href="https://dl.acm.org/ccs" rel="external" target="_blank">CCS Concepts</a>:</p>
<ul>
<li><strong>Computing methodologies – Symbolic and algebraic manipulation – Representation of mathematical objects – Representation of exact numbers</strong></li>
<li>Computing methodologies – Computer graphics – Rendering – Rasterization</li>
<li>Human-centered computing – Interaction design – Empirical studies in interaction design</li>
<li><strong>Human-centered computing – Visualization – Empirical studies in visualization</strong></li>
</ul>
</blockquote>
<h2 id="real-math">Real Math</h2>
<h3 id="feed-me-fractals">Feed me fractals</h3>
<p>In this paper, we investigate two fractals: the Mandelbrot set and a
Newton fractal. Both map a pixel coordinate \((x, y)\) into the complex
plane as \(c = x + yi\).</p>
<p>We evaluate the Mandelbrot set in the usual way:</p>
$$\begin{aligned}
z_0     &amp;= 0            \\
z_{n+1} &amp;= {z_n}^2 + c\end{aligned}$$<p>up to an iteration limit (\(n\)). Pixels that escape (\(|z| \geq 2\)) are
given a hue according to <a href="https://mrob.com/pub/muency/continuousdwell.html" rel="external" target="_blank">Munafo 2023</a>. Pixels that do not escape are
colored black.</p>
<p>We compute the Newton fractal on the polynomial \(p(z) = z^3-1\):</p>
$$\begin{aligned}
z_0     &amp;= c                        \\
z_{n+1} &amp;= \frac{p(z_n)}{p&#39;(z_n)}\end{aligned}$$<p>and plot whether \(z\) reaches zero within a specified iteration limit.
Points that reach zero (within some threshold) are grouped based on
which zero of the function they are close to. Pixels are colored by
assigning each group a hue, and given a color value according to how
many iterations it took to converge to zero.</p>
<h3 id="exact-computation-via-bigrational">Exact computation via <code>BigRational</code></h3>
<p>Since we’re rendering for a computer screen, <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> we can (and do!) use
exact inputs.</p>
<p>The raster grid (pixel grid) has integer locations, with
\(xres \times yres\) pixels. We map each (integer) pixel location
\((px,py)\) to a (rational) vector within the render window, centered at
\((0,0)\):</p>
$$\begin{aligned}
\hat{x} &amp;= \frac{px}{xres} - \frac{1}{2} \\
\hat{y} &amp;= \frac{1}{2} - \frac{py}{yres}\end{aligned}$$<p>We render a portion of the complex plane centered at
\((\frac{x_c}{scale}, \frac{y_c}{scale})\), with equal width and height
\(\frac{size}{scale}\). We constrain these to all be rational numbers,
which allows us to compute exact (rational) pixel coordinates:</p>
$$\begin{aligned}
x &amp;= \hat{x} \times \frac{size}{scale} + \frac{x_c}{scale} \\
y &amp;= \hat{y} \times \frac{size}{scale} + \frac{y
_c}{scale}\end{aligned}$$<p>We perform these computations using an arbitrary-precision rational
number type, <a href="https://docs.rs/num/latest/num/type.BigRational.html" rel="external" target="_blank"><code>num::BigRational</code></a>. <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup></p>
<p>In principle, we could also carry out the fractal computations exactly
using <code>BigRational</code>. The fractal formulae above require complex
arithmetic, which is simple, plus some comparison operators (&#34;greater
than four&#34; for Mandelbrot, &#34;zeroish&#34; for Newton).</p>
<p>When we tried to render the fractals using <code>BigRational</code>, though, it
reached a hard timeout (against the author’s patience). Moreover,
rationality has little place in an aesthetic evaluation such as this, so
we stick with finite-precision types.</p>
<h2 id="unreal-numbers">Unreal numbers</h2>
<p>Instead, we convert <code>BigRational</code> values to various numeric formats,
approximating as closely as the format allows. Some of the conversions
might even be correct (e.g. those we didn’t write).</p>
<p>The formats we investigate are:</p>
<ul>
<li>
<p><code>f32</code> and <code>f64</code>: IEEE 754 single- and double-precision
floating-point formats (<a href="https://www.bibsonomy.org/bibtex/217408cd727ef3e502b41d9d0e8502e60/jaeschke" rel="external" target="_blank">Cowlishaw et al 2008</a>)</p>
</li>
<li>
<p><code>MaskedFloat&lt;N,M&gt;</code>, an IEEE 754 float with some exponent and/or
mantissa bits removed</p>
</li>
<li>
<p><code>IxFy</code>, fixed-point numeric formats (<a href="https://www.electronicdesign.com/technologies/embedded/article/21805517/whats-the-difference-between-fixed-point-floating-point-and-numerical-formats" rel="external" target="_blank">Wong 2017</a>, <a href="https://docs.rs/fixed/1.26.0/fixed/index.html" rel="external" target="_blank">implementation</a>)</p>
</li>
<li>
<p><code>P32</code>, <code>P16</code>, <code>P8</code>: 32/16/8-bit posits,™ an alternate float-like
format (<a href="https://posithub.org/docs/posit_standard-2.pdf" rel="external" target="_blank">Posit Working Group 2022</a>)</p>
</li>
</ul>
<h3 id="maskedfloat">MaskedFloat</h3>
<p>MaskedFloat isn’t yet a popular floating point type, but one we made up
for this paper to try to create more interesting errors than we were
seeing with just IEEE <code>f64</code>. It involves taking an <code>f64</code>, and masking
off some of the bits, for our own amusement.</p>
<p>A normal <code>f64</code> consists of one bit of <strong>s</strong>ign, 11 bits of e<strong>x</strong>ponent,
and then 52 <strong>f</strong>ractional bits, representing the value:</p>
$$(-1)^{s} \times (1.f_{51} f_{50} f_{48} ... f_0 ) \times 2^{x - 1023}$$<p>If we want to experiment with what the world could be like if these were
different (smaller) sizes, we can force some of those bits to one or
zero. For the fractional bits, this is easy, as they are an unsigned
value–just setting the least-significant bits to zero gets rid of it.</p>
<p>For the exponential bits, this is more complicated. If we want to
constrain the exponent to be effectively 4 bits (i.e., range from -7 to
8), we have to constrain the exponent value to be between 1016 and
1031). Thankfully, we can do this with a bit of bit-twiddling. To make
that easy to see, first, let’s see those values in binary:</p>
$$\begin{aligned}
1016 &amp;= 0b01111111000 \\
1031 &amp;= 0b10000000111\end{aligned}$$\[9:3\]\[9:3\]<p> are also not set (i.e., less than 1016), clamp up to
1016.</p>
<p>This naive masking does have the side effect of re-introducing some of
the problems near zero that IEEE had carefully removed when they added
subnormals, as well as adding some more, unique problems. Since our goal
in this paper is &#34;shenanigans&#34;, that’s great news for us.</p>
<p>The exponent has a special value, all-zeros, that is used along with an
all-zero fraction to represent, unsurprisingly, zero. A naive exponent
mask would turn that value instead into the smallest possible exponent
(e.g., in the previous example, \(2^{-1}\)), which isn’t quite accurate;
though that inaccuracy can be interesting, zero is a useful number for
fractal computation, so we preserve this special-case behavior.</p>
<h3 id="fixed-point">Fixed-point</h3>
<p>We use the <code>fixed</code> Rust <a href="https://docs.rs/fixed/1.26.0/fixed/index.html" rel="external" target="_blank">library</a> to perform fixed-point
arithmetic.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> The library offers a family of fixed-point formats
specified as <code>IxFy</code>, with \(x\) signed integer bits and \(y\) fractional
bits.</p>
<p>In this paper, we show a subset of the fixed-point formats we thought
were coolest.</p>
<h3 id="positstrade-and-quires">Posits™ and quires</h3>
<p>For posits,™ we use the <code>softposit</code> Rust <a href="https://docs.rs/softposit/0.4.0/softposit/" rel="external" target="_blank">library</a> and we
implement conversion from <code>BigRational</code> via the associated quire types.
The quire formats are wider fixed-precision formats associated with
posits.™ For instance, the quire associated with the 32-bit posit™ is 512
bits wide, with a precision of \(2^{-240}\) – roughly equivalent to an
<code>I241F240</code> fixed-point.</p>
<h3 id="sources-of-distortion">Sources of distortion</h3>
<p>When rendering fractals, distortion, like inspiration, can come from
anywhere.</p>
<h4 id="bugs">Bugs</h4>
<p>When implementing the MaskedFloat type, the authors originally did not
properly account for the special case around zero, and instead
represented it as the smallest possible positive number. This resulted
in strange, but pretty neat looking, asymmetrical error, depicted in
<a href="#0-mfbug">Figure 2</a>.</p>
<div id="0-mfbug">
<figure><a href="https://cceckman.com/writing/fractal-overdrive/0-mfbug/mf3-bugged.png"><img src="https://cceckman.com/writing/fractal-overdrive/0-mfbug/mf3-bugged.png" alt="Figure 2a: An asymmetric error in MaskedFloat (buggy)"/></a><figcaption>
      <p>Figure 2a: An asymmetric error in MaskedFloat (buggy)</p>
    </figcaption>
</figure>
<figure><a href="https://cceckman.com/writing/fractal-overdrive/0-mfbug/mf3-nobug.png"><img src="https://cceckman.com/writing/fractal-overdrive/0-mfbug/mf3-nobug.png" alt="Figure 2b: An asymmetric error in MaskedFloat (weird, but not a bug)"/></a><figcaption>
      <p>Figure 2b: An asymmetric error in MaskedFloat (weird, but not a bug)</p>
    </figcaption>
</figure>
</div>
<h4 id="scale">Scale</h4>
<p>The Mandelbrot and Newton fractals both exhibit self-similarity,
repeating themselves at various scales. However, not all of the formats
sampled can operate at multiple scales: all of them have some scaling
limits, but some are more limited than others.</p>
<p>This is most obvious when dealing with fixed-point formats. <code>I11F5</code>, for
instance, can only represent 128 distinct values in the range
\(|z| &lt; 2\) - where the Mandelbrot set lives. That’s fewer than the pixels
used to render these images – hence, pixelation, as shown in <a href="#fig:3">Figure 3</a>.</p>
<figure id="fig:3">


<figcaption>Figure 3: Mandelbrot in f32 and I11F5</figcaption>
</figure>
<p>The nature and pattern of the pixelation depends on the format used, as
shown in <a href="#fig:4">Figure 4</a>. In a region of size \(\frac{2}{3}\) centered on
\(\frac{-4}{3} + 0i\), the <code>P8</code> and <code>I11F5</code> formats show different
aesthetic qualities. P8 (depicted) and floating-point stretch into
rectangles when far from \(x=y\); while fixed-point gives
the appearance of overlapping tiles.</p>
<figure id="fig:4">


<figcaption>Figure 4: Mandelbrot in P8 and I11F5, zoomed</figcaption>
</figure>
<h4 id="precision-error">Precision error</h4>
<p>It’s possible to preserve dynamic range (see <a href="#hdr">the below section</a>)
but lose precision,
as in <code>MaskedFloat&lt;6,3&gt;</code>: it has 6 bits of exponent (scale), but only 4
bits at any given scale.
<a href="#fig:5">Figure 5</a> shows this in the Newton fractal. The area
close to the origin maintains high resolution, but it becomes steadily
more pixelated further out. In some sense, this error mirrors the human
eye’s capabilities: a foveal region in the center of vision/complex
plane.</p>
<figure id="fig:5">
<fractal-overdrive name="figure 5" fractal="newton" resolution="1024" numeric="MaskedFloat&lt;6,3&gt;" original="1-mantissa/mf63.png">
</fractal-overdrive>
<figcaption>Figure 5: Newton in MaskedFloat&lt;6,3&gt;</figcaption>
</figure>
<h4 id="exponent-error">Exponent error</h4>
<p>This is the key characteristic of MaskedFloat when configured for high
precision (many mantissa bits) but a small dynamic range. The places
where the exponent saturates, we introduce distortion. This distortion
appears as arcs of discontinuity in the render. See <a href="#fig:6">Figure 6</a>
for a comparison of Mandelbrot fractal rendered with the f64 and
MaskedFloat formats (configured with 4 exponent bits and 51 mantissa bits.)</p>
<figure id="fig:6">


<figcaption>Figure 6: Exponent error in Mandelbrot</figcaption>
</figure>
<h3 id="hdr">A note on dynamic range</h3>
<p>For the fractals of interest, coloring a point involves iterating on a
value. Since in many of the numerical formats, larger numbers means
large possible errors, the range of values this calculation reaches
matters.</p>
<p>This affects how much distortion we see in the Mandelbrot fractal
compared to Newton: in the Mandelbrot set, the iterated values tend to
stay near their starting point, or become larger than our escape
threshold 4, but in the Newton fractal, intermediate values can become
very large when the slope is near zero, and the final numbers are very
small, as \(f(z)\) approaches zero.</p>
<h2 id="which-pictures-are-prettiest">Which pictures are prettiest?</h2>
<p>You may also be interested in <a href="https://github.com/cceckman/fractal-farlands/issues/11" rel="external" target="_blank">this development thread</a>,
where the authors have noted regions of interest.</p>
<h3 id="if-its-fixed-its-broken">If it’s fixed, it’s broken</h3>
<p>Figures <a href="#fig:3">3</a> and <a href="#fig:4">4</a> don’t do a lot to recommend fixed-point to us.
Pixelation can be nice if you’re a child of the 80s or something, but
it’s not really weird enough that we should use a whole new numeric
format. Just use <a href="https://imagemagick.org/" rel="external" target="_blank">ImageMagick</a>, like <a href="https://xkcd.com/2347/" rel="external" target="_blank">everyone else</a>.</p>
<p>The Newton fractal is a different story, as already shown in Figure
<a href="#fig:5">5</a>.
Since the Newton fractal may result in very small or very large
intermediate values, fixed-point numbers are uniquely poorly suited for
accurate computation. In <a href="#fig:7">Figure 7</a>, we can see a nice fractal visualization
of approaches to zeros become a fractal hellscape of non-convergence and
incorrect answers, by switching from <code>f64</code> to <code>I22F10</code>. Despite no
longer containing useful information, the distorted Newton fractal
looks much cooler.</p>
<figure id="fig:7">
<!-- newton/?x=0&y=0&window=4&scale=1&res=512&iters=64 -->


<figcaption>Figure 7: Floating and fixed-precision Newton</figcaption>
</figure>
<h3 id="pixels-and-positstrade">Pixels and Posits™</h3>
<p>Posits™ maintain greater precision than <code>f32</code>, with the same number of
bits. <a href="#fig:8">Figure 8</a>
shows <code>f32</code>, <code>f64</code>, and <code>P32</code> over the same
area.</p>
<figure id="fig:8"> 



<figcaption>Figure 8: Various precisions of Mandelbrot</figcaption>
</figure>
<p>Clearly posits™ are the best option for everything. Right? Come. Follow
the word of <a href="https://posithub.org/docs/posit_standard-2.pdf" rel="external" target="_blank">Gustafson</a>. Enter the circle between zero and
infinity. join us Join Us JOIN US <strong>JOIN US</strong></p>
<p>Sorry, got a little chanty there–didn’t mean to scare you. Can we
interest you in <a href="https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/posits/" rel="external" target="_blank">an informative pamphlet</a>?</p>
<h3 id="newtonian-surfaces">Newtonian surfaces</h3>
<p>Let’s face it, there’s a reason that Mandelbrot is popular: there’s lots
of different shapes and colors. But despite being less popular, Newton
fractals have some interesting artifacts too! Seriously! Promise!</p>
<p>Like <a href="#fig:9">Figure 9</a>: floating-point and <code>P32</code> formats all
run up against the iteration limit at the center area. However,
evaluation at higher iterations &#34;closes&#34; the hole (not shown).</p>
<figure id="fig:9"> 



<figcaption>Figure 9: Newton in various formats</figcaption>
</figure>
<p><code>P16</code>, though, runs up against its limits, rippling out noise and
forming a hole in the center, which persists at higher iterations.
MaskedFloat goes even further and produces a distorted mirror within the
empty space.</p>
<p>It’s a little creepy, honestly. Have you seen <a href="https://www.imdb.com/title/tt0120184/" rel="external" target="_blank"><em>Sphere</em></a>? It’s
like that. Right? Right.</p>
<h3 id="newtonian-event-horizons">Newtonian event horizons</h3>
<p>As you zoom farther out in the Newton fractal, we reach the point where
the formats can no longer store the values of the starting position or
its intermediate values (or can only store with reduced accuracy). The
authors refer to this as the outer event horizon. <a href="#fig:10">Figure 10</a>
shows the shape of this event horizon for various types.
Note that these are not at the same zoom
level–<code>f32</code> can represent much, much larger numbers than the others.<sup id="fnref1:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<figure id="fig:10">
<!-- Window: 2**26 -->




<figcaption>Figure 10: Outer event horizons in the Newton fractal</figcaption>
</figure>
<p>If instead of zooming out towards infinity, we zoom in towards zero, we
reach the inner event horizon–where the formats cannot represent how
small the numbers have become. <a href="#fig:11">Figure 11</a>
shows the shapes and edges of this inner event horizon.
Interestingly, the inner event horizon appears at
approximately the same scale for <code>P16</code>, <code>MaskedFloat&lt;4,50&gt;</code>, and <code>I20F12</code>;
unlike <a href="#fig:10">Figure 10</a>, <a href="#fig:11">Figure 11</a>
depicts a consistent scale.<sup id="fnref1:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure id="fig:11">



<figcaption>Figure 11: Inner event horizons</figcaption>
</figure>
<p>Slightly above the inner event horizon, there’s also an interesting
distortion region, where the intermediate values get twisted and warped
at the edge of their range. See <a href="#fig:12">Figure 12</a>
for some examples, from the wobbly <code>P16</code>,
to the funhouse mirror of MaskedFloat, and lastly a demonic sunrise over <code>I20F12</code>.</p>
<figure id="fig:12">



<figcaption>Figure 12: distortions near the inner event horizon</figcaption>
</figure>
<h3 id="hyperbolic-starbursts">Hyperbolic starbursts</h3>
<p>One additional pattern of distortion that MaskedFloat formats
demonstrate is the &#34;hyperbolic starburst&#34;,<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> so named for its
appearance during an earlier (buggier) implementation of MaskedFloat.
This pattern seems to appear in Mandelbrot near denser regions of the
set e.g. repetitions of the Mandelbrot &#34;beetle&#34; shape.</p>
<p>For instance, <a href="#fig:13">Figure 13</a> shows two MaskedFloat configurations in the
same range: centered on a beetle, in the lighting off of the north bulb.
Note that some portions of <code>MaskedFloat&lt;3,50&gt;</code> mirror the fine structure
of the fractal (lighting bolts), while others appear to be curvilinear.</p>
<figure id="fig:13">


<figcaption>Figure 13: Curvilinear distortions in Mandelbrot</figcaption>
</figure>
<h3 id="errors-abound">Errors abound?</h3>
<p><a href="#fig:14">Figure 14</a>
shows something even odder: an apparent structural difference between
<code>f64</code> and a MaskedFloat format. Whether this points to an offset error
in the format, or another issue, we leave for future investigators.</p>
<figure id="fig:14">


<figcaption>Figure 14: Possible computational errors in MaskedFloat&lt;4,50&gt;</figcaption>
</figure>
<h2 id="assessment-and-future-work">Assessment and future work</h2>
<p>We unequivocally recommend the MaskedFloat family of numeric formats for
making weird-looking fractal art, and whatever format(s) your hardware
supports for everything else.</p>
<p>The authors only explored the Newton fractal on the Wikipedia example
polynomial \(p(z) = z^3-1\). It’s possible other Newton fractals would
lead to more cool distortion. As the core operation in the Newton fractal
is very similar to the core operation in machine learning’s gradient
descent calculation, there’s probably an ML-adjacent paper one could
shovel out about this, if you want big-corp funding.</p>
<h2 id="appendix">Appendix</h2>
<h3 id="artifacts">Artifacts</h3>
<p>Just go to Github: <a href="https://github.com/cceckman/fractal-farlands" rel="external" target="_blank">https://github.com/cceckman/fractal-farlands</a></p>
<h3 id="acknowledgements">Acknowledgements</h3>
<p>Thanks to M+T for leaving Stephen enough sleep to work on this. Thanks
to Q for supporting Charles while working on this.</p>
<p>Well, we say “work”…</p>


</div></div>
  </body>
</html>
