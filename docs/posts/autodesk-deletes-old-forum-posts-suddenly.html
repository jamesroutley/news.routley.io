<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://forums.autodesk.com/t5/net/regarding-community-content-archiving/td-p/13198106">Original</a>
    <h1>Autodesk deletes old forum posts suddenly</h1>
    
    <div id="readability-page-1" class="page"><div>
<article>
<header>


</header>

<p>In 2024, Large Language Models (LLMs) and Generative AI(GenAI) exploded at an unimaginable rate. I didn’t follow the trend. Currently, there is a news every day on new models. Also, the explosion of models reached a stage where local MacBooks can run a decent enough model. I want to have local model with a decent UI support through web or terminal that provides clean user interface.</p>
<p>I stumbled upon <a href="https://github.com/open-webui/open-webui">open-webui</a>.</p>
<blockquote>
<p>Open WebUI is an <a href="https://github.com/open-webui/pipelines">extensible</a>, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs. For more information, be sure to check out our <a href="https://docs.openwebui.com/">Open WebUI Documentation</a>.</p>
</blockquote>
<p>I have previously tried <a href="https://github.com/simonw/llm">llm python package</a> to try out stand alone models.</p>
<h3 id="installing-open-webui">Installing open-webui</h3>
<p>LLM package was setup using <code>uv</code> and <code>python</code> 3.12. Adding open-webui to the existing package failed because of <code>ctranslate</code> version compatability. So I had to run the LLM package and open-webui in Python 3.11 version. After installing open-webui, I expected it to pick up llama model from llm package installation in <code>~/Library/Application\ Support/io.datasette.llm/</code>. That didn’t work. So I installed ollama mac package with <a href="https://ollama.com/library/llama3.2">llama 3.2 model</a>.</p>
<p>Then the open-webui picked up the model (see the top left corner of the image) without making any changes. I used simple <code>uv run open-webui serve</code> to run openwebui in the local machine.</p>
<p><img src="https://kracekumar.com/images/openwebui/openwebui.png" alt="Open WebUI  running on a laptop"/></p>
<p>I tried out the a simple question, <code>When did new year became important global fesatival? Explain the key historical events.</code></p>
<p>Here is the answer</p>
<p><img src="https://kracekumar.com/images/openwebui/newyear_part1.png" alt="New year  answer - Part 1"/></p>
<p><img src="https://kracekumar.com/images/openwebui/newyear_part2.png" alt="New year  answer - Part 2"/></p>
<p>The interface looks similar to ChatGPT and usable for long chat.</p>
<p>The voice to text translation was sub-par in the home page, I asked, <code>explain the beginning of new year and major historical events around it</code>. The translation was out right wrong and considered new year as holi festival. It skipped first part of the voice message.</p>
<p><img src="https://kracekumar.com/images/openwebui/holi.png" alt="Holi"/></p>


</article>
</div></div>
  </body>
</html>
