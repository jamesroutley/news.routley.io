<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.sylver.dev/build-your-own-sqlite-part-4-reading-tables-metadata">Original</a>
    <h1>Build your own SQLite, Part 4: reading tables metadata</h1>
    
    <div id="readability-page-1" class="page"><div id="post-content-parent"><div id="post-content-wrapper"><p>As we saw in the <a target="_blank" href="https://blog.sylver.dev/build-your-own-sqlite-part-1-listing-tables">opening post</a>,
SQLite stores metadata about tables in a special &#34;schema table&#34; starting on page 1.
We&#39;ve been reading records from this table to list the tables in the current database,
but before we can start evaluating SQL queries against user-defined tables, we need to
extract more information from the schema table.</p>
<p>For each table, we need to know:</p>
<ul>
<li>the table name</li>
<li>the root page</li>
<li>the name and type of each column</li>
</ul>
<p>The first two are very easy to extract, as they are directly stored in fields 1 and 3
of the schema table&#39;s records. But column names and types will be a bit trickier, as they are
not neatly separated into record fields, but are stored in a single field in the
form of a <code>CREATE TABLE</code> statement that we&#39;ll need to parse.</p>
<p>The complete source code is available on <a target="_blank" href="https://github.com/geoffreycopin/rqlite/tree/4e098ca03b814448eb1a2650d64cda12227e9300">GitHub</a>.</p>

<h2 id="heading-parsing-create-table-statements">Parsing <code>CREATE TABLE</code> statements</h2>
<p>The first step in extending our SQL parser to support <code>CREATE TABLE</code> statements it to
add the necessary token types to the tokenizer. We&#39;ll support <code>CREATE TABLE</code> statements
of the following form:</p>
<pre><code><span>CREATE</span> <span>TABLE</span> table_name
(
    column1_name column1_type,
    column2_name column2_type, 
    ...
)
</code></pre>
<p>The following tokens are new and need to be added to the <code>Token</code> enum: <code>CREATE</code>, <code>TABLE</code>, <code>(</code>, <code>)</code>.</p>
<pre><code>// sql/tokenizer.rs

#[derive(Debug, Eq, PartialEq)]
pub enum Token {
<span>+   Create,</span>
<span>+   Table,</span>
    Select,
    As,
    From,
<span>+   LPar,</span>
<span>+   RPar,</span>
    Star,
    Comma,
    SemiColon,
    Identifier(String),
}

//[...]

pub fn tokenize(input: &amp;str) -&gt; anyhow::Result&lt;Vec&lt;Token&gt;&gt; {
    let mut tokens = Vec::new();
    let mut chars = input.chars().peekable();

    while let Some(c) = chars.next() {
        match c {
<span>+           &#39;(&#39; =&gt; tokens.push(Token::LPar),</span>
<span>+           &#39;)&#39; =&gt; tokens.push(Token::RPar),</span>
            &#39;*&#39; =&gt; tokens.push(Token::Star),
            &#39;,&#39; =&gt; tokens.push(Token::Comma),
            &#39;;&#39; =&gt; tokens.push(Token::SemiColon),
            c if c.is_whitespace() =&gt; continue,
            c if c.is_alphabetic() =&gt; {
                let mut ident = c.to_string().to_lowercase();
                while let Some(cc) = chars.next_if(|&amp;cc| cc.is_alphanumeric() || cc == &#39;_&#39;) {
                    ident.extend(cc.to_lowercase());
                }

                match ident.as_str() {
<span>+                   &#34;create&#34; =&gt; tokens.push(Token::Create),</span>
<span>+                   &#34;table&#34; =&gt; tokens.push(Token::Table),</span>
                    &#34;select&#34; =&gt; tokens.push(Token::Select),
                    &#34;as&#34; =&gt; tokens.push(Token::As),
                    &#34;from&#34; =&gt; tokens.push(Token::From),
                    _ =&gt; tokens.push(Token::Identifier(ident)),
                }
            }
            _ =&gt; bail!(&#34;unexpected character: {}&#34;, c),
        }
    }

    Ok(tokens)
}
</code></pre>
<p>Next, we need to extend our AST to represent the new statement type.
Our representation will be based on the <a target="_blank" href="https://www.sqlite.org/lang_createtable.html">SQLite documentation</a>.</p>
<pre><code>// sql/ast.rs

//[...]

#[derive(Debug, Clone, Eq, PartialEq)]
pub enum Statement {
    Select(SelectStatement),
<span>+   CreateTable(CreateTableStatement),</span>
}
<span>+</span>
<span>+#[derive(Debug, Clone, Eq, PartialEq)]</span>
<span>+pub struct CreateTableStatement {</span>
<span>+    pub name: String,</span>
<span>+    pub columns: Vec&lt;ColumnDef&gt;,</span>
<span>+}</span>
<span>+</span>
<span>+#[derive(Debug, Clone, Eq, PartialEq)]</span>
<span>+pub struct ColumnDef {</span>
<span>+    pub name: String,</span>
<span>+    pub col_type: Type,</span>
<span>+}</span>
<span>+</span>
<span>+#[derive(Debug, Clone, Eq, PartialEq)]</span>
<span>+pub enum Type {</span>
<span>+    Integer,</span>
<span>+    Real,</span>
<span>+    Text,</span>
<span>+    Blob,</span>
<span>+}</span>

//[...]
</code></pre>
<p>Parsing types is straightforward: we can simply match the incoming identifier
token with a predefined set of types. For now, we&#39;ll restrict ourselves to
<code>INTEGER</code>, <code>REAL</code>, <code>TEXT</code>, <code>STRING</code>, and <code>BLOB</code>.
Once our <code>parse_type</code> method is implemented, constructing <code>ColumnDef</code> nodes
is trivial.</p>
<pre><code>


<span>impl</span> ParserState {
    
    <span><span>fn</span> <span>parse_column_def</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; anyhow::<span>Result</span>&lt;ColumnDef&gt; {
        <span>Ok</span>(ColumnDef {
            name: <span>self</span>.expect_identifier()?.to_string(),
            col_type: <span>self</span>.parse_type()?,
        })
    }

    <span><span>fn</span> <span>parse_type</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; anyhow::<span>Result</span>&lt;Type&gt; {
        <span>let</span> type_name = <span>self</span>.expect_identifier()?;
        <span>let</span> t = <span>match</span> type_name.to_lowercase().as_str() {
            <span>&#34;integer&#34;</span> =&gt; Type::Integer,
            <span>&#34;real&#34;</span> =&gt; Type::Real,
            <span>&#34;blob&#34;</span> =&gt; Type::Blob,
            <span>&#34;text&#34;</span> | <span>&#34;string&#34;</span> =&gt; Type::Text,
            _ =&gt; bail!(<span>&#34;unsupported type: {type_name}&#34;</span>),
        };
        <span>Ok</span>(t)
    }
    
}


</code></pre>
<p>In our implementation if the <code>parse_create_table</code> method, we&#39;ll parse column definitions
using the same pattern as in the <code>parse_result_colums</code> method:</p>
<pre><code>


<span>impl</span> ParserState {
    
    <span><span>fn</span> <span>parse_create_table</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; anyhow::<span>Result</span>&lt;CreateTableStatement&gt; {
        <span>self</span>.expect_eq(Token::Create)?;
        <span>self</span>.expect_eq(Token::Table)?;
        <span>let</span> name = <span>self</span>.expect_identifier()?.to_string();
        <span>self</span>.expect_eq(Token::LPar)?;
        <span>let</span> <span>mut</span> columns = <span>vec!</span>[<span>self</span>.parse_column_def()?];
        <span>while</span> <span>self</span>.next_token_is(Token::Comma) {
            <span>self</span>.advance();
            columns.push(<span>self</span>.parse_column_def()?);
        }
        <span>self</span>.expect_eq(Token::RPar)?;
        <span>Ok</span>(CreateTableStatement { name, columns })
    }
    
}

</code></pre>
<p>Finally, we need to update the <code>parse_statement</code> method to handle the new statement type.
We&#39;ll also update the <code>parse_statement</code> utility function to make the semicolon terminator
optional, as the <code>CREATE TABLE</code> statements stored in the schema table lack a trailing semicolon.</p>
<pre><code>// sql/parser.rs

//[...]

impl ParserState {
    // [...]

    fn parse_statement(&amp;mut self) -&gt; anyhow::Result&lt;Statement&gt; {
<span>-       Ok(ast::Statement::Select(self.parse_select()?))</span>
<span>+       match self.peak_next_token().context(&#34;unexpected end of input&#34;)? {</span>
<span>+           Token::Select =&gt; self.parse_select().map(Statement::Select),</span>
<span>+           Token::Create =&gt; self.parse_create_table().map(Statement::CreateTable),</span>
<span>+           token =&gt; bail!(&#34;unexpected token: {token:?}&#34;),</span>
<span>+       }</span>
    }    

    // [...]
}

// [...]

<span>-pub fn parse_statement(input: &amp;str) -&gt; anyhow::Result&lt;Statement&gt; {</span>
<span>+pub fn parse_statement(input: &amp;str, trailing_semicolon: bool) -&gt; anyhow::Result&lt;Statement&gt; {</span>
    let tokens = tokenizer::tokenize(input)?;
    let mut state = ParserState::new(tokens);
    let statement = state.parse_statement()?;
<span>+   if trailing_semicolon {</span>
        state.expect_eq(Token::SemiColon)?;
<span>+   }</span>
    Ok(statement)
}

<span>+pub fn parse_create_statement(</span>
<span>+    input: &amp;str,</span>
<span>+) -&gt; anyhow::Result&lt;CreateTableStatement&gt; {</span>
<span>+    match parse_statement(input, false)? {</span>
<span>+        Statement::CreateTable(c) =&gt; Ok(c),</span>
<span>+        Statement::Select(_) =&gt; bail!(&#34;expected a create statement&#34;),</span>
<span>+    }</span>
<span>+}</span>
</code></pre>

<p>Now that we have the necessary building blocks to read table metadata,
we can extend our <code>Database</code> struct to store this information.
The <code>TableMetadata::from_cursor</code> method builds a <code>TableMetadata</code> struct
from a <code>Cursor</code> object, which represents a record in the schema table.
The create statement and first page are extracted from fields 4 and 3, respectively.</p>
<p>As records from the schema table contain informations about other kinds
of objects, such as triggers, we check the <code>type</code> field at index 0 to ensure
we&#39;re dealing with a table.</p>
<p>Finally, in <code>Db::collect_metadata</code>, we iterate over all the records in the schema table,
collecting table metadata for each table record we encounter.</p>
<pre><code>// db.rs

<span>+#[derive(Debug, Clone)]</span>
<span>+pub struct TableMetadata {</span>
<span>+    pub name: String,</span>
<span>+    pub columns: Vec&lt;ast::ColumnDef&gt;,</span>
<span>+    pub first_page: usize,</span>
<span>+}</span>

<span>+impl TableMetadata {</span>
<span>+   fn from_cursor(cursor: Cursor) -&gt; anyhow::Result&lt;Option&lt;Self&gt;&gt; {</span>
<span>+       let type_value = cursor</span>
<span>+           .field(0)</span>
<span>+           .context(&#34;missing type field&#34;)</span>
<span>+           .context(&#34;invalid type field&#34;)?;</span>

<span>+       if type_value.as_str() != Some(&#34;table&#34;) {</span>
<span>+           return Ok(None);</span>
<span>+       }</span>

<span>+       let create_stmt = cursor</span>
<span>+           .field(4)</span>
<span>+           .context(&#34;missing create statement&#34;)</span>
<span>+           .context(&#34;invalid create statement&#34;)?</span>
<span>+           .as_str()</span>
<span>+           .context(&#34;table create statement should be a string&#34;)?</span>
<span>+           .to_owned();</span>

<span>+       let create = sql::parse_create_statement(&amp;create_stmt)?;</span>

<span>+       let first_page = cursor</span>
<span>+           .field(3)</span>
<span>+           .context(&#34;missing table first page&#34;)?</span>
<span>+           .as_int()</span>
<span>+           .context(&#34;table first page should be an integer&#34;)? as usize;</span>

<span>+       Ok(Some(TableMetadata {</span>
<span>+           name: create.name,</span>
<span>+           columns: create.columns,</span>
<span>+           first_page,</span>
<span>+       }))</span>
<span>+    }</span>
<span>+}</span>

pub struct Db {
    pub header: DbHeader,
<span>+   pub tables_metadata: Vec&lt;TableMetadata&gt;,</span>
    pager: Pager,
}

impl Db {
    pub fn from_file(filename: impl AsRef&lt;Path&gt;) -&gt; anyhow::Result&lt;Db&gt; {
        let mut file = std::fs::File::open(filename.as_ref()).context(&#34;open db file&#34;)?;

        let mut header_buffer = [0; pager::HEADER_SIZE];
        file.read_exact(&amp;mut header_buffer)
            .context(&#34;read db header&#34;)?;

        let header = pager::parse_header(&amp;header_buffer).context(&#34;parse db header&#34;)?;

<span>+       let tables_metadata = Self::collect_tables_metadata(&amp;mut Pager::new(</span>
<span>+           file.try_clone()?,</span>
<span>+           header.page_size as usize,</span>
<span>+       ))?;</span>

        let pager = Pager::new(file, header.page_size as usize);

        Ok(Db {
            header,
            pager,
<span>+           tables_metadata,</span>
        })
    }

<span>+   fn collect_tables_metadata(pager: &amp;mut Pager) -&gt; anyhow::Result&lt;Vec&lt;TableMetadata&gt;&gt; {</span>
<span>+       let mut metadata = Vec::new();</span>
<span>+       let mut scanner = Scanner::new(pager, 1);</span>

<span>+       while let Some(record) = scanner.next_record()? {</span>
<span>+           if let Some(m) = TableMetadata::from_cursor(record)? {</span>
<span>+               metadata.push(m);</span>
<span>+           }</span>
<span>+       }</span>

<span>+       Ok(metadata)</span>
<span>+   }</span>

    // [...]
}
</code></pre>
<p>Our initial implementation of the <code>.table</code> command can be updated to use the new metadata:</p>
<pre><code>// main.rs

fn display_tables(db: &amp;mut db::Db) -&gt; anyhow::Result&lt;()&gt; {
<span>-   let mut scanner = db.scanner(1);</span>
<span>-</span>
<span>-   while let Some(mut record) = scanner.next_record()? {</span>
<span>-       let type_value = record</span>
<span>-           .field(0)</span>
<span>-           .context(&#34;missing type field&#34;)</span>
<span>-           .context(&#34;invalid type field&#34;)?;</span>

<span>-       if type_value.as_str() == Some(&#34;table&#34;) {</span>
<span>-           let name_value = record</span>
<span>-               .field(1)</span>
<span>-               .context(&#34;missing name field&#34;)</span>
<span>-               .context(&#34;invalid name field&#34;)?;</span>

<span>-           print!(&#34;{} &#34;, name_value.as_str().unwrap());</span>
<span>-       }</span>
<span>-   }</span>
<span>+   for table in &amp;db.tables_metadata {</span>
<span>+       print!(&#34;{} &#34;, &amp;table.name)</span>
<span>+   }</span>

    Ok(())
}
</code></pre>
<h2 id="heading-conclusion">Conclusion</h2>
<p>We&#39;ve extended our SQL parser to support <code>CREATE TABLE</code> statements and used it to 
extract metadata from the schema table. By parsing the schema, we now have a 
way to understand the structure of tables in our database.</p>
<p>In the next post, we&#39;ll leverage this metadata to build a query evaluator 
that can execute simple <code>SELECT</code> queries against user-defined tables, 
bringing us one step closer to a fully functional database engine.</p>
</div></div></div>
  </body>
</html>
