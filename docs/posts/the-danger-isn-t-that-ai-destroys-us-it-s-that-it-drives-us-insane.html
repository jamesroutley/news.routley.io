<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane">Original</a>
    <h1>The danger isn’t that AI destroys us. It’s that it drives us insane</h1>
    
    <div id="readability-page-1" class="page"><div id="maincontent"><div><p><span><span>J</span></span><span>aron Lanier, the godfather of virtual reality and the sage of all things web, is nicknamed the Dismal Optimist. And there has never been a time we’ve needed his dismal optimism more. It’s hard to read an article or listen to a podcast these days without doomsayers telling us we’ve pushed our luck with artificial intelligence, our hubris is coming back to haunt us and robots are taking over the world. There are stories of chatbots becoming best friends, declaring their love, trying to disrupt stable marriages, and threatening chaos on a global scale.</span></p><p>Is AI really capable of outsmarting us and taking over the world? “OK! Well, your question makes no sense,” Lanier says in his gentle sing-song voice. “You’ve just used the set of terms that to me are fictions. I’m sorry to respond that way, but it’s ridiculous … it’s unreal.” This is the stuff of sci-fi movies such as The Matrix and Terminator, he says.</p><p>Lanier doesn’t even like the term artificial intelligence, objecting to the idea that it is actually intelligent, and that we could be in competition with it. “This idea of surpassing human ability is silly because it’s made of human abilities.” He says comparing ourselves with AI is the equivalent of comparing ourselves with a car. “It’s like saying a car can go faster than a human runner. Of course it can, and yet we don’t say that the car has become a better runner.”</p><p>I flush and smile. Flush because I’m embarrassed, smile because I’m relieved. I’ll take my bollocking happily, I say. He squeals with laughter. “Hehehehe! OK. <em>Hehehehe!</em>” But he doesn’t want us to get complacent. There’s plenty left to worry about: human extinction remains a distinct possibility if we abuse AI, and even if it’s of our own making, the end result is no prettier.</p><p>Lanier, 62, has worked alongside many of the web’s visionaries and power-brokers. He is both insider (he works at Microsoft as an interdisciplinary scientist, although he makes it clear that today he is talking on his own behalf) and outsider (he has constantly, and presciently, exposed the dangers the web presents). He is also one of the most distinctive men on the planet – a raggedy prophet with ginger dreads, a startling backstory, an eloquence to match his gargantuan brain and a giggle as alarming as it is life-enhancing.</p><p>Although a tech guru in his own right, his mission is to champion the human over the digital – to remind us we created the machines, and artificial intelligence is just what it says on the tin. In books such as <a href="https://www.theguardian.com/books/2011/feb/20/jaron-lanier-you-are-not-a-gadget-review" data-link-name="in body link">You Are Not a Gadget</a> and <a href="https://www.theguardian.com/books/2018/may/30/ten-arguments-deleting-your-social-media-accounts-right-now-jaron-lanier" data-link-name="in body link">Ten Reasons For Deleting Your Social Media Accounts</a>, he argues that the internet is deadening personal interaction, stifling inventiveness and perverting politics.</p><p>We meet on Microsoft’s videoconference platform Teams so that he can show a recent invention of his that enables us to appear in the same room together even though we are thousands of miles apart. But the technology isn’t working in the most basic sense. He can’t see me. Doubtless he’ll be pleased in a way. There’s nothing Lanier likes more than showing technology can go wrong, especially when operated by an incompetent at the other end. So we switch to the rival Zoom.</p><p>Lanier’s backdrop is full of musical instruments, including a row of ouds hanging from the ceiling. In his other life, he is a professional contemporary classical musician – a brilliant player of rare and ancient instruments. Often he has used music to explain the genius and limitations of tech. At its simplest, digital technology works in a on/off way, like the keys on a keyboard, and lacks the endless variety of a saxophone or human voice.</p><figure id="6ba13b4f-5e1b-43f6-8c76-c5274e30224a" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div><picture><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=380&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=380&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=300&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=300&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 980px)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=620&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=620&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 660px)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=605&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=605&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 480px)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=445&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 320px)"/><img alt="Lanier at home in 1983." src="https://i.guim.co.uk/img/media/bc4195e04d9db586188e4a26e01576d08484348a/0_0_2400_3600/master/2400.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" width="445" height="667.5" loading="lazy"/></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Lanier at home in 1983.</span> Photograph: Janet Fries/Getty Images</figcaption></figure><p>“From my perspective,” he says, “the danger isn’t that a new alien entity will speak through our technology and take over and destroy us. To me the danger is that we’ll use our technology to become mutually unintelligible or to become insane if you like, in a way that we aren’t acting with enough understanding and self-interest to survive, and we die through insanity, essentially.”</p><p>Now I’m feeling less relieved. Death by insanity doesn’t sound too appealing, and it can come in many forms – from world leaders or terrorists screwing with global security AI to being driven bonkers by misinformation or bile on Twitter. Lanier says the more sophisticated technology becomes, the more damage we can do with it, and the more we have a “responsibility to sanity”. In other words, a responsibility to act morally and humanely.</p><p>Lanier was the only child of Jewish parents who knew all about inhumanity. His Viennese mother was blond and managed to talk her way out of a concentration camp by passing as Aryan. She then moved to the US, working as a pianist and stocks trader. His father, whose family had been largely wiped out in Ukrainian pogroms, had a range of jobs from architect to science editor of pulp science-fiction magazines and eventually elementary-school teacher. Lanier was born in New York, but the family soon moved west. When he was nine, his mother was killed after her car flipped over on the freeway on her way back from passing her driving test.</p><p>Both father and son were left traumatised and impoverished; his mother had been the main breadwinner. The two of them moved to New Mexico, living in tents before 11-year-old Lanier started to design their new house, a geodesic dome that took seven years to complete. “It wasn’t good structurally, but it was good therapeutically,” he says. In his <a href="https://www.theguardian.com/books/2017/nov/20/dawn-of-the-new-everything-jaron-lanier-review-virtual-reality-memoirs-tech-visionary" data-link-name="in body link">2017 memoir, Dawn of the New Everything</a>, Lanier wrote that the house looked “a little like a woman’s body. You could see the big dome as a pregnant belly and the two icosahedrons as breasts.”</p><p>He was ludicrously bright. At 14, he enrolled at New Mexico State University, taking graduate-level courses in mathematical notation, which led him to computer programming. He never completed his degree, but went to art school and flunked out. By the age of 17 he was working a number of jobs, including goat-keeper, cheese-maker and assistant to a midwife. Then, by his early 20s, he had became a researcher for Atari in California. When he was made redundant, he focused on virtual reality projects, co-founding VPL Research to commercialise VR technologies. He could have easily been a tech billionaire had he sold his businesses sensibly or at least shown a little interest in money. As it stands, he tells me he has done very nicely financially, and obscene wealth wouldn’t have sat with his values. Today, he lives in Santa Cruz in California with his wife and teenage daughter.</p><p>Although many of the digital gurus started out as idealists, to Lanier there was an inevitability that the internet would screw us over. We wanted stuff for free (information, friendships, music), but capitalism doesn’t work like that. So we became the product – our data sold to third parties to sell us more things we don’t need. “I wrote something that described how what we now call bots will be turned into these agents of manipulation. I wrote that in the early 90s when the internet had barely been turned on.” He squeals with horror and giggles. “Oh <em>my God,</em> that’s 30 years ago!”</p><p>Actually, he believes bots such as OpenAI’s ChatGPT and Google’s Bard could provide hope for the digital world. Lanier was always dismayed that the internet gave the appearance of offering infinite options but in fact diminished choice. Until now, the primary use of AI algorithms has been to choose what videos we would like to see on YouTube, or whose posts we’ll see on social media platforms. Lanier believes it has made us lazy and incurious. Beforehand, we would sift through stacks in a record shop or browse in bookshops. “We were directly connected to a choice base that was actually larger instead of being fed this thing through this funnel that somebody else controls.”</p><figure id="12f124f8-89e4-4e8e-9ec9-b8deedf0d685" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div><picture><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=620&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=620&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 660px)"/><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=605&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=605&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 480px)"/><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=445&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 320px)"/><img alt="Talking at an IT fair in Hanover, Germany, in 2018." src="https://i.guim.co.uk/img/media/930491a4cf8559543da6ba01aa3b146c8b9fc480/0_0_5743_3495/master/5743.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" width="445" height="270.81229322653667" loading="lazy"/></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Talking at an IT fair in Hanover, Germany, in 2018.</span> Photograph: Dpa Picture Alliance/Alamy</figcaption></figure><p>Take the streaming platforms, he says. “Netflix once had a million-dollar prize contest to improve their algorithm, to help people sort through this gigantic space of streaming options. But it has never had that many choices. The truth is you could put all of Netflix’s streaming content on one scrollable page. This is another area where we have a responsibility to sanity, he says – not to narrow our options or get trapped in echo chambers, slaves to the algorithm. That’s why he loves playing live music – because every time he jams with a band, he creates something new.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-18">skip past newsletter promotion</a><p id="EmailSignup-skip-link-18" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>For Lanier, the classic example of restricted choice is Wikipedia, which has effectively become the world’s encyclopedia. “Wikipedia is run by super-nice people who are my friends. But the thing is it’s like <em>one</em> encyclopedia. Some of us might remember when on paper there was both an Encyclopedia Britannica and Encyclopedia Americana and they provided different perspectives. The notion of having the perfect encyclopedia is just weird.”</p><p>So could the new chatbots challenge this? “Right. That’s my point. If you go to a chatbot and say: ‘Please can you summarise the state of the London tube?’ you’ll get different answers each time. And then you have to choose.” This programmed-in randomness, he says, is progress. “All of a sudden this idea of trying to make the computer seem humanlike has gone far enough in this iteration that we might have naturally outgrown this illusion of the monolithic truth of the internet or AI. It means there is a bit more choice and discernment and humanity back with the person who’s interacting with the thing.”</p><p>That’s all well and good, but what about AI replacing us in the workplace? We already have the prospect of chatbots writing articles like this one. Again, he says it’s not the technology that replaces us, it’s how we use it. “There are two ways this could go. One is that we pretend the bot is a real thing, a real entity like a person, then in order to keep that fantasy going we’re careful to forget whatever source texts were used to have the bot function. Journalism would be harmed by that. The other way is you do keep track of where the sources came from. And in that case a very different world could unfold where if a bot relied on your reporting, you get payment for it, and there is a shared sense of responsibility and liability where everything works better. The term for that is data dignity.”</p><p>It seems too late for data dignity to me; the dismal optimist is in danger of being a utopian optimist here. But Lanier soon returns to Planet Bleak. “You can use AI to make fake news faster, cheaper and on greater scales. That combination is where we might see our extinction.”</p><p>In You Are Not a Gadget, he wrote that the point of digital technology was to make the world more “creative, expressive, empathic and interesting”. Has it achieved that? “It has in some cases. There’s a lot of cool stuff on the internet. I think TikTok is dangerous and should be banned yet I love dance culture on TikTok and it should be cherished.” Why should it be banned? “Because it’s controlled by the Chinese, and should there be difficult circumstances there are lots of horrible tactical uses it could be put to. I don’t think it’s an acceptable risk. It’s heartbreaking because a lot of kids love it for perfectly good reasons.”</p><figure id="cc4c9de3-6330-4a5e-a0b4-f79c884a9236" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div><picture><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=380&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=380&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=300&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=300&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 980px)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=620&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=620&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 660px)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=605&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=605&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 480px)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=445&amp;quality=45&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"/><source srcset="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" media="(min-width: 320px)"/><img alt="‘From the beginning, social media was obviously dumb.’" src="https://i.guim.co.uk/img/media/1dff8fcb42136d7602c2294eae3db18ca0e37495/0_0_3460_5200/master/3460.jpg?width=445&amp;quality=85&amp;dpr=1&amp;s=none" width="445" height="668.7861271676301" loading="lazy"/></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>‘From the beginning, social media was obviously dumb.’</span> Photograph: Winni Wintermeyer/The Guardian</figcaption></figure><p>As for Twitter, he says it has brought out the worst in us. “It has a way of taking people who start out as distinct individuals and converging them into the same personality, optimised for Twitter engagement. That personality is insecure and nervous, focused on personal slights and affronted by claims of rights by others if they’re different people. The example I use is Trump, Kanye and Elon [Musk, who now owns Twitter]. Ten years ago they had distinct personalities. But they’ve converged to have a remarkable similarity of personality, and I think that’s the personality you get if you spend too much time on Twitter. It turns you into a little kid in a schoolyard who is both desperate for attention and afraid of being the one who gets beat up. You end up being this phoney who’s self-concerned but loses empathy for others.” It’s a brilliant analysis that returns to his original point – our responsibility to sanity. Does Lanier’s responsibility to his own sanity keep him off social media? He smiles. “I always thought social media was bullshit. It was obviously just this dumb thing from the beginning.”</p><p>There is much about the internet of which he is still proud. He says that virtual reality headsets now used are little different from those he introduced in the 1980s, and his work on surgical simulation has had huge practical benefits. “I know many people whose lives have been saved by the furtherance of this stuff I was demonstrating 40 years ago. <em>My God!</em> I’m so <em>old</em> now!” He stops to question whether he’s overstating his influence, stressing that he was only involved at the beginning. There is also huge potential, he says, for AI to help us tackle climate change, and save the planet.</p><p>But he has also seen the very worst of AI. “I know people whose kids have committed suicide with a very strong online algorithm contribution. So in those cases life was taken. It might not be possible from this one human perspective to say for sure what the giant accounting ledger would tell us now, but whatever that answer would be I’m certain we could have done better, and I’m sure we can and must do better in the future.”</p><p>Again, that word, human. The way to ensure that we are sufficiently sane to survive is to remember it’s our humanness that makes us unique, he says. “A lot of modern enlightenment thinkers and technical people feel that there is something old-fashioned about believing that people are special – for instance that consciousness is a thing. They tend to think there is an equivalence between what a computer could be and what a human brain could be.” Lanier has no truck with this. “We have to say consciousness is a real thing and there is a mystical interiority to people that’s different from other stuff because if we don’t say people are special, how can we make a society or make technologies that serve people?”</p><p>Lanier looks at his watch, and apologises. “You know what, I actually have to go to a dentist’s appointment.” The real world intervenes and asserts its supremacy over the virtual. Artificial intelligence isn’t going to fix his teeth, and he wouldn’t have it any other way.</p></div></div></div>
  </body>
</html>
