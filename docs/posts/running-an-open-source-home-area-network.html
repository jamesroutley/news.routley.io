<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/">Original</a>
    <h1>Running an Open Source Home Area Network</h1>
    
    <div id="readability-page-1" class="page"><p>Insights on running a Home Area Network (HAN) nearly completely on open
source software, including configurations and metrics.</p><div><p>Over the past year or so I began to replace everything around me
with more privacy-respecting, open source software. Not only have <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-two/">I
left macOS for Linux</a>, I have also started to move away from closed source
products towards with open alternatives.</p><p>While there are some areas, where it’s not yet possible to get entirely rid of
closed source software (for example firmware blobs for proprietary hardware),
I have nevertheless managed to move most parts that I directly interact
with to open source software – and even optimized some components along the
way, to better fit my needs and be more lightweight and thereby more portable.</p><h2 id="a0i-router-firewall--wifi-access-point">a0i: Router, Firewall &amp; WiFi Access Point</h2><p>A router is the entrypoint of every local or home area network (LAN/HAN).
Almost everywhere I lived, whether it was a lease, an Airbnb or a hotel, there
usually was a router around that provided internet access through WiFi or
ethernet cable. For leases and Airbnbs, these devices were usually ISP-branded
equipment that the providers installed and maintained. Connecting personal
devices to such equipment comes with certain risks. This type of hardware is
usually locked-down by the IPS and runs closed source software not only by the
provider, but also by the manufacturer of the hardware. Oftentimes, these
routers are set up in ways in which they make it easily possible for the ISP’s
technicians to hop onto them and check the settings in case there’s something
wrong with connectivity.</p><p>I currently have one of these devices, connected to the coaxial cable that’s
coming out of my wall. This router has an integrated cable modem, manages the
internet uplink, acts as a WiFi access point and does other fancy
things. Things I have no control over, simply because the ISP won’t let me
access anything other than a status page that only shows me the uplink status.</p><p>The network this device establishes is not any more private or
trustworthy than for example a Starbucks public WiFi network. In order to keep
a home area network (HAN) safe, one needs to have a trusted network that’s
separate from the <code>192.168.0.0/24</code> things like this set up.</p><p>That’s where <code>a0i</code> comes in.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/a0i.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/a0i_hud65bf46838cbfad1234e475616046b27_325627_1440x0_resize_q75_box.jpg"/><figcaption>a0i, Linksys WRT3200ACM with OpenWrt</figcaption></a></figure><p>The centrepiece of my HAN is a Linksys WRT3200ACM running <a href="https://openwrt.org">OpenWrt</a>. It’s the
gateway to the outside world and offers 5GHz 802.11ac connectivity to every
device that I can’t connect using an ethernet cable. It’s using a fixed, 80 MHz
wide channel and transmits at 14 dBm (25 mW). I set the AP to a fixed channel,
because my WiFi clients sporadically lost connectivity and weren’t able to
reconnect in <code>auto</code> channel mode.</p><p>The WAN port of the router is connected to the ISP’s cable modem/router and
basically acts like a single client device, requesting a dynamic IP from the
modem. While this double-NAT setup isn’t ideal, it allows me to safely connect
to any ISP device, no matter whether that’s an LTE router, a cable or DSL modem
or an ONU. In fact, at times when cable connectivity becomes unbearable, I make
use of OpenWrt’s mwan3 packages to run a failover multi-WAN configuration across
cable and LTE. In that case I simply connect my Netgear Nighthawk – a piece of
hardware I’m still working to transition to an open source alternative like a
Raspberry Pi LTE router – to one of the other ethernet ports on the Linksys and
configure mwan3 accordingly.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/nighthawk.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/nighthawk_hucdc231b2e8fd5af10338706dec3759da_352911_1440x0_resize_q75_box.jpg"/><figcaption>WiFi throughput</figcaption></a></figure><p>Even though the Linksys WRT3200ACM was released back in 2016, it’s still a solid
and well-supported option for OpenWrt – unless WiFi is your primary
requirement. The Marvell 88W8964 driver for Linux isn’t exactly the best
supported/most actively developed and while 5GHz WiFi works fairly well when
configured properly (e.g. using a fixed channel) it won’t be the best option
when a significant number of devices, that transfer large amounts of data, are
connected. On average I have around six active WiFi clients, with maybe two
of them transferring a noticeable amount of data. The average WiFi throughput is
around 350Mb/s, with only short peaks sporadically topping out at roughly
700Mb/s.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/wifi-speeds.webp" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/wifi-speeds.webp"/><figcaption>WiFi throughput</figcaption></a></figure><p>Since the WRT3200ACM only offers roundabout 55 megabytes of usable storage I
keep packages at a minimum. Most software is OpenWrt base, with the exception of
<code>collectd</code> (plus modules), <code>mwan3</code> and <code>dnscrypt-proxy2</code>, which I had installed
manually. While I would like to install e.g. Wireguard, to be able to run
multiple clients on the Linksys, the hardware simply isn’t powerful enough to
handle it.</p><p><code>dnscrypt-proxy2</code> is the DNS server every HAN client uses. It is configured to
use a predefined set of public resolvers, as well as a dynamic list of
anonymized DNS relays and Oblivious DoH servers and relays.</p><p>With ambient temperatures around 26°C, the system temperature of the Linksys
has usually been between 65°C and 75°C, which is why I got one of these
cheap <em>laptop coolers</em>. It has two 80mm fans that draw power from the Linksys&#39;
USB port and push air upwards. Since the router case has holes on the bottom and
the top, the additional air flow cools the internal electronics down to
46°C on average.</p><h2 id="r0n1n-docker-host--iot-gateway">r0n1n: Docker Host &amp; IoT Gateway</h2><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-01.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-01_hu3014544ab72b198b911efa20fc34ffff_112956_1440x0_resize_q75_box.jpg"/><figcaption>r0n1n, Rock Pi 4A 4GB</figcaption></a></figure><p>Up until I <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-one/">switched</a> <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-two/">back</a> to <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-three/">Linux</a> on <a href="https://xn--gckvb8fzb.com/computer/">my workstation</a>,
<code>r0n1n</code> was my primary Linux machine. It’s a Rock Pi 4A with a Rockchip RK3399,
a Mali T860MP4 GPU, 4GB LPDDR4 3200 Mhz RAM and an extension board that allowed
me to connect a 512 GB WD Black Gen 3 NVMe to it. The SBC has a big ass heatsink
attached to the RK3399 that helps keeping it around 50°C, without a fan.</p><p>With the Rock Pi supporting USB PD, it was easily possible to run the SBC as
well as the UPERFECT 15.6-inch portable UHD display off a 45W power brick for
extended periods of time. By attaching it to my Netgear Nighthawk LTE router, it
basically became a modular, portable computer that one could work with anywhere,
independent of WiFi or power outlets. And thanks to the NVMe, IO was blazing
fast.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-03.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-03_hu16d9aad92f872bd2e6fc14c277289c86_113581_1440x0_resize_q75_box.jpg"/><figcaption>r0n1n, Rock Pi 4A 4GB</figcaption></a></figure><p>After I built my SFFPC, however, I had no more use for the Rock Pi 4 as a
Linux desktop, so I decided to rebuild <code>r0n1n</code> and make it a tiny HAN server.
These days <code>r0n1n</code>’s main purpose is running Docker containers and acting as a
gateway for IoT devices (e.g. a Raspberry Pi Zero W camera or ESP32s with
sensors). In order to optimize performance and longevity of the components I
connected an unused Lian Li 120mm 12V fan to the Rock Pi’s 5V output. The lower
voltage makes it run slower (and therefore more silent) than it usually would,
while still providing enough air flow to cool the RK3399 to 31°C and the
NVMe to 35°C (under normal load). Compared to the <a href="https://xn--gckvb8fzb.com/linux-on-the-phone-part-one/">PinePhone Pro</a>, which
also runs (a special variant of) the RK3399, these thermals are ridiculously
good – especially in an environment with ambient temperatures around 26°C.
I might nevertheless install a NVMe heatsink.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-04.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-04_hu67c7ccb71f0e66d0443c163915e3f81e_186954_1440x0_resize_q75_box.jpg"/><figcaption>r0n1n, Rock Pi 4A 4GB</figcaption></a></figure><h3 id="performance">Performance</h3><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-load-temp.webp" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/r0n1n-load-temp.webp"/><figcaption>r0n1n, keeping its cool even at higher loads</figcaption></a></figure><p>Even under heavy load from building Docker images and compiling Go code, the
Rock Pi 4 performs extraordinary well and doesn’t lose a sweat. Compared to a
Raspberry Pi 4 that has the same amount of RAM and an external SSD connected via
USB, the Rock Pi’s RK3399 can handle significantly more load than the Pi’s
Broadcom chip.</p><h3 id="wifi-access-point-systemd-and-hostapd">WiFi Access Point (systemd and hostapd)</h3><p><code>r0n1n</code> is running Manjaro Linux off of its NVMe SSD. Since the Rock Pi 4A
does not have integrated WiFi (nor Bluetooth), I attached a Panda PAU09 N600
WiFi USB adapter to it and configured <code>hostapd</code> and <code>systemd-networkd</code> to bridge
WiFi clients into the main HAN, where they’re being assigned an IP address by
<code>a0i</code>. The reason for using a dedicated access point for all IoT devices/sensors
is the fact that most of these devices don’t support the 5GHz band and I
wouldn’t want to decrease wireless stability on <code>a0i</code> by enabling the 2.4GHz
frequency. Besides of this, since most sensors only communicate with Docker
containers running on <code>r0n1n</code>, this approach allows me to better limit their
access into the internal network.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/panda-pau09.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/panda-pau09_hua7cb6921773154ce65217e51421c3b92_114423_1440x0_resize_q75_box.jpg"/><figcaption>Panda PAU09 N600 USB WiFi Adapter</figcaption></a></figure><p>Since the Panda PAU09 N600 works out of the box, the only thing needed to
enable the WiFi access point is a working <code>hostapd</code> configuration:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/hostapd/hostapd.conf
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/hostapd/hostapd.conf
───────┼────────────────────────────────────────────────────────────────────────
   1   │ interface=wlan0
   2   │ bridge=br0
   3   │ driver=nl80211
   4   │ logger_syslog=-1
   5   │ logger_syslog_level=2
   6   │ logger_stdout=-1
   7   │ logger_stdout_level=2
   8   │ ctrl_interface=/run/hostapd
   9   │ ctrl_interface_group=0
  10   │ ssid=YOUR-SSID-HERE
  11   │ country_code=US
  12   │ hw_mode=g
  13   │ channel=7
  14   │ beacon_int=100
  15   │ dtim_period=2
  16   │ max_num_sta=10
  17   │ rts_threshold=-1
  18   │ fragm_threshold=-1
  19   │ macaddr_acl=0
  20   │ auth_algs=1
  21   │ ignore_broadcast_ssid=0
  22   │ wmm_enabled=1
  23   │ wmm_ac_bk_cwmin=4
  24   │ wmm_ac_bk_cwmax=10
  25   │ wmm_ac_bk_aifs=7
  26   │ wmm_ac_bk_txop_limit=0
  27   │ wmm_ac_bk_acm=0
  28   │ wmm_ac_be_aifs=3
  29   │ wmm_ac_be_cwmin=4
  30   │ wmm_ac_be_cwmax=10
  31   │ wmm_ac_be_txop_limit=0
  32   │ wmm_ac_be_acm=0
  33   │ wmm_ac_vi_aifs=2
  34   │ wmm_ac_vi_cwmin=3
  35   │ wmm_ac_vi_cwmax=4
  36   │ wmm_ac_vi_txop_limit=94
  37   │ wmm_ac_vi_acm=0
  38   │ wmm_ac_vo_aifs=2
  39   │ wmm_ac_vo_cwmin=2
  40   │ wmm_ac_vo_cwmax=3
  41   │ wmm_ac_vo_txop_limit=47
  42   │ wmm_ac_vo_acm=0
  43   │ eapol_key_index_workaround=0
  44   │ eap_server=0
  45   │ own_ip_addr=127.0.0.1
  46   │ wpa=2
  47   │ wpa_key_mgmt=WPA-PSK
  48   │ wpa_passphrase=YOUR-PASSPHRASE-HERE
  49   │ wpa_pairwise=CCMP
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>The configuration for bridging the WiFi clients into the internal network
consist of four files under <code>/etc/systemd/network/</code>:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/systemd/network/*
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/network/10-br0.netdev
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [NetDev]
   2   │ Name=br0
   3   │ Kind=bridge
   4   │ MACAddress=00:00:00:00:00:00
───────┴────────────────────────────────────────────────────────────────────────
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/network/20-br0.network
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Match]
   2   │ Name=br0
   3   │
   4   │ [Network]
   5   │ MulticastDNS=yes
   6   │ DHCP=yes
───────┴────────────────────────────────────────────────────────────────────────
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/network/21-eth0_br0.network
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Match]
   2   │ Name=eth0
   3   │
   4   │ [Network]
   5   │ Description=Add eth0 to br0
   6   │ Bridge=br0
───────┴────────────────────────────────────────────────────────────────────────
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/network/21-wlan0_br0.network
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Match]
   2   │ Name=wlan0
   3   │ WLANInterfaceType=ap
   4   │
   5   │ [Link]
   6   │ RequiredForOnline=no
   7   │
   8   │ [Network]
   9   │ Description=Add wlan0 to br0
  10   │ Bridge=br0
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>What we’re doing here is basically:</p><ul><li>adding a netdev config <code>br0</code> as a <code>bridge</code></li><li>adding a network config for <code>br0</code> that requests its IP via DHCP</li><li>adding a network config for bridging <code>eth0</code> to <code>br0</code></li><li>adding a network config for bridging <code>wlan0</code> to <code>br0</code></li></ul><p>The <code>MACAddress</code> in the <code>[NetDev]</code> section of <code>10-br0.netdev</code> is supposed to set
the MAC address of <code>br0</code> to a static address, so <code>a0i</code> always assigns it the
same IP address via DHCP.</p><p>In order to make the whole setup safe for reboot, we need a drop-in service
config for <code>hostapd</code>, because otherwise <code>systemd</code> will fail launching it
properly:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/systemd/system/hostapd.service.d/hostapd.service
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/system/hostapd.service.d/hostapd.service
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Unit]
   2   │ BindsTo=sys-subsystem-net-devices-wlan0.device
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>We also need to <code>systemctl disable hostapd.service</code> and instead do the
following:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>mkdir /etc/systemd/system/sys-subsystem-net-devices-wlan0.device.wants
</span></span><span><span>ln -s /usr/lib/systemd/system/hostapd.service /etc/systemd/system/sys-subsystem-net-devices-wlan0.device.wants/
</span></span></code></pre></div><h3 id="docker">Docker</h3><p>Besides acting as a 2.4GHz access point for IoT devices, the Rock Pi is running
a variety of different services as Docker containers. One pitfall here is that
Docker likes to mess around with <code>iptables</code>, leading to WiFi clients being
unable to communicate with the internal network. In order to fix this, another
drop-in configuration is needed:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/systemd/system/docker.service.d/10-post.conf
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/system/docker.service.d/10-post.conf
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Service]
   2   │ ExecStartPost=iptables -I DOCKER-USER -i src_if -o dst_if -j ACCEPT
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p><strong>Update:</strong> Because I simply couldn’t get it working with this rule, that was
suggested in the <a href="https://docs.docker.com/network/iptables/#docker-on-a-router">Docker docs in first place</a>, I eventually gave up and used
a <em>jackhammer</em> to fix it:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/systemd/system/docker.service.d/20-post.conf
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/system/docker.service.d/20-post.conf
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Service]
   2   │ ExecStartPost=iptables --policy FORWARD ACCEPT
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>On a different note, if I would have tried to run Gentoo on the Rock Pi 4, I
definitely wouldn’t have used <code>systemd</code>. While the steps described here might
seem straightforward, it was a <strong>gigantic PITA</strong> to figure out the details and get
the setup running. If I would have done it on a vanilla OpenRC Gentoo
installation, I probably would have spent far less time dealing with
configuration and debugging, and more time doing the things that are actually
fun: Watching <code>emerge</code> compile packages. I never had particularly strong
opinions on <code>systemd</code>, mainly because I rarely had to deal with it, but every
time I did, the sheer overkill for configuring the most mundane things killed the
vibe pretty quickly, making me start to understand <a href="https://www.reddit.com/r/linuxmasterrace/comments/5pubmn/why_is_systemd_so_bad/">why</a> <a href="https://www.quora.com/Why-is-Linux-switching-over-to-systemd-when-its-so-bad">people</a>
<a href="https://suckless.org/sucks/systemd/">hate</a> <a href="https://nosystemd.org">systemd</a> so passionately.</p><h3 id="services">Services</h3><p>With over 500GB of storage and <em>plenty</em> of RAM available, the Rock Pi is capable
of running a good amount of Docker containers. And while it certainly would
have been possible to roll my own Kubernetes for the sake of <em>1337ness</em>, Docker
is just enough for the things I need.</p><p>I often try out new services and remove the ones I don’t end up using
enough, but there are also a handful of <em>core services</em> that are always there.
None of these services are accessible from outside the HAN – not because it
wouldn’t be possible, but because they don’t need to be. If data has to be made
available outside this network, the services will periodically push it to a
cloud instance, which serves it to external clients.</p><h4 id="grafana-and-influxdb-and-telegraf">Grafana (and InfluxDB, and Telegraf)</h4><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/grafana.webp" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/grafana.webp"/><figcaption>Grafana displaying cbrspc7 stats</figcaption></a></figure><p>One group of such <em>core services</em> consists of InfluxDB, Telegraf and Grafana.
InfluxDB is the data source for Grafana, towards which all IoT sensors and other
devices write their data. <code>a0i</code> for example runs <code>collectd</code> to collect
performance data from the Linksys, which it sends to InfluxDB. Since the Linksys
has too little storage to run an actual Telegraf node on it, <code>collectd</code> is
collecting the raw data and posting it to the Telegraf container that is running
on <code>r0n1n</code>. The Telegraf node then pumps the data into InfluxDB. The
configuration for that looks like this:</p><pre tabindex="0"><code>[root@r0n1n ~]# bat /home/pi/services/telegraf/telegraf.conf
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /home/pi/services/telegraf/telegraf.conf
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [global_tags]
   2   │
   3   │ [agent]
   4   │   interval = &#34;10s&#34;
   5   │   round_interval = true
   6   │   metric_batch_size = 1000
   7   │   metric_buffer_limit = 10000
   8   │   collection_jitter = &#34;0s&#34;
   9   │   flush_interval = &#34;10s&#34;
  10   │   flush_jitter = &#34;0s&#34;
  11   │   precision = &#34;&#34;
  12   │   hostname = &#34;pr0xy&#34;
  13   │   omit_hostname = false
  14   │   logtarget = &#34;stderr&#34;
  15   │
  16   │ [[outputs.influxdb_v2]]
  17   │   urls = [&#34;http://10.0.0.6:8086&#34;]
  18   │   token = &#34;YOUR-TOKEN-HERE&#34;
  19   │   organization = &#34;all-computers-are-bad&#34;
  20   │   bucket = &#34;root&#34;
  21   │
  22   │ [[inputs.socket_listener]]
  23   │   service_address = &#34;udp://:25826&#34;
  24   │   data_format = &#34;collectd&#34;
  25   │   collectd_security_level = &#34;none&#34;
  26   │   collectd_parse_multivalue = &#34;split&#34;
  27   │   collectd_typesdb = [&#34;/etc/telegraf/types.db&#34;]
  28   │
  29   │ [[inputs.openweathermap]]
  30   │   app_id = &#34;YOUR-TOKEN-HERE&#34;
  31   │   city_id = [&#34;0000000&#34;]
  32   │
  33   │   lang = &#34;en&#34;
  34   │   fetch = [&#34;weather&#34;, &#34;forecast&#34;]
  35   │   base_url = &#34;https://api.openweathermap.org/&#34;
  36   │   response_timeout = &#34;20s&#34;
  37   │   units = &#34;metric&#34;
  38   │   interval = &#34;30m&#34;
  39   │
  40   │ [[inputs.docker]]
  41   │   endpoint = &#34;unix:///var/run/docker.sock&#34;
  42   │   gather_services = false
  43   │   source_tag = false
  44   │   container_name_include = []
  45   │   container_name_exclude = []
  46   │   timeout = &#34;5s&#34;
  47   │   perdevice = true
  48   │   total = false
  49   │   docker_label_include = []
  50   │   docker_label_exclude = []
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>This configuration, including the <code>types.db</code> it refers to (which can be
downloaded from the OpenWrt router, typically under
<code>/usr/share/collectd/types.db</code>) is mounted into the container on launch - just
like the <code>docker.sock</code>, that I’m using to retrieve additional data from the
Docker host:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>docker run -d <span>\
</span></span></span><span><span><span></span>  -p 25826:25826/udp <span>\
</span></span></span><span><span><span></span>  -v /var/run/docker.sock:/var/run/docker.sock <span>\
</span></span></span><span><span><span></span>  -v <span>$HOME</span>/services/telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:ro <span>\
</span></span></span><span><span><span></span>  -v <span>$HOME</span>/services/telegraf/types.db:/etc/telegraf/types.db:ro <span>\
</span></span></span><span><span><span></span>  --name telegraf <span>\
</span></span></span><span><span><span></span>  telegraf
</span></span></code></pre></div><p>Since <code>r0n1n</code> is already running a Telegraf node inside Docker and I wasn’t able
to find a Manjaro package for it to run another node on directly <code>r0n1n</code>, so
that it would have access to thermals and other system data, I decided to simply
compile <code>collectd</code> on the Rock Pi and have it running as a <code>systemd</code> service:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>git clone --recurse-submodules https://github.com/collectd/collectd.git
</span></span><span><span><span>cd</span> collectd
</span></span><span><span>./configure --prefix /usr --enable-python<span>=</span><span>false</span> --enable-smart<span>=</span><span>true</span>
</span></span><span><span>make
</span></span><span><span>su -
</span></span><span><span><span>cd</span> /home/pi/collectd/
</span></span><span><span>make install
</span></span></code></pre></div><pre tabindex="0"><code>[root@r0n1n ~]# bat /etc/systemd/system/collectd.service
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/systemd/system/collectd.service
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [Unit]
   2   │ Description=collectd
   3   │ After=network.target
   4   │
   5   │ [Service]
   6   │ Type=simple
   7   │ #User=root
   8   │ #Group=root
   9   │ WorkingDirectory=/root
  10   │ ExecStart=/usr/bin/collectd -f -C /etc/collectd.conf
  11   │ Restart=on-failure
  12   │
  13   │ [Install]
  14   │ WantedBy=default.target
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>In the <code>collectd.conf</code> I configured the network plugin to report data to the
Telegraf node, similarly to how it is done on <code>a0i</code> – with the only
difference being the IP, since <code>collectd</code> can simply access the Docker container
via <code>127.0.0.1</code>:</p><pre tabindex="0"><code>&lt;Plugin network&gt;
        Server &#34;127.0.0.1&#34; &#34;25826&#34;
        Forward false
        ReportStats true
&lt;/Plugin&gt;
</code></pre><h4 id="postgresql">PostgreSQL</h4><p><code>r0n1n</code> runs the official <code>postgres:alpine</code> Docker image to offer a PostgreSQL
database to other services on <code>r0n1n</code> or <a href="#cbrspc7"><code>cbrspc7</code></a>. The
configuration is fairly vanilla and nothing special, since the service doesn’t
experience much load.</p><h4 id="redis">Redis</h4><p>Similar to <a href="#postgresql">PostgreSQL</a>, <code>r0n1n</code> runs an instance of <code>redis:alpine</code>
for other services to use. The instance is ephemeral as it does not contain any
data that has to be persisted.</p><h4 id="ejabberd">ejabberd</h4><p>Another service that’s a resident on <code>r0n1n</code> is ejabberd. It’s a Jabber server
written in Erlang. I use it for developing and testing XMPP-based protocols as
well as integration of local notifications. The server does not federate with
the outside world and is only available to devices inside the network.</p><p>Since there are no images for the <code>linux/amr64/v8</code> platform yet, I had to
build those on my own:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>git clone --recurse-submodules https://github.com/processone/docker-ejabberd
</span></span><span><span><span>cd</span> docker-ejabberd/mix/
</span></span><span><span>docker build -t ejabberd/mix .
</span></span><span><span><span>cd</span> ../ecs/
</span></span><span><span>docker build -t ejabberd/ecs .
</span></span></code></pre></div><h4 id="journalist">journalist</h4><p><a href="https://xn--gckvb8fzb.com/journalist-an-rss-aggregator/">journalist</a> is my own RSS aggregator that I can use with either
<a href="https://xn--gckvb8fzb.com/canard-a-command-line-tui-client-for-the-journalist-rss-aggregator/">canard</a> on the command line or any other client that supports the
Fever API. It uses the <a href="#postgresql">PostgreSQL</a> instance to store feeds and
data.</p><h4 id="ipfs">IPFS</h4><p>To browse IPFS from multiple devices without running an IPFS node on
every machine, I keep a single <code>lowpower</code> node running on <code>r0n1n</code>. On my
workstation and my phone I use the IPFS Firefox extension, which points to the
node running on the Rock Pi.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/ipfs-peers.webp" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/ipfs-peers.webp"/><figcaption>IPFS Peers</figcaption></a></figure><p>Just like the ejabberd project, the IPFS folks also do not offer an
<code>linux/arm64/v8</code> image, so it needs to be built manually:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>git clone --recurse-submodules https://github.com/ipfs/go-ipfs.git
</span></span><span><span><span>cd</span> go-ipfs
</span></span><span><span>docker build -t ipfs/go-ipfs .
</span></span></code></pre></div><p>The IPFS node is then run using the <code>lowpower</code> profile:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>docker run -d <span>\
</span></span></span><span><span><span></span>  --name ipfs <span>\
</span></span></span><span><span><span></span>  -e <span>IPFS_PROFILE</span><span>=</span>lowpower <span>\
</span></span></span><span><span><span></span>  -v <span>$HOME</span>/services/ipfs/export:/export <span>\
</span></span></span><span><span><span></span>  -v <span>$HOME</span>/services/ipfs/ipfs:/data/ipfs <span>\
</span></span></span><span><span><span></span>  -p 4001:4001 <span>\
</span></span></span><span><span><span></span>  -p 8080:8080 <span>\
</span></span></span><span><span><span></span>  -p 5001:5001 <span>\
</span></span></span><span><span><span></span>  ipfs/go-ipfs:latest
</span></span></code></pre></div><p>In order to be able to use the IPFS node from other machines, it’s necessary to
configure CORS properly with the IP of the Docker host (<code>10.0.0.6</code> in my case):</p><div><pre tabindex="0"><code data-lang="sh"><span><span>docker <span>exec</span> -it ipfs /bin/sh
</span></span><span><span><span># ipfs config \</span>
</span></span><span><span>  --json API.HTTPHeaders.Access-Control-Allow-Origin <span>\
</span></span></span><span><span><span></span>  <span>&#39;[&#34;http://10.0.0.6:5001&#34;, &#34;http://localhost:3000&#34;, &#34;http://127.0.0.1:5001&#34;, &#34;https://webui.ipfs.io&#34;]&#39;</span>
</span></span><span><span><span># ipfs config \</span>
</span></span><span><span>  --json API.HTTPHeaders.Access-Control-Allow-Methods <span>\
</span></span></span><span><span><span></span>  <span>&#39;[&#34;PUT&#34;, &#34;POST&#34;]&#39;</span>
</span></span></code></pre></div><h4 id="restic">restic</h4><p>In order to keep the data on <code>r0n1n</code> safe, <a href="https://restic.net">restic</a> is run periodically by
cron and backups every important directory to an external storage.</p><h2 id="h4nk4-ultra-portable-data-center">h4nk4: Ultra-Portable Data Center</h2><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/h4nk4.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/h4nk4_hu920b7d39288ee7f1d61fa82a273ac271_101796_1440x0_resize_q75_box.jpg"/><figcaption>h4nk4, ultra-portable data center</figcaption></a></figure><p>For everything that <code>r0n1n</code> is not capable of running due to resource
constraints and for vast amounts of storage there’s <a href="https://xn--gckvb8fzb.com/ultra-portable-data-center/"><code>h4nk4</code>, my
<em>ultra-portable data center</em></a>. I built this <em>server</em> a few years ago when I
was still using a <a href="https://xn--gckvb8fzb.com/linux-on-the-phone-part-one/">MacBook Pro</a> as my main machine. The <em>UPDC</em> runs
<a href="https://nixos.org">NixOS</a> and hence is fully reproducible within the matter of hours, no
matter what might happen. The base system runs on a fully encrypted RAID1 on top
of two NVMe SSDs, the data storage is a set of four 2.5&#34; Seagate Barracuda 4TB
drives that run in RAID5 – also fully encrypted. Part of the base system’s NVMe
RAID1 is used as cache for IO operations on the RAID5, resulting in an overall
great performance for data operations of up to 100GB at a time.</p><p>Back when I built <code>h4nk4</code>, it had pfSense running via KVM, which in
turn took care of the five ethernet ports the UPDC offers. With the network now
being under control of <code>a0i</code> the pfSense guest is not needed anymore. For
performance reasons it does however make sense to directly connect to the device
via ethernet cable nevertheless.</p><p>While <code>h4nk4</code> still offers great benefits in terms of storage capacity, data
security and raw computing power, these days it’s not a crucial part of the
infrastructure anymore, and I’m looking forward to rebuild it at some point.</p><p>I would like to increase the amount of storage available while decreasing the
size and weight of the whole device. Since most of the heavy computations are
happening on my workstation, I don’t need <code>h4nk4</code> to be a full-blown <code>amd64</code>
architecture anymore. Ideally, I can soon replace it with a more integrated
solution, e.g. a single-board computer that offers a way to connect <strong>at least</strong>
2 SATA drives at 6GBit/s and ideally one NVMe as cache.</p><h2 id="cbrspc7-the-workstation">cbrspc7: The Workstation</h2><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/cbrspc7.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/cbrspc7_hua6bcfd0bc04e8ccc343e02e0de4c4e71_228245_1440x0_resize_q75_box.jpg"/><figcaption>cbrspc7, Gentoo Linux workstation</figcaption></a></figure><p>My primary workstation is a <a href="https://www.reddit.com/r/sffpc/">SFFPC</a> named <a href="https://williamgibson.fandom.com/wiki/Ono-Sendai_Cyberspace_VII"><code>cbrspc7</code></a>. It runs the best
operating system in the world, or, how regular people call it,
<a href="https://www.gentoo.org/donate/">Gentoo Linux</a>. You can find out more about the <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-one/">why</a> and <a href="https://xn--gckvb8fzb.com/linux-on-the-desktop-part-two/">how</a> all
across this journal, and you can see up to date info on <code>cbrspc7</code> on the
<a href="https://xn--gckvb8fzb.com/computer/">computer page</a>.</p><p>The machine interacts with the rest of the HAN using gigabit ethernet – no
WiFi. It runs a Telegraf node and reports its data to <code>r0n1n</code>, so I can see and,
what’s more important, log all the important stats. Additionally I’m running
<a href="https://github.com/Alexays/Waybar/">waybar</a>, which allows me to display some stats directly on my desktop.</p><p><del><code>cbrspc7</code> will be extended soon. In fact, I’m currently waiting for XTIA to ship
my extension kit. With it, the device’s thermals and cable management will be
greatly enhanced. Believe it or not, but even though this build is completely
open, with ambient temperatures around 26°C, components sometimes hit peak
temperatures of over 75°C. Especially the secondary NVMe, that is mounted on
the backside of the motherboard, is constantly throttling, decreasing the overall
RAID1 performance of my fully encrypted ZFS setup. Hence I’m looking to give it
a little more room to breathe, add another set of fans to the frame and upgrade
the heatsinks.</del></p><p><a href="https://xn--gckvb8fzb.com/xtia-xproto-upgrade/">It was done</a>.</p><p>For more info on the workstation, check the <a href="https://xn--gckvb8fzb.com/computer/">computer page</a>.</p><h2 id="j0l1y-a-portable-battery-powered-sbc-aka-linux-phone">j0l1y: A Portable, Battery-Powered SBC (a.k.a. <em>Linux Phone</em>)</h2><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/j0l1y.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/j0l1y_huf497e0df0ed180b2ef51f4d19e19ad3a_239468_1440x0_resize_q75_box.jpg"/><figcaption>j0l1y, PinePhone Pro Explorer Edition</figcaption></a></figure><p>If you’ve came across <a href="https://xn--gckvb8fzb.com/linux-on-the-phone-part-one/">my post on the PinePhone Pro</a> you know that I’ve been
dipping my toes into that area lately. So far, the PinePhone Pro isn’t that much
of a <em>phone</em> and more like a portable, battery-powered single-board computer.
Unlike other <em>IoT</em> devices, like Raspberry Pis and Arduinos, it does however
connect directly to my 5GHz WiFi and has full access to the rest of the network.</p><p>So far I’ve been only tinkering with different distributions and the <em>apps</em> that
are currently available, but I’m looking forward to test some of <a href="https://github.com/mrusme">my own
projects</a> on the PinePhone an maybe bring an actual mobile-optimized GUI
version of them to the platform.</p><p>I have <a href="https://xn--gckvb8fzb.com/phone/">more phones</a> <em>clogging</em> my WiFi, btw.</p><h2 id="c4m3r4-a-raspberry-pi-zero-w-v11-camera">c4m3r4: A Raspberry Pi Zero W V1.1 Camera</h2><p><code>c4m3r4</code> is one of the IoT devices that connect to the 2.4GHz WiFi provided by
<code>r0n1n</code>. It’s a Raspberry Pi Zero W V1.1 with a Raspberry Pi camera module and a
heatsink attached to it. It doesn’t have a fixed position and instead I move it
around all the time, depending on where I need it. For example, when I’m cooking
a soup and want to make sure it won’t boil over while I’m working at my
workstation, I simply attach it to a wall and point it towards the stove. Or
when I’m waiting for someone to come by, I attach it to the window and make it
point downwards to the entrance. And when I just want to watch the sunset while
I’m writing things like this, I simply attach it to the living room window and
play the RTSP stream using <a href="https://www.videolan.org/vlc/">VLC</a> on my desktop.</p><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/c4m3r4.webp" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/c4m3r4_hu1f4e9e62c9c0da781d704cfa99f0cd21_46270_1440x0_resize_q75_bgffffff_box_2.jpg"/><figcaption>c4m3r4, streaming the sunset</figcaption></a></figure><p>The Zero runs on a minimal installation of Debian 11.2 and <a href="https://github.com/mpromonet/v4l2rtspserver"><code>v4l2rtspserver</code></a>.
I compiled it on-device and created a <code>supervisord</code> configuration to keep it
from stopping/crashing:</p><pre tabindex="0"><code>root@c4m3r4:~# batcat /etc/supervisor/conf.d/v4l2rtspserver.conf
───────┬────────────────────────────────────────────────────────────────────────
       │ File: /etc/supervisor/conf.d/v4l2rtspserver.conf
───────┼────────────────────────────────────────────────────────────────────────
   1   │ [program:v4l2rtspserver]
   2   │ command=/usr/local/bin/v4l2rtspserver /dev/video0
   3   │ autostart=true
   4   │ startsecs=5
   5   │ startretries=5
   6   │ autorestart=true
   7   │ user=pi
───────┴────────────────────────────────────────────────────────────────────────
</code></pre><p>The image quality is fairly decent and the performance is pretty good, with
very little latency. Also, thanks to the additional heatsink, the Zero keeps its
cool even when streaming for extended periods of time:</p><pre tabindex="0"><code>root@c4m3r4:~# vcgencmd measure_temp
temp=36.9&#39;C
</code></pre><p>When I was still locked into Apple’s ecosystem, I used the <a href="https://github.com/brutella/hkcam"><code>hkcam</code></a>
firmware to make the stream available to HomeKit devices. <code>hkcam</code> worked
extremely well for that purpose, the overall stream performance was however not
as great as it is with <code>v4l2rtspserver</code>. If I was to redo the HomeKit setup
today, I would probably use the <code>v4l2rtspserver</code> setup in combination with
<a href="https://homebridge.io">Homebridge</a> to have the RTSP stream available on iOS and macOS devices.</p><h2 id="other-iot-devices">Other <em>IoT</em> devices</h2><figure><a href="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/raspberry-pi4.jpg" target="_blank"><img src="https://xn--gckvb8fzb.com/running-an-open-source-home-area-network/images/raspberry-pi4_hu5052312b5d92c8df8b4d9c495042cbd1_246450_1440x0_resize_q75_box.jpg"/><figcaption>A Raspberry Pi 4 with a custom 3D-printed fan mount</figcaption></a></figure><p>Apart from the devices listed above I have <a href="https://xn--gckvb8fzb.com/belongings/#tech">more devices</a> that I tinker
around with, most prominently single-board computers like the Raspberry Pi 4,
and micro-controllers like the Adafruit Feather M0 WiFi, the SiFive HiFive 1
revB or the SparkFun ESP32-S2. It would go well beyond the scope of this post to
list them all, including the way they’re set up. I also often switch firmwares
to try out new things, therefore these parts of the infrastructure are ever
changing.</p><h2 id="to-be-continued-">To Be Continued …</h2><p>As mentioned before, one of the next big projects will be rebuilding <code>h4nk4</code>
into something significantly smaller with as much or even more capacity. I’m
closely watching the latest developments in the areas of SBCs and NUCs, but so
far I haven’t really seen anything that could work as a replacement for the AMD
machine.</p><p>Another todo on my list regards the Netgear Nighthawk LTE router, that I would
like to replace with a more open alternative. While this is certainly possible
today, <a href="https://www.jeffgeerling.com/blog/2022/using-4g-lte-wireless-modems-on-raspberry-pi">people have tried</a> and found it to be a mixed bag. I do however
believe that the efforts going into projects like the PinePhone Pro will
ultimately benefit this area enough for it to become less of a PITA. Hence, the
PinePhone could actually lead to become my first try replacing the Netgear
router.</p><p>There are still a few more <em>unfree</em> devices around, like the MacBook that I
solely use for <em>Capture One</em> and <em>DaVinci Resolve</em> these days, or the iPhone
that holds on to all the banking apps and ISP apps and all the other things that
would simply not work reliably on a non-Apple, non-Google device. Oh, and the
Apple Watch, that I began to only use during workouts. While there’s no real
open source alternative to that either, there are at least other sports watches
that might allow me to pull my data off them without using proprietary apps or
cloud services. A few more things I’m looking forward to change. However, all in
all I’m very satisfied with the progress and how everything turned out so far.</p></div></div>
  </body>
</html>
