<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2544r0.html">Original</a>
    <h1>Current hardware trends make C&#43;&#43; exceptions harder to justify</h1>
    
    <div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>Many projects avoid or even actively disable C++ exceptions due to a number of reasons (see <a data-link-type="biblio" href="#biblio-p0709r4">[P0709R4]</a> for a detailed discussion).
The unfortunate reality is that, while exceptions are the default error reporting mechanism in C++, there are good reasons for avoiding them.
In fact the current trend to high core counts makes exceptions unsustainable, at least in their current implementation.
In the following, we first illustrate and quantify the problem, and then discuss potential mitigations.
The source code for all experiments is available at <a data-link-type="biblio" href="#biblio-ep">[ep]</a>.</p>
   <p>As illustrational example consider this small code fragment:</p>
<pre><c- k="">struct</c-> <c- nc="">invalid_value</c-> <c- p="">{};</c->

<c- b="">void</c-> <c- nf="">do_sqrt</c-><c- p="">(</c-><c- n="">std</c-><c- o="">::</c-><c- n="">span</c-><c- o="">&lt;</c-><c- b="">double</c-><c- o="">&gt;</c-> <c- n="">values</c-><c- p="">)</c-> <c- p="">{</c->
   <c- k="">for</c-> <c- p="">(</c-><c- k="">auto</c-><c- o="">&amp;</c-> <c- nl="">v</c-> <c- p="">:</c-> <c- n="">values</c-><c- p="">)</c-> <c- p="">{</c->
      <c- k="">if</c-> <c- p="">(</c-><c- n="">v</c-> <c- o="">&lt;</c-> <c- mi="">0</c-><c- p="">)</c-> <c- k="">throw</c-> <c- n="">invalid_value</c-><c- p="">{};</c->
      <c- n="">v</c-> <c- o="">=</c-> <c- n="">std</c-><c- o="">::</c-><c- n="">sqrt</c-><c- p="">(</c-><c- n="">v</c-><c- p="">);</c->
   <c- p="">}</c->
<c- p="">}</c->
</pre>
   <p>It performs a somewhat expensive computation and throws an exception if an invalid value is encountered. Its performance depends on the
likelihood of encountering an exception. To test the performance, we call it 100’000 times with an array of 100 doubles with the value 1.0.
With a certain probability, we set one value of that array to -1 to trigger an error. On an AMD Ryzen 9 5900X we observe the following
execution numbers (in milliseconds) for the whole workload, depending on the thread count and the failure rate:</p>
   <table>
    <thead>
     <tr>
      <td>Threads
      </td><td>1
      </td><td>2
      </td><td>4
      </td><td>8
      </td><td>12
    </td></tr></thead><tbody>
     <tr>
      <td>0.0% failure
      </td><td>19ms
      </td><td>19ms
      </td><td>19ms
      </td><td>19ms
      </td><td>19ms
     </td></tr><tr>
      <td>0.1% failure
      </td><td>19ms
      </td><td>19ms
      </td><td>19ms
      </td><td>19ms
      </td><td>20ms
     </td></tr><tr>
      <td>1.0% failure
      </td><td>19ms
      </td><td>19ms
      </td><td>20ms
      </td><td>20ms
      </td><td>23ms
     </td></tr><tr>
      <td>10% failure
      </td><td>23ms
      </td><td>34ms
      </td><td>59ms
      </td><td>168ms
      </td><td>247ms
   </td></tr></tbody></table>
   <p>In the first column we see that runtime increases with higher failure rates, but that increase is
modest and to be expected. After all, exceptions are for &#34;exceptional&#34; situations, and thus 10% failure
rate is already quite high. When we look at the last column with 12 threads the increase happens much earlier,
though, already at 1% failure the execution time has grown significantly, and at 10% the overhead is unacceptable.</p>
   <p>These numbers were measured on a Linux system using gcc 11.2, but we saw similar results with clang 13 and with
the Microsoft C++ compiler on Windows. The root cause is that the unwinder grabs a global mutex to protect
the unwinding tables from concurrent changes from shared libraries. This has disastrous performance implications
on today’s and upcoming machines. The Ryzen CPU shown above is a simple desktop CPU, when we do the same experiment
on a dual socket AMD EPYC 7713 with 128 cores and 256 execution contexts we get the following numbers:</p>
   <table>
    <thead>
     <tr>
      <td>Threads
      </td><td>1
      </td><td>2
      </td><td>4
      </td><td>8
      </td><td>16
      </td><td>32
      </td><td>64
      </td><td>128
    </td></tr></thead><tbody>
     <tr>
      <td>0.0% failure
      </td><td>24ms
      </td><td>26ms
      </td><td>26ms
      </td><td>30ms
      </td><td>29ms
      </td><td>29ms
      </td><td>29ms
      </td><td>31ms
     </td></tr><tr>
      <td>0.1% failure
      </td><td>29ms
      </td><td>29ms
      </td><td>29ms
      </td><td>29ms
      </td><td>30ms
      </td><td>30ms
      </td><td>31ms
      </td><td>105ms
     </td></tr><tr>
      <td>1.0% failure
      </td><td>29ms
      </td><td>30ms
      </td><td>31ms
      </td><td>34ms
      </td><td>58ms
      </td><td>123ms
      </td><td>280ms
      </td><td>1030ms
     </td></tr><tr>
      <td>10% failure
      </td><td>36ms
      </td><td>49ms
      </td><td>129ms
      </td><td>306ms
      </td><td>731ms
      </td><td>1320ms
      </td><td>2703ms
      </td><td>6425ms
   </td></tr></tbody></table>
   <p>There, we start to get performance problems already at 0.1% failure rate, and the system becomes unusable at 1% failure rate or more.
This makes it hard to justify using exceptions in C++, their performance is hard to predict and they degrade badly under high concurrency.</p>
   <p>On the other hand, and in contrast to most of the alternatives discussed below, traditional C++ exceptions do have the advantage
that they have (nearly) zero overhead compared to no error checking at all as long as no exception occurs. We can measure that with an code fragment that performs a very high number
of function invocations and little extra work per call:</p>
<pre><c- k="">struct</c-> <c- nc="">invalid_value</c-> <c- p="">{};</c->

<c- b="">unsigned</c-> <c- nf="">do_fib</c-><c- p="">(</c-><c- b="">unsigned</c-> <c- n="">n</c-><c- p="">,</c-> <c- b="">unsigned</c-> <c- n="">max_depth</c-><c- p="">)</c-> <c- p="">{</c->
   <c- k="">if</c-> <c- p="">(</c-><c- o="">!</c-><c- n="">max_depth</c-><c- p="">)</c-> <c- k="">throw</c-> <c- n="">invalid_value</c-><c- p="">();</c->
   <c- k="">if</c-> <c- p="">(</c-><c- n="">n</c-> <c- o="">&lt;=</c-> <c- mi="">2</c-><c- p="">)</c-> <c- k="">return</c-> <c- mi="">1</c-><c- p="">;</c->
   <c- k="">return</c-> <c- n="">do_fib</c-><c- p="">(</c-><c- n="">n</c-> <c- o="">-</c-> <c- mi="">2</c-><c- p="">,</c-> <c- n="">max_depth</c-> <c- o="">-</c-> <c- mi="">1</c-><c- p="">)</c-> <c- o="">+</c-> <c- n="">do_fib</c-><c- p="">(</c-><c- n="">n</c-> <c- o="">-</c-> <c- mi="">1</c-><c- p="">,</c-> <c- n="">max_depth</c-> <c- o="">-</c-> <c- mi="">1</c-><c- p="">);</c->
<c- p="">}</c->
</pre>
   <p>On the Ryzen we get as execution time for 10’000 invocations with n = 15 (and a certain probability of
max_depth being 13, which triggers an exception):</p>
   <table>
    <thead>
     <tr>
      <td>Threads
      </td><td>1
      </td><td>2
      </td><td>4
      </td><td>8
      </td><td>12
    </td></tr></thead><tbody>
     <tr>
      <td>0.0% failure
      </td><td>12ms
      </td><td>12ms
      </td><td>12ms
      </td><td>14ms
      </td><td>14ms
     </td></tr><tr>
      <td>0.1% failure
      </td><td>14ms
      </td><td>14ms
      </td><td>14ms
      </td><td>14ms
      </td><td>15ms
     </td></tr><tr>
      <td>1.0% failure
      </td><td>14ms
      </td><td>14ms
      </td><td>14ms
      </td><td>15ms
      </td><td>15ms
     </td></tr><tr>
      <td>10% failure
      </td><td>18ms
      </td><td>20ms
      </td><td>27ms
      </td><td>64ms
      </td><td>101ms
   </td></tr></tbody></table>
   <p>When using C++ exceptions the results are similar to the sqrt scenario from above.
We include them here because for the alternatives that we discuss below the fib scenario is the
worst case, and significantly more expensive than the sqrt scenario.
And again we have the problem that performance degrades with increasing concurrency.</p>
   <h2 data-level="2" id="problems"><span>2. </span><span>Root cause</span><a href="#problems"></a></h2>
   <p>Traditional C++ exceptions have two main problems:</p>
   <p>1) the exceptions are allocated in dynamic memory because of inheritance and because of non-local constructs like
std::current_exception. This prevents basic optimizations like transforming a throw into a goto, because other
parts of the program should be able to see that dynamically allocated exception object. And it causes problems
with throwing exceptions in out-of-memory situations.</p>
   <p>2) exception unwinding is effectively single-threaded, because the table driven unwinder logic used by modern
C++ compilers grabs a global mutex to protect the tables from concurrent changes. This has disastrous consequences
for high core counts and makes exceptions nearly unusable on such machines.</p>
   <p>The first problem seems unfixable without language changes, there are many constructs like &#34;throw;&#34; or
current_exception that rely upon that mechanism. Note that these can occur in any part of the program,
in particular in any function that is called by a catch block that is not inlined, thus we usually cannot
simply elide the object construction.
The second problem could potentially be fixed by
a sophisticated implementation, but that would definitively be an ABI break and it would require
careful coordination of all components involved, including shared libraries.</p>
   <h2 data-level="3" id="alternatives"><span>3. </span><span>Alternatives</span><a href="#alternatives"></a></h2>
   <p>Quite a few alternatives to traditional exceptions have been proposed, we will now look at some of them.
All approaches solve the global mutex problem, thus multi-threaded performance is identical to
single threaded performance and we only show single-threaded results. Source code to report full
performance number is available at <a data-link-type="biblio" href="#biblio-ep">[ep]</a>.
The main problem most of the alternatives have is that while they handle the sqrt scenario just fine, most of them have a
significant performance overhead for the fib scenario. Which makes it difficult to simply replace
traditional exceptions.</p>
   <h3 data-level="3.1" id="expected"><span>3.1. </span><span>std::expected</span><a href="#expected"></a></h3>
   <p>The std:expected proposal <a data-link-type="biblio" href="#biblio-p0323r11">[P0323R11]</a> introduces a variant type that either holds a value or
an error object, which can be used to propagate the error state as a return value instead of
throwing an exception. This solves the performance problem for sqrt, but it has a significant
runtime overhead for fib:</p>
   <table>
    <thead>
     <tr>
      <td>failure rate
      </td><td>0.0%
      </td><td>0.1%
      </td><td>1.0%
      </td><td>10%
    </td></tr></thead><tbody>
     <tr>
      <td>sqrt
      </td><td>18ms
      </td><td>18ms
      </td><td>18ms
      </td><td>16ms
     </td></tr><tr>
      <td>fib
      </td><td>63ms
      </td><td>63ms
      </td><td>63ms
      </td><td>63ms
   </td></tr></tbody></table>
   <p>Single threaded the fib code using std::expected is more than four times slower than using
traditional exceptions. Of course the overhead is less when the function itself is more expensive,
as in the sqrt scenario. Nevertheless the overhead is so high that std::expected is not a
good general purpose replacement for traditional exceptions.</p>
   <h3 data-level="3.2" id="leaf"><span>3.2. </span><span>boost::LEAF</span><a href="#leaf"></a></h3>
   <p>Instead of passing potentially complex error objects around, the catch-by-value proposal <a data-link-type="biblio" href="#biblio-p2232r0">[P2232R0]</a> suggests that it is much more efficient to catch objects by value instead of by reference. When
catching by value, the throw location can identify the accepting catch, and then directly place the
error object into stack memory provided by the try/catch block. The error itself can be propagated
as a single bit. When using the boost::LEAF implementation of such a scheme we get the following
performance numbers:</p>
   <table>
    <thead>
     <tr>
      <td>failure rate
      </td><td>0.0%
      </td><td>0.1%
      </td><td>1.0%
      </td><td>10%
    </td></tr></thead><tbody>
     <tr>
      <td>sqrt
      </td><td>18ms
      </td><td>18ms
      </td><td>18ms
      </td><td>16ms
     </td></tr><tr>
      <td>fib
      </td><td>23ms
      </td><td>22ms
      </td><td>22ms
      </td><td>22ms
   </td></tr></tbody></table>
   <p>This has much less overhead than std::expected, but it is still not for free. For fib we see a slowdown of
approx. 60% compared to traditional exceptions, which is still problematic.</p>
   <p>Note that LEAF profits significantly from using -fno-exceptions here. When enabling exceptions the
fib case needs 29ms, even though not a single exception is thrown, which illustrates that exceptions
are not truly zero overhead. They cause overhead by pessimizing other code.</p>
   <h3 data-level="3.3" id="herbceptions"><span>3.3. </span><span>throwing values</span><a href="#herbceptions"></a></h3>
   <p>The throwing values proposal <a data-link-type="biblio" href="#biblio-p0709r4">[P0709R4]</a> (also known as &#34;Herbceptions&#34;) suggests that we do not allow
for arbitrary exceptions to be thrown, but instead use a specific exception class which can be
passed efficiently using two register values. The exception indicator itself is passed using a
CPU flag when returning from a function. This is a clever idea that we unfortunately cannot
implement in pure C++ due to lack of control over the CPU flags. We have thus tested two alternatives,
one pure C++ approximation, where the non-exceptional result value must be at most pointer
sized for optimal performance, and one hard-coded Herbception implementation using
inline assembler. The performance number are:</p>
   <table>
    <thead>
     <tr>
      <td>failure rate
      </td><td>0.0%
      </td><td>0.1%
      </td><td>1.0%
      </td><td>10%
    </td></tr></thead><tbody>
     <tr>
      <td>C++ emulation
     </td></tr><tr>
      <td>sqrt
      </td><td>18ms
      </td><td>18ms
      </td><td>18ms
      </td><td>16ms
     </td></tr><tr>
      <td>fib
      </td><td>19ms
      </td><td>18ms
      </td><td>18ms
      </td><td>18ms
     </td></tr><tr>
      <td>assembler
     </td></tr><tr>
      <td>sqrt
      </td><td>18ms
      </td><td>18ms
      </td><td>18ms
      </td><td>16ms
     </td></tr><tr>
      <td>fib
      </td><td>13ms
      </td><td>13ms
      </td><td>13ms
      </td><td>13ms
   </td></tr></tbody></table>
   <p>This is close to being an acceptable substitute to traditional C++ exceptions. There is still
some slowdown on the happy path, when no exception occurs, but that overhead is small,
approx. 25% when using C++ and approx. 10% when using assembler, in a scenario where we do nearly nothing except calling other functions. It
overtakes traditional exceptions if failure rates are higher. And it is dramatically better in multi-threaded applications.</p>
   <h3 data-level="3.4" id="traditional"><span>3.4. </span><span>fixing traditional exceptions</span><a href="#traditional"></a></h3>
   <p>Even though none of the leading C++ compilers does so, it is in fact possible to implement contention
free exception unwinding. We did a prototype implementation where we changed the gcc exception logic
to register all unwinding tables in a b-tree with optimistic lock coupling. This allows for fully parallel
exception unwinding, the different threads can all unwind in parallel without any need for atomic writes as
long as there are no concurrent shared library operations. Shared library open/close triggers a full lock,
but that should be rare. With such a data structure we can unwind in parallel, and we get
a multi-threaded performance that is nearly identical to the single-threaded case, both on 12 and on 128 cores.</p>
   <p>That sounds like an ideal solution, but in practice this is hard to introduce. It breaks the existing ABI,
and all shared libraries would have to be compiled with the new model, as otherwise unwinding breaks. In a way
the other alternative mechanisms break the ABI, too, but there the breakage is local to the code that uses
the new mechanisms. Changing the traditional unwinding mechanism requires coordination across all code artifacts
that are linked together. This would only happen if the C++ standard mandates that unwinding has to be contention
free, and even then the introduction of the new ABI would be difficult.</p>
   <p>A less radical change would be to change the global mutex into an rwlock, but unfortunately that is
not easily possible either. Unwinding is not a pure library function but a back and forth between
the unwinder and application/compiler code, and existing code relies upon the fact that it is protected
by a global lock. In libgcc the callback from dl_iterate_phdr manipulates shared state, and switching
to an rwlock leads to data races. Of course it would make sense to change that, but that would be an ABI break, too.</p>
   <p>And fundamentally the current exception design is suboptimal for efficient implementations. For example we would
like to be able to do the following transformation:</p>
<pre><c- k="">struct</c-> <c- nc="">ex</c-> <c- p="">{};</c->
<c- p="">...</c->
<c- b="">int</c-> <c- n="">x</c-><c- p="">;</c->
<c- k="">try</c-> <c- p="">{</c->
   <c- k="">if</c-> <c- p="">(</c-><c- n="">y</c-><c- o="">&lt;</c-><c- mi="">0</c-><c- p="">)</c-> <c- k="">throw</c-> <c- n="">ex</c-><c- p="">{};</c->
   <c- n="">x</c-><c- o="">=</c-><c- mi="">1</c-><c- p="">;</c->
<c- p="">}</c-> <c- k="">catch</c-> <c- p="">(</c-><c- k="">const</c-> <c- n="">ex</c-><c- o="">&amp;</c-><c- p="">)</c-> <c- p="">{</c->
   <c- n="">foo</c-><c- p="">();</c->
   <c- n="">x</c-><c- o="">=</c-><c- mi="">2</c-><c- p="">;</c->
<c- p="">}</c->

<c- o="">=&gt;</c->

<c- b="">int</c-> <c- n="">x</c-><c- p="">;</c->
<c- k="">if</c-> <c- p="">(</c-><c- n="">y</c-><c- o="">&lt;</c-><c- mi="">0</c-><c- p="">)</c-> <c- p="">{</c-> <c- n="">foo</c-><c- p="">();</c-> <c- n="">x</c-><c- o="">=</c-><c- mi="">2</c-><c- p="">;</c-> <c- p="">}</c-> <c- k="">else</c-> <c- n="">x</c-><c- o="">=</c-><c- mi="">1</c-><c- p="">;</c->
</pre>
   <p>But we cannot, as the function foo() might contain surprises like this:</p>
<pre><c- b="">void</c-> <c- nf="">foo</c-><c- p="">()</c-> <c- p="">{</c->
   <c- k="">if</c-> <c- p="">(</c-><c- n="">random</c-><c- p="">()</c-> <c- o="">&lt;</c-> <c- mi="">10</c-><c- p="">)</c-> <c- n="">some_global</c-> <c- o="">=</c-> <c- n="">std</c-><c- o="">::</c-><c- n="">current_exception</c-><c- p="">();</c->
   <c- k="">if</c-> <c- p="">(</c-><c- n="">random</c-><c- p="">()</c-> <c- o="">&lt;</c-> <c- mi="">100</c-><c- p="">)</c-> <c- k="">throw</c-><c- p="">;</c->
<c- p="">}</c->
</pre>
   <p>This forces exceptions to be globally available at all time and prevents more efficient
implementations. And we saw these limitations in practice: Even with fully lock-free unwinding,
we encountered some scalability issues with very high threads counts and high error rates (256 threads, 10% failure).
These were far less severe than with current single-threaded unwinding, but nevertheless
it is clear that the other parts of traditional exception handling do not scale either due to global state.
Which is a strong argument for preferring an exception mechanism that uses only local state.</p>
   <h2 data-level="4" id="thefuture"><span>4. </span><span>Moving Forward</span><a href="#thefuture"></a></h2>
   <p>The current C++ exception mechanism has to change to stay relevant. Mainstream machines will soon have 256 cores
and more, and current implementations cannot cope with that. The main question is which mitigation strategy should we
use?</p>
   <p>Throwing values <a data-link-type="biblio" href="#biblio-p0709r4">[P0709R4]</a> seems quite attractive, as it is one of the fastest approaches, is lock free,
allows for transforming throw into goto, and does not require global coordination across all libraries.
What is missing, however, is a way to integrate that mechanism into the existing language, in particular
the standard library. The mechanism will be opt-in in the sense that we have to recompile the source code to
get the throwing-values mechanism, but that is fine. The question is how can we get compatibility on the
source level? Switching mechanisms based upon compiler flags seems dangerous with regards to the ODR,
and switching from, e.g., std:: to std2:: would be a very invasive change. It is not clear yet what the
best strategy would be. But something has to be done, as otherwise more and more people will be forced
to use -fno-exceptions and switch to home grown solutions to avoid the performance problems on modern
machines.</p>
   <h2 data-level="5" id="acknowledgments"><span>5. </span><span>Acknowledgments</span><a href="#acknowledgments"></a></h2>
   <ul>
    <li data-md="">
     <p>Thanks to Emil Dotchevski and Peter Dimov for their feedback</p>
   </li></ul>
  </div></div>
  </body>
</html>
