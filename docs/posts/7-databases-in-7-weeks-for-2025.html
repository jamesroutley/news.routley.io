<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://matt.blwt.io/post/7-databases-in-7-weeks-for-2025/">Original</a>
    <h1>7 Databases in 7 Weeks for 2025</h1>
    
    <div id="readability-page-1" class="page"><div><p>I’ve been running databases-as-a-service for a long time, and there are always new things to keep abreast of - new technologies, different ways of solving problems, not to mention all the research coming out of universities. In 2025, consider spending a week with each of these database technologies.</p><figure><img src="https://matt.blwt.io/7-databases-in-7-weeks-for-2025/header.webp" alt="A line drawing of a bookshelf, with the books labelled for each database covered - PostgreSQL, SQLite, DuckDB, ClickHouse, FoundationDB, TigerBeetle and CockroachDB"/></figure><h2 id="preamble">Preamble</h2><p>These aren’t the “7 Best Databases” or something similar to power a Buzzfeed listicle - these are just 7 databases that I think are worth your time to really look into for a week or so. You might ask something like “why not Neo4j or MongoDB or MySQL/Vitess or &lt;insert other db here&gt;” - the answer is mostly that I don’t find them interesting. I’m also not covering Kafka or other similar streaming data services - definitely worth your time, but not covered.</p><h2 id="table-of-contents">Table of Contents</h2><ol><li><a href="#1-postgresql">PostgreSQL</a></li><li><a href="#2-sqlite">SQLite</a></li><li><a href="#3-duckdb">DuckDB</a></li><li><a href="#4-clickhouse">ClickHouse</a></li><li><a href="#5-foundationdb">FoundationDB</a></li><li><a href="#6-tigerbeetle">TigerBeetle</a></li><li><a href="#7-cockroachdb">CockroachDB</a></li></ol><ul><li><a href="#wrap-up">Wrap Up</a></li></ul><h2 id="1-postgresql">1. PostgreSQL</h2><h3 id="the-default-database">The Default Database</h3><p>“Just use Postgres” is basically a meme at this point, and for good reason. <a href="https://www.postgresql.org/">PostgreSQL</a> is the pinnacle of <a href="https://boringtechnology.club/">boring technology</a>, and should be the database you reach for when you need a client-server model for your database. ACID compliant, plenty of interesting tricks for replication - both physical and logical - and incredibly well supported across all the major vendors.</p><p>My favourite feature of Postgres, however, are <a href="https://wiki.postgresql.org/wiki/Extensions">extensions</a>. This is where I feel Postgres really comes alive in a way that few other databases can. There are extensions for almost everything you could want - <a href="https://age.apache.org/">AGE</a> enables graph data structures and the user of the Cypher query language, <a href="https://docs.timescale.com/self-hosted/latest/">TimescaleDB</a> enables time-series workloads, <a href="https://github.com/hydradatabase/hydra/tree/main/columnar">Hydra Columnar</a> provides an alternate columnar storage engine, and so on. I’ve <a href="https://matt.blwt.io/post/building-a-postgresql-extension-line-by-line">written about writing an extension</a> relatively recently if you’d like to give it a go yourself.</p><p>Postgres shines as a great “default” database for that reason, and we’re seeing even more non-Postgres services rely on the <a href="https://www.postgresql.org/docs/current/protocol.html">Postgres wire protocol</a> as a general-purpose Layer 7 protocol to provide client compatibility. With a rich ecosystem, sensible default behaviour and that it can even be fit into a <a href="https://pglite.dev/">Wasm install</a> makes it a database worth understanding.</p><p>Spend a week learning about whats possible with Postgres, but also some of its limitations - <a href="https://www.geeksforgeeks.org/multiversion-concurrency-control-mvcc-in-postgresql/">MVCC</a> can be fickle. Implement a simple CRUD app in your favourite language. Maybe even build a Postgres extension.</p><h2 id="2-sqlite">2. SQLite</h2><h3 id="the-local-first-database">The Local-First Database</h3><p>Moving on from a client-server model, we take a detour into “embedded” databases, starting with <a href="https://www.sqlite.org/index.html">SQLite</a>. I’ve termed this the “<a href="https://www.inkandswitch.com/local-first/">local-first</a>” database, where the SQLite database is directly co-located with the application. One of the more famous examples of this usage is <a href="https://www.whatsapp.com/">WhatsApp</a>, which stored chats as local SQLite databases on the device being used. <a href="https://signal.org/">Signal</a> also does the same thing.</p><p>Beyond that, we’re starting to see more creative uses of SQLite rather than “just” a local ACID-compliant database. With the advent of tools like <a href="https://litestream.io/">Litestream</a> enabling streaming backups and <a href="https://fly.io/docs/litefs/">LiteFS</a> to provide distributed access, we can devise more interesting topologies. Extensions like <a href="https://github.com/vlcn-io/cr-sqlite">CR-SQLite</a> allow the use of <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDTs</a> to avoid needing conflict resolution when merging changesets, as used in <a href="https://github.com/superfly/corrosion">Corrosion</a>.</p><p>SQLite has also had a small resurgence thanks to <a href="https://rubyonrails.org/2024/9/27/rails-8-beta1-no-paas-required">Ruby on Rails 8.0</a> - 37signals has gone all in on SQLite, building a bunch of Rails modules like <a href="https://github.com/rails/solid_queue">Solid Queue</a> and configuring Rails to manipulate multiple SQLite databases via <code>database.yml</code> for this purpose. <a href="https://newsletter.pragmaticengineer.com/p/bluesky?open=false#%C2%A7sqlite">Bluesky uses SQLite for the Personal Data Servers</a> - every user has their own SQLite database.</p><p>Spend a week experimenting with local-first architectures using SQLite, or even seeing if you can migrate a client-server model using Postgres to something that “just” needs SQLite instead.</p><h2 id="3-duckdb">3. DuckDB</h2><h3 id="the-query-anything-database">The Query-Anything Database</h3><p>Onto the next embedded database, we have <a href="https://duckdb.org/">DuckDB</a>. Much like SQLite, DuckDB is intended to be an in-process database system, but more focused on online analytical processing (OLAP) versus online transaction processing (OLTP).</p><p>Where DuckDB shines is its use as a “query-anything” database, using SQL as its dialect of choice. It can natively pull data into its engine from CSVs, TSVs, JSON etc, but also formats like Parquet - just check out the list of <a href="https://duckdb.org/docs/data/data_sources.html">data sources</a>. This gives it extreme flexibility - check out <a href="https://motherduck.com/blog/how-to-extract-analytics-from-bluesky/">this example of querying the Bluesky firehose</a>.</p><p>Much like Postgres, DuckDB also <a href="https://duckdb.org/docs/extensions/overview">has extensions</a>, though not quite as rich an ecosystem - DuckDB is much younger, after all. Many contributed by the community can be found on the <a href="https://duckdb.org/community_extensions/list_of_extensions">list of community extensions</a>, though a particular favourite of mine is <a href="https://duckdb.org/community_extensions/extensions/gsheets.html"><code>gsheets</code></a>.</p><p>Spend a week doing some data analysis and processing with DuckDB - be it via a Python notebook or something like <a href="https://evidence.dev/">Evidence</a>, maybe even see how it fits in with your “local-first” approach with SQLite by offloading analytics queries of your SQLite database to DuckDB, which <a href="https://duckdb.org/docs/guides/database_integration/sqlite.html">can read it</a>.</p><h2 id="4-clickhouse">4. ClickHouse</h2><h3 id="the-columnar-database">The Columnar Database</h3><p>Leaving the embedded database sphere, but sticking with the analytics theme, we come to <a href="https://clickhouse.com/">ClickHouse</a>. If I had to only pick two databases to deal with, I’d be quite happy with just Postgres and ClickHouse - the former for OLTP, the latter for OLAP.</p><p>ClickHouse specialises in analytics workloads, and can support very high ingest rates through <a href="https://clickhouse.com/docs/en/architecture/horizontal-scaling">horizontal scaling</a> and sharded storage. It also supports <a href="https://clickhouse.com/docs/en/guides/separation-storage-compute">tiered storage</a>, allowing you to split “hot” and “cold” data - <a href="https://docs.gitlab.com/ee/development/database/clickhouse/tiered_storage.html">GitLab</a> have a pretty thorough doc on this.</p><p>Where ClickHouse comes into its own is when you have analytics queries to run on a dataset too big for something like DuckDB, or you need “real-time” analytics. There is a lot of “benchmarketing” around these datasets, so I’m not going to repeat them here.</p><p>Another reason I suggest checking out ClickHouse is that it is a <em>joy</em> to operate - deployment, scaling, backups and so on are <a href="https://clickhouse.com/docs/en/architecture/cluster-deployment">well documented</a> - even down to setting <a href="https://clickhouse.com/docs/en/operations/tips">the right CPU governor</a> is covered.</p><p>Spend a week exploring some larger analytics datasets, or converting some of the DuckDB analytics from above into a ClickHouse deployment. ClickHouse also has an embedded version - <a href="https://clickhouse.com/docs/en/chdb">chDB</a> - that can offer a more direct comparison.</p><h2 id="5-foundationdb">5. FoundationDB</h2><h3 id="the-layered-database">The Layered Database</h3><p>We now enter the “mind expanding” section of this list, with <a href="https://www.foundationdb.org/">FoundationDB</a>. Arguably, FoundationDB is not a database, but quite literally the foundation for <em>a</em> database. Used in production by Apple, Snowflake and <a href="https://www.tigrisdata.com/blog/building-a-database-using-foundationdb/">Tigris Data</a>, FoundationDB is worth your time because it is quite unique in the world of key-value storage.</p><p>Yes, it’s an ordered key-value store, but that isn’t what is interesting about it. At first glance, it has some curious <a href="https://apple.github.io/foundationdb/known-limitations.html">limitations</a> - transactions cannot exceed 10MB of affected data and they cannot take longer than five seconds after the first read in a transaction. But, as they say, limits set us free. By having these limits, it can achieve full ACID transactions at very large scale - 100+ TiB clusters are known to be in operation.</p><p>FoundationDB is architected for specific workloads and <a href="https://apple.github.io/foundationdb/testing.html">extensively tested</a> using simulation testing, which has been picked up by other technologies, including another database on this list and <a href="https://www.antithesis.com/">Antithesis</a>, founded by some ex-FoundationDB folks. For more notes on this, check out <a href="https://sled.rs/simulation.html">Tyler Neely’s</a> and <a href="https://notes.eatonphil.com/2024-08-20-deterministic-simulation-testing.html">Phil Eaton’s</a> notes on the topic.</p><p>As mentioned, FoundationDB has some very specific semantics that take some getting used to - their <a href="https://apple.github.io/foundationdb/anti-features.html">Anti-Features</a> and <a href="https://apple.github.io/foundationdb/features.html">Features</a> docs are worth familiarising yourself with to understand the problems they are looking to solve.</p><p>But why is it the “layered” database? This is because of the <a href="https://apple.github.io/foundationdb/layer-concept.html">Layers concept</a>. Instead of tying the storage engine to the data model, instead the storage is flexible enough to be remapped across different layers. <a href="https://www.tigrisdata.com/blog/data-layer-foundationdb/">Tigris Data</a> have a great post about building such a layer, and there are some examples such as a <a href="https://github.com/FoundationDB/fdb-record-layer">Record layer</a> and a <a href="https://github.com/FoundationDB/fdb-document-layer">Document layer</a> from the FoundationDB org.</p><p>Spend a week going through the <a href="https://apple.github.io/foundationdb/tutorials.html">tutorials</a> and think about how you could use FoundationDB in place of something like <a href="https://rocksdb.org/">RocksDB</a>. Maybe check out some of the <a href="https://apple.github.io/foundationdb/design-recipes.html">Design Recipes</a> and go read the <a href="https://www.foundationdb.org/files/fdb-paper.pdf">paper</a>.</p><h2 id="6-tigerbeetle">6. TigerBeetle</h2><h3 id="the-obsessively-correct-database">The Obsessively Correct Database</h3><p>Flowing on from the deterministic simulation testing, <a href="https://tigerbeetle.com/">TigerBeetle</a> breaks the mold from our previous databases in that it is decidedly <em>not</em> a general purpose database - it is entirely dedicated to financial transactions.</p><p>Why is this worth a look? Single-purpose databases are unusual, and one that is as <em>obsessively correct</em> as TigerBeetle are a true rarity, especially considering it is open source. They include everything from <a href="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">NASA’s Power of Ten Rules</a> and <a href="https://www.usenix.org/conference/fast18/presentation/alagappan">Protocol-Aware Recovery</a>, through to strict serialisability and Direct I/O to avoid issues with the kernel page cache. It is <em>seriously</em> impressive - just go read their <a href="https://github.com/tigerbeetle/tigerbeetle/blob/a43f2205f5335cb8f56d6e8bfcc6b2d99a4fc4a4/docs/about/safety.md">Safety doc</a> and their <a href="https://github.com/tigerbeetle/tigerbeetle/blob/a43f2205f5335cb8f56d6e8bfcc6b2d99a4fc4a4/docs/TIGER_STYLE.md">approach to programming they call Tiger Style</a>.</p><p>Another interesting point about TigerBeetle is that it’s written in <a href="https://ziglang.org/">Zig</a> - a relative newcomer to the systems programming language school, but clearly has fit well with what the TigerBeetle folks are trying to accomplish.</p><p>Spend a week modelling your financial accounts in a local deployment of TigerBeetle - follow the <a href="https://docs.tigerbeetle.com/quick-start">Quick Start</a> and take a look at the <a href="https://docs.tigerbeetle.com/coding/system-architecture">System Architecture</a> docs on how you might use it in conjunction with one of the more general-purpose databases above.</p><h2 id="7-cockroachdb">7. CockroachDB</h2><h3 id="the-global-database">The Global Database</h3><p>Finally, we come full circle. I struggled a little on what to put here in the last slot. Thoughts originally went to <a href="https://valkey.io/">Valkey</a>, but FoundationDB scratched the key-value itch. I thought about graph databases, or something like <a href="https://www.scylladb.com/">ScyllaDB</a> or <a href="https://cassandra.apache.org/_/index.html">Cassandra</a>. I thought about <a href="https://aws.amazon.com/dynamodb/">DynamoDB</a>, but not being able to run it locally/for free put me off.</p><p>In the end, I decided to close on a globally distributed database - <a href="https://www.cockroachlabs.com/">CockroachDB</a>. It’s Postgres wire-protocol compatible, and inherits some of the more interesting features discussed above - large horizontal scaling, strong consistency - and has some interesting features of its own.</p><p>CockroachDB enables scaling a database across multiple geographies through being based on Google’s <a href="http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf">Spanner</a> system, which relies on atomic and GPS clocks for extremely accurate time synchronisation. Commodity hardware, however, doesn’t have such luxuries, so CockroachDB has some <a href="https://www.cockroachlabs.com/blog/living-without-atomic-clocks/#How-does-CockroachDB-choose-transaction-timestamps?">clever solutions</a> where reads are retried or delayed to account for clock sync delay with NTP, and nodes also compare clock drift amongst themselves and terminate members if they exceed the maximum offset.</p><p>Another interesting feature of CockroachDB is how <a href="https://www.cockroachlabs.com/docs/stable/multiregion-overview">multi-region configurations</a> are used, including <a href="https://www.cockroachlabs.com/docs/stable/table-localities">table localities</a>, where there are different options depending on the read/write tradeoffs you want to make.</p><p>Spend a week re-implementing the the <a href="https://www.cockroachlabs.com/docs/v24.3/movr"><code>movr</code></a> example in a language and framework of your choice.</p><h2 id="wrap-up">Wrap Up</h2><p>We’ve explored a bunch of different databases, all used in production by some of the largest companies on the planet, and hopefully this will have exposed you to some technologies you weren’t familiar with before. Take this knowledge with you as you look to solve interesting problems.</p></div></div>
  </body>
</html>
