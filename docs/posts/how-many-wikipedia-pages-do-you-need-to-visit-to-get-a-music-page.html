<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://liquidbrain.net/blog/quantifying-wikipedia-music-pages/">Original</a>
    <h1>How many wikipedia pages do you need to visit to get a music page?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
            <p>In my <a href="https://liquidbrain.net/blog/wikipedia-music-recs/">previous post</a>, I talked about using Wikipedia to expand my taste in music by repeatedly using the random page function until I hit a page about music. A natural question came up: how long does it take to come across a page pointing towards a piece of music?</p>
<p>To test this, I programmatically obtained the first sentence of 1000 Wikipedia articles. I had initially planned to use plain web-scraping (using the <code>requests</code> python package and a some HTML parsing), but it turns out there&#39;s a Wikimedia API that will return random pages in bulk. After some programming, I had my summaries in hand.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>
<p>Next, I created a small command line interface to manually classify each of the 1000 pages as being about music. I was purposely broad about this -- I classified any page about a musician, band, single, EP, album, composer, opera, musical, DJ, etc. as being about music. As long as I thought that seeing the Wikipedia page would point me towards a piece of music I hadn&#39;t heard before, I classified it as about music. This took around 40 minutes, and I learned a lot about the difficulties of classification problems.</p>
<p>All told, 74 of the 1000 Wikipedia pages were about music. Because this is a random sample,<sup id="fnref:2"><a href="#fn:2">2</a></sup> we can use a proportion z-test to get a confidence interval on the true proportion of articles that would be classified. Using some statistics, we get a 95% confidence interval of 5.8%-9.0% as the true proportion (calculation in footnote).<sup id="fnref:3"><a href="#fn:3">3</a></sup></p>
<hr/>
<p>Thus, we&#39;re 95% confident that it&#39;ll take on average between 1/0.090 ≈ 11.1 and 1/0.058 ≈ 17.2 tries to get to a music page. Not that bad, all things considered!</p>
<p>But what about worst case scenarios? Well, the probability that we look at $n$ pages and they all turn out to be non-music is (1-p)^n, so the probability we&#39;ll see a page within n pages is 1-(1-p)^n. The graph of this looks like:</p>
<p><img alt="Cumulative_probability.png" src="https://liquidbrain.mataroa.blog/images/729a4d90.png"/></p>
<p>A quick calculation shows that (with 95% confidence), the probability of getting an article within 20 articles is between (1-(1-0.058)^20, 1-(1-0.090)^20) = (0.695, 0.848); i.e. between a 70% change and an 85% chance.<sup id="fnref:4"><a href="#fn:4">4</a></sup> What about within 50 tries?<sup id="fnref:5"><a href="#fn:5">5</a></sup> Between 95.0% and 99.1%. After 100 attempts, the probability is between 99.7% and 99.99%.</p>
<p>In other words, even if our luck is bad and the proportion of wikipedia pages about music is at the bottom of our confidence interval, there&#39;s a 95% chance it will take 50 random pages or fewer to run into a music page.</p>
<h2 id="notes">Notes</h2>

        </div></div>
  </body>
</html>
