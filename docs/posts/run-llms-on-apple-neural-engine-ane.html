<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Anemll/Anemll">Original</a>
    <h1>Run LLMs on Apple Neural Engine (ANE)</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">ANEMLL (pronounced like &#34;animal&#34;) is an open-source project focused on accelerating the porting of Large Language Models (LLMs) to tensor processors, starting with the Apple Neural Engine (ANE).</p>

<blockquote>
<p dir="auto">The goal is to provide a fully open-source pipeline from model conversion to inference for common LLM architectures running on ANE.
This enables seamless integration and on-device inference for low-power applications on edge devices, ensuring maximum privacy and security.
This is critical for autonomous applications, where models run directly on the device without requiring an internet connection.</p>
<p dir="auto">We aim to:</p>
<ul dir="auto">
<li>Provide flexible and easy to use library/framework to port LLMs to ANE directly from Hugging Face models</li>
<li>Provide on-device examples for iOS and macOS swift or C/C++ Applications</li>
</ul>
</blockquote>
<p dir="auto">See update <a href="https://github.com/Anemll/Anemll/blob/main/docs/Roadmap.md">Roadmap.md</a> for more details</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Main Components in 0.3.0 Alpha Release</h2><a id="user-content-main-components-in-030-alpha-release" aria-label="Permalink: Main Components in 0.3.0 Alpha Release" href="#main-components-in-030-alpha-release"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">ANEMLL provides five main components for Apple Neural Engine inference development:</p>
<ol dir="auto">
<li>
<p dir="auto"><a href="https://github.com/Anemll/Anemll/blob/main/docs/convert.md">LLM Conversion Tools</a> - Scripts and code to convert models directly from Hugging Face weights</p>
<ul dir="auto">
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/convert_model.md">Single-shot Conversion Script</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://github.com/Anemll/Anemll/blob/main/docs/swift_cli.md">Swift Reference Implementation</a> - Optimized inference code for Swift applications</p>
<ul dir="auto">
<li>Sample CLI application in <code>anemll-swift-cli</code></li>
<li>Core inference engine implementation</li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://github.com/Anemll/Anemll/blob/main/docs/chat.md">Python Sample Code</a> - Reference implementation and testing tools</p>
<ul dir="auto">
<li>Basic chat interface (<code>chat.py</code>)</li>
<li>Advanced conversation management (<code>chat_full.py</code>)</li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://github.com/Anemll/Anemll/blob/main/docs/sample_apps.md">iOS/macOS Sample Applications</a> - Ready-to-use example applications (Alpha, now on TestFlight)</p>
<ul dir="auto">
<li>SwiftUI Chat interface</li>
<li>Model Downloads and integration example</li>
<li>Conversation management</li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://github.com/anemll/anemll-bench">ANEMLL-BENCH</a> - Apple Neural Engine Benchmarking</p>
<ul dir="auto">
<li>Performance testing and comparison</li>
<li>Model optimization metrics</li>
<li>Hardware-specific benchmarks</li>
<li><a href="https://github.com/anemll/anemll-bench">GitHub Repository</a></li>
</ul>
</li>
</ol>

<p dir="auto">We provide sample converted models ready for use:</p>
<ul dir="auto">
<li>LLAMA 3.1 (1B and 8B variants) including iOS &#34;friendly builds&#34;</li>
<li>DeepSeek  distilled models</li>
<li>DeepHermes distilled models</li>
</ul>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">Please note that Quantization should be improved. LUT4 quality is fairly low due to lack of Block Quantization on Apple Neural Engine.
Some GPTQ and Spin Quant should greatly improve LUT4 models.</p>
</div>
<p dir="auto">Visit our <a href="https://huggingface.co/anemll" rel="nofollow">Hugging Face repository</a> for the latest converted models.</p>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Important</p><p dir="auto">This is Alpha Release 0.3.0 for the library. It is designed to process Model Weights directly from Hugging Face models and convert them to the CoreML format for Apple Neural Engine (ANE for short).
This is Alpha Release 0.3.0 for the library. It is designed to process Model Weights directly from Hugging Face models and convert them to the CoreML format for Apple Neural Engine (ANE for short).</p>
<ul dir="auto">
<li>This release only supports LLAMA models including DeepSeek and DeepHermes distilled models on LLaMA 3.1 architecture</li>
<li>The future release will add support for more models and architectures</li>
<li>Please visit <a href="https://huggingface.co/anemll" rel="nofollow">https://huggingface.co/anemll</a> where we upload the latest models and X: <a href="https://x.com/anemll" rel="nofollow">@anemll</a> for updates</li>
<li>Please star this repo to support the project!</li>
</ul>
</div>

<p dir="auto">Swift UI Sample Code</p>
<ul dir="auto">
<li>Sample iOS/macOS inference Chat-Bot App (Alpha)</li>
<li>Updates to Model conversion and upload scripts</li>
<li>Updates to Swift Package and CLI App</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Sample iOS/macOS Applications</h3><a id="user-content-sample-iosmacos-applications" aria-label="Permalink: Sample iOS/macOS Applications" href="#sample-iosmacos-applications"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Downloads reference or custom models from HuggingFace</li>
<li>Inference / chat implementation use Swift Library</li>
<li>Sample TestFlight App for a quick test</li>
<li>See <a href="https://github.com/Anemll/Anemll/blob/main/docs/sample_apps.md">iOS/macOS Sample Applications Guide</a> for details</li>
</ul>

<div dir="auto"><h2 tabindex="-1" dir="auto">Swift CLI Reference Implementation</h2><a id="user-content-swift-cli-reference-implementation" aria-label="Permalink: Swift CLI Reference Implementation" href="#swift-cli-reference-implementation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The Swift CLI provides a reference implementation for running models on Apple Neural Engine. For detailed documentation, see <a href="https://github.com/Anemll/Anemll/blob/main/docs/swift_cli.md">Swift CLI Guide</a>.</p>

<ol dir="auto">
<li>Download a model from <a href="https://huggingface.co/anemll" rel="nofollow">Hugging Face</a></li>
<li>Convert the model using our single-shot conversion script:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./anemll/utils/convert_model.sh --model &lt;path_to_model&gt; --output &lt;output_directory&gt;"><pre>./anemll/utils/convert_model.sh --model <span>&lt;</span>path_to_model<span>&gt;</span> --output <span>&lt;</span>output_directory<span>&gt;</span></pre></div>
<ol start="3" dir="auto">
<li>Run the model using our sample code:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python ./tests/chat.py --meta &lt;output_directory&gt;/meta.yaml"><pre>python ./tests/chat.py --meta <span>&lt;</span>output_directory<span>&gt;</span>/meta.yaml</pre></div>
<p dir="auto">For detailed conversion steps and advanced options, see:</p>
<ul dir="auto">
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/convert.md">Model Conversion Guide</a></li>
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/convert_model.md">Single-shot Conversion Script</a></li>
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/ConvertingDeepSeek.md">DeepSeek Model Guide</a></li>
</ul>

<p dir="auto">We provide two chat interfaces:</p>
<ul dir="auto">
<li><code>chat.py</code> - Basic chat interface for quick testing</li>
<li><code>chat_full.py</code> - Advanced chat with conversation history management</li>
</ul>
<p dir="auto">Features of chat_full.py:</p>
<ul dir="auto">
<li>Maintains full conversation history within context window</li>
<li>Automatically truncates older messages when needed</li>
<li>Shifts context window dynamically during long responses</li>
<li>Shows generation speed and token statistics</li>
<li>Better handles multi-turn conversations</li>
</ul>
<p dir="auto">Example running Chats:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Basic chat
python ./tests/chat.py --meta ./converted_models/meta.yaml

# Full conversation mode
python ./tests/chat_full.py --meta ./converted_models/meta.yaml"><pre><span><span>#</span> Basic chat</span>
python ./tests/chat.py --meta ./converted_models/meta.yaml

<span><span>#</span> Full conversation mode</span>
python ./tests/chat_full.py --meta ./converted_models/meta.yaml</pre></div>
<p dir="auto">See <a href="https://github.com/Anemll/Anemll/blob/main/docs/chat.md">chat.md</a> for more details</p>
<blockquote>
<p dir="auto">[Note]
The first time the model loads, macOS will take some time to place it on the device. Subsequent loads will be instantaneous. Use Ctrl-D to exit, Ctrl-C to interrupt inference.</p>
</blockquote>


<ul dir="auto">
<li>macOS Sequoia with Apple Neural Engine</li>
<li>Minimum 16GB RAM</li>
<li>Python 3.9</li>
</ul>

<ol dir="auto">
<li>Install ANEMLL:
We recommend creating a new virtual environment for this project.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m venv anemll-env
source anemll-env/bin/activate
pip install -r requirements.txt
# pip install anemll
# due to Alpha Release, we do not recommend installing ANEMLL as a package yet"><pre>python -m venv anemll-env
<span>source</span> anemll-env/bin/activate
pip install -r requirements.txt
<span><span>#</span> pip install anemll</span>
<span><span>#</span> due to Alpha Release, we do not recommend installing ANEMLL as a package yet</span></pre></div>
<p dir="auto">CoreML compiler is required to compile the model. It is part of the Xcode command line tools.</p>
<ul dir="auto">
<li>Ensure that Xcode Command Line Tools are installed, as they include <code>coremlcompiler</code>.</li>
<li>You can install them by running <code>xcode-select --install</code>.</li>
<li>Verify that the <code>xcrun</code> command is available and correctly configured in your PATH.</li>
<li>Use <code>xcrun --find coremlcompiler</code> to verify the installation.</li>
<li>If above fails, please try following steps:</li>
<li>Download Xcode from the App Store.</li>
<li>Run <code>sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer/</code> to set the path.</li>
<li>Use <code>xcrun --find coremlcompiler</code> to verify the installation.</li>
<li>Run <code>sudo xcodebuild -license</code> and agree to the license.</li>
</ul>

<p dir="auto">Currently optimized for:</p>
<ul dir="auto">
<li>Meta&#39;s LLaMA 3.2 1B and 8B (1024 context) model including DeepSeek R1 8B distilled model, DeepHermes 3B and 8B models</li>
<li>More models are coming soon</li>
</ul>


<ul dir="auto">
<li>Thanks to <a href="https://apple.com" rel="nofollow">@apple</a> for developing the Apple Neural Engine</li>
<li>Thanks to Apple CoreML Tools team for providing the tools <a href="https://github.com/apple/coremltools">https://github.com/apple/coremltools</a></li>
<li>Thanks to <a href="https://huggingface.co" rel="nofollow">@huggingface</a> for providing the transformers library and models</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Inspirations, feedback and other resources</h3><a id="user-content-inspirations-feedback-and-other-resources" aria-label="Permalink: Inspirations, feedback and other resources" href="#inspirations-feedback-and-other-resources"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Stephen Panaro <a href="https://x.com/flat" rel="nofollow">https://x.com/flat</a> for feedback and coreml-llm-cli <a href="https://github.com/smpanaro/coreml-llm-cli">https://github.com/smpanaro/coreml-llm-cli</a></li>
<li>Seba <a href="https://x.com/CulStory" rel="nofollow">https://x.com/CulStory</a> for inspiration with fast ANE models. <a href="https://huggingface.co/seba" rel="nofollow">https://huggingface.co/seba</a></li>
<li>Maynard Handley <a href="https://x.com/handleym99" rel="nofollow">https://x.com/handleym99</a> For indepth ANE resources <a href="https://github.com/name99-org/AArch64-Explore/blob/main/vol7%20ANE.nb.pdf">https://github.com/name99-org/AArch64-Explore/blob/main/vol7%20ANE.nb.pdf</a> and feedback</li>
</ul>

<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">We welcome contributions! Please read our contributing guidelines before submitting PRs.</p>
</div>
<p dir="auto">Feel free to submit issues and pull requests to improve <strong>ANEMLL</strong>!</p>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">If you&#39;re using ANEMLL in your project, please submit a PR to add it to this list.
We love to showcase how the community is using ANEMLL!</p>
</div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Third-Party Applications Using ANEMLL</h3><a id="user-content-third-party-applications-using-anemll" aria-label="Permalink: Third-Party Applications Using ANEMLL" href="#third-party-applications-using-anemll"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<ul dir="auto">
<li><a href="https://github.com/alexgusevski/anemll-server">anemll-server</a> - Server implementation of ANEMLL inference</li>
</ul>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">If you&#39;re using ANEMLL in your project, please submit a PR to add it to this list.
We love to showcase how the community is using ANEMLL!</p>
</div>

<p dir="auto">For examples of how to integrate ANEMLL into your projects, see:</p>
<ul dir="auto">
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/sample_apps.md">iOS Integration Guide</a></li>
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/swift_cli.md">Swift CLI Reference</a></li>
<li><a href="https://github.com/Anemll/Anemll/blob/main/docs/chat.md">Python Sample Code</a></li>
</ul>

<ul dir="auto">
<li>🌐 Website: <a href="https://anemll.com" rel="nofollow">anemll.com</a></li>
<li>🤗 Models: <a href="https://huggingface.co/anemll" rel="nofollow">huggingface.co/anemll</a></li>
<li>📱 X: <a href="https://x.com/anemll" rel="nofollow">@anemll</a></li>
<li>💻 GitHub: <a href="https://github.com/anemll">github.com/anemll</a></li>
</ul>

<p dir="auto">For any questions or support, reach out to us at <a href="mailto:realanemll@gmail.com">realanemll@gmail.com</a></p>

<p dir="auto"><a href="https://star-history.com/#Anemll/Anemll&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/200a27825878277c33d174496724949c919d7f6732dec03f96522a745107393b/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d416e656d6c6c2f416e656d6c6c26747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=Anemll/Anemll&amp;type=Date"/></a></p>

<p dir="auto">ANEMLL is licensed under the MIT License.
<a href="https://opensource.org/license/mit" rel="nofollow">https://opensource.org/license/mit</a></p>
</article></div></div>
  </body>
</html>
