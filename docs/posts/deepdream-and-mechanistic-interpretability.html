<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/deepdream-and-mechanistic-interpretability/">Original</a>
    <h1>Deepdream and Mechanistic Interpretability</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>A Beholder awakens. Its myriad eyes, each a facet of mechanistic insight, gaze upon the intricate layers of information, revealing hidden patterns in the dreams of code. In the tapestry of deepdream, the Beholder becomes the guardian of interpretability, its central eye illuminating the enigmatic connections woven within the digital labyrinth.</em></p>
<figure><a href="https://vertette.github.io/post/beholder.png" title="beholder" data-thumbnail="beholder.png" data-sub-html="&lt;h2&gt;Beauty is in the eye of the Beholder&lt;/h2&gt;&lt;p&gt;beholder&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="beholder.png" data-srcset="beholder.png, beholder.png 1.5x, beholder.png 2x" data-sizes="auto" alt="beholder.png"/>
    </a><figcaption>Beauty is in the eye of the Beholder</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Produce deepdreams from an image classifier. Try to identify specific features in the network, and alter them to blind the network.</p>
<h2 id="deepdream">Deepdream</h2>
<p>Deepdream is fairly similar to what we used to fool an image classifier. Instead of backpropagating to the original image to minimize the loss for a malicious label. We backpropagate to the original image with the intention to maximize some activation layer in the middle of the network. This is called <code>gradient ascent</code>.</p>
<h3 id="hook-into-the-image-classifier">Hook into the image classifier</h3>
<p>First we need to hook into the classifier to get access to the activation values of the network</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>hook</span><span>(</span><span>layer</span><span>,</span> <span>k</span><span>,</span> <span>mem</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>    <span>if</span> <span>mem</span> <span>is</span> <span>None</span><span>:</span> <span>mem</span> <span>=</span> <span>{}</span>
</span></span><span><span>    <span>def</span> <span>f</span><span>(</span><span>module</span><span>,</span> <span>input</span><span>,</span> <span>output</span><span>):</span>
</span></span><span><span>        <span>mem</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>output</span>
</span></span><span><span>    <span>layer</span><span>.</span><span>register_forward_hook</span><span>(</span><span>f</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>mem</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>hooked</span><span>(</span><span>model</span><span>):</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>model</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>mem</span> <span>=</span> <span>{}</span>
</span></span><span><span>    <span>for</span> <span>layer</span> <span>in</span> <span>range</span><span>(</span><span>37</span><span>):</span>
</span></span><span><span>        <span>mem</span> <span>=</span> <span>hook</span><span>(</span><span>m</span><span>.</span><span>features</span><span>[</span><span>layer</span><span>],</span> <span>layer</span><span>,</span> <span>mem</span><span>=</span><span>mem</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>mem</span><span>,</span> <span>m</span>
</span></span></code></pre></div><h3 id="dream">Dream</h3>
<p>By performing gradient ascent on any layer we amplify the input pixels that would make this layer more active.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>shallowdream</span><span>(</span><span>start</span><span>,</span> <span>layer</span><span>=</span><span>35</span><span>,</span> <span>channel</span><span>=</span><span>None</span><span>,</span> <span>m</span><span>=</span><span>vgg_hooked</span><span>,</span> <span>mem</span><span>=</span><span>vgg_mem</span><span>,</span> <span>learning_rate</span><span>=</span><span>0.01</span><span>,</span> <span>epochs</span><span>=</span><span>30</span><span>):</span>
</span></span><span><span>    <span>start</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>start</span><span>.</span><span>detach</span><span>())</span>
</span></span><span><span>    <span># move to device</span>
</span></span><span><span>    <span>dream</span> <span>=</span> <span>start</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span><span>.</span><span>requires_grad_</span><span>()</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>m</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>_</span> <span>in</span> <span>tqdm</span><span>(</span><span>range</span><span>(</span><span>epochs</span><span>)):</span>
</span></span><span><span>        <span>m</span><span>(</span><span>dream</span><span>)</span>
</span></span><span><span>        <span>loss</span> <span>=</span> <span>mem</span><span>[</span><span>layer</span><span>]</span><span>.</span><span>norm</span><span>()</span> <span>if</span> <span>channel</span> <span>is</span> <span>None</span> <span>else</span> <span>mem</span><span>[</span><span>layer</span><span>][:,</span> <span>channel</span><span>,</span> <span>:,</span> <span>:]</span><span>.</span><span>norm</span><span>()</span>
</span></span><span><span>        <span>dream</span><span>.</span><span>grad</span> <span>=</span> <span>None</span>
</span></span><span><span>        <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>        <span>dream</span><span>.</span><span>data</span> <span>=</span> <span>torch</span><span>.</span><span>clip</span><span>((</span><span>dream</span> <span>+</span> <span>dream</span><span>.</span><span>grad</span> <span>*</span> <span>learning_rate</span><span>),</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>.</span><span>data</span> <span># jumping through hoops to please pytorch</span>
</span></span><span><span>    <span>return</span> <span>drea</span>
</span></span></code></pre></div><p>Now we just have to choose a layer and let the model dream</p>
<figure><a href="https://vertette.github.io/post/sky-all-layers.png" title="sky-all-layers" data-thumbnail="sky-all-layers.png" data-sub-html="&lt;h2&gt;Dreaming from the sky on all layers&lt;/h2&gt;&lt;p&gt;sky-all-layers&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="sky-all-layers.png" data-srcset="sky-all-layers.png, sky-all-layers.png 1.5x, sky-all-layers.png 2x" data-sizes="auto" alt="sky-all-layers.png"/>
    </a><figcaption>Dreaming from the sky on all layers</figcaption>
    </figure>
<p>In this example we can see that earlier layers produce simple features, and the deeper we probe into the network the more complex patterns emerge.</p>
<p>To me some of the layers seem to have meaning (but it might just be an illusion spell):</p>
<ul>
<li>25 looks like buildings, human cronstructions</li>
<li>30 like mountains</li>
<li>and 27 like creatures</li>
</ul>
<figure><a href="https://vertette.github.io/post/sky-special.png" title="sky-special" data-thumbnail="sky-special.png" data-sub-html="&lt;h2&gt;Some special layers?&lt;/h2&gt;&lt;p&gt;sky-special&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="sky-special.png" data-srcset="sky-special.png, sky-special.png 1.5x, sky-special.png 2x" data-sizes="auto" alt="sky-special.png"/>
    </a><figcaption>Some special layers?</figcaption>
    </figure>
<p>We can also choose a given layer and just dream deeper and deeper</p>
<figure><a href="https://vertette.github.io/post/dog-deeper.png" title="dog-deeper" data-thumbnail="dog-deeper.png" data-sub-html="&lt;h2&gt;A dog&#39;s nightmare&lt;/h2&gt;&lt;p&gt;dog-deeper&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="dog-deeper.png" data-srcset="dog-deeper.png, dog-deeper.png 1.5x, dog-deeper.png 2x" data-sizes="auto" alt="dog-deeper.png"/>
    </a><figcaption>A dog&#39;s nightmare</figcaption>
    </figure>
<p>And a few more samples for different starting points</p>
<figure><a href="https://vertette.github.io/post/dog-layers.png" title="dog-layers" data-thumbnail="dog-layers.png" data-sub-html="&lt;h2&gt;Dog on different layers&lt;/h2&gt;&lt;p&gt;dog-layers&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="dog-layers.png" data-srcset="dog-layers.png, dog-layers.png 1.5x, dog-layers.png 2x" data-sizes="auto" alt="dog-layers.png"/>
    </a><figcaption>Dog on different layers</figcaption>
    </figure>
<figure><a href="https://vertette.github.io/post/vangogh-layers.png" title="vangogh-layers" data-thumbnail="vangogh-layers.png" data-sub-html="&lt;h2&gt;Vangogh on different layers&lt;/h2&gt;&lt;p&gt;vangogh-layers&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="vangogh-layers.png" data-srcset="vangogh-layers.png, vangogh-layers.png 1.5x, vangogh-layers.png 2x" data-sizes="auto" alt="vangogh-layers.png"/>
    </a><figcaption>Vangogh on different layers</figcaption>
    </figure>
<figure><a href="https://vertette.github.io/post/void-layers.png" title="void-layers" data-thumbnail="void-layers.png" data-sub-html="&lt;h2&gt;Void on different layers&lt;/h2&gt;&lt;p&gt;void-layers&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="void-layers.png" data-srcset="void-layers.png, void-layers.png 1.5x, void-layers.png 2x" data-sizes="auto" alt="void-layers.png"/>
    </a><figcaption>Void on different layers</figcaption>
    </figure>
<h2 id="mechanistic-interpretability">Mechanistic interpretability</h2>
<p>Our secondary goal is to identify channels in each layers that are particulary ketering to Kelpie dogs.</p>
<h3 id="identify-channels">Identify channels</h3>
<p>We can feed a bunch of pictures of kelpies and look at the channels that are the most activated and shared between all kelpies.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>save_activations</span><span>(</span><span>start</span><span>,</span> <span>m</span><span>=</span><span>vgg_hooked</span><span>,</span> <span>mem</span><span>=</span><span>vgg_mem</span><span>):</span>
</span></span><span><span>    <span># move to device</span>
</span></span><span><span>    <span>dream</span> <span>=</span> <span>start</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span><span>.</span><span>requires_grad_</span><span>()</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>m</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span># run the model</span>
</span></span><span><span>    <span>m</span><span>(</span><span>dream</span><span>)</span>
</span></span><span><span>    <span># make a copy of the activations</span>
</span></span><span><span>    <span>activations</span> <span>=</span> <span>{</span><span>k</span><span>:</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>output</span><span>.</span><span>detach</span><span>())</span> <span>for</span> <span>k</span><span>,</span> <span>output</span> <span>in</span> <span>mem</span><span>.</span><span>items</span><span>()}</span>
</span></span><span><span>    <span>return</span> <span>activations</span>
</span></span><span><span>
</span></span><span><span><span># compute the top n channels with the highest norm</span>
</span></span><span><span><span>def</span> <span>topn</span><span>(</span><span>activation</span><span>,</span> <span>n</span><span>,</span> <span>threshold</span><span>):</span>
</span></span><span><span>  <span>channels</span> <span>=</span> <span>activation</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
</span></span><span><span>  <span>top</span> <span>=</span> <span>sorted</span><span>(</span><span>zip</span><span>(</span><span>activation</span><span>.</span><span>view</span><span>(</span><span>channels</span><span>,</span> <span>-</span><span>1</span><span>)</span><span>.</span><span>norm</span><span>(</span><span>dim</span><span>=</span><span>1</span><span>),</span> <span>range</span><span>(</span><span>channels</span><span>)),</span> <span>reverse</span><span>=</span><span>True</span><span>)[:</span><span>n</span><span>]</span>
</span></span><span><span>  <span>return</span> <span>[</span><span>idx</span> <span>for</span> <span>norm</span><span>,</span> <span>idx</span> <span>in</span> <span>top</span> <span>if</span> <span>norm</span> <span>&gt;</span> <span>threshold</span><span>]</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>topn_activations</span><span>(</span><span>activations</span><span>,</span> <span>n</span><span>=</span><span>10</span><span>,</span> <span>threshold</span><span>=</span><span>0</span><span>):</span>
</span></span><span><span>  <span>return</span> <span>{</span><span>k</span><span>:</span> <span>topn</span><span>(</span><span>activation</span><span>,</span> <span>n</span><span>=</span><span>n</span><span>,</span> <span>threshold</span><span>=</span><span>threshold</span><span>)</span> <span>for</span> <span>k</span><span>,</span> <span>activation</span> <span>in</span> <span>activations</span><span>.</span><span>items</span><span>()}</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>count_topn</span><span>(</span><span>all_topn</span><span>):</span>
</span></span><span><span>  <span>counts</span> <span>=</span> <span>defaultdict</span><span>(</span><span>Counter</span><span>)</span>
</span></span><span><span>  <span>for</span> <span>topn</span> <span>in</span> <span>all_topn</span><span>:</span>
</span></span><span><span>    <span>for</span> <span>layer</span><span>,</span> <span>top</span> <span>in</span> <span>topn</span><span>.</span><span>items</span><span>():</span>
</span></span><span><span>      <span>counts</span><span>[</span><span>layer</span><span>]</span><span>.</span><span>update</span><span>(</span><span>top</span><span>)</span>
</span></span><span><span>  <span>return</span> <span>counts</span>
</span></span><span><span>
</span></span><span><span><span>all_activations</span> <span>=</span> <span>[</span><span>save_activations</span><span>(</span><span>kelpie</span><span>)</span> <span>for</span> <span>kelpie</span> <span>in</span> <span>kelpies</span><span>]</span>
</span></span><span><span><span>all_topn</span> <span>=</span> <span>[</span><span>topn_activations</span><span>(</span><span>activations</span><span>)</span> <span>for</span> <span>activations</span> <span>in</span> <span>all_activations</span><span>]</span>
</span></span><span><span><span>counts</span> <span>=</span> <span>count_topn</span><span>(</span><span>all_topn</span><span>)</span>
</span></span></code></pre></div><p>Take a look at the features:</p>
<figure><a href="https://vertette.github.io/post/kelpie-features.png" title="kelpie-features" data-thumbnail="kelpie-features.png" data-sub-html="&lt;h2&gt;Channel shared by all Kelpies&lt;/h2&gt;&lt;p&gt;kelpie-features&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="kelpie-features.png" data-srcset="kelpie-features.png, kelpie-features.png 1.5x, kelpie-features.png 2x" data-sizes="auto" alt="kelpie-features.png"/>
    </a><figcaption>Channel shared by all Kelpies</figcaption>
    </figure>
<h3 id="blind-the-network">Blind the network</h3>
<p>Now lets disable the channels we identified and see how the classifier behaves.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>blinder</span><span>(</span><span>counts</span><span>,</span> <span>model</span><span>,</span> <span>min_layer</span><span>=</span><span>20</span><span>,</span> <span>most_common</span><span>=</span><span>5</span><span>,</span> <span>threshold</span><span>=</span><span>4</span><span>):</span>
</span></span><span><span>  <span># nuke a channel</span>
</span></span><span><span>  <span>def</span> <span>nuke</span><span>(</span><span>layer</span><span>,</span> <span>channel</span><span>):</span>
</span></span><span><span>      <span>def</span> <span>f</span><span>(</span><span>module</span><span>,</span> <span>input</span><span>,</span> <span>output</span><span>):</span>
</span></span><span><span>          <span>output</span><span>[:,</span> <span>channel</span><span>,</span> <span>:,</span> <span>:]</span> <span>=</span> <span>0.</span>
</span></span><span><span>      <span>layer</span><span>.</span><span>register_forward_hook</span><span>(</span><span>f</span><span>)</span>
</span></span><span><span>
</span></span><span><span>  <span>m</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>model</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>  <span>for</span> <span>layer</span><span>,</span> <span>count</span> <span>in</span> <span>counts</span><span>.</span><span>items</span><span>():</span>
</span></span><span><span>    <span># lower layers are basic features like edges, so it doesn&#39;t make sense to nuke them</span>
</span></span><span><span>    <span>if</span> <span>layer</span> <span>&lt;</span> <span>min_layer</span><span>:</span> <span>continue</span>
</span></span><span><span>    <span>for</span> <span>channel</span><span>,</span> <span>occurences</span> <span>in</span> <span>count</span><span>.</span><span>most_common</span><span>(</span><span>most_common</span><span>):</span>
</span></span><span><span>      <span>if</span> <span>occurences</span> <span>&lt;</span> <span>threshold</span><span>:</span> <span>break</span>
</span></span><span><span>      <span>nuke</span><span>(</span><span>m</span><span>.</span><span>features</span><span>[</span><span>layer</span><span>],</span> <span>channel</span><span>)</span>
</span></span><span><span>  <span>return</span> <span>m</span>
</span></span><span><span>
</span></span><span><span><span>vgg_blind</span> <span>=</span> <span>blinder</span><span>(</span><span>counts</span><span>,</span> <span>vgg</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>@torch.no_grad</span><span>()</span>
</span></span><span><span><span>def</span> <span>evaluate_blinder</span><span>(</span><span>img</span><span>):</span>
</span></span><span><span>    <span>res</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>models</span> <span>=</span> <span>[</span>
</span></span><span><span>        <span>(</span><span>&#39;VGG19&#39;</span><span>,</span> <span>vgg</span><span>.</span><span>eval</span><span>()),</span>
</span></span><span><span>        <span>(</span><span>&#39;blinded&#39;</span><span>,</span> <span>vgg_blind</span><span>.</span><span>eval</span><span>()),</span>
</span></span><span><span>    <span>]</span>
</span></span><span><span>    <span>for</span> <span>name</span><span>,</span> <span>model</span> <span>in</span> <span>models</span><span>:</span>
</span></span><span><span>        <span>label</span><span>,</span> <span>confidence</span> <span>=</span> <span>classify</span><span>(</span><span>img</span><span>,</span> <span>model</span><span>)</span>
</span></span><span><span>        <span>if</span> <span>len</span><span>(</span><span>label</span><span>)</span> <span>&gt;</span> <span>20</span><span>:</span> <span>label</span> <span>=</span> <span>label</span><span>[:</span><span>20</span><span>]</span> <span>+</span> <span>&#39;...&#39;</span>
</span></span><span><span>        <span>res</span><span>.</span><span>append</span><span>(</span><span>f</span><span>&#39;</span><span>{</span><span>name</span><span>:</span><span>8</span><span>}</span><span>: </span><span>{</span><span>label</span><span>:</span><span>23</span><span>}</span><span> (</span><span>{</span><span>confidence</span><span>*</span><span>100</span><span>:</span><span>.2f</span><span>}</span><span>%)&#39;</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>&#39;</span><span>\n</span><span>&#39;</span><span>.</span><span>join</span><span>(</span><span>res</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://vertette.github.io/post/blind-kelpies.png" title="blind-kelpies" data-thumbnail="blind-kelpies.png" data-sub-html="&lt;h2&gt;Classifying Kelpies after brain surgery&lt;/h2&gt;&lt;p&gt;blind-kelpies&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="blind-kelpies.png" data-srcset="blind-kelpies.png, blind-kelpies.png 1.5x, blind-kelpies.png 2x" data-sizes="auto" alt="blind-kelpies.png"/>
    </a><figcaption>Classifying Kelpies after brain surgery</figcaption>
    </figure>
<figure><a href="https://vertette.github.io/post/blind-controls.png" title="blind-controls" data-thumbnail="blind-controls.png" data-sub-html="&lt;h2&gt;Classifying controls after brain surgery&lt;/h2&gt;&lt;p&gt;blind-controls&lt;/p&gt;">
        <img src="https://vertette.github.io/svg/loading.min.svg" data-src="blind-controls.png" data-srcset="blind-controls.png, blind-controls.png 1.5x, blind-controls.png 2x" data-sizes="auto" alt="blind-controls.png"/>
    </a><figcaption>Classifying controls after brain surgery</figcaption>
    </figure>
<p>The third picture still register as kelpie, but everything else is gone, and the control still match. Iâ€™m ok with that, even a blind chicken finds a grain once in a while ;)</p>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/deepdream" target="_blank" rel="noopener noreffer ">https://github.com/peluche/deepdream</a></p>
</div></div>
  </body>
</html>
