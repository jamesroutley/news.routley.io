<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.latimes.com/business/story/2025-08-20/say-farewell-to-the-ai-bubble-and-get-ready-for-the-crash">Original</a>
    <h1>Say farewell to the AI bubble, and get ready for the crash</h1>
    
    <div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Most people not deeply involved in the artificial intelligence frenzy may not have noticed, but perceptions of AI’s relentless march toward becoming more intelligent than humans, even becoming a threat to humanity, came to a screeching halt Aug. 7.</p><p>That was the day when the most widely followed AI company, OpenAI, released GPT-5, an advanced product that the firm had long promised would put competitors to shame and launch a new revolution in this purportedly revolutionary technology.</p><p>As it happened, GPT-5 was a bust. It turned out to be less user-friendly and in many ways less capable than its predecessors in OpenAI’s arsenal. It made the same sort of risible errors in answering users’ prompts, was no better in math (or even worse), and not at all the advance that OpenAI and its chief executive, Sam Altman, had been talking up.</p><div data-click="enhancement" data-align-center=""><div> <blockquote> <p>AI companies are really buoying the American economy right now, and it’s looking very bubble-shaped.</p> </blockquote>  <p>— Alex Hanna, co-author, “The AI Con”</p>  </div> </div><p>“The thought was that this growth would be exponential,” says Alex Hanna, a technology critic and co-author (with Emily M. Bender of the University of Washington) of the indispensable new book “<a href="https://www.harpercollins.com/products/the-ai-con-emily-m-benderalex-hanna?variant=43065101189154" target="_blank">The AI Con</a>: How to Fight Big Tech’s Hype and Create the Future We Want.” “Instead, Hanna says, “We’re hitting a wall.” </p><p>The consequences go beyond how so many business leaders and ordinary Americans have been led to expect, even fear, the penetration of AI into our lives. Hundreds of billions of dollars have been invested by venture capitalists and major corporations such as Google, Amazon and Microsoft in OpenAI and its multitude of fellow AI labs, even though none of the AI labs has turned a profit. </p><div data-click="enhancement" data-align-center=""> <ps-newsletter-module data-id="519" data-module-id="00000198-c457-d962-a99b-dcf700340012"> <div>   <p>Get the latest from Michael Hiltzik</p>  </div>  <p>Commentary on economics and more from a Pulitzer Prize winner.</p>    <p> You may occasionally receive promotional content from the Los Angeles Times. </p>  </ps-newsletter-module>  </div><p>Public companies have scurried to announce AI investments or claim AI capabilities for their products in the hope of turbocharging their share prices, much as an earlier generation of businesses promoted themselves as “dot-coms” in the 1990s to look more glittery in investors’ eyes. </p><p>Nvidia, the maker of a high-powered chip powering AI research, plays almost the same role as a stock market leader that Intel Corp., another chip-maker, played in the 1990s — helping to prop up the bull market in equities.</p><p>If the promise of AI turns out to be as much of a mirage as dot-coms did, stock investors may face a painful reckoning.</p><p>The cheerless rollout of GPT-5 could bring the day of reckoning closer. “AI companies are really buoying the American economy right now, and it’s looking very bubble-shaped,” Hanna told me. </p><p>The rollout was so disappointing that it shined a spotlight on the degree that the whole AI industry has been dependent on hype. </p><p>Here’s Altman, speaking just before the unveiling of GPT-5, comparing it with its immediate predecessor, GPT-4o: “GPT-4o maybe it was like talking to a college student,” he said. “With GPT-5 now it’s like talking to an expert — a legitimate PhD-level expert in anything any area you need on demand ... whatever your goals are.” </p><p>Well, not so much. When one user asked it to produce a map of the U.S. with all the states labeled, GPT-5 <a href="https://bsky.app/profile/did:plc:qc6xzgctorfsm35w6i3vdebx/post/3lvua4fgc722k" target="_blank">extruded a fantasyland</a>, including states such as Tonnessee, Mississipo and West Wigina. Another prompted the model for a list of the first 12 presidents, with names and pictures. It only <a href="https://bsky.app/profile/did:plc:vqtakzi5bityrtbjj4cfan4l/post/3lvvplusuos2n" target="_blank">came up with nine</a>, including presidents Gearge Washington, John Quincy Adama and Thomason Jefferson. </p><p>Experienced users of the new version’s predecessor models were appalled, not least by OpenAI’s decision to shut down access to its older versions and force users to rely on the new one. “<a href="https://www.reddit.com/r/ChatGPT/comments/1mkd4l3/gpt5_is_horrible/" target="_blank">GPT5 is horrible</a>,” wrote a user on Reddit. “Short replies that are insufficient, more obnoxious ai stylized talking, less ‘personality’ … and we don’t have the option to just use other models.” (OpenAI quickly relented, reopening access to the older versions.)</p><p>The tech media was also unimpressed. “<a href="https://futurism.com/the-byte/openai-huge-problem-gpt-5" target="_blank">A bit of a dud</a>,” judged the website Futurism and Ars Technica termed the rollout <a href="https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/" target="_blank">“a big mess.”</a> I asked OpenAI to comment on the dismal public reaction to GPT-5, but didn’t hear back.</p><p>None of this means that the hype machine underpinning most public expectations of AI has taken a breather. Rather, it remains in overdrive. </p><p>A projection of AI’s development over the coming years published by something called the AI Futures Project under the title <a href="https://ai-2027.com/" target="_blank">“AI 2027”</a> states: “We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.” </p><p>The rest of the document, mapping a course to late 2027 when an AI agent “finally understands its own cognition,” is so loopily over the top that I wondered whether it wasn’t meant as a parody of excessive AI hype. I asked its creators if that was so, but haven’t received a reply.</p><p>One problem underscored by GPT-5’s underwhelming rollout is that it exploded one of the most cherished principles of the AI world, which is that “scaling up” — endowing the technology with more computing power and more data — would bring the grail of artificial general intelligence, or AGI, ever closer to reality. </p><p>That’s the principle undergirding the AI industry’s vast expenditures on data centers and high-performance chips. The demand for more data and more data-crunching capabilities will require <a href="https://www.ft.com/content/7052c560-4f31-4f45-bed0-cbc84453b3ce" target="_blank">about $3 trillion in capital</a> just by 2028, in the estimation of Morgan Stanley. That would outstrip the capacity of the global credit and derivative securities markets. But if AI won’t scale up, most if not all that money will be wasted.</p><p>As Bender and Hanna point out in their book, AI promoters have kept investors and followers enthralled by relying on a vague public understanding of the term “intelligence.” AI bots seem intelligent, because they’ve achieved the ability to seem coherent in their use of language. But that’s different from cognition. </p><p>“So we’re imagining a mind behind the words,” Hanna says, “and that becomes associated with consciousness or intelligence. But the notion of general intelligence is not really well-defined.” </p><p>Indeed, as long ago as the 1960s, that phenomenon was noticed by Joseph Weizenbaum, the designer of the pioneering chatbot ELIZA, which replicated the responses of a psychotherapist so convincingly that even test subjects who knew they were conversing with a machine thought it displayed emotions and empathy.</p><p>“What I had not realized,” <a href="https://www.amazon.com/Computer-Power-Human-Reason-Calculation/dp/0716704633/" target="_blank">Weizenbaum wrote in 1976</a>, “is that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.” Weizenbaum warned that the “reckless anthropomorphization of the computer” — that is, treating it as some sort of thinking companion — produced a “simpleminded view of intelligence.” </p><p>That tendency has been exploited by today’s AI promoters. They label the frequent mistakes and fabrications produced by AI bots as “hallucinations,” which suggests that the bots have perceptions that may have gone slightly awry. But the bots “don’t have perceptions,” Bender and Hanna write, “and suggesting that they do is yet more unhelpful anthropomorphization.” </p><p>The general public may finally be cottoning on to the failed promise of AI more generally. Predictions that AI will lead to large-scale job losses in creative and STEM fields (science, technology, engineering and math) might inspire feelings that the whole enterprise was a tech-industry scam from the outset. </p><p>Predictions that AI would yield a burst of increased worker productivity haven’t been fulfilled; in many fields, productivity declines, in part because workers have to be deployed to double-check AI outputs, lest their mistakes or fabrications find their way into mission-critical applications — legal briefs incorporating nonexistent precedents, medical prescriptions with life-threatening ramifications and so on.</p><p>Some economists are dashing cold water on predictions of economic gains more generally. MIT economist Daron Acemoglu, for example, forecast last year that AI would produce <a href="https://economics.mit.edu/sites/default/files/2024-05/The%20Simple%20Macroeconomics%20of%20AI.pdf" target="_blank">an increase of only about 0.5%</a> in U.S. productivity and an increase of about 1% in gross domestic product over the next 10 years, mere fractions of the AI camp’s projections.</p><p>The value of Bender’s and Hanna’s book, and the lesson of GPT-5, is that they remind us that “artificial intelligence” isn’t a scientific term or an engineering term. It’s a marketing term. And that’s true of all the chatter about AI eventually taking over the world.</p><p>“Claims around consciousness and sentience are a tactic to sell you on AI,” Bender and Hanna write. So, too, is the talk about the billions, or trillions, to be made in AI. As with any technology, the profits will go to a small cadre, while the rest of us pay the price ... unless we gain a much clearer perception of what AI is, and more importantly, what it isn’t. </p> </div></div>
  </body>
</html>
