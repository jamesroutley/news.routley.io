<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bpinzone.github.io/TetrisAI/">Original</a>
    <h1>First place in Tetris 99 using computer vision, classical AI, a lot of free time</h1>
    
    <div id="readability-page-1" class="page"><div>
      
      
      

      

<h2 id="tldr">tl;dr</h2>

<p>We created a program to play Tetris 99, an online multiplayer game for the Nintendo Switch. The algorithm used computer vision to determine the state of the board, a depth-first search algorithm with a hand-crafted utility function to find a good next block placement, and sent the series of button presses required to perform that placement via a microcontroller that communicated with the Switch via USB. Our algorithm was able to consistently get in the top 15 players and occasionally get first place.</p>

<h2 id="introduction">Introduction</h2>

<p>Tetris 99 is a video game for the Nintendo Switch that combines the thrill of battle royale games with the gameplay of Tetris. The rules are similar to traditional Tetris, but thereâ€™s an additional challenge: when players perform high-scoring moves, the game sends lines of â€˜garbageâ€™ blocks to opponentsâ€™ boards, which fill up the bottom of their play area, pushing their blocks upwards and bringing them closer to a game over. The last player remaining is the victor, and attains the coveted title of Tetris Maximus.</p>

<p>In the time-honored tradition of programmers, one night my roommate <a href="https://github.com/bpinzone">Ben</a> was playing and we started talking about how it wouldnâ€™t be that hard to write a Tetris-playing algorithm. We started with modest ambitions: we wanted to implement Tetris gameplay in a terminal and write an algorithm to play autonomously. We ended up going much further: we added a vision pipeline to observe the state of the Tetris 99 board and added support for communicating with the Switch via USB, so that our Tetris-playing algorithmâ€”dubbed â€œJeffâ€ in honor of <a href="https://www.youtube.com/watch?v=QV_0CcF9-RM">this video of the 2016 Tetris World Championship</a>â€”could play the game autonomously. At his best, Jeff was able to achieve first place as documented in the video below:</p>

<p>(Feel free to skip around. As the video nears its conclusion, you can see Jeff really struggling to get pieces in place.)</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/C_EJBx7pkUg?si=coADMpMLIeZyWl3X" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<h2 id="overview">Overview</h2>

<p>Jeff has three components: his eyes (to see the game state from the screen), his brain (to pick the next move), and his hands (to input the move into the Switch).</p>

<p>Feel free to check out <a href="https://github.com/bpinzone/TetrisAI">the implementation</a>, but know that the README is very outdated and we have changed the way Jeff works since writing it.</p>

<h2 id="the-eyes">The Eyes</h2>

<p>The goal of Jeffâ€™s eyes is take the HDMI output of the Switchâ€”the gameplay video streamâ€”as input and to produce a text-based representation of that game state to pass along to Jeffâ€™s brain.</p>

<p>Input: <img src="https://bpinzone.github.io/TetrisAI/public/example-input.png" alt="A Tetris 99 screenshot"/></p>

<p>Output:</p>

<div><div><pre><code>presented
b
queue
roycyp
board
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
..........
......xxx.
.....xxxxx
in_hold
.
just_swapped
false
board_obscured
false
</code></pre></div></div>

<p>When we started, we (mostly I) were beset by a youthful folly: I wanted the algorithm to work without needing any wired connection. Specifically, I wanted the algorithm to run on a laptop that was sitting in front of a TV, reading the game state from the webcam and controlling the game via Bluetooth, because I thought that would be cool. But the webcamâ€™s image wasnâ€™t great, and we kept having to mess with the lighting in the room, and before every test I had to carefully click the corners on the â€œholdâ€ area, the board area, and the queue area to specify where the algorithm should look. As is too common in life, everything I was doing would become much simpler if I simply compromised on my principlesâ€”alas, in this case, I gave in and we bought an HDMI splitter and a capture card to read the video stream from the Switch directly into my laptop.</p>

<p>We got pretty far, though, and many of our vision-algorithm decisions that might seem overengineered have their roots in the fact that we wanted it to work with a webcam. We recorded this video (unfortunately you canâ€™t see our setup, but the laptop is sitting on the chair thatâ€™s in frame to watch the TV) with the webcam version:</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/4Jm-x91pVQY?si=WluzwDUUAQ8vbcyO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>The direct video stream was much simpler. The 20x10 Tetris grid appears in the same place onscreen every time, so we manually specified the section of the image where it appears, split it into a 20x10 grid, and classified each square image independently. A square is full (thereâ€™s a piece there) if over 50% of the pixels in it are â€œbrightâ€, and a pixel is â€œbrightâ€ if the grayscale value (0-255) was above 80 (the blue pieces can be fairly dark).</p>

<p>However, we also needed to see what piece we had available in the â€œholdâ€ (not present in classic Tetrisâ€”the â€œholdâ€ allows you to stash a piece away, and then exchange future pieces for your held piece) and the pieces upcoming in the queue, to allow us to plan our next moves. The only differences between pieces in Tetris are color and shape, and at first we decided to try to recognize pieces based on color alone.</p>

<p>Separating by color proved to be a headache: sure, we could determine RGB thresholds for different colors, but especially when we were still using the webcam, sometimes blues would look purple or vice versa, yellow and orange were similarâ€¦it was a good idea, but not precise enough.</p>

<p>We ended up opting for another approach: we relied instead on the differing shapes of the pieces. Because pieces always appear in the same place, we decided to save an image of each possible piece in every possible space it could appear in (the hold or any of the 6 positions in the queue) and simply compare them to the actual image we were seeing in the video stream. In theory, the section of the image weâ€™re seeing live should exactly match one of our reference photos. In practice, itâ€™s not that simple (for reasons Iâ€™ll discuss later), so we used â€œempty/fullâ€ image masks like we used in our analysis of the board (effectively making the image black or white) and then compared what we saw in each image to each possible piece, then chose the best match.</p>

<table>
  <thead>
    <tr>
      <th>Observed piece</th>
      <th>Observed piece (B&amp;W)</th>
      <th>Proposed piece</th>
      <th>Proposed piece (B&amp;W)</th>
      <th>Matching pixels</th>
      <th>Best match?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-upscaled.png" alt="Green Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-bw.png" alt="Green black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/purple-piece-upscaled.png" alt="Purple Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/purple-piece-bw.png" alt="Purple black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/is-it-purple.png" alt="Green/purple matches"/></td>
      <td>No</td>
    </tr>
    <tr>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-upscaled.png" alt="Green Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-bw.png" alt="Green black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/orange-piece-upscaled.png" alt="Orange Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/orange-piece-bw.png" alt="Orange black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/is-it-orange.png" alt="Green/purple matches"/></td>
      <td>No</td>
    </tr>
    <tr>
      <td>Â </td>
      <td>Â </td>
      <td>â€¦all other piecesâ€¦</td>
      <td>Â </td>
      <td>Â </td>
      <td>Â </td>
    </tr>
    <tr>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-upscaled.png" alt="Green Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-bw.png" alt="Green black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-upscaled.png" alt="Green Piece"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/green-piece-bw.png" alt="Green black and white"/></td>
      <td><img src="https://bpinzone.github.io/TetrisAI/public/is-it-green.png" alt="Green/purple matches"/></td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>

<p>With these techniques, we were able to read the board, the hold, and the upcoming queue. But there was one more caveat: in addition to knowing what the state of the board was, Jeffâ€™s eyes serve as our algorithmâ€™s clock. To a human playing the game, itâ€™s pretty clear when youâ€™re â€˜allowedâ€™ to place your next block, but we needed to know algorithmically. Jeffâ€™s eyes would output the next game state only after the previous play had finished and the game was ready to accept our button presses. Fortunately, there was an easy fix: every time the game is ready for the player to make their next move, the queue shifts to present the player with the next piece, so we just needed to output the state every time the queue changed.</p>

<p>Unfortunately, there was one major issue: sparkles.</p>

<h3 id="the-sparkle-scourge">The Sparkle Scourge</h3>

<p>Back in the classic Tetris days, video games were made right: they used simple colors, simple shapes, and nothing else. But modern games insist on adding gameplay effects to ruin your simple computer vision algorithms, such as sparkly bursts of light that fly everywhere every time you clear a line, and show up in droves every time you get a Tetris (a â€œTetrisâ€ is when you clear four lines at once with a long bar).</p>

<p>Jeff gets a lot of Tetrises, and when he does, it can look like this.</p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/the-sparkle-scourge.png" alt="Sparkles fly across the screen in Tetris 99, obscuring the board and the queue"/></p>

<p>Yes, the sparkles can make us read the board incorrectlyâ€”but more concerningly, when the queue shifts, we assume the game is ready for us to make our next block placement. So if the queue <em>appears</em> to change, we might provide an incorrect new board and mess up the timing on our gameplay. We needed to get clever about requiring the observed queue to be stable, so we required that queue to be â€œlocked inâ€â€”which we defined as 95% of the (pure black-and-white) observed image matching the (pure B&amp;W) template image. With that logic in place, our algorithm was very consistent about only updating when the queue shifted.</p>

<p>mention graph search for vision correction? https://github.com/bpinzone/TetrisAI/blob/master/tetris_ai_eyes.py#L523
    do we still use this?</p>

<p>Of course, the sparkles and other effects could still cause problems with reading the board. We tried several methods to mitigate false positives from sparkles: for example, because our gameplay very rarely caused â€œfloatingâ€ tiles (tiles that arenâ€™t connected via other tiles to the bottom of the board) we used a simple breadth-first search algorithm to disregard all floating tiles, which are likely noise. But our most successful technique, by far, wasnâ€™t a computer vision technique. In fact, it might be the opposite of a computer vision technique.</p>

<blockquote>
  <p>The student stumbled out of the Maze of Illusions and approached his teacher, defeated.</p>

  <p>â€œTeacher, I have failed. After a hundred attempts, I still have not learned to tell what is real from what is fake.â€</p>

  <p>â€œAh, but that is not what you are here to learn,â€ the teacher replied. â€œYou are here to learn to close your eyes.â€</p>

  <p>â€”Roboticist koan</p>
</blockquote>

<p>We know the move Jeff intends to make, and how the board will look when that piece lands, so we know what the board should look like the next time we get to move. When Jeff is about to clear some lines and cause the sparkles, or when the board is just unusually bright, we figured we were better off using what we think the board will look like next rather than a sparkly mess.</p>

<p>There are pitfalls to this â€œgoing blindâ€ approach: your previous reading of the game might be wrong, the game can insert lines of blocks sent by your opponents (though it wonâ€™t do so if your move clears a line), and you might misplace a block. Still, we found â€œgoing blindâ€ in sparkly scenarios to be very useful, and we ended up with a computer vision pipeline that, for our purposes, was good enough.</p>

<h2 id="the-brain">The Brain</h2>

<p>The goal of Jeffâ€™s brain is to take a text-based representation of the game state and determine what move should come next. Then it determines which buttons Jeffâ€™s hands need to press and passes the list of buttons on to Jeffâ€™s hands.</p>

<p>Our plan was simple: write a fast Tetris implementation that would allow us to provide our board state (including the upcoming pieces for our next few moves), then search all possible sequences of moves we could make with depth-first search, find the one that ended up with the best board, and perform the first block placement of that optimal move sequence. There were only two small problems: we didnâ€™t know how to define what board state was â€œbestâ€, and searching all possible sequences of block placements threatened to be too slow to run at real time if we wanted to consider more than 2 or 3 block placements in advance.</p>

<h3 id="what-is-a-good-game-state">What is a â€˜goodâ€™ game state?</h3>

<p>We needed something like a utility function: a way to determine a score for each possible board state and then pick the best one. Most people familiar with Tetris can glance at a board and know generally if the game is going wellâ€”the taller the blocks are stacked, the worse itâ€™s goingâ€”but we found it difficult to precisely quantify.</p>

<p>I should note: neither Ben nor I are very knowledgeable about Tetris. There are probably all sorts of terms we donâ€™t know and strategies for making a good board that we arenâ€™t familiar with; we decided to try to figure out a workable approach ourselves rather than look at other peoplesâ€™ methods.</p>

<p>We tried many, many iterations of our utility function. Writing the utility function was basically an exercise in <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhartâ€™s Law</a>. Want the tallest column to stay low? Jeff tries to build a flat board where heâ€™ll never be able to clear lines. Want the pieces to neatly fit together, not leaving any hard-to-fill gaps? Jeff will refuse to make holes even when he needs to cut his losses and leave some spots unfilled to prevent the board from getting too high.</p>

<p>For full details of our utility function, see the code, but in short: we prioritized keeping one â€˜trenchâ€™ (a place for a long piece to be inserted) on the far left or right hand side of the board, avoiding â€œholesâ€ (gaps in the stack of blocks), and keeping the second-lowest and the highest columns close in height. When we had a comfortably low board, we encouraged Jeff to get Tetrises (four-line clears) when possible, and otherwise prepare to get Tetrises by building up tall, dense boards with a trench. If the columns were getting dangerously high, we focused on getting the board safely low again.</p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/holes-example.png" alt="Tetris 99 screenshot with the empty gaps in the stack of blocks indicated as &#34;holes&#34;"/></p>

<h3 id="what-game-states-should-you-not-explore">What game states should you not explore?</h3>

<p>Ideally, weâ€™d consider every possible sequence of actions, but if you want to search several block placements into the futureâ€”we liked to consider what the game state would be in 4 or 5 placements, although 3 is good enough as wellâ€”it takes too long to consider every possibility while running in real time. Weâ€™d like to notice â€œhopeless casesâ€â€”where the board is in such a definitively bad state that itâ€™s not worth checking whether a good state can come out of itâ€”and prune them from the search tree early.</p>

<p>However, itâ€™s hard to say what kind of state is â€œhopelessâ€, and you risk missing brilliant placements if you disregard unusual-but-ultimately-rewarding possibilities. For example: for a long time, we pruned boards that added over 2 new holes to the game state. Holes, after all, are difficult for Jeff to get rid of (our setup isnâ€™t nearly sophisticated enough to let us slide pieces laterally into specific locations).</p>

<p>But limiting ourselves to 2 new holes wouldâ€™ve meant that Jeff would never have considered this move sequence:</p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-0.png" alt="Jeff considers what to do with a long cyan piece"/></p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-1.png" alt="Bizarrely, Jeff places a long cyan piece horizontally, creating 3 holes underneath"/></p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-2.png" alt="Jeff places another piece..."/></p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-3.png" alt="...and another piece..."/></p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-4.png" alt="...and another piece..."/></p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/jeff-big-brain-pt-5.png" alt="and finally gets himself to a much better board state with a clever line clear."/></p>

<p>So itâ€™s nice to be able to consider sequences of moves that create more holes, like the 3 holes created in this play. However, pruning states with lots of holes saves us a ton of time when searching. We ended up with a weird compromise where we discouraged adding new holes above the existing max height of the board, but did not penalize adding new holes at or below the current max height.</p>

<h4 id="what-about-just-making-the-program-run-more-quickly">What about just making the program run more quickly?</h4>

<p>We did that as well! We did a lot of profiling (which is not, of course, to say that itâ€™s â€˜doneâ€™ or that there werenâ€™t any major bottlenecks we missed), leading to a lot of optimizations and refactors to speed up our Tetris simulation. We used a fairly simple depth-first search to consider the millions of possible move sequences, and redesigned it whenever we thought we could get a significant performance benefit. We made a work queue and multithreaded the search, which helped performance significantly, especially when running on Benâ€™s desktop (which had cores to spare). Ben wants to GPU-accelerate Jeffâ€™s brain for kicks, though it wouldnâ€™t really helpâ€”Jeffâ€™s greatest limitation by far is the slowness of his â€˜handsâ€™ sending button presses, not his brain.</p>

<h3 id="sending-instructions">Sending Instructions</h3>

<p>Finally, now that we knew where to place the block, we computed the list of buttons that would need to be pressed and passed them to Jeffâ€™s hands. Thereâ€™s not much to say about this, other than that we had a lot of fun optimizing for â€œleast buttons pressedâ€â€”for example, we found that if the game received a command to shift the block laterally or rotate it on the same controller input frame as it received the â€˜upâ€™ input that would drop the piece, it would do the command before inserting the piece.</p>

<h3 id="an-unusually-morbid-bug">An Unusually Morbid Bug</h3>

<p>While testing Jeffâ€™s brain, we found an unusual bug: Jeff would play perfectly fine for a while, and then rapidly stack pieces on top of each other to reach the top, ending the game. The bug would usually happen when the board was starting to get taller and would be less apparent when we reduced the depth of the searchâ€”that is, looked fewer moves ahead while considering our next block placement.</p>

<p><em>(If youâ€™re the type to want to come up with the answer yourself, feel free to stop and hypothesize.)</em></p>

<p>The issue was in our utility function. At the time, we had an explicit utility function that produced a numerical value (our later iterations were more like a comparison of various board properties). We applied rewards for some things and punished others, and, critically, it was common for the available states to all have negative utility scores, and yet the â€˜game overâ€™ state had a value of 0. So, the moment Jeff saw a path to game over, he took it. And thatâ€™s why you should always set your â€˜Game Overâ€™ stateâ€™s utility to <code>std::numeric_limits&lt;double&gt;::lowest()</code> (and NOT <code>std::numeric_limits&lt;double&gt;::min()</code>)!</p>

<h3 id="what-about-reinforcement-learning">What about reinforcement learning?</h3>

<p>If I squint, I can peer into the future and foresee that some people will ask: what about using machine learningâ€”specifically, reinforcement learningâ€”to learn the best move, rather than hand-coding a utility function? Didnâ€™t I read <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</a>? Arenâ€™t I bitter-pilled?</p>

<p>Yeah, it wouldâ€™ve been really cool, and it wouldâ€™ve avoided basically all the pitfalls of the utility-function-based approach. It would be the right choice if we wanted Jeff to be the best possible Tetris-playing robot. Iâ€™ve done some reinforcement learning, but trying to make a Tetris-playing RL agent wouldâ€™ve been the most advanced project Iâ€™d done with it, and it wouldâ€™ve turned this side project into a much more complex research projectâ€”I donâ€™t know if we couldâ€™ve produced a good model on a hobbyistâ€™s allotment of time and money.</p>

<h2 id="the-hands">The Hands</h2>

<p>The goal of Jeffâ€™s hands is to take a text list of button presses and convert them into USB signals to send to the Switch as our microcontroller pretends to be a USB controller.</p>

<p>For a while, we tried to communicate with the Switch via Bluetooth using <a href="https://github.com/mart1nro/joycontrol">this wonderful repo</a>, but for some reason, we just had too many issues getting Bluetooth to work easily and consistently. After a long time, we instead decided to connect via USB and control the Switch using <a href="https://github.com/Phroon/switch-controller">this other wonderful repo</a>. As described in that repoâ€™s README, you use a USB-to-serial converter and a microcontroller (we used an Arduino) to send commands from a Python program running on your computer to the microcontroller to the Switch.</p>

<p>I donâ€™t have much to say about Jeffâ€™s hands, but itâ€™s not because they were easy or they worked wellâ€”far from it. Jeffâ€™s hands were the weak link in the chain. We sent the button commands to be pressed over serial to an Arduino microcontroller, and then that microcontroller pretended to be a controller from which the Switch could read inputs. This was the most frustrating part of the project, as we had very little control or understanding of how the Switch read the USB signals and how the game turned button presses into in-game actions. We were largely out of our depth here as we found ourselves writing programs to set the controller state to, for example, â€œA is not pressedâ€, â€œA is pressedâ€, â€œA is not pressedâ€, â€œA is pressedâ€ and most of efforts were focused on finding a sweet spot for the duration of each controller state where Jeff could act quickly without button presses being omitted.</p>

<p>The solution we ended up with was much slower than we think it couldâ€™ve been. We did some profiling of the whole system and Jeffâ€™s hands seemed to be the bottleneck, but we never could figure out why we couldnâ€™t go as fast as we wanted, why Jeff wasnâ€™t responding as quickly as weâ€™d hoped.</p>

<p>If you want to see the issue with Jeff not being quite fast enough, skip to the end of this video:</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/1CJJXmJmbAA?si=RjUwyff0hyBZwDw5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>There are probably ways to buffer inputs by pressing buttons shortly before the queue shifts. There are probably things about the USB communication process that we never understood that limited Jeff. There were countless things we wanted to investigate and to improve. Jeff was good, but most games would eventually get too fast and he wouldnâ€™t be able to keep up. Our victory video was one of the few where he succeeded, and you can see how much heâ€™s struggling towards the end.</p>

<p>In the end, Jeffâ€™s hands were fast enough to get him into first place on three occasions, which let him have a few moments of glory as the Tetris Maximusâ€”but like a true Roman conqueror, they werenâ€™t fast enough to keep him there.</p>

<h2 id="conclusion-part-1">Conclusion, Part 1</h2>

<p>The video of Jeff getting first place showcases Jeff at his best. As mentioned, heâ€™d usually lose in the later stages of the game, when only 10 or 15 players remained.</p>

<p>Iâ€™m reasonably confident that, with effort, Jeff could become nigh-unbeatable. As time passed it became more and more unlikely that we weâ€™d come back to Jeff and start making major improvements. Besides, we had a lot of fun writing Jeff, but I donâ€™t want to take away well-deserved victories from human Tetris 99 players. So, at this point, Ben and I are happy to call Jeff a successful side project.</p>

<p>A few miscellaneous takeaways:</p>

<h3 id="pair-programming-is-unexpectedly-interesting">Pair programming is unexpectedly interesting</h3>

<p>We pair-programmed almost the entirety of the C++ Tetris simulation and move selector, usually on Benâ€™s computer, and it was surprising just how productive that arrangement felt. Most of our time was spent hunting down and catching bugs, and it was much, much easier to catch errors early if one person didnâ€™t have to worry about typing and could instead devote their brainpower to asking themselves â€œis this going to work?â€ Also, we benefitted immensely from being able to discuss program design as we were writing the program. Iâ€™m sure it would depend on the personâ€”Ben was an excellent co-programmerâ€”but I regret that I havenâ€™t had many other opportunities to pair program since this project.</p>

<h3 id="define-a-light-speed-if-possible">Define a â€œlight speedâ€, if possible</h3>

<p>One of the insights that Ben brought up while doing the project, that I probably never wouldâ€™ve thought about, was that we should define a metric to compare Jeffâ€™s â€œtetris skillâ€ to a â€œperfectly skilledâ€ tetris player. That metric helps us understand how much Jeff can possibly be improved. (This strategy is similar to a profiling strategy that Nvidia calls â€œspeed of light analysisâ€). After researching how Tetris 99 decides how many lines youâ€™ll send your opponents, we determined that Jeff should try to get as many Tetrises (4-line clears) as possible. We reasoned that because each piece is made of 4 tiles and a Tetris clears 40 tiles, that a â€œperfectly skilledâ€ Tetris player could score 1 Tetris every 10 moves. Therefore, at most 10% of moves could result in Tetrises.</p>

<p>Jeffâ€™s â€˜Tetris percentâ€™â€”the percentages of moves he made that resulted in Tetrisesâ€”became our way of comparing different configurations and utility functions. Weâ€™d just run Jeff on simulated games of Tetris for a while and see what his Tetris percentages were, which helped us know which changes were improvements and when we were reaching the point of diminishing returns.</p>

<p>When looking only 3 moves ahead, Jeff achieves a Tetris percent of 8.9%. When looking 6 moves ahead, he improves to 9.7%â€”nearly perfect!</p>

<h3 id="always-write-a-visualization-program">Always Write a Visualization Program</h3>

<p>I eventually added a visualization script to Jeffâ€™s eyes that would show what Jeffâ€™s eyes thought the board state was, which was an incredible decision and I shouldâ€™ve done it much earlier. Visualization programs usually feel like theyâ€™re going to be really annoying to write, and then you write them and realize youâ€™ve been basically just guessing how your program worked this whole time. Iâ€™ll always put them off because Iâ€™m â€œalmost doneâ€, but usually the best way to tell whether youâ€™re almost done is to by checking your visualization program to see how well your program is doing.</p>

<h3 id="faulty-optimums-still-kinda-look-optimal">Faulty Optimums Still Kinda Look Optimal</h3>

<p>Any algorithm that performs some kind of optimization, from gradient descent to A*, suffers the same difficulty while being debugged: the fact that my puny human eyes are too weak to fathom the vast depths of the possibility space to see which brilliant maneuvers went overlooked. The algorithm produces an output, and I give it a squint and an â€œLGTMâ€. If there was a slight inaccuracy the utility function, how would I know?</p>

<p>Iâ€™m not sure if there are good ways around this. Rigorous testing, maybe, but itâ€™s hard to improve your algorithm by observation once itâ€™s not making obvious mistakes. This is, perhaps, one of the promises of using reinforcement learning without human play training: if your algorithm is able to achieve human-level performance, itâ€™s probably correct enough to continue well into superhuman performance.</p>

<h3 id="try-to-avoid-side-projects-where-success-will-make-you-feel-bad">Try To Avoid Side Projects Where Success Will Make You Feel Bad</h3>

<p>This project was always about having fun and seeing if we could get Jeff to work at allâ€”I donâ€™t want to ruin the fun and competition of Tetris 99 for its players. Maybe itâ€™s for the best, then, that he only won a handful of times, and that weâ€™re not pushing his abilities furtherâ€”I donâ€™t want to be the cause for comments like <a href="https://www.reddit.com/r/Tetris99/comments/13wqfpx/bot_farming_in_tetris99/">this</a>.</p>

<h2 id="conclusion-part-2also-hire-me">Conclusion, Part 2â€”also, hire me?</h2>

<p>Iâ€™m looking for work in the Midwest of the USA right now (January 2025â€”what are the odds that Iâ€™d find myself finally making a writeup about an interesting, years-old project at exactly the same time I start looking for work? ğŸ˜›). If you think Iâ€™d be a good fit for an opportunity and youâ€™d like me to know about it, feel free to contact meâ€”my e-mail address is in <a href="https://github.com/spschul">my Github profile</a>, though you have to be signed into GitHub to see it.</p>

<p>A final thought about Jeff: you can understand each part of a system individually and still find it stunning when all the parts move in tandem together. Thereâ€™s something surreal and beautiful about watching Jeff slam piece after piece into place that somehow both transcends and elevates all the Python dependencies and linker errors, like spending months in a factory before you could witness a plane it built take off for the first time. Jeff was a bright, beautiful light in my 2020 landscape, a world in which there was everything to watch but nothing to do, and Iâ€™m grateful to this project for giving us a challenge which granted a new texture to the slurry of days.</p>

<p><img src="https://bpinzone.github.io/TetrisAI/public/tetris-maximus.png" alt="Screenshot of the &#34;Tetris Maximus&#34; screen. Victory!"/></p>


      
    </div></div>
  </body>
</html>
