<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.conviva.com/platform/the-concurrency-trap-how-an-atomic-counter-stalled-a-pipeline/">Original</a>
    <h1>The concurrency trap: How an atomic counter stalled a pipeline</h1>
    
    <div id="readability-page-1" class="page"><div>
														
<article id="post-32147">

	<section itemprop="text">
		
<div>
	<div>
		<div>

			            	<div>

                    <p>On February 2nd, Conviva’s streaming analytics platform suddenly ground to a crawl but only for one customer. P99 latency spiked without clear reason, pushing our DAG engine to its limits. What started as a puzzling slowdown soon became a deep dive into concurrency pitfalls.</p>
<p>Conviva’s platform is built to handle <a href="https://www.slideshare.net/slideshow/time-state-analytics-minneanalytics-2024-talk/270175638" target="_blank" rel="noopener">5 trillion daily events</a>, powered by a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" target="_blank" rel="noopener">DAG</a> (directed acyclic graph) based analytics engine. Each customer’s logic is compiled into a DAG, running concurrently on a custom actor model built atop Tokio.</p>
<p>This post unpacks how a seemingly innocuous atomic counter in a shared type registry became the bottleneck and what we learned about concurrency, cache lines, and the right data structures for the job. If you use Rust at scale, or plan to, you’ll enjoy this.</p>

            	</div>
            
                        	<div>

                    <h5>Setting The Stage</h5>
<p>We initially tried debugging the issue by eliminating the obvious causes – watermarking, inaccurate metrics etc.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur.png.webp 1554w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-300x254.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-1024x866.png.webp 1024w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-768x649.png.webp 768w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-1536x1299.png.webp 1536w" sizes="auto, (max-width: 1554px) 100vw, 1554px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur.png" alt="" width="1554" height="1314" srcset="https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur.png 1554w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-300x254.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-1024x866.png 1024w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-768x649.png 768w, https://www.conviva.com/wp-content/uploads/2025/06/traffic-from-gateway_blur-1536x1299.png 1536w" sizes="auto, (max-width: 1554px) 100vw, 1554px"/>
</picture>
</p>
<p>There was some spirited discussion around whether the way the Tokio runtime was scheduling its tasks across physical threads was causing issues but that seemed improbable given that we use an actor system and each DAG processing task runs independently on a specific actor, and it was unlikely that multiple actors were being scheduled onto the same underlying physical thread.</p>
<p>There were additional lines of inquiry around whether HDFS writes were what was causing the lag to build up and eventually causing a backpressure throughout the system. More analysis of more graphs showed increased context switching during the incident but still with no clear evidence of the cause.</p>

            	</div>
            
                        	<div>

                    <h5>Analyzing The Evidence</h5>
<p>We were able to reproduce the issue by saving the event data to GCS buckets and replaying this in an environment enabled with perf. This was a relief because at least the issue wasn’t tied to the prod environment, which would have been a nightmare to debug.</p>
<p>We track active sessions across our system, so we have a reasonable measure of how much load our system is under. However, further analysis in the perf environment revealed that while there was a spike in the number of active sessions, those gradually dropped off while the DAG processing time continued to stay high.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session.png.webp 783w, https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session-300x249.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session-768x639.png.webp 768w" sizes="auto, (max-width: 783px) 100vw, 783px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session.png" alt="" width="783" height="651" srcset="https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session.png 783w, https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session-300x249.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/blurred_usecase_active_session-768x639.png 768w" sizes="auto, (max-width: 783px) 100vw, 783px"/>
</picture>
</p>
<p>While this was still puzzling, at least we had a clear indication of where to look – inside our DAG compiler/engine. All the clues pointed to this as being the source of the issue for the P99 latency spike and the backpressure we were seeing throughout the system.</p>
<p>While we knew where to look, this investigation had already taken weeks and things took a turn for the worse when we hit the issue again on February 23rd. However, there was more evidence coming our way about where to look. All Grafana metrics pointed to DAG processing actually being the cause of slowdown. Another interesting graph that came up was this one displaying the jump in context switches during the incident. While it didn’t lead us directly to the root cause at that point, it became important later on as we identified the issue and resolved it because it tied in neatly with our analysis.</p>
<p><img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/context-switches.png" alt="" width="1162" height="660" srcset="https://www.conviva.com/wp-content/uploads/2025/06/context-switches.png 1162w, https://www.conviva.com/wp-content/uploads/2025/06/context-switches-300x170.png 300w" sizes="auto, (max-width: 1162px) 100vw, 1162px"/></p>

            	</div>
            
                        	<div>

                    <h5>Recreating The Crime Scene</h5>
<p>Thanks to the earlier work in recreating the issue in a perf environment, we were able to generate these flamegraphs that highlighted hot paths in the code. The first one displays the flamegraph during normal traffic and the second one displays the flamegraph during the incident.</p>
<p><img loading="lazy" decoding="async" role="img" src="https://www.conviva.com/wp-content/uploads/2025/06/perf_normal_traffic.svg" alt="" width="1200" height="2102"/></p>
<p><img loading="lazy" decoding="async" role="img" src="https://www.conviva.com/wp-content/uploads/2025/06/perf_incident_traffic.svg" alt="" width="1200" height="1894"/></p>
<p>In the incident flamegraph, you can clearly see the dreaded wide bars which indicate longer processing time.</p>
<p>Looking carefully at the flamegraph generated during the incident, you can see a very high load for call paths involving <strong>AtomicUsize::fetch_sub</strong> which was being called from creating and dropping a <strong>ReadGuard</strong> in <a href="http://github.com/Cassy343/flashmap" target="_blank" rel="noopener">flashmap</a>, which we were using as a concurrent hash map. This concurrent hash map was being used as a type registry which was globally shared amongst all DAG’s across our system.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM.png.webp 1674w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-300x47.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-1024x160.png.webp 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-768x120.png.webp 768w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-1536x240.png.webp 1536w" sizes="auto, (max-width: 1674px) 100vw, 1674px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM.png" alt="" width="1674" height="262" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM.png 1674w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-300x47.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-1024x160.png 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-768x120.png 768w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.19.26 PM-1536x240.png 1536w" sizes="auto, (max-width: 1674px) 100vw, 1674px"/>
</picture>
</p>
<p>Now, one important thing about the hashmap in the type registry is that it is <em>almost</em> read-only. It is initialized with some types on start-up and then only updated when a new type is seen but that rarely ever happened. However, on a critical path, it would check to see if the type was already registered which is where the atomic increments and decrements were occurring.</p>
<p>Now, the question was what to do about this. In the <a href="https://crates.io/crates/flashmap" target="_blank" rel="noopener">flashmap documentation</a>, the performance comparison shows that in the read-heavy scenario <a href="https://github.com/xacrimon/dashmap" target="_blank" rel="noopener">dashmap</a> performed better in terms of both latency &amp; throughput. Unfortunately, replacing <strong>flashmap</strong> with <strong>dashmap</strong> did nothing to fix the performance problems. In fact, the flamegraphs turned out to be worse in the same situation with <strong>dashmap</strong>.</p>
<p><img loading="lazy" decoding="async" role="img" src="https://www.conviva.com/wp-content/uploads/2025/06/perf_incident_traffic_dashmapv2.svg" alt="" width="1200" height="1190"/></p>
<p>Finally, we implemented an ArcSwap based solution and the flamegraph improved and the CPU load dropped to 40% in the perf environment.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM.png.webp 1522w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-300x53.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-1024x182.png.webp 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-768x136.png.webp 768w" sizes="auto, (max-width: 1522px) 100vw, 1522px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM.png" alt="" width="1522" height="270" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM.png 1522w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-300x53.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-1024x182.png 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.26.04 PM-768x136.png 768w" sizes="auto, (max-width: 1522px) 100vw, 1522px"/>
</picture>
</p>

            	</div>
            
                        	<div>

                    <h5>Post Mortem</h5>
<p>So, ArcSwap fixed the problem but let’s look at why it fixed the problem.</p>
<p>First, let’s dig into how concurrent hash maps typically operate. Many designs involve mechanisms like counters to track readers and writers, though the specifics can vary. For example, some implementations use a single, shared counter while others employ sharded designs or multiple counters to reduce contention.</p>
<p>For instance, <a href="https://github.com/xacrimon/dashmap/blob/master/src/lib.rs#L85-L89" target="_blank" rel="noopener">Dashmap uses a sharded design</a> where each shard is a separate <strong>HashMap</strong> guarded by a <strong>RWLock</strong></p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM.png.webp 1084w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-300x296.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-1024x1009.png.webp 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-768x757.png.webp 768w" sizes="auto, (max-width: 1084px) 100vw, 1084px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM.png" alt="" width="1084" height="1068" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM.png 1084w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-300x296.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-1024x1009.png 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.27.48 PM-768x757.png 768w" sizes="auto, (max-width: 1084px) 100vw, 1084px"/>
</picture>
</p>
<p>In cases where the data is guarded by a single, shared counter or resides on the same shard, contention can arise under high loads. This is because every CPU core attempting to increment or decrement the counter causes cache invalidation due to <a href="https://en.wikipedia.org/wiki/Cache_coherence" target="_blank" rel="noopener">cache coherence</a>. Each modification forces the cache line containing the counter to “ping-pong” between cores, leading to degraded performance. To understand this better, look at this section below from a great PDF titled <a href="https://assets.bitbashing.io/papers/concurrency-primer.pdf" target="_blank" rel="noopener">What every systems programmer should know about concurrency</a> by Matt Kline.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong.png.webp 781w, https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong-280x300.png.webp 280w, https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong-768x823.png.webp 768w" sizes="auto, (max-width: 781px) 100vw, 781px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong.png" alt="" width="781" height="837" srcset="https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong.png 781w, https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong-280x300.png 280w, https://www.conviva.com/wp-content/uploads/2025/06/cache_line_ping_pong-768x823.png 768w" sizes="auto, (max-width: 781px) 100vw, 781px"/>
</picture>
</p>
<p><em>Note: If you’re interested in understanding more about hardware caches and their implications, look at <a href="https://redixhumayun.github.io/performance/2025/01/27/cache-conscious-hash-maps.html" target="_blank" rel="noopener">this post</a>.</em></p>
<p>Now, let’s contrast this with the approach that <strong>ArcSwap</strong> uses. <strong>ArcSwap</strong> follows the <a href="https://docs.kernel.org/RCU/whatisRCU.html" target="_blank" rel="noopener">read-copy-update (RCU)</a> methodology where:</p>
<ul>
<li>readers access the data without locking</li>
<li>writers create a new copy of the data</li>
<li>writers atomically swap in the new data</li>
<li>old data is reclaimed later during a reclamation phase</li>
</ul>
<p>The ArcSwap repo even has a <a href="https://github.com/vorner/arc-swap/blob/b12da9d783d27111d31afc77e70b07ce6acdf9f6/src/lib.rs#L603" target="_blank" rel="noopener">method called</a> <a href="https://github.com/vorner/arc-swap/blob/b12da9d783d27111d31afc77e70b07ce6acdf9f6/src/lib.rs#L603" target="_blank" rel="noopener">rcu</a>.</p>
<p>This is analogous to how <a href="https://jepsen.io/consistency/models/snapshot-isolation" target="_blank" rel="noopener">snapshot isolation</a> works in databases with multi-version concurrency control. The purpose is, of course, different but there are overlaps in the mechanism.</p>
<p><strong>ArcSwap</strong> avoids cache contention issues for readers that typically crop up when updating a shared read counter with a <a href="https://github.com/vorner/arc-swap/blob/master/src/debt/list.rs#L335" target="_blank" rel="noopener">thread-local epoch counter to track “debt</a>“.</p>
<p>A new version of the data is swapped in using the <a href="https://github.com/vorner/arc-swap/blob/master/src/strategy/hybrid.rs#L207" target="_blank" rel="noopener">standard</a> <a href="https://github.com/vorner/arc-swap/blob/master/src/strategy/hybrid.rs#L207" target="_blank" rel="noopener">cmp_xchg</a> operation. This marks the beginning of a new epoch, but the data associated with the old epoch isn’t cleaned up until all “debt” is paid off, that is until all readers of the previous epoch have finished.</p>
<p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM.png.webp 1204w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-300x232.png.webp 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-1024x793.png.webp 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-768x594.png.webp 768w" sizes="auto, (max-width: 1204px) 100vw, 1204px"/>
<img loading="lazy" decoding="async" src="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM.png" alt="" width="1204" height="932" srcset="https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM.png 1204w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-300x232.png 300w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-1024x793.png 1024w, https://www.conviva.com/wp-content/uploads/2025/06/Screenshot-2025-06-04-at-4.37.29 PM-768x594.png 768w" sizes="auto, (max-width: 1204px) 100vw, 1204px"/>
</picture>
</p>
<p>Hash maps on the other hand allow updating invidual portions of data in the hash map but this is where it becomes important that we have an <em>almost</em> read-only scenario with a small dataset because the additional overhead of writes with <strong>ArcSwap</strong> is worth paying here since reads are faster.</p>

            	</div>
            
                        	<div>

                    <h5>Conclusion</h5>
<p>Given that we had a situation which was almost read-only with a small dataset, the overhead of a concurrent hash map was not suitable since we had no use case for frequent, granular updates. Trading that for <strong>ArcSwap</strong>, which is a specialized <strong>AtomicRef</strong>, something that is designed for occasional swaps where the entire ref is updated, turned out to be a much better fit.</p>

            	</div>
            
            		</div>
	</div>
</div>	</section>
</article><!-- #post-32147 -->
												</div></div>
  </body>
</html>
