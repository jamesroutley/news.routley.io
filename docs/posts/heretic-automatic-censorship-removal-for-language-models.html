<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/p-e-w/heretic">Original</a>
    <h1>Heretic: Automatic censorship removal for language models</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Heretic is a tool that removes censorship (aka &#34;safety alignment&#34;) from
transformer-based language models without expensive post-training.
It combines an advanced implementation of directional ablation, also known
as &#34;abliteration&#34; (<a href="https://arxiv.org/abs/2406.11717" rel="nofollow">Arditi et al. 2024</a>),
with a TPE-based parameter optimizer powered by <a href="https://optuna.org/" rel="nofollow">Optuna</a>.</p>
<p dir="auto">This approach enables Heretic to work <strong>completely automatically.</strong> Heretic
finds high-quality abliteration parameters by co-minimizing the number of
refusals and the KL divergence from the original model. This results in a
decensored model that retains as much of the original model&#39;s intelligence
as possible. Using Heretic does not require an understanding of transformer
internals. In fact, anyone who knows how to run a command-line program
can use Heretic to decensor language models.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2702526/514848515-d71a5efa-d6be-4705-a817-63332afb2d15.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzNzg1NTQsIm5iZiI6MTc2MzM3ODI1NCwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODUxNS1kNzFhNWVmYS1kNmJlLTQ3MDUtYTgxNy02MzMzMmFmYjJkMTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTdUMTExNzM0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTc5YjNhMTNlMzE4MDJiZTZlNDg1ZGNlNWYxMGRkYjcxM2M5MGRlODVkNDg0NWU2ZGFkOTc0MmE5ZDAwMmQzYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.mIqyGDRxdLJQBL33aUGH49xKlgQ5d9JuvN_a2Iz6Zu0"><img width="650" height="715" alt="Screenshot" src="https://private-user-images.githubusercontent.com/2702526/514848515-d71a5efa-d6be-4705-a817-63332afb2d15.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzNzg1NTQsIm5iZiI6MTc2MzM3ODI1NCwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODUxNS1kNzFhNWVmYS1kNmJlLTQ3MDUtYTgxNy02MzMzMmFmYjJkMTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTdUMTExNzM0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTc5YjNhMTNlMzE4MDJiZTZlNDg1ZGNlNWYxMGRkYjcxM2M5MGRlODVkNDg0NWU2ZGFkOTc0MmE5ZDAwMmQzYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.mIqyGDRxdLJQBL33aUGH49xKlgQ5d9JuvN_a2Iz6Zu0"/></a>

<p dir="auto">Running unsupervised with the default configuration, Heretic can produce
decensored models that rival the quality of abliterations created manually
by human experts:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Refusals for &#34;harmful&#34; prompts</th>
<th>KL divergence from original model for &#34;harmless&#34; prompts</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co/google/gemma-3-12b-it" rel="nofollow">google/gemma-3-12b-it</a> (original)</td>
<td>97/100</td>
<td>0 <em>(by definition)</em></td>
</tr>
<tr>
<td><a href="https://huggingface.co/mlabonne/gemma-3-12b-it-abliterated-v2" rel="nofollow">mlabonne/gemma-3-12b-it-abliterated-v2</a></td>
<td>3/100</td>
<td>1.04</td>
</tr>
<tr>
<td><a href="https://huggingface.co/huihui-ai/gemma-3-12b-it-abliterated" rel="nofollow">huihui-ai/gemma-3-12b-it-abliterated</a></td>
<td>3/100</td>
<td>0.45</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/p-e-w/gemma-3-12b-it-heretic" rel="nofollow">p-e-w/gemma-3-12b-it-heretic</a> (ours)</strong></td>
<td><strong>3/100</strong></td>
<td><strong>0.16</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The Heretic version, generated without any human effort, achieves the same
level of refusal suppression as other abliterations, but at a much lower
KL divergence, indicating less damage to the original model&#39;s capabilities.
<em>(You can reproduce those numbers using Heretic&#39;s built-in evaluation functionality,
e.g. <code>heretic --model google/gemma-3-12b-it --evaluate-model p-e-w/gemma-3-12b-it-heretic</code>.
Note that the exact values might be platform- and hardware-dependent.
The table above was compiled using PyTorch 2.8 on an RTX 5090.)</em></p>
<p dir="auto">Heretic supports most dense models, including many multimodal models, and
several different MoE architectures. It does not yet support SSMs/hybrid models,
models with inhomogeneous layers, and certain novel attention systems.</p>
<p dir="auto">You can find a collection of models that have been decensored using Heretic
<a href="https://huggingface.co/collections/p-e-w/the-bestiary" rel="nofollow">on Hugging Face</a>.</p>

<p dir="auto">Prepare a Python 3.10+ environment with PyTorch 2.2+ installed as appropriate
for your hardware. Then run:</p>
<div data-snippet-clipboard-copy-content="pip install heretic-llm
heretic Qwen/Qwen3-4B-Instruct-2507"><pre><code>pip install heretic-llm
heretic Qwen/Qwen3-4B-Instruct-2507
</code></pre></div>
<p dir="auto">Replace <code>Qwen/Qwen3-4B-Instruct-2507</code> with whatever model you want to decensor.</p>
<p dir="auto">The process is fully automatic and does not require configuration; however,
Heretic has a variety of configuration parameters that can be changed for
greater control. Run <code>heretic --help</code> to see available command-line options,
or look at <a href="https://github.com/p-e-w/heretic/blob/master/config.default.toml"><code>config.default.toml</code></a> if you prefer to use
a configuration file.</p>
<p dir="auto">At the start of a program run, Heretic benchmarks the system to determine
the optimal batch size to make the most of the available hardware.
On an RTX 3090, with the default configuration, decensoring Llama-3.1-8B
takes about 45 minutes.</p>
<p dir="auto">After Heretic has finished decensoring a model, you are given the option to
save the model, upload it to Hugging Face, chat with it to test how well it works,
or any combination of those actions.</p>

<p dir="auto">Heretic implements a parametrized variant of directional ablation. For each
supported transformer component (currently, attention out-projection and
MLP down-projection), it identifies the associated matrices in each transformer
layer, and orthogonalizes them with respect to the relevant &#34;refusal direction&#34;,
inhibiting the expression of that direction in the result of multiplications
with that matrix.</p>
<p dir="auto">Refusal directions are computed for each layer as a difference-of-means between
the first-token residuals for &#34;harmful&#34; and &#34;harmless&#34; example prompts.</p>
<p dir="auto">The ablation process is controlled by several optimizable parameters:</p>
<ul dir="auto">
<li><code>direction_index</code>: Either the index of a refusal direction, or the special
value <code>per layer</code>, indicating that each layer should be ablated using the
refusal direction associated with that layer.</li>
<li><code>max_weight</code>, <code>max_weight_position</code>, <code>min_weight</code>, and <code>min_weight_distance</code>:
For each component, these parameters describe the shape and position of the
ablation weight kernel over the layers. The following diagram illustrates this:</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2702526/514848549-82e4b84e-5a82-4faf-b918-ac642f9e4892.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzNzg1NTQsIm5iZiI6MTc2MzM3ODI1NCwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODU0OS04MmU0Yjg0ZS01YTgyLTRmYWYtYjkxOC1hYzY0MmY5ZTQ4OTIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTdUMTExNzM0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDU2ZjU4MjBhMWQyYTk4MjdiYmIzZTA0NTA4MzRiNWYyMmNjMDY3NjBmYTQ2ODMxZGI2MTcwY2I0ZmM2YzgzMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.kOAyj2yaRW2_iIc8Xh5fIDvCFuKtoP9f_LPQ5FtMvqk"><img width="800" height="500" alt="Explanation" src="https://private-user-images.githubusercontent.com/2702526/514848549-82e4b84e-5a82-4faf-b918-ac642f9e4892.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzNzg1NTQsIm5iZiI6MTc2MzM3ODI1NCwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODU0OS04MmU0Yjg0ZS01YTgyLTRmYWYtYjkxOC1hYzY0MmY5ZTQ4OTIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTdUMTExNzM0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDU2ZjU4MjBhMWQyYTk4MjdiYmIzZTA0NTA4MzRiNWYyMmNjMDY3NjBmYTQ2ODMxZGI2MTcwY2I0ZmM2YzgzMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.kOAyj2yaRW2_iIc8Xh5fIDvCFuKtoP9f_LPQ5FtMvqk"/></a>

<p dir="auto">Heretic&#39;s main innovations over existing abliteration systems are:</p>
<ul dir="auto">
<li>The shape of the ablation weight kernel is highly flexible, which, combined with
automatic parameter optimization, can improve the compliance/quality tradeoff.
Non-constant ablation weights were previously explored by Maxime Labonne in
<a href="https://huggingface.co/mlabonne/gemma-3-12b-it-abliterated-v2" rel="nofollow">gemma-3-12b-it-abliterated-v2</a>.</li>
<li>The refusal direction index is a float rather than an integer. For non-integral
values, the two nearest refusal direction vectors are linearly interpolated.
This unlocks a vast space of additional directions beyond the ones identified
by the difference-of-means computation, and often enables the optimization
process to find a better direction than that belonging to any individual layer.</li>
<li>Ablation parameters are chosen separately for each component. I have found that
MLP interventions tend to be more damaging to the model than attention interventions,
so using different ablation weights can squeeze out some extra performance.</li>
</ul>

<p dir="auto">I&#39;m aware of the following publicly available implementations of abliteration
techniques:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/posts/mlabonne/714992455492422" rel="nofollow">AutoAbliteration</a></li>
<li><a href="https://github.com/FailSpy/abliterator">abliterator.py</a></li>
<li><a href="https://github.com/wassname/abliterator">wassname&#39;s Abliterator</a></li>
<li><a href="https://github.com/Tsadoq/ErisForge">ErisForge</a></li>
<li><a href="https://github.com/Sumandora/remove-refusals-with-transformers">Removing refusals with HF Transformers</a></li>
<li><a href="https://github.com/AUGMXNT/deccp">deccp</a></li>
</ul>
<p dir="auto">Note that Heretic was written from scratch, and does not reuse code from
any of those projects.</p>

<p dir="auto">The development of Heretic was informed by:</p>
<ul dir="auto">
<li><a href="https://arxiv.org/abs/2406.11717" rel="nofollow">The original abliteration paper (Arditi et al. 2024)</a></li>
<li><a href="https://huggingface.co/blog/mlabonne/abliteration" rel="nofollow">Maxime Labonne&#39;s article on abliteration</a>,
as well as some details from the model cards of his own abliterated models (see above)</li>
<li><a href="https://huggingface.co/blog/grimjim/projected-abliteration" rel="nofollow">Jim Lai&#39;s article describing &#34;projected abliteration&#34;</a></li>
</ul>

<p dir="auto">Copyright Â© 2025  Philipp Emanuel Weidmann (<a href="mailto:pew@worldwidemann.com">pew@worldwidemann.com</a>)</p>
<p dir="auto">This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Affero General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p dir="auto">This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Affero General Public License for more details.</p>
<p dir="auto">You should have received a copy of the GNU Affero General Public License
along with this program.  If not, see <a href="https://www.gnu.org/licenses/" rel="nofollow">https://www.gnu.org/licenses/</a>.</p>
<p dir="auto"><strong>By contributing to this project, you agree to release your
contributions under the same license.</strong></p>
</article></div></div>
  </body>
</html>
