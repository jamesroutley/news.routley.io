<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.zdnet.com/article/intels-new-deepfake-detector-can-spot-a-real-or-fake-video-based-on-blood-flow-in-video-pixels/">Original</a>
    <h1>Deepfake detector can spot a real or fake video based on blood flow in pixels</h1>
    
    <div id="readability-page-1" class="page"><div id="article-6ea21ce0-e8bc-41f2-b7a1-0108449767a7"><!----> <!----> <div><div><figure><div><div><picture><source media="(max-width: 767px)" srcset="https://www.zdnet.com/a/img/resize/3cf8728dbbd4cca5ff3e8195c1873831aaf3fe31/2022/03/07/2cd77796-f78b-4744-a9b6-f36c73108dba/facial-recognition.jpg?auto=webp&amp;width=768" alt="facial-recognition.jpg"/><source media="(max-width: 1023px)" srcset="https://www.zdnet.com/a/img/resize/80af0c61ddf7dfa635f25dc3b69f8ad929881d62/2022/03/07/2cd77796-f78b-4744-a9b6-f36c73108dba/facial-recognition.jpg?auto=webp&amp;width=1024" alt="facial-recognition.jpg"/><source media="(max-width: 1440px)" srcset="https://www.zdnet.com/a/img/resize/fbcc24f50af7e7d930618b591294ab8d94f4bfb6/2022/03/07/2cd77796-f78b-4744-a9b6-f36c73108dba/facial-recognition.jpg?auto=webp&amp;width=1200" alt="facial-recognition.jpg"/> <img src="https://www.zdnet.com/a/img/resize/fbcc24f50af7e7d930618b591294ab8d94f4bfb6/2022/03/07/2cd77796-f78b-4744-a9b6-f36c73108dba/facial-recognition.jpg?auto=webp&amp;width=1200" alt="facial-recognition.jpg" width="1200" height="800.377358490566" fetchpriority="low"/></picture></div> <!----></div> <!----> <figcaption><div></div> <span>Image: Witthaya Prasongsin / Getty</span></figcaption></figure><p>In recent years, more and more deepfakes have littered the internet – pieces of synthetic media that take an image or video and use someone else&#39;s face or voice to create a new, fake image of people or occurrences. And chances are, you&#39;ve already seen one and didn&#39;t know it was a deepfake.</p><p>The very real-looking characteristics of <a href="https://www.zdnet.com/article/the-next-big-security-threat-is-staring-us-in-the-face-tackling-it-is-going-to-be-tough/" rel="follow">deepfakes have allowed for many instances of misinformation, hoaxes, and fraud to disseminate online</a>. In response, <a href="https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-real-time-deepfake-detector.html#gs.igxwxm" target="_blank" rel="noopener noreferrer nofollow">Intel announced a new technology called &#34;FakeCatcher&#34;</a> to detect deepfake media with a 96% accuracy rate.</p><p>Deepfakes use impressive technology derived from <a href="https://www.zdnet.com/article/machine-learning-is-going-real-time-heres-why-and-how/" rel="follow">machine learning</a> and <a href="https://www.zdnet.com/article/what-is-ai-heres-everything-you-need-to-know-about-artificial-intelligence/" rel="follow">artificial intelligence</a> to create scarily accurate impressions of celebrities and politicians doing and saying things they haven&#39;t. </p><p>Existing technologies can take hours to dispel web surfers&#39; trust in a deepfake, as they use deep learning to investigate signs of digital manipulation.</p><p><strong>Also: <a href="https://www.zdnet.com/article/how-to-spot-a-deepfake-one-simple-trick-is-all-you-need/" rel="follow">How to spot a deepfake? One simple trick is all you need</a></strong></p><p>Intel&#39;s FakeCatcher can detect a deepfake in real time by &#34;assessing what makes us human – &#39;blood flow&#39; in the pixels of a video,&#34; according to a press release. </p><p>Intel says its technology can identify changes in our veins&#39; color when blood circulates through the body. Signals of blood flow are then collected from the face and translated by algorithms to discern if a video is real or a deepfake. </p><p>It&#39;s becoming increasingly important to have software to help us identify deepfakes to avoid harmful consequences. Some deepfake videos and images are graphic in nature, and others perpetuate distrust in the media. </p><p>In the past, scammers have used <a href="https://www.zdnet.com/article/fbi-warning-crooks-are-are-using-deepfakes-to-apply-for-remote-tech-jobs/" rel="follow">deepfakes to pose as job seekers to access sensitive company information</a>. They&#39;ve also been used to <a href="https://www.youtube.com/watch?v=cQ54GDm1eL0" target="_blank" rel="noopener noreferrer nofollow">impersonate prominent political figures to say inflammatory statements</a>. </p><p>Although some movements and mannerisms in deepfakes give away their deceptive nature, most people mindlessly scroll through their Twitter feed and don&#39;t take the time to find out if a video is real or fake. </p><p><strong>Also:</strong> <a href="https://www.zdnet.com/article/the-next-big-security-threat-is-staring-us-in-the-face-tackling-it-is-going-to-be-tough/" rel="follow"><strong>The next big security threat is staring us in the face. Tackling it is going to be tough</strong></a></p><p>And by the time a deepfake garners millions of shares, it&#39;s far too late, as <a href="https://www.pewresearch.org/fact-tank/2019/06/14/about-three-quarters-of-americans-favor-steps-to-restrict-altered-videos-and-images/" target="_blank" rel="noopener noreferrer nofollow">63% of adults in the US admit that an altered video has confused them about current events</a>, according to the Pew Research Center. </p></div></div> <a href="https://www.zdnet.com/editorial-guidelines/" rel="follow"><svg><use xlink:href="#file" aria-hidden="false"></use></svg><span>Editorial standards</span></a> <!---->  <!----></div></div>
  </body>
</html>
