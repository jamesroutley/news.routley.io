<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/">Original</a>
    <h1>My thousand dollar iPhone can&#39;t do math</h1>
    
    <div id="readability-page-1" class="page"><section>
				<p>My iPhone 16 Pro Max produces garbage output when running MLX LLMs. An iPhone 15 Pro runs the same code perfectly. A MacBook Pro also runs the same code perfectly. The tensor outputs on the 16 show numerical values an order of magnitude wrong. I suspect it points to a hardware defect in the Neural Engine or some other ML-needed system.</p><p>It was a PITA to debug, but at least I got a blog post out of it.</p><p>This was supposed to be a simple, unwinding-time project.</p><p>For the past few months I&#39;ve been working on a <s>Clawdbot</s> Moltbot clone that I&#39;ve been calling Schmidt. It basically does the same kind of thing but with a custom chat UI instead of using Telegram, WhatsApp or other &#34;I-can&#39;t-afford-to-be-banned-from&#34; Service. This project has been consuming early days and late nights, so, to unwind, I decided that it may be a good idea to do something simpler. Since I recently subscribed to MiniMax M2.1, I thought I would do what many do and build a simple expense tracking app to test out the model.</p><p>The core functionality is simple: </p><ul><li>Automatically, upon each payment, add the expense to my app</li><li>Update an Apple Watch complication with the % of my monthly budget spent</li><li>Categorize the purchase for later analysis</li></ul><p>This all comes from being basically orphaned by Nubank&#39;s amazing native app (since replaced by a less-full-featured Flutter version).</p><figure><img src="https://journal.rafaelcosta.me/content/images/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp" alt="" loading="lazy" width="752" height="564" srcset="https://journal.rafaelcosta.me/content/images/size/w600/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp 600w, https://journal.rafaelcosta.me/content/images/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp 752w" sizes="(min-width: 720px) 720px"/><figcaption><span>Something like that, I can&#39;t find the original complication itself. Apparently, this was designed by </span><a href="https://dribbble.com/gneumann?ref=journal.rafaelcosta.me" rel="contact"><span>Guilherme Neumann</span></a><span>Â (according to their Dribbble)</span></figcaption></figure><p>Integrating with Shortcuts is manual, but reliable. Within 15 minutes I had a version of the app that could register purchases. The Apple Watch complication, the main goal, can come later. I&#39;d rather get the classification feature, which should be easy, done quickly â€“ so I figured.</p><h2 id="apple-intelligence">Apple Intelligence</h2><p>Given the new LLM-bonanza we&#39;ve been living through, it&#39;s no surprise that Apple has their own set of APIs developers such as me can use. Reading up on the documentation, it&#39;s a matter of checking for the availability of the feature and then asking the model to either reply to a textual query or, in my case, categorize a request.</p><p>MiniMax raced through it in a single prompt and then I ran it on my iPhone. First expense was a purchase at a shop called &#34;Kasai Kitchin&#34;, classified as... <code>unknown</code>.</p><p>Checking the logs, it was clear: the model support was downloading. The feature hadn&#39;t been enabled. Again, weird. I should have it on. Anyway, I go into settings, do the weird dance of toggling it on and off â€“ sadly, that&#39;s not surprising on Apple&#39;s services. Maybe my Settings.app got stuck in a weird state, who knows? â€“ and wait for it to download.</p><figure><img src="https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-01.14.46.png" alt="" loading="lazy" width="1320" height="971" srcset="https://journal.rafaelcosta.me/content/images/size/w600/2026/01/Screenshot-2026-01-28-at-01.14.46.png 600w, https://journal.rafaelcosta.me/content/images/size/w1000/2026/01/Screenshot-2026-01-28-at-01.14.46.png 1000w, https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-01.14.46.png 1320w" sizes="(min-width: 720px) 720px"/></figure><p>After 4h I realized it was not going anywhere. Looking it up, it seems that many have the same issue (<a href="https://discussions.apple.com/thread/255822364?answerId=261482678022&amp;sortBy=rank&amp;page=12&amp;ref=journal.rafaelcosta.me#261482678022">this</a> thread shows 12 pages of frustrated users). Again, not a surprise for Apple&#39;s services recently.</p><p>Oh well, time to give up on the Apple Intelligence approach. Let&#39;s move on to the next one.</p><h2 id="mlx-llm">MLX LLM</h2><p>Well, the iOS framework engineers don&#39;t seem to be the only engineers at Apple capable of coming up with Machine Learning APIs in Swift. Apparently, there&#39;s a whole separate way of doing it â€“ with models downloaded to your app. Not great for the user&#39;s storage, but great for me!</p><p>Again, MiniMax does it in a heartbeat, specially after being given documentation and one or two Medium posts. Time to run on my iPhone and... gibberish.</p><p>The CPU spins to 100% and the model starts generating. But it&#39;s all gibberish. And no &#34;stop&#34; token is generated, so this goes on for long.</p><figure><img src="https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-02.09.49.png" alt="" loading="lazy" width="2000" height="605" srcset="https://journal.rafaelcosta.me/content/images/size/w600/2026/01/Screenshot-2026-01-28-at-02.09.49.png 600w, https://journal.rafaelcosta.me/content/images/size/w1000/2026/01/Screenshot-2026-01-28-at-02.09.49.png 1000w, https://journal.rafaelcosta.me/content/images/size/w1600/2026/01/Screenshot-2026-01-28-at-02.09.49.png 1600w, https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-02.09.49.png 2322w" sizes="(min-width: 720px) 720px"/><figcaption><span>&#34;What is 2+2?&#34; apparently &#34;Applied.....*_dAK[...]&#34; according to my iPhone</span></figcaption></figure><p>At this point, the only explanation is: I&#39;m completely incompetent and can&#39;t even get a simple &#34;ready made&#34; framework to execute what I want. Or, rather, <strong>MiniMax is</strong>! The good thing about offloading your work to an LLM is that you can blame it for your shortcomings. Time to get my hands dirty and do it myself, typing code on my keyboard, like the ancient Mayan and Aztec programmers probably did.</p><h2 id="my-own-mlx-implementation">My own MLX implementation</h2><p>I went back to the documentation, to the Medium posts and, much to my surprise: MiniMax had followed it to the letter. Even went back to some deprecated methods of generation and it also was gibberish. And now there&#39;s no one to blame, but myself. I go to work everyday and this impostor-syndrome inducing problem silently consumes me. </p><p>I stop and think: this cannot be a hardware issue,<em> right</em>? Of course not. The iPhone 15 is still running iOS 18. The iPhone 16 is running 26. It <strong><em>must be an OS issue</em></strong>. Well, time to be late for my work standup and update the old phone. The curiosity is too much. Many minutes later... same results, now on iOS 26. The plot is thickening.</p><p>After that work day, and after many lunch and coffee discussions with coworkers about the sources of my troubles, I get home and immediately set myself on debugging MLX as it runs, if possible. The game plan is:</p><ul><li>Use a known-to-be-reliable model, that fits in RAM (I went with quantized Gemma)</li><li>Use a simple prompt, in my case &#34;What is 2+2?&#34;<ul><li>To be <em>really</em> pedantic: the prompt was <code>&lt;start_of_turn&gt;user\nWhat is 2+2?&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model</code></li></ul></li><li>Run everything with temperature set to <code>0.0</code> â€“ maybe that&#39;s enough to remove variability</li><li>Find the model implementation</li><li>Find where the model iterates through the layers and</li><li>Print out the MLXArray/Tensor with the values on each layer as the input goes through</li></ul><p>A few moments later and I find where I need to be. Added the breakpoints, added the logs and off to the races.</p><figure><img src="https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-27-at-18.28.38.png" alt="" loading="lazy" width="1892" height="1186" srcset="https://journal.rafaelcosta.me/content/images/size/w600/2026/01/Screenshot-2026-01-27-at-18.28.38.png 600w, https://journal.rafaelcosta.me/content/images/size/w1000/2026/01/Screenshot-2026-01-27-at-18.28.38.png 1000w, https://journal.rafaelcosta.me/content/images/size/w1600/2026/01/Screenshot-2026-01-27-at-18.28.38.png 1600w, https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-27-at-18.28.38.png 1892w" sizes="(min-width: 720px) 720px"/><figcaption><span>These ones were the ones I added</span></figcaption></figure><p>I run it on my iPhone 16 Pro Max. The model loads and the prompt is &#34;What is 2+2?&#34;. The tensors start printing out, line after line after line. For once, the logs aren&#39;t <em>complete</em> gibberish â€“ they&#39;re numbers. Floating point values representing the model&#39;s internal state as it processes the input. I save the output to a file and do the same on my iPhone 15 Pro. Same model, same prompt, same code. Time to compare.</p><p>I grep for a pattern I know should be consistent â€“ an array at log-line 58, right before the values get normalized/softmaxed. On a working device, I hypothesize this should be the same every time.</p><p>OK, so the model receives the same thing as input, but at some point, the values start to go off. Like, <strong><em>way off</em></strong>. In order to make sure I&#39;m not crazy, I do one last thing: run the same thing on my Mac. Make the app run on iPad compatibility mode and...</p><p><strong>Bingo! Same as iPhone 15!</strong></p><p>The model isn&#39;t broken. The code isn&#39;t broken. Most importantly, I&#39;m not broken*. My <strong>phone</strong> is broken.</p><p>Let me explain what I think it&#39;s going on here: the iPhone 16 Pro Max contains Apple&#39;s A18 chip with its Neural Engineâ€”a specialized accelerator for machine learning operations. MLX uses Metal to compile tensor operations for this accelerator. Somewhere in that stack, the computations are going <strong>very</strong> wrong. I don&#39;t think it&#39;s a widespread issue but, I do get disappointed that a relatively newly replaced iPhone from Apple Care came with such an issue.</p><p>However, if my Apple Intelligence troubles are related â€“ and they might as well be, I&#39;d assume that code and MLX are not dissimilar in operations being done â€“, it could be that <a href="https://discussions.apple.com/thread/255822364?answerId=261482678022&amp;sortBy=rank&amp;page=12&amp;ref=journal.rafaelcosta.me#261482678022">all the 12 pages of users</a> are users in a similar dillema, but without the means of debugging it.</p><h2 id="what-now">What now?</h2><p>I spent 3 days thinking I was incompetent. I blamed MiniMax. I blamed myself. The entire time, my $1,400 phone had a broken hardware. I could lose more time figuring out <em>exactly</em> what is wrong with it but itâ€™s literally not worth my time.</p><p>I guess I can at least take a lesson that, when debugging, I should always consider the physical layer. I spent three days assuming this was a software problem â€“ my code, the library, the framework, my skills as a developer. The breakthrough was basically: &#34;What if I&#39;m not dumb and it&#39;s not my code?&#34;</p><p>As for my phone: it&#39;ll probably go back to Apple, as a trade in for a new iPhone 17 Pro Max that <em>hopefully ðŸ¤ž</em> can do math.</p><h3 id="update-on-feb-1st">Update on Feb. 1st:</h3><p>Well, now it&#39;s Feb. 1st and I have an iPhone 17 Pro Max to test with and... everything works as expected. So it&#39;s pretty safe to say that <strong>THAT</strong> specific instance of iPhone 16 Pro Max was hardware-defective.<br/></p>
			</section></div>
  </body>
</html>
