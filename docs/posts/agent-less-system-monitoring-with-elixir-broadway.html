<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://opsmaru.com/blog/agent-less-system-monitoring-with-elixir-broadway">Original</a>
    <h1>Agent-Less System Monitoring with Elixir Broadway</h1>
    
    <div id="readability-page-1" class="page"><div>
              <p>We&#39;ve started working on something that will be a critical component the Opsmaru platform. This part requires having proper infrastructure monitoring for several reasons. While Opsmaru has health monitoring for every cluster managed by the platform, it doesn&#39;t give us deep insights into the metrics of the systems.</p>
<p>Up until this point we&#39;ve delayed the development of any system monitoring because there wasn&#39;t a real elegant way for us to do system monitoring (primarily Memory, Disk, CPU, Load). What we mean by that is most of the existing solutions out there require some kind of agent to be installed. Whether you are using fluentd, syslog-ng, logstash, vector, you would have to install them on the running machine. More software means more maintenance cost of keeping them up-to-date, wrangling configuration to get what you need out of them.</p>
<h2>Understanding the Architecture</h2>
<p>Before going deep into the code that would enable us to do system monitoring we first need to look at the architecture and how Opsmaru actually operates.</p>
<p>When you setup a cluster on Opsmaru, it automatically provisions the <code>Uplink</code> module. The <code>Uplink</code> module is what performs all the orchestration / setting up and manages all the app containers running inside the cluster. It does all of this through the LXD hypervisor&#39;s api.</p>
<p><img src="https://cdn.sanity.io/images/gyrrgtvc/production/4d215826e1caad3b1a8f9bdf60df6dbeb6580325-1407x768.png?w=1200" alt="Uplink architecture"/></p>
<p>Uplink is a module that we <a href="https://github.com/upmaru/uplink">developed and open-sourced</a>. Given that we already have something running that manages the cluster for us. It makes sense that we should be able to extend the functionality of uplink to handle system monitoring as well. This was the basis behind the implementation. On top of this we already knew about Elixir&#39;s Broadway library so implementing something within uplink to do this was obvious.</p>
<h2>Retrieving the Data</h2>
<p>LXD already has certain metrics exposed through the <code>/1.0/metrics</code> API. If we call this we would be able to retrieve the metrics of the containers running. There was also another endpoint which would give us some of the metrics <code>/1.0/instances</code>. This meant we had everything we need to be able to collect the metrics data. Great!</p>
<p>We already have an LXD client for elixir so we can coveniently call these endpoints through our wrapper. Calling the function gives us a list of instances with a snapshot of data like cpu, disk, memory and networking usage. This is only a snapshot of the data when we call the function. We will need to do some data processing to get the CPU load from the usage time.</p>
<pre><code translate="no"><span>alias</span> <span>Uplink.Clients.LXD</span>
</code></pre>
<pre><code translate="no"><span>&gt;</span> <span>LXD</span><span>.</span><span>list_instances</span><span>(</span><span>recursion: </span><span>2</span><span>)</span>

<span>[</span> 
  <span>%</span><span>Uplink.Clients.LXD.Instance</span><span>{</span>
    
    <span>state: </span><span>%</span><span>{</span>
      <span>&#34;cpu&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span><span>&#34;usage&#34;</span> <span>=&gt;</span> <span>136630751000</span><span>}</span><span>,</span>
      <span>&#34;disk&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span><span>&#34;root&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span><span>&#34;total&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span> <span>&#34;usage&#34;</span> <span>=&gt;</span> <span>40831488</span><span>}</span><span>}</span><span>,</span>
      <span>&#34;memory&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span>
        <span>&#34;swap_usage&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
        <span>&#34;swap_usage_peak&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
        <span>&#34;total&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
        <span>&#34;usage&#34;</span> <span>=&gt;</span> <span>1998848</span><span>,</span>
        <span>&#34;usage_peak&#34;</span> <span>=&gt;</span> <span>0</span>
      <span>}</span><span>,</span>
      <span>&#34;network&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span>
        <span>&#34;eth0&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span>
          <span>&#34;addresses&#34;</span> <span>=&gt;</span> <span>[</span>
            <span>%</span><span>{</span>
              <span>&#34;address&#34;</span> <span>=&gt;</span> <span>&#34;240.1.252.128&#34;</span><span>,</span>
              <span>&#34;family&#34;</span> <span>=&gt;</span> <span>&#34;inet&#34;</span><span>,</span>
              <span>&#34;netmask&#34;</span> <span>=&gt;</span> <span>&#34;8&#34;</span><span>,</span>
              <span>&#34;scope&#34;</span> <span>=&gt;</span> <span>&#34;global&#34;</span>
            <span>}</span><span>,</span>
            <span>%</span><span>{</span>
              <span>&#34;address&#34;</span> <span>=&gt;</span> <span>&#34;fe80::216:3eff:fe28:5f9a&#34;</span><span>,</span>
              <span>&#34;family&#34;</span> <span>=&gt;</span> <span>&#34;inet6&#34;</span><span>,</span>
              <span>&#34;netmask&#34;</span> <span>=&gt;</span> <span>&#34;64&#34;</span><span>,</span>
              <span>&#34;scope&#34;</span> <span>=&gt;</span> <span>&#34;link&#34;</span>
            <span>}</span>
          <span>]</span><span>,</span>
          <span>&#34;counters&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span>
            <span>&#34;bytes_received&#34;</span> <span>=&gt;</span> <span>215421737</span><span>,</span>
            <span>&#34;bytes_sent&#34;</span> <span>=&gt;</span> <span>3562213</span><span>,</span>
            <span>&#34;errors_received&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
            <span>&#34;errors_sent&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
            <span>&#34;packets_dropped_inbound&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
            <span>&#34;packets_dropped_outbound&#34;</span> <span>=&gt;</span> <span>0</span><span>,</span>
            <span>&#34;packets_received&#34;</span> <span>=&gt;</span> <span>53456</span><span>,</span>
            <span>&#34;packets_sent&#34;</span> <span>=&gt;</span> <span>32510</span>
          <span>}</span><span>,</span>
          <span>&#34;host_name&#34;</span> <span>=&gt;</span> <span>&#34;veth7cd391d8&#34;</span><span>,</span>
          <span>&#34;hwaddr&#34;</span> <span>=&gt;</span> <span>&#34;00:16:3e:28:5f:9a&#34;</span><span>,</span>
          <span>&#34;mtu&#34;</span> <span>=&gt;</span> <span>8951</span><span>,</span>
          <span>&#34;state&#34;</span> <span>=&gt;</span> <span>&#34;up&#34;</span><span>,</span>
          <span>&#34;type&#34;</span> <span>=&gt;</span> <span>&#34;broadcast&#34;</span>
        <span>}</span><span>,</span>
        
    <span>}</span>
  <span>}</span>
<span></span><span>]</span>
</code></pre>
<p>To retrieve the metrics from <code>/1.0/metrics</code> we call the below.</p>
<pre><code translate="no"><span>&gt;</span> <span>LXD</span><span>.</span><span>list_metrics</span><span>(</span><span>target: </span><span>&#34;cluster-member-name&#34;</span><span>)</span>

<span>[</span>
  <span>%</span><span>PrometheusParser.Line</span><span>{</span>
    <span>line_type: </span><span>&#34;ENTRY&#34;</span><span>,</span>
    <span>timestamp: </span><span>nil</span><span>,</span>
    <span>pairs: </span><span>[</span>
      <span>{</span><span>&#34;cpu&#34;</span><span>,</span> <span>&#34;0&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;mode&#34;</span><span>,</span> <span>&#34;system&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;name&#34;</span><span>,</span> <span>&#34;insterra-0710c9ca-01&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;project&#34;</span><span>,</span> <span>&#34;upmaru.insterra&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;type&#34;</span><span>,</span> <span>&#34;container&#34;</span><span>}</span>
    <span>]</span><span>,</span>
    <span>value: </span><span>&#34;23297.273635&#34;</span><span>,</span>
    <span>documentation: </span><span>nil</span><span>,</span>
    <span>type: </span><span>nil</span><span>,</span>
    <span>label: </span><span>&#34;lxd_cpu_seconds_total&#34;</span>
  <span>}</span><span>,</span>
  <span>%</span><span>PrometheusParser.Line</span><span>{</span>
    <span>line_type: </span><span>&#34;ENTRY&#34;</span><span>,</span>
    <span>timestamp: </span><span>nil</span><span>,</span>
    <span>pairs: </span><span>[</span>
      <span>{</span><span>&#34;cpu&#34;</span><span>,</span> <span>&#34;0&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;mode&#34;</span><span>,</span> <span>&#34;user&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;name&#34;</span><span>,</span> <span>&#34;insterra-0710c9ca-01&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;project&#34;</span><span>,</span> <span>&#34;upmaru.insterra&#34;</span><span>}</span><span>,</span>
      <span>{</span><span>&#34;type&#34;</span><span>,</span> <span>&#34;container&#34;</span><span>}</span>
    <span>]</span><span>,</span>
    <span>value: </span><span>&#34;36249.169252&#34;</span><span>,</span>
    <span>documentation: </span><span>nil</span><span>,</span>
    <span>type: </span><span>nil</span><span>,</span>
    <span>label: </span><span>&#34;lxd_cpu_seconds_total&#34;</span>
  <span>}</span>
  
<span>]</span> 
</code></pre>
<p>The output of the <code>list_metrics</code> will return prometheus formatted output. We used the <a href="https://github.com/turnhub/turnio-prometheus-parser"><code>:prometheus_parser</code></a> to convert the data into something we can work with.</p>
<h2>Timeseries Data Collection</h2>
<p>Now that we have access to the data the next decision is to decide where to ship all that data. We decided to go with Elastic stack because on top of being a great choice for timeseries it can also be used for other things like AIOps / Search and many other things we have plans for.</p>
<p>Given that the data collected is a snapshot of the system at the time of collection we will probably need to collect multiple data points at a given time interval and do some processing before we ship the data to elastic.</p>
<h2>Implementing the Broadway Producer</h2>
<p>We want our producer to collect data at a given interval and send the data to our pipeline. Let&#39;s take a look at what that looks like.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  <span>use</span> <span>GenStage</span>
  <span>@</span><span>behaviour</span> <span>Broadway.Producer</span>

   
  <span>def</span> <span>start_link</span><span>(</span><span>opts</span><span>)</span> <span>do</span>
    <span>GenStage</span><span>.</span><span>start_link</span><span>(</span><span>__MODULE__</span><span>,</span> <span>opts</span><span>)</span>
  <span>end</span>

  <span>@</span><span>impl</span> <span>true</span>
  <span>def</span> <span>init</span><span>(</span><span>opts</span><span>)</span> <span>do</span>
    <span>poll_interval</span> <span>=</span> <span>Keyword</span><span>.</span><span>get</span><span>(</span><span>opts</span><span>,</span> <span>:poll_interval</span><span>,</span> <span>15_000</span><span>)</span>
    <span>next_schedule</span> <span>=</span> <span>div</span><span>(</span><span>poll_interval</span><span>,</span> <span>3</span><span>)</span>

    <span>state</span> <span>=</span> <span>%</span><span>{</span>
      <span>demand: </span><span>0</span><span>,</span>
      <span>poll_interval: </span><span>poll_interval</span><span>,</span>
      <span>cycle: </span><span>0</span><span>,</span>
      <span>previous_cpu_metrics: </span><span>[</span><span>]</span><span>,</span>
      <span>previous_network_metrics: </span><span>[</span><span>]</span><span>,</span>
      <span>cpu_60_metrics: </span><span>[</span><span>]</span><span>,</span>
      <span>cpu_300_metrics: </span><span>[</span><span>]</span><span>,</span>
      <span>cpu_900_metrics: </span><span>[</span><span>]</span>
    <span>}</span>

    <span>Process</span><span>.</span><span>send_after</span><span>(</span><span>self</span><span>(</span><span>)</span><span>,</span> <span>:poll</span><span>,</span> <span>next_schedule</span><span>)</span>

    <span>{</span><span>:producer</span><span>,</span> <span>state</span><span>}</span>
  <span>end</span>

  
<span>end</span>
</code></pre>
<p>The reason we need to store <code>cpu_x_metrics</code>, <code>previous_cpu_metrics</code> and <code>previous_network_metrics</code> is that we need to be able to get the change in these values. The <code>cpu_x_metrics</code> allow us to compute the <code>load 1</code>, <code>load 5</code> and <code>load 15</code> values, as you&#39;ll later see.</p>
<p>We pass in the <code>:poll_interval</code> as a configurable parameter. Next we need to implement the <code>handle_demand</code> callbacks of <code>GenStage</code>. We return an empty list when the demand is &lt;= 0, otherwise we check whether we&#39;re <code>ready_to_fetch?</code>.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  
  <span>@</span><span>impl</span> <span>true</span>
  <span>def</span> <span>handle_demand</span><span>(</span><span>demand</span><span>,</span> <span>state</span><span>)</span> <span>when</span> <span>demand</span> <span>&lt;=</span> <span>0</span> <span>do</span>
    <span>{</span><span>:noreply</span><span>,</span> <span>[</span><span>]</span><span>,</span> <span>state</span><span>}</span>
  <span>end</span>

  <span>def</span> <span>handle_demand</span><span>(</span><span>demand</span><span>,</span> <span>state</span><span>)</span> <span>do</span>
    <span>if</span> <span>ready_to_fetch?</span><span>(</span><span>state</span><span>)</span> <span>do</span>
      <span>{</span><span>messages</span><span>,</span> <span>state</span><span>}</span> <span>=</span> <span>load_metrics</span><span>(</span><span>demand</span><span>,</span> <span>state</span><span>)</span>
      <span>{</span><span>:noreply</span><span>,</span> <span>messages</span><span>,</span> <span>state</span><span>}</span>
    <span>else</span>
      <span>{</span><span>:noreply</span><span>,</span> <span>[</span><span>]</span><span>,</span> <span>state</span><span>}</span>
    <span>end</span>
  <span>end</span>
  
<span>end</span>
</code></pre>
<p>The <code>ready_to_fetch?</code> function will ensure that we don&#39;t ship more data than what was configured. It&#39;s a simple call that checks the last time we fetched, and if the time is &lt; than the configured interval we skip.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  
  <span>defp</span> <span>ready_to_fetch?</span><span>(</span><span>state</span><span>)</span> <span>do</span>
    <span>Cache</span><span>.</span><span>transaction</span><span>(</span>
      <span>[</span><span>keys: </span><span>[</span><span>{</span><span>:monitors</span><span>,</span> <span>:metrics</span><span>,</span> <span>:last_fetched_timestamp</span><span>}</span><span>]</span><span>]</span><span>,</span>
      <span>fn</span> <span>-&gt;</span>
        <span>now</span> <span>=</span> <span>DateTime</span><span>.</span><span>to_unix</span><span>(</span><span>DateTime</span><span>.</span><span>utc_now</span><span>(</span><span>)</span><span>,</span> <span>:millisecond</span><span>)</span>

        <span>last_fetched_timestamp</span> <span>=</span> <span>Cache</span><span>.</span><span>get</span><span>(</span><span>{</span><span>:monitors</span><span>,</span> <span>:metrics</span><span>,</span> <span>:last_fetched_timestamp</span><span>}</span><span>)</span>

        <span>is_nil</span><span>(</span><span>last_fetched_timestamp</span><span>)</span> <span>||</span>
          <span>now</span> <span>-</span> <span>last_fetched_timestamp</span> <span>&gt;</span> <span>state</span><span>.</span><span>poll_interval</span>
      <span>end</span>
    <span>)</span>
  <span>end</span>
<span>end</span>
</code></pre>
<p>We use <code>:nebulex</code> caching library to store shared state across the cluster. Incase we run multiple nodes this code ensurs that there is a single source of truth for checking the last fetched time.</p>
<p>Next let&#39;s take a look at the <code>load_metrics/2</code> call.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  
  <span>defp</span> <span>load_metrics</span><span>(</span><span>demand</span><span>,</span> <span>state</span><span>)</span> <span>do</span>
    <span>demand</span> <span>=</span> <span>demand</span> <span>+</span> <span>state</span><span>.</span><span>demand</span>

    <span>metrics</span> <span>=</span> <span>Metrics</span><span>.</span><span>for_instances</span><span>(</span><span>)</span>

    <span>previous_cpu_metrics</span> <span>=</span> <span>state</span><span>.</span><span>previous_cpu_metrics</span>
    <span>previous_network_metrics</span> <span>=</span> <span>state</span><span>.</span><span>previous_network_metrics</span>
    <span>cpu_60_metrics</span> <span>=</span> <span>state</span><span>.</span><span>cpu_60_metrics</span>
    <span>cpu_300_metrics</span> <span>=</span> <span>state</span><span>.</span><span>cpu_300_metrics</span>
    <span>cpu_900_metrics</span> <span>=</span> <span>state</span><span>.</span><span>cpu_900_metrics</span>

    <span>messages</span> <span>=</span>
      <span>transform_metrics</span><span>(</span><span>metrics</span><span>,</span> <span>%</span><span>{</span>
        <span>previous_cpu_metrics: </span><span>previous_cpu_metrics</span><span>,</span>
        <span>previous_network_metrics: </span><span>previous_network_metrics</span><span>,</span>
        <span>cpu_60_metrics: </span><span>cpu_60_metrics</span><span>,</span>
        <span>cpu_300_metrics: </span><span>cpu_300_metrics</span><span>,</span>
        <span>cpu_900_metrics: </span><span>cpu_900_metrics</span><span>,</span>
        <span>cycle: </span><span>state</span><span>.</span><span>cycle</span>
      <span>}</span><span>)</span>

    <span>current_demand</span> <span>=</span> <span>demand</span> <span>-</span> <span>length</span><span>(</span><span>messages</span><span>)</span>

    <span>fetch_timestamp</span> <span>=</span> <span>DateTime</span><span>.</span><span>to_unix</span><span>(</span><span>DateTime</span><span>.</span><span>utc_now</span><span>(</span><span>)</span><span>,</span> <span>:millisecond</span><span>)</span>

    <span>Cache</span><span>.</span><span>put</span><span>(</span><span>{</span><span>:monitors</span><span>,</span> <span>:metrics</span><span>,</span> <span>:last_fetched_timestamp</span><span>}</span><span>,</span> <span>fetch_timestamp</span><span>)</span>

    <span>previous_cpu_metrics</span> <span>=</span>
      <span>Enum</span><span>.</span><span>map</span><span>(</span><span>metrics</span><span>,</span> <span>fn</span> <span>instance</span> <span>-&gt;</span>
        <span>%</span><span>{</span>
          <span>name: </span><span>instance</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span>
          <span>project: </span><span>instance</span><span>.</span><span>data</span><span>.</span><span>project</span><span>,</span>
          <span>timestamp: </span><span>fetch_timestamp</span><span>,</span>
          <span>data: </span><span>Map</span><span>.</span><span>get</span><span>(</span><span>instance</span><span>.</span><span>data</span><span>.</span><span>state</span><span>,</span> <span>&#34;cpu&#34;</span><span>)</span>
        <span>}</span>
      <span>end</span><span>)</span>

    <span>previous_network_metrics</span> <span>=</span>
      <span>Enum</span><span>.</span><span>map</span><span>(</span><span>metrics</span><span>,</span> <span>fn</span> <span>instance</span> <span>-&gt;</span>
        <span>%</span><span>{</span>
          <span>name: </span><span>instance</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span>
          <span>project: </span><span>instance</span><span>.</span><span>data</span><span>.</span><span>project</span><span>,</span>
          <span>timestamp: </span><span>fetch_timestamp</span><span>,</span>
          <span>data: </span><span>Map</span><span>.</span><span>get</span><span>(</span><span>instance</span><span>.</span><span>data</span><span>.</span><span>state</span><span>,</span> <span>&#34;network&#34;</span><span>)</span>
        <span>}</span>
      <span>end</span><span>)</span>

    <span>state</span> <span>=</span>
      <span>state</span>
      <span>|&gt;</span> <span>Map</span><span>.</span><span>put</span><span>(</span><span>:demand</span><span>,</span> <span>current_demand</span><span>)</span>
      <span>|&gt;</span> <span>Map</span><span>.</span><span>put</span><span>(</span><span>:last_fetched_timestamp</span><span>,</span> <span>fetch_timestamp</span><span>)</span>
      <span>|&gt;</span> <span>Map</span><span>.</span><span>put</span><span>(</span><span>:previous_cpu_metrics</span><span>,</span> <span>previous_cpu_metrics</span><span>)</span>
      <span>|&gt;</span> <span>Map</span><span>.</span><span>put</span><span>(</span><span>:previous_network_metrics</span><span>,</span> <span>previous_network_metrics</span><span>)</span>
      <span>|&gt;</span> <span>Map</span><span>.</span><span>put</span><span>(</span><span>:cycle</span><span>,</span> <span>state</span><span>.</span><span>cycle</span> <span>+</span> <span>1</span><span>)</span>

    <span>state</span> <span>=</span>
      <span>if</span> <span>rem</span><span>(</span><span>state</span><span>.</span><span>cycle</span><span>,</span> <span>4</span><span>)</span> <span>==</span> <span>0</span> <span>do</span>
        <span>Map</span><span>.</span><span>put</span><span>(</span><span>state</span><span>,</span> <span>:cpu_60_metrics</span><span>,</span> <span>previous_cpu_metrics</span><span>)</span>
      <span>else</span>
        <span>state</span>
      <span>end</span>

    <span>state</span> <span>=</span>
      <span>if</span> <span>rem</span><span>(</span><span>state</span><span>.</span><span>cycle</span><span>,</span> <span>20</span><span>)</span> <span>==</span> <span>0</span> <span>do</span>
        <span>Map</span><span>.</span><span>put</span><span>(</span><span>state</span><span>,</span> <span>:cpu_300_metrics</span><span>,</span> <span>previous_cpu_metrics</span><span>)</span>
      <span>else</span>
        <span>state</span>
      <span>end</span>

    <span>state</span> <span>=</span>
      <span>if</span> <span>rem</span><span>(</span><span>state</span><span>.</span><span>cycle</span><span>,</span> <span>60</span><span>)</span> <span>==</span> <span>0</span> <span>do</span>
        <span>Map</span><span>.</span><span>put</span><span>(</span><span>state</span><span>,</span> <span>:cpu_900_metrics</span><span>,</span> <span>previous_cpu_metrics</span><span>)</span>
      <span>else</span>
        <span>state</span>
      <span>end</span>

    <span>{</span><span>messages</span><span>,</span> <span>state</span><span>}</span>
  <span>end</span>
  
<span>end</span>
</code></pre>
<p>In essence this is where all the magic of data collection happens. We call the <code>Metrics.for_instances()</code> function. This <a href="https://github.com/upmaru/uplink/blob/develop/lib/uplink/metrics/instance.ex#L7">call wraps</a> all the calls to LXD and returns a list of instances with all the metrics attached. You&#39;ll notice that we need to collect and store the previous metrics as well this is because for CPU and Networking traffic we need to compute the difference across time. For the CPU metrics all we get is a single number. That number is the number of CPU usage time in nanoseconds.</p>
<h3>Computing Usage</h3>
<p>We can use the difference between the two usage to compute the CPU usage.</p>
<pre><code translate="no"><span>defp</span> <span>cpu_percentage</span><span>(</span><span>cores</span><span>,</span> <span>time_diff_seconds</span><span>,</span> <span>earlier_usage</span><span>,</span> <span>later_usage</span><span>)</span> <span>do</span>
  <span>available_compute</span> <span>=</span> <span>cores</span> <span>*</span> <span>time_diff_seconds</span> <span>*</span> <span>:math</span><span>.</span><span>pow</span><span>(</span><span>10</span><span>,</span> <span>9</span><span>)</span>

  <span>(</span><span>later_usage</span> <span>-</span> <span>earlier_usage</span><span>)</span> <span>/</span> <span>available_compute</span>
<span>end</span>
</code></pre>
<h3>Updating the cpu metrics</h3>
<p>You&#39;ll notice that we conditionally update the <code>cpu_x_metrics</code> based on which cycle we&#39;re in. The reason for the numbers <code>4</code>, <code>20</code> and <code>60</code> is that we want to replace those metrics only if that many cycle has passed. In our code we are polling for metrics every 15 seconds. So to be able to compute the difference for <code>load 1</code> which is the system load for 1 minute we replace the value on every 4th cycle. This gives us the ability to compute the difference on a 1 minute interval. Same goes for <code>20</code> and <code>60</code>, if each of our interval is 15 seconds <code>15 * 20 = 300 secs = 5 mins</code>. You get the idea.</p>
<p>Once we&#39;ve transformed the message we return the tuple <code>{messages, state}</code> back to the caller.</p>
<h2>Transforming the Metrics</h2>
<p>In the code above you&#39;ll notice there is a call to <code>transform_metrics/2</code>. Let&#39;s take a look at that function and see what&#39;s inside.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  
  <span>defp</span> <span>transform_metrics</span><span>(</span><span>metrics</span><span>,</span> <span>%</span><span>{</span>
          <span>previous_cpu_metrics: </span><span>previous_cpu_metrics</span><span>,</span>
          <span>previous_network_metrics: </span><span>previous_network_metrics</span><span>,</span>
          <span>cpu_60_metrics: </span><span>cpu_60_metrics</span><span>,</span>
          <span>cpu_300_metrics: </span><span>cpu_300_metrics</span><span>,</span>
          <span>cpu_900_metrics: </span><span>cpu_900_metrics</span><span>,</span>
          <span>cycle: </span><span>cycle</span>
        <span>}</span><span>)</span> <span>do</span>
    <span>metrics</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>metric</span> <span>-&gt;</span>
      <span>previous_cpu_metric</span> <span>=</span>
        <span>Enum</span><span>.</span><span>find</span><span>(</span>
          <span>previous_cpu_metrics</span><span>,</span>
          <span>&amp;</span><span>find_matching_previous</span><span>(</span><span>&amp;</span><span>1</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>project</span><span>)</span>
        <span>)</span>

      <span>previous_network_metric</span> <span>=</span>
        <span>Enum</span><span>.</span><span>find</span><span>(</span>
          <span>previous_network_metrics</span><span>,</span>
          <span>&amp;</span><span>find_matching_previous</span><span>(</span><span>&amp;</span><span>1</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>project</span><span>)</span>
        <span>)</span>

      <span>cpu_60_metric</span> <span>=</span>
        <span>Enum</span><span>.</span><span>find</span><span>(</span>
          <span>cpu_60_metrics</span><span>,</span>
          <span>&amp;</span><span>find_matching_previous</span><span>(</span><span>&amp;</span><span>1</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>project</span><span>)</span>
        <span>)</span>

      <span>cpu_300_metric</span> <span>=</span>
        <span>Enum</span><span>.</span><span>find</span><span>(</span>
          <span>cpu_300_metrics</span><span>,</span>
          <span>&amp;</span><span>find_matching_previous</span><span>(</span><span>&amp;</span><span>1</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>project</span><span>)</span>
        <span>)</span>

      <span>cpu_900_metric</span> <span>=</span>
        <span>Enum</span><span>.</span><span>find</span><span>(</span>
          <span>cpu_900_metrics</span><span>,</span>
          <span>&amp;</span><span>find_matching_previous</span><span>(</span><span>&amp;</span><span>1</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>name</span><span>,</span> <span>metric</span><span>.</span><span>data</span><span>.</span><span>project</span><span>)</span>
        <span>)</span>

      <span>%</span><span>{</span>
        <span>metric: </span><span>metric</span><span>,</span>
        <span>cycle: </span><span>cycle</span><span>,</span>
        <span>previous_network_metric: </span><span>previous_network_metric</span><span>,</span>
        <span>previous_cpu_metric: </span><span>previous_cpu_metric</span><span>,</span>
        <span>cpu_60_metric: </span><span>cpu_60_metric</span><span>,</span>
        <span>cpu_300_metric: </span><span>cpu_300_metric</span><span>,</span>
        <span>cpu_900_metric: </span><span>cpu_900_metric</span>
      <span>}</span>
    <span>end</span><span>)</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>&amp;</span><span>transform_message</span><span>/</span><span>1</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre>
<p>All this function is doing is taking the metrics and matching them up to the individual instance metrics. By matching on the <code>name</code> and <code>project</code> of the instance. In LXD you can isolate your instances by project, this is like namespacing in kubernetes. We then call the <code>transform_message/1</code> which basically outputs <code>%Broadway.Message{}</code> which is what broadway expects.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Producer</span> <span>do</span>
  
  <span>defp</span> <span>transform_message</span><span>(</span><span>message</span><span>)</span> <span>do</span>
    <span>%</span><span>Broadway.Message</span><span>{</span>
      <span>data: </span><span>message</span><span>,</span>
      <span>acknowledger: </span><span>Broadway.NoopAcknowledger</span><span>.</span><span>init</span><span>(</span><span>)</span>
    <span>}</span>
  <span>end</span>
<span>end</span>
</code></pre>
<p>For our case we pass the <code>Broadway.NoopAcknowledger.init()</code> as the acknowledger because there is nothing to acknowledge. To see the full example you can head over to the <a href="https://github.com/upmaru/uplink/blob/develop/lib/uplink/metrics/producer.ex">github repository</a>.</p>
<h2>Implementing the Broadway Pipeline</h2>
<p>Now that we&#39;ve done the hardwork of collecting and transforming the data, next we need to ship it using the pipeline. The pipleine is a lot simpler let&#39;s take a look at the module.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Pipeline</span> <span>do</span>
  <span>use</span> <span>Broadway</span>

  <span>alias</span> <span>Broadway.Message</span>

  
  <span>def</span> <span>handle_message</span><span>(</span><span>,</span> <span>%</span><span>Message</span><span>{</span><span>data: </span><span>data</span><span>}</span> <span>=</span> <span>message</span><span>,</span> <span>)</span> <span>do</span>
    <span>%</span><span>{</span>
      <span>metric: </span><span>instance_metric</span><span>,</span>
      <span>previous_cpu_metric: </span><span>previous_cpu_metric</span><span>,</span>
      <span>previous_network_metric: </span><span>previous_network_metric</span><span>,</span>
      <span>cpu_60_metric: </span><span>cpu_60_metric</span><span>,</span>
      <span>cpu_300_metric: </span><span>cpu_300_metric</span><span>,</span>
      <span>cpu_900_metric: </span><span>cpu_900_metric</span>
    <span>}</span> <span>=</span> <span>data</span>

    <span>memory</span> <span>=</span> <span>Document</span><span>.</span><span>memory</span><span>(</span><span>instance_metric</span><span>)</span>
    <span>cpu</span> <span>=</span> <span>Document</span><span>.</span><span>cpu</span><span>(</span><span>instance_metric</span><span>,</span> <span>previous_cpu_metric</span><span>)</span>
    <span>uptime</span> <span>=</span> <span>Document</span><span>.</span><span>uptime</span><span>(</span><span>instance_metric</span><span>)</span>
    <span>filesystem</span> <span>=</span> <span>Document</span><span>.</span><span>filesystem</span><span>(</span><span>instance_metric</span><span>)</span>
    <span>diskio</span> <span>=</span> <span>Document</span><span>.</span><span>diskio</span><span>(</span><span>instance_metric</span><span>)</span>
    <span>network</span> <span>=</span> <span>Document</span><span>.</span><span>network</span><span>(</span><span>instance_metric</span><span>,</span> <span>previous_network_metric</span><span>)</span>

    <span>load</span> <span>=</span>
      <span>Document</span><span>.</span><span>load</span><span>(</span><span>instance_metric</span><span>,</span> <span>%</span><span>{</span>
        <span>cpu_60_metric: </span><span>cpu_60_metric</span><span>,</span>
        <span>cpu_300_metric: </span><span>cpu_300_metric</span><span>,</span>
        <span>cpu_900_metric: </span><span>cpu_900_metric</span>
      <span>}</span><span>)</span>

    <span>data</span> <span>=</span> <span>%</span><span>{</span>
      <span>memory: </span><span>memory</span><span>,</span>
      <span>cpu: </span><span>cpu</span><span>,</span>
      <span>uptime: </span><span>uptime</span><span>,</span>
      <span>filesystem: </span><span>filesystem</span><span>,</span>
      <span>diskio: </span><span>diskio</span><span>,</span>
      <span>network: </span><span>network</span><span>,</span>
      <span>load: </span><span>load</span>
    <span>}</span>

    <span>Message</span><span>.</span><span>put_data</span><span>(</span><span>message</span><span>,</span> <span>data</span><span>)</span>
  <span>end</span>

  
<span>end</span>
</code></pre>
<p>The goal of this module is to generate documents that are in the format expected by <code>Elasticsearch</code> and simply send the data using the bulk api available in Elasticsearch.</p>
<p>The main workload in the pipeline is it passes the message from the <code>Producer</code> into the <code>Document</code> module and generates the document for <code>:memory</code>, <code>:cpu</code>, <code>:uptime</code>, <code>:filesystem</code>, <code>:diskio</code>, <code>:network</code>, and <code>:load</code>. The next part is the <code>handle_batch</code> which is where we actually ship data to elastic.</p>
<pre><code translate="no"><span>defmodule</span> <span>Uplink.Metrics.Pipeline</span> <span>do</span>
  
  <span>def</span> <span>handle_batch</span><span>(</span><span>,</span> <span>messages</span><span>,</span> <span>,</span> <span>context</span><span>)</span> <span>do</span>
    <span>documents</span> <span>=</span> <span>to_ndjson</span><span>(</span><span>messages</span><span>)</span>
    <span>monitors</span> <span>=</span> <span>Pipelines</span><span>.</span><span>get_monitors</span><span>(</span><span>context</span><span>)</span>

    <span>Logger</span><span>.</span><span>info</span><span>(</span><span>&#34;[Metrics.Pipeline] pushing <span>#{</span><span>DateTime</span><span>.</span><span>utc_now</span><span>(</span><span>)</span><span>}</span>&#34;</span><span>)</span>

    <span>monitors</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>monitor</span> <span>-&gt;</span>
      <span>Metrics</span><span>.</span><span>push!</span><span>(</span><span>monitor</span><span>,</span> <span>documents</span><span>)</span>
    <span>end</span><span>)</span>

    <span>messages</span>
  <span>end</span>

  <span>defp</span> <span>to_ndjson</span><span>(</span><span>messages</span><span>)</span> <span>do</span>
    <span>documents</span> <span>=</span>
      <span>Enum</span><span>.</span><span>flat_map</span><span>(</span><span>messages</span><span>,</span> <span>&amp;</span><span>to_entry</span><span>/</span><span>1</span><span>)</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>&amp;</span><span>Jason</span><span>.</span><span>encode!</span><span>/</span><span>1</span><span>)</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>join</span><span>(</span><span>&#34;<span>\n</span>&#34;</span><span>)</span>

    <span>documents</span> <span>&lt;&gt;</span> <span>&#34;<span>\n</span>&#34;</span>
  <span>end</span>

  <span>defp</span> <span>to_entry</span><span>(</span><span>%</span><span>Message</span><span>{</span><span>}</span> <span>=</span> <span>message</span><span>)</span> <span>do</span>
    <span>dataset</span> <span>=</span>
      <span>message</span><span>.</span><span>data</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>to_list</span><span>(</span><span>)</span>
      <span>|&gt;</span> <span>Enum</span><span>.</span><span>reject</span><span>(</span><span>fn</span> <span>{</span><span>,</span> <span>value</span><span>}</span> <span>-&gt;</span>
        <span>is_nil</span><span>(</span><span>value</span><span>)</span>
      <span>end</span><span>)</span>

    <span>dataset</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span><span>flat_map</span><span>(</span><span>&amp;</span><span>build_request</span><span>/</span><span>1</span><span>)</span>
  <span>end</span>

  <span>defp</span> <span>build_request</span><span>(</span><span>{</span><span>type</span><span>,</span> <span>data</span><span>}</span><span>)</span> <span>when</span> <span>is_list</span><span>(</span><span>data</span><span>)</span> <span>do</span>
    <span>index</span> <span>=</span> <span>Metrics</span><span>.</span><span>index</span><span>(</span><span>type</span><span>)</span>

    <span>Enum</span><span>.</span><span>reduce</span><span>(</span><span>data</span><span>,</span> <span>[</span><span>]</span><span>,</span> <span>fn</span> <span>entry</span><span>,</span> <span>acc</span> <span>-&gt;</span>
      <span>metadata</span> <span>=</span> <span>%</span><span>{</span><span>&#34;create&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span><span>&#34;_index&#34;</span> <span>=&gt;</span> <span>index</span><span>}</span><span>}</span>

      <span>[</span><span>metadata</span><span>,</span> <span>entry</span> <span>|</span> <span>acc</span><span>]</span>
    <span>end</span><span>)</span>
  <span>end</span>

  <span>defp</span> <span>build_request</span><span>(</span><span>{</span><span>type</span><span>,</span> <span>data</span><span>}</span><span>)</span> <span>when</span> <span>is_map</span><span>(</span><span>data</span><span>)</span> <span>do</span>
    <span>index</span> <span>=</span> <span>Metrics</span><span>.</span><span>index</span><span>(</span><span>type</span><span>)</span>
    <span>metadata</span> <span>=</span> <span>%</span><span>{</span><span>&#34;create&#34;</span> <span>=&gt;</span> <span>%</span><span>{</span><span>&#34;_index&#34;</span> <span>=&gt;</span> <span>index</span><span>}</span><span>}</span>

    <span>[</span><span>metadata</span><span>,</span> <span>data</span><span>]</span>
  <span>end</span>
<span>end</span>
</code></pre>
<p>All we&#39;re doing here is generating the <code>ndjson</code> format which is essentially json encoded records delimited by <code>\n</code>. You&#39;ll notice that there is a <code>monitors = Pipeline.get_monitors(context)</code> call. This retrieves the monitors from <code>instellar</code> the core module that stores the credentials for pushing data to elastic. We will write another blog post on that in the near future.</p>
<p>That&#39;s essentially it. There is also another part not covered here which is generating the document in the format expected by elasticsearch. Feel free to checkout the <a href="https://github.com/upmaru/uplink/blob/develop/lib/uplink/metrics/pipeline.ex">source code</a> to see how everything fits together.</p>
<h2>Closing thoughts</h2>
<p>Overall we found that doing things this way was really beneficial since it means we don&#39;t need to install anything on our customer&#39;s cluster. We collect, transform and ship data to an endpoint without having to worry about backpressure and handling all the details of a data shipper.</p>
<div>
  <div>
    
    <div>
      <h5>LXD vs K8s</h5>
      <p>While in this example we extracted data from an LXD cluster, nothing stops us from doing the same with a kubernetes cluster. Kubernetes has the <code>cadvisor</code> api which also gives you alot of these metrics.</p>
    </div>
  </div>
</div>
<p>Next we can just query and use this data for lots of things for example alerts, anomaly detection, usage prediction and recommendation systems.</p>
<p>If you&#39;d like to try this out you can <a href="https://opsmaru.com/auth/users/register">sign up</a> create a cluster and login to your own uplink instance to run some of these commands.</p>

            </div></div>
  </body>
</html>
