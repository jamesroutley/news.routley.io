<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://steve.hollasch.net/cgindex/math/matrix/column-vec.html">Original</a>
    <h1>Column Vectors vs. Row Vectors</h1>
    
    <div id="readability-page-1" class="page">



<p>
The following are excerpts from an interesting Usenet discussion about the
differences in convention between using column vectors or row vectors.  This
drives the 4x4 matrix representation as well, since vector-matrix
multiplication is represented with the matrix on the left for column vectors,
and on the right for row vectors.  The 4x4 matrices in each case are the
transpose of the other convention.

</p><p>
Put another way, if you&#39;re using row vectors, your 4x4 translation components
are in the bottom row.  If you&#39;re using column vectors, your 4x4 translation
components are in the right column.

</p><p>
Generally, in 3D graphics, you have to keep on your toes, since this convention
varies from system to system.

</p>

<hr size="8"/><p>
<b>From</b>: segal@spud.asd.sgi.com (Mark Segal)</p><p>
I&#39;m surprised that this simple topic has generated so many posts.
I&#39;m the one responsible for the &#39;column-major ordering&#39; used in
OpenGL, so I&#39;ll try to explain what&#39;s going on to try to put this
discussion to rest.

</p><p>
First, there are two issues that seem to be confused.  One issue
is how matrices are stored in memory, and the other is whether one
treats vectors as rows of coordinates or as columns.

</p><p>
I&#39;ll dispense with the second issue first.  Recent mathematical
treatments of linear algebra and related fields invariably treat
vectors as columns (there are some technical reasons for this).
For some reason, this has not been the case in computer graphics,
where vectors were written as rows, thus transposing everything
from standard mathematical usage.  When I wrote the OpenGL spec,
I decided to do my part to right this heinous inconsistency.  Thus
the spec is written with vectors treated as columns, with a matrix
correspondingly applied on the left of a column.

</p><p>
The one difficulty was compatibility with the current GL, where
vectors had been written as rows.  So I come up with this
subterfuge: say that matrices in OpenGL are stored in column major
order.  The point is that you could rewrite the spec with everything
transposed (with vectors written as rows), and everything would be
exactly the same as it was, including the row major ordering of
matrices.

</p><p>
So we&#39;ve come to the second issue: how matrices are stored in memory.
If you treat vectors as columns, then in OpenGL matrices are stored
column major.  If you treat vectors as rows, then matrices are stored (as
they are in the current GL) row major.  That&#39;s all there is to it.
OpenGL documentation treats vectors as columns, so it will be simplest
for most people who use it to adopt this convention.  But it won&#39;t
affect any code you may have written to calculate matrices for the
current GL in any way.

</p><p>
To say without qualification that &#39;OpenGL stores matrices this way&#39;
is technically nonsense. OpenGL does nothing.  OpenGL DOCUMENTATION
assumes that vectors are columns therefore implying that matrices are
given column major, but you are free to take the alternate interpretation
if you wish.  It is also nonsense to say that the hardware (or an OpenGL
implementation) &#39;premultiples&#39; or &#39;postmultiplies&#39; (I could never remember
which was which anyway).  OpenGL applies a matrix (representing a
transformation) to a series of coordinates (representing a vector) using
the rules of matrix multiplication.  You may view this as performing the
multiplication c&#39; = Mc, where c and c&#39; are columns, or as r&#39; = rM(transpose)
where r and r&#39; are rows (and r=c(transpose) and r&#39;=c&#39;(transpose) ).
The two formulas represent the same calculation.

</p><p>
So, in spite of this lengthy explanation, I don&#39;t think that there is
actually any issue here, since there is no change from the current GL,
and since a programmer is free to view matrices and vectors as she pleases.

</p><hr size="6"/>

<b>From</b>: erich@eye.com (Eric Haines)</div>
  </body>
</html>
