<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://hannahilea.com/blog/botfly-test">Original</a>
    <h1>The Botfly Test: Characterizing parasitic automated behavior in online communities</h1>
    
    <div id="readability-page-1" class="page"><div>
      <nav role="navigation">
        @hannahilea:
        <a href="https://hannahilea.com/">home</a> | <a href="https://hannahilea.com/projects">projects</a> |
        <a href="https://hannahilea.com/">blog</a>
      </nav>

      
      <p>3 Mar 2025</p>
      <p>
        I recently encountered non-transparent automated behavior in a tech-community forum, and it really, <em>really</em> annoyed me. After confirming that my spidey senses were correct, and that this user was actively, regularly, and
        non-transparently performing and benefiting from automated interactions in the forum, I spent some time trying to figure out why exactly I was <em>so</em> annoyed by it.
      </p>
      <p>
        I came up with a basic set of <a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bechdel_test">Bechdel Test</a>-style criteria for determining if specific automated behavior (i.e., bot activity) is
        obnoxious within the community it inhabits.
      </p>
      <div>
        <div>
          <h3>The Botfly Test</h3>
          <p>When a user programs an account to interact in an online community in automated ways:</p>
          <ol type="1">
            <li>
              <p>Is the account <strong>transparent</strong> about being a bot when it performs an action?</p>
            </li>
            <li>
              <p>
                Does the account provide a <strong>prosocial</strong><a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> service to the community it inhabits?
              </p>
            </li>
            <li>
              <p>Is the user <strong>unselfish</strong> in how they benefit from the value generated by their automated account?</p>
            </li>
          </ol>
          <p>If the answer to one or more of these is “no,” the user fails the test: through the bot they’ve programmed, they are behaving parasitically within the community.</p>
        </div>
      </div>
      <p>The Botfly Test provides <em>minimum standards</em> for demonstrating prosocial community behavior. A bot that passes this test isn’t necessarily of benefit to the community, but a bot that fails this test definitely isn’t.</p>
      <p>Or, more personally: if a bot passes the test, it may annoy me—if it fails the test, it almost CERTAINLY annoys me.</p>
      <p>Notably:</p>
      <ul>
        <li>
          <p><strong>If all answers aren’t a definitive “yes,” it fails the test.</strong></p>
          <p>Some of these questions are clearly open to interpretation, and/or depend on the community at hand. If you have to jump through hoops to explain why a bot passes, it does not pass.</p>
          <p>Also, the questions are ordered from most to least obvious and objective, to enable failing fast.</p>
        </li>
        <li>
          <p><strong>Community context matters: Automated behavior that passes this test in one community may fail in another.</strong></p>
          <p>
            The norms of a given community—both the written guidelines and typical human-human and human-bot interactions in the community—affect the answers to the Botfly Test. The criteria of the Botfly Test must therefore be applied to a
            bot’s actions <strong>as relate to a given community or sub-community</strong>.
          </p>
          <p>
            For example, sufficient transparency in one community (“including ‘bot’ in the username”) may not be sufficient in another; a “service” to one community might be an annoyance in another; the value (karma/points/etc) accrued by
            actions may boost an account’s reach in one community but have no effect in another.
          </p>
        </li>
        <li>
          <p>
            <strong>The Botfly Test is a <em>starting point</em> for assessing antisocial automated behavior. Passing it does not mean the bot should continue to exist in its current form.</strong>
          </p>
          <p>For example, a bot that is not deemed a Botfly in one community may—with the same actions!—be actively be causing harm in another community. This is still bad, and should be addressed!</p>
        </li>
        <li>
          <p><strong>This test is designed for communities that are themselves prosocial.</strong></p>
          <p>You know what doesn’t annoy me? People using their powers of programming and automation for good, to disrupt harmful and cruel activities.</p>
        </li>
      </ul>
      <p>
        The choice of test name is more than just a cute use of a word that contains “bot”; <a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Botfly">botflies</a> are a type of parasitic fly who lay their
        larvae to incubate and hatch under the skin of mammals—human and non-human alike. While they aren’t deadly, they are prettttttty gross, and a good response to encountering one is to evict it. Identifying and removing botfly larvae
        improves the health of the affected individual and therefore also the overall health of its community.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>
      </p>
      <p>For the sake of you, dear reader, I am not including a single photo of a botfly in this post—larva or otherwise.</p>
      <h2 id="case-study-a-hackernews-botfly">Case study: A HackerNews botfly</h2>
      <p>
        The situation that prompted the creation of this test: a <a target="_blank" rel="noreferrer noopener" href="https://news.ycombinator.com/news">HackerNews (HN)</a> user is automatically cross-posting content to HN from a smaller tech
        community’s feed (<a target="_blank" rel="noreferrer noopener" href="https://lobste.rs/">lobste.rs</a>). Within minutes of a new post being made to lobste.rs, this account reposts it to HackerNews. This account does interact
        manually in the community at well, leaving the occasional non-automated comment.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>
        <a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>
      </p>
      <p>How does this user’s automated behavior in the HN community score?</p>
      <ol type="1">
        <li>
          <p><strong>Transparent?</strong> FAIL.</p>
          <ul>
            <li>The username does not disclose that it is a bot.</li>
            <li>The profile describes the human author, including links to their associated company, without disclosing that any/most of the account’s behavior is automated.</li>
          </ul>
        </li>
        <li>
          <p><strong>Prosocial?</strong> SOFT PASS.</p>
          <ul>
            <li>
              The cross-posted links are arguably of interest to the HN community,<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> providing the service of sharing relevant content.
            </li>
            <li>
              As far as I can tell, the automation does not explicitly violate any HN community guidelines.<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>
            </li>
          </ul>
        </li>
      </ol>
      <ol start="3" type="1">
        <li>
          <p><strong>Unselfish?</strong> FAIL.</p>
          <ul>
            <li>
              The early-and-often automated posting has yielded a wildly high karma score.<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a> While HN says<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a>
              that karma does not directly contribute to post ranking (and therefore high-visibility presence on the front page of HN), it does seem to have some effect on the reach of a user’s other interactions on the site (e.g., comment
              rankings, flagging, etc). This gives this user inflated influence relative to community peers who are not also automating their actions, especially relevant when the account is used to post the occasional manual comment.
            </li>
          </ul>
        </li>
      </ol>
      <p>A very clear case of Botflyism!</p>
      <p>
        If the user wants to course-correct, they could do a few things:<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a>
      </p>
      <ul>
        <li>Retire the existing account in favor of two new accounts, one which they use for their manual interactions in the HN community (voting, commenting, posting, etc), the other of which handles the bot actions.</li>
        <li>Make the username of the bot account reflect that it is a bot (<code>lobsters_bot</code>, etc), and describe the automation behavior in the account’s profile.</li>
        <li>
          Bonus: Add some human-scale pauses into the automated behavior, to give human users who want to cross-post a chance to do that. There is no time-sensitive reason to cross-post; might as well do it batched once a day, or 24-hours
          after an original lobste.rs post has been published.<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>
        </li>
      </ul>
      <h2 id="faqs">FAQs</h2>
      <ul>
        <li>
          <p><strong>Q:</strong> <em>Why does it matter if a user in a community has pre-programmed automated interactions in the form of a bot? I think that’s totally fine!</em><br/></p>
          <p><strong>A:</strong> Yeah, that’s a valid question. I think it comes down to trust, scale of influence, and harm mitigation.</p>
          <p>
            Automation allows activity to be performed on a super-human scale, and the result of that activity—a flood of comments in support of a specific idea, downvoting any post that is counter to the bot author’s interests,
            etc—influences the very real feelings and very real downstream actions of the rest of the community it inhabits.
          </p>
          <div>
            <figure>
              <img src="https://hannahilea.com/blog/assets/Internet_dog.jpg" alt="New Yorker cartoon drawing of a dog sitting at a computer, with caption below that reads &#39;On the Internet, no one knows you&#39;re a dog&#39;."/>
              <figcaption>Peter Steiner for the New Yorker, 1993 <a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">[source]</a></figcaption>
            </figure>
          </div>
          <p>
            While <a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">on the internet, nobody knows you’re a dog</a>, folks interacting with you in an environment
            specifically designed to foster communication—forums! social media! etc!—should be able to reasonably assume that the set of users they’re conversing with are unique maybe-dogs, rather than a <strong>single</strong> maybe-dog
            who has programmed a bunch of computers to do its bidding.
          </p>
          <div>
            <figure>
              <img src="https://hannahilea.com/blog/assets/Internet_bots_dog.jpg" alt="Remixed verion of the above cartoon, showing one dog sitting at a bunch of computers, with caption below that reads &#39;On the Internet, no one knows a bunch of you are the same dog&#39;."/>
              <!-- <figcaption></figcaption> -->
            </figure>
          </div>
          <p>Specifically, I agree with HN’s <a target="_blank" rel="noreferrer noopener" href="https://news.ycombinator.com/newsguidelines.html">community user guidance</a>:</p>
          <blockquote>
            <p>“HN is a community—–users should have an identity that others can relate to.”</p>
          </blockquote>
          <p>I think this applies to any other community that is based around conversational human interactions.</p>
        </li>
        <li>
          <p>
            <strong>Q:</strong> <em>So I’ve unintentionally <strong>created</strong> a bot that fails the Botfly Test—what now?</em><br/>
          </p>
          <p><strong>A:</strong> Easy: Disable it. Bam. You know what’s better than introducing an annoying and potentially harmful agent into a community? Not introducing an annoying and potentially harmful agent into a community.</p>
        </li>
        <li>
          <p><strong>Q:</strong> <em>No, but, like, I really think my bot should continue to exist, and I swear I am acting in good faith here?</em><br/></p>
          <p>
            <strong>A:</strong> Cool, figure out which pieces of the test it fails, and make them pass: Be transparent that your bot is a bot, make sure it isn’t stepping on toes or causing harm, tweak the parameters of what it posts or how
            often it posts or the language of how it posts, etc. Make sure that any potential conflict-of-interest behavior that could be perceived to benefit you is split out so that it does not benefit you, e.g. by creating separate
            accounts for your manual vs automated interactions.
          </p>
        </li>
        <li>
          <p>
            <strong>Q:</strong> <em>So I’ve <strong>found</strong> a bot that fails the Botfly Test—what now? </em><br/>
          </p>
          <p><strong>A:</strong> Well, the test is about annoyance. So maybe you just be annoyed? ¯\_(ツ)_/¯</p>
          <p>More seriously: reach out to the author—if you can identify them—and kindly let them know, and if they are well-intentioned and acting in good faith, they will address it.</p>
          <p>Or if it is more than just annoying—causing harm or otherwise violating community practices—take it to a mod.</p>
          <p>Or make sure the rest of the community is aware that a user that they have been <em>responding</em> to as if it were an individual human posting</p>
          <p>
            …or obsess about it and then write up a ridiculous number of words about the situation and then delete most of them and turn the remainder into a set of criteria that you share as a blog post, thereby soothing your peevish soul?
          </p>
        </li>
      </ul>
      <h2 id="bonus-anecdote">Bonus anecdote</h2>
      <p>When I was a kid my family adopted a pair of barn kittens, and the kittens both had botflies. Never fear, once the botflies had been removed the kittens grew up into healthy, cute, pro-social kitties!</p>
      <p>Here is Adelaide, shortly after her botfly was removed:</p>
      <figure>
        <img src="https://hannahilea.com/blog/assets/addy.png" alt="Photo of adorably tiny kitten"/>
      </figure>
      <p>Now go forth, and don’t be a jerk on the internet. Or if you’re going to be a jerk, do it on a human scale. Or if you’re going to do it on a super-human scale, at least be transparent about it.</p>
      
      <hr/>
      <ul>
        <li>Created: 2025-03-3</li>
        <li>Last updated: 2025-03-3</li>
        <li>Type: Musing</li>
        <li>Tags: spite-driven-development, bechdel-test</li>
      </ul>
      
    </div></div>
  </body>
</html>
