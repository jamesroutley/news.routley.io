<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.reverberate.org/2020/05/29/hoares-rebuttal-bubble-sorts-comeback.html">Original</a>
    <h1>Hoare’s Rebuttal and Bubble Sort’s Comeback</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em><strong>Editor’s note</strong>: For this blog entry I welcome my friend and colleague Gerben Stavenga
as a guest author.</em></p>

<p>Recently Andrei Alexandrescu published an interesting
<a href="https://dlang.org/blog/2020/05/14/lomutos-comeback/">post</a> about optimizing
QuickSort using the Lomuto partition scheme. The essence of that post is that
for many situations the performance of QuickSort is completely dominated by
branch mispredicts and that a big speed up can be achieved by writing
branchless code. This has been observed by many, and various branchless
sorting routines have been proposed. Andrei observed that from the two well
known QuickSort partitioning schemes Lomuto is easily implemented branchless,
and this indeed performs much better for sorting small primitives. I recently
experimented with similar ideas but took them in a different but interesting
direction. I discovered that a hybrid of the Hoare and Lomuto schemes can 
deliver a large improvement even compared with branchless Lomuto. And the 
final surprise is that Bubble Sort takes the crown for small arrays. The key
to all these wins is exploiting instruction-level parallelism and reducing 
dependency chains.</p>



<p>Quicksort refers to a class of algorithms for sorting an array that all share the same outline</p>

<div><div><pre><code><span>void</span> <span>QuickSort</span><span>(</span><span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>right</span> <span>-</span> <span>left</span> <span>&gt;</span> <span>kCutOff</span><span>)</span> <span>{</span>
    <span>auto</span> <span>pivot</span> <span>=</span> <span>ChoosePivotElement</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>);</span>  <span>// Important but not focus here</span>
    <span>auto</span> <span>p</span> <span>=</span> <span>Partition</span><span>(</span><span>pivot</span><span>,</span> <span>left</span><span>,</span> <span>right</span><span>);</span>  <span>// The main work loop</span>
    <span>QuickSort</span><span>(</span><span>left</span><span>,</span> <span>p</span><span>);</span>
    <span>QuickSort</span><span>(</span><span>p</span><span>,</span> <span>right</span><span>);</span>  <span>// Tail call, ideally the largest sub-interval</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>SortSmallArray</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Countless variations exist varying in the choice of <code>kCutOff</code>, choice of the
sorting algorithm for the small arrays and choice of pivot element. These are
important for performance but the main work QuickSort performs is done in
the <code>Partition</code> function. There are two canonical schemes for implementing
<code>Partition</code>: the original Hoare scheme and the Lomuto scheme. The Hoare
partition scheme works by swapping elements that violate the partition property
from the front of the array with elements from the back of the array,
processing the array from the outside inwards converging on the partition point
somewhere in the middle.</p>

<div><div><pre><code><span>T</span><span>*</span> <span>HoarePartition</span><span>(</span><span>T</span> <span>pivot</span><span>,</span> <span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>)</span> <span>{</span>
  <span>while</span> <span>(</span><span>left</span> <span>&lt;</span> <span>right</span><span>)</span> <span>{</span>
     <span>left</span> <span>=</span> <span>ScanForward</span><span>(</span><span>pivot</span><span>,</span> <span>left</span><span>,</span> <span>right</span><span>);</span>
     <span>if</span> <span>(</span><span>left</span> <span>==</span> <span>right</span><span>)</span> <span>break</span><span>;</span>
     <span>right</span> <span>=</span> <span>ScanBackward</span><span>(</span><span>pivot</span><span>,</span> <span>left</span><span>,</span> <span>right</span><span>);</span>
     <span>if</span> <span>(</span><span>left</span> <span>==</span> <span>right</span><span>)</span> <span>break</span><span>;</span>
     <span>swap</span><span>(</span><span>*</span><span>left</span><span>,</span> <span>*</span><span>right</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>left</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>In contrast the Lomuto scheme processes the array from front to back,
maintaining a properly partitioned array for the elements processed so far at
each step.</p>

<div><div><pre><code><span>T</span><span>*</span> <span>LomutoPartition</span><span>(</span><span>T</span> <span>pivot</span><span>,</span> <span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>)</span> <span>{</span>
  <span>T</span><span>*</span> <span>p</span> <span>=</span> <span>left</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>it</span> <span>=</span> <span>left</span><span>;</span> <span>it</span> <span>&lt;</span> <span>right</span><span>;</span> <span>it</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>*</span><span>it</span> <span>&lt;</span> <span>pivot</span><span>)</span> <span>{</span>
      <span>std</span><span>::</span><span>swap</span><span>(</span><span>*</span><span>it</span><span>,</span> <span>*</span><span>p</span><span>);</span>   <span>// Could be a self-swap</span>
      <span>p</span><span>++</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>p</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>A remarkably simple loop, with an additional property that it’s stable with
respect to the ordering of the elements smaller than the pivot. It’s easy to
see that the above loop can be implemented without conditional branches. The
conditional swapping can be implemented by conditional moves and the
conditional pointer increase could be implemented as a unconditional <code>p += (*it
&lt; pivot)</code>. Andrei’s blog shows the performance gain of this simple branchless
loop over production quality implementations in various standard libraries.</p>



<p>Here I want to take the optimizations further and dive deeper into the
performance analysis of sorting algorithms. When conditional branching is
removed the performance of code tends to become much more stable and easier to
understand, data dependencies become key. We are going to analyse the code in
terms of a self explanatory pseudo-assembly code, where named variables should
be thought of as CPU registers and loads/stores to memory are made explicit. In
this notation the basic loop above becomes</p>

<div><div><pre><code><span>loop:</span>
<span>val</span> <span>=</span> <span>Load</span><span>(</span><span>it</span><span>)</span>              <span>// 1</span>
<span>prev_val</span> <span>=</span> <span>Load</span><span>(</span><span>p</span><span>)</span>          <span>// 2</span>
<span>is_smaller</span> <span>=</span> <span>val</span> <span>&lt;</span> <span>pivot</span>    <span>// 3</span>
<span>valnew</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>prev_val</span><span>,</span> <span>val</span><span>)</span>   <span>// 4</span>
<span>prev_val</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>val</span><span>,</span> <span>prev_val</span><span>)</span> <span>// 5</span>
<span>Store</span><span>(</span><span>it</span><span>,</span> <span>valnew</span><span>)</span>           <span>// 6</span>
<span>Store</span><span>(</span><span>p</span><span>,</span> <span>prev_val</span><span>)</span>          <span>// 7</span>
<span>p</span> <span>+=</span> <span>is_smaller</span>             <span>// 8</span>
<span>it</span><span>++</span>                        <span>// 9</span>
<span>if</span> <span>(</span><span>it</span> <span>&lt;</span> <span>right</span><span>)</span> <span>goto</span> <span>loop</span>
</code></pre></div></div>

<p>How would it run on a parallel out-of order CPU? As a first approximation we
can pretend that the CPU is arbitrarily parallel, ie. it can execute unlimited
instructions in parallel as long as the instructions are independent. What is
important to understand is the loop carried dependency chains. They determine
the minimum latency a loop could possibly run. In the above code you see that
the dependency between iterations of the loop are carried by <code>it</code> and <code>p</code>. Only
line 8 and 9 participate on the loop carried chain and both are single cycle
instructions.  So we determine that the loop could potentially run at a
throughput of 1 cycle per iteration.</p>

<center>
<img src="https://docs.google.com/drawings/d/e/2PACX-1vRAynXWaiSSZ6s3cBKOPoFo6eDfIa3FUmM7ODtwX_8BblTjOVMvGw_JnnlDJqZBjQ5fA8AHcnnzKfPo/pub?w=740"/>
</center>

<p>However this dependency analysis is not quite correct. There are also loads and
stores to memory. If you store something to a certain memory address and later
load from that address you must read the value of the previous store. That
means loads have dependencies on stores, or at least if the address overlaps.
Here <code>it</code> and <code>p</code> are dynamic values and for sure they can overlap, depicted by
the dashed lines in the diagram above. So let’s add the fact that there is a
dependency between the loads at line 1 and 2 on the stores of line 6 and 7.</p>

<center>
<img src="https://docs.google.com/drawings/d/e/2PACX-1vSZZnMmf6LSF4uaN-VFVghW4TztbhvBGlByk6Aqqkl60dNxR_MpCxii8DD2fKb6eIpirQdCKe_UhtK0/pub?w=740"/>
</center>

<p>This completely changes the game, now there is a long loop carried data
dependency, lines 6 and 7 depend on lines 4 and 5, which both depend on line 3
, which depend on the loads at lines 1 and 2, which potentially depend on the
stores at lines 6 and 7 of the previous iteration. If we count the cycles, we
get 5 cycles for the loads (loads itself can be done in parallel), 1 cycle for
the comparison, 1 cycle for the conditional move and 1 cycle for the store,
hence this loop will run ~8 cycles. A far cry from the 1 cycle iterations our
cursory discussion indicated.</p>

<p>Although it’s not possible to reorder stores and loads in general it’s
essential for performance of a CPU to do so. Let’s take a simple memcpy loop</p>

<div><div><pre><code><span>loop:</span>
<span>val</span> <span>=</span> <span>Load</span><span>(</span><span>it</span><span>)</span>
<span>Store</span><span>(</span><span>it</span> <span>+</span> <span>delta</span><span>,</span> <span>val</span><span>)</span>
<span>it</span><span>++</span>
<span>if</span> <span>(</span><span>it</span> <span>&lt;</span> <span>end</span><span>)</span> <span>goto</span> <span>loop</span>
</code></pre></div></div>

<p>If the load cannot be reordered with the previous store, this is a 5 + 1 = 6
cycle latency loop. However in memcpy it’s guaranteed that loads and stores
never overlap. If the CPU would instead reorder, the above loop would execute
with a throughput of one iteration per cycle. It’s execution would look like,
ignoring the instructions needed for control flow.</p>

<div><div><pre><code><span>val_0</span> <span>=</span> <span>Load</span><span>(</span><span>it_0</span><span>);</span> <span>it_1</span> <span>=</span> <span>it_0</span> <span>+</span> <span>1</span><span>;</span>    <span>// Cycle 1</span>
<span>val_1</span> <span>=</span> <span>Load</span><span>(</span><span>it_1</span><span>);</span> <span>it_2</span> <span>=</span> <span>it_1</span> <span>+</span> <span>1</span><span>;</span>    <span>// Cycle 2</span>
<span>val_2</span> <span>=</span> <span>Load</span><span>(</span><span>it_2</span><span>);</span> <span>it_3</span> <span>=</span> <span>it_2</span> <span>+</span> <span>1</span><span>;</span>    <span>// Cycle 3</span>
<span>val_3</span> <span>=</span> <span>Load</span><span>(</span><span>it_3</span><span>);</span> <span>it_4</span> <span>=</span> <span>it_3</span> <span>+</span> <span>1</span><span>;</span>    <span>// Cycle 4</span>
<span>// The value of the load at cycle 1 becomes available.</span>
<span>// From this point all instructions of the loop are executed each cycle.</span>
<span>val_4</span> <span>=</span> <span>Load</span><span>(</span><span>it_4</span><span>);</span> <span>it_5</span> <span>=</span> <span>it_4</span> <span>+</span> <span>1</span><span>;</span> <span>Store</span><span>(</span><span>val_0</span><span>);</span>    <span>// Cycle 5</span>
<span>val_5</span> <span>=</span> <span>Load</span><span>(</span><span>it_5</span><span>);</span> <span>it_6</span> <span>=</span> <span>it_5</span> <span>+</span> <span>1</span><span>;</span> <span>Store</span><span>(</span><span>val_1</span><span>);</span>    <span>// Cycle 6</span>
</code></pre></div></div>

<p>In practice most of the stores preceding a load in the instruction stream are
in fact to different addresses and it is possible to reorder loads in front of
stores. Therefore CPU’s do reorder loads in front of stores, which is called
speculative loading, however the effects of the load are only committed when
it’s verified no store has invalidated the speculative load. If a preceding
store, in effect, invalidates the load, execution is rolled back to the load
and the CPU starts over. One can imagine that this is very costly and very akin
to branch mispredicts. While a lot of stores and loads are to different
addresses, there are also plenty of stores and loads to the same address, think
about register spills for example. Therefore the CPU uses a prediction model
based on instruction address to determine if a load has a dependency on
previous stores. In general the CPU is pretty conservative, the cost of a wrong
reordering is very high. In the code above the CPU will encounter loads from
the same address as recent stores and will be hesitant to do the necessary
re-ordering.</p>

<h2 id="revisiting-the-lomuto-partition-scheme">Revisiting the Lomuto partition scheme</h2>

<p>Looking closer it’s the load from <code>p</code> that is problematic. The load from <code>it</code>
is in fact always from a different address than the previous stores.
Furthermore the load at <code>p</code> is also responsible for a lot of extra work in the
loop. It is necessary as otherwise the store at <code>p</code> will corrupt values in the
array. The values that are overwritten are values previously encountered in the
scan and are those elements that are larger than the pivot. If instead we would
save these values in a temporary buffer there is no need to swap.</p>

<div><div><pre><code><span>// Distributes the elements [left, right) into begin of left and from end of</span>
<span>// scratch buffer </span>
<span>T</span><span>*</span> <span>DistributeForward</span><span>(</span><span>T</span> <span>pivot</span><span>,</span> <span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>,</span> <span>T</span><span>*</span> <span>scratch</span><span>)</span> <span>{</span>
  <span>auto</span> <span>scratch_end</span> <span>=</span> <span>scratch</span> <span>+</span> <span>kScratchSize</span> <span>-</span> <span>1</span><span>;</span>
  <span>ptrdiff_t</span> <span>offset</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>it</span> <span>=</span> <span>left</span><span>;</span> <span>it</span> <span>&lt;</span> <span>right</span><span>;</span> <span>it</span><span>++</span><span>)</span> <span>{</span>
    <span>auto</span> <span>val</span> <span>=</span> <span>*</span><span>it</span><span>;</span>
    <span>bool</span> <span>is_larger</span> <span>=</span> <span>val</span> <span>&gt;=</span> <span>pivot</span><span>;</span>
    <span>auto</span> <span>dst</span> <span>=</span> <span>is_larger</span> <span>?</span> <span>scratch_end</span> <span>:</span> <span>it</span><span>;</span>
    <span>dst</span><span>[</span><span>offset</span><span>]</span> <span>=</span> <span>val</span><span>;</span>
    <span>offset</span> <span>-=</span> <span>is_larger</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>right</span> <span>+</span> <span>offset</span><span>;</span>
<span>}</span>

<span>T</span><span>*</span> <span>ModifiedLomutoPartition</span><span>(</span><span>T</span> <span>pivot</span><span>,</span> <span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>,</span> <span>T</span><span>*</span> <span>scratch</span><span>)</span> <span>{</span>
  <span>auto</span> <span>p</span> <span>=</span> <span>DistributeForward</span><span>(</span><span>pivot</span><span>,</span> <span>left</span><span>,</span> <span>right</span><span>,</span> <span>scratch</span><span>);</span>
  <span>// To complete the partition we need to copy the elements in scratch</span>
  <span>// to the end of the array.</span>
  <span>auto</span> <span>size</span> <span>=</span> <span>right</span> <span>-</span> <span>p</span><span>;</span>
  <span>memcpy</span><span>(</span><span>p</span><span>,</span> <span>scratch</span> <span>+</span> <span>kScratchSize</span> <span>-</span> <span>size</span><span>,</span> <span>size</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>));</span>
  <span>return</span> <span>p</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is a much simpler loop, only one load and one store per iteration. More
importantly the load will never clash with a previous store. This loop runs
much faster than the original loop, it’s not 1 cycle per iteration but 2.5
cycles on my machine. This is indicative that it’s saturating the ILP of the
CPU. Unfortunately the above code is not in-place anymore, it requires O(n)
additional memory for the scratch buffer.</p>

<center>
<img src="https://docs.google.com/drawings/d/e/2PACX-1vTOJvXw1e0spAQWGEdogAHPoHsRd0YAjDia9EeZs9s9b2RPiO_plokZH-Q3jiRjr7cAZsVG2aa6fR_v/pub?w=740"/>
</center>

<h2 id="the-elegant-hybrid">The elegant hybrid</h2>

<p>If instead we use a smallish fixed size temporary buffer, we can still use the
above code except we need to abort when the fixed buffer is full. What do we do
then? The function returned the partition point <code>p</code> where it left the loop. At
this point <code>[left, p)</code> have the correct elements smaller than pivot at the front
of the array. The scratch buffer is full with elements larger or equal to pivot
and <code>[p, p + kScratchSize)</code> contains information we don’t need anymore. The
idea is that we can do the same algorithm but backwards, we can use <code>[p, p +
kScratchSize)</code> as a temporary buffer. Notice how <code>DistributeForward()</code>
fills the scratch buffer from back to front; the backwards version would fill
the scratch from front to back. So performing <code>DistributeBackwards()</code> using the
interval  <code>[p, p + kScratchSize)</code> as scratch will neatly pack all smaller
elements encountered to the correct place. This continues until the scratch
space is full, but now a new scratch space at the end of the array opened up.
Wait, this looks like Hoare’s algorithm but hybridized with the Lomuto-inspired
distribute function.</p>

<div><div><pre><code><span>T</span><span>*</span> <span>ModifiedHoarePartition</span><span>(</span><span>T</span> <span>pivot</span><span>,</span> <span>T</span><span>*</span> <span>left</span><span>,</span> <span>T</span><span>*</span> <span>right</span><span>,</span> <span>T</span><span>*</span> <span>scratch</span><span>)</span> <span>{</span>
  <span>auto</span> <span>pleft</span> <span>=</span> <span>DistributeForward</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>pivot</span><span>,</span> <span>scratch</span><span>);</span>
  <span>if</span> <span>(</span><span>right</span> <span>-</span> <span>pleft</span> <span>&lt;=</span> <span>kScratchSize</span><span>)</span> <span>{</span>
    <span>auto</span> <span>size</span> <span>=</span> <span>right</span> <span>-</span> <span>pleft</span><span>;</span>
    <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>pleft</span><span>,</span> <span>scratch</span> <span>+</span> <span>kScratchSize</span> <span>-</span> <span>size</span><span>,</span> <span>size</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>));</span>
    <span>return</span> <span>pleft</span><span>;</span>
  <span>}</span>
  <span>left</span> <span>=</span> <span>pleft</span> <span>+</span> <span>kScratchSize</span><span>;</span>
  <span>T</span><span>*</span> <span>res</span><span>;</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>right</span> <span>=</span> <span>DistributeBackward</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>pivot</span><span>,</span> <span>left</span> <span>-</span> <span>kScratchSize</span><span>)</span>
        <span>-</span> <span>kScratchSize</span><span>;</span>
    <span>if</span> <span>(</span><span>right</span> <span>&lt;=</span> <span>left</span><span>)</span> <span>{</span>
      <span>res</span> <span>=</span> <span>right</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>left</span> <span>=</span> <span>DistributeForward</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>pivot</span><span>,</span> <span>right</span><span>)</span> <span>+</span> <span>kScratchSize</span><span>;</span>
    <span>if</span> <span>(</span><span>right</span> <span>&lt;=</span> <span>left</span><span>)</span> <span>{</span>
      <span>res</span> <span>=</span> <span>left</span> <span>-</span> <span>kScratchSize</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>res</span><span>,</span> <span>scratch</span><span>,</span> <span>kScratchSize</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>));</span>
  <span>return</span> <span>res</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>What we are ending up with is an in-place algorithm that’s almost branchfree.
The precise number of iterations in the modified Lomuto partitioning scheme
depend on the outcome of the comparisons and will be difficult to predict
exactly right. However the loop is guaranteed to iterate at least kScratchSize
times. This basically amortises the cost of branch mispredictions over many
elements making them irrelevant for performance. I consider this to be a truly
elegant design.</p>

<h2 id="fallback-for-sorting-short-arrays">Fallback for sorting short arrays</h2>

<p>The next step is the fallback for short arrays where the overhead of recursion
starts dominating. In the literature insertion sort is most often recommended
together with countless micro-optimizations applied. I found that at this point
partitioning was so fast that QuickSort beat insertion sort all the way down to
just a few elements. The problem is that insertion sort has unpredictable
branches, basically 1 miss per insert. The solution is Bubble sort. Bubble sort
has a very predictable access pattern and the swap can be implemented
branchless. A little more optimizing you discover you don’t need a swap. One
can keep the maximum in register and store the minimum.</p>

<div><div><pre><code><span>void</span> <span>BubbleSort</span><span>(</span><span>T</span><span>*</span> <span>arr</span><span>,</span> <span>size_t</span> <span>n</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>n</span><span>;</span> <span>i</span> <span>&gt;</span> <span>1</span><span>;</span> <span>i</span><span>--</span><span>)</span> <span>{</span>
    <span>auto</span> <span>max</span> <span>=</span> <span>arr</span><span>[</span><span>0</span><span>];</span>
    <span>for</span> <span>(</span><span>size_t</span> <span>j</span> <span>=</span> <span>1</span><span>;</span> <span>j</span> <span>&lt;</span> <span>i</span><span>;</span> <span>j</span><span>++</span><span>)</span> <span>{</span>
      <span>auto</span> <span>y</span> <span>=</span> <span>arr</span><span>[</span><span>j</span><span>];</span>
      <span>arr</span><span>[</span><span>j</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>(</span><span>max</span> <span>&lt;=</span> <span>y</span> <span>?</span> <span>max</span> <span>:</span> <span>y</span><span>);</span>
      <span>max</span> <span>=</span> <span>(</span><span>max</span> <span>&lt;=</span> <span>y</span> <span>?</span> <span>y</span> <span>:</span> <span>max</span><span>);</span>
    <span>}</span>
    <span>arr</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>max</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In the above inner-loop <code>max</code> is the variable that participates on the longest
loop carried data chain, with a compare and conditional move on it. This makes
the above loop execute in 2 cycles per iteration. However we can do better. If
instead of bubbling the max, we’re bubbling up the two largest elements we only
need to iterate the bubbling stage ++n/2++ times, instead of ++n++ times. It
turns out that using a clever implementation one can bubble two elements in the
same 2 cycles.</p>

<div><div><pre><code><span>void</span> <span>BubbleSort2</span><span>(</span><span>T</span><span>*</span> <span>arr</span><span>,</span> <span>size_t</span> <span>n</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>n</span><span>;</span> <span>i</span> <span>&gt;</span> <span>1</span><span>;</span> <span>i</span> <span>-=</span> <span>2</span><span>)</span> <span>{</span>
    <span>auto</span> <span>x</span> <span>=</span> <span>arr</span><span>[</span><span>0</span><span>];</span>
    <span>auto</span> <span>y</span> <span>=</span> <span>arr</span><span>[</span><span>1</span><span>];</span>
    <span>if</span> <span>(</span><span>y</span> <span>&lt;</span> <span>x</span><span>)</span> <span>std</span><span>::</span><span>swap</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>);</span>
    <span>for</span> <span>(</span><span>size_t</span> <span>j</span> <span>=</span> <span>2</span><span>;</span> <span>j</span> <span>&lt;</span> <span>i</span><span>;</span> <span>j</span><span>++</span><span>)</span> <span>{</span>
      <span>auto</span> <span>z</span> <span>=</span> <span>arr</span><span>[</span><span>j</span><span>];</span>
      <span>bool</span> <span>is_smaller</span> <span>=</span> <span>y</span> <span>&lt;=</span> <span>z</span><span>;</span>
      <span>auto</span> <span>w</span> <span>=</span> <span>is_smaller</span> <span>?</span> <span>y</span> <span>:</span> <span>z</span><span>;</span>
      <span>y</span> <span>=</span> <span>is_smaller</span> <span>?</span> <span>z</span> <span>:</span> <span>y</span><span>;</span>
      <span>is_smaller</span> <span>=</span> <span>x</span> <span>&lt;=</span> <span>z</span>
      <span>arr</span><span>[</span><span>j</span> <span>-</span> <span>2</span><span>]</span> <span>=</span> <span>(</span><span>is_smaller</span> <span>?</span> <span>x</span> <span>:</span> <span>z</span><span>);</span>
      <span>x</span> <span>=</span> <span>is_smaller</span> <span>?</span> <span>w</span> <span>:</span> <span>x</span><span>;</span>
    <span>}</span>
    <span>arr</span><span>[</span><span>i</span> <span>-</span> <span>2</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
    <span>arr</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>y</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The benchmarks verify that indeed this makes a difference.</p>

<div><div><pre><code><span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort</span><span>&gt;/</span><span>2</span>            <span>2</span> <span>ns</span>          <span>2</span> <span>ns</span>  <span>400700000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort</span><span>&gt;/</span><span>8</span>            <span>5</span> <span>ns</span>          <span>5</span> <span>ns</span>  <span>155200000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort</span><span>&gt;/</span><span>32</span>          <span>14</span> <span>ns</span>         <span>14</span> <span>ns</span>   <span>52600000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort2</span><span>&gt;/</span><span>2</span>           <span>1</span> <span>ns</span>          <span>1</span> <span>ns</span>  <span>514500000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort2</span><span>&gt;/</span><span>8</span>           <span>3</span> <span>ns</span>          <span>3</span> <span>ns</span>  <span>256700000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>BubbleSort2</span><span>&gt;/</span><span>32</span>          <span>9</span> <span>ns</span>          <span>9</span> <span>ns</span>   <span>78400000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>InsertionSort</span><span>&gt;/</span><span>2</span>                      <span>4</span> <span>ns</span>          <span>4</span> <span>ns</span>  <span>183600000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>InsertionSort</span><span>&gt;/</span><span>8</span>                     <span>11</span> <span>ns</span>         <span>11</span> <span>ns</span>   <span>63500000</span>
<span>BM_SmallSort</span><span>&lt;</span><span>InsertionSort</span><span>&gt;/</span><span>32</span>                    <span>17</span> <span>ns</span>         <span>17</span> <span>ns</span>   <span>42000000</span>
</code></pre></div></div>

<p>In fact it’s possible to generalize this, one can bubble up the top ++N++ in
constant cycles per iteration in the model where the CPU has arbitrary ILP.</p>

<h2 id="bringing-it-all-together">Bringing it all together</h2>

<p>What are the results? The results are nothing short of spectacular. The
following is a simple benchmark on sorting 100000 int’s. The time is normalized
by the number of elements, so it’s the amount of time spent per element. I’m
using clang + libc++ here, as gcc is dramatically worse in emitting branch free
code.</p>

<div><div><pre><code><span>CPU:</span> <span>Intel</span> <span>Skylake</span> <span>Xeon</span> <span>with</span> <span>HyperThreading</span> <span>(</span><span>36</span> <span>cores</span><span>)</span> <span>dL1</span><span>:</span><span>32</span><span>KB</span> <span>dL2</span><span>:</span><span>1024</span><span>KB</span> <span>dL3</span><span>:</span><span>24</span><span>MB</span>
<span>Benchmark</span>                         <span>Time</span><span>(</span><span>ns</span><span>)</span>        <span>CPU</span><span>(</span><span>ns</span><span>)</span>     <span>Iterations</span>
<span>------------------------------------------------------------------------</span>
<span>BM_Sort</span><span>&lt;</span><span>std_sort</span><span>&gt;</span>                       <span>51.6</span>           <span>51.6</span>     <span>10000000</span>
<span>BM_Sort</span><span>&lt;</span><span>std_stable_sort</span><span>&gt;</span>                <span>65.6</span>           <span>65.6</span>     <span>10000000</span>
<span>BM_Sort</span><span>&lt;</span><span>lib_qsort</span><span>&gt;</span>                      <span>90.4</span>           <span>90.5</span>      <span>7800000</span>
<span>BM_Sort</span><span>&lt;</span><span>andrei_sort</span><span>&gt;</span>                    <span>32.6</span>           <span>32.6</span>     <span>21500000</span>
<span>BM_Sort</span><span>&lt;</span><span>exp_gerbens</span><span>::</span><span>QuickSort</span><span>&gt;</span>         <span>16.4</span>           <span>16.4</span>     <span>43200000</span>
</code></pre></div></div>

<p>We’re talking about a 2x win over Andrei’s implementation as copied from his
github. The code is available at my <a href="https://github.com/gerben-s/quicksort-blog-post">GitHub</a>,
although it doesn’t contain benchmarks for the code as published by Andrei as
it didn’t contain a license.</p>

<p>We’ve seen how crucial it is to understand data dependencies in order to
optimize code. Especially hidden memory dependencies between load and stores
can greatly influence performance of work loops. Understanding the data
dependency graph of code is often where the real performance gains lie, yet
very little attention is given to it in the blogosphere. I’ve read many
articles about the impact of branch mispredictions, importance of data locality
and caches, but much less about data dependencies. I bet that a question like
“why are linked lists slow?” is answered by many in terms of locality, caches
or unpredictable random memory access. At least I’ve heard those reasons often,
even <a href="https://youtu.be/YQs6IC-vgmo?t=215">Stroustrup</a> says as much. Those
reasons can play a part, but it’s not the main reason. Fundamentally iterating
a linked list has a load-to-use on the critical path, making it 5 times slower
than iterating a flat array. Furthermore accessing flat arrays allow loop
unrolling which can further improve ILP.</p>



<p>This brings us to answer why QuickSort is fast compared to other sorts with
good or even better theoretical complexity. It’s all about data dependencies.
The quick sort partition loop above demonstrates a distinctive feature. The
element it will process next does not depend on the outcome of the comparisons
in previous iterations. Compare this to merge sort. In merge sort the two head
elements are compared, however the next elements that need to be compared
depend on the outcome of this comparison. It’s trivial to implement merge sort
branch free. It will look like</p>

<div><div><pre><code><span>val1</span> <span>=</span> <span>Load</span><span>(</span><span>left</span> <span>+</span> <span>k</span> <span>-</span> <span>right_idx</span><span>)</span>  <span>// 1</span>
<span>val2</span> <span>=</span> <span>Load</span><span>(</span><span>right</span> <span>+</span> <span>right_idx</span><span>)</span>
<span>is_smaller</span> <span>=</span> <span>val2</span> <span>&lt;</span> <span>val1</span>   <span>// 2</span>
<span>tmp</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>val2</span><span>,</span> <span>val1</span><span>)</span>
<span>Store</span><span>(</span><span>out</span> <span>+</span> <span>k</span><span>,</span> <span>tmp</span><span>);</span>
<span>k</span><span>++</span><span>;</span>
<span>right_idx</span> <span>+=</span> <span>is_smaller</span>  <span>// 3</span>
</code></pre></div></div>

<p>This is about 8 cycles per iteration to update <code>right_idx</code>, we have a load and
non-trivial indexing at line 1 (6 cycles), and line 2 and 3 both being 1 cycle.
Similar analysis holds for heap sort, restoring the heap property requires
comparing the two children and recurse on the subtree of the biggest child.</p>

<div><div><pre><code><span>left</span> <span>=</span> <span>Load</span><span>(</span><span>2</span> <span>*</span> <span>idx</span><span>)</span>
<span>right</span> <span>=</span> <span>Load</span><span>(</span><span>2</span> <span>*</span> <span>idx</span> <span>+</span> <span>1</span><span>)</span>
<span>is_smaller</span> <span>=</span> <span>left</span> <span>&lt;</span> <span>right</span>
<span>tmp</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>right</span><span>,</span> <span>left</span><span>)</span>
<span>Store</span><span>(</span><span>idx</span><span>,</span> <span>tmp</span><span>);</span>
<span>idx</span> <span>=</span> <span>2</span> <span>*</span> <span>idx</span> <span>+</span> <span>is_smaller</span>
</code></pre></div></div>

<p>Again this is 8 cycles on the loop carried data chain. This goes to the heart
of the matter of why QuickSort is fast even though theoretically it has
inferior behavior compared to heap and merge sort. By construction heap and
merge sort divide the data very evenly in the implied tree structure, the heap
structure is a binary tree of minimum depth as is the recursive subdivision
that merge sort performs. This means that the number of comparisons they do is
++n \lg(n)++ which tightly hugs the information theoretical lower bound of
++\lg(n!)++.</p>

<p>In contrast, QuickSort bets on obtaining a reasonably balanced tree with high
probability. The bits of information extracted from a comparison with the pivot
depends on its rank in the array. Only pivots that are close to the median will
result in obtaining 1 bit of information per comparison. Solving the recurrence
equation of QuickSort with a uniform pivot choice, gives ++2n \ln{n}++ as the
number of comparisons on average. Hence QuickSort does a factor ++2 \ln(2) =
1.4++ more comparisons than heap sort or merge sort on average, or equivalently
more iterations in the inner work loop. However the enormous speed difference
in the basic work loop more than compensates for this information theoretical
factor.</p>

<p>Also, when partitioning big arrays spending a little amount of work improving
the choice of pivot by a median of three brings this factor down to ~1.2.
Further improvements can get this factor rather close to 1. The main point here
is that this factor is dominated by the differences in throughput of the work
loop.</p>

<p>We can significantly speed up merge sort with a simple trick. Due to the large
dependency chain, merge sort loop runs at a very low IPC. This basically means
we can add more instructions for free. In particular merge sort has a backwards
equivalent. We can merge forward and backward in a single loop while keeping
the latency of the loop body the same. It also eliminates an awkward exit
condition as now you can unconditionally iterate n/2 times. This reduces the
number of iterations roughly by 2x.</p>

<div><div><pre><code>BM_Sort&lt;exp_gerbens::QuickSort&gt;                       10.7           10.7     65011712
BM_MergeSort&lt;MergeSort&gt;                               23.4           23.4     29884416
BM_MergeSort&lt;MergeSortDouble&gt;                         13.2           13.2     52756480
</code></pre></div></div>

<p>Another trick is preloading values for the next iteration,</p>

<div><div><pre><code><span>next_val1</span> <span>=</span> <span>Load</span><span>(</span><span>left</span> <span>+</span> <span>k</span> <span>-</span> <span>right_idx</span> <span>+</span> <span>1</span><span>)</span>
<span>next_val2</span> <span>=</span> <span>Load</span><span>(</span><span>right</span> <span>+</span> <span>right_idx</span> <span>+</span> <span>1</span><span>)</span>
<span>is_smaller</span> <span>=</span> <span>val2</span> <span>&lt;</span> <span>val1</span>
<span>tmp</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>val2</span><span>,</span> <span>val1</span><span>)</span>
<span>val1</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>val1</span><span>,</span> <span>next_val1</span><span>)</span>
<span>val2</span> <span>=</span> <span>cmov</span><span>(</span><span>is_smaller</span><span>,</span> <span>next_val2</span><span>,</span> <span>val2</span><span>)</span>
<span>Store</span><span>(</span><span>out</span> <span>+</span> <span>k</span><span>,</span> <span>tmp</span><span>);</span>
<span>k</span><span>++</span><span>;</span>
<span>right_idx</span> <span>+=</span> <span>is_smaller</span>
</code></pre></div></div>

<p>You see that in a single iteration the increase of <code>right_idx</code> does not depend
on a load as <code>val1</code> and <code>val2</code> are already available at the start of the
iteration. Over two iterations one can see that <code>right_idx</code> depends on itself.
This chain is ~8 cycles long but spread over 2 iterations which gives a
throughput of ~4 cycles per iteration. Combining these two tricks could lead to
merge sort on par with the simple partition loop of QuickSort. However it’s
just a mitigation. If instead of sorting a simple primitive value we would sort
pointers to a struct. The comparison operator would have an extra load which
immediately adds to the critical path. QuickSort is immune to this, even rather
costly comparisons do not influence the ability to make progress. Of course if
the comparison itself suffers from frequent branch misses, then that will limit
the ability to overlap different stages of the iteration in the CPU pipeline.</p>

<p>A lot of thanks to Josh for discussions, helpful suggestions, his insights and
for providing space on his blog for this post.</p>

<ul>
  <li><em><a href="https://news.ycombinator.com/item?id=23363165">Discuss this article on Hacker News.</a></em></li>
</ul>

  </div>

</article>

      </div>
    </div></div>
  </body>
</html>
