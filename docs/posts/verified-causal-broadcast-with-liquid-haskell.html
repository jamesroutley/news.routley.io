<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://decomposition.al/blog/2022/09/07/verified-causal-broadcast-with-liquid-haskell/">Original</a>
    <h1>Verified Causal Broadcast with Liquid Haskell</h1>
    
    <div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        <i aria-hidden="true"></i>
        
        <time datetime="2022-09-07T00:00:00+00:00">September 7, 2022</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
        



<p>Last week at <a href="https://ifl22.github.io/">IFL</a>, I gave a talk on my research group’s work on <a href="https://arxiv.org/abs/2206.14767">using Liquid Haskell to verify an implementation of causal broadcast</a>!  This post is a pseudo-transcript with some slides, and I’ve posted the <a href="https://users.soe.ucsc.edu/~lkuper/talks/2022-08-31-ifl-cbcast-lh.pdf">full set of slides</a> as well.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup></p>

<h2 id="hi">Hi!</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-6.png" alt="Verified Causal Broadcast with Liquid Haskell"/>
</figure>

<p>I’m Lindsey Kuper, and I’m an assistant professor at the University of California, Santa Cruz, where I’m part of the <a href="https://lsd.ucsc.edu/">LSD Lab</a> (that’s the Languages, Systems, and Data Lab, in case you were wondering).  I’m very excited to be traveling internationally again, after three years of not doing that!</p>

<p>This is work that was led by my PhD student, <a href="https://curious.software/plr/">Patrick Redmond</a>, with help from another one of my PhD students, <a href="https://gshen42.github.io/">Gan Shen</a>, and our collaborator, <a href="https://nikivazou.github.io/">Niki Vazou</a> at IMDEA.</p>

<p>Lately I’ve been interested in using <em>language-integrated verification</em> tools to help us build distributed systems that are guaranteed to work like they’re supposed to.  The particular guarantee that we’re concerned with here is something called causal delivery of broadcast messages, which I’ll explain with examples in the first part of the talk.  The language-integrated verification tool that we’re using is the refinement type system and the accompanying theorem-proving features that are built into <a href="https://ucsd-progsys.github.io/liquidhaskell-blog/">Liquid Haskell</a>, and I’ll talk about that in the second part of the talk.  So, let’s jump in!</p>

<h2 id="the-problem">The problem</h2>

<p>So as I mentioned, this is my first international travel in about three years, and so not too long before the trip I realized that I didn’t know where my passport was.  And so I sent a message to my coauthors in the group chat, saying “Oh, no!  I lost my passport.”  These are messages being sent over an asynchronous network, the Internet, so there’s no bound on how long they might take to arrive at their destination and some might take longer than others.  Let’s say the message to Patrick takes a little longer than the rest of them do.  That’s to be expected.  And let’s also suppose for now that the underlying message transport mechanism doesn’t inherently give you any guarantees about message ordering.</p>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-11.png" alt="Found what?"/>
  <figcaption>Found what?</figcaption>
</figure>

<p>Fortunately, a little later I found my passport (this is a true story, by the way) and let everyone know.  Unfortunately, this second message overtakes the first message on the way to Patrick, and so Patrick is confused because sees this “Found it!” message and doesn’t have the context.</p>

<p>This is one example of a violation of what’s known as <em>causal message delivery</em>.  The send of my lost passport message happens before the send of my “Found it!” message, in the sense of Lamport’s happens-before relation.  Since the sends are ordered in this way, so should the corresponding deliveries on the recipient’s end.  In particular, this is a special case of a causal message delivery violation known as a FIFO delivery violation: the messages are both from the same sender and they both go to the same recipient, so they should arrive as though they are coming through a FIFO queue, and if that isn’t what happens, it’s a violation of FIFO delivery.</p>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-13.png" alt="FIFO delivery helps."/>
  <figcaption>FIFO delivery helps.</figcaption>
</figure>

<p>One way to address this problem is to decouple message <em>reception</em> from message <em>delivery</em>.  Receiving a message is something that happens <em>to</em> you; you don’t control when it happens.  Delivering a message, on the other hand, is something the recipient <em>can</em> control.  Imagine a little mail clerk hanging out on Patrick’s process.  The mail clerk intercepts each incoming message and chooses to either sit on it in the mail room for a while, or hand it off right away to the application that might be waiting for it, such as Patrick’s chat client.  In this case the mail clerk can choose to delay the message until after the previous one from me has been received and delivered, and only then deliver it.</p>

<p>Now, it turns out that FIFO violations are relatively easy to deal with.  In fact, if we happen to be communicating over TCP and the messages in question are sent within the same TCP session, then FIFO violations are already ruled out by TCP’s built-in message ordering guarantees, and so the mail clerk wouldn’t need to do anything.</p>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-15.png" alt="FIFO delivery doesn&#39;t solve all our problems."/>
  <figcaption>FIFO delivery doesn&#39;t solve all our problems.</figcaption>
</figure>

<p>But all is not well!  Patrick was happy to hear that I found my passport, so he sent a nice message back.  This is yet another asynchronous message.  Unfortunately, Gan and Niki now both saw the “Yay!” message after seeing the “lost passport” message from me, but <em>before</em> seeing the “Found it!” message from me.  So from their point of view, Patrick was celebrating the fact that my passport is <em>lost</em>.  Maybe they thought Patrick was being rude or sarcastic, which wouldn’t be like him at all.</p>

<p>This is another violation of causal delivery.  In this case, the send of my “Found it!” message happens before the send of Patrick’s “Yay!” message, which we can see by following these messages forward through time and seeing that Patrick’s send is reachable from my send.  So these messages can be said to have an order according to happens-before; they’re not concurrent messages.  But for Gan and Niki, the messages were delivered in an order that was inconsistent with that happens-before order.  And this time, because the messages came from <em>different senders</em>, the FIFO delivery that we already get from protocols like TCP will do nothing to help us.  So we need the mail clerks on these processes to do something to ensure that messages are delivered at their intended recipient in an order that respects the happens-before order.</p>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-18.png" alt="We need causal delivery."/>
  <figcaption>We need causal delivery.</figcaption>
</figure>

<p>Mechanisms that do this have been well known and widely used in the distributed systems literature for decades.  A typical approach is to attach a piece of metadata to each message that summarizes the causal dependencies of the message in a way that can be efficiently checked on the receiver’s end.  Our notional “mail clerk” can use this metadata to determine the causal relationship between messages, if there is one, and delay the delivery of a message to a process until every causally preceding message has been delivered.  There’s a <a href="https://dl.acm.org/doi/10.1145/128738.128742">classic algorithm</a> for this, developed by Ken Birman and collaborators in the 90s. Let’s take a look at how it works.</p>

<h2 id="causal-broadcast-with-vector-clocks">Causal broadcast with vector clocks</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-37.png" alt="Birman et al.&#39;s causal broadcast protocol."/>
  <figcaption>Birman et al.&#39;s causal broadcast protocol.</figcaption>
</figure>

<p>In the Birman causal broadcast algorithm, each process keeps track of a vector with the same number of entries as there are processes, initialized to all zeroes.  Intuitively, this vector tracks the number of messages that the process has delivered from each of the processes, including itself.  Initially, nobody has delivered any messages, so everyone has a vector of zeroes.  This data structure is known as a vector clock, or VC for short.  Whenever a process broadcasts a message, it first increments its own entry in its vector clock by one.  So for example, when I send my “Lost my passport” message, the last entry in my vector changes from 0 to 1.  I then attach that vector clock to the outgoing message as metadata.</p>

<p>Whenever a process receives a message, the mail clerk checks if it’s deliverable.  Here’s the deliverability policy our mail clerk uses: a message is deliverable if the attached vector clock is 1 <em>greater</em> than the recipient’s vector clock in the sender’s position, and less than or equal to the recipient’s vector clock in every other position.  So let’s look at how that plays out in this execution.</p>

<p>When my first message gets to Niki with the <code>[0,0,0,1]</code> vector clock attached, it is indeed one greater than Niki’s VC in my position and equal to Niki’s VC everywhere else.  So it’s deliverable.  Niki delivers the message and <em>updates</em> her process VC to the maximum of her own VC and the message VC.  Same thing happens for Gan.</p>

<p>Now, here comes the “Found it!” message from me.  When I send the “Found it!” message, I again increment my own position in my VC before attaching it to the message, so the message VC is <code>[0,0,0,2]</code>.  When the message gets to Patrick, it’s not deliverable, since its VC is one too big in the sender’s position. So the mail clerk holds on to it.  Then my first message shows up for Patrick.  That one <em>is</em> deliverable according to the mail clerk’s policy.  So it’s delivered, and Patrick’s process VC gets updated to the maximum of his own VC and the message VC.</p>

<p>Now the undeliverable message has become deliverable, so that one gets delivered too, and Patrick’s process VC gets updated to the maximum of the two again.  Next, Patrick sends his own message.  To do so, he increments his own entry in his VC.  So his VC is now <code>[1,0,0,2]</code>.  Intuitively, the 1 represents his own message and the 2 represents the two messages from me that causally precede it.  Patrick’s message shows up at all the recipients.  I can deliver it right away and update my VC to the maximum of its VC and my VC. But for Gan and Niki it has to be queued, because their process VCs are still at only 1 in the entry representing me.  They have to wait for the “Found it!” message to show up from me.</p>

<p>When that message shows up, it’s deliverable for both of them, so they deliver it, and then they can deliver the “Yay!” message that was delayed.  And now we’re finally done, with everyone’s vector clocks in agreement and all the messages having been delivered in causal order.</p>

<p>That’s the protocol in a nutshell.  Protocols like this are ubiquitous in distributed systems, and their implementation is often quite fiddly and error-prone, so that motivates the need for mechanically verified implementations.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>  In particular, what we want to do is guarantee with a machine-checked proof that if you run this protocol, where each of these processes is locally doing this low-level twiddling of vector clocks, then globally, across the entire execution, all messages will be delivered in causal order.  That’s precisely what we did, using Liquid Haskell.  So I’m now going to switch gears to talk a little about what Liquid Haskell is and how it works, and then we’ll come back to how we can use Liquid Haskell to express this causal delivery property of executions.</p>

<h2 id="refinement-types">Refinement types</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-45.png" alt="Refinement types."/>
  <figcaption>Refinement types.</figcaption>
</figure>

<p>Liquid Haskell adds <em>refinement types</em> to Haskell.  For the purposes of this talk, I’ll define refinement types as data types that let programmers specify logical predicates that restrict, or refine, the set of values that can inhabit the type.  I’ll give some simple examples, using Liquid Haskell syntax.</p>

<p>For instance, we can define a <code>Nat</code> type that refines Haskell’s built-in <code>Int</code> type with a <em>refinement predicate</em> that says that our <code>Int</code> has to be no less than zero.</p>

<div><div><pre><code><span>type</span> <span>Nat</span> <span>=</span> <span>{</span> <span>v</span><span>:</span><span>Int</span> <span>|</span> <span>v</span> <span>&gt;=</span> <span>0</span> <span>}</span>
</code></pre></div></div>

<p>This is kind of the Hello World of refinement types, but it turns out to be pretty handy to us, because we can represent our vector clocks as lists of <code>Nat</code>s.</p>



<p>What operations should this <code>VectorClock</code> type support?  We need to do things like compare vector clocks, merge then, and so on.  Let’s consider the merge operation.  When a process delivers a message, it needs to merge its own vector clock with that of the received message by taking the maximum of corresponding vector clock entries.  The implementation of merge is straightforward; we use Haskell’s <code>zipWith</code> and take the maximum of corresponding vector clock entries.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup></p>

<div><div><pre><code><span>vcMerge</span> <span>::</span> <span>VectorClock</span> <span>-&gt;</span> <span>VectorClock</span> <span>-&gt;</span> <span>VectorClock</span>
<span>vcMerge</span> <span>=</span> <span>zipWith</span> <span>max</span>
</code></pre></div></div>

<p>Now, let’s use refinement types to tighten up the type of <code>vcMerge</code> some more.  For example, we want the vector clocks we’re merging to have the same length.  Let’s start by implementing a type of vector clocks of a given length:</p>

<div><div><pre><code><span>type</span> <span>VCsized</span> <span>N</span> <span>=</span> <span>{</span> <span>vc</span><span>:</span><span>VectorClock</span> <span>|</span> <span>len</span> <span>vc</span> <span>==</span> <span>N</span> <span>}</span>
</code></pre></div></div>

<p><code>VCsized</code> is the type of a vector clock indexed by a length N.  Now we can define a type for a vector clock that’s the same length as another specified vector.  I’ll call that <code>VCsameLength</code>.</p>

<div><div><pre><code><span>type</span> <span>VCsameLength</span> <span>V</span> <span>=</span> <span>VCsized</span> <span>{</span><span>len</span> <span>V</span><span>}</span>
</code></pre></div></div>

<p>(By the way, these curly braces around <code>flen V</code> in the type are Liquid Haskell syntax to show that that’s an expression argument to a type.)</p>

<p>With our <code>VCsameLength</code> type defined, we can write a signature for <code>vcMerge</code> that expresses the precondition that the vector clocks we’re merging are of the same length, and the postcondition that the returned VC will have the same length as the argument VCs did.  And the implementation of <code>vcMerge</code> is still the same.</p>

<div><div><pre><code><span>vcMerge</span> <span>::</span> <span>v</span><span>:</span><span>VectorClock</span> <span>-&gt;</span> <span>VCsameLength</span> <span>{</span><span>v</span><span>}</span> <span>-&gt;</span> <span>VCsameLength</span> <span>{</span><span>v</span><span>}</span>
<span>vcMerge</span> <span>=</span> <span>zipWith</span> <span>max</span>
</code></pre></div></div>

<p>Let’s use this version of <code>vcMerge</code> instead.</p>

<h2 id="refinement-reflection">Refinement <em>reflection</em></h2>

<p>So far, this is all pretty much what you would expect from a refinement type system.  Where I think Liquid Haskell really shines, however, is where it lets you go beyond specifying preconditions and postconditions of individual functions, and lets you <em>extrinsically verify</em> properties that are not captured by a single function’s type, using a mechanism called <em>refinement reflection</em>.</p>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-56.png" alt="Refinement reflection."/>
  <figcaption>Refinement reflection.</figcaption>
</figure>

<p>Let’s use refinement reflection to prove that our <code>vcMerge</code> function in commutative – that is, that the order of the VC arguments we give it doesn’t matter.</p>

<p>I’ll do this by defining a type <code>Commutative</code>.  This is the type of a Haskell function that returns a <em>proof</em> that a given binary function, <code>A</code>, is commutative.  In fact, it returns a value of this <code>Proof</code> type, which in Liquid Haskell is just a type alias for Haskell’s <code>()</code> (unit) type.  The value of <code>Proof</code> type is refined by a predicate that expresess the commutativity of that function <code>A</code>.</p>

<div><div><pre><code><span>type</span> <span>Commutative</span> <span>a</span> <span>A</span> <span>=</span> <span>x</span><span>:</span><span>a</span> <span>-&gt;</span> <span>y</span><span>:</span><span>a</span> <span>-&gt;</span> <span>{</span> <span>_</span><span>:</span><span>Proof</span> <span>|</span> <span>A</span> <span>x</span> <span>y</span> <span>==</span> <span>A</span> <span>y</span> <span>x</span> <span>}</span>
</code></pre></div></div>

<p>With the definition of <code>Commutative</code> in place, we can now state the property we want to prove.  <code>vcMergeComm</code> says that given any size N, <code>vcMerge</code> is commutative when applied to two vector clocks of length N.  In fact, <code>vcMergeComm</code> is the type of a function that returns a <em>proof</em> of this when given a size N and any two vector clocks of that size.</p>

<div><div><pre><code><span>vcMergeComm</span> <span>::</span> <span>n</span><span>:</span><span>Nat</span> <span>-&gt;</span> <span>Commutative</span> <span>(</span><span>VCsized</span> <span>n</span><span>)</span> <span>vcMerge</span>
</code></pre></div></div>

<p>Now we can prove commutativity of <code>vcMerge</code> by filling in an implementation of <code>vcMergeComm</code> to inhabit the type we wrote down.  Here it is:</p>

<div><div><pre><code><span>vcMergeComm</span> <span>_n</span> <span>[]</span>      <span>[]</span>      <span>=</span> <span>()</span>
<span>vcMergeComm</span> <span>n</span>  <span>(</span><span>_x</span><span>:</span><span>xs</span><span>)</span> <span>(</span><span>_y</span><span>:</span><span>ys</span><span>)</span> <span>=</span> <span>vcMergeComm</span> <span>(</span><span>n</span> <span>-</span> <span>1</span><span>)</span> <span>xs</span> <span>ys</span>
</code></pre></div></div>

<p>The proof is by induction on the structure of vector clocks. The base case, in which both VCs are empty lists, is automatic for the SMT solver, so the body of the base case need not say anything but <code>()</code>. The inductive case is not automatic, but it is a one-liner; it has a recursive call to <code>vcMergeComm</code>.</p>

<p>In general, Liquid Haskell programmers can extrinsically specify arbitrary properties in refinement types, and the programmer can then prove those properties by writing programs that inhabit those refinement types.  Liquid Haskell provides a library of proof combinators that you can use to chain together bits of evidence and build up a proof.</p>

<p>So, Liquid Haskell can do more than traditional refinement types.  It doesn’t just let you give more precise types to programs you were writing anyway; it also lets you use refinement type annotations as a place to specify any property about your code that you might want to prove.  You can then assist the SMT solver in proving that property by writing Haskell programs to inhabit those types.</p>

<p>Being based on Haskell also lets programmers gradually port code from plain Haskell to Liquid Haskell, adding richer specifications to code as they go.  For instance, a programmer might begin with an implementation of <code>vcMerge</code> with the original type we had, <code>VectorClock -&gt; VectorClock -&gt; VectorClock</code>, later refine it to the fancier refinement type we have here, yet later extrinsically prove the property <code>vcMergeComm</code>, and still later use the proof returned by <code>vcMergeComm</code> as a premise to carry out another, more interesting extrinsic proof.  And that’s the sort of workflow that we often use.</p>

<h2 id="causal-delivery-as-a-refinement-type">Causal delivery as a refinement type</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-58.png" alt="Causal delivery as a refinement type."/>
  <figcaption>Causal delivery as a refinement type.</figcaption>
</figure>

<p>Let’s return to causal broadcast.  The protocol I described earlier was introduced by Ken Birman et al. in the early 90s in the context of their Isis system for fault-tolerant distributed computing.  The protocol ensures that when a process receives a message, that message is delayed if necessary and then delivered, meaning applied to that process’s state, only after any causally preceding messages have been delivered.  In particular, if the send of message \(m\) happens before the send of message \(m&#39;\), in the sense of Lamport’s happens-before relation, then we know that on all processes, the delivery of \(m\) has to precede the delivery of \(m&#39;\).</p>

<p>As we saw earlier, this is done by using vector clocks to represent causal dependencies, and delaying messages in a queue on the receiver’s side until it’s okay to deliver them.  The deliverability check is done by comparing the receiving process’s vector clock with the vector clock of the message.</p>

<p>We used Liquid Haskell to verify that the causal delivery property holds of our implementation.  To do this, we first need to express causal delivery as a refinement type.</p>

<p>Here’s a simplified look at how we can use refinements in Liquid Haskell to express the type of a process that observes causal delivery.  So, a process keeps track of the events that have occurred on it so far, including any messages it’s delivered – and that sequence of events comprises its <em>process history</em>.  This type, <code>CausalDelivery</code>, says that if any two messages m and m’ both appear in a process history as having been delivered, and m causally precedes m’, then those deliveries have to appear in the process history in an order that’s consistent with their causal order.</p>

<div><div><pre><code><span>type</span> <span>CausalDelivery</span> <span>p</span> <span>=</span>
     <span>{</span> <span>m</span> <span>:</span> <span>Message</span> <span>|</span> <span>elem</span> <span>(</span><span>Deliver</span> <span>m</span> <span>)</span> <span>(</span><span>pHist</span> <span>p</span><span>)</span> <span>}</span>
  <span>-&gt;</span> <span>{</span> <span>m&#39;</span><span>:</span> <span>Message</span> <span>|</span> <span>elem</span> <span>(</span><span>Deliver</span> <span>m&#39;</span><span>)</span> <span>(</span><span>pHist</span> <span>p</span><span>)</span>
                     <span>&amp;&amp;</span> <span>causallyBefore</span> <span>m</span> <span>m&#39;</span> <span>}</span>
  <span>-&gt;</span> <span>{</span> <span>_</span><span>:</span> <span>Proof</span> <span>|</span> <span>ordered</span> <span>(</span><span>pHist</span> <span>p</span><span>)</span> <span>(</span><span>Deliver</span> <span>m</span><span>)</span> <span>(</span><span>Deliver</span> <span>m&#39;</span><span>)</span> <span>}</span>
</code></pre></div></div>

<p>So this is essentially taking the definition of causal delivery from the Birman et al. paper and turning it into a property that we can enforce about a process in Liquid Haskell.  Now that we’ve defined this type, the verification task is to ensure that for any process history that could actually be produced by a run of the CBCAST protocol, this causal delivery property holds.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup></p>

<h2 id="causal-delivery-preservation-as-a-refinement-type">Causal delivery preservation as a refinement type</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-62.png" alt="Ensuring that a process observes causal delivery."/>
  <figcaption>Ensuring that a process observes causal delivery.</figcaption>
</figure>

<p>The way that we accomplish this is to express the CBCAST protocol in terms of a state transition system, where states represent the states of processes, and state transitions are the operations that broadcast, receive, or deliver messages.  Here, the <code>Op</code> type represents those three kinds of state transitions, and the <code>step</code> function takes us from process state to process state.</p>

<p>We can then prove a property that I’ve called <code>causalDeliveryPreservation</code> here, which says that if a process observes causal delivery to begin with, then any process that could result from a sequence of state transitions produced by the protocol will observe causal delivery, too.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup></p>

<p>This property took a few hundred lines of Liquid Haskell code to prove, with the most interesting part, of course, being the part that dealt with <code>deliver</code> operations.  The proof development as a whole is about a thousand lines.</p>

<p>A couple things to mention here.  One is that we found that the real key was implementing the protocol in terms of a state transition system.  This wasn’t the way it was described in the <a href="https://dl.acm.org/doi/10.1145/128738.128742">original paper</a>, although of course all the ideas were there.  But we found that that’s what we needed to do to be able to express and prove properties like this, and it took a while for us to arrive at that design, even though it seems obvious in retrospect.</p>

<p>Another thing: the property that I’ve written down on this slide is actually just a property of an individual process, but what we really want is a property of entire executions – we want to be able to say that if this property is true of every process individually then the entire execution observes causal delivery as a whole.  To do that we had to define a global state machine and a global transition system, and I’m happy to report that a little earlier this month we, and by “we” I mean my student Patrick, were able to get that global proof done.  A cool thing about it in my opinion is that since we’re leveraging the correspondence between vector clocks and happens-before and taking it as axiomatic, we really <em>don’t</em> need anything fancy to make this connection from local to global work.</p>

<p>I’ve always thought vector clocks were really neat, because they let you take something as ineffable and mysterious as causality, and boil it down to something as simple and concrete as a vector of natural numbers.  But now after doing this project, I think they’re even cooler, because they let you take something like a happens-before relationship that’s spread out over a whole execution, and boil it down to a property that’s locally checkable.  So you get a sort of “local reasoning for free”, which I love!</p>

<h2 id="a-plea-for-help">A plea for help</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-65.png" alt="The blue-sky vision."/>
  <figcaption>The blue-sky vision.</figcaption>
</figure>

<p>All that said, I now want to make a plea for help!</p>

<p>The blue-sky vision of this work is that we want programmers to be able to mechanically specify and verify interesting correctness properties, not just of models, but of real, executable implementations of distributed systems.  Moreover, they should be able to do this using verification capabilities integrated into the same general-purpose, industrial-strength programming language that they use for implementation.</p>

<p>Many of us are already sold on language-integrated verification by means of expressive type systems, and I think that our results so far suggest that with Liquid Haskell, it <em>is</em> possible.  Unfortunately, I think it’s still way too hard to do.</p>

<p>Thanks to refinement reflection, Liquid Haskell <em>can</em> be used to turn Haskell into a proof assistant, and make no mistake, I think it’s great that this is possible at all.  But developing long proofs in Liquid Haskell is still quite painful.  It  provides only very coarse-grained feedback – either it reports a type error or it doesn’t.  We’ve been thinking about how to improve the situation, and one of our proposals is to extend Liquid Haskell with support for Agda-style typed holes, and interactive editing commands that take advantage of them.  We published a <a href="https://arxiv.org/abs/2110.04461">short paper</a> about this idea at the <a href="https://2021.splashcon.org/home/hatra-2021">HATRA workshop last year</a>, but it’s still no more than an idea, and there’s a lot of work to do, so I would invite collaboration from anyone who’s interested in helping out here.</p>

<h2 id="tak">Tak!</h2>

<figure>
  <img src="https://decomposition.al/assets/images/2022-08-31-ifl-cbcast-lh-67.png" alt="Thanks!"/>
  <figcaption>Thanks!</figcaption>
</figure>

<p>To conclude, we saw that we can use Liquid Haskell’s refinement types to express and prove properties about the order in which messages are delivered in a distributed system, which should enable easier implementation and verification of applications on top of the messaging layer.  Our <a href="https://github.com/lsd-ucsc/cbcast-lh">code is on GitHub</a>, so give it a try!  Finally, while Liquid Haskell is up to the task for projects like this, we still think it could be much easier to use, and we look forward to continuing to improve it.</p>

<p>Thank you for listening!</p>



        
      </section>

      

      

      
  

    </div></div>
  </body>
</html>
