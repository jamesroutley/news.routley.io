<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://liquidbrain.net/blog/reflections-on-an-llm-only-coding-project/">Original</a>
    <h1>Reflections on an LLM-Only Coding Project</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
            <p>In my previous past, I talked about using LLMs to learn more about coding<sup id="fnref:1"><a href="#fn:1">1</a></sup>. I was curious about reversing my advice, so I decided to complete a project without writing a line of code. [Edit: see the <a href="https://github.com/ChiWilliams/TimeSheetEntry">repository</a> if you&#39;re curious!]</p>
<p>I had Claude Sonnet 3.6 implement a browser extension that lets me add a row to my time-tracking spreadsheet. I set the following rules:  </p>
<ol>
<li>The process is asking Claude 3.6 to implement a file; I copy &amp; paste the result into result; then I ask for edits.  </li>
<li>I can test the code and give feedback, but no writing new lines.  </li>
<li>I can add environment variables </li>
</ol>
<p>My takeaways from the exercise:<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>

<ul>
<li><em>The project got done</em>: As in, the project is in a workable state; it probably wouldn&#39;t have otherwise. </li>
<li><em>The project got done quickly</em>: ~700 LOC in 3 hours. Pretty much no amount of me being in the coding loop would have made that faster (at least for this size project).  </li>
<li><em>Making a &#34;specification&#34; was easy</em>: I exchanged several messages describing what I wanted out of the extension, and then asked it to make a specification. This let me more quickly determine what exactly I wanted.<sup id="fnref:3"><a href="#fn:3">3</a></sup>  </li>
<li><em>Fast iteration</em>: Because I didn&#39;t need to worry about implementing the UI, I could iterate much faster on it.  </li>
<li><em>Clean(ish) code</em>: The output is generally clean code, at least cleaner than I would have written in 3 hours.  </li>
</ul>

<ul>
<li><em>Technical Debt</em>: I have very little understanding of what&#39;s going on. If I needed to make a change myself (like change a category label), I would either have to learn the entire codebase from scratch, or ask an LLM. So I&#39;m dependent which leads to ...  </li>
<li><em>Brittle changes</em>: Because I&#39;m dependent on the LLM, all I could do to change something was give the entire file (or most of the file) and hope the fix works. Occasionally, it took a couple of tries (or a new context) to get things working.  </li>
<li><em>Less fun</em>: The things that were least automated about this process were filling out the OAuth form for google sheets. The fun feature scrunging was done for me, but I still had to figure out the bureaucracy.</li>
<li><em>I learned a lot less</em>: if I&#39;d done this project myself. I would have learned a lot about UI, and the sheets API, and styling with CSS. Instead, the only thing I really learned was OAuth because that&#39;s what I did.  </li>
</ul>

<ul>
<li><em>Using chat</em>: I was using the chat web app instead of something like Cursor or Aider! This was ehh. It didn&#39;t have great ergonomics. </li>
<li><em>Managing contexts</em> was crucial, both in getting Claude to pass along summaries to future instances, and in starting a fresh instance when getting stuck. </li>
<li><em>Using onefilellm</em>: this made it easy to communicate the entire codebase as an attached file.<sup id="fnref:4"><a href="#fn:4">4</a></sup></li>
<li><em>Tree-based interface?</em> This may not be the ideal coding interface, but I would love the ability to turn my LLM interactions into a tree. I often have two different questions for an LLM after its responses. And it would nice to be able to branch from one point (And eventually merge back together somehow). Almost like a chatbot git.  </li>
</ul>

<ul>
<li><em>Human in the loop</em>: At least at the moment, complete LLM dependence is not the most effective for me. It is faster at the beginning, but the technical debt builds up quickly. I don&#39;t necessarily need to understand every line perfectly, but I should understand the broad strokes. </li>
<li><em>Actually using the LLM</em>: On the other hand, it is freeing to give up some control. I often feel like I need to type <em>every line</em> but it is faster to pass off what I understand.<sup id="fnref:5"><a href="#fn:5">5</a></sup> So with something like the extension&#39;s manifest.json, I&#39;m fine to have the LLM write the boilerplate.</li>
<li><em>Volition and LLMs</em>: At the Recurse Center: the directive of &#34;coding at the edge of your ability&#34; is balanced off with &#34;building volitional muscles.&#34;<sup id="fnref:6"><a href="#fn:6">6</a></sup> This project did not have me coding at the edge of my abilities, but I still had to exercise a lot of volition! It was my idea to make the extension, and I specified how the UI was going to feel. Especially with &#34;home-cooked software&#34;<sup id="fnref:7"><a href="#fn:7">7</a></sup> knowing what you want rather than how to get it seems like it will become more and more important in the near term (6 months - 3 years). I don&#39;t know what comes after that, but for the moment, there&#39;s a lot of places to explore!<sup id="fnref:8"><a href="#fn:8">8</a></sup>  </li>
</ul>
<p>Cheers!</p>


        </div></div>
  </body>
</html>
