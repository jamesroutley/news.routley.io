<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.redox-os.org/news/kernel-10/">Original</a>
    <h1>Redox: Significant performance and correctness improvements to the kernel</h1>
    
    <div id="readability-page-1" class="page"><div>
  
    
  
  
    <h5>By Jacob Lorentzon (4lDO2)
      
        on <time datetime="2024-03-29 17:00:00 +0100 +0100">Friday, March 29, 2024</time>
      
    </h5>
  
  
<p>Ever since my demand paging RSoC project was completed last summer, there have
been numerous additional incremental improvements to the kernel, including
fixes, simplifications, and some significant optimizations. The changes can be
divided into the “correctness” and “performance” categories, even though there
is a relatively large overlap.</p>

<h2 id="physalloc-replacement-and-complete-frame-bookkeeping">Physalloc replacement and complete frame bookkeeping</h2>
<p>Although the demand paging MR did formalize the different types of grants,
which previously merely indicated <em>where</em> user memory areas were, and frames
got proper bookkeeping such as the refcount, that <strong>was very much not the case
for physallocated frames.</strong> Requiring root, they were simply treated as “borrowed
physical memory” (<code>PhysBorrowed</code>), which is intended to be used by drivers to
map device memory or other pages, not controlled by the frame allocator. As a
result, some checks had to be worked around, and <strong>driver bugs could cause kernel
memory corruption</strong>.</p>
<p>This was fixed in the <a href="https://gitlab.redox-os.org/redox-os/kernel/-/merge_requests/265">phys_contiguous mmap
MR</a>, which
replaces the physalloc syscalls with a special memory scheme file,
<code>/scheme/memory/phys_contiguous?&lt;memory type&gt;</code>, instead used together with
regular mmap. As a result, deallocation is fully automatic, and most
importantly, the kernel will now <strong>deny any attempt to map allocator-owned
memory as “physically borrowed”</strong>! This should protect against e.g. faulty ACPI
AML code, but if this rule turns out to be too restrictive, it only requires
one line of code to disable.</p>
<h2 id="tlb-shootdown">TLB shootdown</h2>
<p>Virtually all CPUs supporting virtual memory, have a Translation Lookaside
Buffer to cache commonly used mappings. This makes page unmaps in multithreaded
programs more complex, as they need to ensure the TLB is up-to-date in all
other threads before they can free the frames, a mechanism called <em>TLB
shootdown</em>. That involves interrupting the other CPUs to get them to flush
their TLBs, in a synchronized way. The signals MR described below
initially did not work due to double frees elsewhere, caused by the lack of TLB
shootdown. This has now been fixed.</p>
<h2 id="improved-signal-handling">Improved signal handling</h2>
<p>The previous signal code was problematic, in that it simply implemented
userspace-like signals except also in the kernel, by copying and restoring the
kernel stacks. This meant that a Ctrl-C interrupt could cause a thread to
<code>exit()</code> before running destructors, for example resulting in a bug <a href="https://gitlab.redox-os.org/redox-os/kernel/-/issues/117">where
Orbital windows were not properly
closed</a>.</p>
<p>This was fixed in the <a href="https://gitlab.redox-os.org/redox-os/kernel/-/merge_requests/283">signals
MR</a>. Some
schemes need to implement scheme call cancellation, however, before interrupted
syscalls can fully work.</p>
<h2 id="misc">Misc</h2>
<p>Additionally, bjorn3 has fixed a lot of UB and other bugs in the kernel,
including the part that bootstraps into userspace, as well as deduplicate most
i686 and x86_64 code. The userspace-bootstrap change makes it easier to add
support for other bootloaders, such as GRUB, by integrating the bootstrap
executable (which is responsible for setting up a stack, opening standard file
descriptors, and creating the environment necessary to start the relibc
userspace, and execute init) into the initfs image.</p>
<p>An important fix as part of that, is that the initfs image including bootstrap,
is no longer mapped to address 0x0. This proves once again how important it is
not to create any Rust reference to NULL, which in this case confused bootstrap
thinking a <code>Some(&amp;initfs_memory)</code> was <code>None</code>, as the slice pointed to NULL!</p>

<h2 id="kernel-profiling">Kernel profiling</h2>
<p>Normally when optimizing userspace applications, profiling can be done easily
using e.g. <code>perf record</code> or an integrated tool such as <code>cargo flamegraph</code>. When
profiling a kernel however, the sampling part needs to be implemented from
scratch. The current implementation uses non-maskable interrupt IPIs to
interrupt other CPUs at scheduled intervals, which is necessary since
interrupts are disabled almost everywhere in kernel mode. The NMI handler
tracks whether the CPU was interrupted in user or kernel mode, and in the
latter case, performs a stack trace and sends it to a ring buffer, which a new
daemon <code>profiled</code> reads from, and extracts into a <code>perf</code>-compatible text
format.</p>
<p>Profiling userspace is yet to be implemented, possibly both as combined
userspace and kernel profiling, or just userspace.</p>
<p>With profiling enabled, this allows producing awesome
<a href="https://brendangregg.com/flamegraphs.html">flamegraphs</a>, using
<a href="https://github.com/jonhoo/inferno">inferno</a>! At the time profiling was
implemented, <strong>the following is what it looked like when booting and starting
NetSurf:</strong></p>
<p><a href="https://www.redox-os.org/img/flamegraphs/boot-and-netsurf-before.svg"><img src="https://www.redox-os.org/img/flamegraphs/boot-and-netsurf-before.svg" alt="Profiling SVG for boot and starting NetSurf"/></a></p>
<p>(Click on the flamegraphs to open them interactively.)</p>
<p>As the flamegraph suggests, a very significant part of the time spent in the
kernel, is spent allocating frames, in <code>rmm::BuddyAllocator</code>. In fact, in
some cases a massive performance boost from <a href="https://www.redox-os.org/news/kernel-9">demand paging</a> may
have been strengthened in part because frame allocation was simply very slow.
But even with demand paging, <strong>it accounted for roughly 35% of total boot
time</strong> (in the kernel, after the arch-specific initialization):</p>
<p><a href="https://www.redox-os.org/img/flamegraphs/boot-before.svg"><img src="https://www.redox-os.org/img/flamegraphs/boot-before.svg" alt="Profiling SVG for boot"/></a></p>
<h2 id="new-p2buddy-frame-allocator">New p2buddy frame allocator</h2>
<p>The obvious optimization target, apart from context switching (which at the
time was blocked by the problematic signal handling code), was therefore the
frame allocator.</p>
<p>Originally, pre-2020, the Redox kernel used a recycling allocator on top of a
bump allocator, which essentially stored an array (a <code>Vec</code>) of <code>(base, frame count)</code> that could be merged or split. In 2020, the Redox Memory Manager (RMM)
<a href="https://gitlab.redox-os.org/redox-os/kernel/-/merge_requests/155#5c18a8ea7df607b2fa2c8d143a8eced7e7449795">was
introduced</a>,
which provided a more optimized <em>buddy allocator</em>.</p>
<p>However, <strong>both the recycling allocator and RMM’s buddy allocator, were <em>O(n)</em></strong>,
w.r.t. the <strong>total number of allocatable frames</strong>. The recycling allocator had
to iterate through an array that could theoretically grow to half of the
allocatable frames (maximum fragmentation), whereas the RMM buddy allocator had
to iterate through <em>usage arrays</em> to find a sufficient number of contiguous
frames, without an optimized way to allocate in larger units. Since the
majority of frame allocations were only single-frame, as they had to be
allocatable and deallocatable independently, even the RMM buddy allocator
turned out to be relatively slow.</p>
<p>Although the RMM buddy allocator could probably have been optimized further, it
would be advantegous to reuse the already existing <code>PageInfo</code>s, which store the
refcount of userspace-owned pages to implement both CoW <code>MAP_PRIVATE</code> and
<code>MAP_SHARED</code> mmaps. That space is <strong>not used when the frame is free, so why not
use it as the frame allocator data structure</strong>?</p>
<p>The power-of-two buddy (p2buddy) allocator, uses the two words in each
<code>PageInfo</code> to implement a doubly-linked list per <em>order</em>, i.e. the
log<sub>2</sub> of the number of frames for an allocation, and stores that
order in the unused pointer bits. One bit is used to distinguish between used
and free frames, and must not be overwritten except by the allocator. The list
heads are stored as a global array. This p2buddy allocator is similar to buddy
allocators found in other kernels, such as Linux and FreeBSD.</p>
<p>The allocator now only supports power-of-two allocation sizes, called
<em>p2frames</em>, where the orders can currently range from 0 to 10, inclusive. It
looks for the smallest possible p2frame large enough for the allocation, and
possibly splits it into smaller p2frames. Freeing frames makes it look for free
neighboring p2frames, merging them into a higher-order p2frame if possible.
This algorithm is guaranteed to take <em>O(k)</em> steps, w.r.t. the (constant) number
of orders <em>k</em>. Thus, <strong>the new allocator is <em>O(1)</em> w.r.t. the total number
total frames available</strong>.</p>
<p>The new flamegraph when simply booting, is now instead:</p>
<p><a href="https://www.redox-os.org/img/flamegraphs/boot-after.svg"><img src="https://www.redox-os.org/img/flamegraphs/boot-after.svg" alt="Profiling SVG for boot, p2buddy"/></a></p>
<p>The time spent inside the frame allocator, has almost disappeared entirely, and
comprises only the 0.9% slice in the bottom-left corner. Additionally, NetSurf
now starts significantly faster, and the boot time has also been reduced. For
Jeremy, the boot time was reduced from 4s to 3s!</p>
<p>Of course, memory allocation overhead can still be significant for other
workloads, and there are lots of future optimizations to be made.</p>
<h2 id="syscall-optimization">Syscall optimization</h2>
<p>With the signal MR having flattened the kernel stacks, the syscall prologue and
epilogue code that kept track of where the userspace registers were, could be
removed. Most of the ptrace and debug logic was moved to the context switch
code, and some other improvements were made. On a CPU where the hardware
<code>syscall</code>+<code>sysret</code> latency is 56 cycles, the latency changed (roughly) as
follows, from these optimizations:</p>
<ul>
<li>August 2023, initial: 344 cycles (-0%, cumulative)</li>
<li>After signal MR: 236 cycles (-31%)</li>
<li>Caching ptrace breakpoint state: 184 cycles (-47%)</li>
<li>Using saved regs directly for syscall debugging: 116 cycles (-66%)</li>
</ul>
<p>Thus, the majority of the syscall latency on Redox <strong>is now almost spent in the
syscall/sysret microcode itself</strong>. It can probably be optimized further, even
though performance may be reduced slightly once Spectre mitigations are
properly implemented. Worth noting that this is the <em>base syscall latency</em>,
i.e. the time it takes to do an invalid syscall that returns <code>ENOSYS</code>, and not
the time spent in the various syscalls themselves. That said, most simple
syscalls, such as <code>sigprocmask</code>, do not take more than a few hundred cycles to
run.</p>

<p>This year, there have been numerous improvements both to the kernel’s
correctness, as well as raw performance. The signal and TLB shootdown MRs have
significantly improved kernel memory integrity and possibly eliminated many
hard-to-debug and nontrivial <a href="https://en.wikipedia.org/wiki/Heisenbug">heisenbugs</a>. Nevertheless, there is still a lot of
work to be done optimizing and fixing bugs in relibc, in order to improve
compatibility with ported applications, and most importantly of all, getting
closer to a self-hosted Redox.</p>


</div></div>
  </body>
</html>
