<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/yyx990803/vite-vs-next-turbo-hmr/discussions/8">Original</a>
    <h1>Is Turbopack 10x Faster than Vite?</h1>
    
    <div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="4525942" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">A week ago, Vercel announced <a href="https://twitter.com/vercel/status/1584961746418208774" rel="nofollow">Turbopack</a>, a Rust-based successor to Webpack.</p>
<p dir="auto">In the announcement, one of the headlines was that Turbopack is &#34;10x faster than Vite&#34;. This line is repeated in various marketing materials from Vercel, including <a href="https://twitter.com/vercel/status/1584961746418208774" rel="nofollow">tweet</a>, <a href="https://vercel.com/blog/turbopack" rel="nofollow">blog post</a>, and marketing emails sent to Vercel users. The benchmark graphs are also included in <a href="https://turbo.build/blog/turbopack-benchmarks#bench" rel="nofollow">Turbopack&#39;s documentation</a>, originally showing that Next 13 with Turbopack is able to perform a React Hot-Module Replacement (HMR) in 0.01s while for Vite it takes 0.09s. There were also benchmarks for cold start performance, but since none of the cold start benchmarks showed a 10x advantage, we can only assume the &#34;10x faster&#34; claim was based on the HMR performance.</p>
<p dir="auto">Vercel did not include any links to the benchmarks they used to produce these numbers in the marketing materials or the documentation. So I got curious and decided to verify the claims myself with a benchmark using the freshly released Next 13 and Vite 3.2. The code and methodology are publicly available <a href="https://github.com/yyx990803/vite-vs-next-turbo-hmr">here</a>.</p>
<p dir="auto">The gist of my methodology is comparing HMR performance by measuring the delta between the following two timestamps:</p>
<ol dir="auto">
<li>
<p dir="auto">The time when a source file is modified, recorded via a separate Node.js process watching for file changes;</p>
</li>
<li>
<p dir="auto">The time when the updated React component is re-rendered, recorded via a <code>Date.now()</code> call directly in the component&#39;s render output. Note this call happens during the virtual DOM render phase of the component so it isn&#39;t affected by React reconciliation or actual DOM updates.</p>
</li>
</ol>
<p dir="auto">The benchmark also measures the numbers in two different cases:</p>
<ol dir="auto">
<li>
<p dir="auto">The &#34;root&#34; case, where the component imports 1,000 different child components and also renders them together.</p>
</li>
<li>
<p dir="auto">The &#34;leaf&#34; case, where the component is imported by the root but has no imports or child components of its own.</p>
</li>
</ol>
<h2 dir="auto">Nuances</h2>
<p dir="auto">Before we jump to the numbers, there are a few additional nuances that are worth mentioning:</p>
<ol dir="auto">
<li>Whether Next is using React Server Components (RSC).</li>
<li>Whether Vite is using SWC instead of Babel for React transforms.</li>
</ol>
<h3 dir="auto">React Server Components</h3>
<p dir="auto">Next 13 introduced a major architectural shift in that now the components are by default server components unless the user explicitly opt-in to client mode with the <code>&#39;use client&#39;</code> directive. Not only is it the default, the Next documentation also recommends users to stay in server mode as much as possible to improve end-user performance.</p>
<p dir="auto">My initial benchmark measured Next 13&#39;s HMR performance with both the root and leaf components in server mode. The result showed that Next 13 was actually slower in both cases, and the difference was significant for leaf components.</p>
<p dir="auto"><a href="https://github.com/yyx990803/vite-vs-next-turbo-hmr/tree/df326fb22c8cf46118cf801b0250245dfbe29f9d#numbers">Round 1 snapshot (Next w/ RSC, Vite w/ Babel)</a></p>
<p dir="auto">When I posted the numbers on Twitter, it was quickly pointed out that I should be benchmarking Next components without RSC to make it equal. So I added <code>&#39;use client&#39;</code> directive to the Next root component to opt-in to client mode. Indeed, in client mode Next HMR improved significantly, going 2x faster than Vite:</p>
<p dir="auto"><a href="https://github.com/yyx990803/vite-vs-next-turbo-hmr/tree/97c58aee02c465099103593f8441af7fc7b8fae1#numbers">Round 2 snapshot (Next w/o RSC, Vite w/ Babel)</a></p>
<h3 dir="auto">SWC vs. Babel Transforms</h3>
<p dir="auto">Our goal is making the benchmark focus only on the HMR performance difference. To make sure we are actually comparing apples to apples, we should also eliminate another variable: the fact that Vite&#39;s default React preset uses Babel to transform React HMR and JSX.</p>
<p dir="auto">React HMR and JSX transforms are not features coupled to build tools. It can be done via either <a href="https://babeljs.io/" rel="nofollow">Babel</a> (js-based) or <a href="https://swc.rs/" rel="nofollow">SWC</a> (rust-based). Esbuild can also transform JSX, but lacks support for HMR. SWC is significantly faster than Babel (20x single threaded, 70x on multiple cores). The reason Vite currently defaults to Babel was a trade-off between install size and practicality. SWC&#39;s install size is quite heavy (58MB in <code>node_modules</code> whereas Vite itself is only 19MB), and many users still relied on Babel for other transforms, so a Babel pass was somewhat inevitable for them. However, that may change in the future.</p>
<p dir="auto">Vite core does not rely on Babel. Using SWC instead of Babel to handle React transforms does not require anything to be changed in Vite itself -- it is only a matter of replacing the default React plugin with <a href="https://github.com/ArnaudBarre/vite-plugin-swc-react-refresh">vite-plugin-swc-react-refresh</a>. After switching, we saw significant improvement for Vite in the root case, catching up with Next:</p>
<table role="table">
<thead>
<tr>
<th></th>
<th>Vite (root)</th>
<th>Vite (leaf)</th>
<th>Next (root)</th>
<th>Next (leaf)</th>
</tr>
</thead>
<tbody>
<tr>
<td>5-run average (ms)</td>
<td>338.2</td>
<td>141.8</td>
<td>334.6</td>
<td>84.4</td>
</tr>
</tbody>
</table>
<p dir="auto">Interestingly, the growth curve here shows that Next/turbo got 4x slower in the root case compared to the leaf case, whereas Vite only got 2.4x slower. This implies a curve where Vite HMR scales better in even larger components.</p>
<p dir="auto">In addition, switching to SWC should also improve Vite&#39;s cold start metrics in Vercel&#39;s benchmarks.</p>
<h3 dir="auto">Performance on Different Hardware</h3>
<p dir="auto">Since this is a composite benchmark that involves both Node.js and native Rust parts, there will be non-trivial variance on different hardware. The numbers I posted were gathered on my M1 MacBook Pro. Other users have run the same benchmark on different hardware and reported different results. In some cases <a href="https://twitter.com/SaurabhCharde/status/1586352676668723201" rel="nofollow">Vite is faster in the root case</a>, whereas in others <a href="https://twitter.com/Saied_Za/status/1586067681794719744" rel="nofollow">Vite is significantly faster in both cases</a>.</p>
<h2 dir="auto">Vercel&#39;s Clarification</h2>
<p dir="auto">After I posted my benchmark, Vercel published a <a href="https://turbo.build/blog/turbopack-benchmarks" rel="nofollow">blog post</a> clarifying their benchmark methodologies, and made their benchmark available for public verification. While this probably should have been done on day one, it is definitely a step in the right direction.</p>
<p dir="auto">After reading the post and benchmark code, here are a few key takeaways:</p>
<ol dir="auto">
<li>
<p dir="auto">The Vite implementation is <a href="https://github.com/vercel/turbo/blob/main/crates/next-dev/benches/bundlers/vite/vite.config.js#L2">still using the default, Babel-based React plugin</a>.</p>
</li>
<li>
<p dir="auto">There were number rounding issues in the original numbers for the 1k component case - Turbopack&#39;s 15ms was rounded down to 0.01s while Vite&#39;s 87ms was rounded up to 0.09s. This further got marketed as a 10x advantage when the original numbers were close to 6x.</p>
</li>
<li>
<p dir="auto">Vercel&#39;s benchmark uses the &#34;browser eval time&#34; of the updated module as the end timestamp, instead of React component re-render time.</p>
</li>
<li>
<p dir="auto">The post included a graph showing that Turbopack <em>can be</em> 10x faster than Vite when the total module count surpasses 30k.</p>
</li>
</ol>
<p dir="auto">To sum up, the &#34;10x faster than Vite&#34; claim would hold if all of the following are true:</p>
<ol dir="auto">
<li>Vite is <strong>not</strong> using the same SWC transform</li>
<li>The application contains over <strong>30k</strong> modules</li>
<li>The benchmark only measures the time for the hot updated module to be evaluated, but not when the changes are actually applied.</li>
</ol>
<h2 dir="auto">What is a &#34;Fair&#34; Comparison?</h2>
<p dir="auto">If what we are trying to compare is &#34;out-of-the-box default&#34;, then we should compare with RSC enabled in Next, since that is the default and is what Next is actively encouraging users to use. Since Vercel&#39;s benchmark is not using RSC, and is measuring the &#34;module evaluation time&#34; to exclude the variance caused by React&#39;s HMR runtime, it should be fair to assume that the benchmark&#39;s goal is to perform an apples-to-apples comparison of the HMR mechanism inherent to Vite and Turbopack.</p>
<p dir="auto">With that premise, unfortunately, the fact that Vite is still using Babel in the benchmark makes it not an equal scenario, and still leaves the 10x claim invalid. It should be considered inaccurate until the numbers are updated with Vite using SWC transforms.</p>
<p dir="auto">In addition, I believe most would agree that:</p>
<ul dir="auto">
<li>
<p dir="auto">30k modules is an extremely unlikely scenario for the vast majority of users. With Vite using SWC, the number of modules needed to reach the 10x claim will likely grow to be even more unrealistic. While it is theoretically possible, using it to justify the kind of marketing Vercel has been pushing seems disingenuous.</p>
</li>
<li>
<p dir="auto">Users care more about end-to-end HMR performance, i.e. the time from saving to seeing changes reflected, compared to the theoretical &#34;module evaluation&#34; timing. When seeing &#34;10x faster updates&#34;, an average user would think in terms of the former instead of the latter. Vercel conveniently omitted this caveat in its marketing. In reality, the end-to-end HMR for a server component (the default) in Next is <strong>slower</strong> than that in Vite.</p>
</li>
</ul>
<p dir="auto">As the author of Vite, I am glad to see a well-funded company like Vercel making significant investments into improving frontend tooling. We may even leverage Turbopack in Vite in the future where applicable. I believe healthy competition in the OSS space eventually benefits all developers.</p>
<p dir="auto">However, I also believe that OSS competition should be based on open communication, fair comparisons, and mutual respect. It is disappointing and concerning to see aggressive marketing using cherry-picked, non-peer-reviewed, borderline-misleading numbers typically only found in commercial competition. As a company built on top of its OSS success, I believe Vercel can do better.</p>
    </td>
  </tr>

    </tbody>
  </div></div>
  </body>
</html>
