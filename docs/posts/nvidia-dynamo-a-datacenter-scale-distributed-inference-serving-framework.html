<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/ai-dynamo/dynamo">Original</a>
    <h1>Nvidia Dynamo: A Datacenter Scale Distributed Inference Serving Framework</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto"><a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/5ce2e21e84680df1ab24807babebc3417d27d66e0826a350eb04ab57f4c8f3e5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368655f322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache_2.0-blue.svg"/></a>
<a href="https://github.com/ai-dynamo/dynamo/releases/latest"><img src="https://camo.githubusercontent.com/0d163215531d730a6cc8272875df00368b7090308a8b3a9920974241ca8033af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f61692d64796e616d6f2f64796e616d6f" alt="GitHub Release" data-canonical-src="https://img.shields.io/github/v/release/ai-dynamo/dynamo"/></a>
<a href="https://discord.gg/nvidia-dynamo" rel="nofollow"><img src="https://camo.githubusercontent.com/fefe05dcdf7ef0e82744647a0dc8ff15ad1fd657b5a61c0cf90930fefc02972d/68747470733a2f2f646362616467652e6c696d65732e70696e6b2f6170692f7365727665722f44393275715a526a435a3f7374796c653d666c6174" alt="Discord" data-canonical-src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat"/></a></p>
<p dir="auto">| <strong><a href="https://github.com/ai-dynamo/dynamo/blob/main/docs/guides">Guides</a></strong> | <strong><a href="https://github.com/ai-dynamo/dynamo/blob/main/docs/architecture.md">Architecture and Features</a></strong> | <strong><a href="https://github.com/ai-dynamo/dynamo/blob/main/lib/bindings/python/README.md">APIs</a></strong> | <strong><a href="https://github.com/ai-dynamo/dynamo/blob/main/deploy/dynamo/sdk/README.md">SDK</a></strong> |</p>
<p dir="auto">NVIDIA Dynamo is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments. Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:</p>
<ul dir="auto">
<li><strong>Disaggregated prefill &amp; decode inference</strong> – Maximizes GPU throughput and facilitates trade off between throughput and latency.</li>
<li><strong>Dynamic GPU scheduling</strong> – Optimizes performance based on fluctuating demand</li>
<li><strong>LLM-aware request routing</strong> – Eliminates unnecessary KV cache re-computation</li>
<li><strong>Accelerated data transfer</strong> – Reduces inference response time using NIXL.</li>
<li><strong>KV cache offloading</strong> – Leverages multiple memory hierarchies for higher system throughput</li>
</ul>
<p dir="auto">Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.</p>

<p dir="auto">The following examples require a few system level packages.</p>
<div data-snippet-clipboard-copy-content="apt-get update
DEBIAN_FRONTEND=noninteractive apt-get install -yq python3-dev python3-pip libucx0

pip install ai-dynamo[all]"><pre><code>apt-get update
DEBIAN_FRONTEND=noninteractive apt-get install -yq python3-dev python3-pip libucx0

pip install ai-dynamo[all]
</code></pre></div>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">TensorRT-LLM Support is currently available on a <a href="https://github.com/ai-dynamo/dynamo/tree/dynamo/trtllm_llmapi_v1/examples/trtllm#building-the-environment">branch</a></p>
</div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Running and Interacting with an LLM Locally</h3><a id="user-content-running-and-interacting-with-an-llm-locally" aria-label="Permalink: Running and Interacting with an LLM Locally" href="#running-and-interacting-with-an-llm-locally"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To run a model and interact with it locally you can call <code>dynamo run</code> with a hugging face model. <code>dynamo run</code> supports several backends
including: <code>mistralrs</code>, <code>sglang</code>, <code>vllm</code>, and <code>tensorrtllm</code>.</p>

<div data-snippet-clipboard-copy-content="dynamo run out=vllm deepseek-ai/DeepSeek-R1-Distill-Llama-8B"><pre><code>dynamo run out=vllm deepseek-ai/DeepSeek-R1-Distill-Llama-8B
</code></pre></div>
<div data-snippet-clipboard-copy-content="? User › Hello, how are you?
✔ User · Hello, how are you?
Okay, so I&#39;m trying to figure out how to respond to the user&#39;s greeting. They said, &#34;Hello, how are you?&#34; and then followed it with &#34;Hello! I&#39;m just a program, but thanks for asking.&#34; Hmm, I need to come up with a suitable reply. ..."><pre><code>? User › Hello, how are you?
✔ User · Hello, how are you?
Okay, so I&#39;m trying to figure out how to respond to the user&#39;s greeting. They said, &#34;Hello, how are you?&#34; and then followed it with &#34;Hello! I&#39;m just a program, but thanks for asking.&#34; Hmm, I need to come up with a suitable reply. ...
</code></pre></div>

<p dir="auto">Dynamo provides a simple way to spin up a local set of inference
components including:</p>
<ul dir="auto">
<li><strong>OpenAI Compatible Frontend</strong> – High performance OpenAI compatible http api server written in Rust.</li>
<li><strong>Basic and Kv Aware Router</strong> – Route and load balance traffic to a set of workers.</li>
<li><strong>Workers</strong> – Set of pre-configured LLM serving engines.</li>
</ul>
<p dir="auto">To run a minimal configuration you can use a pre-configured
example.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Start Dynamo Distributed Runtime Services</h4><a id="user-content-start-dynamo-distributed-runtime-services" aria-label="Permalink: Start Dynamo Distributed Runtime Services" href="#start-dynamo-distributed-runtime-services"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">First start the Dynamo Distributed Runtime services:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose -f deploy/docker-compose.yml up -d"><pre>docker compose -f deploy/docker-compose.yml up -d</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Start Dynamo LLM Serving Components</h4><a id="user-content-start-dynamo-llm-serving-components" aria-label="Permalink: Start Dynamo LLM Serving Components" href="#start-dynamo-llm-serving-components"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Next serve a minimal configuration with an http server, basic
round-robin router, and a single worker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd examples/llm
dynamo serve graphs.agg:Frontend -f configs/agg.yaml"><pre><span>cd</span> examples/llm
dynamo serve graphs.agg:Frontend -f configs/agg.yaml</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="curl localhost:8000/v1/chat/completions   -H &#34;Content-Type: application/json&#34;   -d &#39;{
    &#34;model&#34;: &#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;,
    &#34;messages&#34;: [
    {
        &#34;role&#34;: &#34;user&#34;,
        &#34;content&#34;: &#34;Hello, how are you?&#34;
    }
    ],
    &#34;stream&#34;:false,
    &#34;max_tokens&#34;: 300
  }&#39; | jq"><pre>curl localhost:8000/v1/chat/completions   -H <span><span>&#34;</span>Content-Type: application/json<span>&#34;</span></span>   -d <span><span>&#39;</span>{</span>
<span>    &#34;model&#34;: &#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;,</span>
<span>    &#34;messages&#34;: [</span>
<span>    {</span>
<span>        &#34;role&#34;: &#34;user&#34;,</span>
<span>        &#34;content&#34;: &#34;Hello, how are you?&#34;</span>
<span>    }</span>
<span>    ],</span>
<span>    &#34;stream&#34;:false,</span>
<span>    &#34;max_tokens&#34;: 300</span>
<span>  }<span>&#39;</span></span> <span>|</span> jq</pre></div>
</article></div></div>
  </body>
</html>
