<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://softwaredoug.com/blog/2025/01/21/llm-judge-decision-tree">Original</a>
    <h1>Coping with dumb LLMs using classic ML</h1>
    
    <div id="readability-page-1" class="page"><div>
	  <p>In <a href="https://www.faridrener.com/blog/2025/01/13/llm-for-judgment-lists">previous</a> <a href="https://www.faridrener.com/blog/2025/01/19/llm-as-judge-both-ways">posts</a> I use a local LLM to choose which two products were more relevant for a search query (see <a href="https://github.com/softwaredoug/local-llm-judge/tree/main">this github repo</a>) to guide search relevance improvements. Using human labels in an open e-commerce search dataset as a baseline (<a href="https://github.com/wayfair/WANDS/">WANDS from Wayfair</a>), I measure the LLM’s preference for a product, seeing if it matches human search relevance raters. If I can do this, then I can use my laptop as the search relevance evaluator / judge. This can then guide search quality tuning and iterations, without an expensive OpenAI bill.</p>

<p>My goal, not so much to replace other labels but to at least be a reliable to flag what looks amiss / promising much faster without needing to always recruit humans.</p>

<p>In this post I’ll talk through how I combine many dumb LLM decisions on single product attributes into a smart decision. And compare it to an agent with all the product metadata.</p>

<p>As an example, from the dumb decisions, my plucky laptop search relevance judges looked at prompts such as:</p>

<div><div><pre><code>Which of these product names (if either) is more relevant to the furniture e-commerce search query:

Query: entrance table

Product LHS name: aleah coffee table
    (remaining product attributes omited)
Or
Product RHS name:  marta coffee table
    (remaining product attributes omited)
Or
Neither / Need more product attributes

Only respond &#39;LHS&#39; or &#39;RHS&#39; if you are confident in your decision

RESPONSE:
Neither
</code></pre></div></div>

<p>Collecting 1000 agent preferences, I compare them to human preferences. Then I see if the agent is any good at predicting relevance. Then I can gain confidence, unleashing it on a pair of products for a query, and trust the results accordingly. (all assuming human evaluators are any good at this!)</p>

<p>In my posts, I look at a bunch of different variants on the above prompt:</p>

<ul>
  <li>Forcing a decision to LHS / RHS OR allowing “Neither”/ “I don’t know”  (see <a href="https://www.faridrener.com/blog/2025/01/13/llm-for-judgment-lists">first post</a>)</li>
  <li>One pass “dont double check”, OR Checking both sides, marking “Neither” if repeating the prompt swapping LHS with RHS disagreed (see <a href="https://www.faridrener.com/blog/2025/01/19/llm-as-judge-both-ways">second post</a>)</li>
</ul>

<p>I crafted prompts for 4 product attributes:</p>
<ul>
  <li>Product name (as above)</li>
  <li>Product taxonomic categorization (ie Which is more relevant? <code>Outdoor Furniture &gt; chairs &gt; ... &gt; adirondack chairs</code> vs ``Outdoor Furniture &gt; accesorries &gt; …`</li>
  <li>Product classification (ie <code>outdoor furniture</code> vs <code>living room chairs</code>)</li>
  <li>Product description (see below)</li>
</ul>

<p>As examples of these variants, here’s description prompt same two products above:</p>

<div><div><pre><code>Which of these product descriptions (if either) is more relevant to the furniture e-commerce search query:

Query: entrance table

Product LHS description: This coffee table is great for your entrance, use it to put in your doorway...
    (remaining product attributes omited)
Or
Product RHS description:  You&#39;ll love this table from lazy boy. It goes in your living room. And you&#39;ll find ...
    (remaining product attributes omited)
Or
Neither / Need more product attributes

Only respond &#39;LHS&#39; or &#39;RHS&#39; if you are confident in your decision

RESPONSE:
LHS
</code></pre></div></div>

<p>And as an example the variant where we double check, we can confirm we get the same preference swapping LHS/RHS:</p>

<div><div><pre><code>Which of these product descriptions (if either) is more relevant to the furniture e-commerce search query:

Query: entrance table

Product LHS description:  You&#39;ll love this table from lazy boy. It goes in your living room. And you&#39;ll find ...
    (remaining product attributes omited)
Or
Product RHS description: This coffee table is great for your entrance, use it to put in your doorway...
    (remaining product attributes omited)
Or
Neither / Need more product attributes

Only respond &#39;LHS&#39; or &#39;RHS&#39; if you are confident in your decision

RESPONSE:
RHS
</code></pre></div></div>

<p>Now we say the first preference is consistent. We can truly say the product description “coffee table for your entrance” is the best preference for “entrance table”.</p>

<p>All of these permutations (fields, double checking, allowing neither) are experiments I’ve run, with results below. When the agent chickens-out (or isn’t consistent in double checking) we improve precision, but lose recall.</p>

<p>On the bottom right of the table for product name below, double checking AND allowing the LLM to say “Neither”, gives us preference on 11.9% of 1000 product pairs. Within that 11.9%, we correctly predict relevance preference 90.76% of the time. That’s up considerably from the upper left - getting a decision on each pair, but with precision degraded to 75.08%.</p>

<p><img src="https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExbzQ1aHN6NjN2b2ZldWIwZDg3Y3J4dDhtZ3d0aXNtYnVjeW16bTRiYiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/DloYCssHhX1K0/giphy.gif" alt=""/></p>

<p>All permutations of field x allowing neither x double checking all listed below</p>

<h3 id="product-name">Product Name</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dont double check</th>
      <th>Double check</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Force</td>
      <td>75.08% / 100%</td>
      <td>87.99% / 65 %</td>
    </tr>
    <tr>
      <td>Allow Neither</td>
      <td>85.38% / 17.10%</td>
      <td>90.76% / 11.90%</td>
    </tr>
  </tbody>
</table>

<h3 id="product-classification">Product classification</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dont double check</th>
      <th>Double  check</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Force</td>
      <td>70.5% / 100%</td>
      <td>87.76% / 58.0%</td>
    </tr>
    <tr>
      <td>Allow Neither</td>
      <td>87.01% / 17.70%</td>
      <td>84.47% / 10.3%</td>
    </tr>
  </tbody>
</table>

<h3 id="categorization-hierarchy">Categorization Hierarchy</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dont double check</th>
      <th>Double check</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Force</td>
      <td>74.6% / 100%</td>
      <td>86.1% / 69.70%</td>
    </tr>
    <tr>
      <td>Allow Neither</td>
      <td>85.71% / 18.20%</td>
      <td>89.91% / 10.8%</td>
    </tr>
  </tbody>
</table>

<h3 id="description">Description</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dont double check</th>
      <th>Double check</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Force</td>
      <td>70.31% / 98.70%</td>
      <td>76.58% / 72.60%</td>
    </tr>
    <tr>
      <td>Allow Neither</td>
      <td>79.21% / 10.10%</td>
      <td>83.02% / 5.3%</td>
    </tr>
  </tbody>
</table>

<h2 id="putting-products-back-together">Putting products back together</h2>

<p>Finally, with all we’ve learned, we can try an uber prompt with all 4 fields listed.</p>

<div><div><pre><code>Which of these furniture products is more relevant to the furniture e-commerce search query:

Query: entrance table
Product LHS name: aleah coffee table
Product LHS description:  You&#39;ll love this table from lazy boy. It goes in your living room. And you&#39;ll find ...
 ...
Or
Product LHS name: marta coffee table
Product RHS description: This coffee table is great for your entrance, use it to put in your doorway...
 ...
Or
Neither / Need more product attributes

Only respond &#39;LHS&#39; or &#39;RHS&#39; if you are confident in your decision

RESPONSE:
RHS
</code></pre></div></div>

<p>When we apply all variants to the uber prompt. We get fairly useful results on upper right below (force / double check)</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dont double check</th>
      <th>Double check</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Force</td>
      <td>78.10% / 100.0%</td>
      <td>91.72% / 65.2%</td>
    </tr>
    <tr>
      <td>Allow Neither</td>
      <td>91.89% / 11.10%</td>
      <td>88.90% / 2.7%</td>
    </tr>
  </tbody>
</table>

<h2 id="improving-further-with-decision-trees">Improving further with decision trees</h2>

<p>Instead of an uber prompt, another strategy might be to somehow combine the individual attribute decisions into an overall decision.</p>

<p>One way of capturing all the variants above, we have a set of agent predictions for each strategy:</p>

<table>
  <thead>
    <tr>
      <th>Query</th>
      <th>LHS product</th>
      <th>RHS Product</th>
      <th>Name</th>
      <th>Desc</th>
      <th>Category</th>
      <th>Class.</th>
      <th>Human Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>entrance table</td>
      <td>alea coffee table</td>
      <td>marta coffee Table</td>
      <td>Neither</td>
      <td>LHS</td>
      <td>LHS</td>
      <td>RHS</td>
      <td>LHS</td>
    </tr>
  </tbody>
</table>

<p>Combining these dumb agents individual decisions into a smarter overall decision seems promising…</p>

<p>The first thought is we should use an ensemble! The more votes of these little attribute-specific agents wins! If they mostly point to LHS, then just choose LHS, its that easy!</p>

<p>OR… OR… and hear me out.</p>

<p>Look at the data above, imagine repeating it over 1000s of query product pairs, like:</p>

<table>
  <thead>
    <tr>
      <th>Query</th>
      <th>LHS product</th>
      <th>RHS Product</th>
      <th>Name</th>
      <th>Desc</th>
      <th>Category</th>
      <th>Class.</th>
      <th>Human Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>entrance table</td>
      <td>alea coffee table</td>
      <td>marta coffee Table</td>
      <td>Neither</td>
      <td>LHS</td>
      <td>LHS</td>
      <td>RHS</td>
      <td>LHS</td>
    </tr>
    <tr>
      <td>leather couch</td>
      <td>lazy boy recliner</td>
      <td>suede love  seat</td>
      <td>RHS</td>
      <td>LHS</td>
      <td>RHS</td>
      <td>Neither</td>
      <td>RHS</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
    </tr>
  </tbody>
</table>

<p>The really astute reader will notice something.</p>

<p><img src="https://www.faridrener.com/assets/media/2025/unix-system.jpg" alt=""/></p>

<p>It’s a Machine Learning problem!</p>

<p>We have a set of <strong>features</strong> - the individual predictions of each attribute
We have a <strong>label</strong> we want to predict - the human preference</p>

<p>The table above becomes a classification problem!</p>

<p>We can “learn” the right ensemble. Perhaps with a decision tree or other simple classifier.</p>

<p>First step, bulid up a big table like the one above with 1000s of LLM evaluations of individual fields and variants on or off. So in reality we have:</p>

<table>
  <thead>
    <tr>
      <th>Query</th>
      <th>LHS product</th>
      <th>RHS Product</th>
      <th>Name</th>
      <th>Name (double check)</th>
      <th>Name  (allow neither)</th>
      <th>Name (double check/allow neither)</th>
      <th>Desc</th>
      <th>…</th>
      <th>Human Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>entrance table</td>
      <td>alea coffee table</td>
      <td>marta coffee Table</td>
      <td>Neither</td>
      <td>LHS</td>
      <td>LHS</td>
      <td>RHS</td>
      <td>RHS</td>
      <td>…</td>
      <td>LHS</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>RHS</td>
      <td>…</td>
      <td>…</td>
    </tr>
  </tbody>
</table>

<p>So I collect N of each type of LLM evaluation with a <a href="https://github.com/softwaredoug/local-llm-judge/blob/main/collect.sh">script</a>:</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>N</span><span>=</span><span>&#34;</span><span>$1</span><span>&#34;</span>

poetry run python <span>-m</span> local_llm_judge.main <span>--verbose</span> <span>--eval-fn</span> category_allow_neither <span>--N</span> <span>$N</span>
poetry run python <span>-m</span> local_llm_judge.main <span>--verbose</span> <span>--eval-fn</span> category <span>--N</span> <span>$N</span>
poetry run python <span>-m</span> local_llm_judge.main <span>--verbose</span> <span>--eval-fn</span> category_allow_neither <span>--check-both-ways</span> <span>--N</span> <span>$N</span>

...
poetry run python <span>-m</span> local_llm_judge.main <span>--verbose</span> <span>--eval-fn</span> name <span>--N</span> <span>$N</span>
...
</code></pre></div></div>

<p>I stressed my laptops heat disapation capabilities by running <code>./collect.sh 7000</code> to get 7000 examples (first 1000 the same test used above, next 6000 I’ll use for training).</p>

<p>Each run above has an output of the query, LHS, RHS product with human and agent preference. The agent preference in each is our feature.</p>

<p>Finally, we can point a <a href="https://github.com/softwaredoug/local-llm-judge/blob/main/local_llm_judge/train.py">training script</a> to the outputs generated by each LLM run from the script above:</p>

<div><div><pre><code>$ poetry run python -m  local_llm_judge.train --feature_names data/both_ways_category.pkl data/both_ways_name.pkl  data/both_ways_desc.pkl data/both_ways_classs.pkl data/both_ways_category_allow_neither.pkl data/both_ways_name_allow_neither.pkl data/both_ways_desc_allow_neither.pkl data/both_ways_class_allow_neither.pkl
</code></pre></div></div>

<p>The training script builds out our training features (the agent preference of the agent variants we’re using) along with human pairwise preference we want to predict.</p>

<p>As a basic spike, I just use a simple Scikit decision tree to try to predict human_preference from the agent_preferences:</p>

<div><div><pre><code><span>def</span> <span>train_tree</span><span>(</span><span>train</span><span>,</span> <span>test</span><span>):</span>
    <span>clf</span> <span>=</span> <span>DecisionTreeClassifier</span><span>()</span>
    <span>clf</span><span>.</span><span>fit</span><span>(</span><span>train</span><span>.</span><span>drop</span><span>(</span><span>columns</span><span>=</span><span>[</span><span>&#39;</span><span>query</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>product_id_lhs</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>product_id_rhs</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>human_preference</span><span>&#39;</span><span>]),</span>
            <span>train</span><span>[</span><span>&#39;</span><span>human_preference</span><span>&#39;</span><span>])</span>
    <span>...</span>
</code></pre></div></div>

<p>And finally, when using the tree, we make a precision / recall tradeoff. We enforce a threshold on the prediction probability to accept the decision, otherwise label as “Neither”:</p>

<div><div><pre><code><span>def</span> <span>predict_tree</span><span>(</span><span>clf</span><span>,</span> <span>test</span><span>,</span> <span>threshold</span><span>=</span><span>0.9</span><span>):</span>
    <span>&#34;&#34;&#34;</span><span>Only assign LHS or RHS if the probability is above the threshold</span><span>&#34;&#34;&#34;</span>
    <span>probas</span> <span>=</span> <span>clf</span><span>.</span><span>predict_proba</span><span>(</span><span>test</span><span>.</span><span>drop</span><span>(</span><span>columns</span><span>=</span><span>[</span><span>&#39;</span><span>query</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>product_id_lhs</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>product_id_rhs</span><span>&#39;</span><span>,</span> <span>&#39;</span><span>human_preference</span><span>&#39;</span><span>]))</span>
    <span>definitely_lhs</span> <span>=</span> <span>probas</span><span>[:,</span> <span>0</span><span>]</span> <span>&gt;</span> <span>threshold</span>
    <span>definitely_rhs</span> <span>=</span> <span>probas</span><span>[:,</span> <span>1</span><span>]</span> <span>&gt;</span> <span>threshold</span>
</code></pre></div></div>

<p>The script tries every variant:</p>

<div><div><pre><code>[&#39;both_ways_desc_allow_neither&#39;, &#39;both_ways_class_allow_neither&#39;] 1.0 0.013
[&#39;both_ways_name&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9861111111111112 0.072
[&#39;both_ways_category&#39;, &#39;both_ways_name&#39;, &#39;both_ways_classs&#39;, &#39;both_ways_name_allow_neither&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9673366834170855 0.398
[&#39;both_ways_category&#39;, &#39;both_ways_name&#39;, &#39;both_ways_classs&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9668508287292817 0.362
[&#39;both_ways_desc&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9666666666666667 0.06
[&#39;both_ways_desc&#39;, &#39;both_ways_desc_allow_neither&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9666666666666667 0.06
[&#39;both_ways_name&#39;, &#39;both_ways_desc_allow_neither&#39;, &#39;both_ways_class_allow_neither&#39;] 0.9666666666666667 0.09
[&#39;both_ways_category&#39;, &#39;both_ways_name&#39;, &#39;both_ways_classs&#39;] 0.9665738161559888 0.359
[&#39;both_ways_category&#39;, &#39;both_ways_name&#39;, &#39;both_ways_desc&#39;, &#39;both_ways_classs&#39;, &#39;both_ways_category_allow_neither&#39;] 0.9659367396593674 0.411
[&#39;both_ways_category&#39;, &#39;both_ways_name&#39;, &#39;both_ways_classs&#39;, &#39;both_ways_category_allow_neither&#39;, &#39;both_ways_name_allow_neither&#39;] 0.9654320987654321 0.405
...
</code></pre></div></div>

<p>Many caveants to this data - how reproducible is this? What happens when we do some cross-validation or on more test data? Treat it as an interesting data point in a scientific lab notebook, not a guarantee it will definitely work.</p>

<p>The data though is quite interesting. One variant appears to be able to classify every human label in test correctly. But only for 1.3% of the data. Another does 96.5% precision on 40.5% of the data.</p>

<p>Trees allow us to see the dependencies between features when predicting relevance. We can use this as an exploratory tool to guide searc  solutions. We can dump the tree with <code>print(export_text(clf, feature_names=feature_names))</code>, noting how the tree thinks about the dependencies in the data, helping you plan, prioritize, and strategize how search should work.</p>

<div><div><pre><code>|--- both_ways_category &lt;= 0.50           # category preference is either LHS (-1) or neither (0)
|   |--- both_ways_category &lt;= -0.50          # category preference is LHS (-1)
|   |   |--- both_ways_name &lt;= 0.50               # Name preference is LHS (-1) or neither (0)
             |--- class: -1                          # Then prediction is &#34;LHS&#34;
...
</code></pre></div></div>

<p>According to this tree, any search solution might want to focus on category first before considering name, for example.</p>

<p>Finally, this is just the start. A dumb decision tree classifier may not be the best choice. Perhaps we want to do some kind of gradient boosting instead of a tree? Given trees tend to overfit, perhaps another solution would be best.</p>

<p>But the upshot of all this is we can take lots of dumb agents, making single, basic decisions, and combine their outputs into something smarter using traditional ML. We can use them to understand the reasoning behind human labels, helping inform how we build solutions. Local LLMs could become ML feature generators, maybe heavily cachable ones at that! We keep their decisions dumb, simple, and interpretable combining them at the end with fast boring, old ML that can finish the job.</p>

      


	  </div></div>
  </body>
</html>
