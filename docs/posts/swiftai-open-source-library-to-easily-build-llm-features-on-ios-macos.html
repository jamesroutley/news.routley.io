<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/mi12labs/SwiftAI">Original</a>
    <h1>Show HN: SwiftAI – open-source library to easily build LLM features on iOS/macOS</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">A modern, type-safe Swift library for building AI-powered apps. SwiftAI provides a unified API that works seamlessly across different AI models - from Apple&#39;s on-device models to cloud-based services like OpenAI.</p>
<p dir="auto"><a href="https://swift.org" rel="nofollow"><img src="https://camo.githubusercontent.com/82dbddd91d4872f77254e7d422d3359e1d65f7220da0042eb8b872db547dd737/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53776966742d352e31302b2d6f72616e67652e737667" alt="Swift 5.10+" data-canonical-src="https://img.shields.io/badge/Swift-5.10+-orange.svg"/></a>
<a href="https://developer.apple.com/ios/" rel="nofollow"><img src="https://camo.githubusercontent.com/91cd9a821ad13d6c3d96810e82b8996744ae464bf4f68f6388872149f0dd2f97/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f694f532d31372e302b2d626c75652e737667" alt="iOS 17.0+" data-canonical-src="https://img.shields.io/badge/iOS-17.0+-blue.svg"/></a>
<a href="https://developer.apple.com/macos/" rel="nofollow"><img src="https://camo.githubusercontent.com/1b319debc2f6d3569197d622b547f65819f8e93cd59c6695ae6537ee74fc533f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d61634f532d31342e302b2d626c75652e737667" alt="macOS 14.0+" data-canonical-src="https://img.shields.io/badge/macOS-14.0+-blue.svg"/></a>
<a href="https://github.com/mi12labs/SwiftAI/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"/></a></p>

<ul dir="auto">
<li>🤖 <strong>Model Agnostic</strong>: Unified API across Apple&#39;s on-device models, OpenAI, Anthropic, and custom backends</li>
<li>🎯 <strong>Structured Output</strong>: Strongly-typed structured outputs with compile-time validation</li>
<li>🔧 <strong>Agent Tool Loop</strong>: First-class support for tool use</li>
<li>💬 <strong>Conversations</strong>: Stateful chat sessions with automatic context management</li>
<li>🏗️ <strong>Extensible</strong>: Plugin architecture for custom models and tools</li>
<li>⚡ <strong>Swift-Native</strong>: Built with async/await and modern Swift concurrency</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="import SwiftAI

let llm = SystemLLM()
let response = try await llm.reply(to: &#34;What is the capital of France?&#34;)
print(response.content) // &#34;Paris&#34;"><pre><span>import</span> SwiftAI

<span>let</span> <span>llm</span> <span>=</span> <span>SystemLLM</span><span>(</span><span>)</span>
<span>let</span> <span>response</span> <span>=</span> <span><span>try</span></span> <span>await</span> llm<span>.</span><span>reply</span><span>(</span>to<span>:</span> <span>&#34;</span><span>What is the capital of France?</span><span>&#34;</span><span>)</span>
<span>print</span><span>(</span>response<span>.</span>content<span>)</span> // &#34;Paris&#34;</pre></div>


<p dir="auto"><strong>Xcode:</strong></p>
<ol dir="auto">
<li>Go to <strong>File → Add Package Dependencies</strong></li>
<li>Enter: <code>https://github.com/mi12labs/SwiftAI</code></li>
<li>Click <strong>Add Package</strong></li>
</ol>
<p dir="auto"><strong>Package.swift:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="dependencies: [
    .package(url: &#34;https://github.com/mi12labs/SwiftAI&#34;, from: &#34;main&#34;)
]"><pre><span>dependencies:</span> <span>[</span>
    <span>.</span><span>package</span><span>(</span>url<span>:</span> <span>&#34;</span><span>https://github.com/mi12labs/SwiftAI</span><span>&#34;</span><span>,</span> from<span>:</span> <span>&#34;</span><span>main</span><span>&#34;</span><span>)</span>
<span>]</span></pre></div>

<div dir="auto"><h3 tabindex="-1" dir="auto">🚀 Step 1: Your First AI Query</h3><a id="user-content--step-1-your-first-ai-query" aria-label="Permalink: 🚀 Step 1: Your First AI Query" href="#-step-1-your-first-ai-query"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Start with the simplest possible example - just ask a question and get an answer:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import SwiftAI

// Initialize Apple&#39;s on-device language model.
let llm = SystemLLM()

// Ask a question and get a response.
let response = try await llm.reply(to: &#34;What is the capital of France?&#34;)
print(response.content) // &#34;Paris&#34;"><pre><span>import</span> SwiftAI

// Initialize Apple&#39;s on-device language model.
<span>let</span> <span>llm</span> <span>=</span> <span>SystemLLM</span><span>(</span><span>)</span>

// Ask a question and get a response.
<span>let</span> <span>response</span> <span>=</span> <span><span>try</span></span> <span>await</span> llm<span>.</span><span>reply</span><span>(</span>to<span>:</span> <span>&#34;</span><span>What is the capital of France?</span><span>&#34;</span><span>)</span>
<span>print</span><span>(</span>response<span>.</span>content<span>)</span> // &#34;Paris&#34;</pre></div>
<p dir="auto"><strong>What just happened?</strong></p>
<ul dir="auto">
<li><code>SystemLLM()</code> creates Apple&#39;s on-device AI model</li>
<li><code>reply(to:)</code> sends your question and returns a <code>String</code> by default</li>
<li><code>try await</code> handles the asynchronous AI processing</li>
<li>The response is wrapped in a <code>response</code> object - use <code>.content</code> to get the actual text</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">📊 Step 2: Structured Responses</h3><a id="user-content--step-2-structured-responses" aria-label="Permalink: 📊 Step 2: Structured Responses" href="#-step-2-structured-responses"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Instead of getting plain text, let&#39;s get structured data that your app can use directly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Define the structure you want back
@Generable
struct CityInfo {
  let name: String
  let country: String
  let population: Int
}

let response = try await llm.reply(
  to: &#34;Tell me about Tokyo&#34;,
  returning: CityInfo.self // Tell the LLM what to output
)

let cityInfo = response.content
print(cityInfo.name)       // &#34;Tokyo&#34;
print(cityInfo.country)    // &#34;Japan&#34;
print(cityInfo.population) // 13960000"><pre>// Define the structure you want back
<span>@<span>Generable</span></span>
<span>struct</span> <span>CityInfo</span> <span>{</span>
  <span>let</span> <span><span>name</span></span><span>:</span> <span>String</span>
  <span>let</span> <span><span>country</span></span><span>:</span> <span>String</span>
  <span>let</span> <span><span>population</span></span><span>:</span> <span>Int</span>
<span>}</span>

<span>let</span> <span>response</span> <span>=</span> <span><span>try</span></span> <span>await</span> llm<span>.</span><span>reply</span><span>(</span>
  to<span>:</span> <span>&#34;</span><span>Tell me about Tokyo</span><span>&#34;</span><span>,</span>
  returning<span>:</span> <span>CityInfo</span><span>.</span>self // Tell the LLM what to output
<span>)</span>

<span>let</span> <span>cityInfo</span> <span>=</span> response<span>.</span>content
<span>print</span><span>(</span>cityInfo<span>.</span>name<span>)</span>       // &#34;Tokyo&#34;
<span>print</span><span>(</span>cityInfo<span>.</span>country<span>)</span>    // &#34;Japan&#34;
<span>print</span><span>(</span>cityInfo<span>.</span>population<span>)</span> // 13960000</pre></div>
<p dir="auto"><strong>What&#39;s new here?</strong></p>
<ul dir="auto">
<li><code>@Generable</code> tells SwiftAI this struct can be generated by AI</li>
<li><code>returning: CityInfo.self</code> specifies you want structured data, not a string</li>
<li>SwiftAI automatically converts the AI&#39;s response into your struct</li>
<li>No JSON parsing required!</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">💡 Key Concept: Type-Safe AI</h4><a id="user-content--key-concept-type-safe-ai" aria-label="Permalink: 💡 Key Concept: Type-Safe AI" href="#-key-concept-type-safe-ai"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">SwiftAI ensures the AI returns data in exactly the format your code expects. If the AI can&#39;t generate valid data, you&#39;ll get an error instead of broken data.</p>

<p dir="auto">Let your AI call functions in your app to get real-time information:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Create a tool the AI can use
struct WeatherTool: Tool {
  let description = &#34;Get current weather for a city&#34;

  @Generable
  struct Arguments {
    let city: String
  }

  func call(arguments: Arguments) async throws -&gt; String {
    // Your weather API logic here
    return &#34;It&#39;s 72°F and sunny in \(arguments.city)&#34;
  }
}

// Use the tool with your AI
let weatherTool = WeatherTool()
let response = try await llm.reply(
    to: &#34;What&#39;s the weather like in San Francisco?&#34;,
    tools: [weatherTool]
)
print(response.content) // &#34;Based on current data, it&#39;s 72°F and sunny in San Francisco&#34;"><pre>// Create a tool the AI can use
<span>struct</span> <span>WeatherTool</span><span>:</span> <span>Tool</span> <span>{</span>
  <span>let</span> <span><span>description</span></span> <span>=</span> <span>&#34;</span><span>Get current weather for a city</span><span>&#34;</span>

  <span>@<span>Generable</span></span>
  <span>struct</span> <span>Arguments</span> <span>{</span>
    <span>let</span> <span><span>city</span></span><span>:</span> <span>String</span>
  <span>}</span>

  <span>func</span> call<span>(</span>arguments<span>:</span> <span>Arguments</span><span>)</span> <span>async</span> <span>throws</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    // Your weather API logic here
    <span>return</span> <span>&#34;</span><span>It&#39;s 72°F and sunny in </span><span>\(</span>arguments<span>.</span>city<span>)</span><span>&#34;</span>
  <span>}</span>
<span>}</span>

// Use the tool with your AI
<span>let</span> <span>weatherTool</span> <span>=</span> <span>WeatherTool</span><span>(</span><span>)</span>
<span>let</span> <span>response</span> <span>=</span> <span><span>try</span></span> <span>await</span> llm<span>.</span><span>reply</span><span>(</span>
    to<span>:</span> <span>&#34;</span><span>What&#39;s the weather like in San Francisco?</span><span>&#34;</span><span>,</span>
    tools<span>:</span> <span>[</span>weatherTool<span>]</span>
<span>)</span>
<span>print</span><span>(</span>response<span>.</span>content<span>)</span> // &#34;Based on current data, it&#39;s 72°F and sunny in San Francisco&#34;</pre></div>
<p dir="auto"><strong>What&#39;s new here?</strong></p>
<ul dir="auto">
<li><code>Tool</code> protocol lets you create functions the AI can call</li>
<li><code>Arguments</code> struct defines what parameters your tool needs (also <code>@Generable</code>)</li>
<li>The AI automatically decides when to call your tool</li>
<li>You get back a natural language response that incorporates the tool&#39;s data</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">💡 Key Concept: AI Function Calling</h4><a id="user-content--key-concept-ai-function-calling" aria-label="Permalink: 💡 Key Concept: AI Function Calling" href="#-key-concept-ai-function-calling"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The AI reads your tool&#39;s description and automatically decides whether to call it. You don&#39;t manually trigger tools - the AI does it when needed.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">🔄 Step 4: Model Switching</h3><a id="user-content--step-4-model-switching" aria-label="Permalink: 🔄 Step 4: Model Switching" href="#-step-4-model-switching"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Different AI models have different strengths. SwiftAI makes switching seamless:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Choose your model based on availability
let llm: any LLM = {
  let systemLLM = SystemLLM()
  return systemLLM.isAvailable ? systemLLM : OpenaiLLM(apiKey: &#34;your-api-key&#34;)
}()

// Same code works with any model
let response = try await llm.reply(to: &#34;Write a haiku about Berlin.&#34;)
print(response.content)"><pre>// Choose your model based on availability
<span>let</span> <span>llm</span><span>:</span> <span>any</span> <span>LLM</span> <span>=</span> <span>{</span>
  <span>let</span> <span>systemLLM</span> <span>=</span> <span>SystemLLM</span><span>(</span><span>)</span>
  <span>return</span> systemLLM<span>.</span>isAvailable <span>?</span> systemLLM <span>:</span> <span>OpenaiLLM</span><span>(</span>apiKey<span>:</span> <span>&#34;</span><span>your-api-key</span><span>&#34;</span><span>)</span>
<span>}</span><span>(</span><span>)</span>

// Same code works with any model
<span>let</span> <span>response</span> <span>=</span> <span><span>try</span></span> <span>await</span> llm<span>.</span><span>reply</span><span>(</span>to<span>:</span> <span>&#34;</span><span>Write a haiku about Berlin.</span><span>&#34;</span><span>)</span>
<span>print</span><span>(</span>response<span>.</span>content<span>)</span></pre></div>
<p dir="auto"><strong>What&#39;s new here?</strong></p>
<ul dir="auto">
<li><code>SystemLLM</code> runs on-device (private, fast, free)</li>
<li><code>OpenaiLLM</code> uses the cloud (more capable, requires API key)</li>
<li><code>isAvailable</code> checks if the on-device model is ready</li>
<li>Same <code>reply()</code> method works with any LLM</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">💡 Key Concept: Model Agnostic API</h4><a id="user-content--key-concept-model-agnostic-api" aria-label="Permalink: 💡 Key Concept: Model Agnostic API" href="#-key-concept-model-agnostic-api"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Your code doesn&#39;t change when you switch models. This lets you optimize for different scenarios (privacy, capabilities, cost) without rewriting your app.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">💬 Step 5: Conversations</h3><a id="user-content--step-5-conversations" aria-label="Permalink: 💬 Step 5: Conversations" href="#-step-5-conversations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For multi-turn conversations, use <code>Chat</code> to maintain context across messages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Create a chat with tools
let chat = try Chat(with: llm, tools: [weatherTool])

// Have a conversation
let greeting = try await chat.send(&#34;Hello! I&#39;m planning a trip.&#34;)
let advice = try await chat.send(&#34;What should I pack for Seattle?&#34;)
// The AI remembers context from previous messages"><pre>// Create a chat with tools
<span>let</span> <span>chat</span> <span>=</span> <span><span>try</span></span> <span>Chat</span><span>(</span>with<span>:</span> llm<span>,</span> tools<span>:</span> <span>[</span>weatherTool<span>]</span><span>)</span>

// Have a conversation
<span>let</span> <span>greeting</span> <span>=</span> <span><span>try</span></span> <span>await</span> chat<span>.</span><span>send</span><span>(</span><span>&#34;</span><span>Hello! I&#39;m planning a trip.</span><span>&#34;</span><span>)</span>
<span>let</span> <span>advice</span> <span>=</span> <span><span>try</span></span> <span>await</span> chat<span>.</span><span>send</span><span>(</span><span>&#34;</span><span>What should I pack for Seattle?</span><span>&#34;</span><span>)</span>
// The AI remembers context from previous messages</pre></div>
<p dir="auto"><strong>What&#39;s new here?</strong></p>
<ul dir="auto">
<li><code>Chat</code> maintains conversation history automatically</li>
<li><code>send()</code> is like <code>reply()</code> but remembers previous messages</li>
<li>Tools work in conversations too</li>
<li>The AI remembers context from earlier in the conversation</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">💡 Key Concept: Stateful vs Stateless</h4><a id="user-content--key-concept-stateful-vs-stateless" aria-label="Permalink: 💡 Key Concept: Stateful vs Stateless" href="#-key-concept-stateful-vs-stateless"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><code>reply()</code> is stateless - each call is independent</li>
<li><code>Chat</code> is stateful - builds on previous conversation</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">🎯 Step 6: Advanced Constraints</h3><a id="user-content--step-6-advanced-constraints" aria-label="Permalink: 🎯 Step 6: Advanced Constraints" href="#-step-6-advanced-constraints"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Add validation rules and descriptions to guide AI generation:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@Generable
struct UserProfile {
  @Guide(description: &#34;A valid username starting with a letter&#34;, .pattern(&#34;^[a-zA-Z][a-zA-Z0-9_]{2,}$&#34;))
  let username: String

  @Guide(description: &#34;User age in years&#34;, .minimum(13), .maximum(120))
  let age: Int

  @Guide(description: &#34;One to three favorite colors&#34;, .minimumCount(1), .maximumCount(3))
  let favoriteColors: [String]
}"><pre><span>@<span>Generable</span></span>
<span>struct</span> <span>UserProfile</span> <span>{</span>
  <span>@<span>Guide</span><span>(</span>description<span>:</span> <span>&#34;</span><span>A valid username starting with a letter</span><span>&#34;</span><span>,</span> <span>.</span>pattern<span>(</span><span>&#34;</span><span>^[a-zA-Z][a-zA-Z0-9_]{2,}$</span><span>&#34;</span><span>)</span><span>)</span></span>
  <span>let</span> <span><span>username</span></span><span>:</span> <span>String</span>

  <span>@<span>Guide</span><span>(</span>description<span>:</span> <span>&#34;</span><span>User age in years</span><span>&#34;</span><span>,</span> <span>.</span>minimum<span>(</span><span>13</span><span>)</span><span>,</span> <span>.</span>maximum<span>(</span><span>120</span><span>)</span><span>)</span></span>
  <span>let</span> <span><span>age</span></span><span>:</span> <span>Int</span>

  <span>@<span>Guide</span><span>(</span>description<span>:</span> <span>&#34;</span><span>One to three favorite colors</span><span>&#34;</span><span>,</span> <span>.</span>minimumCount<span>(</span><span>1</span><span>)</span><span>,</span> <span>.</span>maximumCount<span>(</span><span>3</span><span>)</span><span>)</span></span>
  <span>let</span> <span><span>favoriteColors</span></span><span>:</span> <span>[</span><span>String</span><span>]</span>
<span>}</span></pre></div>
<p dir="auto"><strong>What&#39;s new here?</strong></p>
<ul dir="auto">
<li><code>@Guide</code> adds constraints and descriptions to fields which help LLM generate good content</li>
<li><code>.pattern()</code> tells the LLM to follow a regex</li>
<li><code>.minimum()</code> and <code>.maximum()</code> constrain numbers</li>
<li><code>.minimumCount()</code> and <code>.maximumCount()</code> control array sizes</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">💡 Key Concept: Validated Generation</h4><a id="user-content--key-concept-validated-generation" aria-label="Permalink: 💡 Key Concept: Validated Generation" href="#-key-concept-validated-generation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Constraints ensure the AI follows your business rules.</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>What You Want</th>
<th>What To Use</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple text response</td>
<td><code>reply(to:)</code></td>
<td><code>reply(to: &#34;Hello&#34;)</code></td>
</tr>
<tr>
<td>Structured data</td>
<td><code>reply(to:returning:)</code></td>
<td><code>reply(to: &#34;...&#34;, returning: MyStruct.self)</code></td>
</tr>
<tr>
<td>Function calling</td>
<td><code>reply(to:tools:)</code></td>
<td><code>reply(to: &#34;...&#34;, tools: [myTool])</code></td>
</tr>
<tr>
<td>Conversation</td>
<td><code>Chat</code></td>
<td><code>chat.send(&#34;Hello&#34;)</code></td>
</tr>
<tr>
<td>Model switching</td>
<td><code>any LLM</code></td>
<td><code>SystemLLM()</code> or <code>OpenaiLLM()</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Type</th>
<th>Privacy</th>
<th>Capabilities</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SystemLLM</strong></td>
<td>On-device</td>
<td>🔒 Private</td>
<td>Good</td>
<td>🆓 Free</td>
</tr>
<tr>
<td><strong>OpenaiLLM</strong></td>
<td>Cloud API</td>
<td><g-emoji alias="warning">⚠️</g-emoji> Shared</td>
<td>Excellent</td>
<td>💰 Paid</td>
</tr>
<tr>
<td><strong>CustomLLM</strong></td>
<td>Your choice</td>
<td>Your choice</td>
<td>Your choice</td>
<td>Your choice</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">Check the <code>Examples/</code> directory for sample apps that uses SwiftAI.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">⚡ Feature Parity Status vs FoundationModels SDK</h2><a id="user-content--feature-parity-status-vs-foundationmodels-sdk" aria-label="Permalink: ⚡ Feature Parity Status vs FoundationModels SDK" href="#-feature-parity-status-vs-foundationmodels-sdk"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Streaming responses</td>
<td>❌ <a href="https://github.com/mi12labs/SwiftAI/issues/2" data-hovercard-type="issue" data-hovercard-url="/mi12labs/SwiftAI/issues/2/hovercard">#issue</a></td>
</tr>
<tr>
<td>Structured outputs for enums</td>
<td>❌ <a href="https://github.com/mi12labs/SwiftAI/issues/4" data-hovercard-type="issue" data-hovercard-url="/mi12labs/SwiftAI/issues/4/hovercard">#issue</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">We welcome contributions! Please read our <a href="https://github.com/mi12labs/SwiftAI/blob/main/CONTRIBUTING.md">Contributing Guidelines</a>.</p>

<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/your-org/SwiftAI.git
cd SwiftAI
swift build
swift test"><pre>git clone https://github.com/your-org/SwiftAI.git
<span>cd</span> SwiftAI
swift build
swift <span>test</span></pre></div>

<p dir="auto">SwiftAI is released under the MIT License. See <a href="https://github.com/mi12labs/SwiftAI/blob/main/LICENSE">LICENSE</a> for details.</p>

<p dir="auto">SwiftAI is <strong>alpha</strong> 🚧 – rough edges and breaking changes are expected.</p>
<hr/>
<p dir="auto">Built with ❤️ for the Swift community</p>
</article></div></div>
  </body>
</html>
