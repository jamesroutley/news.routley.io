<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2309.04332">Original</a>
    <h1>Graph Neural Networks Use Graphs When They Shouldn&#39;t</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2309.04332">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  Predictions over graphs play a crucial role in various domains, including
social networks, molecular biology, medicine, and more. Graph Neural Networks
(GNNs) have emerged as the dominant approach for learning on graph data.
Instances of graph labeling problems consist of the graph-structure (i.e., the
adjacency matrix), along with node-specific feature vectors. In some cases,
this graph-structure is non-informative for the predictive task. For instance,
molecular properties such as molar mass depend solely on the constituent atoms
(node features), and not on the molecular structure. While GNNs have the
ability to ignore the graph-structure in such cases, it is not clear that they
will. In this work, we show that GNNs actually tend to overfit the
graph-structure in the sense that they use it even when a better solution can
be obtained by ignoring it. We examine this phenomenon with respect to
different graph distributions and find that regular graphs are more robust to
this overfitting. We then provide a theoretical explanation for this
phenomenon, via analyzing the implicit bias of gradient-descent-based learning
of GNNs in this setting. Finally, based on our empirical and theoretical
findings, we propose a graph-editing method to mitigate the tendency of GNNs to
overfit graph-structures that should be ignored. We show that this method
indeed improves the accuracy of GNNs across multiple benchmarks.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Maya Bechler-Speicher [<a href="https://arxiv.org/show-email/8a42092b/2309.04332">view email</a>]
      </p></div></div>
  </body>
</html>
