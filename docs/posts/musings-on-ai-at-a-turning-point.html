<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://riskmusings.substack.com/p/musings-on-ai-at-a-turning-point">Original</a>
    <h1>Musings on AI at a Turning Point</h1>
    
    <div id="readability-page-1" class="page"><div><div dir="auto"><p><span>It’s terrifying when our creations exceed us. Exhilarating and inspiring too. But mythology is rife with creators devouring or casting out their children when they perceived those children as a threat. AI raises these questions for us, especially with the recent release of </span><a href="https://chat.openai.com" rel="">ChatGPT</a><span>, a large language model that produces surprisingly human responses.</span></p><p><span>To be clear, there is zero chance ChatGPT will take over the world tomorrow or anytime soon, but if AI might view humans as outmoded relics </span><em>someday</em><span>, what is the right approach to that possibility? </span></p><p><strong>How about, “Just don’t go there and don’t make super-powerful AI”?</strong></p><p><span>That’s an understandable impulse, but as numerous individuals and organizations worldwide experiment with AI, it’s likely that someone, somewhere, someday </span><em>will</em><span> go there, so turning our backs seems like a non-starter from a practical standpoint. </span></p><p><span>“</span><a href="https://riskmusings.substack.com/p/possible-paths-for-ai-regulation" rel="">Strengthen controls and keep them strong</a><span>” is a good impulse, but risk managers face a far harder task than humans or AIs that try to bypass controls: the attackers only need to be right once, whereas the defenders need to be right every time. This strongly suggests controls will eventually fail. </span></p><p><span>So, are we just buying time, a few more decades before the inevitable ascendance of artificial general intelligence (AGI)? That probably sounds hyperbolic, and it feels that way to me, too. But in the face of major advances in technology, hyperbole also feels justifiable. Fear feels equally justifiable, but it must be channeled into action: what can humans do to prepare for AGI? How can we best think about </span><a href="https://riskmusings.substack.com/p/possible-paths-for-ai-regulation" rel="">a control framework</a><span> that might be sustainable? </span></p><p><strong>Let’s get real: will AI take my job?</strong></p><p><span>Well, there’s </span><a href="https://www.quora.com/Calculators-didn-t-replace-mathematicians-So-can-you-say-in-the-same-way-that-AI-wont-replace-humans" rel="">an argument</a><span> that calculators didn’t destroy humans’ ability to have careers as mathematicians, and that’s heartening on the surface. Most software developers don’t program in assembly code anymore, either, and no one seems up in arms about that. Few engineers miss slide rules.</span></p><p>Similarly, AI will probably change how people approach computing. Software developers might become more like racecar drivers in the future, steering AI toward optimal performance. And that will be a different profession, but maybe not a worse profession. </p><p>And yet. Calculators, high-level programming languages, and engineering software aren’t designed to improve themselves over time. AI is (or can be). </p><p><span>And there’s something about thinking through a problem with slow tenacity and distractible brain cells, failing and failing and maybe finally succeeding, that builds pathways for innovation. I deeply hope there are problems that humans will always be better at solving—that we will not be outperformed in every way. Because humans need purpose, </span><a href="https://riskmusings.substack.com/p/opportunity-and-hope" rel="">we need opportunity and hope</a><span> in order to feel fulfilled.</span></p><p><strong>I’m still getting the sense that our future is up in the air?</strong><span> </span></p><p><span>Despite ChatGPT’s incredible performance, it isn’t necessarily a hope-klller in its current incarnation. Its poetry is surprisingly impressive, but </span><a href="https://www.theamandagorman.com/" rel="">Amanda Gorman</a><span> could easily blow it out of the water. Its essays are adequate, but watermarking technology could prevent them from making high-school writing assignments moot. As </span></p><p><span> writes, &#34;</span><a href="https://thealgorithmicbridge.substack.com/p/openai-has-the-key-to-identify-chatgpts" rel="">OpenAI Has the Key To Identify ChatGPT&#39;s Writing</a><span>.&#34; </span></p><p><span>So, in some fields, AI might turn out to be an opportunity-expander like the calculator was. In others, like time-consuming visual art that’s often a nice-to-have instead of a must-have, </span><a href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="">the threat that human artists could become obsolete feels imminent</a><span>. </span></p><p>What’s clear is that AI is important, and it is here now, and we cannot go back. </p><p>Seeing ChatGPT’s output reminds me of the first time I downloaded the Mosaic web browser in 1994. It was instantly clear that this was addictive, a gateway to something not-quite-formed but world-changing, that this was a new way of working, a new way of learning, a new way of thinking from link to link to link instead of A to Z through a book. I didn’t realize it yet, but my attention span was about to shatter. I couldn’t stop clicking, reading, learning to build websites in this new online web. </p><p>Similarly, being part of AI’s evolution will be addictive. It will be rewarding. But, much like the web turned out to be, it is going to be a double-edged sword. </p><p>That’s because I value my humanity, the slowness of my cells’ mitosis, the complex cascades of biological processes, the amazing phenomenon of conscious and subconscious thought (we still don’t know everything about how our brains work!). I value the craft and effort brought to creating a poem, a piece of music, a novel, a machine, a company. Whether raising a child or making art, creation can give meaning to life—and not just creation, but the shepherding of those creations. </p><p>So, here we are, with ChatGPT—one of our creations—showing suddenly and irrevocably that AI’s advances will come in bursts, nothing and nothing and then suddenly something that stuns us out of our chairs. We’re creating innovations that may surpass us now, and that’s scary. Not because of today’s technology, but because of tomorrow’s. </p><p>More to come.</p><p>-&lt;&gt;-&lt;&gt;-&lt;&gt;-</p><p><strong>Extra, Extra!</strong></p><p>Tangential extras for curious readers: </p><p><span>1. </span><a href="https://www.elementsofai.com/" rel="">Elements of AI</a><span> - by the University of Helsinki and MinnaLearn </span><em>- </em><span>a free online course in AI basics for non-experts. </span></p><p><span>2. </span><a href="https://www.nextplatform.com/2022/12/01/counting-the-cost-of-training-large-language-models/" rel="">Counting the Cost of Training Large Language Models</a><span> - by Timothy Prickett Morgan in </span><em>The Next Platform </em><span>- looking under the hood at the technology used to train large language models like GPT-3.</span></p></div></div></div>
  </body>
</html>
