<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://samsunglabs.github.io/MegaPortraits/">Original</a>
    <h1>MegaPortraits: One-Shot Megapixel Neural Head Avatars</h1>
    
    <div id="readability-page-1" class="page"><section>
    <div>

  <div>
    
    

  


        

        <p>
          ACMM 2022
        </p>

    <div>


            <div>
            <!-- <div class="row" > -->
            <div>
                <p><img src="https://samsunglabs.github.io/MegaPortraits/static/images/add_port.jpg" alt=""/>
                </p>
            </div>
              </div>

          

    </div>
        <!--odiv <div class="is-size-4 publication-authors">
        </>
         -->

  <!-- Icons Grid -->
  <section>
    
  </section>



  <section>
    <div>

      <div>

        <div>

          <p>
            <h2>Abstract</h2>
          </p>


          <div>

            <p>
In this work, we advance the neural head avatar technology to the
megapixel resolution while focusing on the particularly challenging
task of cross-driving synthesis, i.e., when the appearance of the
driving image is substantially different from the animated source
image. We propose a set of new neural architectures and training
methods that can leverage both medium-resolution video data and
high-resolution image data to achieve the desired levels of rendered
image quality and generalization to novel views and motion. We
show that suggested architectures and methods produce convincing
high-resolution neural avatars, outperforming the competitors in
the cross-driving scenario. Lastly, we show how a trained high-
resolution neural avatar model can be distilled into a lightweight
student model which runs in real-time and locks the identities of
neural avatars to several dozens of pre-defined source images. Real-time operation and identity lock are essential for many practical
applications head avatar systems.
            </p>
            
            
        </div>

        
          


          

        <p>
          <h2>Main scheme</h2>
        </p>

        <div>
          <center>
            <div>
              <p><img src="https://samsunglabs.github.io/MegaPortraits/static/images/method.png" alt=""/>
              </p>
            </div>
        </center></div>

      <div>
        <p>
          We propose a system for the one-shot creation of high-resolution
          human avatars, called megapixel portraits or MegaPortraits for short.
          Our model is trained in two stages. Optionally, we propose an
          additional distillation stage for faster inference.
        </p>
        <p>
          Our training setup is relatively standard. We sample two random frames from our dataset at each step: the source frame and the driver frame. Our model imposes the motion of the driving frame (i.e., the
          head pose and the facial expression) onto the appearance of the source frame to produce an output image. The main learning signal is obtained from the training episodes where the source and the
          driver frames come from the same video, and hence our model’s prediction is trained to match the driver frame.
        </p>      

        </div>
      </div>
    </div>
  </div>

</section>








<!--  <section class="hero">-->
<!--    <!– <div class="columns is-centered">-->
<!--      <h2 class="title is-4">Magnification Results</h2>-->
<!--    </div> –>-->
<!--    <div class="hero-body">-->
<!--  </section>-->


  <section>
    
<!--    <div class="container">-->
<!--          <div class=" is-centered ">-->
<!--            <!– <div class="row" > –>-->
<!--            <div class="column is-centered">-->
<!--                <div class="item is-centered">-->
<!--                  <video poster="" id="blocks" autoplay controls muted loop  height="50%">-->
<!--                    <source src="static/videos/results/presentation.mp4" type="video/mp4">-->
<!--                  </video>-->
<!--                </div>-->
<!--            </div>-->
<!--  -->
<!--    </div>-->


    <div>
          <div>
            <!-- <div class="row" > -->
            <div>
                <p>
                  <iframe width="1280" height="720" src="https://www.youtube.com/embed/9D5ulvdg0jM">
                  </iframe>
                </p>
            </div>

    </div>


<!--    <div class="container">-->
<!--      <div class="content  is-centered has-text-centered">-->
<!--        <h3 class="title is-2">Comparision</h3>-->
<!--      </div>-->

<!--    <div class="columns is-centered">-->

<!--        <div class="column">-->
<!--          <h3 class="title is-4">256 input/output resolution</h3>-->
<!--          <div class="columns is-centered">-->
<!--            <div class="column content">-->
<!--              <div class="text-white">-->
<!--                <img class="img-fluid mb-3" src="static/images/256.png" alt="" >-->
<!--              </div>-->
<!--            </div>-->
<!--  -->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="column">-->
<!--          <h3 class="title is-4">512 input/output resolution</h3>-->
<!--          <div class="columns is-centered">-->
<!--            <div class="column content">-->
<!--              <div class="text-white">-->
<!--                <img class="img-fluid mb-3" src="static/images/512.png" alt="" >-->
<!--              </div>-->
<!--            </div>-->
<!--  -->
<!--          </div>-->
<!--        </div>-->
<!--    </div>-->
<!--    <br><br>-->
<!--    <hr>-->
<!--  </div>-->


  

</div>

  </section></div>

  

  <section id="BibTeX">
    <div>
      <h2>BibTeX</h2>
      <pre><code>
      @inproceedings{Drobyshev22MP,
                author = {Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor},
                title = {MegaPortraits: One-shot Megapixel Neural Head Avatars},
                journal   = {Proceedings of the 30th ACM International Conference on Multimedia},
                year      = {2022},
      }
    </code></pre>
    </div>
  </section>

  <!-- Footer -->
  





</div></section></div>
  </body>
</html>
