<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://payments.posthaven.com/w6d2-revisit-past-projects-with-tools-of-the-future">Original</a>
    <h1>W6D2 - Revisit past projects with tools of the future</h1>
    
    <div id="readability-page-1" class="page"><div id="post_body_2087256">
    
      <div><p>For my first data science <a href="https://github.com/savarin/rateflask">project</a>, I build a machine learning model using Lending Club data. The hypothesis is I can use that data to ‘cherry pick’ loans in a way that outperforms the average return. More specifically, all loans within a certain grade pay the same interest rate and if I can stack rank to select the top 5% say, then I beat the average.<br/></p>
<p>What I didn’t quite expect is to later work for a startup that did exactly this.<br/></p>
<p>I digress. The point I’m trying to get to relates to the loan data itself. The model I built mainly used the numerical features like the borrower’s FICO score and income. There was a text blob column which is what the borrower wrote as their intention for the loan proceeds. This text blob became simple features like number of characters, number of words, number of sentences.<br/></p>
<p>With text embeddings, this column can now be a vector and the whole model be trained on both the numerical features and the semantic meaning of the text. It’s one use case of many that language models now unlock.<br/></p></div>
    
  </div></div>
  </body>
</html>
