<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/deepseek-ai/3FS">Original</a>
    <h1>Fire-Flyer File System from DeepSeek</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="https://github.com/deepseek-ai/3fs/actions/workflows/build.yml"><img src="https://github.com/deepseek-ai/3fs/actions/workflows/build.yml/badge.svg" alt="Build"/></a>
<a href="https://github.com/deepseek-ai/3FS/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/f05745377bc0526bd7ea30e833987d17304dcaf45da9be7eeb2894bca1e4b5b9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c4943454e53452d4d49542d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/LICENSE-MIT-blue.svg"/></a></p>
<p dir="auto">The Fire-Flyer File System (3FS) is a high-performance distributed file system designed to address the challenges of AI training and inference workloads. It leverages modern SSDs and RDMA networks to provide a shared storage layer that simplifies development of distributed applications. Key features and benefits of 3FS include:</p>
<ul dir="auto">
<li>
<p dir="auto">Performance and Usability</p>
<ul dir="auto">
<li><strong>Disaggregated Architecture</strong> Combines the throughput of thousands of SSDs and the network bandwidth of hundreds of storage nodes, enabling applications to access storage resource in a locality-oblivious manner.</li>
<li><strong>Strong Consistency</strong> Implements Chain Replication with Apportioned Queries (CRAQ) for strong consistency, making application code simple and easy to reason about.</li>
<li><strong>File Interfaces</strong> Develops stateless metadata services backed by a transactional key-value store (e.g., FoundationDB). The file interface is well known and used everywhere. There is no need to learn a new storage API.</li>
</ul>
</li>
<li>
<p dir="auto">Diverse Workloads</p>
<ul dir="auto">
<li><strong>Data Preparation</strong> Organizes outputs of data analytics pipelines into hierarchical directory structures and manages large volume of intermediate outputs efficiently.</li>
<li><strong>Dataloaders</strong> Eliminates the need for prefetching or shuffling datasets by enabling random access to training samples across compute nodes.</li>
<li><strong>Checkpointing</strong> Supports high-throughput parallel checkpointing for large-scale training.</li>
<li><strong>KVCache for Inference</strong> Provides a cost-effective alternative to DRAM-based caching, offering high throughput and significantly larger capacity.</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li><a href="https://github.com/deepseek-ai/3FS/blob/main/docs/design_notes.md">Design Notes</a></li>
<li><a href="https://github.com/deepseek-ai/3FS/blob/main/deploy/README.md">Setup Guide</a></li>
<li><a href="https://github.com/deepseek-ai/3FS/blob/main/src/lib/api/UsrbIo.md">USRBIO API Reference</a></li>
<li><a href="https://github.com/deepseek-ai/3FS/blob/main/specs/README.md">P Specifications</a></li>
</ul>


<p dir="auto">The following figure demonstrates the throughput of read stress test on a large 3FS cluster. This cluster consists of 180 storage nodes, each equipped with 2×200Gbps InfiniBand NICs and sixteen 14TiB NVMe SSDs. Approximately 500+ client nodes were used for the read stress test, with each client node configured with 1x200Gbps InfiniBand NIC. The final aggregate read throughput reached approximately 6.6 TiB/s with background traffic from training jobs.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/3FS/blob/main/docs/images/peak_throughput.jpg"><img src="https://github.com/deepseek-ai/3FS/raw/main/docs/images/peak_throughput.jpg" alt="Large block read throughput under stress test on a 180-node cluster"/></a></p>

<p dir="auto">We evaluated <a href="https://github.com/deepseek-ai/smallpond">smallpond</a> using the GraySort benchmark, which measures sort performance on large-scale datasets. Our implementation adopts a two-phase approach: (1) partitioning data via shuffle using the prefix bits of keys, and (2) in-partition sorting. Both phases read/write data from/to 3FS.</p>
<p dir="auto">The test cluster comprised 25 storage nodes (2 NUMA domains/node, 1 storage service/NUMA, 2×400Gbps NICs/node) and 50 compute nodes (2 NUMA domains, 192 physical cores, 2.2 TiB RAM, and 1×200 Gbps NIC/node). Sorting 110.5 TiB of data across 8,192 partitions completed in 30 minutes and 14 seconds, achieving an average throughput of <em>3.66 TiB/min</em>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/3FS/blob/main/docs/images/gray_sort_server.png"><img src="https://github.com/deepseek-ai/3FS/raw/main/docs/images/gray_sort_server.png" alt=""/></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/3FS/blob/main/docs/images/gray_sort_client.png"><img src="https://github.com/deepseek-ai/3FS/raw/main/docs/images/gray_sort_client.png" alt=""/></a></p>

<p dir="auto">KVCache is a technique used to optimize the LLM inference process. It avoids redundant computations by caching the key and value vectors of previous tokens in the decoder layers.
The top figure demonstrates the read throughput of all KVCache clients, highlighting both peak and average values, with peak throughput reaching up to 40 GiB/s. The bottom figure presents the IOPS of remove ops from garbage collection (GC) during the same time period.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/3FS/blob/main/docs/images/kvcache_read_throughput.png"><img src="https://github.com/deepseek-ai/3FS/raw/main/docs/images/kvcache_read_throughput.png" alt="KVCache Read Throughput"/></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/3FS/blob/main/docs/images/kvcache_gc_iops.png"><img src="https://github.com/deepseek-ai/3FS/raw/main/docs/images/kvcache_gc_iops.png" alt="KVCache GC IOPS"/></a></p>

<p dir="auto">Clone 3FS repository from github:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/deepseek-ai/3fs"><pre><code>git clone https://github.com/deepseek-ai/3fs
</code></pre></div>
<p dir="auto">When <code>deepseek-ai/3fs</code> has been cloned to local file system, run the
following commands to check out the submodules:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd 3fs
git submodule update --init --recursive
./patches/apply.sh"><pre><span>cd</span> 3fs
git submodule update --init --recursive
./patches/apply.sh</pre></div>

<p dir="auto">Install dependencies:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# for Ubuntu 20.04.
apt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libprocps-dev libdwarf-dev libunwind-dev \
  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \
  libgoogle-perftools-dev google-perftools libssl-dev ccache libclang-rt-14-dev gcc-10 g++-10 libboost1.71-all-dev

# for Ubuntu 22.04.
apt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libprocps-dev libdwarf-dev libunwind-dev \
  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \
  libgoogle-perftools-dev google-perftools libssl-dev ccache gcc-12 g++-12 libboost-all-dev"><pre><span><span>#</span> for Ubuntu 20.04.</span>
apt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libprocps-dev libdwarf-dev libunwind-dev \
  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \
  libgoogle-perftools-dev google-perftools libssl-dev ccache libclang-rt-14-dev gcc-10 g++-10 libboost1.71-all-dev

<span><span>#</span> for Ubuntu 22.04.</span>
apt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libprocps-dev libdwarf-dev libunwind-dev \
  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \
  libgoogle-perftools-dev google-perftools libssl-dev ccache gcc-12 g++-12 libboost-all-dev</pre></div>
<p dir="auto">Install other build prerequisites:</p>
<ul dir="auto">
<li><a href="https://github.com/libfuse/libfuse/releases/tag/fuse-3.16.1"><code>libfuse</code></a> 3.16.1 or newer version</li>
<li><a href="https://apple.github.io/foundationdb/getting-started-linux.html" rel="nofollow">FoundationDB</a> 7.1 or newer version</li>
<li><a href="https://www.rust-lang.org/tools/install" rel="nofollow">Rust</a> toolchain</li>
</ul>

<p dir="auto">Build 3FS in <code>build</code> folder:</p>
<div data-snippet-clipboard-copy-content="cmake -S . -B build -DCMAKE_CXX_COMPILER=clang++-14 -DCMAKE_C_COMPILER=clang-14 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_EXPORT_COMPILE_COMMANDS=ON
cmake --build build -j 32"><pre><code>cmake -S . -B build -DCMAKE_CXX_COMPILER=clang++-14 -DCMAKE_C_COMPILER=clang-14 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_EXPORT_COMPILE_COMMANDS=ON
cmake --build build -j 32
</code></pre></div>

<p dir="auto">Follow instructions in <a href="https://github.com/deepseek-ai/3FS/blob/main/deploy/README.md">setup guide</a> to run a test cluster.</p>

<p dir="auto">Please visit <a href="https://github.com/deepseek-ai/3fs/issues">https://github.com/deepseek-ai/3fs/issues</a> to report issues.</p>
</article></div></div>
  </body>
</html>
