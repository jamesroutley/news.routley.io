<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dockyard.com/blog/2023/07/18/introducing-exgboost-gradient-boosting-in-elixir">Original</a>
    <h1>EXGBoost: Gradient Boosting in Elixir</h1>
    
    <div id="readability-page-1" class="page"><div>
  <article>
    <header>
      <div>
        
        
        <div>
          <p><img src="https://assets.dockyard.com/dockyard_com/introducing-exgboost-1b9c6625-e2bc-4562-8c3b-7dfd7a34b8d5-large.webp" alt="Hexagonal tiles with small images of a rocket on each one, with one tile detaching from the rest with lines to indicate movement away from the rest of the tiles"/></p>
          
        </div>
      </div>
      <div>
        <p><img src="https://s3.amazonaws.com/dockyard-com-production/images/team-monster-10.png" alt="Sean Moriarity"/>

        </p>
        
      </div>

      
    </header>

    <section>
      <div>
<h2>Introduction</h2><p>Over the past 2.5 years, we’ve worked hard to significantly expand Elixir’s machine learning capabilities. The <a href="https://github.com/elixir-nx/nx">Nx</a> project makes it possible for Elixir programmers to implement efficient numeric algorithms directly in Elixir. Nx is a library for array-based programming. That means it’s suitable for implementing things like <a href="https://github.com/elixir-nx/axon">neural networks</a>, some <a href="https://github.com/elixir-nx/scholar">traditional machine learning algorithms</a>, and even applications using <a href="https://github.com/woodward/integrator">ordinary differential equations</a>.</p><p>A number of other projects have also sprung out of the Elixir Nx efforts including:</p><ul><li><a href="https://livebook.dev">Livebook</a> - Interactive code notebooks for Elixir</li><li><a href="https://github.com/elixir-nx/explorer">Explorer</a> - Dataset analysis and exploration</li><li><a href="https://github.com/elixir-nx/bumblebee">Bumblebee</a> - Pretrained machine learning models and servings</li><li><a href="https://github.com/livebook-dev/vega_lite">VegaLite</a> - VegaLite bindings for rich visualizations</li></ul><p>The Elixir machine learning ecosystem is slowly closing the capabilities gap between itself and Python. One of the biggest remaining gaps I wrote about in my post <a href="https://dockyard.com/blog/2022/07/12/elixir-versus-python-for-data-science">comparing Elixir and Python for Data Science</a> was the lack of a library for implementing decision trees in Elixir. Today, I am excited to introduce a library that fills that void: <a href="https://github.com/acalejos/exgboost/">EXGBoost</a>.</p><p>EXGBoost provides bindings to the popular <a href="https://xgboost.readthedocs.io/en/stable/">XGBoost</a> library. In the words of the documentation:</p><blockquote><p>Xtreme Gradient Boosting (XGBoost) is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It implements machine learning algorithms under the Gradient Boosting framework.</p></blockquote><p>EXGBoost brings a critical missing piece to the table for developers turning to Elixir for machine learning. In this post, we’ll explore the EXGBoost API, and discuss why it’s such an important addition to the Elixir Nx Ecosystem.</p><h2>What is Gradient Boosting?</h2><p>Gradient boosting is a popular machine learning approach for both regression and classification tasks. Gradient boosting is an <em>ensemble method</em> for machine learning that uses an ensemble of <em>weak classifiers</em>. You can kind of think of this as meaning that gradient boosting uses predictions from a lot of bad models to produce a single strong prediction. Ensembles are models comprised of many models, while weak classifiers are quite literally classifiers that barely perform better than random guessing.</p><p>The weak classifier most often used in gradient boosting is the <em>decision tree</em>. A decision tree is a type of model that learns branches of logic from a training set to classify inputs into one of a number of outputs. Decision trees are easily interpretable models. The trained classifier is quite literally a logical decision tree in which each input variable maps to decision branches and eventual outputs.</p><p>Gradient boosting trains many small decision trees on single input variables, and incorporates predictions from each into a final prediction. Gradient boosting is a powerful framework for training simple and interpretable machine learning models.</p><h2>Why Gradient Boosting?</h2><p>Gradient boosting is fundamentally different than any of the algorithms that exist in the Elixir machine learning ecosystem today. One of the greatest differences is that it’s not easy to implement using purely Nx operations and numerical definitions. While there are efforts in the Python ecosystem, such as <a href="https://github.com/microsoft/hummingbird">Hummingbird</a>, to compile traditional machine learning models such as decision trees to tensor computations, these efforts require a trained model. The training logic for decision trees is not something that’s easily expressed as tensor computations.</p><p>Given this fact, why even bother? Scholar has a growing number of traditional machine learning algorithms, and Axon has deep learning covered. Why bother with gradient boosting? As it turns out, gradient boosting is one of the few machine learning techniques that still rivals deep learning for certain modalities. As an example, models based on the gradient boosting framework consistently outperform their deep learning counterparts with tabular data. Additionally, the trained models are often simpler, more performant, and easier to interpret. Gradient boosting is simply too powerful to ignore.</p><p>Given that tabular datasets represent a significant chunk of business data, gradient boosting is extremely important to have in a data scientist’s toolkit. Interpretability is a bonus. Deep learning is often jibed for a lack of interpretability. Deep learning models really are a black box. Interpretability is often an important factor in a company’s decision to deploy a machine learning model. All of these factors make the addition of EXGBoost a huge boon to the Elixir machine learning ecosystem.</p><h2>How can I use EXGBoost?</h2><p>To get comfortable with EXGBoost, we’ll go through a simple example: predicting the price of diamonds based on several attributes from this <a href="https://www.kaggle.com/datasets/shivam2503/diamonds">diamond</a> dataset. Go ahead and download the dataset from Kaggle, and then install the following dependencies:</p><!-- livebook:{"force_markdown":true} --><div>
      
      <pre><code id="code-block-6562" translate="no"><span>Mix</span><span>.</span><span>install</span><span data-group-id="6070142203-1">(</span><span data-group-id="6070142203-2">[</span><span>
  </span><span data-group-id="6070142203-3">{</span><span>:nx</span><span>,</span><span> </span><span>&#34;~&gt; 0.5&#34;</span><span data-group-id="6070142203-3">}</span><span>,</span><span>
  </span><span data-group-id="6070142203-4">{</span><span>:exgboost</span><span>,</span><span> </span><span>&#34;~&gt; 0.2&#34;</span><span data-group-id="6070142203-4">}</span><span>,</span><span>
  </span><span data-group-id="6070142203-5">{</span><span>:scholar</span><span>,</span><span> </span><span>&#34;~&gt; 0.1&#34;</span><span data-group-id="6070142203-5">}</span><span>,</span><span>
  </span><span data-group-id="6070142203-6">{</span><span>:explorer</span><span>,</span><span> </span><span>&#34;~&gt; 0.5&#34;</span><span data-group-id="6070142203-6">}</span><span>
</span><span data-group-id="6070142203-2">]</span><span data-group-id="6070142203-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(6562)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><!-- livebook:{"break_markdown":true} --><p>You’ll also want to require the Explorer macros:</p><div>
      
      <pre><code id="code-block-6658" translate="no"><span>require</span><span> </span><span>Explorer.DataFrame</span><span>,</span><span> </span><span>as</span><span>:</span><span> </span><span>DF</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(6658)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>Next, read in the dataset using Explorer:</p><div>
      
      <pre><code id="code-block-6674" translate="no"><span>df</span><span> </span><span>=</span><span> </span><span>Explorer.DataFrame</span><span>.</span><span>from_csv!</span><span data-group-id="7070523715-1">(</span><span>&#34;/Users/sean/diamonds.csv&#34;</span><span data-group-id="7070523715-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(6674)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>You’ll notice we have a number of both qualitative and quantitative features. The first column is just an ID column, so you can discard that:</p><p>Now, before we can convert the DataFrame to a tensor, we need to convert the string columns to numeric columns. The string columns represent categories that we can just numerically encode:</p><div>
      
      <pre><code id="code-block-6754" translate="no"><span>df</span><span> </span><span>=</span><span>
  </span><span>DF</span><span>.</span><span>mutate</span><span data-group-id="7614303490-1">(</span><span>
    </span><span>df</span><span>,</span><span>
    </span><span>for</span><span> </span><span>col</span><span> </span><span>&lt;-</span><span> </span><span>across</span><span data-group-id="7614303490-2">(</span><span>~w[cut color clarity]</span><span data-group-id="7614303490-2">)</span><span> </span><span data-group-id="7614303490-3">do</span><span>
      </span><span data-group-id="7614303490-4">{</span><span>col</span><span>.</span><span>name</span><span>,</span><span> </span><span>Explorer.Series</span><span>.</span><span>cast</span><span data-group-id="7614303490-5">(</span><span>col</span><span>,</span><span> </span><span>:category</span><span data-group-id="7614303490-5">)</span><span data-group-id="7614303490-4">}</span><span>
    </span><span data-group-id="7614303490-3">end</span><span>
  </span><span data-group-id="7614303490-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(6754)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>Now, we want to shuffle this data and split it into training and test sets:</p><div>
      
      <pre><code id="code-block-6834" translate="no"><span>n_rows</span><span> </span><span>=</span><span> </span><span>DF</span><span>.</span><span>n_rows</span><span data-group-id="1752079354-1">(</span><span>df</span><span data-group-id="1752079354-1">)</span><span>
</span><span>split_at</span><span> </span><span>=</span><span> </span><span>floor</span><span data-group-id="1752079354-2">(</span><span>0.8</span><span> </span><span>*</span><span> </span><span>n_rows</span><span data-group-id="1752079354-2">)</span><span>

</span><span>df</span><span> </span><span>=</span><span> </span><span>DF</span><span>.</span><span>shuffle</span><span data-group-id="1752079354-3">(</span><span>df</span><span data-group-id="1752079354-3">)</span><span>
</span><span>train_df</span><span> </span><span>=</span><span> </span><span>DF</span><span>.</span><span>slice</span><span data-group-id="1752079354-4">(</span><span>df</span><span>,</span><span> </span><span>0</span><span>..</span><span>split_at</span><span data-group-id="1752079354-4">)</span><span>
</span><span>test_df</span><span> </span><span>=</span><span> </span><span>DF</span><span>.</span><span>slice</span><span data-group-id="1752079354-5">(</span><span>df</span><span>,</span><span> </span><span>split_at</span><span>..</span><span>-</span><span>1</span><span data-group-id="1752079354-5">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(6834)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>Finally, we want to convert both DataFrames into tensors:</p><div>
      
      <pre><code id="code-block-7010" translate="no"><span>features</span><span> </span><span>=</span><span> </span><span>~w(carat cut color clarity depth table x y z)</span><span>
</span><span>targets</span><span> </span><span>=</span><span> </span><span>~w(price)</span><span>

</span><span>x_train</span><span> </span><span>=</span><span>
  </span><span>train_df</span><span data-group-id="7917108911-1">[</span><span>features</span><span data-group-id="7917108911-1">]</span><span>
  </span><span>|&gt;</span><span> </span><span>Nx</span><span>.</span><span>stack</span><span data-group-id="7917108911-2">(</span><span>axis</span><span>:</span><span> </span><span>1</span><span data-group-id="7917108911-2">)</span><span>

</span><span>y_train</span><span> </span><span>=</span><span>
  </span><span>train_df</span><span data-group-id="7917108911-3">[</span><span>targets</span><span data-group-id="7917108911-3">]</span><span>
  </span><span>|&gt;</span><span> </span><span>Nx</span><span>.</span><span>stack</span><span data-group-id="7917108911-4">(</span><span>axis</span><span>:</span><span> </span><span>1</span><span data-group-id="7917108911-4">)</span><span>

</span><span>x_test</span><span> </span><span>=</span><span>
  </span><span>test_df</span><span data-group-id="7917108911-5">[</span><span>features</span><span data-group-id="7917108911-5">]</span><span>
  </span><span>|&gt;</span><span> </span><span>Nx</span><span>.</span><span>stack</span><span data-group-id="7917108911-6">(</span><span>axis</span><span>:</span><span> </span><span>1</span><span data-group-id="7917108911-6">)</span><span>

</span><span>y_test</span><span> </span><span>=</span><span>
  </span><span>test_df</span><span data-group-id="7917108911-7">[</span><span>targets</span><span data-group-id="7917108911-7">]</span><span>
  </span><span>|&gt;</span><span> </span><span>Nx</span><span>.</span><span>stack</span><span data-group-id="7917108911-8">(</span><span>axis</span><span>:</span><span> </span><span>1</span><span data-group-id="7917108911-8">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7010)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>With our data ready, we can start using EXGBoost to train a model. The EXGBoost API is intentionally small. At the top level, there are two important functions: <code>train/3</code> and <code>predict/3</code>. For most use cases, this is all you’ll ever need. You can configure both training and prediction with a number of options. There are more complex APIs if you need something more custom; however, for this use case, we’ll stick to the basics.</p><p>To train a model, you just pass a training set to <code>EXGBoost.train/3</code>. You also need to specify an objective. The objective is the metric or loss function used to optimize the model. In this case, our objective is a regression, so we’ll use the squared-error loss. You can tell EXGBoost to use this loss function by specifying <code>obj: :reg_squarederror</code>:</p><div>
      
      <pre><code id="code-block-7266" translate="no"><span>model</span><span> </span><span>=</span><span> </span><span>EXGBoost</span><span>.</span><span>train</span><span data-group-id="0520001966-1">(</span><span>x_train</span><span>,</span><span> </span><span>y_train</span><span>,</span><span> </span><span>obj</span><span>:</span><span> </span><span>:reg_squarederror</span><span data-group-id="0520001966-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7266)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>In addition to specifying an objective, you can specify evaluation strategies to evaluate the model during training. To do this, you just need to specify <code>evals</code> which is a list of tuples consisting of <code>{features, targets, name}</code>. In this case, we can evaluate the model on the training set during training:</p><div>
      
      <pre><code id="code-block-7298" translate="no"><span>model</span><span> </span><span>=</span><span>
  </span><span>EXGBoost</span><span>.</span><span>train</span><span data-group-id="1348461299-1">(</span><span>x_train</span><span>,</span><span> </span><span>y_train</span><span>,</span><span>
    </span><span>obj</span><span>:</span><span> </span><span>:reg_squarederror</span><span>,</span><span>
    </span><span>evals</span><span>:</span><span> </span><span data-group-id="1348461299-2">[</span><span data-group-id="1348461299-3">{</span><span>x_train</span><span>,</span><span> </span><span>y_train</span><span>,</span><span> </span><span>&#34;train&#34;</span><span data-group-id="1348461299-3">}</span><span data-group-id="1348461299-2">]</span><span>
  </span><span data-group-id="1348461299-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7298)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>You’ll notice our model trained for 10 iterations. You can also customize this by specifying <code>num_boost_rounds</code>:</p><div>
      
      <pre><code id="code-block-7330" translate="no"><span>model</span><span> </span><span>=</span><span>
  </span><span>EXGBoost</span><span>.</span><span>train</span><span data-group-id="1190091597-1">(</span><span>x_train</span><span>,</span><span> </span><span>y_train</span><span>,</span><span>
    </span><span>obj</span><span>:</span><span> </span><span>:reg_squarederror</span><span>,</span><span>
    </span><span>evals</span><span>:</span><span> </span><span data-group-id="1190091597-2">[</span><span data-group-id="1190091597-3">{</span><span>x_train</span><span>,</span><span> </span><span>y_train</span><span>,</span><span> </span><span>&#34;train&#34;</span><span data-group-id="1190091597-3">}</span><span data-group-id="1190091597-2">]</span><span>,</span><span>
    </span><span>num_boost_rounds</span><span>:</span><span> </span><span>15</span><span>
  </span><span data-group-id="1190091597-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7330)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>There are a number of other options to control training such as callbacks, regularization techniques, and more. With a trained model, you simply need to call <code>EXGBoost.predict/3</code> to get predictions on a set of inputs:</p><div>
      
      <pre><code id="code-block-7442" translate="no"><span>y_pred</span><span> </span><span>=</span><span> </span><span>EXGBoost</span><span>.</span><span>predict</span><span data-group-id="4641649959-1">(</span><span>model</span><span>,</span><span> </span><span>x_test</span><span data-group-id="4641649959-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7442)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>We can use Scholar to evaluate these predictions:</p><div>
      
      <pre><code id="code-block-7490" translate="no"><span>Scholar.Metrics</span><span>.</span><span>mean_absolute_error</span><span data-group-id="8258284561-1">(</span><span>Nx</span><span>.</span><span>squeeze</span><span data-group-id="8258284561-2">(</span><span>y_test</span><span data-group-id="8258284561-2">)</span><span>,</span><span> </span><span>y_pred</span><span data-group-id="8258284561-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7490)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>In total across 10788 examples, our model had an average absolute error of $333. You can see what this means by inspecting the pairwise error:</p><div>
      
      <pre><code id="code-block-7570" translate="no"><span>Nx</span><span>.</span><span>abs</span><span data-group-id="7208477035-1">(</span><span>Nx</span><span>.</span><span>subtract</span><span data-group-id="7208477035-2">(</span><span>Nx</span><span>.</span><span>squeeze</span><span data-group-id="7208477035-3">(</span><span>y_test</span><span data-group-id="7208477035-3">)</span><span>,</span><span> </span><span>y_pred</span><span data-group-id="7208477035-2">)</span><span data-group-id="7208477035-1">)</span><span>
</span></code>
        <span onclick="return CopyToClipboard.copyCode(7570)">
          <svg aria-hidden="true" focusable="false" role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path></svg>
        </span>
      </pre>
    </div><p>Notice that some predictions are quite close, while others miss the mark by a lot. That happens, and you can try messing around with the training process a bit more to bring this error down!</p><h2>Conclusion</h2><p>EXGBoost brings a new set of capabilities to the Elixir machine learning ecosystem. With a simple API built on top of a powerful framework, it opens a world of possibilities for machine learning developers in the Elixir ecosystem. Before concluding, I need to give a huge shoutout to <a href="https://twitter.com/ac_alejos">Andrés Alejos</a> for bringing gradient boosting to the Elixir community. Until next time!</p>
      </div>
    </section>
  </article>
</div></div>
  </body>
</html>
