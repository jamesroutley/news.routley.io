<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2304.01433">Original</a>
    <h1>TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jouppi%2C+N+P">Norman P. Jouppi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurian%2C+G">George Kurian</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+P">Peter Ma</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagarajan%2C+R">Rahul Nagarajan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nai%2C+L">Lifeng Nai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patil%2C+N">Nishant Patil</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramanian%2C+S">Suvinay Subramanian</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swing%2C+A">Andy Swing</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Towles%2C+B">Brian Towles</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Young%2C+C">Cliff Young</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiang Zhou</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zongwei Zhou</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patterson%2C+D">David Patterson</a></p></div>
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2304.01433">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  In response to innovations in machine learning (ML) models, production
workloads changed radically and rapidly. TPU v4 is the fifth Google domain
specific architecture (DSA) and its third supercomputer for such ML models.
Optical circuit switches (OCSes) dynamically reconfigure its interconnect
topology to improve scale, availability, utilization, modularity, deployment,
security, power, and performance; users can pick a twisted 3D torus topology if
desired. Much cheaper, lower power, and faster than Infiniband, OCSes and
underlying optical components are &lt;5% of system cost and &lt;3% of system power.
Each TPU v4 includes SparseCores, dataflow processors that accelerate models
that rely on embeddings by 5x-7x yet use only 5% of die area and power.
Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves
performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips
and thus ~10x faster overall, which along with OCS flexibility helps large
language models. For similar sized systems, it is ~4.3x-4.5x faster than the
Graphcore IPU Bow and is 1.2x-1.7x faster and uses 1.3x-1.9x less power than
the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers
of Google Cloud use ~3x less energy and produce ~20x less CO2e than
contemporary DSAs in a typical on-premise data center.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Cliff Young [<a href="https://arxiv.org/show-email/78b1cf94/2304.01433">view email</a>]
      </p></div></div>
  </body>
</html>
