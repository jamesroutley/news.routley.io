<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://xenaproject.wordpress.com/2024/12/11/fermats-last-theorem-how-its-going/">Original</a>
    <h1>Fermat&#39;s Last Theorem – how it’s going</h1>
    
    <div id="readability-page-1" class="page"><div>
						
<p>So I’m two months into trying to teach a proof of Fermat’s Last Theorem (FLT) to a computer. Most of “how it’s going” is quite tedious and technical to explain: to cut a long story short, Wiles proved an “R=T” theorem and much of the work so far has gone into teaching the computer what R and T are; we still have not finished either definition. However my PhD student Andrew Yang has already proved the abstract commutative algebra result which we need (“if abstract rings R and T satisfy lots of technical conditions then they’re equal”), and this is an exciting first step. The current state of the write-up is <a href="https://imperialcollegelondon.github.io/FLT/blueprint/">here</a>, and the system we are using is <a href="https://lean-fro.org/">Lean</a> and its mathematical library <a href="https://github.com/leanprover-community/mathlib4">mathlib</a>, maintained by the <a href="https://leanprover-community.github.io/">Lean prover community</a>. If you know a bit of Lean and a bit of number theory then feel free to read the <a href="https://github.com/ImperialCollegeLondon/FLT/blob/main/CONTRIBUTING.md">contribution guidelines</a>, checkout the <a href="https://github.com/orgs/ImperialCollegeLondon/projects/102">project dashboard</a> and claim an <a href="https://github.com/ImperialCollegeLondon/FLT/issues">issue</a>. As I say, we’re two months in. However we already have one interesting story, which I felt was worth sharing. Who knows if it’s an indication of what is to come.</p>



<p>We’re not formalising the old-fashioned 1990s proof of FLT. Since then, work of many people (Diamond/Fujiwara, Kisin, Taylor, Scholze and several others) led to the proof being generalised and simplified, and part of the motivation of my work is not to just get FLT over the line but to prove these more general and powerful results. Why? Because if the AI mathematics revolution actually happens (which it might) and if Lean turns out to be an important component (which it might) then computers will be in a better position to start helping humans to push back the boundaries of modern number theory because of this formalization work, as they’ll have access to key modern definitions in a form which they understand. One concept which was not used in Wiles’ original proof but which is being used in the proof we’re formalizing, is crystalline cohomology, a theory developed in the 60s and 70s in Paris, with the foundations laid down by Berthelot following ideas of Grothendieck. The basic idea here is that the classical exponential and logarithm functions play a key role in differential geometry (relating Lie algebras and Lie groups, for example), and in particular in understanding de Rham cohomology, but they do not work in more arithmetic situations (for example in characteristic p); the theory of “divided power structures”, developed in the 1960s in a series of beautiful papers by Roby, play a crucial role in constructing an analogue of these functions which can be used in the arithmetic case. tl;dr: we need to teach the computer crystalline cohomology, so first we need to teach it divided powers.</p>



<p>Antoine Chambert-Loir and Maria Ines de Frutos Fernandez have been teaching the theory of divided powers to Lean, and over the summer Lean did that irritating thing which it sometimes does: it complained about the human presentation of an argument in the standard literature, and on closer inspection it turned out that the human argument left something to be desired. In particular a key lemma in Roby’s work seems to be incorrect. When Antoine told me this in a DM, he remarked that he would suppose I thought this was funny, and indeed the very long string of laughing emojis which he got back as a response to his message confirmed this. However Antoine, being rather more professional than me, argued that instead of me tweeting about the issue (which I can’t do anyway because I left Twitter and joined <a href="https://bsky.app/profile/xenaproject.bsky.social">bluesky</a> yesterday), we should in fact attempt to fix the problem. We went about this in rather different ways. Antoine put it on his job list to look at, and I completely ignored the problem and just started occasionally mentioning to people that the proof was in trouble, in a weak sense. I say “in a weak sense” because this observation has to be put into some context. According to the way I currently view mathematics (as a formalist), the entire theory of crystalline cohomology vanished from the literature at the moment Antoine discovered the issue, with massive collateral damage (for example huge chunks of Scholze’s work just disappeared, entire books and papers vaporised etc). But this disappearance is only <em>temporary</em>. Crystalline cohomology is in no practical sense “wrong”. The theorems were still undoubtedly <em>correct</em>, it’s just that the proofs were as far as I am concerned <em>incomplete</em> (or at least, the ones Antoine and Maria Ines were following were), and unfortunately it is now our job to fix them. The thing I want to stress is that it was absolutely clear to both me and Antoine that the proofs of the main results were of course going to be <em>fixable</em>, even if an intermediate lemma was false, because crystalline cohomology has been used so much since the 1970s that if there were a problem with it, it would have come to light a long time ago. Every expert I’ve spoken to is in complete agreement on this point (and several even went so far as to claim that I’m making a fuss about nothing, but perhaps they don’t understand what formalization actually means in practice: you can’t just say “I’m sure it’s fixable” — you have to <strong>actually fix it</strong>). One added twist is that Roby, Grothendieck and Berthelot have all died, so we could not go back to the original experts and ask directly for help.</p>



<p>[For those that are interested in more technical details, here they are: Berthelot’s thesis does not develop the theory of divided powers from scratch, he uses Roby’s “Les algebres a puissances divisees”, published in Bull Sci Math, 2ieme serie, 89, 1965, pages 75-91. Lemme 8 (on p86) of that paper seems to be false and it’s not obvious how to repair the proof; the proof of the lemma misquotes another lemma of Roby from his 1963 Ann Sci ENS paper; the correct statement is Gamma_A(M) tensor_A R = Gamma_R(M tensor_A R) but one of the tensor products accidentally falls off in the application. This breaks Roby’s proof that the divided power algebra of a module has divided powers, and thus stops us from defining the ring A_{cris}.]</p>



<p>So as I say, Antoine worked on fixing the problem, whereas I just worked on gossiping about it to the experts, and I made the mistake of telling Tadashi Tokieda about it in a <a href="https://www.instagram.com/coffeezeeholloway/">coffeeshop in Islington</a>, he duly went back to Stanford and mentioned it to Brian Conrad, and the next thing I knew Conrad was in my inbox asking me what was all this about crystalline cohomology being wrong. I explained the technical details of the issue, Conrad agreed that there seemed to be a problem and he went off to think about it. Several hours later he got back to me and pointed out that another, different, proof of the claim that the universal divided power algebra of a module had divided powers was in the appendix to the Berthelot-Ogus book on crystalline cohomology, and that as far as Conrad was concerned this approach should be fine. The proof was back on! </p>



<p>And that is pretty much the end of the story, other than the fact that last month I visited Berkeley and I had lunch with Arthur Ogus, who I’ve known since I was a post-doc there in the 90s. I’d promised Arthur a story of how he’d saved Fermat’s Last Theorem, and over the meal I told him about how his appendix had dug me out of a hole. His response was “Oh! That appendix has several errors in it! But it’s OK, I think I know how to fix them.”</p>



<p>This story really highlights, to me, the poor job which humans do of documenting modern mathematics. There appear to be so many things which are “known to the experts” but not correctly documented. The experts are in agreement that the important ideas are robust enough to withstand knocks like this, but the <em>details</em> of what is actually going on might not actually be where you expect them to be. For me, this is just one of many reasons why humans might want to consider getting mathematics written down <em>properly</em>, i.e. in a formal system, where the chances of error are orders of magnitude smaller. However most mathematicians are not formalists, and for those people I need to justify my work in a different way. For those mathematicians, I argue that teaching machines our arguments is a crucial step towards getting machines to do it themselves. Until then, we seemed to be doomed to fix up human errors manually.</p>



<p>The story does have a happy ending though — two weeks ago Maria Ines gave <a href="https://talks.cam.ac.uk/talk/index/222778">a talk</a> about formalization of divided powers in the Cambridge Formalization of Mathematics seminar (which was started by Angeliki Koutsoukou-Argyraki a couple of years ago — thanks Angeliki!), and my understanding of Maria Ines’ talk is that these issues have now been sorted out. So we are actually back on track. Until the next time the literature lets us down…</p>

			
														</div><div id="entry-author-info">
						<p><img alt="" src="https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=60&amp;d=identicon&amp;r=G" srcset="https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=60&amp;d=identicon&amp;r=G 1x, https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=90&amp;d=identicon&amp;r=G 1.5x, https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=120&amp;d=identicon&amp;r=G 2x, https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=180&amp;d=identicon&amp;r=G 3x, https://2.gravatar.com/avatar/e7ccfd42722fdb89c0fdea2f473152c14ab978bc1974acc4d67944906653f36e?s=240&amp;d=identicon&amp;r=G 4x" height="60" width="60" loading="lazy" decoding="async"/>						</p><!-- #author-avatar -->
						<div id="author-description">
							<h2>
							About xenaproject							</h2><p>
							The Xena Project aims to get mathematics undergraduates (at Imperial College and beyond) trained in the art of formalising mathematics on a computer. Why? Because I have this feeling that digitising mathematics will be really important one day.							</p><!-- #author-link	-->
						</div><!-- #author-description -->
					</div></div>
  </body>
</html>
