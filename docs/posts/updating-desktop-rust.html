<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tritium.legal/blog/update">Original</a>
    <h1>Updating Desktop Rust</h1>
    
    <div id="readability-page-1" class="page"><article>
    <p>Desktop software can be fast, local and secure--critical for good legal technology.</p>

    <p>But, unlike web apps, desktop applications go stale and require updates for each
        new build.<sup><a href="#1">1</a></sup> </p>

    <p>Each such update is a moment of truth for the application’s developers. For some period during the
        update the application is almost unavoidably non-functional. If things go wrong, the user may be stuck with
        the current version forever. Worse, a bad update may brick the application
        altogether. And you’ve worked really, really hard to deliver great software in the first
        place.<sup><a href="#2">2</a></sup></p>

    <p>There are some Rust crates addressing this, but because it is so central to the user
        experience, this is again an operation Tritium <a href="https://tritium.legal/blog/word">wants to own</a>.</p>

    <p>So what’s a good approach? Let’s consider a few examples.</p>

    <h2>Background Update Daemon</h2>

    <p>Some applications run a background service which manages updates.</p>

    <p>Adobe, for example, seems to have a separate auto-update binary called <code>Adobe Acrobat Update Service</code>
        that runs as a daemon. A separate service running at predictable intervals allows them to ensure pristine
        conditions for updates at
        off-peak hours, perhaps with even timing staggered to ensure sufficient bandwidth on the update server. They can
        manage atomic updates and rollbacks while the user sleeps.</p>

    <p>Oh, and they also get routine passive telemetry about their installed base as a side effect.</p>

    <p>But for legal technology, privacy is paramount, and users don’t expect Tritium to phone home when idle.
        An integrated drafting environment needs to be trusted with reading, editing and redlining confidential and
        trade
        secret documents. Surprising the user with separate named processes in <code>Task Manager</code> risks damaging
        that trust.</p>

    <p>It also seems over-expansive from a security perspective to keep a possibly
        elevated, network-accessible application running in the background just to ensure your
        application remains up-to-date.</p>

    <p>This approach is out.</p>

    <h2>Asynchronous Background Thread</h2>

    <p>The excellent <a href="https://github.com/zed-industries/zed" target="_blank" rel="noopener">Zed editor</a>
        adopts a more nuanced approach.</p>

    <p>Instead of a separate daemon, as far as I can tell, Zed spawns an auto-updater child thread that
        periodically phones home to check for updates <em>while the application runs</em>.</p>

    <p>Here’s some of the Zed code. From <code>auto_update.rs</code>:</p>

    <pre><code>...

const POLL_INTERVAL: Duration = Duration::from_secs(60 * 60);

...

impl AutoUpdater {

    pub fn start_polling(&amp;self, cx: &amp;mut Context&lt;Self&gt;) -&gt; Task&lt;Result&lt;()&gt;&gt; {
        cx.spawn(async move |this, cx| {
            loop {
                this.update(cx, |this, cx| this.poll(UpdateCheckType::Automatic, cx))?;
                cx.background_executor().timer(POLL_INTERVAL).await;
            }
        })
    }

    pub fn poll(&amp;mut self, check_type: UpdateCheckType, cx: &amp;mut Context&lt;Self&gt;) {
        if self.pending_poll.is_some() {
            return;
        }

        cx.notify();

        self.pending_poll = Some(cx.spawn(async move |this, cx| {
            let result = Self::update(this.upgrade()?, cx.clone()).await;
            this.update(cx, |this, cx| {
                this.pending_poll = None;
                if let Err(error) = result {
                    this.status = match check_type {
                        // Be quiet if the check was automated (e.g. when offline)
                        UpdateCheckType::Automatic =&gt; {
                            log::info!(&#34;auto-update check failed: error:{:?}&#34;, error);
                            AutoUpdateStatus::Idle
                        }
                        UpdateCheckType::Manual =&gt; {
                            log::error!(&#34;auto-update failed: error:{:?}&#34;, error);
                            AutoUpdateStatus::Errored {
                                error: Arc::new(error),
                            }
                        }
                    };

                    cx.notify();
                }
            })
            .ok()
        }));
    }

...

}</code></pre>

    <p>That’s pretty straightforward. We check for an update once an hour and handle
        errors.</p>

    <p>Ok, so we have an update downloaded and validated. What’s next?</p>

    <p>On POSIX systems, in theory,<sup><a href="#3">3</a></sup> we can just update the files in place. Except for
        dynamically loaded assets, this
        should work just fine. The OS treats file locking as advisory and open file descriptors are irrelevant, so even
        if the file is running you overwrite it
        in place and the user will get the freshest version on the next launch. You’ll want to at least handle those
        assets separately such that, for example, your user isn’t running version 1.2 in memory while reading the
        updated version 1.3 config from disk. But maybe it’s as simple as unpacking things and waiting for a restart.
    </p>

    <p>But what about Windows?</p>
    <p>Windows generally treats running binaries as locked. Any attempt to overwrite a running
        binary should throw an exception. Again, the Zed source provides a reasonable solution.</p>

    <p>From <code>auto_update_helper</code>:</p>

    <pre><code>pub(crate) fn run() -&gt; Result&lt;()&gt; {
    let helper_dir = std::env::current_exe()?
        .parent()
        .context(&#34;No parent directory&#34;)?
        .to_path_buf();
    init_log(&amp;helper_dir)?;
    let app_dir = helper_dir
        .parent()
        .context(&#34;No parent directory&#34;)?
        .to_path_buf();

    log::info!(&#34;======= Starting Zed update =======&#34;);
    let (tx, rx) = std::sync::mpsc::channel();
    let hwnd = create_dialog_window(rx)?.0 as isize;
    let args = parse_args(std::env::args().skip(1));
    std::thread::spawn(move || {
        let result = perform_update(app_dir.as_path(), Some(hwnd), args.launch);
        tx.send(result).ok();
        unsafe { PostMessageW(Some(HWND(hwnd as _)), WM_TERMINATE, WPARAM(0), LPARAM(0)) }.ok();
    });
    unsafe {
        let mut message = MSG::default();
        while GetMessageW(&amp;mut message, None, 0, 0).as_bool() {
            DispatchMessageW(&amp;message);
        }
    }
    Ok(())
}</code></pre>

    <p>This is compiled into a separate binary containing a <code>main()</code> that calls <code>run()</code> on Windows
        and is no-op otherwise. It is also immediately recognizable for the Windows API naming conventions.
    </p>

    <p><strong>Why a separate binary?</strong></p>

    <p>That’s the trick to freeing the locked <code>Zed.exe</code> for updating while maintaining flow control.</p>

    <p>Once an update is ready, the <code>auto_update_helper</code> is queued for the next startup. It runs
        <code>perform_update</code> which loops through a <code>const</code> list of <code>JOBS</code> like installing
        new files and removing old ones, including the now unlocked <code>Zed.exe</code>. Once complete, the helper
        hands the process back off to Zed with:
    </p>

    <pre><code>if launch {
    #[allow(clippy::disallowed_methods, reason = &#34;doesn&#39;t run in the main binary&#34;)]
    let _ = std::process::Command::new(app_dir.join(&#34;Zed.exe&#34;)).spawn();
}</code></pre>

    <p>And they&#39;re back to work.</p>

    <h2>Speedbump</h2>

    <p>The Zed auto-updater code is robust to errors and generally stays out of the way.</p>

    <p>It also empowers the user to ignore broken updates and just continue using the current version without any
        concern for its staleness.</p>

    <p>However, when you’re early in development on a privacy-sensitive legal tech, staleness can be a
        problem. You can’t leave users exposed to versions containing a security flaw, for example. More likely, glaring
        bugs could be damaging to establishing trust.</p>

    <p>Tritium thus adopts what I’ll call the “speedbump” auto-updater approach.</p>

    <p>Tritium makes a one-time asychronous check for updates every time the community user starts the application. If
        an update is available, Tritium downloads the update, exits and automatically deploys the update right then
        and there. As with the Zed update, Tritium hands this off to a helper process which also retains the
        command-line arguments to pass to the new version on restart. If things go well, the user should be back in
        action with the freshest version in a few seconds. Nothing more than a small speedbump.</p>

    <p>The application is stuck in this state if things go wrong, however, and the user will have to manually uninstall
        and reinstall it.</p>

    <p>Because it happens on launch every time, it also serves as a potential flow interruption. If things don’t work or
        take too long, we’re going to have an unhappy user. Lawyers are not patient or generally much interested in
        buggy technology. They want their word processor and redlining to work, and they don’t really care why.</p>

    <p>But putting this UX bottleneck front-and-center follows a principle outlined in a great book <em>The Goal</em>.
        Understanding that users will hit the “speedbump” on every boot ensures that it receives first-class performance
        attention and is always top of mind in development. It becomes embedded in the user experience. We thus won’t be
        able to get sloppy and deploy large updates
        silently in the background or neglect the update experience.</p>

    <p>Unlike Zed, Tritium uses the helper binary on all platforms for simplicity. But what about the updater itself?
    </p>

    <p><strong>How do we update that?</strong></p>

    <pre><code>async fn do_update() {
    ...

    let tmp_updater = tmp_directory.join(UPDATER_EXE);
    let Ok(current_exe) = std::env::current_exe() else {
        log::error!(&#34;Failed to determine current executable path&#34;);
        return;
    };
    let Some(working_dir) = current_exe.parent() else {
        log::error!(
            &#34;Failed to determine working directory from current executable path: {}&#34;,
            current_exe.display()
        );
        return;
    };

    ...

    let Ok(_) = std::fs::write(&amp;tmp_file, &amp;bytes) else {
        log::error!(
            &#34;Failed to write update file to temporary directory: {}&#34;,
            tmp_file.display()
        );
        return;
    };
    let mut updater_exe = working_dir.to_path_buf();
    updater_exe.push(UPDATER_EXE);
    log::info!(
        &#34;Copying updater executable from {} to {}&#34;,
        updater_exe.display(),
        tmp_updater.display()
    );
    match std::fs::copy(&amp;updater_exe, &amp;tmp_updater) {
        Err(error) =&gt; {
            log::error!(&#34;Failed to copy updater executable: {}&#34;, error);
            return;
        }
        _ =&gt; {}
    };

    ...

    let Ok(_) = std::process::Command::new(tmp_updater)
        .arg(current_exe.to_path_buf().as_os_str())
        .arg(tmp_file.to_path_buf().as_os_str())
        .spawn()
    else {
        log::error!(&#34;Failed to spawn updater process.&#34;);
        return;
    };
    // do the update in a separate process which will restart the app
    std::process::exit(0);
}</code></pre>

    <p>We rename the legacy <code>updater</code> binary, run it under its new name and deploy the updated version which
        cleans up after itself next time.</p>

    <p>Magic.</p>
    <p>Thanks for reading.</p>

    <hr/>
    <p id="1">[1] This applies to a much more limited extent to enterprises who orchestrate their own updates using more
        sophisticated tools. Commercial Tritium licensees have access to a customizable installer and version-pinned
        binaries as described <a href="https://tritium.legal/docs">in
            the documentation</a>.</p>
    <p id="2">[2] The Zed team recently made a mistake and disabled Zed&#39;s auto-updates by default: <a href="https://www.reddit.com/r/ZedEditor/comments/1nf8x5a/zed_manual_update_required_we_temporarily_broke/">as
            written about here</a>. I grieved for them. Developers work extremely hard to create software that is
        compelling enough to be
        downloaded and
        installed that it is an absolutely brutal to potentially orphan a large
        number of users with a legacy version. Their plight partially inspired this post.</p>

    <p id="3">[3] EDIT (15 October 2025): As pointed out by saagarjha on Hacker News, updating signed files in place
        on macOS is likely to cause a crash. Tritium avoids this by using the second updater binary on all platforms,
        but steps to make in-place updates on macOS are better described: <a href="https://developer.apple.com/documentation/security/updating-mac-software">here</a>.
    </p>
</article></div>
  </body>
</html>
