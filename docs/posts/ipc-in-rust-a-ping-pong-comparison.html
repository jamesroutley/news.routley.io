<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://3tilley.github.io/posts/simple-ipc-ping-pong/">Original</a>
    <h1>IPC in Rust – A Ping Pong Comparison</h1>
    
    <div id="readability-page-1" class="page"><div>
      <p>I wanted to explore different ways of communicating between different processes executing on the same machine, and doing so as fast as possible. We&#39;re focussing on high speed inter-process communication (IPC), but some of these approaches can be extended across a network. We&#39;ll do this exploration in Rust.</p>
<p>A reminder that since these are independent processes, most approaches you&#39;d take within-process are unavailable to us. Rather than communicating between threads, or between asynchronous routines, these are techniques to shared data between different programs. They might not even both be written in Rust.</p>
<p>The code will mostly be snippets, but the full source is available <a href="https://github.com/3tilley/rust-experiments/tree/master/ipc">here</a>, with benchmark results at the end.</p>

<p>We want to send a message (&#34;ping&#34;) from one process to another, and when it&#39;s received reply with an acknowledgement (&#34;pong&#34;). This cycle gives us an opportunity to time how long it takes to round trip between two processes. Timing is complicated, and there is a note on it below but we&#39;ll run lots of cycles, and calculate average time from there.</p>
<p>We&#39;ll set up all the experiments as similarly as possible, with a producer process sending a ping, and a consumer processes replying with a pong. Performance profiling can lead one down a deep rabbit hole, but hopefully this experiment is simple enough that we&#39;ll be able to largely isolate the effect of the communication. Though I don&#39;t doubt keen-eyed readers will highlight optimisations missed, or operations outside the communication that are not as computationally-free as I&#39;ve assumed.</p>
<p>Note that we&#39;re focussing on low-latency here, not high-throughput. Within High-Performance Computing they are related, but are focussed on different goals. As an example to illustrate the difference, imagine a piece of software that performs linear algebra tasks by outsourcing those computations to the GPU. For some problem sets (like training Neural Networks) the time taken to complete the training will be significantly faster on the GPU - the calculations performed per second (or throughput) will be much higher. However there is a cost to marshalling and shipping the data onto the GPU in the first place, and it will never be quicker to multiply two small matrices together like that.</p>
<h2 id="a-note-on-timing">A Note on Timing
</h2>
<p>We tend to assume that computers keep precise, and synchronised clocks. And compared to humans, they largely do. However when trying to measure very quick operations, there are limits to this. For starters, I&#39;m working on a PC with a 4GHz processor. In order to measure something in single cycles, that means I need a clock capable of 0.25ns time resolution - or the time taken for light to travel roughly 10cm. Electrical signals move significantly slower than this, so for a clock outside the processor, even the time taken to sample the timer will dwarf the time taken to perform a few cycles of calculation.</p>
<p>Consider the clock attached to the coin battery on your motherboard. This allows the system to be disconnected from the mains, plugged back in and still know the current time. This is known as a Real Time Clock (RTC). These mostly run at 32.768 kHz (2^15 Hz), only giving them a theoretical resolution of 30 µs - or about a hundred thousand clock cycles. What&#39;s more they are often configured to produce time at a resolution much lower than that - clearly that clock isn&#39;t going to cut it.</p>
<p>The traditional solution is to use a Time Stamp Counter or TSC. This is a processor register that keeps ticking up at the rate of the processor clock speed - so should offer sufficient resolution for our needs. Traditionally the x86 instruction RDTSC is used to read its value. However given the nature of modern CPUs with varying clockspeeds, hyperthreading, deep pipelines, and the fear of cache/timing attacks, it&#39;s more complicated than this. On Windows the Microsoft suggestion is to use the <code>QueryPerformanceCounter</code> function, and on Linux <code>clock_gettime(CLOCK_MONOTONIC)</code> - but note these are both system calls (more on those later). Their resolution is also hardware dependent, if you have a newer device (within 10 years) this may be an <a href="https://en.wikipedia.org/wiki/High_Precision_Event_Timer">HPET</a> , or it could be a modern incarnation of the TSC. Either way these benchmarks are going to yield different results on different hardware and different operating systems, even if the code ran similarly.</p>
<p><strong>Post takeaway</strong> - timing short-duration events is difficult. If in doubt, run enough iterations of your event such that the total completed time is in milliseconds, and then whatever timing source your benchmarking suite relies on should lead to an accurate result.</p>
<p>To learn about the pain of synchronising multiple clocks like this on a network, read or listen this incredible in-depth piece from Jane Street: https://signalsandthreads.com/clock-synchronization/</p>

<p>This was an opportunity for me to try out <a href="https://github.com/nvzqz/divan">Divan</a> for benchmarking. It&#39;s a <strong>comfy bench</strong>marking tool, with the goal of being more ergonomic than <a href="https://github.com/bheisler/criterion.rs">Criterion</a>.</p>
<p>I&#39;ll save offering judgment yet as I haven&#39;t used it a whole lot, but it seems to do what I need it to do. For each approach we will:</p>
<ol>
<li>Create the consumer process, and wait for it to become available</li>
<li>Prepare data and open connections in both processes, and wait for them to complete</li>
<li>Start timing</li>
<li>Run the ping / pong cycle a number of times</li>
<li>Stop timer</li>
<li>Get an average time per operation</li>
</ol>
<p>Fortunately <code>divan</code> gives the tools for that, and allows us to annotate the benches with how many operations were executed, and then produce averages based on that (with some caveats). An example benchmark is here:</p>
<pre data-lang="rust"><code data-lang="rust"><span>#[</span><span>divan</span><span>::</span><span>bench</span><span>]  
</span><span>fn </span><span>stdin_stdout</span><span>(</span><span>bencher</span><span>: Bencher) {  
</span><span>    </span><span>let</span><span> n = </span><span>1000</span><span>;  
</span><span>    </span><span>let mut</span><span> pipe_runner = ipc::pipes::PipeRunner::new(</span><span>false</span><span>);  
</span><span>    </span><span>let mut</span><span> return_buffer = pipe_runner.</span><span>prepare</span><span>();  
</span><span>    bencher  
</span><span>        .</span><span>counter</span><span>(divan::counter::ItemsCount::new(n))  
</span><span>        .</span><span>bench_local</span><span>(</span><span>move </span><span>|| {  
</span><span>            pipe_runner.</span><span>run_inner</span><span>(n, &amp;</span><span>mut</span><span> return_buffer)  
</span><span>        });  
</span><span>}
</span></code></pre>

<p>This is the first thing that comes to mind to connect processes on the same machine. Like <code>cat | grep</code> we&#39;ll just connect <code>stdout</code> of the producer to <code>stdin</code> of the consumer, and vice-versa. This will work on Windows, Linux, and presumably MacOS.</p>
<p>The consumer process reads five bytes into an array from <code>stdin</code>, checks if they&#39;re equal to <code>ping</code> followed by a newline, and then responds appropriately. It&#39;ll also respond to <code>pong</code>.</p>
<pre data-lang="rust"><code data-lang="rust"><span>use </span><span>std::io::{stdin, stdout, Read, Write};  
</span><span>  
</span><span>fn </span><span>main</span><span>() {  
</span><span>    </span><span>let mut</span><span> arr = [</span><span>0</span><span>u8</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>];  
</span><span>    </span><span>loop </span><span>{  
</span><span>        </span><span>let</span><span> read_result = </span><span>stdin</span><span>().</span><span>read_exact</span><span>(&amp;</span><span>mut</span><span> arr);  
</span><span>        </span><span>if</span><span> read_result.</span><span>is_ok</span><span>() {  
</span><span>            </span><span>let</span><span> output = </span><span>match </span><span>&amp;arr {  
</span><span>                </span><span>b</span><span>&#34;</span><span>ping</span><span>\n</span><span>&#34; =&gt; </span><span>b</span><span>&#34;</span><span>pong</span><span>\n</span><span>&#34;,  
</span><span>                </span><span>b</span><span>&#34;</span><span>pong</span><span>\n</span><span>&#34; =&gt; </span><span>b</span><span>&#34;</span><span>ping</span><span>\n</span><span>&#34;,  
</span><span>                _ =&gt; </span><span>b</span><span>&#34;</span><span>Error</span><span>&#34;,  
</span><span>            };  
</span><span>            </span><span>stdout</span><span>().</span><span>write</span><span>(output).</span><span>unwrap</span><span>();  
</span><span>        }  
</span><span>    }  
</span><span>}
</span></code></pre>
<p>The producer process is a little more complex as it has to create and handle consumer first, but pushes out a <code>ping</code> , waits for a response, and then panics if it&#39;s not <code>pong</code>.</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub fn </span><span>run_inner</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>n</span><span>: </span><span>usize</span><span>, </span><span>mut </span><span>return_value</span><span>: &amp;</span><span>mut</span><span> [</span><span>u8</span><span>; 5]) {  
</span><span>    </span><span>if let </span><span>Some(</span><span>ref mut</span><span> pipes_input) = </span><span>self</span><span>.pipe_proc.stdin {  
</span><span>        </span><span>if let </span><span>Some(</span><span>ref mut</span><span> pipes_output) = </span><span>self</span><span>.pipe_proc.stdout {  
</span><span>            </span><span>for </span><span>_ in </span><span>0</span><span>..n {  
</span><span>                pipes_input.</span><span>write</span><span>(</span><span>b</span><span>&#34;</span><span>ping</span><span>\n</span><span>&#34;).</span><span>unwrap</span><span>();  
</span><span>                pipes_output.</span><span>read_exact</span><span>(return_value).</span><span>unwrap</span><span>();  
</span><span>                </span><span>if</span><span> return_value != </span><span>b</span><span>&#34;</span><span>pong</span><span>\n</span><span>&#34; {  
</span><span>                    panic!(&#34;</span><span>Unexpected response</span><span>&#34;)  
</span><span>                }  
</span><span>            }  
</span><span>        }  
</span><span>    }  
</span><span>}
</span></code></pre>
<p>Aside from some fiddly <code>ref mut</code> treatment for the pipes, this was pretty easy to write. With more complex data structures it might be annoying as some decision would have to be made on a delimiter between messages that wasn&#39;t just newlines, but it feels fairly extendable as well.</p>

<p>A natural approach would be to try a client and server connected via HTTP. This felt dangerously like benchmarking HTTP servers though, so instead I just went straight to TCP.</p>
<pre data-lang="rust"><code data-lang="rust"><span>...
</span><span>// Producer
</span><span>impl </span><span>TcpRunner {  
</span><span>    </span><span>pub fn </span><span>new</span><span>(</span><span>start_child</span><span>: </span><span>bool</span><span>, </span><span>tcp_nodelay</span><span>: </span><span>bool</span><span>) -&gt; TcpRunner {  
</span><span>        </span><span>let</span><span> listener = TcpListener::bind(&#34;</span><span>127.0.0.1:0</span><span>&#34;).</span><span>unwrap</span><span>();  
</span><span>        </span><span>let</span><span> port = listener.</span><span>local_addr</span><span>().</span><span>unwrap</span><span>().</span><span>port</span><span>();  
</span><span>        </span><span>let</span><span> exe = </span><span>crate</span><span>::executable_path(&#34;</span><span>tcp_consumer</span><span>&#34;);  
</span><span>        </span><span>let</span><span> child_proc = </span><span>if</span><span> start_child {  
</span><span>            Some(Command::new(exe).</span><span>args</span><span>(&amp;[port.</span><span>to_string</span><span>(), tcp_nodelay.</span><span>to_string</span><span>()]).</span><span>spawn</span><span>().</span><span>unwrap</span><span>())  
</span><span>        } </span><span>else </span><span>{  
</span><span>            None  
</span><span>        };  
</span><span>        </span><span>let</span><span> stream = TcpStreamWrapper::from_listener(listener, tcp_nodelay);  
</span><span>        </span><span>Self </span><span>{ child_proc, wrapper: stream, tcp_nodelay }  
</span><span>    }  
</span><span>  
</span><span>    </span><span>pub fn </span><span>run</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>n</span><span>: </span><span>usize</span><span>, </span><span>print</span><span>: </span><span>bool</span><span>) {  
</span><span>        </span><span>// TODO: Decide whether this can be done without copying from the socket  
</span><span>        </span><span>let mut</span><span> buf = [</span><span>0</span><span>u8</span><span>; </span><span>4</span><span>];  
</span><span>        </span><span>for </span><span>_ in </span><span>0</span><span>..n {  
</span><span>            </span><span>self</span><span>.wrapper.stream.</span><span>write</span><span>(</span><span>b</span><span>&#34;</span><span>ping</span><span>&#34;).</span><span>unwrap</span><span>();  
</span><span>            </span><span>self</span><span>.wrapper.stream.</span><span>read_exact</span><span>(&amp;</span><span>mut</span><span> buf).</span><span>unwrap</span><span>();  
</span><span>            </span><span>if </span><span>!buf.</span><span>eq</span><span>(</span><span>b</span><span>&#34;</span><span>pong</span><span>&#34;) {  
</span><span>                panic!(&#34;</span><span>Sent ping didn&#39;t get pong</span><span>&#34;)  
</span><span>            }  
</span><span>        }  
</span><span>    }  
</span><span>}
</span><span>
</span><span>...
</span><span>
</span><span>// pipes_consumer.rs
</span><span>// Consumer
</span><span>fn </span><span>main</span><span>() {  
</span><span>    </span><span>let</span><span> args: Vec&lt;String&gt; = std::env::args().</span><span>collect</span><span>();  
</span><span>    </span><span>let</span><span> port = </span><span>u16</span><span>::from_str(&amp;args[</span><span>1</span><span>]).</span><span>unwrap</span><span>();  
</span><span>    </span><span>let</span><span> nodelay = </span><span>bool</span><span>::from_str(&amp;args[</span><span>2</span><span>]).</span><span>unwrap</span><span>();  
</span><span>    </span><span>let mut</span><span> wrapper = ipc::tcp::TcpStreamWrapper::from_port(port, nodelay);  
</span><span>    </span><span>let mut</span><span> buf = [</span><span>0</span><span>u8</span><span>; </span><span>4</span><span>];  
</span><span>    </span><span>while let </span><span>Ok(_) = wrapper.stream.</span><span>read</span><span>(&amp;</span><span>mut</span><span> buf) {  
</span><span>        </span><span>if</span><span> buf.</span><span>eq</span><span>(</span><span>b</span><span>&#34;</span><span>ping</span><span>&#34;) {  
</span><span>            wrapper.stream.</span><span>write</span><span>(</span><span>b</span><span>&#34;</span><span>pong</span><span>&#34;).</span><span>unwrap</span><span>();  
</span><span>        } </span><span>else </span><span>{  
</span><span>            panic!(&#34;</span><span>Received unknown value {:?}</span><span>&#34;, buf)  
</span><span>        }  
</span><span>    }  
</span><span>}
</span></code></pre>
<p>All in all, this was fairly simple. Currently ping is written to the socket, copied off, and then checked. Pong is then written back. There is a comment in the code highlighting this, but it&#39;s not clear to me whether the socket can be read without copying it to a local buffer. Given it&#39;s only 5 bytes, and a system call would be required either way, this is likely negligible.</p>
<p>The only other item of interest is that we can set TCP_NODELAY, which disables <a href="https://stackoverflow.com/questions/3761276/when-should-i-use-tcp-nodelay-and-when-tcp-cork">Nagle&#39;s algorithm</a>. Generally TCP waits briefly to build a packet large enough to be worth sending. Given that we are looking for fast transmission, it makes sense to disable this. Benchmarks with and without this setting are given. Spoiler - it didn&#39;t seem to change anything.</p>
<p>Implementation wise, it was slightly more complex than the previous case. A port to connect to had to be passed to the consumer, a connection established, but not too difficult. I felt comfortable writing this code, and I also liked that it could be split across a network if needed. For complex usecases I&#39;d probably miss some HTTP niceties, but for firing packets back and forth this felt flexible and maintainable.</p>

<p>Naturally, the next approach was to try UDP. UDP is traditionally used in these contexts for a &#34;fire and forget&#34; mechanism. Unlike TCP the protocol doesn&#39;t offer a way of recovering lost or out of order packets. This can be an advantage, because it keeps the connection from getting too &#34;chatty&#34; but if consistency is important those layers need to be implemented manually - either in or out of band. We&#39;ll sidestep this discussion because we&#39;re running both processes on the same machine and using the loopback adapter, but note that it&#39;s still possible to lose packets this way. If the socket buffer is filled with more data than can be read off of it in the reading loop, it will be unapologetically dropped. Perhaps a demonstration for another post.</p>
<p>I&#39;ll just show the producer as the consumer is fairly similar.</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub struct </span><span>UdpRunner {  
</span><span>    </span><span>child_proc</span><span>: Option&lt;Child&gt;,  
</span><span>    </span><span>wrapper</span><span>: UdpStreamWrapper,  
</span><span>    </span><span>their_port</span><span>: </span><span>u16</span><span>,  
</span><span>}  
</span><span>  
</span><span>impl </span><span>UdpRunner {  
</span><span>    </span><span>pub fn </span><span>new</span><span>(</span><span>start_child</span><span>: </span><span>bool</span><span>) -&gt; UdpRunner {  
</span><span>        </span><span>let</span><span> wrapper = UdpStreamWrapper::new();  
</span><span>        </span><span>let</span><span> their_port = portpicker::pick_unused_port().</span><span>unwrap</span><span>();  
</span><span>        </span><span>let</span><span> exe = </span><span>crate</span><span>::executable_path(&#34;</span><span>udp_consumer</span><span>&#34;);  
</span><span>        </span><span>let</span><span> child_proc = </span><span>if</span><span> start_child {  
</span><span>            Some(  
</span><span>                Command::new(exe)  
</span><span>                    .</span><span>args</span><span>(&amp;[wrapper.our_port.</span><span>to_string</span><span>(), their_port.</span><span>to_string</span><span>()])  
</span><span>                    .</span><span>spawn</span><span>()  
</span><span>                    .</span><span>unwrap</span><span>(),  
</span><span>            )  
</span><span>        } </span><span>else </span><span>{  
</span><span>            None  
</span><span>        };  
</span><span>        </span><span>// Awkward sleep to make sure the child proc is ready  
</span><span>        </span><span>sleep</span><span>(Duration::from_millis(</span><span>100</span><span>));  
</span><span>        wrapper  
</span><span>            .socket  
</span><span>            .</span><span>connect</span><span>(format!(&#34;</span><span>127.0.0.1:</span><span>{}</span><span>&#34;, their_port))  
</span><span>            .</span><span>expect</span><span>(&#34;</span><span>Child process can&#39;t connect</span><span>&#34;);  
</span><span>        </span><span>Self </span><span>{  
</span><span>            child_proc,  
</span><span>            wrapper,  
</span><span>            their_port,  
</span><span>        }  
</span><span>    }  
</span><span>  
</span><span>    </span><span>pub fn </span><span>run</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>n</span><span>: </span><span>usize</span><span>, </span><span>print</span><span>: </span><span>bool</span><span>) {  
</span><span>        </span><span>let</span><span> start = Instant::now();  
</span><span>        </span><span>let mut</span><span> buf = [</span><span>0</span><span>u8</span><span>; </span><span>4</span><span>];  
</span><span>        </span><span>for </span><span>_ in </span><span>0</span><span>..n {  
</span><span>            </span><span>self</span><span>.wrapper.socket.</span><span>send</span><span>(</span><span>b</span><span>&#34;</span><span>ping</span><span>&#34;).</span><span>unwrap</span><span>();  
</span><span>            </span><span>self</span><span>.wrapper.socket.</span><span>recv</span><span>(&amp;</span><span>mut</span><span> buf).</span><span>unwrap</span><span>();  
</span><span>            </span><span>if </span><span>!buf.</span><span>eq</span><span>(</span><span>b</span><span>&#34;</span><span>pong</span><span>&#34;) {  
</span><span>                panic!(&#34;</span><span>Sent ping didn&#39;t get pong</span><span>&#34;)  
</span><span>            }  
</span><span>        }  
</span><span>    }  
</span><span>}
</span></code></pre>
<p>Overall this worked ok, but it was significantly more fiddly for a few reasons:</p>
<ol>
<li>As UDP is a broadcast protocol, it doesn&#39;t care whether anyone is listening. This means we have to spin up the consumer, connect to the producer, and confirm that they are connected. This could be done out of band, but I&#39;ve just hacked it by sleeping for a period that seems long enough for the consumer to wake up and be prepared to receive instructions</li>
<li>The API was similar to the TCP API, but meant different things. Specifically the <code>connect</code> method doesn&#39;t guarantee any connection has been made, just that the program had bound itself to a remote address that may or may not subsequently fail, or just pump data into the ether. It takes an array of address like the TCP connect method, but it has no meaningful way of deciding whether an address is useful or not (as it doesn&#39;t get a handshake) so just takes the first one and binds to it. All of this is in the <a href="https://doc.rust-lang.org/std/net/struct.UdpSocket.html#method.connect">documentation</a> but it&#39;s not ergonomic. Maybe <code>bind</code> would be a better name, although that does have a specific meaning that may not be appropriate</li>
</ol>
<p>These UDP downsides are well known, and it&#39;s used where they don&#39;t matter as much, or the asynchronous nature is useful. It&#39;s also possible to attach multiple listeners, which isn&#39;t possible with TCP. One can see where this might be useful, and why UDP is ubiquitous in usecases like online gaming.</p>

<p>Shared memory is a known rapid way of sharing data between processes. One process allocates a block of memory, and passes that handle to another process. Each process is then free to read from or write to that block of memory independently. If your first instinct is to fear synchronisation and race conditions, you&#39;d be absolutely correct. What&#39;s worse is that out of the box, Rust doesn&#39;t help us here, despite usually being very helpful with that kind of thing. We&#39;re on our own, and it&#39;s going to be <code>unsafe</code>.</p>
<p>First of all we&#39;ll write the code that will execute in both the producer and consumer to create (or take) a handle to some shared memory, and then lay that out as the producer lock, the consumer lock, and a four byte buffer for us to exchange data.</p>
<pre data-lang="rust"><code data-lang="rust"><span>// Shared memory layout
</span><span>//|    0    |    1    |    2    |    3    |    4    |    5    |    6    |    7    |
</span><span>//|   producer lock   |   consumer lock   |      data buffer (ping or pong)       |
</span><span>pub struct </span><span>ShmemWrapper {  
</span><span>    </span><span>pub </span><span>shmem</span><span>: Shmem,  
</span><span>    </span><span>pub </span><span>owner</span><span>: </span><span>bool</span><span>,  
</span><span>    </span><span>pub </span><span>our_event</span><span>: Box&lt;dyn EventImpl&gt;,  
</span><span>    </span><span>pub </span><span>their_event</span><span>: Box&lt;dyn EventImpl&gt;,  
</span><span>    </span><span>pub </span><span>data_start</span><span>: </span><span>usize</span><span>,  
</span><span>}  
</span><span>  
</span><span>impl </span><span>ShmemWrapper {  
</span><span>    </span><span>pub fn </span><span>new</span><span>(</span><span>handle</span><span>: Option&lt;String&gt;) -&gt; ShmemWrapper {  
</span><span>        </span><span>let</span><span> owner = handle.</span><span>is_none</span><span>();  
</span><span>        </span><span>// If we&#39;ve been given a memory handle, attach it, if not, create one  
</span><span>        </span><span>let mut</span><span> shmem = </span><span>match</span><span> handle {  
</span><span>            None =&gt; </span><span>shmem_conf</span><span>().</span><span>create</span><span>().</span><span>unwrap</span><span>(),  
</span><span>            Some(h) =&gt; </span><span>shmem_conf</span><span>()  
</span><span>                .</span><span>os_id</span><span>(&amp;h)  
</span><span>                .</span><span>open</span><span>()  
</span><span>                .</span><span>expect</span><span>(&amp;format!(&#34;</span><span>Unable to open the shared memory at </span><span>{}</span><span>&#34;, h)),  
</span><span>        };  
</span><span>        </span><span>let mut</span><span> bytes = </span><span>unsafe </span><span>{ shmem.</span><span>as_slice_mut</span><span>() };  
</span><span>        </span><span>// The two events are locks - one for each side. Each side activates the lock while it&#39;s  
</span><span>        </span><span>// writing, and then unlocks when the data can be read
</span><span>        </span><span>let </span><span>((our_event, lock_bytes_ours), (their_event, lock_bytes_theirs)) = </span><span>unsafe </span><span>{  
</span><span>            </span><span>if</span><span> owner {  
</span><span>                (  
</span><span>                    BusyEvent::new(bytes.</span><span>get_mut</span><span>(</span><span>0</span><span>).</span><span>unwrap</span><span>(), </span><span>true</span><span>).</span><span>unwrap</span><span>(),  
</span><span>                    BusyEvent::new(bytes.</span><span>get_mut</span><span>(</span><span>2</span><span>).</span><span>unwrap</span><span>(), </span><span>true</span><span>).</span><span>unwrap</span><span>(),  
</span><span>                )  
</span><span>            } </span><span>else </span><span>{  
</span><span>                (
</span><span>	                </span><span>// If we&#39;re not the owner, the events have been created already  
</span><span>                    BusyEvent::from_existing(bytes.</span><span>get_mut</span><span>(</span><span>2</span><span>).</span><span>unwrap</span><span>()).</span><span>unwrap</span><span>(),  
</span><span>                    BusyEvent::from_existing(bytes.</span><span>get_mut</span><span>(</span><span>0</span><span>).</span><span>unwrap</span><span>()).</span><span>unwrap</span><span>(),  
</span><span>                )  
</span><span>            }  
</span><span>        };  
</span><span>        </span><span>// Confirm that we&#39;ve correctly indexed two bytes for each lock  
</span><span>        assert!(lock_bytes_ours &lt;= </span><span>2</span><span>);  
</span><span>        assert!(lock_bytes_theirs &lt;= </span><span>2</span><span>);  
</span><span>        </span><span>if</span><span> owner {  
</span><span>            our_event.</span><span>set</span><span>(EventState::Clear).</span><span>unwrap</span><span>();  
</span><span>            their_event.</span><span>set</span><span>(EventState::Clear).</span><span>unwrap</span><span>();  
</span><span>        }  
</span><span>        ShmemWrapper {  
</span><span>            shmem,  
</span><span>            owner,  
</span><span>            our_event,  
</span><span>            their_event,  
</span><span>            data_start: </span><span>4</span><span>,  
</span><span>        }  
</span><span>    }  
</span><span>  
</span><span>    </span><span>pub fn </span><span>signal_start</span><span>(&amp;</span><span>mut </span><span>self</span><span>) {  
</span><span>        </span><span>self</span><span>.our_event.</span><span>set</span><span>(EventState::Clear).</span><span>unwrap</span><span>()  
</span><span>    }  
</span><span>    </span><span>pub fn </span><span>signal_finished</span><span>(&amp;</span><span>mut </span><span>self</span><span>) {  
</span><span>        </span><span>self</span><span>.our_event.</span><span>set</span><span>(EventState::Signaled).</span><span>unwrap</span><span>()  
</span><span>    }  
</span><span>  
</span><span>    </span><span>pub fn </span><span>write</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>data</span><span>: &amp;[</span><span>u8</span><span>; 4]) {  
</span><span>        </span><span>let mut</span><span> bytes = </span><span>unsafe </span><span>{ </span><span>self</span><span>.shmem.</span><span>as_slice_mut</span><span>() };  
</span><span>  
</span><span>        </span><span>for</span><span> i in </span><span>0</span><span>..data.</span><span>len</span><span>() {  
</span><span>            bytes[i + </span><span>self</span><span>.data_start] = data[i];  
</span><span>        }  
</span><span>    }  
</span><span>  
</span><span>    </span><span>pub fn </span><span>read</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;[</span><span>u8</span><span>] {  
</span><span>        </span><span>unsafe </span><span>{ &amp;</span><span>self</span><span>.shmem.</span><span>as_slice</span><span>()[</span><span>self</span><span>.data_start..</span><span>self</span><span>.data_start + </span><span>4</span><span>] }  
</span><span>    }  
</span><span>}
</span></code></pre>
<p>With these structures in place, we simply lock, write, unlock, and then read when we&#39;re allowed to.</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub fn </span><span>run</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>n</span><span>: </span><span>usize</span><span>, </span><span>print</span><span>: </span><span>bool</span><span>) { 
</span><span>	</span><span>for </span><span>_ in </span><span>0</span><span>..n {  
</span><span>	    </span><span>// Activate our lock in preparation for writing  
</span><span>	    </span><span>self</span><span>.wrapper.</span><span>signal_start</span><span>();  
</span><span>	    </span><span>self</span><span>.wrapper.</span><span>write</span><span>(</span><span>b</span><span>&#34;</span><span>ping</span><span>&#34;);  
</span><span>	    </span><span>// Unlock after writing  
</span><span>	    </span><span>self</span><span>.wrapper.</span><span>signal_finished</span><span>();  
</span><span>	        </span><span>// Wait for their lock to be released so we can read  
</span><span>	    </span><span>if </span><span>self</span><span>.wrapper.their_event.</span><span>wait</span><span>(Timeout::Infinite).</span><span>is_ok</span><span>() {  
</span><span>	        </span><span>let str </span><span>= </span><span>self</span><span>.wrapper.</span><span>read</span><span>();  
</span><span>	        </span><span>if str </span><span>!= </span><span>b</span><span>&#34;</span><span>pong</span><span>&#34; {  
</span><span>	            panic!(&#34;</span><span>Sent ping didn&#39;t get pong</span><span>&#34;)  
</span><span>	        }  
</span><span>	    }  
</span><span>	} 
</span><span>}
</span></code></pre>
<p>This code was horrible to write, and took some time to get right. I&#39;m almost certain there are still bugs in there. It was complicated because:</p>
<ul>
<li>We have to do all of our own synchronisation without much help. In some situations, you can imagine using a queue or messaging system to communicate out of band between the processes, letting them know when it&#39;s safe to read or write. Given our messages are so small though, this would kill all the performance we&#39;ve gone to the effort of achieving</li>
<li>It&#39;s very low level. We have to marshal the bytes ourselves, and use a lot of unsafe to do so. This also exposes us to changes in the layout of structs that would lead to hard-to-find bugs</li>
<li>I came across several bugs. On the Windows implementation of the most featureful crate there is a minimum page size <a href="https://github.com/elast0ny/shared_memory/issues/107">bug</a> when allocating memory pages</li>
<li>It&#39;s not clear whether underlying memory can be easily resized. For our purposes this isn&#39;t a problem given we only have 8 bytes, but you can imagine this would quite quickly become an issue</li>
</ul>
<p>To be honest, unless I was absolutely sure I needed all of the shared memory performance, I wouldn&#39;t want to use code like this in Production. Other languages have shared memory frameworks to make things like this easier, but I wasn&#39;t able to find anything in Rust when I looked.</p>

<p>I&#39;ve added results for Windows and Linux, but take these with a significant grain of salt as they are different machines. It&#39;s probably fair to compare them within platform though.</p>
<table><thead><tr><th>Platform</th><th>Approach</th><th>Time per Operation (µs)</th><th>Ops per Second</th><th>Time Comparison to Shared Memory</th></tr></thead><tbody>
<tr><td>Linux</td><td>1 - stdin_stdout</td><td>4.802</td><td>208k</td><td>27.7x</td></tr>
<tr><td>Linux</td><td>2 - tcp_nodelay</td><td>10.930</td><td>92k</td><td>63.1x</td></tr>
<tr><td>Linux</td><td>2 - tcp_yesdelay</td><td>11.190</td><td>89k</td><td>64.6x</td></tr>
<tr><td>Linux</td><td>3 - udp</td><td>9.120</td><td>110k</td><td>52.6x</td></tr>
<tr><td>Linux</td><td>4 - shared_memory</td><td>0.173</td><td>5770k</td><td>1.0x</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>Windows</td><td>1 - stdin_stdout</td><td>28.450</td><td>35k</td><td>150.2x</td></tr>
<tr><td>Windows</td><td>2 - tcp_nodelay</td><td>39.390</td><td>25k</td><td>208.0x</td></tr>
<tr><td>Windows</td><td>2 - tcp_yesdelay</td><td>39.360</td><td>25k</td><td>207.8x</td></tr>
<tr><td>Windows</td><td>3 - udp</td><td>41.700</td><td>24k</td><td>220.2x</td></tr>
<tr><td>Windows</td><td>4 - shared_memory</td><td>0.189</td><td>5280k</td><td>1.0x</td></tr>
</tbody></table>
<p><img src="https://3tilley.github.io/posts/ipc-results-graph.png" alt="results"/></p>
<p>The time per operation is similar for most of the approaches, apart from using shared memory. With shared memory we can perform a ping-pong in under 200ns, or around 1000 processor cycles. I have to admit, I still found this a little disappointing. Moving a few bytes around should be faster than that, but I&#39;m going to resist digging too deep yet. Preparing an environment with core-pinning and the correct thread priority is tricky, and given we have to do this with two concurrently running processes, it&#39;s even more difficult. Consider too that with hyper-threaded cores, should these processes run on different physical cores, or different logical cores? Do I have to disable Spectre/Meltdown type mitigations? Which memory cache level can we share? Having sunk a lot of hours similar situations before, I&#39;m going to leave the log unflipped for now.</p>
<h2 id="system-calls">System calls
</h2>
<p>But why are all the other methods so slow - and not only that, but so similarly slow? Well Linux gives us the easiest tool to see what&#39;s happening <a href="https://man7.org/linux/man-pages/man1/strace.1.html">strace</a>. <code>strace</code> allows us to run a command and see what system calls are made by that command. We can test this with the tcp runner, with 10 cycles of ping-pong. It generates a large amount of results, especially since I&#39;m running this through <code>cargo</code>, but we can trim it down and see that in the heart of the execution there are system calls. Given I&#39;ve only attached this to the producer process, and we can see that there are two systems calls per cycle (a read and a write), so for the whole cycle we require four system calls.</p>
<pre data-lang="bash"><code data-lang="bash"><span>$</span><span> strace</span><span> -r</span><span> cargo run</span><span> --release</span><span> -- -n 10 -m tcp
</span><span>...
</span><span>    </span><span>0.000694</span><span> accept4(3, {sa_family=AF_INET, sin_port=htons(33404), sin_addr=inet_addr(&#34;</span><span>127.0.0.1</span><span>&#34;)}, </span><span>[</span><span>128 =&gt; 16</span><span>]</span><span>, SOCK_CLOEXEC) = </span><span>4
</span><span>     </span><span>0.000939</span><span> setsockopt(4, SOL_TCP, TCP_NODELAY, </span><span>[</span><span>1</span><span>]</span><span>, 4) = </span><span>0
</span><span>     </span><span>0.000866</span><span> close(3)                  = </span><span>0
</span><span>     </span><span>0.006059</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000495</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000125</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000143</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000040</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000131</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000113</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000130</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000133</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000136</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000112</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000130</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000112</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000129</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000112</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000129</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000634</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000169</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000286</span><span> sendto(4, &#34;</span><span>ping</span><span>&#34;, 4, MSG_NOSIGNAL, NULL, 0) = </span><span>4
</span><span>     </span><span>0.000227</span><span> recvfrom(4, &#34;</span><span>pong</span><span>&#34;, 4, 0, NULL, NULL) = </span><span>4
</span><span>     </span><span>0.000174</span><span> write(1, &#34;</span><span>10 cycles completed in 3ms 669us</span><span>&#34;..., 4010 cycles completed in 3ms 669us 247ns 
</span><span>) = </span><span>40
</span><span>     </span><span>0.000166</span><span> write(1, &#34;</span><span>2725.5383 per second\n</span><span>&#34;, 212725.5383 per second
</span><span>
</span><span>...
</span><span>
</span></code></pre>
<p>How expensive are system calls? Well I&#39;ve used <code>strace -r</code> to show times per call, but given previous discussions about how calling a timer can affect times (it adds at least one syscall per line) I won&#39;t take those numbers as ironclad. Especially <code>strace</code> is pausing and unpausing the process. Roughly roughly speaking though we&#39;re looking at least a few microseconds per read or write. Four of those, and you can see why tcp struggles to do better than 10µs per operation. This is similar for all of the other approaches.</p>
<p>System calls on Linux are complex, and there are various mitigations, but having to wipe registers, validate, drop down into the kernel ring, get the output, and then undo those steps takes time. So if you really care about microseconds, try and avoid them in your hot loops.</p>
<p>For the shared memory approach we can see that after the mmap to create the block of shared memory, there are no calls in our loop, so we don&#39;t pay that cost.</p>
<pre data-lang="bash"><code data-lang="bash"><span>$</span><span> strace</span><span> -r</span><span>  ./target/release/ipc</span><span> -n</span><span> 10</span><span> -m</span><span> shmem
</span><span>...
</span><span>    </span><span>0.000215</span><span> mmap(NULL, 8, PROT_READ|</span><span>PROT_WRITE,</span><span> MAP_SHARED, 3, 0) = </span><span>0x7f81dac8b000
</span><span>     </span><span>0.000091</span><span> mmap(NULL, 36864, PROT_READ|</span><span>PROT_WRITE,</span><span> MAP_PRIVATE|</span><span>MAP_ANONYMOUS</span><span>|</span><span>MAP_STACK, -1</span><span>, 0) = </span><span>0x7f81dac46000
</span><span>     </span><span>0.000051</span><span> rt_sigprocmask(SIG_BLOCK, </span><span>~</span><span>[]</span><span>, </span><span>[]</span><span>, 8) = </span><span>0
</span><span>     </span><span>0.000140</span><span> clone3({flags=CLONE_VM|CLONE_VFORK, exit_signal=SIGCHLD, stack=0x7f81dac46000, stack_size=0x9000}, 88) = </span><span>70905
</span><span>     </span><span>0.000653</span><span> munmap(0x7f81dac46000, 36864) = </span><span>0
</span><span>     </span><span>0.000066</span><span> rt_sigprocmask(SIG_SETMASK, </span><span>[]</span><span>, NULL, 8) = </span><span>0
</span><span>     </span><span>0.000058</span><span> clock_nanosleep(CLOCK_REALTIME, 0, {tv_sec=1, tv_nsec=0}, 0x7ffe52d29560) = </span><span>0
</span><span>     </span><span>1.576578</span><span> write(1, &#34;</span><span>10 cycles completed in 521us 91n</span><span>&#34;..., 3510 cycles completed in 521us 91ns
</span><span>...
</span></code></pre>

<p>I was surprised at how similarly most things performed. I did a cursory investigation into Linux-specific approaches like dbus and Unix Domain Sockets, but they seemed to be in the same ballpark as the non-shared memory approaches. The only other thing to try would be memory-mapped files, but I thought I&#39;d save that for when I wanted to try something similar with larger blocks of data.</p>
<p>If I had to do this in Production, for the majority of workloads I&#39;d probably still use an HTTP / TCP connection. It&#39;s portable, reliable on message failure, and I could split it across machines if needs be. However for the cases where latency really matters, the maintenance overhead of using shared memory is worth it.</p>
<p>For anyone who wants a deeper dive, or to offer critiques and improvements, the code is available <a href="https://github.com/3tilley/rust-experiments/tree/master/ipc">here</a>.</p>

  </div></div>
  </body>
</html>
