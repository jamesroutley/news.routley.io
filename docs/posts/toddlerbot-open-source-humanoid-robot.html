<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://toddlerbot.github.io/">Original</a>
    <h1>Toddlerbot: Open-Source Humanoid Robot</h1>
    
    <div id="readability-page-1" class="page">
  <section>
    <div>
      <div>
        <div>
          <div>
            
            
            

            <p><span><sup>*</sup>Equal contribution,</span>
              <span><sup>†</sup>Equal advising</span>
            </p>

            <p><span>Stanford University</span>
            </p>

            
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- 
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          RoboCraft shapes elasto-plastic objects into various 3D target shapes in the real
          world.
        </h2>
      </div>
    </div>
  </section> -->

  <!-- <section class="section">
    <div class="container is-max-desktop"> -->
  <!-- Abstract. -->
  <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Learning-based robotics research driven by data demands a new approach to robot hardware design—one that
              serves as both a platform for policy execution and a tool for embodied data collection to train policies.
              We introduce ToddlerBot, a low-cost, open-source humanoid robot platform designed for scalable policy
              learning and research in robotics and AI. ToddlerBot enables seamless acquisition of high-quality
              simulation and real-world data. The plug-and-play zero-point calibration and transferable motor system
              identification ensure a high-fidelity digital twin, enabling zero-shot policy transfer from simulation to
              the real-world. A user-friendly teleoperation interface facilitates streamlined real-world data collection
              for learning motor skills from human demonstrations. Utilizing its data collection ability and
              anthropomorphic design, ToddlerBot is an ideal platform to perform whole-body loco-manipulation.
              Additionally, ToddlerBot's compact size (0.56m, 3.4kg) ensures safe operation in real-world environments.
              Reproducibility is achieved with an entirely 3D-printed, open-source design and commercially available
              components, keeping the total cost under 6,000 USD. Comprehensive documentation allows assembly and
              maintenance with basic technical expertise, as validated by a successful independent replication of the
              system. We demonstrate ToddlerBot's capabilities through arm span, payload, endurance tests,
              loco-manipulation tasks, and a collaborative long-horizon scenario where two robots tidy a toy session
              together. By advancing ML-compatibility, capability, and reproducibility, ToddlerBot provides a robust
              platform for scalable learning and dynamic policy execution in robotics research.
            </p>
          </div>
        </div>
      </div> -->
  <div>
    <div>
      <p>
          <strong>TL;DR: ToddlerBot is a low-cost, open-source humanoid robot platform designed for
            scalable policy learning and research in robotics and AI.</strong>
        </p>
    </div>
  </div>
  <!--/ Abstract. -->

  <!-- Paper video. -->
  <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/o2LPhcZRtSo?rel=0&showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
  <!--/ Paper video. -->
  <!-- </div>
  </section> -->

  <section>
    <div>
      <div>
        <div>
          <h2>2.0 Release</h2>
          <p>
              <strong><em>See <a href="https://github.com/hshi74/toddlerbot/blob/main/CHANGELOG.md">CHANGELOG.md</a> for
                  details. 1x Speed unless otherwise noted.</em></strong>
            </p>

          <h3>New Capabilities</h3>
          
          </div>
      </div>

      <div>
        <div>
          <h2>Design</h2>
          <p>
              We present ToddleBot&#39;s mechatronic design in the figure below. We highlight ToddlerBot&#39;s 30
              active DoFs with orange markers: 7 DoFs per arm, 6 DoFs per leg, a 2-DoF neck, and a 2-DoF waist. Green
              markers indicate two end-effector designs—a compliant palm and a parallel-jaw gripper. Purple markers
              denote the sensor and electronics layout with exploded views, featuring two fisheye cameras, a speaker,
              two microphones, an IMU, and a Jetson Orin NX computer.
            </p>
          <div>
            <p><img src="https://toddlerbot.github.io/static/images/design.png" alt="Mechatronic Design."/>
            </p>
          </div>
        </div>
      </div>

      <div>
        <div>
          <h2>Results</h2>
          <p>
              <strong><em>1x Speed unless otherwise noted.</em></strong>
            </p>

          <h3>Capability: Arm Span, Payload, and Endurance</h3>
          
          </div>
        <br/>
      </div>
    </div>
    
  </section>

  

  <section id="BibTeX">
    <div>
      <h2>BibTeX</h2>
      <pre><code>@article{shi2025toddlerbot,
  title={ToddlerBot: Open-Source ML-Compatible Humanoid Platform for Loco-Manipulation},
  author={Shi, Haochen and Wang, Weizhuo and Song, Shuran and Liu, C. Karen},
  journal={arXiv preprint arXiv:2502.00893},
  year={2025}
}</code></pre>
    </div>
  </section>

  <section id="Acknowledgement">
    <div>
      <h2>Acknowledgement</h2>
      <p>The authors would like to express their gratitude to Kaizhe Hu for assembling the second instance of ToddlerBot
        and assisting with keyframe animation and demo recording. We also extend our thanks to Huy Ha, Yen-Jen Wang, Pei
        Xu, and Yifan Hou for their insightful discussions on locomotion, and to Sirui Chen, Chen Wang, and Yunfan Jiang
        for valuable input on manipulation policy deployment.
        We are grateful to Albert Wu for his guidance on mathematical formulation and notation. Additionally, we thank
        João Pedro Araújo for his assistance with the motion capture system.
        Finally, we appreciate the helpful discussions from all members of TML and REALab. This work was supported by
        National Science Foundation NSF-FRR-2153854, NSF-2143601, NSF-2037101, Sloan Fellowship, Stanford Institute for
        Human-Centered Artificial Intelligence, and Stanford Wu Tsai Human Performance Alliance.</p>
    </div>
  </section>

  



</div>
  </body>
</html>
