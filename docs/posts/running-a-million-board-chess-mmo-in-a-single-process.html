<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://eieio.games/blog/a-million-realtime-chess-boards-in-a-single-process">Original</a>
    <h1>Running a million-board chess MMO in a single process</h1>
    
    <div id="readability-page-1" class="page"><article>
<p><a href="https://onemillionchessboards.com">One Million Chessboards</a> is a 1000x1000 grid of chess boards. Moving a piece moves it for everyone, instantly. There are no turns, and pieces can move between boards.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-gameplay-firstframe.webp" width="940" height="564" preload="metadata" alt="Gameplay from one million chessboards. Lots of pieces are moving around on a large grid of boards. The user moves a queen to capture a king on another board, then jumps around the grid using the minimap."><p>Loading...</p></video><p>making some moves</p></div>
<p>In the 10 days after launch, over 150,000 players made over 15,000,000 moves and hundreds of millions of queries. The game runs out of a single process that I didn’t touch over those 10 days <a>1</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>1</span></p><p>Once activity died down I bounced the server, reset the game, and started
experimenting with rule tweaks.</p></div></div></div></div>
<p>Making this project taught me a lot. It’s the first time I’ve used protobufs or <a href="https://en.wikipedia.org/wiki/Go_(programming_language)">golang</a>, the first time I’ve measured nanoseconds, and my first time writing <a href="https://en.wikipedia.org/wiki/Netcode#Rollback">rollback netcode</a>.</p>
<p>Let me tell you about it.</p>
<ul>
<li><em><a href="https://github.com/nolenroyalty/one-million-chessboards">read the code here</a></em></li>
<li><em><a href="https://onemillionchessboards.com">play the game here</a></em></li>
<li><em><a href="https://www.youtube.com/watch?v=bF1EuktmWoc">this essay is also a video on my youtube channel, if that’s more your style</a></em></li>
</ul>
<!-- -->
<h2 id="toc:basics">Basics</h2>
<p>Here’s a quick overview of the site before we jump into the details.</p>
<h3 id="toc:rules">Rules</h3>
<p><strong>Pieces can move between boards</strong> - I wanted one global game, not a million simultaneous ones <a>2</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>2</span></p><p>This seemed to really disappoint actual chess players. I’m a little surprised
by that - I don’t think that a million simultaneous games would lead to
particularly interesting gameplay! - but maybe I’m wrong.</p></div></div></div></div>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-move-between-boards-firstframe.png" width="998" height="562" preload="metadata" alt="A queen on one million chessboards moves horizontally across several adjacent boards"><p>Loading...</p></video><p>moving between boards</p></div>
<p>This meant that sharding the boards over many processes wasn’t free because those processes would need to communicate.</p>
<p>There are <strong>no turns</strong>. I didn’t think asking the whole internet to take turns would work well. And I thought real-time chess would be fun.</p>

<p>This meant that speed mattered; I needed to make sure that clients could make moves fast.</p>
<p><strong>I prevented pieces from <em>capturing</em> pieces on other boards</strong>. This was originally to prevent a queen from immediately capturing the king on the board above or below her, but ended up producing fun emergent gameplay as people (ab)used it to make indestructible structures like Rooklyn and Queens.</p>
<div><p><img alt="a board full of rooks on one million chessboards" loading="lazy" width="290" height="363" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rooklyn.webp"/><img alt="a board full of queens on one million chessboards" loading="lazy" width="1290" height="1384" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-queens.webp"/><img alt="A complex design featuring white and black pieces across many boards on one million chessboards." loading="lazy" width="611" height="593" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-worldbuilding.webp"/></p><p>Rooklyn, Queens, and a digital monument</p></div>
<p>This rule was interesting, but it locked up the game. After activity died down I tried relaxing the restriction to only apply to unmoved pieces. I think this was a mistake - the original version was likely better.</p>
<p>The site has some other fun features. You can click on pieces to see how many times they’ve moved or captured a piece, there’s a minimap that lets you quickly jump to anywhere on the grid, and you can zoom out to see an overview of a larger chunk of the board at once.</p>
<div><div><p><img alt="A queen with the &#39;treasonous&#39; achievement&#39;" loading="lazy" width="682" height="336" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/treason.webp"/></p><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/zoomout-smallqual-firstframe.png" width="718" height="404" preload="metadata" alt="Zooming in and out on one million chessboards"><p>Loading...</p></video></div><p>15 moves and 14 captures for this queen - not bad!</p></div>
<h3 id="toc:system-design-goals">System Design Goals</h3>
<p>Last year I built a surprisingly popular site called <a href="https://en.wikipedia.org/wiki/One_Million_Checkboxes">One Million Checkboxes</a>. I learned a lot while <a href="https://eieio.games/blog/scaling-one-million-checkboxes/">scaling it to handle load</a>; those learnings directly lead to my design goals.</p>
<p>I wanted to <strong>minimize bandwidth</strong> since it was my one unbounded cost. It’s very stressful going to bed not knowing what you’ll owe when you wake up.</p>
<p>I chose to run in a <strong>single process</strong> - partially because it was easier than sharding, partially because it was a fun challenge, but primarily because I was still smarting from a Hacker News <a href="https://news.ycombinator.com/item?id=41081000">comment</a> (correctly!) pointing out that I didn’t need one for One Million Checkboxes.</p>
<div><p><img alt="Sorry, I&#39;m talking hypothetically about how this would be designed, not in the context of your specific timeframe! &gt; &#39;is my specialized datastore gonna be faster than Redis&#39; Absolutely! With how efficient this code would be, you&#39;d likely never need to scale horizontally, and in that case it is extremely easy to compete with a network hop (at least 1ms latency) versus L1 cache (&lt;50ns) The comparison with redis otherwise only applies once you do need to scale horizontally.There&#39;s also the fact that redis must be designed to support any query pattern efficiently; a much harder problem then supporting just 1-2 queries efficiently." loading="lazy" width="1512" height="528" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/hn-omcb1-scaling.webp"/></p><p>This irked me because they were *right*</p></div>
<p>I aimed to be <strong>bottlenecked by syscalls or message serialization</strong> overhead. Both of those operations parallelize well, which means I could scale vertically to address them if I needed to.</p>
<p>And finally, I wanted to be <strong>surprisingly fast</strong>. My biggest gripe with most One Million Checkboxes clones is that they have too many loading spinners (One Million Checkboxes sent all its data to all clients which - when it wasn’t crashing - kept things snappy). I couldn’t ship <em>all</em> my data to clients this time so they’d have to load data occasionally - but I wanted to be faster than anyone would reasonably expect.</p>
<h3 id="toc:basic-architecture">Basic Architecture</h3>
<p>The server runs in a single golang process. It sits behind an nginx reverse proxy that sits behind cloudflare. An auxiliary VM handles metrics collection and stores backups of the game state. The frontend is written in React.</p>
<div><p><img alt="Diagram of the One Million Chessboards tech stack. A client written in React talks to cloudflare, which talks to nginx, which acts as a reverse proxy for a single golang process. A separate VM handles metrics and backups." loading="lazy" width="2642" height="1452" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-tech-stack.webp"/></p><p>metrics are handled via vector and loki</p></div>
<p>The server has 4 core components - the board, client manager, minimap aggregator, and board to disk handler.</p>
<div><p><img alt="Server components for One Million Chessboards. The board is an 8000x8000 array of pieces, the client manager is a 160x160 array that tracks where clients are, the minimap aggregator is a 200x200 array that summarizes piece locations, and the board to disk handler is a duplicate of the board that saves state to disk" loading="lazy" width="1708" height="1282" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-server-components.webp"/></p><p>yes, they&#39;re all arrays, what of it</p></div>
<ul>
<li><strong>The board</strong> is a dense 8000x8000 array of uint64s representing pieces.</li>
<li><strong>The client manager</strong> tracks the location of each client</li>
<li><strong>The minimap aggregator</strong> summarizes where pieces are</li>
<li><strong>The board to disk handler</strong> duplicates our board state and regularly serializes that state to disk</li>
</ul>
<p>The server also has a set of goroutines (go’s lightweight threads) for every connected user. These goroutines track per-client data, accept moves, and are responsible for compressing and sending data to each client:</p>
<div><p><img alt="The responsibilities of the client.go component on the OMCB server. It tracks a user&#39;s location, accepts moves, distributes relevant moves, and sends snapshots" loading="lazy" width="2865" height="1611" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-client-go-responsibilities.webp"/></p><p>I regret calling this &#39;client&#39; since it sounds like I&#39;m referring to the website</p></div>
<p>The client has a few more responsibilities like assigning you a starting location next to another active player or tracking whether you’re playing black or white.</p>
<h2 id="toc:distribution">Distribution</h2>
<p>One Million Chessboards starts with 32 million pieces. We can’t ship all the pieces to every client!</p>
<p>So we distribute state via <strong>snapshots</strong> and <strong>move batches.</strong> Snapshots and move batches are sent based on a player’s <strong>position.</strong></p>
<ul>
<li>A <strong>position</strong> is the center of a player’s screen - if a player’s position is 100,100 they might see pieces between square 84,84 and square 116,116</li>
<li>A <strong>snapshot</strong> is a list of all pieces in a 95x95 square around a position.</li>
<li>A <strong>move batch</strong> is a list of all moves (e.g. ‘piece #2 moved to 300,300’) that have happened close to a position</li>
</ul>
<p>When a player connects we send them a <strong>snapshot</strong>. After that we send <strong>move batches</strong>, since moves are the only way that the board state changes. As the client moves positions we send them new snapshots <a>3</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>3</span></p><p>These updates are sent over websockets, meaning they use TCP. I think we
<em>could</em> send some of them (at least moves) over UDP using WebRTC, which would
be faster and consistent with what many networked games running outside of the
browser do. I avoided this just because I knew how to use websockets and was
already learning a ton of stuff for this project, but did add sequence numbers
to everything so that I could swap to UDP if I needed to.</p></div></div></div></div>
<p>We send batches of moves to clients every 200 milliseconds (unless the batch becomes very large). Batching <em>massively</em> reduced load for One Million Checkboxes so I kept the same logic here.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-scrolling-firstframe.png" width="824" height="464" preload="metadata" alt=""><p>Loading...</p></video><p>data is fetched as the client moves so that players don&#39;t see loading screens as they scroll</p></div>
<p>The server tracks the position of the last snapshot it sent to the client. The client tells the server whenever it changes position, and the server decides when to send new snapshots.</p>
<p>The server sends a new snapshot if a player’s position is more than 12 horizontal or vertical tiles away from its previous position - if a client is panning around, this gets them new data <em>before</em> they need it, avoiding loading spinners <a>4</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>4</span></p><p>To avoid overloading the server, the client throttles and debounces the number
of “I’ve changed position” messages you can send in a second.</p></div></div></div></div>
<p>We also send a new snapshot every 2 minutes in case clients get into a weird state or drops a message while their tab is backgrounded.</p>
<h3 id="toc:protocol">Protocol</h3>
<p>Updates are shipped to clients using <a href="https://protobuf.dev/">protobufs</a> (a binary serialization format from Google) <a>5</a> and compressed using <a href="https://en.wikipedia.org/wiki/Zstd">zstd</a>. Protobufs are small (reducing bandwidth costs) and very fast to serialize.</p>
<div data-is-footnote="true"><div><div><div><p><span>5</span></p><p>I also considered BSON and messagepack (too large), flatbuffers (better
client-side, but harder to serialize), and Cap’N’Proto. Cap’N’Proto seems even
better for my use-case than protobufs but I wasn’t confident enough in the
third-party javascript tooling for it, whereas protobufjs seemed rock solid.</p></div></div></div></div>
<p>Snapshots and moves contain a piece id, the piece’s position, and some metadata (the piece type, move and capture counts, etc). Protobufs use a <a href="https://protobuf.dev/programming-guides/encoding/">variable number of bytes</a> to encode a number depending on its size, keeping our message size low.</p>
<p>These protobufs compress surprisingly well! Here are some numbers I measured before shipping:</p>
<pre><code><span>Bandwidth usage for ~5,000 snapshots and ~575,000 moves:
</span><span>
</span><span>76  MB - compressed protobuf
</span><span>98  MB - compressed JSON
</span><span>269 MB - uncompressed protobuf
</span><span>2.5 GB - uncompressed unoptimized JSON
</span></code></pre>
<p>In the month of launch I shipped a bit over a terrabyte of data. I’m glad I didn’t go with uncompressed JSON!</p>
<h3 id="toc:the-right-moves">The Right Moves</h3>
<p>A naive algorithm for distributing state to players in a multiplayer game is often quadratic. You accept moves from <code>N</code> players and distribute those moves to all <code>N</code> players - that’s <code>O(N^2)</code> <a>6</a>!</p>
<div data-is-footnote="true"><div><div><div><p><span>6</span></p><p>Forgive me - I’m playing it a little loose with N! Players may send moves at
different rates. But the number of moves your game receives per second
typically scales with the number of players, so this is true enough for our
purposes.</p></div></div></div></div>
<p>Doing <code>O(N^2)</code> work (and having <code>O(N^2)</code> bandwidth usage) is scary. To do better, we want to send users all <em>relevant</em> moves (moves that are close to them) without sending them every move that happens.</p>
<p>To do this, we divide our grid into <strong>zones</strong> - 50x50 groups of tiles. And we send clients moves that happen in a 3x3 box of zones centered on their current position.</p>
<p>Concretely, if a client is at <code>255, 285</code> their central zone is <code>5,5</code> and their 3x3 box spans from <code>4,4</code> to <code>6,6</code>.</p>
<div><p><img alt="A grid of 50x50 squares. A client in zone 5,5 also cares about zones 4,4 + 4,5 + 4,6 + 5,4 + 5,6 + 6,4 + 6,5 + 6,6" loading="lazy" width="2510" height="973" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-zone-grid.webp"/></p><p>a client cares about 22,500 tiles at all times</p></div>
<p>We put all clients that currently care about a zone in a set and store those sets in a 2D array.</p>
<p>After we’ve validated a move, we calculate the zones that it touches. A rook moving from <code>395, 200</code> to <code>405, 200</code> is moving from zone <code>7,4</code> to zone <code>8,4</code>. Then we find the clients tracking zones <code>7,4</code> or <code>8,4</code> and send them the move.</p>
<p><img alt="Each zone contains a set of clients that are tracking that zone" desc="looking up the clients that care about a zone is fast and easy" loading="lazy" width="2927" height="1481" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-a-zones-clients.webp"/></p>
<h3 id="toc:magic-numbers">Magic Numbers</h3>
<p>Why is a snapshot 95x95? Why do we send new snapshots if a client moves more than 12 tiles? Why is our zone size 50?</p>
<p>They’re all derived from the UI! I started with the fact that clients can’t see more than 35x35 tiles <a>7</a> and worked backwards. The math here isn’t super important, but you can expand the below section if you’re curious.</p>
<div data-is-footnote="true"><div><div><div><p><span>7</span></p><p>I chose 35x35 purely by feel.</p></div></div></div></div>
<details><summary><svg xmlns="http://www.w3.org/2000/svg" width="20px" height="20px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path><circle cx="12" cy="12" r="3"></circle></svg> <!-- -->Magic numbers details</summary><p>So clients can see up to 35x35 squares when zoomed in, and 70x70 squares when zoomed out (the exact number they see is dynamically calculated by their screen size).</p><p>When a player is zoomed out, panning or using the arrow keys changes the position by up to 10 tiles. A snapshot size of 95x95 is large enough that moving by 10 tiles in any direction will never require loading data as long as a player has an up-to-date snapshot.</p><div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-move-zoom-firstframe.png" width="994" height="560" preload="metadata" alt="One Million Chessboards gameplay. The user is zoomed out and moves up using the arrow keys, showing new pieces. They double-click on a cluster of pieces and zoom back in."><p>Loading...</p></video><p>moving while zoomed out moves by 5 to 10 tiles</p></div><p>A player’s view radius as extends a maximum of 35 tiles in each direction from some central point. Our snapshots extend in <code>95 / 2 = 47.5</code> tiles in each direction from the same point. This means that we should send a new snapshot if a player’s position changes by more than <code>47.5 - 35 = 12.5</code> tiles.</p><p>We want to send a client all <strong>relevant</strong> moves while minimizing the number of moves that we send them. We can say that a move is <strong>relevant</strong> if it would have been included in the client’s last snapshot. 50 is the smallest number that evenly divides 8000 (the size of our grid) while maintaining this property.</p></details>
<h3 id="toc:sending-data-once">Sending data once</h3>
<p>Some data - like the number of connected users - is the same for everyone.</p>
<p>We make heavy use of Cloudflare to cache this data instead of looping over every websocket connection to send it to each user individually.</p>
<div><p><img alt="Global data on OMCB - the minimap, player count, and pieces remaining, and number of moves made. Clients poll this via GET requests but most requests hit Cloudflare." loading="lazy" width="2871" height="2099" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-global-data.webp"/></p><p>thank you cloudflare</p></div>
<p>To do this:</p>
<ul>
<li>Every few seconds, our server computes new values for global data</li>
<li>Every few seconds, clients <em>poll</em> for new global data</li>
<li>Our server responds to those requests with a low <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Access-Control-Max-Age">max-age header</a></li>
<li>Cloudflare is configured to cache these responses based on their max-age</li>
</ul>
<p>This (totally free!) setup has offloaded hundreds of millions of requests from my server to Cloudflare, reducing the server’s workload and bandwidth usage.</p>
<h2 id="toc:state">State</h2>
<p>The board is stored as a 64 million (8000x8000) element array protected by a <code>RWMutex</code> (which allows many readers or one writer).</p>
<p>Each piece is represented as a <code>uint64</code>; the empty piece is <code>0</code>. The board is row-major; if there’s a piece at <code>200,300</code> that piece exists at <code>board[300][200]</code>.</p>
<pre><code><span><span>type</span> Board <span>struct</span> <span>{</span>
</span><span>	sync<span>.</span>RWMutex
</span><span>	pieces                                    <span>[</span><span>8000</span><span>]</span><span>[</span><span>8000</span><span>]</span><span>uint64</span>
</span><span>	rawRowsPool                               sync<span>.</span>Pool
</span><span>	seqNum                                    <span>uint64</span>
</span><span>	totalMoves                                atomic<span>.</span>Uint64
</span><span>  
</span><span><span>}</span>
</span></code></pre>
<p>We use our 64 bits to assign each piece a unique ID (which we need client side) and to track fun metadata like the number of times that a piece has moved. This metadata also allows us to do stuff like support <a href="https://en.wikipedia.org/wiki/En_passant">En Passant</a>.</p>
<pre><code><span>
</span><span><span>const</span> <span>(</span>
</span><span>    PieceIdShift                          <span>=</span> <span>0</span>  
</span><span>    
</span><span>    
</span><span>    PieceTypeShift                        <span>=</span> <span>25</span> 
</span><span>    IsWhiteShift                          <span>=</span> <span>29</span> 
</span><span>    JustDoubleMovedShift                  <span>=</span> <span>30</span> 
</span><span>    KingKillerShift                       <span>=</span> <span>31</span> 
</span><span>    KingPawnerShift                       <span>=</span> <span>32</span> 
</span><span>    QueenKillerShift                      <span>=</span> <span>33</span> 
</span><span>    QueenPawnerShift                      <span>=</span> <span>34</span> 
</span><span>    
</span><span>    AdoptedKillerShift                    <span>=</span> <span>35</span> 
</span><span>    HasCapturedPieceTypeOtherThanOwnShift <span>=</span> <span>36</span> 
</span><span>    AdoptedShift                          <span>=</span> <span>39</span> 
</span><span>    MoveCountShift                        <span>=</span> <span>40</span> 
</span><span>    CaptureCountShift                     <span>=</span> <span>52</span> 
</span><span><span>)</span>
</span></code></pre>
<p>Moves are fed into a go channel (roughly a threadsafe queue), where a single writer validates them (making sure they follow chess rules), applies them, and distributes them to the relevant clients.</p>
<p>When a client needs a snapshot they take a read lock, copy the relevant data, release the lock, and then do some post-processing before serializing and sending the snapshot.</p>
<p>The writer holds the write lock for about 500 nanoseconds. Readers hold the read lock for around 20 microseconds.</p>
<div><p><img alt="Workflows for movement and snapshots on one million chessboards. Both are run through a single mutex. Moves take about 500 nanoseconds and snapshots take about 19,000 nanoseconds." loading="lazy" width="3582" height="1905" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-board-interactions.webp"/></p><p>my napkin math for latency numbers was originally an order of magnitude high. oops.</p></div>
<p>Post-processing weeds out empty pieces so that we don’t serialize them. Since we want to minimize the amount of time we hold our read lock, it’s much faster to do this <em>after</em> releasing the lock - that way we only have to hold the lock for 95 copies instead of 9025 reads.</p>
<p>I picked this architecture because it is simple and easy to think about. It makes a few tradeoffs.</p>
<h3 id="toc:dense-not-sparse">Dense not Sparse</h3>
<p>We could store this data as a sparse map instead of a dense array. This would at least halve our memory usage - our board starts half empty!</p>
<p>But doing that would make it slower - or at least more complicated - to take snapshots. Right now a snapshot requires 95 copies of 95 sequential values. CPUs are very good at copying sequential values.</p>
<pre><code><span>
</span><span>preLock <span>:=</span> time<span>.</span><span>Now</span><span>(</span><span>)</span>
</span><span>b<span>.</span><span>RLock</span><span>(</span><span>)</span>
</span><span>seqnum <span>:=</span> b<span>.</span>seqNum
</span><span><span>for</span> y <span>:=</span> minY<span>;</span> y <span>&lt;=</span> maxY<span>;</span> y<span>++</span> <span>{</span>
</span><span>    <span>copy</span><span>(</span>pieces<span>[</span>y<span>-</span>minY<span>]</span><span>,</span> b<span>.</span>pieces<span>[</span>y<span>]</span><span>[</span>minX<span>:</span>maxX<span>+</span><span>1</span><span>]</span><span>)</span>
</span><span><span>}</span>
</span><span>b<span>.</span><span>RUnlock</span><span>(</span><span>)</span>
</span><span>lockTook <span>:=</span> time<span>.</span><span>Since</span><span>(</span>preLock<span>)</span><span>.</span><span>Nanoseconds</span><span>(</span><span>)</span>
</span></code></pre>
<p>64 million uint64s is 512 MB of memory. That’s not nothing, but it’s certainly within my server’s capabilities. I’m happy with the tradeoff here.</p>
<h3 id="toc:a-single-mutex">A single mutex</h3>
<p>Using a single mutex seemed a little scary. From profiling I didn’t think it was a bottleneck, but production traffic might expose pathological cases I didn’t test.</p>
<p>So I considered a row-based locking approach that would likely reduce contention at the cost of complexity (and a small hit to best-case speed).</p>
<p>But I don’t write a lot of lock-based code. I figured the number of deadlocks I added scaled with the number of locks I added.</p>
<p>I decided to ship the single-mutex approach but log lock-hold times for each move and snapshot (I fed the data into <a href="https://grafana.com/docs/loki/latest/">loki</a> via <a href="https://vector.dev/">vector</a>) <a>8</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>8</span></p><p>vector was <em>great</em>. It was super easy to install and set up. Loki was really
nice to use - I loved being able to treat it like a big greppable log file
when I wanted to - but the docs for setting it up were a little frustrating.
That said, I’m happy with this stack and will use it again.</p></div></div></div></div>
<pre><code><span>
</span><span>now <span>:=</span> time<span>.</span><span>Now</span><span>(</span><span>)</span> 
</span><span>b<span>.</span><span>Lock</span><span>(</span><span>)</span>
</span><span>b<span>.</span>pieces<span>[</span>move<span>.</span>FromY<span>]</span><span>[</span>move<span>.</span>FromX<span>]</span> <span>=</span> <span>uint64</span><span>(</span>EmptyEncodedPiece<span>)</span>
</span><span>b<span>.</span>pieces<span>[</span>move<span>.</span>ToY<span>]</span><span>[</span>move<span>.</span>ToX<span>]</span> <span>=</span> <span>uint64</span><span>(</span>movedPiece<span>.</span><span>Encode</span><span>(</span><span>)</span><span>)</span>
</span><span>b<span>.</span>seqNum<span>++</span>
</span><span>seqNum <span>:=</span> b<span>.</span>seqNum
</span><span>b<span>.</span><span>Unlock</span><span>(</span><span>)</span>
</span><span>took <span>:=</span> time<span>.</span><span>Since</span><span>(</span>now<span>)</span><span>.</span><span>Nanoseconds</span><span>(</span><span>)</span>
</span></code></pre>
<p>This meant that if the site was slow I could check my metrics, see whether lock times were much higher than I expected, and swap to row-based locking if needed.</p>
<p>The mutex was never a problem. I’m glad I did the simple thing.</p>
<h3 id="toc:bad-napkin-math">Bad napkin math</h3>
<p>When first speccing out the backend I did some awful math.</p>
<p>I wanted to estimate the amount of time it would take to get a 95x95 snapshot. <a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">Latency numbers every programmer should know</a> told me that a read from memory takes about 100ns.</p>
<p>Our snapshots have 9025 values. Multiplying that by 100ns told me it’d take almost a millisecond for a snapshot! That’s way too long to block the writer given that I thought we’d be read-heavy.</p>
<p>To speed things up I decided to fill the board with atomics - values that you can safely read and write across threads - so that I could read and write to the board concurrently.</p>
<p>I explained this plan to some <a href="https://github.com/eliothedeman">smart friends</a> and they told me it was bad.</p>
<div><p><img alt="messenger screenshot. Full text: &#39;Oh yeah you don&#39;t want atomics for that. You want sharded locks. like 1 mutex for each block.&#39;" loading="lazy" width="712" height="250" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/eliot-advice-1.webp"/></p><p>thanks eliot</p></div>
<p>There are several problems with my approach. But - simplifying a <em>lot</em> - the big one is that reading and writing lots of atomics in a tight loop is expensive. CPUs have caches and atomic operations exist in part to make sure those caches don’t serve up stale values.</p>
<p>That involves telling each core “hey, make sure that you don’t have a stale value cached for this memory location.” And doing that in a tight loop for a lot of values is a lot of work. That work would eat into much (or all!) of the benefit I got from concurrency.</p>
<p>As I tried to figure out what to do I realized that my napkin math was way off.</p>
<div><p><img alt="Reading sequential values is faster than reading scattered values" loading="lazy" width="2674" height="1580" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/sequential-good.webp"/></p><p>sequential good scattered bad</p></div>
<p>My snapshot isn’t 9025 arbitrary values - it’s 95 groups of 95 sequential values! And copying sequential values is really fast. I redid my math and realized that my snapshots were <em>at least</em> an order of magnitude faster than I had calculated. And so I moved to the single-mutex approach.</p>
<p>This would have been obvious to me if I spent more time thinking about performance. But it wasn’t.</p>
<p>That’s ok though. Learning by doing is the best way to learn. It’ll be obvious next time :)</p>
<h3 id="toc:serialization">Serialization</h3>
<p>Since we’re not using a database, we need a way to persist our state to disk.</p>
<p>The naive solution here would be to take a read lock for the entire board, then read in every value and write it to disk. But that takes time - at least a second or two - and during that time players wouldn’t be able to make new moves.</p>
<p>To avoid that multi-second lockup we duplicate the whole board!</p>
<div><p><img alt="The OMCB board feeds validated moves to a copy of itself. A timer occasionally tells that copy to serialize state to disk, which it does atomically." loading="lazy" width="2819" height="1634" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-serialization.webp"/></p><p>nice and simple (?)</p></div>
<p>After moves are validated, they’re re-applied to a copy of the board. We occasionally freeze <em>that</em> board and atomically <a>9</a> write it to disk. A cron job ferries old snapshots to another VM for archival.</p>
<div data-is-footnote="true"><div><div><div><p><span>9</span></p><p>“Atomically” here means “write the data to a temporary file, move that file to
its final location after the write, and then call fsync.” Disks are full of
Deep Magic and I suspect that I have not accounted for every possible failure
mode here, but this is good enough for my purposes.</p></div></div></div></div>
<p>This prevents lockups unless the work queue for our copy fills up. The work queue is very large and serialization is infrequent so this isn’t a major concern.</p>
<p>We make sure to write out our state when the server shuts down so that we don’t lose any moves.</p>
<h2 id="toc:rollback">Rollback</h2>
<p>Here are two clients. On one client moves happen immediately. On the other they happen after 250ms <a>10</a>.</p>
<p>(hit the compare button to play both videos at the same time)</p>
<div data-is-footnote="true"><div><div><div><p><span>10</span></p><p>I think this is a reasonable estimate for round-trip latency for a
WiFi-connected client that’s far from my server.</p></div></div></div></div>

<!-- -->

<p>A delay of 250ms isn’t unplayable,but it’s not great. The delay also compounds; it gets more annoying as you try to move the same piece several times. Waiting 0ms feels much better.</p>
<p>To achieve 0ms wait times we apply moves <em>optimistically</em> and <em>immediately</em> - pieces move on the client before we hear back from the server at all. Folks often call this “rollback” or “rollback netcode.”</p>
<p>To do this, we separate our <strong>ground truth</strong> - actual updates from the server - from our <strong>optimistically-tracked state</strong> - moves we think we’ve made but haven’t heard back from the server about.</p>
<p>When our piece display renders a piece, it checks our optimistic state before referencing the ground truth.</p>
<p><img alt="one million chessboards rendering checks optimistic state before the ground truth" loading="lazy" width="2131" height="1070" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-optimistic-state.webp"/></p>
<p>When we make a move, we give the server a “move token” that identifies it.</p>
<p>The server passes back that move token when accepting or rejecting a move. When it accepts a move, it also tells us the piece ID (if any) that we captured, since in some cases we may unintentionally capture a piece.</p>
<p><img alt="server messages contain a move token and, if the move was valid, the id of the the captured piece" loading="lazy" width="1413" height="641" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-messages.webp"/></p>
<p>When we receive a rejection from the server we revert our move.</p>
<h3 id="toc:but-wait">But wait!</h3>
<p><em>Just</em> relying on server rejections can put the board into an invalid state.</p>
<p>For example, here two players move different rooks to the same position (I’ll call the left client A and the right client B). A moves before B, so B learns of A’s move <em>before</em> it receives a server rejection message for its own move.</p>
<p>B rolls back its own move as soon as it learns of A’s move. If it didn’t do this - if B waited for a rejection - we’d briefly have two rooks occupying the same square.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-simple-firstframe.png" width="926" height="522" preload="metadata" alt="Two rooks move to the same square. One rook&#39;s move is undone."><p>Loading...</p></video><p>two rooks try to occupy the same square</p></div>
<p>This can get complicated because moves can depend on each other. For example, what if you move a knight and then move a rook to where that knight was, but it turns out that the knight’s move wasn’t valid? We need to roll back <em>both</em> moves!</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-2pieces-firstframe.png" width="926" height="522" preload="metadata" alt="A knight moves out of the way so that a rook can move to where it was. Both the knight and the rook&#39;s move are reversed."><p>Loading...</p></video><p>looks like we&#39;ve got ourselves a dependency graph.</p></div>
<h3 id="toc:edge-cases">Edge cases</h3>
<p>There’s more complexity lurking here than I first realized. Much of that complexity comes from precisely defining what is (and isn’t) a conflict when processing moves client side.</p>
<p>If two pieces of the same color occupy the same square, we <em>always</em> have a conflict and need to roll back.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-reverse-castle-firstframe.webp" width="766" height="430" preload="metadata" alt="A bishop moves, allowing white to castle kingside. The bishop move and the castle are reverted when a conflict is detected with the bishop&#39;s move."><p>Loading...</p></video><p>I love watching the castle undo itself</p></div>
<p>But if two pieces of <em>different</em> colors occupy the same square we might not have a conflict - like here, where we move our bishop to a square and then realize that there was a black rook on that square. Instead of rolling back, we decide that we <em>probably</em> captured the rook.</p>

<p>Some moves - castling, advancing a pawn - aren’t allowed to capture a piece. So in that case we <em>do</em> need to roll back if we end up occupying the same square as a piece of the opposite color.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-castle-firstframe.webp" width="766" height="430" preload="metadata" alt="A black rook moves onto the back rank of white. White tries to castle, but the move is undone because the rook is in the way."><p>Loading...</p></video><p>look, I still love watching the castle undo itself</p></div>
<p>Relatedly, we might <em>think</em> we captured a piece and then learn that the piece actually moved out of the way. Most of the time this is fine and we just re-add the piece to the board:</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-uncapture-firstframe.webp" width="684" height="386" preload="metadata" alt="A queen captures another queen that has actually moved out of the way. The queen re-appears after being captured."><p>Loading...</p></video><p>realizing that I needed to handle this was annoying</p></div>
<p>But that’s not true for pawns, since pawns can <em>only</em> move diagonally when they’re capturing another piece. If we failed to capture that piece, we need to roll back!</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-revert-pawn-firstframe.webp" width="684" height="386" preload="metadata" alt="A pawn captures a queen which has actually moved out of the way. The move is undone."><p>Loading...</p></video><p>This is particularly annoying because it&#39;s just for pawns!</p></div>
<h3 id="toc:actually-rolling-back">Actually rolling back</h3>
<p>Once we’ve detect a conflict, we roll back all moves <em>related</em> to that conflict. We say two moves are related if they touch the same squares or the same pieces. We track related moves with a dependency graph.</p>
<p>Here’s what that might look like if we move a rook out of the way, then move a knight to the square we vacated, then move that knight again.</p>
<p><img alt="a sequence of rook and knight moves" loading="lazy" width="1364" height="815" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-graphs1.webp"/></p>
<p>There’s a dependency here - without moving our rook out of the way we can’t move the knight to the square that it vacated! We merge dependency graphs when they touch the same squares.</p>
<p><img alt="the rook and knight moves merge into a single dependency graph" loading="lazy" width="2043" height="813" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-graph2.webp"/></p>
<p>If we detect a conflict or receive a rejection, we unwind all moves in that merged graph. This is a little too aggressive - here our knight moves depend on our rook, but not vice-versa - but it simplifies the code substantially and works well enough in practice.</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/omcb-rollback-forgraph-firstframe.webp" width="250" height="250" preload="metadata" alt="A rook moves, allowing a knight to take its spot. Both moves are reverted."><p>Loading...</p></video><p>rolling back our graph</p></div>
<p>And as moves are confirmed, we remove them from the graph since we don’t need to unwind them anymore!</p>
<p><img alt="As moves are confirmed, they&#39;re removed from the dependency graph" loading="lazy" width="2043" height="813" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-graphs3.webp"/></p>
<p>There’s a little more detail here. For eaxmple, each move (and server ack/reject) comes with a sequence number to prevent ambiguity about which move happened last. But that’s the gist.</p>
<h3 id="toc:this-was-really-hard">This was really hard</h3>
<p>Now that I understand how to think about rollback it doesn’t seem that hard. But in the moment I found it <em>extremely</em> challenging <a>11</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>11</span></p><p>When I first sat down to add rollback, I made a cup of coffee at 9 PM and
figured I’d program till I solved it. At around 4 AM I realized I needed to
throw everything I’d done. I did the same thing (and failed again) the next
night, which is around the time I realized I needed to think a little harder
before starting to code.</p></div></div></div></div>
<p>I think that’s true of many of my favorite problems. The real challenge is taking a step back, precisely understanding your desired behavior, and forming a good mental model of the domain.</p>
<h2 id="toc:profiling-wins-and-costs">Profiling, wins, and costs</h2>
<p>One Million Chessboards is the first game that I’ve profiled in a meaningful way before shipping. Writing in golang made this all pretty easy!</p>
<p>I wrote a few scripts that spun up hundreds of clients, requested lots of snapshots, and slammed a million moves through the server as fast as possible <a>12</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>12</span></p><p>For simplicity these clients only move pawns, since pawns are easy to move in
valid ways from an empty board</p></div></div></div></div>
<p>This was far from perfect - for example, I suspect that my profiling was more write-heavy that my actual traffic.</p>
<p>But it was good enough to use <a href="https://jvns.ca/blog/2017/09/24/profiling-go-with-pprof/">go’s excellent profiling tools</a> to look at what in my code was slow and catch regressions I would have otherwise missed.</p>
<p>It also made it very easy to measure my bandwidth usage by just having my clients count the number of bytes that they received!</p>
<pre><code><span>
</span><span>
</span><span><span>_</span><span>,</span> message<span>,</span> err <span>:=</span> ws<span>.</span><span>ReadMessage</span><span>(</span><span>)</span>
</span><span><span>if</span> err <span>!=</span> <span>nil</span> <span>{</span>
</span><span>    <span>goto</span> restart
</span><span><span>}</span>
</span><span>c<span>.</span>receivedBytes<span>.</span><span>Add</span><span>(</span><span>int64</span><span>(</span><span>len</span><span>(</span>message<span>)</span><span>)</span><span>)</span>
</span></code></pre>
<h3 id="toc:go-was-a-win">Go was a win</h3>
<p>My multiplayer games involve giving the whole internet concurrent read-write access (with a few rules) to a chunk of memory on a single computer.</p>
<p>I found golang to be <em>perfect</em> for this - it’s a quick language designed for concurrency that lets me reason about how memory will be laid out. I’ll be using it going forward for games like this.</p>
<p>Go is also a <em>dumb</em> language. I found myself missing the power of OCaml - the language I know best.</p>
<p>But that simplicify was also a boon. It pushed me to do everything with big arrays protected by mutexes. And it turns out you can go pretty far with big arrays protected by mutexes.</p>
<h3 id="toc:costs">Costs</h3>
<p>One Million Chessboards runs on a single Digital Ocean “CPU-optimized” box.</p>
<p>The night before launch I upgraded it to run on a 16-core “premium intel” box (~$450/month). I knew this was <em>probably</em> overkill, but I really didn’t want to deal with scaling up on launch day.</p>
<p>And it was <em>massive</em> overkill; I’m not sure I ever hit double-digit CPU usage. I’ve shrunk the box substantially (~$80/month) and I suspect I could keep going.</p>
<div><p><img alt="htop output on the one million chessboards box; CPU usage is very low." loading="lazy" width="2910" height="484" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/omcb-htop.webp"/></p><p>lol</p></div>
<p>Because my protocol optimizations keep my bandwidth usage low, this server (and my small metrics vm) are my only costs. I’ll end up spending a few hundred dollars on the project depending on how long I choose to run it in its current state.</p>
<p>Several folks have <a href="https://buymeacoffee.com/eieio">sent me donations</a> (thank you!). And my costs are <em>more than</em> covered by tech entrepreneur / youtuber <a href="https://t3.gg/">Theo</a>, who sent in a $500 donation on launch day. Thank you very much Theo :)</p>
<h2 id="toc:was-this-game-good">Was this game good?</h2>
<p>I’m proud of One Million Chessboards.. But I think I made some mistakes.</p>
<p>Folks were confused about being assigned to a single color, and the UI didn’t explain this behavior super well. Cross-board capturing was also confusing to folks, although I think some people enjoyed figuring out the rules through trial and error.</p>
<p>More generally, the game’s differences from standard chess <a href="https://www.reddit.com/r/chess/comments/1ka38w5/one_million_chessboards/">turned off some chess players</a> more than I expected - here’s a comment from the chess subreddit:</p>
<div><p><img alt="User1: Really weird… seems to be permanently black’s move and you can move pieces across boards!
User2: Yes it looks like you are assigned either black or white when you join the board, if you&#39;re black all the black pieces are your domain, and vice versa
User1: Thanks for clarifying. This is weird. I don’t like it. I DONT LIKE IT. 🤮🤢
" loading="lazy" width="1792" height="502" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/i-dont-like-it.webp"/></p><p>they don&#39;t like it</p></div>
<p>I’m not sure what to make of this. Maybe the game needed a tutorial or a “what is this” button?</p>
<h3 id="toc:trying-too-hard-to-impress">Trying too hard to impress</h3>
<p>Someone left this comment on Hacker News:</p>
<div><p><img alt="&gt; You can move between boards.
Evidently move between boards but not capture between boards :-( It&#39;s extra weird because it&#39;s not that the movement isn&#39;t projected (e.g. queen blue lines all point correctly across board boundaries just the lines always stop at every piece on the other board, regardless of color)
So, I guess as an exercise in scale, well done! As one million chess boards, caveat gamator
" loading="lazy" width="1028" height="380" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/caveat.webp"/></p><p>caveat gameator</p></div>
<p>While I don’t agree with all of this comment I think there’s some truth to the game being an exercise in scale.</p>
<p>I was focused on building another <a href="https://onemillioncheckboxes.com">one million-style game</a>. I was excited about this project because I wanted to push myself, to demonstrate that this game <em>could</em> be built in a single process, and to demonstrate that I was capable of building it.</p>
<p>I think that lead me to design decisions that existed to support the scale of the game, instead of design decisions that existed to make the game fun.</p>
<h3 id="toc:a-lack-of-awe">A lack of awe</h3>
<p>I realized my biggest mistake when I tried to record footage.</p>
<p>Multiplayer games have a cold-start problem; they aren’t fun when you’re the only one there. To deal with this for One Million Chessboards, I use reservoir sampling (which I learned about from my friend Sam’s <a href="https://samwho.dev/reservoir-sampling/">phenomenal blog post</a> <a>13</a>) to place new players next to someone who has made moves within the last few seconds - that way there’s some activity when you join.</p>
<div data-is-footnote="true"><div><div><div><p><span>13</span></p><p>Sam sent me a draft of his blog on the same day that I sent him a draft of my
game - absolutely perfect timing.</p></div></div></div></div>
<p>This did a good job of forming clusters of players; you typically see <em>some</em> activity upon loading the site. But because I tuned my position assignment to form small clusters, the game failed to have the awe-inspiring “wow, there are so many people here” moment that I wanted.</p>
<p>With One Million Checkboxes, everyone started in the same place. That meant that even early on the top few rows of checkboxes looked crazy, which I think drew people in. It’s cool to interact with strangers on the internet!</p>
<div><video controls="" playsinline="" poster="/images/a-million-realtime-chess-boards-in-a-single-process/../scaling-one-million-checkboxes/30mins-activity-firstframe.png" width="2926" height="1646" preload="metadata" alt="Activity on OMCB 30 minutes after launch. Checkboxes are being checked and unchecked constantly."><p>Loading...</p></video><p>One Million Checkboxes, 30 minutes in</p></div>
<p>I wasn’t able to record similar footage for One Million Chessboards; even with a thousand players online it didn’t <em>feel</em> like there were lots of people on the site.</p>
<p>I don’t know how to fix this. Because boards empty out over time, I couldn’t put everyone in the same starting position <a>14</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>14</span></p><p>Well I could, but that starting spot would quickly become empty! Varying the
default starting location over time might work, but I suspect there’s some
kind of issue with that choice in practice.</p></div></div></div></div>
<p>But I’ve learned a really valuable lesson!</p>
<p>My favorite way to learn is to identify a totally new thing that I can think about as a first-class problem.</p>
<p>Prior to One Million Chessboards I knew I had to think about the multiplayer cold-start problem. I tried to address that by building up an audience so that my games would have some players at launch <a>15</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>15</span></p><p>Way back when I made <a href="https://eieio.games/blog/stranger-video">stranger video</a> I solved this
issue by spending 8 hours straight on the site on launch day so that people
had someone to play against!</p></div></div></div></div>
<p>But now I know that conveying a game’s scale <em>immediately</em> when you load in is critical, and that telling folks “there are 1,000 players online” isn’t enough. Knowing that will make my next massively multiplayer game better.</p>
<h2 id="toc:wrapping-up">Wrapping up</h2>
<p>Thank you to my friends Won Chun, <a href="https://x.com/freemanjiangg">Freeman Jiang</a>, and <a href="https://github.com/eliothedeman">Eliot</a> for their help building this; my go would have been worse and my site substantially slower without your help.</p>
<p>And thank you to the <a href="https://www.recurse.com/">Recurse Center</a> - I built this site and wrote this blog at Recurse. Recurse is the best place I know of to build sites like this (or to learn how to build sites like this!) - if that sounds fun to you you should <a href="https://www.recurse.com/apply">apply</a>.</p>
<h3 id="toc:fear-of-trying">Fear of trying</h3>
<p>I have made many of my <a href="https://eieio.games/blog/writing-down-every-uuid/">most popular</a> <a href="https://eieio.games/blog/one-million-checkboxes/">projects</a> in 2-4 days. This project took 15 times longer. That <em>terrified</em> me.</p>
<p>Last year, after the heights of One Million Checkboxes, I released a game called <a href="https://eieio.games/blog/paccam">PacCam</a>. I worked on it for an embarrasingly long time and had high hopes; I thought after One Million Checkboxes folks would pay attention to my next game.</p>
<p>Instead it was a flop; it got less traction than many of the things I made <em>before</em> I found an audience with One Million Checkboxes. And that crushed me - it made me want to stop making games.</p>
<p>Now I can look back on PacCam and see all sorts of problems. But in the moment the experience pushed me towards very short projects - things I could make in a week or less. Plenty of those projects went well (great!) and I wasn’t super attached to the ones that went poorly since I made them quickly.</p>
<p>But I knew I couldn’t make One Million Chessboards the way that I wanted to in a week. I wanted it to be <em>great</em> - not just a prototype - on release. I wanted to learn from my mistakes, to make something fast, to surprise and delight and wow people. And to show that I could do it.</p>
<p>So I chose to push through that fear, pour myself into the project, and hope for the best. When I finished I wasn’t sure what I needed to call the project a success.</p>
<p>One feature I added to One Million Chessboards was piece achievements. Some were simple, like an achievement for capturing a king. But some were harder to find.</p>
<p>A few days in, Ali found the trickiest achievement - a piece is granted “self-hating” if it captures a lot of pieces of its own kind and no other pieces.</p>
<div><p><img alt="A rook on One Million Chessboards with the title &#39;self-hating.&#39; Image also contains a screenshot of a bluesky post that says &#39;To whomever was filling entire boards with matching white pieces. You put up a noble fight but I have to say it felt good wiping the board clear.
Chuckled when my rook gained the title self-hating after clearing numerous rooks.&#39;" loading="lazy" width="1186" height="836" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/self-hating.webp"/></p><p>those poor Rooks</p></div>
<p>This wasn’t my biggest hidden feature, and it was far from the hardest one to add (that’d be rollback!).
But it wasn’t something that I <em>needed</em> to add - I’d guess under 0.1% of players ever saw it.</p>
<p>Ali noticed that - and told me that it was in that moment that they thought ‘I think this game was made with love!’</p>
<div><p><img alt="Nolen: oh man i&#39;m delighted someone found that achievement i wasn&#39;t sure if anyone would see it!
Ali: It was at that moment I went &#39;I think this game was made with love!&#39;" loading="lazy" width="1186" height="704" decoding="async" data-nimg="1" src="https://eieio.games/images/a-million-realtime-chess-boards-in-a-single-process/made-with-love.webp"/></p><p>❤️</p></div>
<p>I don’t think I can ask for anything more.</p>
<p>More high-effort (and low-effort) games soon.</p></article></div>
  </body>
</html>
