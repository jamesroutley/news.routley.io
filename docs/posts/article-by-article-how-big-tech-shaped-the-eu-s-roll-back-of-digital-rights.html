<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://corporateeurope.org/en/2026/01/article-article-how-big-tech-shaped-eus-roll-back-digital-rights">Original</a>
    <h1>Article by article, how Big Tech shaped the EU&#39;s roll-back of digital rights</h1>
    
    <div id="readability-page-1" class="page"><div role="main">
    <a id="main-content" tabindex="-1"></a>

    <section id="content">
        <div>
    


<div id="block-entityviewcontent">
  
    
      <div>

  

  <div>
  
      <div>

  

  <p><img loading="lazy" src="https://hamy.xyz/sites/default/files/styles/image_l/public/2026-01/IMG_0198%281%29.jpeg?itok=mF_GNG30" width="800" height="533" alt="Action in November against the Digital Omnibus"/>



  </p>


</div>


  </div>


</div>


  </div>







<div id="block-mainpagecontent">
  
    
      <div>

  

  

      
  
            <p id="docs-internal-guid-8d970413-7fff-a660-cab2-d5a54af12fbd" dir="ltr">In a new analysis by Corporate Europe Observatory and LobbyControl, we trace Big Tech&#39;s fingerprints on the Digital Omnibus proposals - a major deregulation of EU digital laws including the GDPR and the AI Act. They are helped in this attempt by the Trump administration and the European far right.</p>
      
      <div>
              <div>  <div>
          
            <div><p id="docs-internal-guid-baf45d50-7fff-fae2-9151-ff9c7515bb69" dir="ltr">At the end of November 2025, Ursula von der Leyen gave Trump and his tech oligarchs an early Christmas present: an unprecedented attack on digital rights. In its so-called Digital Omnibus, the European Commission proposed weakening important rules designed to protect us from Big Tech’s abuses of power.</p>
<p dir="ltr">These are the protections that keep everyone&#39;s data safe, governments and companies accountable, protect people from having artificial intelligence (AI) systems decide their life opportunities, and ultimately keep our societies free from unchecked surveillance.</p>
<p dir="ltr">At the same time, the Digital Omnibus is part of the European Commission&#39;s <a href="https://corporateeurope.org/en/deregulation-watch">deregulation agenda</a>, which threatens key social and environmental standards in Europe. Ironically this deregulation agenda is being promoted by the Commission as a way to make the EU &#39;competitive&#39; – despite in reality actively empowering US Big Tech companies that dominate the field.</p>
<p dir="ltr">The Digital Omnibus was immediately <a href="https://noyb.eu/en/digital-omnibus-eu-commission-wants-wreck-core-gdpr-principles">heavily</a> <a href="https://edri.org/our-work/europe-is-dismantling-its-digital-rights-from-within/">criticised</a> by <a href="https://www.amnesty.org/en/latest/news/2025/11/eu-digital-omnibus-proposals-will-tear-apart-accountability-on-digital-rights/">numerous</a> <a href="https://www.beuc.eu/press-release/eus-plan-simplify-digital-laws-benefit-mainly-large-companies-expense-consumers">civil</a> society organisations. <a href="https://www.politico.eu/article/brussels-police-world-digital-tech-us-china-regulations/">Politico</a> even called it the end of the ‘Brussels effect’ – that is, that European tech regulations are adopted in other countries – and wrote that “Washington is [now] setting the pace on deregulation in Europe.”</p>
<p dir="ltr">To show the extent of Big Tech’s influence on the Digital Omnibus, we compared the Commission’s proposals with the lobbying positions from Big Tech and its associations. </p>
<p dir="ltr">The proposals in the Digital Omnibus concern both data protection and rules for AI. While the EU mistakenly speaks of benefits for European corporations, it is clear that weak digital rules strengthen the power of Google, Microsoft, Meta etc, thereby jeopardising the goal of becoming more independent from Big Tech and the US. </p>
<p dir="ltr">In the past, Big Tech has repeatedly spread the one-sided lobbying message that data protection hinders economic growth and innovation, <a href="https://euneedsai.com/">especially</a> with regard to AI. This includes exceptions for SMEs and a fundamental focus on making <a href="https://www.lobbyregister.bundestag.de/media/2f/ca/502331/Stellungnahme-Gutachten-SG2503310295.pdf">more use of data</a> instead of protecting it.</p>
<p dir="ltr">Tech companies are spreading these messages with a record-breaking lobbying budget, a huge lobbying network, and support from the Trump administration. The digital industry’s annual lobby spending has grown from <a href="https://corporateeurope.org/en/2025/10/big-tech-lobby-budgets-hit-record-levels">€113 million in 2023 to €151 million today</a> – an increase of 33.6 percent in just two years.</p>
<p dir="ltr">Now, the European Commission appears to be bowing to this lobbying pressure and adopting key lobbying messages from Google, Microsoft, Meta and their many lobby organisations in its Digital Omnibus. </p>
<p dir="ltr">Here we break down these industry lobbying messages, how they have been adopted by the Commission as proposed text changes, and what the real world impacts could be.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h2 id="docs-internal-guid-8c742d9c-7fff-2d73-6bd2-abdc2b2f3b0b">How the Commission aims to weaken the GDPR and ePrivacy</h2>
<p>The General Data Protection Regulation (GDPR) is the backbone of the EU’s digital rulebook. While the Commission <a href="https://ec.europa.eu/commission/presscorner/detail/fr/speech_25_2732">claims</a> it is only giving the GDPR a “face-lift”, its proposed changes -  from the definition of personal data to the use of data for training AI - will have far-reaching consequences to people’s rights, and will benefit Big Tech’s problematic business model based on massive data extraction.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-9e92ada9-7fff-22f1-9b6c-122a6665ff03">Limiting the definition of personal data </h3>
<p dir="ltr">The Commission intends to stop classifying pseudonymised data (ie swapping out a user&#39;s identifiable name for a code or number) as personal data if a company claims it cannot identify a person, thereby exempting it from GDPR protection. This rule would also apply even when other actors ( for instance data brokers) can still identify individuals based on the pseudonymised data.</p>
<p dir="ltr">As the digital rights organisations <a href="https://noyb.eu/en/digital-omnibus-eu-commission-wants-wreck-core-gdpr-principles">Noyb</a> and <a href="https://edri.org/our-work/commissions-digital-omnibus-is-a-major-rollback-of-eu-digital-protections/">EDRi</a> have pointed out, this change turns a universal rule into a subjective one. GDPR protections will only apply when a company has the means to identify a person based on the data it holds. This gives huge leeway to companies to decide not to apply the GDPR arguing that they can’t identify a person. Worse, data can be sold to other companies or data brokers that do have the means to re-identify individuals. </p>
<p dir="ltr">But even if data is never sold or passed on to third parties, the proposed subjective approach would still severely narrow the scope of the GDPR. Big Tech companies such as Meta and Google for instance could use personal data for online tracking by claiming that the data cannot be traced back to a natural person and is therefore not covered by the GDPR.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div>
<dl>
<dt><strong>Digital Omnibus</strong></dt>
<dd>
<p dir="ltr"><strong>Proposed changed text to article 4(1) of the GDPR in the digital omnibus in italics:</strong> “Information relating to a natural person is not necessarily personal data for every other person or entity, merely because another entity can identify that natural person. </p>
<p dir="ltr"><em>Information shall not be personal for a given entity where that entity cannot identify the natural person to whom the information relates, taking into account the means reasonably likely to be used by that entity. Such information does not become personal for that entity merely because a potential subsequent recipient has means reasonably likely to be used to identify the natural person to whom the information relates.</em></p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position  </dt>
<dd>
<p id="docs-internal-guid-faedc10c-7fff-a82e-6b7c-f7f0c86a1bc4" dir="ltr">This move closely reflects Big Tech&#39;s lobby position. The industry  has long been calling for greater commercial use of personal data. The use of anonymous and pseudonymous data in particular would contribute to this.</p>
<p dir="ltr"><strong>DigitalEurope</strong>, (which counts all Big Tech companies among its members), <a href="https://corporateeurope.org/sites/default/files/2026-01/DigitalEurope%20lobby%20paper.pdf">wrote</a>: “Clarify that pseudonymised data is not personal data when recipients cannot reasonably re-identify individuals.”</p>
<p dir="ltr"><strong>Microsoft Germany</strong> also <a href="https://www.lobbyregister.bundestag.de/media/92/8d/322766/Stellungnahme-Gutachten-SG2406280060.pdf">lobbied</a> for weakening the definition along similar lines.</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-20d6b5a7-7fff-42d2-a79e-520cb267b9e1">Limiting your right to access your own data </h3>
<p dir="ltr"><strong>Summary: </strong>Currently, anyone can request a copy of their personal data from any company or organisation that holds it. However, the Commission intends to limit this right if a person ‘abuses’ it.</p>
<p dir="ltr">This will severely limit the rights of individuals to know which of their data is being held by Big Tech. For instance, <a href="https://www.workerinfoexchange.org/post/historic-digital-rights-win-for-wie-and-the-adcu-over-uber-and-ola-at-amsterdam-court-of-appeal">in 2023 Uber and Ola drivers who were ‘robo-fired’ won a court case</a> against the company after it refused access to their work-related information. Ola tried to argue that the drivers requests for data amounted to an abuse of data protection rights, an excuse that the Commission now wants to give a legal basis.</p>
<p dir="ltr">This will make it harder to hold Big Tech to account and to contest their unlawful practices. “The proposal threatens to dismantle a tool of counter-power”, as the academic René Mahieu <a href="https://verfassungsblog.de/digital-omnibus-right-of-access-to-personal-data/">writes</a>. </p>
<p dir="ltr">Contrary to the claims made by industry, and adopted by the German Government, it is not citizens who have ‘abused’ their right to access their own data, but tech companies that have disregarded this right. According to the privacy organisation NOYB<a href="https://noyb.eu/sites/default/files/2025-12/noyb%20Digital%20Omnibus%20Report%20V1.pdf"> 90 percent of data access requests are not respected</a>. In one case, it took <a href="https://noyb.eu/en/noyb-win-youtube-ordered-honour-users-right-access">more than five years </a>for Youtube to respect a particular data access request.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p dir="ltr"><strong>Proposed changed text to article 12(5) of the GDPR in the digital omnibus in italics: “</strong>Where requests from a data subject are manifestly unfounded or excessive, in particular because of their repetitive character <em>or also, for requests under Article 15 because the data subject abuses the rights conferred by this regulation for purposes other than the protection of their data</em>, the controller may either: a) charge a reasonable fee [...] or refuse to act on the request.</p>
<p dir="ltr">The controller shall bear the burden of demonstrating <em>that</em> the <em>request is</em> manifestly unfounded <em>or that there are reasonable grounds to believe that it is excessive</em>.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt><strong>Big Tech’s lobby position  </strong></dt>
<dd>
<p dir="ltr"><strong>The German Government lobbied for this change </strong>in an <a href="https://noyb.eu/sites/default/files/2025-11/German%20Proposal%20for%20simplification%20of%20the%20GDPR.pdf">influential but controversial position paper</a>. What has largely gone under the radar, however, is that these proposals were actually <a href="https://www.lobbycontrol.de/pressemitteilung/digitalgipfel-weniger-datenschutz-mehr-macht-fuer-big-tech-123225/">pushed</a> by Big Tech companies.</p>
<p dir="ltr">In a <a href="https://www.lobbyregister.bundestag.de/inhalte-der-interessenvertretung/stellungnahmengutachtensuche/SG2510270013">lobby paper</a> dated 16 August 2025, <strong>Google</strong> called on the German Government to &#34;Introduce a ‘disproportionate efforts’ exemption to compliance with Articles 15-22 GDPR&#34;. With regard to Article 12(5), Google proposed the following addition highlighted in bold: </p>
<p dir="ltr">“Where requests from a data subject are manifestly unfounded or excessive, in particular because of their repetitive character, <strong>or, taking into account the scope of the processing and the cost of implementation, where responding to the request would involve a disproportionate effort</strong>, the controller may either: (a) charge a reasonable fee taking into account the administrative costs of providing the information or communication or taking the action requested; or (b) refuse to act on the request.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-0be98fd3-7fff-5dd0-ab4d-99f12b489c19"><strong>Using your personal data for training AI</strong></h3>
<p dir="ltr">Generative AI models are being trained on enormous amounts of data. The Commission intends to permit the training of AI models with personal data, including highly sensitive data such as sexuality, political beliefs, or ethnicity, without active consent. People’s data will only be protected from being used for training AI models if they explicitly opt-out.</p>
<p dir="ltr">Tech companies can basically hoover up any personal data on the internet to train their AI models without active consent (opt-out would still be possible). The protection of sensitive data for training AI such as political beliefs, union membership or sexuality is also weakened.</p>
<p dir="ltr">There is a risk of ‘data leakage’ whereby AI systems reproduce the personal data it has been trained on or produce fake information. In one such case a journalist was<a href="https://www.abc.net.au/news/2024-11-04/ai-artificial-intelligence-hallucinations-defamation-chatgpt/104518612"> falsely accused by a Microsoft chatbot of child abuse</a> when in fact he had just published articles on criminal court cases about it. The AI system, in essence a statistical programme, had conflated this information and had made him out to be a criminal.</p>
<p dir="ltr">Major tech companies such as Meta, Google and X stand to benefit as they can train their AI models with massive troves of personal data collected through their platforms. </p>
<p dir="ltr">Big Tech companies are spending enormous amounts, <a href="https://www.cnbc.com/2025/10/31/big-tech-ai-spending-billions-microsoft-google-software-subscriptions.html">possibly as much as US$550 billion in 2026</a>, to dominate the AI market. Loosening rules on AI data collection plays directly into their hands.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-3b899312-7fff-49a3-e7a2-3628b41a1914" dir="ltr"><strong>Proposed text: </strong></p>
<ul>
<li dir="ltr"><strong>The digital omnibus introduces a new article 88c in the GDPR introducing the use of personal data for AI training as a legitimate interest</strong>: <em>“Where the processing of personal data is necessary for the interests of the controller in the context of the development and operation of an AI system such processing may be pursued for legitimate interests within the meaning of Article 6(1)(f)”</em></li>
<li dir="ltr"><strong>The digital omnibus also waters down protections on using sensitive data for AI training by introducing article 9(5) to the GDPR</strong>:<em> “For processing referred to in point (k) of paragraph 2, appropriate organisational and technical measures shall be implemented to avoid the collection and otherwise processing of special categories of personal data. Where, despite the implementation of such measures, the controller identifies special categories of personal data in the datasets used for training, testing or validation or in the AI system or AI model, the controller shall remove such data. If removal of those data requires disproportionate effort, the controller shall in any event effectively protect without undue delay such data from being used to produce outputs, from being disclosed or otherwise made available to third parties.”</em></li>
</ul>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-3eeab578-7fff-3789-9ae3-187d8abc0314" dir="ltr">This has been a top priority of Big Tech lobbying. Almost every trade association and company has lobbied both the Commission and member states on that topic.</p>
<p dir="ltr">Big Tech lobby organisation<strong> </strong><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “It is crucial to reaffirm the role of legitimate interest as a lawful basis under the GDPR for responsible AI innovation, moving beyond the non-binding EDPB opinion to provide harmonised legal certainty for AI training.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Reinforce the use of ‘legitimate interest’ as a ground to process personal data for key use cases such as product development – including of AI models – and security.”</p>
<p dir="ltr">Big Tech lobby organisation<a href="https://corporateeurope.org/sites/default/files/2026-01/DOT%20Europe%20letter%20to%20Danish%20government.pdf"><strong> Dot Europe</strong></a> (in a lobby letter to the Danish Government): “GDPR Article 9 strictly limits the processing of special category data (e.g., race, ethnicity, health), posing challenges for AI development, particularly in healthcare. AI models need access to sensitive data to ensure accuracy, fairness, and cultural relevance.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-670509c7-7fff-9a7b-7fc9-3369e98f1371"><strong>Weakening rules on automated decision-making </strong></h3>
<p dir="ltr">Currently, automated systems cannot be used to make decisions with legal effect or for online profiling. A human must be in the loop. The Commission’s proposal is a structural shift from a general prohibition on automated decision-making but with a few narrow exceptions towards an authorisation regime where a company can employ automated decision-making whenever it thinks this is “necessary”.</p>
<p dir="ltr">Important decisions including credit scoring, ‘robo-firings’, profiling, and welfare benefits could in the future be taken by automated decision-making without human intervention. This change will increasingly expose people to possibly flawed and biased algorithms which could make life-changing decisions, including if you get a loan or are fired from your job. Moreover these algorithms are generally black boxes, meaning it can be hard to uncover evidence of bias. Scandals in the <a href="https://www.amnesty.org/en/latest/news/2021/10/xenophobic-machines-dutch-child-benefit-scandal/">Netherlands</a> and <a href="https://www.bbc.com/news/world-australia-66130105">Australia</a> already show how thousands of people can be wrongly targeted with devastating effects.</p>
<p dir="ltr">In 2024, a subsidiary of the food delivery platform Glovo <a href="https://edri.org/our-work/italian-dpas-e5m-fine-against-glovo-marks-milestone-for-workers-rights/">was fined</a> €5 million by the Italian data protection authority under article 22 of the GDPR for violating workers&#39; rights. The platform had used its rating system to automatically assign orders or ‘deactivate’ (read: ‘fire’) workers based on their ratings.</p>
<p dir="ltr">While the drastic weakening of article 22 will benefit a range of different sectors, from the insurance and banking sector to gig economy companies, Big Tech is also set to profit. </p>
<p dir="ltr">At the moment, social media giants employ thousands of underpaid workers to review harmful or illegal content on social media. This change will allow Big Tech companies to fully automate content moderation, cutting these costs essentially down to zero. Since the inauguration of Trump, Meta has<a href="https://www.theguardian.com/technology/2025/apr/23/meta-hastily-changed-moderation-policy-with-little-regard-to-impact-says-oversight-board"> fired thousands of content moderators</a>. Amnesty International<a href="https://www.amnesty.org/en/latest/news/2025/02/meta-new-policy-changes/"> has warned </a>that replacing content moderators with automated systems could amplify the most harmful content including content inciting racial hatred.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-5e95c669-7fff-85a3-b42e-c9abac657944" dir="ltr"><strong>Proposed text to Article 22 of the GDPR in italics</strong>: “<em>A decision which produces legal effects for a data subject or similarly significantly affects him or her may be based solely on automated processing, including profiling, only where that decision</em>: (a) is necessary for entering into, or performance of, a contract between the data subject and a data controller<em> regardless of whether the decision could be taken otherwise than by solely automated means</em>.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position  </dt>
<dd>
<p id="docs-internal-guid-a08c610f-7fff-3c44-3663-0ddb62903a26" dir="ltr">While Big Tech companies have been complaining about the overlap between article 22 of the GDPR with the AI Act and the Platform Work Directive, it seems it was mainly insurance sector lobbying that was decisive in rolling back the protection on automated decision-making (Big Tech is however still set to benefit from this change). In 2023, the European Court of Justice<a href="https://curia.europa.eu/juris/liste.jsf?num=C-634/21"> ruled in a landmark case </a>that credit scores based on profiling cannot be used by banks and insurance companies to decide on granting a loan or other financial products. The Digital Omnibus might now undermine that ruling. </p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088532_en"><strong>Insurance Europe</strong></a>: &#34;Automated-decision making should be allowed as long as it is subject to safeguard mechanisms. To ensure that Art. 22 does not become an obstacle to the development of new digital solutions, it should be clarified that it is a right of the data subject and not an ex-ante prohibition.&#34;</p>
<p dir="ltr">Big Tech lobby organisation <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “The definitions of the General Data Protection Regulation’s (GDPR) ‘automated individual decision-making’ (Article 22), the AI Act’s ‘AI system’ (Article 3(1)), and the Platform Work Directive’s (PWD) for automated decision-making systems often overlap.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-7d6fe0e9-7fff-bd1c-753a-6bddaf70988d"><strong>Folding parts of ePrivacy into the GDPR</strong></h3>
<p dir="ltr">Cookies are the backbone of the AdTech industry, used to trace our online activities in order to target us with personalised ads. Article 5(3) of the ePrivacy directive requires websites and apps to ask for prior consent before storing cookies. The Commission now wants to ‘fold’ parts of article 5(3) into the GDPR. This replaces a categorical, consent-based mechanism with a more flexible framework based on balancing and exceptions.</p>
<p dir="ltr">Folding ePrivacy into the GDPR creates a more permissive system that allows companies to use exceptions to track behaviour. The <a href="https://netzpolitik.org/2025/databroker-files-all-you-need-to-know-about-how-adtech-data-exposes-the-eu-to-espionage/">Databroker Files</a> demonstrated that commercial datasets which contain millions of locations could actually be used to spy on the public in Europe. These and other examples show the risks to our privacy are real: reporting shows how the vast trade in location data from smartphones can be traced back to individuals showing where they were at a specific time.</p>
<p dir="ltr">It will allow them to do even more of what they already do: track you <a href="https://techcrunch.com/2020/12/10/france-fines-google-120m-and-amazon-42m-for-dropping-tracking-cookies-without-consent/">without your consent</a>. Big Tech firms have been <a href="https://techcrunch.com/2021/11/01/digging-into-googles-push-to-freeze-eprivacy/">lobbying for years against ePrivacy</a> as it could undermine their invasive business model based on surveillance ads. </p>
<p>Several Big Tech firms have moreover <a href="https://techcrunch.com/2020/12/10/france-fines-google-120m-and-amazon-42m-for-dropping-tracking-cookies-without-consent/">faced fines </a>for tracking users without consent. This change might let these companies get away with their most problematic practices.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-a1220957-7fff-28f4-8fce-45d6d0d0f6b0" dir="ltr"><strong>New text added to article 5(3) of the ePrivacy directive in italics</strong>: “<em>This paragraph shall not apply if the subscriber or user is a natural person, and the information stored or accessed constitutes or leads to the processing of personal data.”</em></p>
<p dir="ltr"><strong>A new GDPR article 88a takes over instead which also introduces a series of exceptions to ask for consent</strong> including when “creating aggregated information about the usage of an online service to measure the audience of such a service, where it is carried out by the controller of that online service solely for its own use”.</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-616d9873-7fff-185e-3391-0eaa46c03ead" dir="ltr">The telecom sector, publishers and the tech industry have lobbied for years against strong privacy protections as guaranteed by the ePrivacy directive. In 2018 a major Big Tech driven lobby campaign <a href="https://corporateeurope.org/en/power-lobbies/2018/06/shutting-down-eprivacy-lobby-bandwagon-targets-council">prevented</a> efforts to strengthen the ePrivacy Directive. A court document showed Google revealing that “we have been successful in slowing down and delaying the [ePrivacy Regulation] process and have been working behind the scenes hand in hand with the other companies.” The digital omnibus is another step in dismantling ePrivacy protections with all major players pushing for the changes as proposed by the Commission.</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088017_en"><strong>Google</strong></a>: “The most effective simplification is to delete Article 5(3) from the ePrivacy directive and govern all data processing related to cookies under the GDPR risk-based framework. Alternatively, a significant step toward simplification would be to amend Article 5(3) to extend the scope of permitted exemptions to allow specific, low-risk processing activities that are essential both for the functioning of a safe and sustainable digital ecosystem as well as for user experience. This would create clear exemptions for functions such as first-party audience measurement, ad frequency capping, and anti-fraud measures—allowing them to operate without generating unnecessary consent requests.”  </p>
<p dir="ltr"><a href="https://corporateeurope.org/sites/default/files/2026-01/Microsoft%20lobby%20paper%20data%20union%20strategy.pdf"><strong>Microsoft</strong></a><strong>:</strong> “The “cookie rule” in article 5 (3) eP[rivacy] D[irective] could be moved to the GDPR or, if kept in, rendered more flexible by allowing cookie placement without consent in a wider range of circumstances, e.g. for security, software updates, anti-fraud, and analytics.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h2 id="docs-internal-guid-e42d9ba0-7fff-743a-578b-669027a52594"><strong>How the Commission aims to weaken the AI Act</strong></h2>
<p dir="ltr">&#34;Europe is open for AI and for business!&#34; Ursula von der Leyen tweeted during the AI Action Summit in Paris. In its single-minded priority to “win the global AI race”, the Commission is slashing rules and protections against risky AI systems. A year-long <a href="https://corporateeurope.org/en/2025/11/preparing-roll-back-digital-rights-commissions-secretive-meetings-industry">lobby campaign</a> by the Trump administration and Big Tech to delay the implementation of the AI Act has clearly paid off.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-f2d642be-7fff-e6de-2e0c-7fe036554457"><strong>No Checks and Balances for risky AI systems </strong></h3>
<p dir="ltr">A controversial win for Big Tech firms during the AI Act negotiations was allowing companies to “self-assess” if they believe an AI system is high-risk. To compensate for that loophole, industry had to register these AI systems in a public database. Now this transparency failsafe will also be removed, basically giving tech companies a free hand in deciding if an AI system is risky without any public oversight. </p>
<p dir="ltr">The risk to fundamental rights these high-risk AI systems pose are far from hypothetical.  From<a href="https://www.bbc.com/news/business-54698858"> algorithmic-powered employee firings</a> to<a href="https://www.axios.com/2020/08/19/england-exams-algorithm-grading"> biased algorithms that disadvantage students</a> based on their socio-economic background, highly problematic AI systems are already in circulation. The AI Act lets companies self-assess if these AI systems are high-risk or not, and should therefore comply with requirements such as proper risk management, accuracy, and transparency.</p>
<p dir="ltr">The digital omnibus will worsen an already huge loophole in the AI Act with potentially disastrous impacts on our rights.</p>
<p dir="ltr">Not only can AI companies already self-assess if their AI systems are risky, the digital omnibus will remove any possibility of public oversight of that assessment, giving these companies a blank check to do as they please without any accountability mechanism.</p>
<p dir="ltr">In<a href="https://www.linkedin.com/feed/update/urn:li:activity:7396855577064398849/"> a reaction on LinkedIn</a> Daniel Leufer from the NGO Access Now called this “the biggest, most ridiculous loophole in the AI Act that will let unscrupulous providers unilaterally exempt themselves from the AI Act&#39;s obligations with oversight”.  </p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-aa943702-7fff-4db2-83eb-5cc135dae204" dir="ltr"><strong>Paragraph 2 of article 49 of the AI Act is deleted.</strong></p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-27e01355-7fff-f562-cfea-5cf2ab5716da" dir="ltr">The Commission’s proposals are completely in line with the lobby position of the two lobby organisations Dot Europe and DigitalEurope that count Big Tech members as its members. </p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Abolish the mandatory registration of AI systems, along with the related EU and Member State databases.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087422_en"><strong>Dot Europe</strong></a><strong>:</strong> “when a provider of AI systems provides concrete justifications that its AI system does not pose a significant risk of harm to the health, safety or fundamental rights of natural persons per Article 6(3), it should not be required to register its system in the high-risk AI database per Article 49.”  </p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-6a019008-7fff-431e-f228-8639b04b8077"><strong>Delay in the implementation of the AI Act</strong></h3>
<p dir="ltr">The Commission intends to postpone the implementation of part of the AI Regulation by almost a year and a half. This means giving Big Tech more than 12 months to continue releasing potentially risky systems onto the market without any safeguards.</p>
<p dir="ltr">This proposal would enable companies to continue to release risky AI systems for at least a year onto the market without any safeguards. Moreover, as the<a href="https://cdt.org/wp-content/uploads/2025/12/CDT-Europe-Brief-Digital-Omnibus-Threatens-Hard-Won-AI-Safeguards.pdf"> Center for Democracy and Technology points out</a>, delaying the parts of the AI Act on high-risk AI systems, will also obstruct the ban of the most dangerous AI systems, leaving dangerous practices such as <a href="https://edri.org/our-work/emotion-misrecognition/">emotion recognition systems</a> and facial recognition AI used in public spaces on the market for longer.</p>
<p dir="ltr">Delaying is<a href="https://corporateeurope.org/en/2023/11/how-pesticide-lobby-sabotaging-eu-pesticide-reduction-law-sur"> a tried and tested industry lobbying tactic</a>. It will give Big Tech more time to further water down the AI Act. Already, tech lobbyists are <a href="https://ccianet.org/news/2025/12/dont-let-digital-simplification-stall-eu-member-states-warned-by-tech-sector/">calling</a> for the further deregulation of the AI Act.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position </dt>
<dd>
<p id="docs-internal-guid-b5a2e1d9-7fff-3947-9538-0a5ddb96be61" dir="ltr">A delay in the implementation of the AI Act is a central demand in a <a href="https://corporateeurope.org/en/2025/11/preparing-roll-back-digital-rights-commissions-secretive-meetings-industry">year-long tech lobby campaign</a> which was backed by the Trump administration.</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “The first priority should be to delay AI Act implementation until at least 12 months after relevant guidance, codes of practice, or technical standards become available.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Delay the application of high-risk AI requirements until at least 12 months after relevant harmonised standards are published, allowing sufficient time for adaptation.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33089184_en"><strong>Meta</strong></a><strong>: </strong>“It is critical to first pause the implementation and enforcement of the [AI Act]. This pause will provide the necessary time to undertake meaningful reforms without risking the EU falling behind in the global AI race. </p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h3 id="docs-internal-guid-25437b55-7fff-a246-ab30-33677ccc0348"><strong>Using your sensitive data to train AI </strong></h3>
<p dir="ltr">The AI Act under narrow circumstances allowed the use of sensitive data for mitigation of high-risk AI models to prevent bias and discrimination. This exception is now expanded to all AI systems based on the assessment of companies if the processing is necessary (see also above as part of the changes to the GDPR).</p>
<p dir="ltr">This will allow intrusive gathering of your most sensitive personal data to train AI systems. Also see above “Using your personal data for training AI.</p>
<p dir="ltr">While Big Tech claims that more data is necessary for detecting bias, <a href="https://www.sciencedirect.com/science/article/pii/S0160791X25003173">research</a> <a href="https://edri.org/wp-content/uploads/2021/09/EDRi_Beyond-Debiasing-Report_Online.pdf">suggests</a> that debiasing -  certain statistical techniques to ‘correct’ bias in databases that are used to train AI - is often ineffective and is unable to detect the many forms and contexts in which discrimination and bias manifests. Instead, it is a technical fix that enables Big Tech companies to collect yet more sensitive personal data to train their AI models while creating the illusion of ethical AI, all while encouraging the widespread adoption of AI across all sectors of society.</p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-14fc2415-7fff-f8e5-5791-dc9231e90f97" dir="ltr"><strong>The digital omnibus introduces article 4(a) to the AI Act</strong>: “To the extent necessary to ensure bias detection and correction in relation to high-risk AI systems in accordance with Article 10 (2), points (f) and (g), of this Regulation, providers of such systems may exceptionally process special categories of personal data.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-a8b18b69-7fff-bdab-e1e3-069b36e29e69" dir="ltr">The tech lobby constantly portrays data protection as a major obstacle to AI training and has therefore repeatedly lobbied, either specifically or in general terms, for the weakening of data protection. </p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088017_en"><strong>Google</strong></a>: “We propose extending the allowance in Article 10(5) to permit the necessary data processing for bias detection and correction across all AI systems and general purpose AI models. Extending this provision will provide a harmonized legal basis for developers to proactively build the fair, representative, and trustworthy AI that aligns with the EU’s core values and benefits all citizens. It will also reduce the risk of AI models and systems perpetuating or amplifying societal discrimination, irrespective of their specific AI Act risk classification.”  </p>
<p dir="ltr">Big Tech lobby organisation<strong> </strong><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087752_en"><strong>Information Technology Industry Council (ITI)</strong></a>: “The AI Act&#39;s Article 10(5) allowance for special categories of personal data processing for bias mitigation should be extended to the training of all AI systems and GPAI models, not just those classified as &#34;high-risk.”</p>
</dd>
</dl>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><h2 id="docs-internal-guid-c7899791-7fff-10f8-e917-ea91e4494d4c"><strong>A Big Tech-far right alliance in the making?</strong></h2>
<p dir="ltr">The Commission’s digital omnibus received widespread criticism. Civil society organisations, think tanks, experts, and political groups in the European Parliament from the left to the centre all perceived the Commission’s proposals as handouts to Big Tech and the Trump administration.</p>
<p dir="ltr">But while the Social Democrats in the Parliament called the digital omnibus <a href="https://www.socialistsanddemocrats.eu/newsroom/sds-dont-deregulate-and-weaken-eus-digital-legal-framework-protects-people">unacceptable deregulation</a>, <a href="https://www.politico.eu/article/ursula-von-der-leyen-eu-parliament-showdown-digital-red-tape-crusade/">far right parties</a> quickly came to the support of the Commission.</p>
<p dir="ltr">Big Tech lobbying of the European Parliament also shifted in higher gear. Lobbying of the far-right seems to have become a particular priority for Meta, and to a lesser extent Google. While during the previous parliamentary mandate, Meta only met once with a far-right MEP, during this parliamentary mandate it has <a href="https://corporateeurope.org/en/media/6519">already met 38 times </a>with MEPs from the ECR, the Patriots and the Europe of Sovereign Nations Group. The digital omnibus is a key priority in those meetings. In the week of 8 December 2025, Meta met with four far right MEPs with most of those meetings mentioning the digital omnibus. </p>
<p dir="ltr">Google has also not shied away from meeting far-right MEPs. A few days after the launch of the digital omnibus, the Head of Public Affairs of Google France <a href="https://www.instagram.com/p/DRfV_JpDdhf/?img_index=2">joined a dinner party</a> in Strasbourg hosted by six French MEPs from the far right Rassemblement National. </p>
</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><div>

  

  <p><img loading="lazy" src="https://hamy.xyz/sites/default/files/styles/image_l/public/2026-01/Screenshot%20from%202026-01-13%2010-06-50.png?itok=gFs9cpmp" width="800" height="579" alt="Google France at a dinner party of far-right MEPs of Rassemblement National "/>



  </p>

<div>
    
            <p>The Head of Public Affairs of Google France joined at a dinner party in Strasbourg hosted by six MEPs from the far right Rassemblement National.</p>
      
            <p>Souce: Instagram</p>
      
  </div>

</div>

</div>
      
      </div>
</div>
              <div>  <div>
          
            <div><p dir="ltr">Big Tech&#39;s lobbying strategy in the US, where it has <a href="https://www.theguardian.com/global/2025/dec/15/ai-trump-openai-google-data-centers">aligned</a> itself with the Trump administration, now appears to have been extended to the European Parliament.</p>
<p dir="ltr">As outlined in this article, the digital omnibus is not just an unprecedented attack on our digital rights – it also closely mirrors Big Tech lobbying positions. The Commission’s deregulation agenda threatens to undermine years of progress in reining these tech giants and protecting our privacy. </p>
<p dir="ltr">The emerging far right - Big Tech alliance in the European Parliament points towards an even more alarming trend. It should now be clear to all that the Commission’s deregulation agenda isn&#39;t just opening the door to Big Tech, it&#39;s inviting the far right in.</p>
<p dir="ltr">However, this outcome is not inevitable. The European Parliament now has a crucial opportunity to stop this dangerous proposal and defend the hard-won data protection safeguards.</p>
<p dir="ltr">The Digital Omnibus has received massive pushback, from civil society organsations, from within parliament and from member states, including Malta, which recently requested more time to scrutinise the proposal.</p>
<p dir="ltr">What happens next depends on whether we manage to increase the pressure. </p>
<p dir="ltr">Now is the time to make our voices heard and make it crystal clear to the European Parliament and national governments that they must stand up for our privacy, freedom of expression and democratic control over technology, and reject the Digital Omnibus.</p>
</div>
      
      </div>
</div>
          </div>
  



</div>


  </div>

<div id="block-views-block-random-promotion-block-1">
  
    
      <div><div>
  
    
      
      <div>
          <div><div><div><p>This article continues after the banner</p>
<a href="https://corporateeurope.org/en/newsletter"><div>

  

  <p><img loading="lazy" src="https://hamy.xyz/sites/default/files/styles/image_l/public/2023-06/banner_newsletter.png?itok=AePb7Pff" width="800" height="200" alt="Subscribe to our newsletter"/>



  </p>


</div>

</a></div></div></div>

    </div>
  
          </div>
</div>

  </div>
  </div>

    </section>

  </div></div>
  </body>
</html>
