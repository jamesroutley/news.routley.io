<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lostpixels.io/writings/building-interactive-plotter-art">Original</a>
    <h1>Show HN: I built an interactive plotter art exhibit for SIGGRAPH</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p>I was given the opportunity to participate in SIGGRAPH 2023 in Los Angeles, and I decided to showcase how art, code, and pen plotters all mesh together. In order to do this, I created an interactive art installation which brought together all three.</p>
<p>Building an interactive art installation requires careful planning and application architecture. In this post, I will explain my decisions and how I arrived at them.</p>
<p>My design goal was simple: A person can walk up, play with a MIDI controller, see a resulting image on a screen, and then send the image to a pen plotter. The plotter draws their unique drawing, and they can take it home and frame it.</p>
<p>There were far more details within the implementation, though:</p>
<ul>
<li>The application had to be fast. Turning a dial on the MIDI controller should provide real-time feedback.</li>
<li>Compatibility with the pen plotter. It only accepts vector assets.</li>
<li>Handling a queue of artwork - in the case of crowds, all coming to the installation simultaneously.</li>
<li>Plots should take at most 10 minutes to make.</li>
</ul></div></div></div><div><div><div><h2>Rendering &amp; Performance</h2>
<p>When I make <a href="https://lostpixels.io/browse/plotter">plotter art</a>, I use <a href="https://p5js.org/">P5.JS</a> and the <a href="https://github.com/zenozeng/p5.js-svg">P5-SVG plugin</a> to render my graphics as SVGs. This workflow allows me to download the files as vectors. Then, I can upload them to <a href="https://github.com/nornagon/saxi">Saxi</a>, a utility that controls my Axidraw pen plotters. The translation between coding art and having the pen plotter draw it is nearly seamless.</p>
<p>Rendering a graphic at 60FPS and responding to user input started to become slow with this approach, though. I found that updating the DOM with new SVG elements 60 times a second wasn&#39;t ideal. I flipped back to the typical rendering approach used by P5.JS, which leverages HTML canvas. It immediately fixed all frame rate issues and made the application feel much more fluid when twirling the MIDI controls.</p>
<p>To have the performance of canvas and compatibility of SVGs, I made two instances of P5.JS sketches, one with each rendering target. I only rendered the vector instance before the application was transmitted to the cloud job manager.</p>
<p>I needed to build an application UI to display helpful hints, an intro screen, and some submission steps. To do this, I brought in <a href="https://svelte.dev/">Svelte</a>. Although I could have used React here, I like the ease of use that comes with Svelte. React felt heavy-handed since I wasn&#39;t worried about component reuse or application render performance at this layer. Never defeated, though, React managed to make its way into the stack later on.</p></div></div></div><div><div><div><h2>Sending Files</h2>
<p>My client application was running on hardware, and I planned to have two instances on-site. The next problem was taking the graphic on the iPad and getting it to a pen plotter.</p>
<ul>
<li>What would happen if there was a line and many people all wanted to make drawings in quick succession?</li>
<li>How could I later identify who made what, all while respecting user privacy?</li>
<li>What if the system went down, or I needed to swap out an iPad, computer, or pen plotter?</li>
</ul>
<p>I decided to spin up a cloud instance and write a custom job manager that would allow me to see every submission and assign statuses to it. This way, a queue of art could build up, and I could easily keep track of it. The application needed to accept information from n-number iPads running my sideloaded drawing app.</p>
<p>I built a NextJS application and deployed it to Digital Ocean&#39;s App platform. I went with NextJS because of my familiarity with React and its ease of use for API creation using the /api directory. I could have used many other backend solutions to build this basic CRUD app, but having everything under the same hood helped me iterate quickly.</p>
<p>I attached a Postgres database to my app to persist items in my queue. Then, I used DO Spaces to host the SVGs, which would be transmitted to my API via the iPads.</p>
<p>I tacked on a simple static microsite for the project using Eleventy. I bundled it with the Digital Ocean mono repo feature, thus saving me the costs of spinning up another app instance.</p></div></div></div></div>
  </body>
</html>
