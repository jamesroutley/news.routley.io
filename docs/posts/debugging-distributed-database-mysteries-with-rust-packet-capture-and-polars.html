<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://questdb.io/blog/debugging-distributed-database-mysteries-with-rust-pcap-and-polars/">Original</a>
    <h1>Debugging distributed database mysteries with Rust, packet capture and Polars</h1>
    
    <div id="readability-page-1" class="page"><article><p>
  QuestDB is a high performance <a href="https://questdb.io/glossary/time-series-database/">time-series database</a>
  with SQL analytics that can power through data ingestion and analysis.
  It&#39;s <a href="https://github.com/questdb/questdb">open source</a>
  and integrates with many tools and languages. Give us a try!</p>
<hr/>
<p>A few months back I was working on the primary-replica replication feature in
QuestDB. The feature was nearing completion of development but we had a report
that it was using a significant amounts of network bandwidth.</p>
<p>During the process of debugging the issue I ended up implementing my own
quick&#39;n&#39;dirty network profiling tooling. This is a blog post on how I wrote the
tool and how I analysed the data.</p>
<h2 id="the-performance-problem">The performance problem<a aria-label="Direct link to The performance problem" title="Direct link to The performance problem" href="https://questdb.io/blog/debugging-distributed-database-mysteries-with-rust-pcap-and-polars/#the-performance-problem">​</a></h2>
<p>A bit of context first: Our database instances do not replicate directly
point-to-point. Instead, they compress and upload the table&#39;s WAL (write-ahead
log) files to a central object store such as AWS S3 or Azure Blob store. In
other words, we store each table&#39;s full edit history in a series of files in the
object store that we can replay back at any time.</p>

<p>This architecture:</p>
<ul>
<li>decouples deployment</li>
<li>allows rebuilding a database instance up to a specific transaction point</li>
<li>is generally more scalable</li>
</ul>
<p>By delegating the work to an external component, it relieves the primary
database instance from having to deal with serving the replica instances.</p>
<p>Each uploaded file (segment) contains a block of transactions. We overwrite the
last file over and over with more transactions until it&#39;s large enough to roll
over to the next file. We need to do this because the compatible object stores
we use, for the most part, do not support appending.</p>

<p>Being a time series database, users would typically stream (ingest) records into
the database at a relatively constant rate (consuming network bandwidth
inbound). The primary database instance would then write artifacts to the object
store (consuming network bandwidth outbound).</p>
<p>On an early deployment on DigitalOcean, we noticed that our outbound object
store bandwidth usage was significantly higher than the inbound ingestion
bandwith usage. Not only that, but the outbound object store bandwidth usage
kept growing hour by hour. And it did so despite a constant ingestion rate.</p>
<p>I&#39;ve lost the original metrics and numbers, but it would have looked something
like the following diagram (use your imagination to imagine the usual network
bandwidth usage noise):</p>
<figure><p><img alt="" src="https://questdb.io/img/blog/2024-07-24/replication-issue.svg" loading="lazy"/></p></figure>
<p>Needless to say that the replication bandwidth should be roughly proportional to
the ingestion bandwidth and <em>not grow over time</em>!</p>
<h2 id="capturing-the-network-traffic">Capturing the network traffic<a aria-label="Direct link to Capturing the network traffic" title="Direct link to Capturing the network traffic" href="https://questdb.io/blog/debugging-distributed-database-mysteries-with-rust-pcap-and-polars/#capturing-the-network-traffic">​</a></h2>
<p>I needed to understand what was going on <em>accurately</em>, so at first I turned to
Wireshark. I hoped I could perform a simulated test run and capture a time
series about packet sizes for both the inbound and outbound connections, but
struggled to do this. It&#39;s likely possible to accomplish this in Wireshark, but
I find its UI pretty daunting, and I&#39;m more comfortable with writing code.</p>
<p>Wireshark is built on packet capture, so instead I grabbed my favourite tool
(Rust) and used the <a href="https://crates.io/crates/pcap" rel="noopener noreferrer nofollow"><code>pcap</code></a> crate (wrapping the
<a href="https://www.tcpdump.org/" rel="noopener noreferrer nofollow"><code>libpcap</code></a> C library) to capture the two time series.</p>
<p>For each connection, whenever I&#39;d observe a packet I&#39;d capture two fields:</p>
<ul>
<li>The packet&#39;s timestamp (<code>i64</code> epoch nanos timestamp).</li>
<li>The packet&#39;s size (<code>u64</code>).</li>
</ul>
<p>After writing a script to generate some load, I set up my test with
<a href="https://crates.io/crates/s3s-fs" rel="noopener noreferrer nofollow"><code>s3s-fs</code></a> - a binary that emulates an AWS S3
endpoint, then ran a primary QuestDB instance on the same machine.</p>
<p>I could now monitor the database&#39;s inbound traffic on port <code>9000</code> and the
replication traffic on port <code>10101</code> using a <code>net-traffic-capture</code> tool I I wrote
for this purpose in Rust.</p>

<p>Here are the first few lines of the <code>main</code> function of the packet capture tool.
They run a loop over the intercepted traffic for the specific ports over the
loopback device.</p>
<p>For the full code see
<a href="https://github.com/questdb/replication-stats/blob/main/net-traffic-capture/" rel="noopener noreferrer nofollow">github.com/questdb/replication-stats -&gt; /net-traffic-capture/</a>.</p>
<div><div><pre tabindex="0"><code><span><span>fn</span><span> </span><span>main</span><span>(</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>anyhow</span><span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>    </span><span></span><br/></span><span><span>    </span><span>let</span><span> ports</span><span>:</span><span> </span><span>HashSet</span><span>&lt;</span><span>_</span><span>&gt;</span><span> </span><span>=</span><span> ports</span><span>.</span><span>into_iter</span><span>(</span><span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> writer_queue </span><span>=</span><span> </span><span>writer</span><span>::</span><span>Writer</span><span>::</span><span>run</span><span>(</span><span>dir</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> device </span><span>=</span><span> </span><span>get_loopback_device</span><span>(</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> cap </span><span>=</span><span> </span><span>Capture</span><span>::</span><span>from_device</span><span>(</span><span>device</span><span>)</span><span>?</span><span></span><br/></span><span><span>        </span><span>.</span><span>promisc</span><span>(</span><span>false</span><span>)</span><span></span><br/></span><span><span>        </span><span>.</span><span>snaplen</span><span>(</span><span>128</span><span>)</span><span></span><br/></span><span><span>        </span><span>.</span><span>timeout</span><span>(</span><span>1</span><span>)</span><span></span><br/></span><span><span>        </span><span>.</span><span>buffer_size</span><span>(</span><span>4</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span><span>)</span><span></span><br/></span><span><span>        </span><span>.</span><span>open</span><span>(</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>    cap</span><span>.</span><span>filter</span><span>(</span><span>&#34;tcp&#34;</span><span>,</span><span> </span><span>true</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> link_type </span><span>=</span><span> cap</span><span>.</span><span>get_datalink</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>loop</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>let</span><span> packet </span><span>=</span><span> </span><span>ignore_timeouts</span><span>(</span><span>cap</span><span>.</span><span>next_packet</span><span>(</span><span>)</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> </span><span>Some</span><span>(</span><span>packet</span><span>)</span><span> </span><span>=</span><span> packet </span><span>else</span><span> </span><span>{</span><span></span><br/></span><span><span>            </span><span>continue</span><span>;</span><span></span><br/></span><span><span>        </span><span>}</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> tcp_data </span><span>=</span><span> </span><span>parse_tcp</span><span>(</span><span>&amp;</span><span>packet</span><span>,</span><span> link_type</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> </span><span>Some</span><span>(</span><span>tcp_data</span><span>)</span><span> </span><span>=</span><span> tcp_data </span><span>else</span><span> </span><span>{</span><span></span><br/></span><span><span>            </span><span>continue</span><span>;</span><span></span><br/></span><span><span>        </span><span>}</span><span>;</span><span></span><br/></span><span><span>        </span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><span>}</span><br/></span></code></pre></div></div>
<p>The byte parsing logic here is implemented using the excellent
<a href="https://crates.io/crates/etherparse" rel="noopener noreferrer nofollow"><code>etherparse</code></a> crate.</p>
<div><div><pre tabindex="0"><code><span><span>fn</span><span> </span><span>parse_tcp</span><span>(</span><span></span><br/></span><span><span>    packet</span><span>:</span><span> </span><span>&amp;</span><span>Packet</span><span>,</span><span></span><br/></span><span><span>    link_type</span><span>:</span><span> </span><span>Linktype</span><span></span><br/></span><span><span></span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>anyhow</span><span>::</span><span>Result</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>TcpData</span><span>&gt;&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>    </span><span>if</span><span> packet</span><span>.</span><span>header</span><span>.</span><span>caplen </span><span>&lt;</span><span> </span><span>32</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>return</span><span> </span><span>Ok</span><span>(</span><span>None</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span>    </span><span>let</span><span> ipv4data </span><span>=</span><span> </span><span>match</span><span> link_type </span><span>{</span><span></span><br/></span><span><span>        </span><span>Linktype</span><span>::</span><span>NULL</span><span> </span><span>=&gt;</span><span> </span><span>&amp;</span><span>packet</span><span>.</span><span>data</span><span>[</span><span>4</span><span>..</span><span>]</span><span>,</span><span></span><br/></span><span><span>        </span><span>Linktype</span><span>::</span><span>ETHERNET</span><span> </span><span>=&gt;</span><span> </span><span>skip_ethernet_header</span><span>(</span><span>packet</span><span>.</span><span>data</span><span>)</span><span>?</span><span>,</span><span></span><br/></span><span><span>        _ </span><span>=&gt;</span><span> </span><span>return</span><span> </span><span>Err</span><span>(</span><span>anyhow</span><span>::</span><span>anyhow!</span><span>(</span><span></span><br/></span><span><span>            </span><span>&#34;Unsupported link type: {:?}&#34;</span><span>,</span><span> link_type</span><span>)</span><span>)</span><span>,</span><span></span><br/></span><span><span>    </span><span>}</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> sliced </span><span>=</span><span> </span><span>SlicedPacket</span><span>::</span><span>from_ip</span><span>(</span><span>ipv4data</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> </span><span>Some</span><span>(</span><span>InternetSlice</span><span>::</span><span>Ipv4</span><span>(</span><span>ipv4slice</span><span>,</span><span> _</span><span>)</span><span>)</span><span> </span><span>=</span><span> sliced</span><span>.</span><span>ip </span><span>else</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>return</span><span> </span><span>Ok</span><span>(</span><span>None</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>}</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> src_addr </span><span>=</span><span> ipv4slice</span><span>.</span><span>source_addr</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> dest_addr </span><span>=</span><span> ipv4slice</span><span>.</span><span>destination_addr</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> </span><span>TransportSlice</span><span>::</span><span>Tcp</span><span>(</span><span>tcp</span><span>)</span><span> </span><span>=</span><span> sliced</span><span>.</span><span>transport</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span> </span><span>else</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>return</span><span> </span><span>Ok</span><span>(</span><span>None</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>}</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> src_port </span><span>=</span><span> tcp</span><span>.</span><span>source_port</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> dest_port </span><span>=</span><span> tcp</span><span>.</span><span>destination_port</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span></span><br/></span><span><span>    </span><span>let</span><span> link_bytes_len </span><span>=</span><span> </span><span>4</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> data_offset </span><span>=</span><span> link_bytes_len </span><span>+</span><span></span><br/></span><span><span>        </span><span>(</span><span>(</span><span>ipv4slice</span><span>.</span><span>ihl</span><span>(</span><span>)</span><span> </span><span>*</span><span> </span><span>4</span><span>)</span><span> </span><span>+</span><span> </span><span>(</span><span>tcp</span><span>.</span><span>data_offset</span><span>(</span><span>)</span><span> </span><span>*</span><span> </span><span>4</span><span>)</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span></span><br/></span><span><span>    </span><span>let</span><span> tcp_data </span><span>=</span><span> </span><span>TcpData</span><span> </span><span>{</span><span></span><br/></span><span><span>        ts</span><span>:</span><span> </span><span>to_system_time</span><span>(</span><span>packet</span><span>.</span><span>header</span><span>.</span><span>ts</span><span>)</span><span>,</span><span></span><br/></span><span><span>        src</span><span>:</span><span> </span><span>Addr</span><span> </span><span>{</span><span></span><br/></span><span><span>            ip</span><span>:</span><span> src_addr</span><span>,</span><span></span><br/></span><span><span>            port</span><span>:</span><span> src_port</span><span>,</span><span></span><br/></span><span><span>        </span><span>}</span><span>,</span><span></span><br/></span><span><span>        dest</span><span>:</span><span> </span><span>Addr</span><span> </span><span>{</span><span></span><br/></span><span><span>            ip</span><span>:</span><span> dest_addr</span><span>,</span><span></span><br/></span><span><span>            port</span><span>:</span><span> dest_port</span><span>,</span><span></span><br/></span><span><span>        </span><span>}</span><span>,</span><span></span><br/></span><span><span>        data_offset</span><span>,</span><span></span><br/></span><span><span>        flags</span><span>:</span><span> </span><span>TcpMeta</span><span>::</span><span>from_tcp_header</span><span>(</span><span>&amp;</span><span>tcp</span><span>)</span><span>,</span><span></span><br/></span><span><span>    </span><span>}</span><span>;</span><span></span><br/></span><span><span>    </span><span>Ok</span><span>(</span><span>Some</span><span>(</span><span>tcp_data</span><span>)</span><span>)</span><span></span><br/></span><span><span></span><span>}</span><br/></span></code></pre></div></div>
<p>Once parsed, I had to write these time series metrics to disk in a format I
could analyse easily later.</p>
<p>Being a database engineer, I&#39;ve got this: I re-implemented a tiny subset of
QuestDB&#39;s ingestion logic in Rust. One thread sits on the pcap loop listening
and parsing network packets, passing messages over a message queue to another
thread responsible to append the time series to disk.</p>
<p><em>I could have captured the data into another QuestDB instance, but I was
concerned that this might skew the results.</em></p>

<p>The thread that&#39;s responsible for disk writing uses growable memory mapped files
to write the data into a columnar format. In other words, for each of the two
time series, there&#39;s a timestamp column and a packet size column.</p>
<div><div><pre tabindex="0"><code><span><span></span><br/></span><span><span></span><span>struct</span><span> </span><span>U64ColWriter</span><span> </span><span>{</span><span></span><br/></span><span><span>    file</span><span>:</span><span> </span><span>std</span><span>::</span><span>fs</span><span>::</span><span>File</span><span>,</span><span></span><br/></span><span><span>    mmap</span><span>:</span><span> </span><span>MmapMut</span><span>,</span><span></span><br/></span><span><span>    len</span><span>:</span><span> </span><span>u64</span><span>,</span><span></span><br/></span><span><span>    cap</span><span>:</span><span> </span><span>u64</span><span>,</span><span></span><br/></span><span><span></span><span>}</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>impl</span><span> </span><span>U64ColWriter</span><span> </span><span>{</span><span></span><br/></span><span><span>    </span><span>fn</span><span> </span><span>new</span><span>(</span><span>path</span><span>:</span><span> </span><span>&amp;</span><span>Path</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>let</span><span> cap </span><span>=</span><span> </span><span>increment</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> file </span><span>=</span><span> </span><span>std</span><span>::</span><span>fs</span><span>::</span><span>OpenOptions</span><span>::</span><span>new</span><span>(</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>read</span><span>(</span><span>true</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>write</span><span>(</span><span>true</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>create</span><span>(</span><span>true</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>truncate</span><span>(</span><span>true</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>open</span><span>(</span><span>path</span><span>)</span><span></span><br/></span><span><span>            </span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>        file</span><span>.</span><span>set_len</span><span>(</span><span>cap</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> mmap </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>MmapMut</span><span>::</span><span>map_mut</span><span>(</span><span>&amp;</span><span>file</span><span>)</span><span>?</span><span> </span><span>}</span><span>;</span><span></span><br/></span><span><span>        </span><span>Ok</span><span>(</span><span>Self</span><span> </span><span>{</span><span></span><br/></span><span><span>            file</span><span>,</span><span></span><br/></span><span><span>            mmap</span><span>,</span><span></span><br/></span><span><span>            len</span><span>:</span><span> </span><span>0</span><span>,</span><span></span><br/></span><span><span>            cap</span><span>,</span><span></span><br/></span><span><span>        </span><span>}</span><span>)</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><br/></span><span><span>    </span><span>fn</span><span> </span><span>may_resize</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>let</span><span> required </span><span>=</span><span> </span><span>self</span><span>.</span><span>len </span><span>+</span><span> </span><span>size_of</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span><span></span><br/></span><span><span>        </span><span>if</span><span> required </span><span>&lt;</span><span> </span><span>self</span><span>.</span><span>cap </span><span>{</span><span></span><br/></span><span><span>            </span><span>return</span><span> </span><span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span><br/></span><span><span>        </span><span>}</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>cap </span><span>+=</span><span> </span><span>increment</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>file</span><span>.</span><span>set_len</span><span>(</span><span>self</span><span>.</span><span>cap</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>mmap </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>MmapMut</span><span>::</span><span>map_mut</span><span>(</span><span>&amp;</span><span>self</span><span>.</span><span>file</span><span>)</span><span>?</span><span> </span><span>}</span><span>;</span><span></span><br/></span><span><span>        </span><span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><br/></span><span><span>    </span><span>fn</span><span> </span><span>append</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> val</span><span>:</span><span> </span><span>u64</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>may_resize</span><span>(</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> offset </span><span>=</span><span> </span><span>self</span><span>.</span><span>len </span><span>as</span><span> </span><span>usize</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>mmap</span><span>[</span><span>offset</span><span>..</span><span>offset </span><span>+</span><span> </span><span>size_of</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>(</span><span>)</span><span>]</span><span></span><br/></span><span><span>            </span><span>.</span><span>copy_from_slice</span><span>(</span><span>&amp;</span><span>val</span><span>.</span><span>to_le_bytes</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>len </span><span>+=</span><span> </span><span>size_of</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span><span></span><br/></span><span><span>        </span><span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><span>}</span><br/></span></code></pre></div></div>
<p>All we need now is to add an extra <code>.count</code> file to track the number of written
rows. The code updates it last after writing the two column files.</p>
<div><div><pre tabindex="0"><code><span><span>impl</span><span> </span><span>DatapointWriter</span><span> </span><span>{</span><span></span><br/></span><span><span>    </span><span>fn</span><span> </span><span>new</span><span>(</span><span>path</span><span>:</span><span> </span><span>&amp;</span><span>Path</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>let</span><span> ts_writer </span><span>=</span><span> </span><span>U64ColWriter</span><span>::</span><span>new</span><span>(</span><span></span><br/></span><span><span>            </span><span>&amp;</span><span>path</span><span>.</span><span>with_extension</span><span>(</span><span>&#34;ts&#34;</span><span>)</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> val_writer </span><span>=</span><span> </span><span>U64ColWriter</span><span>::</span><span>new</span><span>(</span><span></span><br/></span><span><span>            </span><span>&amp;</span><span>path</span><span>.</span><span>with_extension</span><span>(</span><span>&#34;val&#34;</span><span>)</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>let</span><span> count_writer </span><span>=</span><span> </span><span>CountWriter</span><span>::</span><span>new</span><span>(</span><span></span><br/></span><span><span>            </span><span>&amp;</span><span>path</span><span>.</span><span>with_extension</span><span>(</span><span>&#34;count&#34;</span><span>)</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>Ok</span><span>(</span><span>Self</span><span> </span><span>{</span><span></span><br/></span><span><span>            ts_writer</span><span>,</span><span></span><br/></span><span><span>            val_writer</span><span>,</span><span></span><br/></span><span><span>            count_writer</span><span>,</span><span></span><br/></span><span><span>        </span><span>}</span><span>)</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><br/></span><span><span>    </span><span>fn</span><span> </span><span>append</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> ts</span><span>:</span><span> </span><span>u64</span><span>,</span><span> val</span><span>:</span><span> </span><span>u64</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span> </span><span>{</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>ts_writer</span><span>.</span><span>append</span><span>(</span><span>ts</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>val_writer</span><span>.</span><span>append</span><span>(</span><span>val</span><span>)</span><span>?</span><span>;</span><span></span><br/></span><span><span>        </span><span>self</span><span>.</span><span>count_writer</span><span>.</span><span>increment</span><span>(</span><span>)</span><span></span><br/></span><span><span>    </span><span>}</span><span></span><br/></span><span><span></span><span>}</span><br/></span></code></pre></div></div>
<p>Memory mapped files reduce the number of system calls and also allow the kernel
to decide when to flush the data to disk in a very efficient manner. What&#39;s
more, once written to memory, the data is safe within the kernel and can survive
a process crash (but not a kernel panic or a sudden power cut). This makes it
&#34;transactional enough&#34; for most use cases, and certainly for this one. The
reason for using two threads is that writing to memory mapped files is still a
blocking IO operation and I did not want to slow down the pcap loop.</p>
<h2 id="analysing-the-network-traffic">Analysing the network traffic<a aria-label="Direct link to Analysing the network traffic" title="Direct link to Analysing the network traffic" href="https://questdb.io/blog/debugging-distributed-database-mysteries-with-rust-pcap-and-polars/#analysing-the-network-traffic">​</a></h2>
<p>Now over to my second favourite tool: Python. The column files written are
effectively just packed 64-bit integers. A few lines of <code>pyarrow</code> later and the
collected samples are loaded into a <code>pyarrow.Table</code> and from that, loaded
zero-copy into a <code>polars.DataFrame</code>.</p>
<p>For the full code see
<a href="https://github.com/questdb/replication-stats/blob/main/analysis/" rel="noopener noreferrer nofollow">github.com/questdb/replication-stats -&gt; /analisys/</a>.</p>
<div><div><pre tabindex="0"><code><span><span></span><br/></span><span><span></span><span>def</span><span> </span><span>read_col</span><span>(</span><span>count</span><span>,</span><span> dtype</span><span>,</span><span> path</span><span>)</span><span>:</span><span></span><br/></span><span><span>    </span><span>with</span><span> </span><span>open</span><span>(</span><span>path</span><span>,</span><span> </span><span>&#39;rb&#39;</span><span>)</span><span> </span><span>as</span><span> col_file</span><span>:</span><span></span><br/></span><span><span>        mem </span><span>=</span><span> mmap</span><span>.</span><span>mmap</span><span>(</span><span></span><br/></span><span><span>            col_file</span><span>.</span><span>fileno</span><span>(</span><span>)</span><span>,</span><span></span><br/></span><span><span>            length</span><span>=</span><span>count </span><span>*</span><span> </span><span>8</span><span>,</span><span></span><br/></span><span><span>            access</span><span>=</span><span>mmap</span><span>.</span><span>ACCESS_READ</span><span>)</span><span></span><br/></span><span><span>        buf </span><span>=</span><span> pa</span><span>.</span><span>py_buffer</span><span>(</span><span>mem</span><span>)</span><span></span><br/></span><span><span>        </span><span>return</span><span> pa</span><span>.</span><span>Array</span><span>.</span><span>from_buffers</span><span>(</span><span>dtype</span><span>,</span><span> count</span><span>,</span><span> </span><span>[</span><span>None</span><span>,</span><span> buf</span><span>]</span><span>)</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>def</span><span> </span><span>read_port_table</span><span>(</span><span>port</span><span>,</span><span> name</span><span>,</span><span> data_dir</span><span>)</span><span>:</span><span></span><br/></span><span><span>    data_dir </span><span>=</span><span> Path</span><span>(</span><span>data_dir</span><span>)</span><span></span><br/></span><span><span>    </span><span>with</span><span> </span><span>open</span><span>(</span><span>data_dir </span><span>/</span><span> </span><span>f&#39;</span><span>{</span><span>port</span><span>}</span><span>.count&#39;</span><span>,</span><span> </span><span>&#39;rb&#39;</span><span>)</span><span> </span><span>as</span><span> f</span><span>:</span><span></span><br/></span><span><span>        count </span><span>=</span><span> struct</span><span>.</span><span>unpack</span><span>(</span><span>&#39;&lt;Q&#39;</span><span>,</span><span> f</span><span>.</span><span>read</span><span>(</span><span>)</span><span>)</span><span>[</span><span>0</span><span>]</span><span></span><br/></span><span><span>    ts_arr </span><span>=</span><span> read_col</span><span>(</span><span></span><br/></span><span><span>        count</span><span>,</span><span> pa</span><span>.</span><span>timestamp</span><span>(</span><span>&#39;ns&#39;</span><span>)</span><span>,</span><span> data_dir </span><span>/</span><span> </span><span>f&#39;</span><span>{</span><span>port</span><span>}</span><span>.ts&#39;</span><span>)</span><span></span><br/></span><span><span>    val_arr </span><span>=</span><span> read_col</span><span>(</span><span></span><br/></span><span><span>        count</span><span>,</span><span> pa</span><span>.</span><span>uint64</span><span>(</span><span>)</span><span>,</span><span> data_dir </span><span>/</span><span> </span><span>f&#39;</span><span>{</span><span>port</span><span>}</span><span>.val&#39;</span><span>)</span><span></span><br/></span><span><span>    </span><span>return</span><span> pl</span><span>.</span><span>from_arrow</span><span>(</span><span></span><br/></span><span><span>        pa</span><span>.</span><span>Table</span><span>.</span><span>from_arrays</span><span>(</span><span></span><br/></span><span><span>            </span><span>[</span><span>ts_arr</span><span>,</span><span> val_arr</span><span>]</span><span>,</span><span> names</span><span>=</span><span>[</span><span>&#39;ts&#39;</span><span>,</span><span> name</span><span>]</span><span>)</span><span></span><br/></span><span><span>    </span><span>)</span><span>.</span><span>sort</span><span>(</span><span>&#39;ts&#39;</span><span>)</span><br/></span></code></pre></div></div>
<p>At this stage I was ready to launch Jupyter Lab and start dissecting the table
and plot some graphs!</p>
<p>When I originally ran my simulation, I did so in a way that simulated time 100x
faster than real time. The code below loads it and scales the timestamps back to
real time.</p>
<div><div><pre tabindex="0"><code><span><span>data </span><span>=</span><span> read_ports_table</span><span>(</span><span></span><br/></span><span><span>    </span><span>{</span><span>9000</span><span>:</span><span> </span><span>&#39;ilp&#39;</span><span>,</span><span> </span><span>10101</span><span>:</span><span> </span><span>&#39;replication&#39;</span><span>}</span><span>,</span><span></span><br/></span><span><span>    data_dir</span><span>=</span><span>&#39;../captures/&#39;</span><span> </span><span>+</span><span> data_dir</span><span>,</span><span></span><br/></span><span><span>    scale_ts</span><span>=</span><span>scaling</span><span>)</span><br/></span></code></pre></div></div>
<p>The data is now merged into a single table with a single <code>ts</code> timestamp column
(ordered) and two packet size columns, one for each port. These two are labelled
<code>ilp</code> (for ingestion) and <code>replication</code> (for the mock AWS S3 traffic).</p>
<p>In this sample data you&#39;ll notice one of the columns is zero. This is because
that port had no traffic at that timestamp.</p>
<table><thead><tr><th>ts : datetime[ns]</th><th>ilp : u64</th><th>replication : u64</th></tr></thead><tbody><tr><td>2024-02-06 17:50:31.517389</td><td>0</td><td>376</td></tr><tr><td>2024-02-06 17:50:31.709789</td><td>0</td><td>414</td></tr><tr><td>2024-02-06 17:50:32.311689</td><td>0</td><td>649</td></tr><tr><td>2024-02-06 17:50:32.349789</td><td>0</td><td>669</td></tr><tr><td>2024-02-06 17:50:32.402989</td><td>0</td><td>677</td></tr><tr><td>2024-02-06 17:50:33.045389</td><td>0</td><td>459</td></tr><tr><td>2024-02-06 17:50:33.360989</td><td>0</td><td>699</td></tr><tr><td>2024-02-06 17:50:33.363089</td><td>0</td><td>667</td></tr><tr><td>2024-02-06 17:50:33.370589</td><td>0</td><td>690</td></tr><tr><td>2024-02-06 17:50:35.635789</td><td>0</td><td>500</td></tr><tr><td>2024-02-06 17:50:36.178789</td><td>0</td><td>546</td></tr><tr><td>2024-02-06 17:50:36.318489</td><td>0</td><td>593</td></tr><tr><td>…</td><td>…</td><td>…</td></tr></tbody></table>
<p>The next task is to group by time: Individual packet sizes and timestamps are
not useful. We need a bandwidth usage metric in bytes/sec over a sampling
interval.</p>
<p>If I had loaded the data into QuestDB, I&#39;d now be able to use the <code>SAMPLE BY</code>
SQL statement. In Polars we can use the <code>group_by_dynamic</code> function.</p>
<div><div><pre tabindex="0"><code><span><span>grouping_window </span><span>=</span><span> </span><span>60</span><span> </span><span>*</span><span> </span><span>1000</span><span>  </span><span></span><br/></span><span><span>scale </span><span>=</span><span> </span><span>1000</span><span> </span><span>/</span><span> grouping_window</span><br/></span><span><span>grouped </span><span>=</span><span> data</span><span>.</span><span>group_by_dynamic</span><span>(</span><span></span><br/></span><span><span>    </span><span>&#34;ts&#34;</span><span>,</span><span></span><br/></span><span><span>    every</span><span>=</span><span>f&#34;</span><span>{</span><span>grouping_window</span><span>}</span><span>ms&#34;</span><span></span><br/></span><span><span>    </span><span>)</span><span>.</span><span>agg</span><span>(</span><span></span><br/></span><span><span>        pl</span><span>.</span><span>col</span><span>(</span><span>&#34;ilp&#34;</span><span>)</span><span>.</span><span>sum</span><span>(</span><span>)</span><span> </span><span>*</span><span> scale</span><span>,</span><span></span><br/></span><span><span>        pl</span><span>.</span><span>col</span><span>(</span><span>&#34;replication&#34;</span><span>)</span><span>.</span><span>sum</span><span>(</span><span>)</span><span> </span><span>*</span><span> scale</span><span>)</span><span></span><br/></span><span><span>grouped</span><br/></span></code></pre></div></div>
<p>The <code>grouped</code> table now contains the bandwidth usage for each port over a
sampling interval.</p>
<table><thead><tr><th>ts : datetime[ns]</th><th>ilp : f64</th><th>replication : f64</th></tr></thead><tbody><tr><td>2024-02-06 17:50:00</td><td>0.0</td><td>137.783333</td></tr><tr><td>2024-02-06 17:57:00</td><td>104.433333</td><td>23.683333</td></tr><tr><td>2024-02-06 17:58:00</td><td>433.8</td><td>124.166667</td></tr><tr><td>2024-02-06 17:59:00</td><td>417.733333</td><td>143.066667</td></tr><tr><td>2024-02-06 18:00:00</td><td>425.766667</td><td>160.883333</td></tr><tr><td>2024-02-06 18:01:00</td><td>433.8</td><td>182.566667</td></tr><tr><td>2024-02-06 18:02:00</td><td>449.866667</td><td>204.5</td></tr><tr><td>2024-02-06 18:03:00</td><td>441.833333</td><td>225.25</td></tr><tr><td>2024-02-06 18:04:00</td><td>449.866667</td><td>245.8</td></tr><tr><td>2024-02-06 18:05:00</td><td>441.833333</td><td>303.566667</td></tr><tr><td>2024-02-06 18:06:00</td><td>425.766667</td><td>91.633333</td></tr><tr><td>2024-02-06 18:07:00</td><td>409.7</td><td>158.333333</td></tr><tr><td>…</td><td>…</td><td>…</td></tr></tbody></table>
<p>Plottable data, finally.</p>
<div><div><pre tabindex="0"><code><span><span>import</span><span> plotly</span><span>.</span><span>express </span><span>as</span><span> px</span><br/></span><span><span>fig </span><span>=</span><span> px</span><span>.</span><span>line</span><span>(</span><span></span><br/></span><span><span>    grouped</span><span>,</span><span></span><br/></span><span><span>    x</span><span>=</span><span>&#39;ts&#39;</span><span>,</span><span></span><br/></span><span><span>    y</span><span>=</span><span>[</span><span>&#39;ilp&#39;</span><span>,</span><span> </span><span>&#39;replication&#39;</span><span>]</span><span>,</span><span></span><br/></span><span><span>    markers</span><span>=</span><span>False</span><span>,</span><span></span><br/></span><span><span>    line_shape</span><span>=</span><span>&#39;hv&#39;</span><span>,</span><span></span><br/></span><span><span>    labels</span><span>=</span><span>{</span><span>&#39;ts&#39;</span><span>:</span><span> </span><span>&#39;timestamp&#39;</span><span>,</span><span> </span><span>&#39;value&#39;</span><span>:</span><span> </span><span>&#39;bytes/sec&#39;</span><span>}</span><span>,</span><span></span><br/></span><span><span>    template</span><span>=</span><span>&#39;plotly_dark&#39;</span><span>)</span><span></span><br/></span><span><span>fig</span><span>.</span><span>show</span><span>(</span><span>)</span><br/></span></code></pre></div></div>
<p>This tooling allowed me to quickly identify the problem. It turns out that we
were re-uploading the full table&#39;s transaction metadata from the start (i.e.
from <code>CREATE TABLE</code> onwards).</p>
<p>The fix was to instead distribute the table metadata across multiple files so it
can be uploaded incrementally without causing network usage growth.</p>
<p>With the fix in place I was then able to use this network analysis tooling to
further fine tune the replication algorith such that replicating between
instances is now more bandwidth efficient than ingestion itself.</p>
<p>This same tooling also helped me build the
<a href="https://questdb.io/docs/guides/replication-tuning" rel="">replication tuning guide</a> for QuestDB.</p>
<p>This is one of the final plots generated by the tool running replication with
network-bandwidth optimized parameters.</p>
<figure><div><p><img alt="Network traffic with network efficiency settings" height="360" src="https://questdb.io/img/guides/replication-tuning/one_row_sec_small.webp" width="1072" loading="lazy"/></p><figcaption>Network traffic with network efficiency settings</figcaption></div></figure>
<p>The value of the tool is clearer when zooming into a particular section of the
plot.</p>
<p>In the plot below it&#39;s pretty easy to spot the zig-zag pattern caused by
continuously re-uploading the last active segment, with a fall-off once the
segment is rolled over.</p>
<figure><div><p><img alt="Zoomed in section of the pcap plot" height="360" src="https://questdb.io/img/blog/2024-07-24/pcap_zoom.webp" width="1156" loading="lazy"/></p><figcaption>Zoomed in section of the pcap plot</figcaption></div></figure>
<h2 id="summary">Summary<a aria-label="Direct link to Summary" title="Direct link to Summary" href="https://questdb.io/blog/debugging-distributed-database-mysteries-with-rust-pcap-and-polars/#summary">​</a></h2>
<p>This blog post shows a basic approach for programmatic packet capture and how
it&#39;s then easy to plot the captured time series metrics in Python and Polars.</p>
<p>You also had a chance to see the techniques we use inside QuestDB itself to
obtain great ingestion performance.</p>
<p>Come talk to us on <a href="https://slack.questdb.io/" rel="noopener noreferrer nofollow">Slack</a> or
<a href="https://community.questdb.io/" rel="noopener noreferrer nofollow">Discourse</a>!</p><div><div><div><div><p><span>Subscribe to our newsletters for the latest. Secure and never shared or sold.</span></p></div></div></div></div></article></div>
  </body>
</html>
