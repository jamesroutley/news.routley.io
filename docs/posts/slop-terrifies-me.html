<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ezhik.jp/ai-slop-terrifies-me/">Original</a>
    <h1>Slop Terrifies Me</h1>
    
    <div id="readability-page-1" class="page"><div> <main> <article> <h2>ðŸ¦” ðŸ¦” ðŸ¦”</h2> <figure>
										<a href="https://www.scd31.com/assets/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.png" target="_blank">
											<img src="https://www.scd31.com/assets/thumbnails/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.jpg"/>
										</a>
										
									</figure>
								
<p>What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?</p>

<p>Imagine if this is as good as AI gets. If this is where it stops, you&#39;d still have models that can almost code a web browser, almost code a compilerâ€”and can even present a pretty cool demo if allowed to take a few shortcuts. You&#39;d still get models that can kinda-sorta simulate worlds and write kinda-sorta engaging stories. You&#39;d still get self-driving cars that almost work, except when they don&#39;t. You get AI that can make you like 90% of a thing!</p>
<p>90% is a lot. Will you care about the last 10%?</p>
<p>I&#39;m terrified that you won&#39;t.</p>
<p>I&#39;m terrified of the <em>good enough to ship</em>â€”and I&#39;m terrified of nobody else caring. I&#39;m less afraid of AI agents writing apps that they will never experience than I am of the AI herders who won&#39;t care enough to actually learn what they ship. And I sure as hell am afraid of the people who will experience the slop and will be fine with it.</p>
<p>As a <a href="https://www.scd31.com/losing-the-plot-that-was-never-there">woodworking enthusiast</a> I am slowly making my peace with standing in the middle of an IKEA. But at the rate things are going in this dropshipping hell, IKEA would be the dream. Software <em>temufication</em> stings much more than software commoditization.</p>

<p>I think Claude and friends can help with crafting good software and with learning new technologies and programming languagesâ€”though I sure as hell move slower when I stop to learn and understand than the guy playing Dwarf Fortress with 17 agents. But at the same time AI models seem to constantly nudge towards that same median Next-React-Tailwind, <em>good enough</em> app. These things just don&#39;t handle going off the beaten path well.</p>
<figure>
										<a href="https://www.scd31.com/assets/claudes-mid-paper-clone.png" target="_blank">
											<img src="https://www.scd31.com/assets/thumbnails/claudes-mid-paper-clone.jpg" alt="Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired."/>
										</a>
										<figcaption>Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired.</figcaption>
									</figure>
								
<p>Mind you, it&#39;s not like slop is anything new. A lot of human decisions had to happen before your backside ended up in an extremely uncomfortable chair, your search results got polluted by poorly-written SEO-optimized articles, and your brain had to deal with a ticket booking website with a user interface so poorly designed that it made you cry. So it&#39;s a people problem. Incentives just don&#39;t seem to align to make good software. Move fast and break things, etc, etc. You&#39;ll make a little artisan app, and if it&#39;s any good, Google will come along with a free clone, kill you, then kill its cloneâ€”and the world will be left with net zero new good software. And now, with AI agents, it gets even worse as agent herders can do the same thing much faster.</p>
<p>Developers aside, there&#39;s also the users. AI models can&#39;t be imaginative, and the developers can&#39;t afford to, but surely with AI tools, the gap between <em>users</em> and <em>developers</em> will be bridged, ChatGPT will become the new HyperCard and people will turn their ideas into reality with just a few sentences? There&#39;s so many people out there who are coding without knowing it, from Carol in Accounting making insane Excel spreadsheets to all the kids on TikTok automating their phones with Apple Shortcuts and hacking up cool Notion notebooks.</p>
<p>But what if those people are an aberration? What if this state of <em>tech learned helplessness</em> cannot be fixed? What if people really do just want a glorified little TV in their pocket? What if most people truly just don&#39;t care about tech problems, about privacy, about Liquid Glass, about Microsoft&#39;s upsells, about constantly dealing with apps and features which just <em>don&#39;t work</em>? What if there will be nobody left to carry the torch? What if the future of computing belongs not to artisan developers or Carol from Accounting, but to whoever can churn out the most software out the fastest? What if <em>good enough</em> really is good enough for most people?</p>
<p>I&#39;m terrified that our craft will die, and nobody will even care to mourn it.</p> <h2>ðŸ¦” ðŸ¦” ðŸ¦”</h2> <center><sub><time>2026-02-08</time>  â€¢ <a href="https://mastodon.social/@Ezhik/116034520904489092">Discuss on Mastodon</a> â€¢ <a href="https://bsky.app/profile/did:plc:png3xhpd6ccblcrcrxsxmfrs/post/3medprdipoc2l">Discuss on Bluesky</a></sub></center></article></main></div></div>
  </body>
</html>
