<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/">Original</a>
    <h1>Piccolo – A Stackless Lua Interpreter</h1>
    
    <div id="readability-page-1" class="page"><div>
    

<p><strong>2024-05-01</strong></p>

    <ul>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#history-of-piccolo">History of piccolo</a>
            
        </li>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#a-stackless-interpreter-design">A &#34;Stackless&#34; Interpreter Design</a>
            
        </li>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#benefits-of-stackless">Benefits of Stackless</a>
            
                <ul>
                    
                        <li>
                            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#cancellation">Cancellation</a>
                        </li>
                    
                        <li>
                            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#pre-emptive-concurrency">Pre-emptive Concurrency</a>
                        </li>
                    
                        <li>
                            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#fuel-pacing-and-custom-scheduling">Fuel, Pacing, and Custom Scheduling</a>
                        </li>
                    
                        <li>
                            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#symmetric-coroutines-and-coroutine-yieldto">&#34;Symmetric&#34; Coroutines and coroutine.yieldto</a>
                        </li>
                    
                </ul>
            
        </li>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#the-big-lie">The &#34;Big Lie&#34;</a>
            
        </li>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#rust-coroutines-lua-coroutines-and-snarfing">Rust Coroutines, Lua Coroutines, and Snarfing</a>
            
        </li>
    
        <li>
            <a href="https://kyju.org/blog/piccolo-a-stackless-lua-interpreter/#zooming-out">Zooming Out</a>
            
        </li>
    
    </ul>

<hr/>


<p><a href="https://github.com/kyren/piccolo">piccolo</a> is an interpreter for the Lua
language written in pure, mostly safe Rust with an eye towards safe sandboxing
and resiliency. It uses <a href="https://github.com/kyren/gc-arena">gc-arena</a> for its
garbage collection system, and in fact <code>gc-arena</code> was originally created as part
of <code>piccolo</code>.</p>
<p>You can try it out below in an the interactive REPL. I&#39;m not much of a web
developer, and this is a little homegrown web terminal thingy, so hopefully this
works for you. I&#39;m going to be using REPLs like this to demonstrate a lot of
what makes <code>piccolo</code> unique, so if it doesn&#39;t work or you or you don&#39;t have
Javascript turned on, then this might be a pretty boring post and I&#39;m sorry!</p>
<p><strong>↓ Type Some Lua Here ↓</strong><span><sup><a data-aside="aside-1">[1]</a></sup><span id="aside-1">You know, if you want to...</span></span>

</p>


<p>I find REPLs to be really magical and inviting,<span><sup><a data-aside="aside-2">[2]</a></sup><span id="aside-2"><img src="https://blog.jacobvosmaer.nl/0024-creativity-books/neat.png" alt="I just think they&#39;re neat okay"/></span></span>

and I end up eventually wanting to attach them to everything I ever make.<span><sup><a data-aside="aside-3">[3]</a></sup><span id="aside-3">It&#39;s possible to like things <em>too</em> much.</span></span>
 Not just a REPL
but the idea that your program is a sort of <em>Living Thing</em> that understands
a <em>Language</em>, and if the normal UI isn&#39;t fit for purpose and you&#39;re enough of
a <em>Witch</em>, you can always just <em>Speak</em> to the program in the way it naturally
understands... cast a <em>Spell</em> to achieve your <em>Goals</em>, or maybe just have a
<em>Conversation</em>. I think it helps close the gap between the author of a program
and the user. I&#39;m not better than the user, who am I to tell them what they can
and can&#39;t say to the program?</p>
<p>I hope you feel the same way about REPLs as I do because there are a lot of them
on this page, and I&#39;m going to ask you to type things into them. If you&#39;re not
into it, well... I&#39;ll try and always give you working code that you can copy and
paste, but where&#39;s the fun in that?</p>
<hr/>
<p>I said in my <a href="https://kyju.org/blog/rust-safe-garbage-collection/">last post in this series</a>
that my goal wasn&#39;t to try to sell anyone on <code>gc-arena</code> or <code>piccolo</code><span><sup><a data-aside="aside-4">[4]</a></sup><span id="aside-4"><em>yet</em> anyway</span></span>
 and I think that&#39;s still true here. <code>piccolo</code> is pretty
rough around the edges<span><sup><a data-aside="aside-5">[5]</a></sup><span id="aside-5">which you probably noticed if you tried to
use large parts of the stdlib in the REPL above</span></span>
 right now, but it&#39;s
more complete than you might think<span><sup><a data-aside="aside-6">[6]</a></sup><span id="aside-6">The implementation strategy so
far has been to do the hardest parts first to prove that the basic idea works,
so most of really hard parts of the VM are feature complete.</span></span>
 and it
has some interesting and unique features. Still, I&#39;m not telling you to go out
and replace <a href="https://luajit.org">LuaJIT</a> or <a href="https://luau-lang.org/">Luau</a> or
<a href="https://lua.org">The Ur Lua</a> with <code>piccolo</code> just yet.</p>
<p>In this post, I  just want to talk about what makes <code>piccolo</code> special, and
hopefully you&#39;ll find it interesting. In a future post, I&#39;m going to tie all of
this together, the way <code>gc-arena</code> and <code>piccolo</code> are designed, how they work now,
and how I <em>wish</em> they could work in the future, but this post is going to focus
just on <code>piccolo</code> as it works right now.</p>
<h2 id="history-of-piccolo">History of <code>piccolo</code></h2>
<p>When I was first writing <code>piccolo</code> (in 2019), I had noticed that nobody had
quite figured out how to make VMs for certain kinds of languages that could be
competitive with C while being implemented primarily in safe Rust. Mostly I&#39;m
referring to problems surrounding garbage collection, rather than something like
designing fast interpreter loops (which is something I&#39;m not very good at yet!).</p>
<p>Languages that have ownership semantics similar to Rust are of course much
easier to write VMs for <em>in</em> Rust, because the implemented language can
<em>snarf</em><span><sup><a data-aside="aside-7">[7]</a></sup><span id="aside-7">my absolute favorite PLT jargon</span></span>
 much of the
functionality from the host language. It&#39;s pretty easy to express the exact
semantics of <code>Rc</code> by just... using <code>Rc</code> itself to implement the language. There
are several such scripting languages that try to have matching ownership and
mutability semantics with Rust and I think that&#39;s honestly a great idea because
sharing these core semantics with the host language just removes a huge amount
of cognitive burden when crossing the language boundary, and you can make an
embedded language this way that feels like it fits in perfectly with the host.</p>
<p><em>However</em>, I also think it&#39;s a bit of a disappointment if only Rust-like
languages can be easily made using Rust. Certainly this is not actually true,
and there are plenty of other Rust runtimes for languages with &#34;unrestricted
ownership&#34; (proper garbage collection, unrestricted references... the terms for
this are a bit all over the place, but what I <em>mean</em> is languages like Lua).
At the time at least, when I surveyed language runtimes written in Rust they
broadly fell into one of several categories, none of which was what I wanted
for <code>piccolo</code>...</p>
<ol>
<li>Languages with ownership semantics similar to Rust, so no &#34;true garbage
collection&#34; / &#34;unrestricted ownership&#34; or whatever you want to call it
(<a href="https://github.com/pistondevelopers/dyon">dyon</a>,
<a href="https://github.com/rune-rs/rune">rune</a>, etc...)</li>
<li>Language runtimes with true garbage collection (tracing or generational
collector) but whose implementations were <em>wildly</em>, <em>infectiously</em> unsafe as
they would be in C, due to the nature of garbage collected pointers and their
interactions with the Rust stack.</li>
<li>Language runtimes for languages that are meant to have proper garbage
collection but the implementer used <code>Rc</code> or similar and left the problem of
what to do about reference cycles for later
(<a href="https://github.com/RustPython/RustPython/issues/4181">RustPython</a>).</li>
</ol>
<p>I wanted to have a language for Rust that felt as natural as Lua does for C,
<em>and</em> one that had true garbage collection<span><sup><a data-aside="aside-8">[8]</a></sup><span id="aside-8"><em>and</em> I have extremely bad
NIH syndrome</span></span>
... and frankly I really like just plain vanilla Lua. I
think it matches perfectly with Rust <em>because</em> they&#39;re so different, I think
having an Rust embedded language that frees you from even having to <em>think</em>
about ownership is very powerful because it can be used for things where having
to think about ownership can be more trouble than its worth. Let each language
play to their strengths, and Rust and Lua in a lot of ways have complementary
strengths.</p>
<p>Since I just looooove Lua so much and I had so much experience with vanilla
PUC-Rio Lua (aka <a href="https://lua.org">The Ur Lua</a>), I decided to try and write an
interpreter designed similarly to<span><sup><a data-aside="aside-9">[9]</a></sup><span id="aside-9">shamelessly stolen from</span></span>

PUC-Rio&#39;s Lua, with a similar sort of garbage collector, but because I was
primarily interested in sandboxing untrusted scripts, <em>somehow</em> made of mostly
safe Rust.<span><sup><a data-aside="aside-10">[10]</a></sup><span id="aside-10">or at least not like
<a href="https://github.com/luau-lang/luau/blob/e76802f2ce698ca090a793b24c07e336b21ade9f/VM/src/lvmexecute.cpp#L26">this</a></span></span>
 <code>gc-arena</code> was born out of my efforts to solve this problem.</p>
<p>But I <em>really</em> don&#39;t intend to throw any shade at any of the projects I listed
above or any other Rust-implemented language runtime written in a different
style. These are hard problems and <code>gc-arena</code> is <em>not</em> a perfect solution.
In fact, in the early days of <code>gc-arena</code> and <code>piccolo</code>, I ran into so many
seemingly unsolvable problems that I became hopelessly frustrated and gave up on
<code>piccolo</code> entirely for about <em>four years</em>.</p>
<img src="https://blog.jacobvosmaer.nl/0024-creativity-books/hiatus.png" title="Portrait of Frustration" width="100%"/>
<p>It was only through <a href="https://github.com/ruffle-rs/ruffle">Ruffle</a>&#39;s use of
<code>gc-arena</code> and Ruffle contributors helping to get through the roadblocks we
encountered that I was eventually able to pick <code>piccolo</code> back up. Today, there
are not <em>nearly</em> so many unsolved problems in trying to use <code>gc-arena</code> to
implement a language like Lua or ActionScript, but it really came down
to <code>Ruffle</code> contributors helping to solve each issue one by one over the
intervening years.</p>
<p>BUT, even with all of the major roadblocks overcome (pointers to <code>Unsize</code> types,
GC finalization, non-&#39;static <code>Any</code>, a bunch more I&#39;ve forgotten) influence from
the biggest limitation of <code>gc-arena</code> stubbornly remained: the &#34;Mutation XOR
Collection&#34; design of <code>gc-arena</code> that was talked about in the 
<a href="https://kyju.org/blog/rust-safe-garbage-collection/">last post</a>. <code>gc-arena</code>&#39;s design
requires that code that wants to access garbage collected data do so through
special <em>mutation</em> methods, and that <em>collection</em> must ONLY happen when no
<em>mutation</em> methods are executing.</p>
<p>This &#34;Mutation XOR Collection&#34; design means that calls to <code>Arena::mutate</code>
must <em>return</em> before garbage collection can safely take place, to prove that
no garbage collected pointers exist anywhere on the Rust stack. Unless I were
willing to just give up on ever hoping to match Lua runtimes written in C, or
were willing to limit the places <code>piccolo</code> could be used,<span><sup><a data-aside="aside-11">[11]</a></sup><span id="aside-11">If I were
making a runtime that was more limited in purpose, I could instead limit garbage
collection to, say, once a frame if I were making a video game or something like
Ruffle, or just simply require that continuous execution of Lua not go on
for &#34;too long&#34;, but this would make <code>piccolo</code> much less <em>general</em>.</span></span>

I had to figure out a way to make the entire execution context of <code>piccolo</code>
<em>suspendable</em>, just to be able to leave calls to <code>Arena::mutate</code>, so that
garbage collection could take place at arbitrary points.</p>
<p>At the beginning, this limitation <em>infuriated</em> me, and I spent ages trying
<strong>anything</strong> I could to find an acceptable way around it. It still certainly
is limiting, but now that <code>piccolo</code> has gotten further along I think what I&#39;ve
ended up with is actually very cool, and what started out as purely a painful
compromise might actually end up being <code>piccolo</code>&#39;s &#34;killer feature&#34;...</p>
<h2 id="a-stackless-interpreter-design">A &#34;Stackless&#34; Interpreter Design</h2>
<p>Some of the biggest, most interesting features of <code>piccolo</code> come from its
&#34;stackless&#34; design, originally born only from necessity due to the limitations
of <code>gc-arena</code>. This design is similar to other &#34;stackless&#34; interpreters, and
the one most people have heard of is
<a href="https://github.com/stackless-dev/stackless/wiki/">Stackless Python</a>, so if
you&#39;re familiar with it, most of what you know will be applicable to <code>piccolo</code>
as well.</p>
<p>&#34;Stackless&#34; here is jargon that&#39;s used in a couple of places, not just in
interpreter design. You may have heard that Rust has &#34;stackless&#34; coroutines,
and the word &#34;stackless&#34; as I&#39;m using it here means the exact same thing. It
means that piccolo&#39;s Lua runtime is not &#34;stackful&#34;, it does not rely on the
Rust function call stack to maintain its execution state, and execution can be
suspended at any time. This applies not just for plain interpreted Lua bytecode
but also for Rust code executed from Lua (callbacks) in any form, for any
depth of Lua -&gt; Rust -&gt; Lua calls. The overriding design decision made early in
piccolo&#39;s life was that execution of Lua (and ALL callback code called from Lua)
must always be able to be suspended, and that execution would be driven from the
outside by polling:</p>
<pre data-lang="rust"><code data-lang="rust"><span></span><span></span><span>
</span><span></span><span></span><span></span><span><span>let</span> execution_state <span>=</span> <span>...</span><span>;</span>
</span><span>
</span><span></span><span></span><span><span>loop</span> <span><span>{</span>
</span></span><span><span>    <span>match</span> execution_state<span>.</span><span>poll</span><span><span>(</span></span><span><span>)</span></span> <span><span>{</span>
</span></span></span><span><span><span>        <span>None</span> <span>=&gt;</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>            </span></span></span></span><span><span><span><span>            </span></span></span></span><span><span><span><span>            </span></span></span></span><span><span><span><span>        </span><span><span>}</span></span>
</span></span></span><span><span><span>        <span>Some</span><span><span>(</span>result</span><span><span>)</span></span> <span>=&gt;</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>            </span></span></span></span><span><span><span><span>            </span></span></span></span><span><span><span><span>            <span>break</span><span>;</span>
</span></span></span></span><span><span><span><span>        </span><span><span>}</span></span>
</span></span></span><span><span><span>    </span><span><span>}</span></span>
</span></span><span><span></span><span><span>}</span></span>
</span></code></pre>
<p>This should be <em>extremely</em> familiar to anyone who has ever touched Rust futures,
and the similarity is no accident. The core of the design of <code>piccolo</code> is
virtually the same as Async Rust: that all long running operations are reified
into objects that must be <em>polled to completion</em>.</p>
<p>The obvious benefit for <code>piccolo</code> is that it becomes trivial now to exit a call
to <code>gc_arena::Arena::mutate</code> and allow for collection, since we can now do so
in-between calls to <code>execution_state.poll()</code>.<span><sup><a data-aside="aside-12">[12]</a></sup><span id="aside-12">In reality this is
<code>piccolo::Executor::step</code>, but I wanted to show the similarity to normal Rust
futures.</span></span>
 What I didn&#39;t fully appreciate when I began writing <code>piccolo</code>
is that this style of writing an interpreter, though at times more difficult,
comes with <em>many</em> other benefits that make it (in my opinion) a worthwhile goal,
or at least a very interesting place in the design space and I hope a unique
niche that piccolo can fill.</p>
<h2 id="benefits-of-stackless">Benefits of Stackless</h2>
<h3 id="cancellation">Cancellation</h3>
<p>An obvious side benefit of polling execution in the style of <code>Future</code> is that,
just like a <code>Future</code>, execution can be canceled at any time by just... not
continuing to call <code>poll</code>.</p>
<p>Let&#39;s go back to the REPL from above, but this time, let&#39;s see what happens when
we run some Lua code that never returns.</p>
<p>If you don&#39;t know much Lua, try typing something like:</p>
<pre data-lang="lua"><code data-lang="lua"><span><span>while</span> <span>true</span> <span><span>do</span> <span>end</span></span>
</span></code></pre>
<p>or maybe</p>
<pre data-lang="lua"><code data-lang="lua"><span><span><span>repeat</span>
</span></span><span><span>    <span>print</span><span><span><span>(</span><span><span>&#34;</span>Look Around You<span>&#34;</span></span><span>)</span></span></span>
</span></span><span><span></span><span>until</span> <span>false</span>
</span></code></pre>
<p><strong>↓ Just Endlessly Do It ∞ ↓</strong>
</p>


<p>You should see a big <strong>interrupt</strong> button appear, and when you press it, the
command should stop. How this works under the hood in this demo is that inside
this webpage there is some javascript that looks something like this:</p>
<pre data-lang="javascript"><code data-lang="javascript"><span><span>this</span><span>.</span><span>interval</span> <span>=</span> <span><span>setInterval</span></span><span>(</span><span>(</span><span><span><span>(</span><span>)</span></span> </span><span><span>=&gt;</span> <span><span>{</span>
</span></span></span><span><span><span>    <span>if</span> <span>(</span><span><span>this</span><span>.</span><span>executor</span><span>.</span><span>step</span></span><span>(</span><span>8192</span><span>)</span><span>)</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        <span><span>this</span><span>.</span><span>finish</span></span><span>(</span><span>)</span><span>;</span>
</span></span></span></span><span><span><span><span>    <span>}</span></span>
</span></span></span><span><span><span><span>}</span></span></span><span>)</span><span><span>.</span><span>bind</span></span><span>(</span><span>this</span><span>)</span><span>,</span> <span>0</span><span>)</span><span>;</span>
</span></code></pre>
<p>This is the &#34;poll loop&#34; that we talked about above that polls running
Lua code to completion. This is still not exactly how it would look when
using <code>piccolo</code> directly but it&#39;s a little closer... The <code>executor</code> there is
a <code>piccolo::Executor</code> object,<span><sup><a data-aside="aside-13">[13]</a></sup><span id="aside-13">Well, it&#39;s a simplified wrapper for
Javascript</span></span>
 and <code>Executor::step</code> is called in a loop until the code
has completed. Here, Lua execution actually hooks into the normal Javascript
event loop, every time the closure is run, the <code>piccolo::Executor</code> is &#34;stepped&#34;
for <code>8192</code> &#34;steps&#34;. The &#34;steps&#34; value here is referred to inside <code>piccolo</code> as
&#34;fuel&#34; and (more or less) corresponds to a number of Lua VM instructions to run
before returning. Since the timeout given to <code>setInterval</code> is <code>0</code>, we run this
function regularly and rapidly but without blocking the main Javascript event
loop. When the <strong>interrupt</strong> button is pressed, the interval is canceled and
the executor is dropped, interrupting execution. In fact, every REPL on the page
works in the same way and shares the main Javascript event loop, so all of them
can execute Lua code concurrently.</p>
<p>Interruptable Lua code is not something new to <code>piccolo</code>, PUC-Rio Lua (and most
of its forks) have something like this in the form of
<a href="https://www.lua.org/manual/5.4/manual.html#lua_sethook">lua_sethook</a>. This
function allows you to, among a few other things, set &#34;hook&#34; function that runs
every <code>count</code> VM instructions, and one of the things this function can do when
run is interrupt running code by calling e.g.
<a href="https://www.lua.org/manual/5.4/manual.html#lua_error">lua_error</a>.<span><sup><a data-aside="aside-14">[14]</a></sup><span id="aside-14">If you also know that you can call
<a href="https://www.lua.org/manual/5.4/manual.html#lua_yield">lua_yield</a> from a hook
function and mimic what <code>piccolo</code> tasklets do, I know that too, <em>wait just a
bit</em> and I&#39;ll talk about it.</span></span>
So we can imagine a situation in which we
can set up something similar to what <code>piccolo</code> is doing here, either by running
Lua code in a different thread and waiting for an <code>interrupt</code> flag to be set in
the hook function, or by pumping an event loop from within the hook function or
something similar.<span><sup><a data-aside="aside-15">[15]</a></sup><span id="aside-15">If you&#39;re internally screaming about calling
<code>lua_yield</code> from a hook, <em><strong>wait</strong></em>.</span></span>
</p>
<p>However, I would argue that the way <code>piccolo</code> is structured makes this
effortless and natural due to its stackless design. Since PUC-Rio Lua is written
in normal, stackful style, the best thing it can offer is a hook function that
will be periodically called by the VM loop, whereas with <code>piccolo</code> the user
never <em>loses control</em> to the VM in the first place. <code>piccolo</code> is designed such
that a call to <code>Executor::step</code> should <em>always</em> return in a reasonable, bounded
amount of time proportional to the &#34;fuel&#34; it is given,<span><sup><a data-aside="aside-16">[16]</a></sup><span id="aside-16">Ensuring
this is true in <em>all</em> cases so that it can be relied on as a security boundary
is complex and a WIP, but is 100% a goal of <code>piccolo</code>.</span></span>
 so it is not
necessary to provide an equivalent to <code>lua_hook</code> at all.</p>
<h3 id="pre-emptive-concurrency">Pre-emptive Concurrency</h3>
<p>One of Lua&#39;s best and most defining features is its support for coroutines.
Coroutines in Lua can be used to provide seamless <em>cooperative</em> multitasking,
and are especially powerful for things like game development where some kind of
<em>script</em> must execute concurrently with the running simulation of a video game.</p>
<p>However, Lua coroutines only provide <em>cooperative</em> multitasking, the script must
decide where and when to yield control to the caller, and a buggy (or malicious)
script that does not yield control may need to be interrupted and canceled (via
<code>lua_sethook</code>) or might make the game hang.</p>
<p>Rust (at least, unstable Rust) also has coroutines, and they are used behind
the scenes to implement async. In Rust, like in Lua, these coroutines provide
<em>cooperative</em> multitasking, Rust code must decide when to call <code>await</code>,
or an implementation of <code>Future::poll</code> must decide when to return. A buggy
implementation of <code>Future</code> will hang an async executor thread just like a buggy
Lua coroutine might hang a game loop.</p>
<p>In <code>piccolo</code>, running Lua code acts very similarly to a Rust &#34;task&#34; (a term for
something that implements <code>Future</code> and is run on an async &#34;executor&#34;), and like
Rust tasks, they can easily be run concurrently. However, <code>piccolo</code> works very
hard to <em>guarantee</em> that <code>piccolo::Executor::step</code> returns in a bounded amount
of time, even <em>without</em> the cooperation of the running Lua code. So, by using
several independent <code>piccolo::Executor</code> &#34;tasklets&#34; and multiplexing calls to
each <code>piccolo::Executor::step</code>, we can give Lua <em>pre-emptive multitasking</em>.</p>
<p>It&#39;s easier to understand with a demonstration. The two REPLs below are
connected to <em>one</em> Lua instance. Instead of a single <code>print</code> function, they have
the functions <code>print_left</code> and <code>print_right</code> to print in the left or right REPL
console. They share global variables, so we can use this to demonstrate that the
two interfaces are running Lua code on the same VM.</p>
<p>In the left REPL, type something like this</p>
<pre data-lang="lua"><code data-lang="lua"><span><span>i</span> <span>=</span> <span>0</span>
</span><span><span>while</span> <span>true</span> <span><span>do</span>
</span></span><span><span>    <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span>
</span></span><span><span><span>end</span></span>
</span></code></pre>
<p>While that is running in the left REPL, in the right REPL type this:</p>
<pre data-lang="lua"><code data-lang="lua"><span><span>while</span> <span>true</span> <span><span>do</span>
</span></span><span><span>    <span>print_right</span><span><span><span>(</span><span>i</span><span>)</span></span></span>
</span></span><span><span><span>end</span></span>
</span></code></pre>
<p><strong>↓ These two REPLs are connected to the same <code>Lua</code> instance! ↓</strong>
</p>


<p>You should notice that it appears that two separate Lua REPLs access the same
state, seemingly in parallel! In fact, if you copied the exact code above, the
right REPL probably prints values of <code>i</code> seemingly at random, every thousand and
a half or so increments.</p>
<p>In this demo, this behavior comes from the way that running Lua code is run
inside <code>setInterval</code> callbacks... The REPLs here work exactly the same as any
of the REPLs above <em>except</em> that they both share a Lua instance, and this
really is the only difference. There are two <code>setInterval</code> callbacks calling
<code>Executor::step</code> being run by the browser at the same time and each callback
is run in a round-robin fashion.<span><sup><a data-aside="aside-17">[17]</a></sup><span id="aside-17">I actually don&#39;t know how the
task scheduler in browsers works <em>exactly</em>, but I think it will execute
both REPLs in a simple round-robin way?</span></span>
 In a plain Rust environment
you could get the same behavior by looping and calling <code>Executor::step</code> for
one executor then another in turn, in a simple round-robin scheduler. This is
very similar in a way to OS threads which also are pre-emptively scheduled, but
instead of using an OS scheduler, we write our own scheduler and execute some
running Lua for a <em>time slice</em> via calls to <code>Executor::step</code>.<span><sup><a data-aside="aside-18">[18]</a></sup><span id="aside-18">This
idea is not new, and other stackless interpreters have called this scheduling
idea <a href="https://github.com/stackless-dev/stackless/wiki/Tasklets">tasklets</a>.</span></span>
 In fact, though you can&#39;t observe actual <em>data races</em> here or even an
analogue of it within Lua, you can observe a mirror of other <em>race condition</em>
problems that OS concurrency primitives are meant to solve, and a custom
scheduler for these Lua &#34;tasklets&#34; might even want to provide a version of
common OS primitives to prevent them and aid scheduling.<span><sup><a data-aside="aside-19">[19]</a></sup><span id="aside-19">Stackless
Python has a custom version of
<a href="https://github.com/stackless-dev/stackless/wiki/Channels">channels</a> to
communicate between tasklets that serves this purpose, but I don&#39;t actually know
whether these channels affect tasklet scheduling (but they could!).</span></span>
</p>
<p>This is <em>also</em> again, VERY similar to how rust Futures (well, tasks) work when
running on an async executor. Async tasks can be round robin scheduled <em>or</em> in
some more advanced way, but each task has a &#34;slice&#34; of execution given to
it by calling its <code>Future::poll</code> method. The difference in <code>piccolo</code> is that
Lua scripts are not actually <em>aware</em> that they are being scheduled this way,
and <em>from the perspective of Lua</em>, this scheduling happens pre-emptively. Rust
<em>callbacks</em> in <code>piccolo</code> are more privileged than this and actually receive a
<code>piccolo::Fuel</code> object that they can use to consume fuel proportional to their
work, and must be trusted to cooperatively schedule themselves (you can always
incorrectly write <code>loop {}</code> in a callback, after all), but <em>Lua code</em> cannot
break out, at least not on its own.</p>
<p>Yet another way to look at this is that <code>piccolo</code> executes Lua code <em>sort of</em>
as if there are something like invisible <code>coroutine.yield</code> statements inserted
everywhere, but ones that operate on a different level of abstraction from the
real <code>coroutine.yield</code>, ones which regular Lua code cannot interact with.</p>
<p>Let&#39;s imagine we transformed the above code that I asked you to type in the
paired REPLs into something like this in plain Lua:</p>
<pre data-lang="lua"><code data-lang="lua"><span></span><span></span><span></span><span><span><span><span>function</span> <span><span>coroutine_example</span></span><span><span>(</span><span>)</span></span>
</span></span></span><span><span><span>    <span>local</span> <span>i</span> <span>=</span> <span>0</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>local</span> <span>co1</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>local</span> <span>co2</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span>i</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span><span><span><span><span>        <span>coroutine</span><span>.</span><span><span>resume</span></span><span><span><span>(</span><span>co1</span><span>)</span></span></span>
</span></span></span></span><span><span><span><span>        <span>coroutine</span><span>.</span><span><span>resume</span></span><span><span><span>(</span><span>co2</span><span>)</span></span></span>
</span></span></span></span><span><span><span><span>    <span>end</span></span>
</span></span></span><span><span><span><span>end</span></span></span>
</span></code></pre>
<p><strong>↓ The above code is loaded here you want to run it ↓</strong>
</p>


<p>This behaves <em>sort of</em> like the code above but in a much more predictable way.
If you know Lua and are comfortable with coroutines, you can probably tell that
the above code is pretty much just a convoluted version of a simple for loop,
but it&#39;s enough to demonstrate the idea. We have two coroutines that execute
their own loops independent of each other and we schedule between them, but this
time we require that the body of the coroutines <em>decide</em> where to yield to the
scheduler to allow the other task to run. Stackless execution in <code>piccolo</code> is
<em>almost</em> the same as if we could painlessly <em>automatically</em> insert these calls
to <code>coroutine.yield</code> everywhere in the body of our running Lua tasks and use
this to pre-emptively rather than cooperatively schedule them.</p>
<h3 id="fuel-pacing-and-custom-scheduling">Fuel, Pacing, and Custom Scheduling</h3>
<p>In the last section where I transformed the code executed in the concurrent
REPLs into basic Lua coroutines, you may have noticed a big difference between
the two. In the first example, the scheduling between the two Lua REPLs was
somewhat random and hard to discern, the left REPL would increment the <code>i</code> value
more than a thousand times for every time the right REPL printed the value of
<code>i</code>, but in the second example the first task would increment the <code>i</code> value once
for every time the second task printed <code>i</code>. The reason for this has to do with
how the javascript for this page is actually written, but it&#39;s a perfect, simple
example of something using <code>piccolo</code> enables: custom tasklet scheduling.</p>
<p>I&#39;ve mentioned &#34;fuel&#34; before in the context of <code>piccolo::Executor::step</code>. Here
is the <em>real</em> signature of <code>Executor::step</code> inside <code>piccolo</code>:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span><span>impl</span> </span><span><span>Executor</span> </span><span><span><span>{</span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span><span>pub</span> <span>fn</span> </span><span>step</span></span><span><span><span>(</span><span>self</span>, <span>ctx</span><span>:</span> <span>Context<span>&lt;</span><span>&#39;gc</span><span>&gt;</span></span>, <span>fuel</span><span>:</span> <span>&amp;</span><span>mut</span> Fuel</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>bool</span></span> </span><span><span><span>{</span>
</span></span></span></span></span><span><span><span><span><span>        <span>...</span>
</span></span></span></span></span><span><span><span><span><span>    </span><span><span>}</span></span></span>
</span></span></span><span><span><span></span><span><span>}</span></span></span>
</span></code></pre>
<p>The method requires a <code>fuel: &amp;mut Fuel</code> parameter to, well, &#34;fuel&#34; the VM, and
the running VM <em>consumes</em> this fuel as it runs. <code>Fuel</code> is a very simple wrapper
around an <code>i32</code> value (you can see the current implementation
<a href="https://github.com/kyren/piccolo/blob/973951add4ad02d4fe5c0b27079ce342464a80c2/src/fuel.rs#L9">here</a>),
that is decremented by <code>Executor</code> as it runs Lua code, and also optionally by
<em>any Rust callback</em> that it calls. <code>piccolo</code>&#39;s ultimate goal is to enable
treating all loaded Lua code as potentially malicious, but Rust callbacks
are <em>never</em> on the other side of this security boundary. Callbacks are meant
to <em>cooperate</em> with the execution system of <code>piccolo</code> and act as part of the
security boundary to potentially malicious Lua, and as such, they can consume
<code>Fuel</code> or even &#34;interrupt&#34; the &#34;flow&#34; of fuel to the <code>Executor</code> that calls them.</p>
<p>This system makes a lot of sense to provide, and not only strictly for
<em>security</em>. <code>piccolo</code>&#39;s goal is to enable Lua tasks to <em>run concurrently</em> not
only with Rust but with each other, and as such there are many ways we we might
want to give certain tasks more or less time to run. We could imagine a game
engine where we want to provide a sandbox for running Lua code such that <em>no
matter what</em>, if the script is badly written or buggy, that the game simulation
can continue without being compromised. Tasks could be scheduled such that
they are assigned a certain amount of fuel &#34;per second&#34; up to a predefined
&#34;tank limit&#34;, giving them a kind of &#34;burst&#34; fuel. In this way, a task that
periodically needs a lot of computational power can get it, but a <em>broken</em> task
that has infinite looped will always use a much smaller amount of sustainable
fuel per frame.<span><sup><a data-aside="aside-20">[20]</a></sup><span id="aside-20">You could get funky with this too, make game
entities that have scripts attached that always use the maximum fuel get
<em>hot</em> in game and make that have a gameplay effect. This might only be fun in
something like ComputerCraft... or maybe it&#39;s not fun at all and you shouldn&#39;t
listen to me about gamedev... probably the second one.</span></span>
</p>
<p>Besides just &#34;consuming&#34; fuel, another thing a Rust callback can do is
<em>interrupt</em> fuel. This is quite similar in behavior to just consuming all of
the remaining fuel so the difference isn&#39;t that important, but it exists to mesh
well with the use case described before, where we want to give tasks a
sizeable &#34;reserve tank&#34; of fuel. &#34;Interrupting&#34; fuel flow makes the outer
<code>Executor::step</code> <em>immediately</em> return to the Rust code calling it, no matter the
amount of fuel currently consumed. This is mostly useful for technical purposes,
for example if one Lua task is waiting on some event and cannot possibly
currently make any progress, or if some callback <em>must</em> return to the outer Rust
caller immediately to take effect.</p>
<p>This is what is happening on REPLs on this page when <code>print</code> is called! I
noticed when testing the REPL I was writing that calling <code>print</code> in a hot loop
slowed down the whole page quite a lot, and mostly just to create and destroy
a bunch of output <code>div</code>s faster than they could be read as the output went far
past the console scrollback limit. So, to fix this, I made <code>print</code> callbacks
in this page <em>always call <code>Fuel::interrupt</code></em> to make the page more responsive
during hot loops. When you call <code>print</code> in a REPL on this page, it immediately
yields control to the browser task queue! This is the sort of thing that having
deep control over VM scheduling allows you to do: <em>customize</em> it to make it
work in many different situations.<span><sup><a data-aside="aside-21">[21]</a></sup><span id="aside-21"><em>Yes</em> I know you can also use
<code>lua_yield</code> in a callback for the same effect, but crucially, that means you
<em>cannot</em> mix these callbacks with normal Lua coroutines. I&#39;m going to talk more
about this before the end, I promise.</span></span>
</p>
<h3 id="symmetric-coroutines-and-coroutine-yieldto">&#34;Symmetric&#34; Coroutines and <code>coroutine.yieldto</code></h3>
<p>It&#39;s tough to talk about coroutines because there tend to not be universally
agreed upon definitions, but I&#39;m going to try. You might want to have the
<a href="https://en.wikipedia.org/wiki/Coroutine">wikipedia article</a> on coroutines and
possibly <a href="https://dl.acm.org/doi/pdf/10.1145/1462166.1462167">this paper</a> open
if you want the full extra credit for this section.</p>
<p>Lua has what is usually referred to as &#34;asymmetric coroutines&#34;, which
are (as far as I can tell) the most commonly seen type of coroutine.
This is also the same sort of coroutine that Rust supports with the
(unstable)
<a href="https://doc.rust-lang.org/stable/std/ops/trait.Coroutine.html">std::ops::Coroutine</a>
trait. As such, this can feel like a fancy term for a simple idea, but it refers
to the limitation that coroutines yield <em>only to their caller</em>. It is also
possible to instead support fully &#34;symmetric&#34; coroutines that can yield <em>to any
other coroutine</em>, not just the calling one!</p>
<p>This is probably easier to understand expressed as a Lua function that <em>almost</em>
provides what we want. Symmetric coroutines work as if we had the following
function in Lua:</p>
<pre data-lang="lua"><code data-lang="lua"><span></span><span></span><span><span><span><span>function</span> <span><span>yieldto</span></span><span><span>(</span><span>co</span><span>)</span></span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>coroutine</span><span>.</span><span><span>resume</span></span><span><span><span>(</span><span>co</span><span>)</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span><span>end</span></span></span>
</span></code></pre>
<p>We want a function that can yield <em>to</em> another coroutine by resuming that
coroutine and yielding to the caller... whatever that other coroutine would
have yielded. The <em>problem</em> is that this function as written is a stack leak:
there is no way for normal Lua to &#34;tail yield&#34; like it can &#34;tail return&#34;, the
<code>yieldto</code> function as written will consume stack space for the current call to
<code>coroutine.resume</code>, only giving the stack space up when the stack of coroutines
eventually finishes. True symmetric coroutines do not have this limitation, and
can mutually yield to each other without bound.</p>
<p>Because of the way <code>piccolo</code>&#39;s <code>Executor</code> works, Lua control flow that might
normally be expressed as a Rust function call (such as a callback resuming
another coroutine) is <em>reified</em> into the structure of the <code>Executor</code>, and the
actual Rust control flow always &#34;jumps back up&#34; to <code>Executor::step</code>. This is
actually the origin of the term &#34;trampoline style&#34; when referring to stackless
interpreters, that control flow always &#34;jumps back&#34; to the same place. In
PUC-Rio Lua, <code>coroutine.resume</code> is a normal C function call, so it is impossible
to directly support this &#34;tail yield&#34; operation and avoid the stack leak, but
<code>piccolo</code>&#39;s design <em>just</em> so happens to allow easily providing this as a builtin
function: <code>coroutine.yieldto</code>, enabling full symmetric coroutines!</p>
<p>Let&#39;s see how it works...</p>
<pre data-lang="lua"><code data-lang="lua"><span></span><span><span><span><span>function</span> <span><span>browse_internet</span></span><span><span>(</span><span>)</span></span>
</span></span></span><span><span><span>    <span>local</span> <span>be_bored</span>
</span></span></span><span><span><span>    <span>local</span> <span>be_optimistic</span>
</span></span></span><span><span><span>    <span>local</span> <span>be_dooming</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_bored</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>I&#39;m bored, I think I&#39;ll mindlessly browse The Internet<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yieldto</span></span><span><span><span>(</span><span>be_optimistic</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_optimistic</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>Maybe The Internet won&#39;t be so bad this time<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yieldto</span></span><span><span><span>(</span><span>be_dooming</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_dooming</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>I think I need a break from The Internet<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yieldto</span></span><span><span><span>(</span><span>be_bored</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>coroutine</span><span>.</span><span><span>resume</span></span><span><span><span>(</span><span>be_bored</span><span>)</span></span></span>
</span></span></span><span><span><span><span>end</span></span></span>
</span></code></pre>
<p><strong>↓ You can run the 100% accurate Internet Simulator below ↓</strong>
</p>


<p>Now, unless you&#39;re already pretty familiar with coroutines (or for some
unearthly reason you decided to stop reading this and instead go carefully read
<a href="https://dl.acm.org/doi/pdf/10.1145/1462166.1462167">the paper I linked earlier</a>),
you might not know that &#34;symmetric&#34; and &#34;asymmetric&#34; coroutines are actually of
equivalent expressive power. Let&#39;s pretend that we don&#39;t have
<code>coroutine.yieldto</code> and transform the previous example a bit to make up for it.</p>
<pre data-lang="lua"><code data-lang="lua"><span></span><span><span><span><span>function</span> <span><span>browse_internet</span></span><span><span>(</span><span>)</span></span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span><span>function</span> <span><span>run_coroutines</span></span><span><span>(</span><span>co</span><span>,</span> <span>...</span><span>)</span></span>
</span></span></span></span></span><span><span><span><span><span>        </span></span></span></span></span><span><span><span><span><span>        </span></span></span></span></span><span><span><span><span><span>        </span></span></span></span></span><span><span><span><span><span>        </span></span></span></span></span><span><span><span><span><span>        <span>local</span> <span>_</span><span>,</span> <span>next</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>resume</span></span><span><span><span>(</span><span>co</span><span>,</span> <span>...</span><span>)</span></span></span>
</span></span></span></span></span><span><span><span><span><span>        <span>if</span> <span>not</span> <span>next</span> <span><span>then</span>
</span></span></span></span></span></span><span><span><span><span><span><span>            <span>return</span>
</span></span></span></span></span></span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span><span><span><span><span><span>        <span>return</span> <span>run_coroutines</span><span><span><span>(</span><span>next</span><span>)</span></span></span>
</span></span></span></span></span><span><span><span><span><span>    <span>end</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>local</span> <span>be_bored</span>
</span></span></span><span><span><span>    <span>local</span> <span>be_optimistic</span>
</span></span></span><span><span><span>    <span>local</span> <span>be_dooming</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_bored</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>I&#39;m bored, I think I&#39;ll mindlessly browse The Internet<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>be_optimistic</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_optimistic</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>Maybe The Internet won&#39;t be so bad this time<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>be_dooming</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>be_dooming</span> <span>=</span> <span>coroutine</span><span>.</span><span><span>create</span></span><span><span><span>(</span><span><span><span>function</span><span><span>(</span><span>)</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        <span>while</span> <span>true</span> <span><span>do</span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>print</span><span><span><span>(</span><span><span>&#34;</span>I think I need a break from The Internet<span>&#34;</span></span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>            <span>coroutine</span><span>.</span><span><span>yield</span></span><span><span><span>(</span><span>be_bored</span><span>)</span></span></span>
</span></span></span></span></span></span></span></span><span><span><span><span><span><span><span><span>        <span>end</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    <span>end</span></span></span><span>)</span></span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span>run_coroutines</span><span><span><span>(</span><span>be_bored</span><span>)</span></span></span>
</span></span></span><span><span><span><span>end</span></span></span>
</span></code></pre>
<p><strong>↓ After the above transform, our simulator is still 100% Accurate ↓</strong>
</p>


<p>So, the <code>coroutine.yieldto</code> function that <code>piccolo</code> provides doesn&#39;t <em>actually</em>
make Lua fundamentally any more powerful, instead it is more of a convenience.
So why bring this up? Well, besides it being a very <em>neat</em> function to be able
to provide, and <code>piccolo</code> being able to provide it in a way that <em>doesn&#39;t</em>
require any outside &#34;runner&#34;, I wanted to bring attention to the <em>idea</em> of
transforming code like this.</p>
<p>It&#39;s no coincidence that <code>piccolo</code> has an easy time providing
<code>coroutine.yieldto</code>. The above transform takes normal control flow and turns
it into control flow via <em>return values</em>. This is very nearly the <em>exact same</em>
transform that has already been done by <code>piccolo</code>&#39;s stackless design that I&#39;ve
been talking about this whole time.</p>
<p>In fact, let&#39;s look at the actual implementation of <code>coroutine.yieldto</code> in the code for
the <code>coroutine</code> lib inside <code>piccolo</code>:</p>
<pre data-lang="rust"><code data-lang="rust"><span>coroutine<span>.</span><span>set</span><span><span>(</span>ctx<span>,</span> <span><span>&#34;</span>yieldto<span>&#34;</span></span><span>,</span> <span>Callback<span>::</span></span>from_fn<span><span>(</span><span>&amp;</span>ctx<span>,</span> <span><span><span>|</span></span></span><span><span><span>ctx</span><span>,</span> _<span>,</span> <span>mut</span> <span>stack</span><span>|</span></span> </span><span><span><span>{</span>
</span></span></span></span></span><span><span><span><span><span>    <span>let</span> thread<span>:</span> Thread <span>=</span> stack<span>.</span><span>from_front</span><span><span>(</span>ctx</span><span><span>)</span></span><span>?</span><span>;</span>
</span></span></span></span></span><span><span><span><span><span>    <span>Ok</span><span><span>(</span><span>CallbackReturn<span>::</span></span>Yield <span><span>{</span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        to_thread<span>:</span> <span>Some</span><span><span>(</span>thread</span><span><span>)</span></span><span>,</span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        then<span>:</span> <span>None</span><span>,</span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>    </span><span><span>}</span></span></span><span><span>)</span></span>
</span></span></span></span></span><span><span><span><span><span></span><span><span>}</span></span></span></span><span><span>)</span></span></span><span><span>)</span></span><span>.</span><span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span></code></pre>
<p>Ignoring some of the unimportant details, we see that the <code>&#39;yieldto&#39;</code> field is
set to a callback function, and that callback function takes a single argument
of a <code>Thread</code>. Then, it returns an enum value <code>CallbackReturn::Yield</code> and states
which thread to yield to (the normal <code>coroutine.yield</code> function simply sets
<code>to_thread</code> to <code>None</code> instead). This is <em>exactly</em> the same as the transform that
we&#39;ve already done above, which shows why this is so simple for <code>piccolo</code> to
provide: <code>piccolo::Executor</code> <em>already works like this</em>.</p>
<h2 id="the-big-lie">The &#34;Big Lie&#34;</h2>
<p>So far I have talked a lot about <code>piccolo</code>&#39;s <em>unique</em> design, and how it allows
<code>piccolo</code> to have powers that other Lua interpreters <em>can&#39;t have</em>. I have been
lying to you! The actual truth is rather complicated, and you need the context
of everything I&#39;ve said so far to fully understand it.</p>
<p>The real truth is... PUC-Rio Lua can already sort of do about 70% of the same
things <code>piccolo</code> can do. In fact, <code>piccolo</code> is <strong>not</strong> uniquely designed at all,
it is the <em>natural conclusion</em> to the way PUC-Rio Lua already works.</p>
<p>Let&#39;s start by doing something that I think almost nobody who uses PUC-Rio Lua
or Luau or LuaJIT knows that they can do.<span><sup><a data-aside="aside-22">[22]</a></sup><span id="aside-22">LuaJIT is slightly more
complicated because you probably have to <em>disable the JIT</em> to make it work in
all cases.</span></span>
 We&#39;re going to implement tasklets using the plain Lua C API!</p>
<p>I don&#39;t have the energy to get normal PUC-Rio Lua 5.4 working in a browser with
Emscripten, so you won&#39;t be able to run these examples interactively, you&#39;ll
just have to trust me (or set up a C build environment with Lua 5.4 and try
them yourself). You&#39;ll also have to understand C and the PUC-Rio Lua C API to
fully understand these examples, but hopefully I can comment them enough to show
what&#39;s going on even if you don&#39;t.</p>
<pre data-lang="c"><code data-lang="c"><span><span><span>#include</span> <span><span>&lt;</span>assert.h<span>&gt;</span></span>
</span></span><span><span><span>#include</span> <span><span>&lt;</span>stdbool.h<span>&gt;</span></span>
</span></span><span>
</span><span><span><span>#include</span> <span><span>&#34;</span>lauxlib.h<span>&#34;</span></span>
</span></span><span><span><span>#include</span> <span><span>&#34;</span>lua.h<span>&#34;</span></span>
</span></span><span><span><span>#include</span> <span><span>&#34;</span>lualib.h<span>&#34;</span></span>
</span></span><span>
</span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span><span>void</span> <span><span>yield_hook</span></span><span><span><span>(</span></span></span><span><span>lua_State<span>*</span> <span>L</span><span>,</span> lua_Debug<span>*</span> <span>_ar</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
</span></span></span><span><span><span>    <span><span>lua_yield</span><span><span>(</span></span></span><span><span>L<span>,</span> <span>0</span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span></span></span><span><span><span>}</span></span></span>
</span><span>
</span><span><span>int</span> <span><span>main</span></span><span><span><span>(</span></span></span><span><span><span>int</span> <span>_argc</span><span>,</span> <span>char</span><span>*</span><span>*</span> <span>_argv</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    lua_State<span>*</span> L <span>=</span> <span><span>luaL_newstate</span><span><span>(</span></span></span><span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>    <span><span>luaL_openlibs</span><span><span>(</span></span></span><span><span>L</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    lua_State<span>*</span> co <span>=</span> <span><span>lua_newthread</span><span><span>(</span></span></span><span><span>L</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span>assert</span><span><span>(</span></span></span><span><span>
</span></span></span></span></span><span><span><span><span><span>        <span><span>luaL_loadstring</span><span><span>(</span></span></span><span><span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            co<span>,</span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>while true do<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>    print(&#39;hello&#39;)<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>end<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        </span></span><span><span><span>)</span></span></span>
</span></span></span></span></span><span><span><span><span><span>        <span>==</span> LUA_OK
</span></span></span></span></span><span><span><span><span><span>    </span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span>lua_sethook</span><span><span>(</span></span></span><span><span>co<span>,</span> yield_hook<span>,</span> LUA_MASKCOUNT<span>,</span> <span>256</span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span>while</span> <span><span>(</span><span>true</span><span>)</span></span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        <span>int</span> nresults<span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>assert</span><span><span>(</span></span></span><span><span><span><span>lua_resume</span><span><span>(</span></span></span><span><span>co<span>,</span> <span>NULL</span><span>,</span> <span>0</span><span>,</span> <span>&amp;</span>nresults</span></span><span><span><span>)</span></span></span> <span>==</span> LUA_YIELD</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>lua_pop</span><span><span>(</span></span></span><span><span>co<span>,</span> nresults</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>printf</span><span><span>(</span></span></span><span><span><span><span>&#34;</span>there<span>\n</span><span>&#34;</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>    <span>}</span></span>
</span></span></span><span><span><span></span></span><span><span><span>}</span></span></span>
</span></code></pre>
<p>The example above shows a fully working, if simplistic, Lua tasklet system.
In the same way that <code>piccolo</code>&#39;s <code>Executor::step</code> function works &#34;as though&#34;
there are invisible periodic calls to <code>coroutine.yield</code> everywhere, calling
<code>lua_yield</code> from a <code>lua_Hook</code> function <em>also</em> (and much more literally) inserts
invisible periodic calls to <code>coroutine.yield</code>. This is more or less everything
required for a tasklet!</p>
<p>PUC-Rio Lua can do about 70% of what <code>piccolo</code> can do, right out of the box! The
<em>problem</em> is the <strong>last 30%</strong>. Let&#39;s modify the example above <em>very slightly</em>...</p>
<pre data-lang="c"><code data-lang="c"><span><span><span>#include</span> <span><span>&lt;</span>assert.h<span>&gt;</span></span>
</span></span><span><span><span>#include</span> <span><span>&lt;</span>stdbool.h<span>&gt;</span></span>
</span></span><span>
</span><span><span><span>#include</span> <span><span>&#34;</span>lauxlib.h<span>&#34;</span></span>
</span></span><span><span><span>#include</span> <span><span>&#34;</span>lua.h<span>&#34;</span></span>
</span></span><span><span><span>#include</span> <span><span>&#34;</span>lualib.h<span>&#34;</span></span>
</span></span><span>
</span><span></span><span></span><span><span>void</span> <span><span>yield_hook</span></span><span><span><span>(</span></span></span><span><span>lua_State<span>*</span> <span>L</span><span>,</span> lua_Debug<span>*</span> <span>_ar</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
</span></span></span><span><span><span>    <span><span>lua_yield</span><span><span>(</span></span></span><span><span>L<span>,</span> <span>0</span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span></span></span><span><span><span>}</span></span></span>
</span><span>
</span><span><span>int</span> <span><span>main</span></span><span><span><span>(</span></span></span><span><span><span>int</span> <span>_argc</span><span>,</span> <span>char</span><span>*</span><span>*</span> <span>_argv</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    lua_State<span>*</span> L <span>=</span> <span><span>luaL_newstate</span><span><span>(</span></span></span><span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>    <span><span>luaL_openlibs</span><span><span>(</span></span></span><span><span>L</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    lua_State<span>*</span> co <span>=</span> <span><span>lua_newthread</span><span><span>(</span></span></span><span><span>L</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span>assert</span><span><span>(</span></span></span><span><span>
</span></span></span></span></span><span><span><span><span><span>        <span><span>luaL_loadstring</span><span><span>(</span></span></span><span><span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            co<span>,</span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>while true do<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>    table.sort({3, 2, 1}, function(a, b)<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>        for _ = 1,1000000 do end<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>        return a &lt; b<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>    end)<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>    print(&#39;hello&#39;)<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>            <span><span>&#34;</span>end<span>\n</span><span>&#34;</span></span>
</span></span></span></span></span></span></span><span><span><span><span><span><span><span>        </span></span><span><span><span>)</span></span></span>
</span></span></span></span></span><span><span><span><span><span>        <span>==</span> LUA_OK
</span></span></span></span></span><span><span><span><span><span>    </span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    </span></span></span><span><span><span>    <span><span>lua_sethook</span><span><span>(</span></span></span><span><span>co<span>,</span> yield_hook<span>,</span> LUA_MASKCOUNT<span>,</span> <span>256</span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span></span></span><span><span><span>    <span>while</span> <span><span>(</span><span>true</span><span>)</span></span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        <span>int</span> nresults<span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>assert</span><span><span>(</span></span></span><span><span><span><span>lua_resume</span><span><span>(</span></span></span><span><span>co<span>,</span> <span>NULL</span><span>,</span> <span>0</span><span>,</span> <span>&amp;</span>nresults</span></span><span><span><span>)</span></span></span> <span>==</span> LUA_YIELD</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>lua_pop</span><span><span>(</span></span></span><span><span>co<span>,</span> nresults</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>        <span><span>printf</span><span><span>(</span></span></span><span><span><span><span>&#34;</span>there<span>\n</span><span>&#34;</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
</span></span></span></span><span><span><span><span>    <span>}</span></span>
</span></span></span><span><span><span></span></span><span><span><span>}</span></span></span>
</span></code></pre>
<p>If you try and run this C code, it will immediately error on this <code>assert</code> in the main loop:</p>
<pre data-lang="c"><code data-lang="c"><span>        <span><span>assert</span><span><span>(</span></span></span><span><span><span><span>lua_resume</span><span><span>(</span></span></span><span><span>co<span>,</span> <span>NULL</span><span>,</span> <span>0</span><span>,</span> <span>&amp;</span>nresults</span></span><span><span><span>)</span></span></span> <span>==</span> LUA_YIELD</span><span><span>)</span></span></span><span>;</span>
</span></code></pre>
<p>The reason for this is that <code>lua_resume</code> is erroring and returns <code>LUA_ERRRUN</code>
instead of <code>LUA_YIELD</code>. This is happening because <code>lua_yield</code>, which is
being called from our &#34;hook&#34; function, <em>cannot be called from within most
C callbacks</em>. What is the C callback? It&#39;s our call to the stdlib function
<code>table.sort</code> within the body of the tasklet loop. At the time that the call to
<code>lua_yield</code> is called incorrectly, the C call stack looks something like this
(simplified):</p>
<p><code>main</code> -&gt; <code>lua_resume</code> -&gt; <code>luaV_execute</code> (the main VM loop) -&gt; <code>sort</code> (in
ltablib.c) -&gt; <code>lua_call</code> -&gt; <code>luaV_execute</code> (the main VM loop again, for the
comparator) -&gt; <code>yield_hook</code> -&gt; <code>lua_yield</code></p>
<p>PUC-Rio Lua uses the normal C stack for much of its internal state, and calls
to <code>lua_yield</code> are expressed as a C
<a href="https://en.cppreference.com/w/c/program/longjmp">longjmp</a>, jumping back up to
an upper C frame and popping any call frames in-between from the call stack.
So, certain operations are simply <em>disallowed</em> when the inner call to <code>longjmp</code>
would destroy essential information about the runtime state.</p>
<p>There IS a way around this problem, however. Ultimately, the problem is that
the call to <code>table.sort</code>, a C function, in turn calls a Lua function with the C
API function <code>lua_call</code>. Any Lua function called this way is <em>disallowed</em> from
calling <code>coroutine.yield</code> (or its C equivalent <code>lua_yield</code>). PUC-Rio&#39;s C API
provides a <em>special</em> version of <code>lua_call</code> to get around this:
<a href="https://www.lua.org/manual/5.4/manual.html#lua_callk">lua_callk</a>. You can read
in more detail about the entire situation in the section of the PUC-Rio Lua 5.4
manual called
<a href="https://www.lua.org/manual/5.4/manual.html#4.5">Handling Yields in C</a>.</p>
<p>This does work, and in this way, PUC-Rio Lua provides the ability to yield from
situations like this Lua -&gt; C -&gt; Lua sandwich. However, <code>table.sort</code> is not
written this way, and in fact none of the stdlib is written this way at all!
The reason for this is, frankly, that transforming C code to work this way
<em>is enormously difficult</em>. The C code in question must be able to handle a
<em><code>longjmp</code></em>, when the inner Lua code triggering a <code>longjmp</code> will <em>destroy</em>
(not even unwind!) the current C stack up to where it was called, and the only
way for the C code to resume is through the <code>lua_KFunction</code> and <code>lua_KContext</code>
passed to <code>lua_callk</code>. There are no <code>Drop</code> impls to rely on, no automatic memory
management, no coroutines, the C code must be transformed so that it relies
entirely on a type pointed to by a <code>lua_KContext</code> for its state, so that it can
be suspended at any time.<span><sup><a data-aside="aside-23">[23]</a></sup><span id="aside-23">This should sound familiar.</span></span>
</p>
<p>This is not the only problem, either. By repurposing normal Lua coroutine yields
like this to yield back to C, you <em>take away Lua coroutines from the usable part
of the Lua language</em>. If we were to try to use normal coroutines in our tasklet
system, the inner <code>lua_yield</code> from the hook function would just yield to the
nearest thing that has called <code>lua_resume</code>, which in this case would be the
<em>Lua thread</em> which called <code>coroutine.resume</code> and not the top-level C code. I
<strong>love</strong> coroutines,<span><sup><a data-aside="aside-24">[24]</a></sup><span id="aside-24">As much or more than I love REPLs!</span></span>
 and
Lua without coroutines is frankly no longer really Lua, but with enough effort,
I think you <em>could</em> get around this problem too! Remember the transform we did
before, where we made symmetric coroutines out of asymmetric ones? You can do
something similar with the normal Lua C API but wrapping <code>coroutine.yield</code> in
a special version that instead returned whether or not it is a <em>real</em> yield or
a synthetic one from the <code>lua_Hook</code> function. You would have to go further than
this to make it work, restructuring all of the other <code>coroutine</code> methods so that
which thread was waiting on the results of which other thread was kept in an
array rather than the C stack, so that the coroutine &#34;tasklet&#34; system continues
to work while providing a similar, inner system for &#34;normal&#34; Lua coroutines.</p>
<p>You could also do the work of re-implementing every single function in the
stdlib that calls back into Lua in such a way that it used <code>lua_callk</code> with a
continuation function instead of <code>lua_call</code>, too, so that every C function in
the stdlib became suspendable. For good measure, you could also periodically
yield long running callbacks even if they <em>didn&#39;t</em> call back into Lua, just to
make sure that execution always jumped back out to the outermost C code in a
bounded amount of time.</p>
<p>So lets summarize this list of theoretical changes we can make to PUC-Rio Lua to
make a <em>complete</em> tasklet system.<span><sup><a data-aside="aside-25">[25]</a></sup><span id="aside-25">The &#34;30%&#34; is obviously very
generous, in reality, the last 30% makes this &#34;vanilla&#34; tasklet system useless
in a huge number of cases. It&#39;s not that 30% of use cases are non-viable,
it&#39;s that 30% of the surface area of Lua no longer works, so <em>most</em> uses are
non-viable.</span></span>
</p>
<ol>
<li>Use <code>lua_Hook</code> functions to insert synthetic calls to <code>lua_yield</code> within all
Lua code.</li>
<li>Make <em>all</em> of the stdlib that calls Lua functions suspendable by using
<code>lua_callk</code> and continuations.</li>
<li>Reimplement the Lua <code>coroutine</code> library making it one level of abstraction
up from normal calls to <code>lua_yield</code>, so that normal Lua coroutines can still
work. We would need to implement <code>coroutine.resume</code> in a different way that
does not use the C stack. We can do a transform similar to implementing
&#34;symmetric&#34; coroutines over &#34;asymmetric&#34; ones here, where we implement
&#34;Lua&#34; coroutines over our lower level &#34;synthetic&#34; yielding. Lua calls to
<code>coroutine.yield</code> and <code>coroutine.resume</code> would now <em>both</em> be a yield to
the calling C code, and the yielded values would tell the outer C code what
to do next (whether to resume another coroutine or yield to whatever the
&#34;upper&#34; coroutine was). As a side effect, <code>coroutine.yieldto</code> becomes easy
to implement.</li>
<li>For good measure, keep track of some unit of time cost in all callbacks, and
insert calls to <code>lua_yieldk</code> in all long running callbacks so we know that
control will always return to the outer calling C code in a reasonable amount
of time.</li>
</ol>
<p>We have now reached, very roughly, the current design of <code>piccolo</code>.</p>
<h2 id="rust-coroutines-lua-coroutines-and-snarfing">Rust Coroutines, Lua Coroutines, and Snarfing</h2>
<p>In the previous section I laid out a rough explanation of how to transform
PUC-Rio Lua <em>as it exists today</em> and build a system similar to what <code>piccolo</code>
forces by design. However, I am not aware of <em>anyone</em> ever doing anything like
this on a grand scale.<span><sup><a data-aside="aside-26">[26]</a></sup><span id="aside-26">I <em>know</em> people do tasklet systems in PUC-Rio
Lua and Luau, but I think they limit the tasklet code to very <em>simple</em> Lua that
doesn&#39;t require completely rewriting the Lua stdlib.</span></span>
 The reason for
this, I think, is simple, and that is that it is just <em>monumentally hard</em> to
write C callbacks this way!</p>
<p>The <em>same problem</em> exists in <code>piccolo</code> though, which I alluded to near the
beginning of this post. In <code>piccolo</code>, long running callbacks are represented by
a trait called
<a href="https://github.com/kyren/piccolo/blob/973951add4ad02d4fe5c0b27079ce342464a80c2/src/callback.rs#L215">Sequence</a>
which allows them to be suspended. More precisely, it is not so much that they
are <em>suspended</em> as it is that their API must mirror the outer <code>Executor</code> API
in piccolo: they must be <em>polled to completion</em>. Now, the situation is <strong>not
nearly</strong> as bad here as trying to use <code>lua_callk</code> / <code>lua_pcallk</code> / <code>lua_yieldk</code>
in plain C, but fundamentally it can still be more than a <em>little</em> painful.</p>
<p>The <code>Sequence</code> trait shares a lot in common with the <code>Future</code> trait, in that
both represent an <em>operation that must be polled to completion</em>. Like I said
before when I was introducing the &#34;stackless&#34; design, this similarity is no
accident.</p>
<p>I used the slang word &#34;snarf&#34; casually near the beginning of this post without
really explaining it. As I understand it, <em>snarfing</em> is something from PLT
jargon where if you implement an inner programming language B in an outer
programming language A, features from language A can be very easily and
automatically incorporated into language B. The most common example I see here
is actually <em>garbage collection</em>, if you implement a runtime for a garbage
collected language within another garbage collected language, <em>and you&#39;re okay
with the GC semantics from the outer language being reflected in the inner
language</em>, then you can <em>snarf</em> garbage collection from the outer language.
Think of implementing Lua in something like Go, even though the specifics of the
GC semantics in Lua may not be expressible in Go,<span><sup><a data-aside="aside-27">[27]</a></sup><span id="aside-27">I don&#39;t actually
know whether Go can express all of the minutia of Lua weak / ephemeron tables
and finalization.</span></span>
 it would probably be worth it to just <em>snarf</em> garbage
collection from Go and use <em>plain Go pointers</em> as Lua references.</p>
<p><em>Snarfing</em> can also be simpler things like implementing the stdlib of the
inner language using the stdlib of the outer language, in PUC-Rio Lua, there
is actually a good deal of functionality snarfed from C, most of it bad (like
<a href="https://www.lua.org/manual/5.4/manual.html#pdf-os.setlocale">os.setlocale</a>).</p>
<p>With <em>all</em> of this context finally out of the way, I can say what I&#39;ve wanted to
say almost from the beginning of this very long blog post: <em>The original design
I wanted with <code>piccolo</code> and <code>gc-arena</code> was for Lua to snarf coroutines from
Rust.</em> I&#39;m going to talk about this in more detail in a future post because this
post is so long already, but <code>Sequence</code>&#39;s similarity to <code>Future</code> is because <em>I
want to use Rust coroutines to implement <code>piccolo</code></em>.</p>
<p>Think about it... why is PUC-Rio Lua&#39;s C interpreter written the way it is?
Why do <code>lua_callk</code> and <code>lua_pcallk</code> and <code>lua_yieldk</code> exist at all... they exist
because <em>C does not have coroutines</em>. This entire post I have been dancing
around this issue without addressing it because I feared it wouldn&#39;t make
sense without a mountain of context, but the entire time I&#39;ve been talking
about &#34;reifing state&#34; that would &#34;normally be held inside the call stack&#34; into
objects that can be &#34;polled to completion&#34;... that is the very <em>core</em> of what a
coroutine <em>is</em>.</p>
<p>The only real downside to <code>gc-arena</code> and <code>piccolo</code> is having to do this
transform <strong>manually</strong> rather than letting the Rust compiler do it. The pain of
using <code>gc-arena</code> and <code>piccolo</code> is THE SAME pain that existed before Rust Async
was stabilized, with Future combinator libraries having to fill the gap. In
fact, an older of <code>gc-arena</code> tried to provide combinators like this to try and
fill the gap, but making it fit into <code>piccolo</code> in a generic way was just too
painful and the combinator library was dropped. <code>piccolo::Sequence</code> actually
comes from the remains of this combinator library.</p>
<p>And all of this exists <em>solely</em> because <em>I can&#39;t figure out how to make a Rust
coroutine implement <code>gc_arena::Collect</code></em>.<span><sup><a data-aside="aside-28">[28]</a></sup><span id="aside-28">If I sound agitated,
it&#39;s because I spent a large amount of my life force trying to make this work
somehow. It needs Rust compiler changes.</span></span>
 If I could figure this out,
all of the problems with <code>gc-arena</code> and <code>piccolo</code> could melt away, and the Rust
compiler could do the painful transformation into &#34;stackless&#34; interpreter design
largely <em>for us</em>. Even the term &#34;stackless&#34; is shared with <em>Rust coroutines</em>.</p>
<h2 id="zooming-out">Zooming Out</h2>
<p>I&#39;m gonna spend a bit of time here zooming out some more. Hopefully I won&#39;t zoom
out so far that I stop even being anchored to reality.</p>
<p>I think Rust&#39;s really cool core idea is the same that is shared by all systems
programming languages: that they are meant to be the <em>last stop</em> in a line
of other choices. I honestly <em>don&#39;t</em> think every single bit of software needs
to be written in Rust or any systems programming language. To me, systems
programming languages are languages where if you need to make system A work
with system B, <em>no matter what those systems are</em>, you can use them. Rust and C
are languages that you&#39;re supposed to use when what you&#39;re making needs to <em>fit
almost anywhere</em>. They&#39;re supposed to be the languages with the fewest possible
<em>assumptions</em> about how the rest of the world works, becasue they&#39;re meant to
be a host or glue language to inner systems with <em>better</em> assumptions, which are
<em>more</em> fit to purpose.</p>
<p>I know that this perspective on systems programming languages is not universal,
and that the real world is actually quite resistent to putting things into neat
little boxes like this, but I think this perspective is at least a useful one.</p>
<p>As such, I always flinch a little when I see people trying to write systems in
Rust as though they&#39;re trying to figure out the <em>one</em> solution for something,
assuming that no other solution would EVER need to exist within the same
program, or even need to exist at all. I think one size fits all solutions to
problems are not where Rust&#39;s strength is. Global async reactors / executors,
whole-program garbage collectors,<span><sup><a data-aside="aside-29">[29]</a></sup><span id="aside-29">Anything with global variables,
really. Hating on global variables might sound kinda 90s, but that doesn&#39;t
make it wrong.</span></span>
 heck even whole program <em>allocators</em>,<span><sup><a data-aside="aside-30">[30]</a></sup><span id="aside-30">Maybe Zig has some good ideas here?</span></span>
 all of these things always make me
<em>some</em> amount of uncomfortable because I just think that.. systems programming
languages are meant for making BIG end products or libraries that last a long
time, where more than one of these kinds of systems might need to exist at once,
or you may need to take them apart and use them a la carte. It&#39;s not that I
think these are wrong to use or wrong to make, I just don&#39;t prefer to use those
kinds of solutions myself <em>if I can avoid them</em> because also honestly <em>the user
of my library knows better than me</em>. There&#39;s a tradeoff in programming between
flexibility and fitness for purpose, systems programming is the way it is
because it&#39;s supposed to be <em>ultimately flexible</em>, it&#39;s what you use when a more
friendly, more tailored tool isn&#39;t <em>flexible enough</em>. I don&#39;t like going against
that idea when writing code that I want to last for a long time.<span><sup><a data-aside="aside-31">[31]</a></sup><span id="aside-31">I also understand that compromises have to be made sometimes, and usability
matters, so I genuinely mean no offense to libraries that might choose different
priorities, but it might not be what I <em>personally</em> want.</span></span>
</p>
<hr/>
<p>One of my favorite parts of pretty much every version of Lua is how painless
it is to have multiple copies of the interpreter. If you&#39;ve ever run into
large garbage collector pauses in other languages, this rarely happens in Lua
not because its garbage collector is <em>just that good</em>, but because you aren&#39;t
forced to have just ONE of them in your program, you can have as many of them
as you need, each in isolation from each other! Lua is a language that actually
meshes very well with my vague ideas about the core idea of systems programming,
because PUC-Rio Lua was written to <em>fit almost anywhere</em>. It&#39;s actually amazing
how neatly it fits into C, how it is fine being the <em>bottom</em> of the hierarchy,
it&#39;s <em>just</em> a C library and you <em>just</em> call C functions. Two distant parts
of a program both use Lua? Different <em>versions</em> of Lua with different loaded
libraries? You can make it work! It doesn&#39;t read external files unless you tell
it to, it doesn&#39;t do anything unless you tell it to because it makes <em>very few
assumptions</em>. It&#39;s <em>your tool</em>, and it fits neatly into whatever program you
already have. I think this is why it has remained so popular for so many years.
<span><sup><a data-aside="aside-32">[32]</a></sup><span id="aside-32">And so popular to integrate into big, complex systems programming
projects like video games.</span></span>
</p>
<p>I want to make a version of Lua that feels for Rust like PUC-Rio feels for C,
but to go even further. I want to make a version of Lua that <em>fits anywhere</em> as
much as I possibly can make it. Untrusted input! Cancellation! I want to make
a version of Lua with the <em>fewest possible opinions</em> about how the rest of the
program is structured. I know <code>piccolo</code> is a little far from that in several
ways right now, but that&#39;s my ultimate goal. I think stackless interpreters
actually fit this idea of being as <em>unobtrusive</em> as possible, of <em>fitting
anywhere</em> better than classical language interpreters.</p>
<p>Garbage collection systems in general are very often at odds with this idea of
<em>fitting anywhere</em>. There can only be one
<a href="https://www.hboehm.info/gc/">boehm gc</a> in a C program, after all. It&#39;s
interesting to me that garbage collector systems as a library <em>for</em> C have to be
so much slower than garbage collectors written for other languages but written
<em>in</em> C. The problem is not that C can&#39;t write fast garbage collection systems,
the problem is that the C language <em>itself</em> has so few &#34;global assumptions&#34;
built into it. It&#39;s much easier to write a garbage collector for a language
that can annotate where GC pointers are on the language&#39;s call stack or in heap
allocated objects than one like C, where it is extremely difficult to have such
things.</p>
<hr/>
<p>Progress in systems programming languages seems to happen when new abstractions
are invented that give new <em>fundamental powers</em> but do NOT introduce more
required assumptions. I think <em>coroutines</em> are one of these, and that all
systems programming languages should have a stackless coroutine system because
it is the sort of thing that can <em>fit into other systems</em> as much as possible. I
think there is also some kind of deep connection between higher level languages
whose compilers / interpreters do things like annotate where garbage collected
pointers are stored in the language&#39;s call stack or automatically insert garbage
collector <em>safe points</em>, and the idea of coroutines as a <em>general reification</em>
of the call stack itself, letting the <em>language</em> do this manipulation rather
than a specialized compiler.</p>
<p>I came up with this connection way back in early 2019, but if we could make
Rust coroutines implement <code>Collect</code>, then this makes yield / await into <em>an
abstraction of the garbage collector safe point</em>. When a <code>Future</code> or <code>Coroutine</code>
yields control to the caller, all of the (apparent) <em>stack</em> variables are
guaranteed to be stored inside the state of the running coroutine. This would
allow <code>gc-arena</code> to easily separate collection and mutation in normal, straight
line Rust code that is simply <em>annotated</em> with <code>await</code>s (or <code>yield</code>s) to mark
where garbage collection can safely take place in the same way that a higher
level language runtime inserts <em>safe points</em> to mark where garbage collection
can safely take place.<span><sup><a data-aside="aside-33">[33]</a></sup><span id="aside-33">I feel like I&#39;m doing a math proof but I
can&#39;t really figure out a direct line between A and B but I <em>know</em> they&#39;re the
same, so I go from A and get as far as I can towards B, and I go from B and get
as far as I can towards A, then I <em>wave my arms really wildly up and down</em> so
everyone gets it.</span></span>
</p>
<p>I think Rust is <em>so close</em> to having some very interesting, novel powers with
its coroutines by simply being able to <em>combine</em> existing features together.
I can automatically serialize a custom struct with <code>#[derive(Serialize)]</code>, and
I can automatically transform a function body into a state machine, but
<em>what I cannot</em> do is <code>#[derive(Serialize)]</code> this state machine, nor can I
<code>#[derive(Collect)]</code> it. <em><strong>Why not??</strong></em></p>
<p>This deserves its own blog post, but I felt like I couldn&#39;t rightly close
out this post without at least mentioning it. In my next post I&#39;m going to
explore this idea more fully and hopefully try and actually make it &#34;work&#34; by
<em>pretending</em> to be able to <code>#[derive(Collect)]</code> a coroutine. I think that Rust
might need more than <em>just</em> this feature to make this system workable, but if
it did work, it could represent a largely painless, general, <em>isolated</em> system
for tracing garbage collection in Rust. A garbage collection system that can
<em>fit anywhere</em>.</p>
<p>Bye!</p>


  </div></div>
  </body>
</html>
