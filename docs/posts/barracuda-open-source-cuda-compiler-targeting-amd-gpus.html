<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Zaneham/BarraCUDA">Original</a>
    <h1>BarraCUDA Open-source CUDA compiler targeting AMD GPUs</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">An open-source CUDA compiler that targets AMD GPUs, with more architectures planned. Written in 15,000 lines of C99. Zero LLVM dependency. Compiles <code>.cu</code> files straight to GFX11 machine code and spits out ELF <code>.hsaco</code> binaries that AMD GPUs can actually run.</p>
<p dir="auto">This is what happens when you look at NVIDIA&#39;s walled garden and think &#34;how hard can it be?&#34; The answer is: quite hard, actually, but I did it anyway.</p>
<p dir="auto">note: if youre here to test out my current tenstorrent implementation youll have to clone that respective branch :-)</p>

<p dir="auto">Takes CUDA C source code, the same <code>.cu</code> files you&#39;d feed to <code>nvcc</code>, and compiles them to AMD RDNA 3 (gfx1100) binaries. No LLVM. No HIP translation layer. No &#34;convert your CUDA to something else first.&#34; Just a lexer, a parser, an IR, and roughly 1,700 lines of hand-written instruction selection that would make a compiler textbook weep.</p>
<div data-snippet-clipboard-copy-content="┌──────────────────────────────────────────────────────────────┐
│                     BarraCUDA Pipeline                       │
├──────────────────────────────────────────────────────────────┤
│  Source (.cu)                                                │
│       ↓                                                      │
│  Preprocessor → #include, #define, macros, conditionals      │
│       ↓                                                      │
│  Lexer → Tokens                                              │
│       ↓                                                      │
│  Parser (Recursive Descent) → AST                            │
│       ↓                                                      │
│  Semantic Analysis → Type checking, scope resolution         │
│       ↓                                                      │
│  BIR (BarraCUDA IR) → SSA form, typed instructions           │
│       ↓                                                      │
│  mem2reg → Promotes allocas to SSA registers                 │
│       ↓                                                      │
│  Instruction Selection → AMDGPU machine instructions         │
│       ↓                                                      │
│  Register Allocation → VGPR/SGPR assignment                  │
│       ↓                                                      │
│  Binary Encoding → GFX11 instruction words                   │
│       ↓                                                      │
│  ELF Emission → .hsaco ready for the GPU                     │
│       ↓                                                      │
│  Your kernel runs on ya silicon                              │
└──────────────────────────────────────────────────────────────┘"><pre><code>┌──────────────────────────────────────────────────────────────┐
│                     BarraCUDA Pipeline                       │
├──────────────────────────────────────────────────────────────┤
│  Source (.cu)                                                │
│       ↓                                                      │
│  Preprocessor → #include, #define, macros, conditionals      │
│       ↓                                                      │
│  Lexer → Tokens                                              │
│       ↓                                                      │
│  Parser (Recursive Descent) → AST                            │
│       ↓                                                      │
│  Semantic Analysis → Type checking, scope resolution         │
│       ↓                                                      │
│  BIR (BarraCUDA IR) → SSA form, typed instructions           │
│       ↓                                                      │
│  mem2reg → Promotes allocas to SSA registers                 │
│       ↓                                                      │
│  Instruction Selection → AMDGPU machine instructions         │
│       ↓                                                      │
│  Register Allocation → VGPR/SGPR assignment                  │
│       ↓                                                      │
│  Binary Encoding → GFX11 instruction words                   │
│       ↓                                                      │
│  ELF Emission → .hsaco ready for the GPU                     │
│       ↓                                                      │
│  Your kernel runs on ya silicon                              │
└──────────────────────────────────────────────────────────────┘
</code></pre></div>
<p dir="auto">Every single encoding has been validated against <code>llvm-objdump</code> with zero decode failures. I didn&#39;t use LLVM to compile, but I did use it to check my homework.</p>

<div dir="auto" data-snippet-clipboard-copy-content="# It&#39;s C99. It builds with gcc. There are no dependencies.
make

# That&#39;s it. No cmake. No autoconf. No 47-step build process.
# If this doesn&#39;t work, your gcc is broken, not the Makefile."><pre><span><span>#</span> It&#39;s C99. It builds with gcc. There are no dependencies.</span>
make

<span><span>#</span> That&#39;s it. No cmake. No autoconf. No 47-step build process.</span>
<span><span>#</span> If this doesn&#39;t work, your gcc is broken, not the Makefile.</span></pre></div>

<ul dir="auto">
<li>A C99 compiler (gcc, clang, whatever you&#39;ve got)</li>
<li>A will to live (optional but recommended)</li>
<li>LLVM is NOT required. BarraCUDA does its own instruction encoding like an adult.</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="# Compile to AMD GPU binary
./barracuda --amdgpu-bin kernel.cu -o kernel.hsaco

# Dump the IR (for debugging or curiosity)
./barracuda --ir kernel.cu

# Just parse and dump the AST
./barracuda --ast kernel.cu

# Run semantic analysis
./barracuda --sema kernel.cu"><pre><span><span>#</span> Compile to AMD GPU binary</span>
./barracuda --amdgpu-bin kernel.cu -o kernel.hsaco

<span><span>#</span> Dump the IR (for debugging or curiosity)</span>
./barracuda --ir kernel.cu

<span><span>#</span> Just parse and dump the AST</span>
./barracuda --ast kernel.cu

<span><span>#</span> Run semantic analysis</span>
./barracuda --sema kernel.cu</pre></div>

<p dir="auto">The following CUDA features compile to working GFX11 machine code:</p>

<ul dir="auto">
<li><code>__global__</code>, <code>__device__</code>, <code>__host__</code> function qualifiers</li>
<li><code>threadIdx</code>, <code>blockIdx</code>, <code>blockDim</code>, <code>gridDim</code> builtins</li>
<li>Structs, enums, typedefs, namespaces</li>
<li>Pointers, arrays, pointer arithmetic</li>
<li>All C control flow: <code>if</code>/<code>else</code>, <code>for</code>, <code>while</code>, <code>do-while</code>, <code>switch</code>/<code>case</code>, <code>goto</code>/<code>label</code></li>
<li>Short-circuit <code>&amp;&amp;</code> and <code>||</code></li>
<li>Ternary operator</li>
<li>Templates (basic instantiation)</li>
<li>Multiple return paths, <code>continue</code>, <code>break</code></li>
</ul>

<ul dir="auto">
<li><code>__shared__</code> memory (allocated from LDS, properly tracked)</li>
<li><code>__syncthreads()</code> → <code>s_barrier</code></li>
<li>Atomic operations: <code>atomicAdd</code>, <code>atomicSub</code>, <code>atomicMin</code>, <code>atomicMax</code>, <code>atomicExch</code>, <code>atomicCAS</code>, <code>atomicAnd</code>, <code>atomicOr</code>, <code>atomicXor</code></li>
<li>Warp intrinsics: <code>__shfl_sync</code>, <code>__shfl_up_sync</code>, <code>__shfl_down_sync</code>, <code>__shfl_xor_sync</code></li>
<li>Warp votes: <code>__ballot_sync</code>, <code>__any_sync</code>, <code>__all_sync</code></li>
<li>Vector types: <code>float2</code>, <code>float3</code>, <code>float4</code>, <code>int2</code>, <code>int3</code>, <code>int4</code> with <code>.x</code>/<code>.y</code>/<code>.z</code>/<code>.w</code> access</li>
<li>Half precision: <code>__half</code>, <code>__float2half()</code>, <code>__half2float()</code></li>
<li><code>__launch_bounds__</code> (parsed, propagated, enforces VGPR caps)</li>
<li>Cooperative groups: <code>cooperative_groups::this_thread_block()</code> with <code>.sync()</code>, <code>.thread_rank()</code>, <code>.size()</code></li>
<li>Operator overloading</li>
</ul>

<ul dir="auto">
<li>Full C preprocessor: <code>#include</code>, <code>#define</code>/<code>#undef</code>, function-like macros, <code>#ifdef</code>/<code>#ifndef</code>/<code>#if</code>/<code>#elif</code>/<code>#else</code>/<code>#endif</code>, <code>#pragma</code>, <code>#error</code>, <code>-I</code>/<code>-D</code> flags</li>
<li>Error recovery (reports multiple errors without hanging)</li>
<li>Source location tracking in IR dumps</li>
<li>Struct pass-by-value</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="__global__ void vector_add(float *c, float *a, float *b, int n)
{
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if (idx &lt; n)
        c[idx] = a[idx] + b[idx];
}"><pre><span>__global__</span> <span>void</span> <span>vector_add</span>(<span>float</span> *c, <span>float</span> *a, <span>float</span> *b, <span>int</span> n)
{
    <span>int</span> idx = <span>threadIdx</span>.<span>x</span> + <span>blockIdx</span>.<span>x</span> * <span>blockDim</span>.<span>x</span>;
    <span>if</span> (idx &lt; n)
        c[idx] = a[idx] + b[idx];
}</pre></div>
<div data-snippet-clipboard-copy-content="$ ./barracuda --amdgpu-bin vector_add.cu -o vector_add.hsaco
wrote vector_add.hsaco (528 bytes code, 1 kernels)"><pre><code>$ ./barracuda --amdgpu-bin vector_add.cu -o vector_add.hsaco
wrote vector_add.hsaco (528 bytes code, 1 kernels)
</code></pre></div>
<p dir="auto">No LLVM required :-)</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>File</th>
<th>Lines</th>
<th>What It Does</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lexer.c</code></td>
<td>747</td>
<td>Tokenises CUDA C source</td>
</tr>
<tr>
<td><code>preproc.c</code></td>
<td>1,370</td>
<td>C preprocessor (macros, includes, conditionals)</td>
</tr>
<tr>
<td><code>parser.c</code></td>
<td>1,500</td>
<td>Recursive descent parser → AST</td>
</tr>
<tr>
<td><code>sema.c</code></td>
<td>1,725</td>
<td>Type checking, scope resolution, overload resolution</td>
</tr>
<tr>
<td><code>bir.c</code> + <code>bir_lower.c</code></td>
<td>3,032</td>
<td>SSA intermediate representation + AST→BIR lowering</td>
</tr>
<tr>
<td><code>bir_mem2reg.c</code></td>
<td>965</td>
<td>Promotes stack allocas to SSA registers</td>
</tr>
<tr>
<td><code>bir_print.c</code></td>
<td>579</td>
<td>IR pretty printer with source location annotations</td>
</tr>
<tr>
<td><code>amdgpu_isel.c</code></td>
<td>1,788</td>
<td>Instruction selection: BIR → AMDGPU machine ops</td>
</tr>
<tr>
<td><code>amdgpu_emit.c</code></td>
<td>1,735</td>
<td>Register allocation + GFX11 binary encoding + ELF emission</td>
</tr>
<tr>
<td><code>main.c</code></td>
<td>317</td>
<td>CLI driver</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>15,117</strong></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">All data structures use pre-allocated fixed-size arrays. No malloc in hot paths. No recursion. Bounded loops everywhere. The kind of code that would make JPL&#39;s coding standards committee nod approvingly before going back to landing things on Mars.</p>

<p dir="auto">Being honest about limitations is important. Here&#39;s what&#39;s missing:</p>
<ul dir="auto">
<li><code>unsigned</code> as a bare type specifier (use <code>unsigned int</code> or just <code>int</code>)</li>
<li><code>+=</code>, <code>-=</code>, <code>&gt;&gt;=</code> and friends (compound assignment, spell it out for now)</li>
<li><code>const</code> qualifier</li>
<li><code>__constant__</code> memory</li>
<li>2D array declarations in shared memory (<code>__shared__ float a[16][16]</code>, flatten to 1D)</li>
<li>Integer literal suffixes (<code>0xFFu</code>, <code>1ULL</code>)</li>
<li>Parameter reassignment in <code>__device__</code> functions (use local variables)</li>
<li>Textures and surfaces</li>
<li>Dynamic parallelism (device-side kernel launch)</li>
<li>Multiple translation units</li>
<li>Host code generation (only device code is compiled)</li>
</ul>
<p dir="auto">None of these are architectural blockers. They&#39;re all &#34;haven&#39;t got round to it yet&#34; items.</p>

<p dir="auto">14 test files, 35+ kernels, ~1,700 BIR instructions, ~27,000 bytes of machine code:</p>
<ul dir="auto">
<li><code>vector_add.cu</code> - The &#34;hello world&#34; of GPU computing</li>
<li><code>cuda_features.cu</code> - Atomics, warp ops, barriers, gotos, switch, short-circuit</li>
<li><code>test_tier12.cu</code> - Vectors, shared memory, operator overloading</li>
<li><code>notgpt.cu</code> - AI-generated CUDA with extremely sarcastic comments (tiled SGEMM, reductions, histograms, prefix scan, stencils, half precision, cooperative groups, and the &#34;kitchen sink&#34; kernel)</li>
<li><code>stress.cu</code> - N-body simulation, nested control flow, bit manipulation, struct pass-by-value, chained function calls</li>
<li><code>canonical.cu</code> - Canonical patterns from NVIDIA samples adapted for the parser</li>
<li><code>test_errors.cu</code> - Deliberate syntax errors to verify error recovery</li>
<li><code>test_launch_bounds.cu</code> - <code>__launch_bounds__</code> parsing and VGPR cap enforcement</li>
<li><code>test_coop_groups.cu</code> - Cooperative groups lowering</li>
<li>Plus preprocessor tests, template tests, unsigned integer tests</li>
</ul>


<p dir="auto">Fix the known gaps: compound assignment operators, bare <code>unsigned</code>, integer literal suffixes, <code>const</code>, parameter reassignment. These are all small parser/lowerer changes. The goal is to compile real-world <code>.cu</code> files without modifications.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Medium Term: Optimisation</h3><a id="user-content-medium-term-optimisation" aria-label="Permalink: Medium Term: Optimisation" href="#medium-term-optimisation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The generated code works but isn&#39;t winning any benchmarks. Priorities:</p>
<ul dir="auto">
<li>Instruction scheduling (hide memory latency)</li>
<li>Better register allocation (currently linear scan, consider graph colouring)</li>
<li>Constant folding and dead code elimination</li>
<li>Loop-invariant code motion</li>
<li>Occupancy tuning based on register pressure</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Long Term: More Architectures</h3><a id="user-content-long-term-more-architectures" aria-label="Permalink: Long Term: More Architectures" href="#long-term-more-architectures"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The IR (BIR) is target-independent. The backend is cleanly separated. Adding a new target means writing a new <code>isel</code> + <code>emit</code> pair. Candidates:</p>
<ul dir="auto">
<li><strong>Tenstorrent</strong> - RISC-V based AI accelerators. Open ISA. Very different execution model (tile-based, not SIMT) but the IR maps well.</li>
<li><strong>Intel Arc</strong> - Xe architecture. Would give BarraCUDA coverage across all three major GPU vendors.</li>
<li><strong>RISC-V Vector Extension</strong> - For when GPUs are too mainstream and you want to run CUDA on a softcore.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">GFX11 Encoding Notes (For The Brave)</h2><a id="user-content-gfx11-encoding-notes-for-the-brave" aria-label="Permalink: GFX11 Encoding Notes (For The Brave)" href="#gfx11-encoding-notes-for-the-brave"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If you&#39;re considering writing your own AMDGPU backend, here are the things that will ruin your afternoon:</p>
<ul dir="auto">
<li>SOP1 prefix is <code>0xBE800000</code>, not what you&#39;d expect from the docs</li>
<li>SOPC prefix is <code>0xBF000000</code></li>
<li>VOP3 VDST is at bits <code>[7:0]</code>, not <code>[15:8]</code> like a sensible person would assume</li>
<li>Null SADDR is <code>0x7C</code> for global memory, <code>0xFC</code> for scratch</li>
<li>RDNA 3 is Wave32 by default, not Wave64 like GCN</li>
<li>The ISA manual is 500 pages and contradicts itself at least twice</li>
</ul>
<p dir="auto">All 1,735 lines of <code>amdgpu_emit.c</code> are a testament to reading those pages so you don&#39;t have to.</p>

<p dir="auto">Found a bug? Want to discuss the finer points of AMDGPU instruction encoding? Need someone to commiserate with about the state of GPU computing?</p>
<p dir="auto"><strong><a href="mailto:zanehambly@gmail.com">zanehambly@gmail.com</a></strong></p>
<p dir="auto">Open an issue if theres anything you want to discuss. Or don&#39;t. I&#39;m not your mum.</p>
<p dir="auto">Based in New Zealand, where it&#39;s already tomorrow and the GPUs are just as confused as everywhere else.</p>

<p dir="auto">Apache 2.0. Do whatever you want. If this compiler somehow ends up in production, I&#39;d love to hear about it, mostly so I can update my LinkedIn with something more interesting than wrote a CUDA compiler for fun.</p>
<hr/>
</article></div></div>
  </body>
</html>
