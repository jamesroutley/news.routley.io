<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://techcrunch.com/2024/05/16/eu-opens-child-safety-probes-of-facebook-and-instagram-citing-addictive-design-concerns/">Original</a>
    <h1>EU opens child safety probes of Facebook and Instagram, citing addictive design</h1>
    
    <div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Facebook and Instagram are under formal investigation in the European Union over child protection concerns, the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_24_2664" target="_blank" rel="noreferrer noopener">Commission announced</a> Thursday. The proceedings follow a raft of <a href="https://techcrunch.com/2023/12/01/meta-dsa-rfi-2-child-safety/">requests for information to parent entity Meta</a> since the bloc’s online governance regime, the Digital Services Act (DSA), started applying last August.</p>

<p>The development could be significant as the formal proceedings unlock additional investigatory powers for EU enforcers, such as the ability to conduct office inspections or apply interim measures. Penalties for any confirmed breaches of the DSA could reach up to 6% of Meta’s global annual turnover.</p>

<p>Meta’s two social networks are designated as very large online platforms (VLOPs) under the DSA. This means the company faces an extra set of rules — overseen by the EU directly — requiring it to assess and mitigate systemic risks on Facebook and Instagram, including in areas like minors’ mental health. </p>

<p>In a briefing with journalists, senior Commission officials said they suspect Meta of failing to properly assess and mitigate risks affecting children. </p>

	
	


	
	


<p>They particularly highlighted concerns about addictive design on its social networks, and what they referred to as a “rabbit hole effect,” where a minor watching one video may be pushed to view more similar content as a result of the platforms’ algorithmic content recommendation engines.</p>

<p>Commission officials gave examples of depression content, or content that promotes an unhealthy body image, as types of content that could have negative impacts on minors’ mental health.</p>

<p>They are also concerned that the age assurance methods Meta uses may be too easy for kids to circumvent. </p>


	
	


	
	


<p>“One of the underlying questions of all of these grievances is how can we be sure who accesses the service and how effective are the age gates — particularly for avoiding that underage users access the service,” said a senior Commission official briefing press today on background. “This is part of our investigation now to check the effectiveness of the measures that Meta has put in place in this regard as well.”</p>

<p>In all, the EU suspects Meta of infringing DSA Articles 28, 34, and 35. The Commission will now carry out an in-depth investigations of the two platforms’ approach to child protection.  </p>

<p>Meta has been contacted for a response. </p>

<p>The EU opened a similar probe into addictive design concerns on video sharing social network TikTok <a href="https://techcrunch.com/2024/04/22/tiktok-lite-dsa-probe/" target="_blank" rel="noreferrer noopener">last month</a>.</p>

<p>The Commission also already opened two DSA investigations on Meta’s social networks. <a href="https://techcrunch.com/2024/04/30/meta-first-dsa-probes/">Last month</a> it said it would investigate separate concerns related to Facebook’s and Instagram’s approach to election integrity.</p>

<figure></figure>
</div></div>
  </body>
</html>
