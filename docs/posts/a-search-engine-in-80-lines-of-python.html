<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html">Original</a>
    <h1>A search engine in 80 lines of Python</h1>
    
    <div id="readability-page-1" class="page"><div>
    





  <title>A search engine in 80 lines of Python</title>
  
  
  
  
  
    
  


  <!-- Header -->
  

  <!-- Post Content -->
    <hr/>
    
    <i><p>February 05, 2024 · <span title="Estimated read time">
  
  
    26 mins · 4718 words
  
</span>
 </p></i> 
  
      <p>Last September I hopped on board with <a href="https://www.wallapop.com/">Wallapop</a> as a Search Data Scientist and since then part of my work has been working with <a href="https://solr.apache.org/">Solr</a>, an open source search engine based on <a href="https://lucene.apache.org/">Lucene</a>. I’ve got the basics of how a search engine works, but I had this itch to understand it even better. So, I rolled up my sleeves and decided to build one from scratch.</p>

<p>Now, let’s talk goals. Ever heard of the “<a href="https://www.marginalia.nu/log/19-website-discoverability-crisis/">Small Website Discoverability Crisis</a>”? The problem it’s basically that small websites, ones like this one, are impossible to be found using Google or any other search engine. My mission? Making those tiny websites great again. I believe in bringing back the glory of the little guys, away from the Google SEO frenzy.</p>

<p>In this post I will walk you through the journey of buliding a search engine from scratch using Python. As usual, all the code I’ve written can be found on my GitHub (<a href="https://github.com/alexmolas/microsearch">microsearch repo</a>). This implementation doesn’t pretend to be a production-ready search engine, just a usable toy example showing how a search engine works under the hood.</p>

<p>Also, let me be sincere and admit I’ve exaggerated a little bit in the post title. Indeed, the search engine I’ve implemented is around 80 lines of Python, but I’ve also written some complementary code (data crawler, API, HTML templates, etc.) that’s over makes the whole project a bit bigger. However, I think the interesting part of this project is the search engine which has less than 80 lines.</p>

<p>PS. After writing this post and <code>microsearch</code> I realized that Bart de Goede did <a href="https://github.com/bartdegoede/python-searchengine">something similar</a> a couple of years ago. My implementation is very similar to Bart’s, but in my case, I think I did some things better, in particular (1) my crawler is async, which makes things much faster, and (2) I’ve implemented a user interface that allows to interact with the search engine.</p>



<p>Now, let’s delve into the components that make up <code>microsearch</code> and explore how I crafted each element: (1) the crawler, (2) the inverted index, (3) the ranker, and (4) the interface. In the following sections, I’ll provide both theoretical descriptions and practical details on how each concept was implemented in my project.</p>

<h2 id="crawler">Crawler</h2>

<p>The first step to building a search engine is to have data to search. Depending on your use case you can crawl existing data (as <a href="https://developers.google.com/search/docs/crawling-indexing/overview-google-crawlers">Google</a> does) or you can use your own data (as Wallapop or any other e-commerce/marketplace does).</p>

<p>Since one of my intentions was to build a “local Google” I decided to use data from the blogs I follow to build the search engine. In this case, crawling consists of downloading and cleaning all the posts of a certain list of blogs. To make it easier I’ve only crawled posts of blogs with RSS <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>. And to make it faster, I’ve used the <code>asyncio</code> Python library. Using asynchronous code has sped up the crawling time from 20 minutes to 20 seconds.</p>

<p>In my case, I’ve used a list of 642 RSS feeds. Of these feeds around 100 are the ones I usually read (blogs about ML, data science, math, etc.), and I scrapped the other 500 from <a href="https://github.com/surprisetalk/blogs.hn">surprisetalk blogs.hn project</a>.</p>

<details>
<summary>Crawler code</summary>

<figure><pre><code data-lang="python"><span>import</span> <span>argparse</span>
<span>import</span> <span>aiohttp</span>
<span>import</span> <span>asyncio</span>
<span>import</span> <span>feedparser</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>from</span> <span>bs4</span> <span>import</span> <span>BeautifulSoup</span>
<span>import</span> <span>logging</span>

<span>logging</span><span>.</span><span>basicConfig</span><span>(</span><span>level</span><span>=</span><span>logging</span><span>.</span><span>INFO</span><span>)</span>
<span>logger</span> <span>=</span> <span>logging</span><span>.</span><span>getLogger</span><span>(</span><span>__name__</span><span>)</span>


<span>def</span> <span>parse_feed</span><span>(</span><span>feed_url</span><span>):</span>
    <span>try</span><span>:</span>
        <span>feed</span> <span>=</span> <span>feedparser</span><span>.</span><span>parse</span><span>(</span><span>feed_url</span><span>)</span>
        <span>return</span> <span>[</span><span>entry</span><span>.</span><span>link</span> <span>for</span> <span>entry</span> <span>in</span> <span>feed</span><span>.</span><span>entries</span><span>]</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>&#34;Error parsing feed </span><span>{</span><span>feed_url</span><span>}</span><span>: </span><span>{</span><span>e</span><span>}</span><span>&#34;</span><span>)</span>
        <span>return</span> <span>[]</span>


<span>async</span> <span>def</span> <span>fetch_content</span><span>(</span><span>session</span><span>,</span> <span>url</span><span>):</span>
    <span>async</span> <span>with</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span> <span>as</span> <span>response</span><span>:</span>
        <span>return</span> <span>await</span> <span>response</span><span>.</span><span>text</span><span>()</span>


<span>async</span> <span>def</span> <span>process_feed</span><span>(</span><span>feed_url</span><span>,</span> <span>session</span><span>,</span> <span>loop</span><span>):</span>
    <span>try</span><span>:</span>
        <span>post_urls</span> <span>=</span> <span>await</span> <span>loop</span><span>.</span><span>run_in_executor</span><span>(</span><span>None</span><span>,</span> <span>parse_feed</span><span>,</span> <span>feed_url</span><span>)</span>
        <span>tasks</span> <span>=</span> <span>[</span><span>fetch_content</span><span>(</span><span>session</span><span>,</span> <span>post_url</span><span>)</span> <span>for</span> <span>post_url</span> <span>in</span> <span>post_urls</span><span>]</span>
        <span>post_contents</span> <span>=</span> <span>await</span> <span>asyncio</span><span>.</span><span>gather</span><span>(</span><span>*</span><span>tasks</span><span>)</span>
        <span>cleaned_contents</span> <span>=</span> <span>[</span><span>clean_content</span><span>(</span><span>content</span><span>)</span> <span>for</span> <span>content</span> <span>in</span> <span>post_contents</span><span>]</span>
        <span>return</span> <span>list</span><span>(</span><span>zip</span><span>(</span><span>post_urls</span><span>,</span> <span>cleaned_contents</span><span>))</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>&#34;Error processing feed </span><span>{</span><span>feed_url</span><span>}</span><span>: </span><span>{</span><span>e</span><span>}</span><span>&#34;</span><span>)</span>
        <span>return</span> <span>[]</span>


<span>def</span> <span>clean_content</span><span>(</span><span>html_content</span><span>):</span>
    <span>soup</span> <span>=</span> <span>BeautifulSoup</span><span>(</span><span>html_content</span><span>,</span> <span>&#34;html.parser&#34;</span><span>)</span>
    <span>for</span> <span>script</span> <span>in</span> <span>soup</span><span>([</span><span>&#34;script&#34;</span><span>,</span> <span>&#34;style&#34;</span><span>]):</span>
        <span>script</span><span>.</span><span>extract</span><span>()</span>
    <span>text</span> <span>=</span> <span>soup</span><span>.</span><span>get_text</span><span>()</span>
    <span>lines</span> <span>=</span> <span>(</span><span>line</span><span>.</span><span>strip</span><span>()</span> <span>for</span> <span>line</span> <span>in</span> <span>text</span><span>.</span><span>splitlines</span><span>())</span>
    <span>chunks</span> <span>=</span> <span>(</span><span>phrase</span><span>.</span><span>strip</span><span>()</span> <span>for</span> <span>line</span> <span>in</span> <span>lines</span> <span>for</span> <span>phrase</span> <span>in</span> <span>line</span><span>.</span><span>split</span><span>(</span><span>&#34;  &#34;</span><span>))</span>
    <span>cleaned_text</span> <span>=</span> <span>&#34; &#34;</span><span>.</span><span>join</span><span>(</span><span>chunk</span> <span>for</span> <span>chunk</span> <span>in</span> <span>chunks</span> <span>if</span> <span>chunk</span><span>)</span>
    <span>return</span> <span>cleaned_text</span>


<span>def</span> <span>parse_args</span><span>():</span>
    <span>parser</span> <span>=</span> <span>argparse</span><span>.</span><span>ArgumentParser</span><span>()</span>
    <span>parser</span><span>.</span><span>add_argument</span><span>(</span><span>&#34;--feed-path&#34;</span><span>)</span>
    <span>return</span> <span>parser</span><span>.</span><span>parse_args</span><span>()</span>


<span>async</span> <span>def</span> <span>main</span><span>(</span><span>feed_file</span><span>):</span>
    <span>async</span> <span>with</span> <span>aiohttp</span><span>.</span><span>ClientSession</span><span>()</span> <span>as</span> <span>session</span><span>:</span>
        <span>loop</span> <span>=</span> <span>asyncio</span><span>.</span><span>get_event_loop</span><span>()</span>
        <span>with</span> <span>open</span><span>(</span><span>feed_file</span><span>,</span> <span>&#34;r&#34;</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
            <span>feed_urls</span> <span>=</span> <span>[</span><span>line</span><span>.</span><span>strip</span><span>()</span> <span>for</span> <span>line</span> <span>in</span> <span>file</span><span>]</span>

        <span>tasks</span> <span>=</span> <span>[</span><span>process_feed</span><span>(</span><span>feed_url</span><span>,</span> <span>session</span><span>,</span> <span>loop</span><span>)</span> <span>for</span> <span>feed_url</span> <span>in</span> <span>feed_urls</span><span>]</span>
        <span>results</span> <span>=</span> <span>await</span> <span>asyncio</span><span>.</span><span>gather</span><span>(</span><span>*</span><span>tasks</span><span>)</span>

    <span>flattened_results</span> <span>=</span> <span>[</span><span>item</span> <span>for</span> <span>sublist</span> <span>in</span> <span>results</span> <span>for</span> <span>item</span> <span>in</span> <span>sublist</span><span>]</span>
    <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>flattened_results</span><span>,</span> <span>columns</span><span>=</span><span>[</span><span>&#34;URL&#34;</span><span>,</span> <span>&#34;content&#34;</span><span>])</span>
    <span>df</span><span>.</span><span>to_parquet</span><span>(</span><span>&#34;output.parquet&#34;</span><span>,</span> <span>index</span><span>=</span><span>False</span><span>)</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span><span>:</span>
    <span>args</span> <span>=</span> <span>parse_args</span><span>()</span>
    <span>asyncio</span><span>.</span><span>run</span><span>(</span><span>main</span><span>(</span><span>args</span><span>.</span><span>feed_path</span><span>))</span></code></pre></figure>

</details>

<h2 id="inverted-index">Inverted index</h2>

<p>An inverted index is a data structure that maps keywords to documents. This data structure makes it trivial to find documents where a certain word appears. When a user searches for some query the inverted index is used to retrieve all the documents that match with the keywords in the query.</p>

<p>To implement the inverted index I’ve used a <code>defaultdict</code> with the signature <code>dict[str, dict[str, int]]</code>. This is, a mapping that given a word (a <code>str</code>) returns another mapping from URL (a <code>str</code>) to the number of times that word appears in the URL (a <code>int</code>). The default value of the mapping is a mapping from URL to <code>0</code>, so if we try to get the value of a keyword that doesn’t exist in a URL we get a zero.</p>

<p>The logic of the inverted index is defined within a class called <code>SearchEngine</code>. We initialize it with two private dicts.</p>

<div><div><pre><code><span>class</span> <span>SearchEngine</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>_index</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]]</span> <span>=</span> <span>defaultdict</span><span>(</span><span>lambda</span><span>:</span> <span>defaultdict</span><span>(</span><span>int</span><span>))</span>
        <span>self</span><span>.</span><span>_documents</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]</span> <span>=</span> <span>{}</span>
</code></pre></div></div>

<p>Then we implement the <code>index</code> methods, which receives an URL and its content, normalizes the content (ie: remove punctuation, everything to lowercase, etc.), and then add it to the index.</p>

<div><div><pre><code><span>def</span> <span>index</span><span>(</span><span>self</span><span>,</span> <span>url</span><span>:</span> <span>str</span><span>,</span> <span>content</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>self</span><span>.</span><span>_documents</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>content</span>
    <span>words</span> <span>=</span> <span>normalize_string</span><span>(</span><span>content</span><span>).</span><span>split</span><span>(</span><span>&#34; &#34;</span><span>)</span>
    <span>for</span> <span>word</span> <span>in</span> <span>words</span><span>:</span>
        <span>self</span><span>.</span><span>_index</span><span>[</span><span>word</span><span>][</span><span>url</span><span>]</span> <span>+=</span> <span>1</span>
</code></pre></div></div>

<p>To make the indexing process more usable we can implement a bulk index option, which receives a list of URLs and documents and index them.</p>

<div><div><pre><code><span>def</span> <span>bulk_index</span><span>(</span><span>self</span><span>,</span> <span>documents</span><span>:</span> <span>list</span><span>[</span><span>tuple</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]]):</span>
    <span>for</span> <span>url</span><span>,</span> <span>content</span> <span>in</span> <span>documents</span><span>:</span>
        <span>self</span><span>.</span><span>index</span><span>(</span><span>url</span><span>,</span> <span>content</span><span>)</span>
</code></pre></div></div>

<p>Finally, we can read the index using the <code>get_url</code> method, which receives a keyword and returns the URLs that contain the keyword.</p>

<div><div><pre><code><span>def</span> <span>get_urls</span><span>(</span><span>self</span><span>,</span> <span>keyword</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]:</span>
    <span>keyword</span> <span>=</span> <span>normalize_string</span><span>(</span><span>keyword</span><span>)</span>
    <span>return</span> <span>self</span><span>.</span><span>_index</span><span>[</span><span>keyword</span><span>]</span>
</code></pre></div></div>

<p>For example, to index the document <code>Foo</code> with the text <code>Hello, World! My name is Foo!</code>, and the document <code>Bar</code> with the text <code>Hello, World! My name is Bar, I&#39;m not Foo!</code> and then search for the word <code>Foo</code>, we can do it as</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> from microsearch.engine import engine
<span>&gt;&gt;&gt;</span> engine.index<span>(</span><span>&#34;Foo&#34;</span>, <span>&#34;Hello, World! My name is Foo!&#34;</span><span>)</span>
<span>&gt;&gt;&gt;</span> engine.index<span>(</span><span>&#34;Bar&#34;</span>, <span>&#34;Hello, World! My name is Bar, I&#39;m not Foo!&#34;</span><span>)</span>
<span>&gt;&gt;&gt;</span> engine.get_urls<span>(</span><span>&#34;foo&#34;</span><span>)</span>
defaultdict<span>(</span>&lt;class <span>&#39;int&#39;</span><span>&gt;</span>, <span>{</span><span>&#39;Foo&#39;</span>: 1, <span>&#39;Bar&#39;</span>: 1<span>})</span>
<span>&gt;&gt;&gt;</span> engine.get_urls<span>(</span><span>&#34;Foo&#34;</span><span>)</span>
defaultdict<span>(</span>&lt;class <span>&#39;int&#39;</span><span>&gt;</span>, <span>{</span><span>&#39;Foo&#39;</span>: 1, <span>&#39;Bar&#39;</span>: 1<span>})</span>
</code></pre></div></div>

<h2 id="ranker">Ranker</h2>

<p>Once you have a set of matching documents for a given query, you need a way to sort them. The most famous ranker is Google’s <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a>, which ranks documents based on the links. However, other options to rank the documents exist, such as <a href="https://en.wikipedia.org/wiki/Okapi_BM25">BM25</a>, which ranks documents based on the content. In my case, I decided to use the standard BM25. The score between a query $Q$ and a document $D$ is computed as</p>

\[\sum_{i=1}^n \text{IDF}(q_i) \frac{f(q_i, D)\times(k_1 + 1)}{f(q_i, D) + k_1 \left(1 - b + b \frac{|D|}{\text{avgdl}}\right)}\]

<p>where the query $Q$ contains the keywords $q_1$, $q_2$, …, $q_n$, the document $D$ has length $|D|$, the average length of a document is defined as $\text{avgdl}$, $k_1$ and $b$ are free parameters, $f(q_i, D)$ is the number of times that keyword $q_i$ appears in the document $D$, and finally $\text{IDF}(q_i)$ is the inverse document frequency, computed as</p>

\[\text{IDF}(q_i) = \ln \left(1 + \frac{N - n(q_i) + 0.5}{ n(q_i) + 0.5}\right)\]

<p>where $N$ is the number of documents and $n(q_i)$ is the number of documents containing $q_i$. There are other ways to compute the IDF, but apparently, you can justify this option from theoretical grounds.</p>

<p>With all this math we are ready to implement the missing part of our <code>SearchEngine</code> class. Firstly we add the constants $k_1$ and $b$ as parameters of our class</p>

<div><div><pre><code><span>class</span> <span>SearchEngine</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>k1</span><span>:</span> <span>float</span> <span>=</span> <span>1.5</span><span>,</span> <span>b</span><span>:</span> <span>float</span> <span>=</span> <span>0.75</span><span>):</span>
        <span>self</span><span>.</span><span>_index</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]]</span> <span>=</span> <span>defaultdict</span><span>(</span><span>lambda</span><span>:</span> <span>defaultdict</span><span>(</span><span>int</span><span>))</span>
        <span>self</span><span>.</span><span>_documents</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]</span> <span>=</span> <span>{}</span>
        <span>self</span><span>.</span><span>k1</span> <span>=</span> <span>k1</span>
        <span>self</span><span>.</span><span>b</span> <span>=</span> <span>b</span>
</code></pre></div></div>

<p>now we expose some useful properties that we’ll use later</p>

<div><div><pre><code><span>@</span><span>property</span>
<span>def</span> <span>posts</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>list</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>list</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>.</span><span>keys</span><span>())</span>

<span>@</span><span>property</span>
<span>def</span> <span>number_of_documents</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>return</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>)</span>

<span>@</span><span>property</span>
<span>def</span> <span>avdl</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span> 
    <span>return</span> <span>sum</span><span>(</span><span>len</span><span>(</span><span>d</span><span>)</span> <span>for</span> <span>d</span> <span>in</span> <span>self</span><span>.</span><span>_documents</span><span>.</span><span>values</span><span>())</span> <span>/</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>)</span>
</code></pre></div></div>

<p>With this information, we are ready to implement our BM25 scorer. The first thing we need to implement is the inverse document frequency method</p>

<div><div><pre><code><span>def</span> <span>idf</span><span>(</span><span>self</span><span>,</span> <span>kw</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>N</span> <span>=</span> <span>self</span><span>.</span><span>number_of_documents</span>
    <span>n_kw</span> <span>=</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>get_urls</span><span>(</span><span>kw</span><span>))</span>
    <span>return</span> <span>log</span><span>((</span><span>N</span> <span>-</span> <span>n_kw</span> <span>+</span> <span>0.5</span><span>)</span> <span>/</span> <span>(</span><span>n_kw</span> <span>+</span> <span>0.5</span><span>)</span> <span>+</span> <span>1</span><span>)</span>
</code></pre></div></div>

<p>and with this method, we can finally implement the BM scorer. This method receives a keyword and returns a mapping from all the URLs that contain that keyword to their score.</p>

<div><div><pre><code><span>def</span> <span>bm25</span><span>(</span><span>self</span><span>,</span> <span>kw</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]:</span>
    <span>result</span> <span>=</span> <span>{}</span>
    <span>idf_score</span> <span>=</span> <span>self</span><span>.</span><span>idf</span><span>(</span><span>kw</span><span>)</span>
    <span>avdl</span> <span>=</span> <span>self</span><span>.</span><span>avdl</span>
    <span>for</span> <span>url</span><span>,</span> <span>freq</span> <span>in</span> <span>self</span><span>.</span><span>get_urls</span><span>(</span><span>kw</span><span>).</span><span>items</span><span>():</span>
        <span>numerator</span> <span>=</span> <span>freq</span> <span>*</span> <span>(</span><span>self</span><span>.</span><span>k1</span> <span>+</span> <span>1</span><span>)</span>
        <span>denominator</span> <span>=</span> <span>freq</span> <span>+</span> <span>self</span><span>.</span><span>k1</span> <span>*</span> <span>(</span><span>1</span> <span>-</span> <span>self</span><span>.</span><span>b</span> <span>+</span> <span>self</span><span>.</span><span>b</span> <span>*</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>[</span><span>url</span><span>])</span> <span>/</span> <span>avdl</span><span>)</span>
        <span>result</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>idf_score</span> <span>*</span> <span>numerator</span> <span>/</span> <span>denominator</span>
    <span>return</span> <span>result</span>
</code></pre></div></div>

<p>This method receives a keyword, and for all the indexed documents it computes the BM25 score for that keyword. With this method we can finally implement the <code>search</code> method, which will be the one we’ll use to make queries to our search engine.</p>

<p>The <code>search</code> method receives a query, normalizes it, extracts its keywords (ie: splits it by space), computes the BM25 scores for each keyword, and returns a dictionary of URLs with their total score.</p>

<div><div><pre><code><span>def</span> <span>search</span><span>(</span><span>self</span><span>,</span> <span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]:</span>
    <span>keywords</span> <span>=</span> <span>normalize_string</span><span>(</span><span>query</span><span>).</span><span>split</span><span>(</span><span>&#34; &#34;</span><span>)</span>
    <span>url_scores</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]</span> <span>=</span> <span>{}</span>
    <span>for</span> <span>kw</span> <span>in</span> <span>keywords</span><span>:</span>
        <span>kw_urls_score</span> <span>=</span> <span>self</span><span>.</span><span>bm25</span><span>(</span><span>kw</span><span>)</span>
        <span>url_scores</span> <span>=</span> <span>update_url_scores</span><span>(</span><span>url_scores</span><span>,</span> <span>kw_urls_score</span><span>)</span>
    <span>return</span> <span>url_scores</span>
</code></pre></div></div>

<p>Following the same example as before, we can use it to search as</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> from microsearch.engine import engine
<span>&gt;&gt;&gt;</span> engine.index<span>(</span><span>&#34;Foo&#34;</span>, <span>&#34;Hello, World! My name is Foo!&#34;</span><span>)</span>
<span>&gt;&gt;&gt;</span> engine.index<span>(</span><span>&#34;Bar&#34;</span>, <span>&#34;Hello, World! My name is Bar, I&#39;m not Foo!&#34;</span><span>)</span>
<span>&gt;&gt;&gt;</span> engine.search<span>(</span><span>&#34;foo&#34;</span><span>)</span>
<span>{</span><span>&#39;Foo&#39;</span>: 0.19869271730423296, <span>&#39;Bar&#39;</span>: 0.16844281759753774<span>}</span>
<span>&gt;&gt;&gt;</span> engine.search<span>(</span><span>&#34;foo bar&#34;</span><span>)</span>
<span>{</span><span>&#39;Foo&#39;</span>: 0.19869271730423296, <span>&#39;Bar&#39;</span>: 0.8088260293054897<span>}</span>
</code></pre></div></div>

<p>Putting everything together, we have a search engine class that implements the functionalities to index and search documents in less than 80 lines of code.</p>

<details>
<summary>
Complete code to have a search engine in 80 lines of Python
</summary>

<figure><pre><code data-lang="python"><span>from</span> <span>collections</span> <span>import</span> <span>defaultdict</span>
<span>from</span> <span>math</span> <span>import</span> <span>log</span>
<span>import</span> <span>string</span>


<span>def</span> <span>update_url_scores</span><span>(</span><span>old</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>],</span> <span>new</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]):</span>
    <span>for</span> <span>url</span><span>,</span> <span>score</span> <span>in</span> <span>new</span><span>.</span><span>items</span><span>():</span>
        <span>if</span> <span>url</span> <span>in</span> <span>old</span><span>:</span>
            <span>old</span><span>[</span><span>url</span><span>]</span> <span>+=</span> <span>score</span>
        <span>else</span><span>:</span>
            <span>old</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>score</span>
    <span>return</span> <span>old</span>

<span>def</span> <span>normalize_string</span><span>(</span><span>input_string</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>translation_table</span> <span>=</span> <span>str</span><span>.</span><span>maketrans</span><span>(</span><span>string</span><span>.</span><span>punctuation</span><span>,</span> <span>&#39; &#39;</span> <span>*</span> <span>len</span><span>(</span><span>string</span><span>.</span><span>punctuation</span><span>))</span>
    <span>string_without_punc</span> <span>=</span> <span>input_string</span><span>.</span><span>translate</span><span>(</span><span>translation_table</span><span>)</span>
    <span>string_without_double_spaces</span> <span>=</span> <span>&#39; &#39;</span><span>.</span><span>join</span><span>(</span><span>string_without_punc</span><span>.</span><span>split</span><span>())</span>
    <span>return</span> <span>string_without_double_spaces</span><span>.</span><span>lower</span><span>()</span>


<span>class</span> <span>SearchEngine</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>k1</span><span>:</span> <span>float</span> <span>=</span> <span>1.5</span><span>,</span> <span>b</span><span>:</span> <span>float</span> <span>=</span> <span>0.75</span><span>):</span>
        <span>self</span><span>.</span><span>_index</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]]</span> <span>=</span> <span>defaultdict</span><span>(</span><span>lambda</span><span>:</span> <span>defaultdict</span><span>(</span><span>int</span><span>))</span>
        <span>self</span><span>.</span><span>_documents</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]</span> <span>=</span> <span>{}</span>
        <span>self</span><span>.</span><span>k1</span> <span>=</span> <span>k1</span>
        <span>self</span><span>.</span><span>b</span> <span>=</span> <span>b</span>

    <span>@</span><span>property</span>
    <span>def</span> <span>posts</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>list</span><span>[</span><span>str</span><span>]:</span>
        <span>return</span> <span>list</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>.</span><span>keys</span><span>())</span>

    <span>@</span><span>property</span>
    <span>def</span> <span>number_of_documents</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
        <span>return</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>)</span>

    <span>@</span><span>property</span>
    <span>def</span> <span>avdl</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
        <span># todo: refactor this. it can be slow to compute it every time. compute it once and cache it
</span>        <span>return</span> <span>sum</span><span>(</span><span>len</span><span>(</span><span>d</span><span>)</span> <span>for</span> <span>d</span> <span>in</span> <span>self</span><span>.</span><span>_documents</span><span>.</span><span>values</span><span>())</span> <span>/</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>)</span>

    <span>def</span> <span>idf</span><span>(</span><span>self</span><span>,</span> <span>kw</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
        <span>N</span> <span>=</span> <span>self</span><span>.</span><span>number_of_documents</span>
        <span>n_kw</span> <span>=</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>get_urls</span><span>(</span><span>kw</span><span>))</span>
        <span>return</span> <span>log</span><span>((</span><span>N</span> <span>-</span> <span>n_kw</span> <span>+</span> <span>0.5</span><span>)</span> <span>/</span> <span>(</span><span>n_kw</span> <span>+</span> <span>0.5</span><span>)</span> <span>+</span> <span>1</span><span>)</span>

    <span>def</span> <span>bm25</span><span>(</span><span>self</span><span>,</span> <span>kw</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]:</span>
        <span>result</span> <span>=</span> <span>{}</span>
        <span>idf_score</span> <span>=</span> <span>self</span><span>.</span><span>idf</span><span>(</span><span>kw</span><span>)</span>
        <span>avdl</span> <span>=</span> <span>self</span><span>.</span><span>avdl</span>
        <span>for</span> <span>url</span><span>,</span> <span>freq</span> <span>in</span> <span>self</span><span>.</span><span>get_urls</span><span>(</span><span>kw</span><span>).</span><span>items</span><span>():</span>
            <span>numerator</span> <span>=</span> <span>freq</span> <span>*</span> <span>(</span><span>self</span><span>.</span><span>k1</span> <span>+</span> <span>1</span><span>)</span>
            <span>denominator</span> <span>=</span> <span>freq</span> <span>+</span> <span>self</span><span>.</span><span>k1</span> <span>*</span> <span>(</span>
                <span>1</span> <span>-</span> <span>self</span><span>.</span><span>b</span> <span>+</span> <span>self</span><span>.</span><span>b</span> <span>*</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>_documents</span><span>[</span><span>url</span><span>])</span> <span>/</span> <span>avdl</span>
            <span>)</span>
            <span>result</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>idf_score</span> <span>*</span> <span>numerator</span> <span>/</span> <span>denominator</span>
        <span>return</span> <span>result</span>

    <span>def</span> <span>search</span><span>(</span><span>self</span><span>,</span> <span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]:</span>
        <span>keywords</span> <span>=</span> <span>normalize_string</span><span>(</span><span>query</span><span>).</span><span>split</span><span>(</span><span>&#34; &#34;</span><span>)</span>
        <span>url_scores</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>]</span> <span>=</span> <span>{}</span>
        <span>for</span> <span>kw</span> <span>in</span> <span>keywords</span><span>:</span>
            <span>kw_urls_score</span> <span>=</span> <span>self</span><span>.</span><span>bm25</span><span>(</span><span>kw</span><span>)</span>
            <span>url_scores</span> <span>=</span> <span>update_url_scores</span><span>(</span><span>url_scores</span><span>,</span> <span>kw_urls_score</span><span>)</span>
        <span>return</span> <span>url_scores</span>

    <span>def</span> <span>index</span><span>(</span><span>self</span><span>,</span> <span>url</span><span>:</span> <span>str</span><span>,</span> <span>content</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>self</span><span>.</span><span>_documents</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>content</span>
        <span>words</span> <span>=</span> <span>normalize_string</span><span>(</span><span>content</span><span>).</span><span>split</span><span>(</span><span>&#34; &#34;</span><span>)</span>
        <span>for</span> <span>word</span> <span>in</span> <span>words</span><span>:</span>
            <span>self</span><span>.</span><span>_index</span><span>[</span><span>word</span><span>][</span><span>url</span><span>]</span> <span>+=</span> <span>1</span>

    <span>def</span> <span>bulk_index</span><span>(</span><span>self</span><span>,</span> <span>documents</span><span>:</span> <span>list</span><span>[</span><span>tuple</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]]):</span>
        <span>for</span> <span>url</span><span>,</span> <span>content</span> <span>in</span> <span>documents</span><span>:</span>
            <span>self</span><span>.</span><span>index</span><span>(</span><span>url</span><span>,</span> <span>content</span><span>)</span>

    <span>def</span> <span>get_urls</span><span>(</span><span>self</span><span>,</span> <span>keyword</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]:</span>
        <span>keyword</span> <span>=</span> <span>normalize_string</span><span>(</span><span>keyword</span><span>)</span>
        <span>return</span> <span>self</span><span>.</span><span>_index</span><span>[</span><span>keyword</span><span>]</span></code></pre></figure>


</details>
<h2 id="interface">Interface</h2>

<p>Finally, once we have a search engine, we want to expose it somehow. In my case, I decided to build a small FastAPI app that exposes an endpoint with the search engine, and then it also renders a simple webpage that allows you to search. To make the output easier to read I decided to just select the top-N URLs.</p>

<details>
<summary>
FastAPI search engine app
</summary>


<figure><pre><code data-lang="python"><span>import</span> <span>argparse</span>
<span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span><span>,</span> <span>Form</span><span>,</span> <span>Path</span><span>,</span> <span>Request</span>
<span>from</span> <span>fastapi.responses</span> <span>import</span> <span>HTMLResponse</span>
<span>from</span> <span>fastapi.staticfiles</span> <span>import</span> <span>StaticFiles</span>
<span>from</span> <span>fastapi.templating</span> <span>import</span> <span>Jinja2Templates</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>from</span> <span>uvicorn</span> <span>import</span> <span>run</span>

<span>from</span> <span>microsearch.engine</span> <span>import</span> <span>SearchEngine</span>


<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>
<span>engine</span> <span>=</span> <span>SearchEngine</span><span>()</span>
<span>templates</span> <span>=</span> <span>Jinja2Templates</span><span>(</span><span>directory</span><span>=</span><span>&#34;templates&#34;</span><span>)</span>
<span>app</span><span>.</span><span>mount</span><span>(</span><span>&#34;/static&#34;</span><span>,</span> <span>StaticFiles</span><span>(</span><span>directory</span><span>=</span><span>&#34;static&#34;</span><span>),</span> <span>name</span><span>=</span><span>&#34;static&#34;</span><span>)</span>


<span>def</span> <span>get_top_urls</span><span>(</span><span>scores_dict</span><span>:</span> <span>dict</span><span>,</span> <span>n</span><span>:</span> <span>int</span><span>):</span>
    <span>sorted_urls</span> <span>=</span> <span>sorted</span><span>(</span><span>scores_dict</span><span>.</span><span>items</span><span>(),</span> <span>key</span><span>=</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>[</span><span>1</span><span>],</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>
    <span>top_n_urls</span> <span>=</span> <span>sorted_urls</span><span>[:</span><span>n</span><span>]</span>
    <span>top_n_dict</span> <span>=</span> <span>dict</span><span>(</span><span>top_n_urls</span><span>)</span>
    <span>return</span> <span>top_n_dict</span>


<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>&#34;/&#34;</span><span>,</span> <span>response_class</span><span>=</span><span>HTMLResponse</span><span>)</span>
<span>async</span> <span>def</span> <span>search</span><span>(</span><span>request</span><span>:</span> <span>Request</span><span>):</span>
    <span>posts</span> <span>=</span> <span>engine</span><span>.</span><span>posts</span>
    <span>return</span> <span>templates</span><span>.</span><span>TemplateResponse</span><span>(</span>
        <span>&#34;search.html&#34;</span><span>,</span> <span>{</span><span>&#34;request&#34;</span><span>:</span> <span>request</span><span>,</span> <span>&#34;posts&#34;</span><span>:</span> <span>posts</span><span>}</span>
    <span>)</span>


<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>&#34;/results/{query}&#34;</span><span>,</span> <span>response_class</span><span>=</span><span>HTMLResponse</span><span>)</span>
<span>async</span> <span>def</span> <span>search_results</span><span>(</span><span>request</span><span>:</span> <span>Request</span><span>,</span> <span>query</span><span>:</span> <span>str</span> <span>=</span> <span>Path</span><span>(...)):</span>
    <span>results</span> <span>=</span> <span>engine</span><span>.</span><span>search</span><span>(</span><span>query</span><span>)</span>
    <span>results</span> <span>=</span> <span>get_top_urls</span><span>(</span><span>results</span><span>,</span> <span>n</span><span>=</span><span>5</span><span>)</span>
    <span>return</span> <span>templates</span><span>.</span><span>TemplateResponse</span><span>(</span>
        <span>&#34;results.html&#34;</span><span>,</span> <span>{</span><span>&#34;request&#34;</span><span>:</span> <span>request</span><span>,</span> <span>&#34;results&#34;</span><span>:</span> <span>results</span><span>,</span> <span>&#34;query&#34;</span><span>:</span> <span>query</span><span>}</span>
    <span>)</span>


<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>&#34;/about&#34;</span><span>)</span>
<span>def</span> <span>read_about</span><span>(</span><span>request</span><span>:</span> <span>Request</span><span>):</span>
    <span>return</span> <span>templates</span><span>.</span><span>TemplateResponse</span><span>(</span><span>&#34;about.html&#34;</span><span>,</span> <span>{</span><span>&#34;request&#34;</span><span>:</span> <span>request</span><span>})</span>


<span>def</span> <span>parse_args</span><span>():</span>
    <span>parser</span> <span>=</span> <span>argparse</span><span>.</span><span>ArgumentParser</span><span>()</span>
    <span>parser</span><span>.</span><span>add_argument</span><span>(</span><span>&#34;--data-path&#34;</span><span>)</span>
    <span>return</span> <span>parser</span><span>.</span><span>parse_args</span><span>()</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span><span>:</span>
    <span>args</span> <span>=</span> <span>parse_args</span><span>()</span>
    <span>data</span> <span>=</span> <span>pd</span><span>.</span><span>read_parquet</span><span>(</span><span>args</span><span>.</span><span>data_path</span><span>)</span>
    <span>content</span> <span>=</span> <span>list</span><span>(</span><span>zip</span><span>(</span><span>data</span><span>[</span><span>&#34;URL&#34;</span><span>].</span><span>values</span><span>,</span> <span>data</span><span>[</span><span>&#34;content&#34;</span><span>].</span><span>values</span><span>))</span>
    <span>engine</span><span>.</span><span>bulk_index</span><span>(</span><span>content</span><span>)</span>
    <span>run</span><span>(</span><span>app</span><span>,</span> <span>host</span><span>=</span><span>&#34;127.0.0.1&#34;</span><span>,</span> <span>port</span><span>=</span><span>8000</span><span>)</span></code></pre></figure>


</details>

<p>If you run it you’ll see something like</p>

<!-- _includes/image.html -->
<figure>
  <img src="https://patrickweaver.net/docs/search-engine/screenshot-fastapi-app.png" alt="Search Engine interface." width="700"/>
  <figcaption>Search Engine interface.</figcaption>
</figure>

<p>then you can introduce your queries using the search box and search the indexed documents. For example, if I search for <code>how to build a search engine?</code></p>

<!-- _includes/image.html -->
<figure>
  <img src="https://patrickweaver.net/docs/search-engine/search-results.png" alt="Search results for the query `how to build a search engine`." width="700"/>
  <figcaption>Search results for the query `how to build a search engine`.</figcaption>
</figure>

<p>I’m aware this is not the nicest UI ever, and the UX can be improved a lot. However, it works fast, the results aren’t so bad, and most importantly, I’ve built it myself from scratch.</p>

<h2 id="missing-features">Missing features</h2>

<p>For the readers who usually work with search engines, it’s obvious that there are a lot of missing features in my implementation. This is a non-exhaustive list of what it’s missing.</p>

<ul>
  <li>This implementation doesn’t have <strong>query operators</strong>, ie operators that allow you to tune how the query behaves. For example, if you google <code>how to build a search engine -solr</code> you’ll get results that don’t contain the word <code>solr</code> in them.</li>
  <li>The reverse index works by indexing single keywords, and there’s no option to <strong>index n-grams</strong>. Google allows you to search for <code>&#34;search engine&#34;</code> (notice the double quotes) and it’ll only show you results where the two words appear in this specific order.</li>
  <li>Also, this implementation doesn’t have <strong>query or document expansion</strong>, so if you search <code>engine</code> you won’t get documents with the word <code>engines</code>.</li>
  <li>The <strong>crawling and indexing parts are independent</strong> but we could implement it in such a way that the indexing happens during the crawling, ie: as soon as we have a document we index it. This could be done asynchronously as well.</li>
</ul>



<p>I’ve enjoyed a lot working on this project. It has helped me to understand better how Solr works under the hood, and while I still have a lot to learn I think I have a better intuition now.</p>

<p>As a side effect, I’ve also learned how amazing is writing asynchronous code for IO-bounded operations. My first implementation of the crawler took ages to finish, and with the async implementation, it took a moment to finish.</p>

<p>My next step on my journey to build a personal search engine is to implement semantic search capabilities in the search engine. I’ve been playing a bit with embedding models and ANN, so my next step is to add this functionality to microsearch. Keep tuned for more!</p>

<hr/>





  <!-- Footer -->
  



  </div></div>
  </body>
</html>
