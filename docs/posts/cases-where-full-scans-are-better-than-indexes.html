<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.jefftk.com/p/you-dont-always-need-indexes">Original</a>
    <h1>Cases where full scans are better than indexes</h1>
    
    <div id="readability-page-1" class="page"><div>

<div>

    <p><span>

Sometimes you have a lot of data, and one approach to support quick
searches is pre-processing it to build an index so a search can
involve only looking at a small fraction of the total data.  The
threshold at which it&#39;s worth switching to indexing, though, might be
higher than you&#39;d guess.  Here are some cases I&#39;ve worked on where
full scans were better engineering choices:

</span></p>
<ul>

<li><p>Ten years ago I wrote an interoffice messaging application for
a small billing service.  Messages were stored in MySQL and I was
going to add indexing if full-text searches got slow or we had load
issues, but even with ten years worth of messages to search it stayed
responsive.

</p></li>
<li><p>I recently <a href="https://news.ycombinator.com/item?id=35840944">came across</a>
someone maintaining a 0.5GB full text index to support searching their
shell history, 100k commands.  I <a href="https://www.jefftk.com/p/logging-shell-history-in-zsh">use</a>
<code>grep</code> on a flat file, and testing now it takes 200ms for a
query across my 180k history entries.

</p></li>
<li><p>My <a href="https://www.trycontra.com/">contra dance search
tool</a> ranks each dance in response to your query, with no
geospatial indexing, because there are just ~350 dances.

</p></li>
<li><p>The <a href="https://www.jefftk.com/mgs-counts/">viral counts
explorer</a> I&#39;ve been playing with for work searches the taxonomic
tree of human viruses in real time, scanning ~15k names with JS&#39;s
&#34;includes&#34; command about as fast as you can type.

</p></li>
<li><p>When I worked in ads I would often need to debug issues using
production logs, and would use Dremel (<a href="https://research.google/pubs/pub36632.pdf">Melnik
2010</a>, <a href="https://research.google/pubs/pub49489.pdf">Melnik
2020</a>) to run a distributed scan of very large amounts of data at
interactive speeds.  Because queries were relatively rare, an index
would have been far more expensive to maintain.

</p></li>
</ul>

<p>

Unless you know from the start that you&#39;ll be searching hundreds of
millions of records, consider starting with simple scans and only add
indexing if you can&#39;t get acceptable performance.  And even then, if
queries are rare and highly varied you may still do better to do
the work at query time instead of ingestion time.

  </p>
</div>



  
<p>Comment via: <a href="https://www.facebook.com/jefftk/posts/pfbid02PXduG7d9zAyryrVRyRzsW3H6PYEA6ewsWSaATPY1w5jWbQmGnvHjkoZA5nd9rC3Ll">facebook</a>, <a href="https://lesswrong.com/posts/XZWe727eGdkREihbo">lesswrong</a>, <a href="https://mastodon.mit.edu/@jefftk/110429759665224536">mastodon</a></p>

</div></div>
  </body>
</html>
