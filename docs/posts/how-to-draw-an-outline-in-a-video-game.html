<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ameye.dev/notes/rendering-outlines/">Original</a>
    <h1>How to draw an outline in a video game</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Different techniques for rendering outlines in Unity.</p><p><b>21</b> minute read</p><h2 id="introduction" tabindex="-1"><a href="#introduction" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Introduction</h2><p>Rendering outlines is a technique that is often used in games either for <mark>aesthetic</mark> reasons or for supporting <mark>gameplay</mark> by using it for highlights and selections around an object. For example in the game Sable, outlines are used to create a comic-book-like style. In The Last of Us, outlines are used to highlight enemies when the player goes into stealth mode.</p><p>In this post, I will discuss 5 techniques for rendering an outline around an object.</p><blockquote><p>üñçÔ∏è Interested in an outline rendering toolkit for Unity? 3 years after making this post <a href="https://assetstore.unity.com/packages/slug/294140?aid=1011l3n8v&amp;pubref=site" target="_blank" rel="noopener noreferrer">I made Linework</a>!</p></blockquote><h2 id="rim-effects" tabindex="-1"><a href="#rim-effects" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Rim Effects</h2><p><picture><source type="image/webp" srcset="rim-effect/final.png-400w.webp 400w, rim-effect/final.png-800w.webp 800w, rim-effect/final.png-1200w.webp 1200w, rim-effect/final.png-1907w.webp 1907w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Rim effect outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-400w.jpeg" width="1907" height="748" srcset="rim-effect/final.png-400w.jpeg 400w, rim-effect/final.png-800w.jpeg 800w, rim-effect/final.png-1200w.jpeg 1200w, rim-effect/final.png-1907w.jpeg 1907w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="technique" tabindex="-1"><a href="#technique" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Technique</h3><p>One of the most basic outline effects can be achieved by using a so called <mark>fresnel effect</mark> which can be used to render an outline on the rim/edge of an object. The fresnel effect describes the reflection/transmission of light when falling onto a transparent surface. However, when using it for rendering outlines, this physical meaning of the effect is not important. The following formula is used to form the outline.</p><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>p</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mn>1.0</mn><mo>‚àí</mo><mi>s</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>t</mi><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Out = pow((1.0 - saturate(dot(N, V))), P)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>O</span><span>u</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>p</span><span>o</span><span>w</span><span>(</span><span>(</span><span>1</span><span>.</span><span>0</span><span></span><span>‚àí</span><span></span></span><span><span></span><span>s</span><span>a</span><span>t</span><span>u</span><span>r</span><span>a</span><span>t</span><span>e</span><span>(</span><span>d</span><span>o</span><span>t</span><span>(</span><span>N</span><span>,</span><span></span><span>V</span><span>)</span><span>)</span><span>)</span><span>,</span><span></span><span>P</span><span>)</span></span></span></span></span></p><p>The formula takes the dot product between the normalized normal vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span> and the normalized view direction <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>V</span></span></span></span>. Then, this gets exponentiated with a power <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>P</span></span></span></span>. It is important to note that this is only an approximation of the fresnel effect, but it works well for our outlines.</p><p><picture><source type="image/webp" srcset="rim-effect/fresnel.png-400w.webp 400w, rim-effect/fresnel.png-800w.webp 800w, rim-effect/fresnel.png-1200w.webp 1200w, rim-effect/fresnel.png-1893w.webp 1893w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Fresnel effect." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-400w.jpeg" width="1893" height="748" srcset="rim-effect/fresnel.png-400w.jpeg 400w, rim-effect/fresnel.png-800w.jpeg 800w, rim-effect/fresnel.png-1200w.jpeg 1200w, rim-effect/fresnel.png-1893w.jpeg 1893w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>When putting this fresnel-based outline on a sphere, you see that when we approach the grazing angle (the edge/rim of the object), the effect gets stronger.</p><h3 id="implementation" tabindex="-1"><a href="#implementation" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Implementation</h3><p>For this approach, the objects that need to have an outline get rendered using a custom shader. This shader implements the fresnel effect and allows us to set the width, power, softness and color of the outline.</p><pre><code><span>float</span> edge1 <span>=</span> <span>1</span> <span>-</span> _OutlineWidth<span>;</span>
<span>float</span> edge2 <span>=</span> edge1 <span>+</span> _OutlineSoftness<span>;</span>
<span>float</span> fresnel <span>=</span> <span>pow</span><span>(</span><span>1.0</span> <span>-</span> <span>saturate</span><span>(</span><span>dot</span><span>(</span>normalWS<span>,</span> viewWS<span>)</span><span>)</span><span>,</span> _OutlinePower<span>)</span><span>;</span>
<span>return</span> <span>lerp</span><span>(</span><span>1</span><span>,</span> <span>smoothstep</span><span>(</span>edge1<span>,</span> edge2<span>,</span> fresnel<span>)</span><span>,</span> <span>step</span><span>(</span><span>0</span><span>,</span> edge1<span>)</span><span>)</span> <span>*</span> _OutlineColor<span>;</span></code></pre><p>The technique produces an outline that is always an <mark>inner line</mark> and is not visible outside of the object and so maybe shouldn&#39;t even be called an outline. By controlling the width, power and softness of the outline, it is possible to create hard lines or a more soft/glowy effect.</p><p>Characteristic for this approach is that it works well for objects like spheres and capsules with smooth and round edges, but it breaks down for objects like cubes or more complex models that have sharp edges.</p><p>For a cube for example, the outline will look really bad and not even resemble an outline. For a more complex model, you will have the issue of getting lots of uneven line widths, although the overall outline effect can look alright.</p><blockquote><p><strong>üí¨ Rim effect</strong> outlines are simple but only work well on spherical objects.</p></blockquote><h2 id="vertex-extrusion" tabindex="-1"><a href="#vertex-extrusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Vertex Extrusion</h2><p><picture><source type="image/webp" srcset="vertex-extrusion/final.png-400w.webp 400w, vertex-extrusion/final.png-800w.webp 800w, vertex-extrusion/final.png-1200w.webp 1200w, vertex-extrusion/final.png-4148w.webp 4148w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Vertex extrusion outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-400w.jpeg" width="4148" height="1648" srcset="vertex-extrusion/final.png-400w.jpeg 400w, vertex-extrusion/final.png-800w.jpeg 800w, vertex-extrusion/final.png-1200w.jpeg 1200w, vertex-extrusion/final.png-4148w.jpeg 4148w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="technique-1" tabindex="-1"><a href="#technique-1" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Technique</h3><p>The second technique uses a <mark>re-rendered/duplicate</mark> version of the original object/mesh to form the outline. This duplicate object gets shown <mark>behind</mark> the original object and its vertices get extruded in order to make the duplicate object larger than the original one. The duplicate object is usually just rendered with a flat color.</p><h3 id="extrusion-direction" tabindex="-1"><a href="#extrusion-direction" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Extrusion direction</h3><p>In order to make the duplicate mesh larger, we need to change the positions of its vertices. We will be moving the vertices a certain <mark>distance</mark> along a certain <mark>direction</mark>. The first step is to pick this direction.</p><h4>1. Vertex position</h4><p>The <mark>first method</mark> to enlarge the mesh is to simply scale it up. This is done by moving each vertex position along the vertex position. This may sound weird but the vertex position in local space, can be seen as a vector between the center of the object and the vertex position itself and so we can move the original vertex position along that vector. For the distance, we use a width parameter.</p><pre><code>
positionOS <span>+=</span> positionOS <span>*</span> width<span>;</span></code></pre><p>Doing this just kind of inflates the mesh.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/object-space-vertex-position.png-400w.webp 400w, vertex-extrusion/object-space-vertex-position.png-800w.webp 800w, vertex-extrusion/object-space-vertex-position.png-1200w.webp 1200w, vertex-extrusion/object-space-vertex-position.png-1904w.webp 1904w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Move along vertex position in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-400w.jpeg" width="1904" height="855" srcset="vertex-extrusion/object-space-vertex-position.png-400w.jpeg 400w, vertex-extrusion/object-space-vertex-position.png-800w.jpeg 800w, vertex-extrusion/object-space-vertex-position.png-1200w.jpeg 1200w, vertex-extrusion/object-space-vertex-position.png-1904w.jpeg 1904w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>For a sphere, all of the vertices have the same distance from the center point of the object and so they all get moved an equal amount. However, for other objects, these distances may vary and so vertices that are distanced further away from the center of the object, will get moved more. To fix this, you can normalize the vector along which the movement occurs.</p><pre><code>
positionOS <span>+=</span> <span>normalize</span><span>(</span>positionOS<span>)</span> <span>*</span> width<span>;</span></code></pre><p>The result is that now all the vertices get moved an equal distance in object space, usually resulting in an outline that looks more equal-width.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/object-space-normalized-vertex-position.png-400w.webp 400w, vertex-extrusion/object-space-normalized-vertex-position.png-800w.webp 800w, vertex-extrusion/object-space-normalized-vertex-position.png-1200w.webp 1200w, vertex-extrusion/object-space-normalized-vertex-position.png-1909w.webp 1909w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Move along normalized vertex position in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-400w.jpeg" width="1909" height="860" srcset="vertex-extrusion/object-space-normalized-vertex-position.png-400w.jpeg 400w, vertex-extrusion/object-space-normalized-vertex-position.png-800w.jpeg 800w, vertex-extrusion/object-space-normalized-vertex-position.png-1200w.jpeg 1200w, vertex-extrusion/object-space-normalized-vertex-position.png-1909w.jpeg 1909w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>However, due to working in object space, the outline still isn&#39;t a perfect equal-width outline. We will address this later.</p><h4>2. Normal vector</h4><p>A <mark>second method</mark> is to move the vertices along their normal vector.</p><pre><code>
positionOS <span>+=</span> normalOS <span>*</span> width<span>;</span></code></pre><p>The result is a pretty nice-looking outline for objects with smooth corners such as spheres and capsules. We&#39;re still working in object space so again, the outline isn&#39;t a perfect equal-width outline.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/object-space-normal-vector.png-400w.webp 400w, vertex-extrusion/object-space-normal-vector.png-800w.webp 800w, vertex-extrusion/object-space-normal-vector.png-1200w.webp 1200w, vertex-extrusion/object-space-normal-vector.png-1909w.webp 1909w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Move along normal vector in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-400w.jpeg" width="1909" height="860" srcset="vertex-extrusion/object-space-normal-vector.png-400w.jpeg 400w, vertex-extrusion/object-space-normal-vector.png-800w.jpeg 800w, vertex-extrusion/object-space-normal-vector.png-1200w.jpeg 1200w, vertex-extrusion/object-space-normal-vector.png-1909w.jpeg 1909w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>For objects with sharper corners such as cubes, you will get visible gaps in the outline. Any model with sharp angles will have these kind of artifacts.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/exploded-cube.png-400w.webp 400w, vertex-extrusion/exploded-cube.png-800w.webp 800w, vertex-extrusion/exploded-cube.png-1012w.webp 1012w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Outline gaps on objects with sharp corners." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-400w.jpeg" width="1012" height="938" srcset="vertex-extrusion/exploded-cube.png-400w.jpeg 400w, vertex-extrusion/exploded-cube.png-800w.jpeg 800w, vertex-extrusion/exploded-cube.png-1012w.jpeg 1012w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>This can be resolved by using custom-authored normals, addressed in the next method.</p><h4>3. Vertex color</h4><p>A <mark>third method</mark> is to move the vertices along their vertex color. The logic behind this is that you can generate custom normals and store those in the vertex color channels of the mesh. For example you could bake spherical (smooth) normals into vertex colors and use those for a cube mesh.</p><pre><code>
positionOS <span>+=</span> vertexColor <span>*</span> width<span>;</span></code></pre><p>You can see the the outline around the cube looks much better when using custom normals.</p><p>This method can avoid artifacts with models that have sharp edges but the big downside is the manual setup involved since you need to generate custom normals for your mesh, although this process can be automated using a script that bakes the normals.</p><h3 id="extrusion-space" tabindex="-1"><a href="#extrusion-space" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Extrusion space</h3><p>Once we have decided the direction along which we want to move the vertices, we need to choose in which coordinate space this extrusion should happen. During the vertex stage of our shader, the coordinates of the vertices start out being defined in object space and end up being transformed to clip space. This is done by applying the <mark>MVP (model/view/projection) matrix</mark>. Throughout the whole rendering pipeline, the coordinates of the vertices go through these spaces.</p><blockquote><p><strong>1.</strong> üì¶ object/model/local space</p></blockquote><blockquote><p><strong>2.</strong> üåç world space</p></blockquote><blockquote><p><strong>3.</strong> üì∑ camera/eye/view space</p></blockquote><blockquote><p><strong>4.</strong> ‚úÇÔ∏è (homogeneous) clip space</p></blockquote><blockquote><p><strong>5.</strong> üñ•Ô∏è screen space</p></blockquote><blockquote><p><strong>6.</strong> üñºÔ∏è viewport/window space</p></blockquote><p>The significance of these coordinate spaces for our outlines will be explained below.</p><h4>Object space</h4><p>The <mark>first method</mark> is to translate the vertices in object space.</p><pre><code>
IN<span>.</span>positionOS<span>.</span>xyz <span>+=</span> IN<span>.</span>positionOS<span>.</span>xyz <span>*</span> width<span>;</span></code></pre><p>There are 2 big issues with doing the outline in object space. This is because when working in object space, the MVP transformations are yet to be applied. These transformations will alter the shape of the outline, distorting it in the process. The issues are as follows:</p><ol><li><p><mark>Scaling</mark> of the outline</p><p>-&gt; when going from object space to world space (applying model matrix M)</p></li><li><p><mark>Foreshortening</mark></p><p>-&gt; due to the perspective divide happening when going from clip space to screen space</p></li></ol><p><picture><source type="image/webp" srcset="vertex-extrusion/foreshortening.png-400w.webp 400w, vertex-extrusion/foreshortening.png-800w.webp 800w, vertex-extrusion/foreshortening.png-871w.webp 871w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-400w.jpeg" width="871" height="721" srcset="vertex-extrusion/foreshortening.png-400w.jpeg 400w, vertex-extrusion/foreshortening.png-800w.jpeg 800w, vertex-extrusion/foreshortening.png-871w.jpeg 871w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>Another consideration is that when translating the vertices in object space, this is done in a 3D space. This means that some translations will be done directly towards or away from the camera, not contributing to the apparent-width of the outline. Instead of using object-space units, it might be better to be able to control the outline width in terms of screen-space pixels.</p><h4>Clip space</h4><p>A <mark>second method</mark> is to perform the translations of the vertices in clip space.</p><pre><code>
OUT<span>.</span>positionHCS <span>=</span> <span>TransformObjectToHClip</span><span>(</span>IN<span>.</span>positionOS<span>.</span>xyz<span>)</span><span>;</span>


<span>float3</span> normalHCS <span>=</span> <span>mul</span><span>(</span><span>(</span><span>float3x3</span><span>)</span>UNITY_MATRIX_VP<span>,</span> <span>mul</span><span>(</span><span>(</span><span>float3x3</span><span>)</span>UNITY_MATRIX_M<span>,</span> IN<span>.</span>normalOS<span>)</span><span>)</span><span>;</span>


OUT<span>.</span>positionHCS<span>.</span>xy <span>+=</span> <span>normalize</span><span>(</span>normalHCS<span>.</span>xy<span>)</span> <span>/</span> _ScreenParams<span>.</span>xy <span>*</span> OUT<span>.</span>positionHCS<span>.</span>w <span>*</span> width <span>*</span> <span>2</span><span>;</span></code></pre><p>As a first step, the vertex position and normal vector are both transformed from <mark>object space to clip space</mark>. As a second step, the vertex gets translated along its normal vector. Since we are working in a 2D space now, <mark>only the x and y</mark> coordinates of the vertex positions get altered. The offset gets divided by the width and height of the screen to account for the <mark>aspect ratio</mark> of the screen. Then, the offset gets multiplied by the w component of the clip space vertex position. This is done because in the next stage, the clip space coordinates will be converted to screen space coordinates with a so-called <mark>perspective divide</mark> which will divide the clip space x/y/z coordinates by the clip space w coordinate. Since we want to end up with the same outline after this transformation to screen space, we pre-multiply by this clip space w coordinate so that the perspective divide will have no net effect on the outline. Finally, the offset gets multiplied by our desired outline width and a factor 2 so that a width unit 1 will correspond with exactly 1 pixel on the screen.</p><p><em>Phew!</em></p><p>I recommend reading this post on <a href="https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity/#working-in-clip-space" target="_blank" rel="noopener noreferrer">creating an outline in clip space</a>. Having something explained in different ways is always useful.</p><p>The result of this whole process is a very clean outline. Since we&#39;re working in clip space, the outline is equal-width, extending the same amount (visually) around the object.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/clip-space-normal-vector.png-400w.webp 400w, vertex-extrusion/clip-space-normal-vector.png-800w.webp 800w, vertex-extrusion/clip-space-normal-vector.png-1200w.webp 1200w, vertex-extrusion/clip-space-normal-vector.png-1908w.webp 1908w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Move along normal vector in clip space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-400w.jpeg" width="1908" height="700" srcset="vertex-extrusion/clip-space-normal-vector.png-400w.jpeg 400w, vertex-extrusion/clip-space-normal-vector.png-800w.jpeg 800w, vertex-extrusion/clip-space-normal-vector.png-1200w.jpeg 1200w, vertex-extrusion/clip-space-normal-vector.png-1908w.jpeg 1908w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>Still, (if not using custom-authored normals) the method has issues with meshes that have sharp-corners, resulting in gaps in the outline. This will be apparent in meshes that are more complex. Also, if the normals of the mesh are not set up correctly and some of them are facing the wrong way, the vertices of the outline will be moved in the opposite direction, resulting in gaps in the outline. This method being dependent on the normal vectors of the mesh is the most important downside. This is visible for the mesh in the image below.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.webp 400w, vertex-extrusion/clip-space-normal-vector-complex-model.png-800w.webp 800w, vertex-extrusion/clip-space-normal-vector-complex-model.png-1200w.webp 1200w, vertex-extrusion/clip-space-normal-vector-complex-model.png-1901w.webp 1901w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Move along normal vector in clip space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.jpeg" width="1901" height="819" srcset="vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.jpeg 400w, vertex-extrusion/clip-space-normal-vector-complex-model.png-800w.jpeg 800w, vertex-extrusion/clip-space-normal-vector-complex-model.png-1200w.jpeg 1200w, vertex-extrusion/clip-space-normal-vector-complex-model.png-1901w.jpeg 1901w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="masking" tabindex="-1"><a href="#masking" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Masking</h3><p>The duplicate mesh should be rendered so that only the outline sticking out is visible. The most common solution for this is to <mark>cull the front-facing geometry</mark> of the duplicated mesh, using the backfaces of the geometry to form the outline. A depth test of <mark>less than or equal to</mark> is used to make sure the backfaces only show up where the outlines should go.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/cull-front.png-400w.webp 400w, vertex-extrusion/cull-front.png-800w.webp 800w, vertex-extrusion/cull-front.png-1200w.webp 1200w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Cull front." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-400w.jpeg" width="1200" height="1750" srcset="vertex-extrusion/cull-front.png-400w.jpeg 400w, vertex-extrusion/cull-front.png-800w.jpeg 800w, vertex-extrusion/cull-front.png-1200w.jpeg 1200w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>Another option is to use a <mark>stencil mask</mark> to prevent the duplicate mesh from showing up in front of the original mesh. When using this stencil mask method, no culling is needed. One side-effect is that there will be absolutely <mark>no inner lines</mark> on the inside of the object and if two objects overlap, the outline will also only be visible around those 2 objects.</p><p><picture><source type="image/webp" srcset="vertex-extrusion/stencil-mask.png-400w.webp 400w, vertex-extrusion/stencil-mask.png-800w.webp 800w, vertex-extrusion/stencil-mask.png-1200w.webp 1200w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Stencil mask." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-400w.jpeg" width="1200" height="1750" srcset="vertex-extrusion/stencil-mask.png-400w.jpeg 400w, vertex-extrusion/stencil-mask.png-800w.jpeg 800w, vertex-extrusion/stencil-mask.png-1200w.jpeg 1200w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><blockquote><p><strong>üí¨ Vertex extrusion</strong> outlines are simple and look good when done in clip space. There are issues with sharp corners but these can be mitigated by using custom normals, which do require some extra setup.</p></blockquote><h2 id="blurred-buffer" tabindex="-1"><a href="#blurred-buffer" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Blurred Buffer</h2><p><picture><source type="image/webp" srcset="blurred-buffer/final.png-400w.webp 400w, blurred-buffer/final.png-800w.webp 800w, blurred-buffer/final.png-1200w.webp 1200w, blurred-buffer/final.png-1907w.webp 1907w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-400w.jpeg" width="1907" height="675" srcset="blurred-buffer/final.png-400w.jpeg 400w, blurred-buffer/final.png-800w.jpeg 800w, blurred-buffer/final.png-1200w.jpeg 1200w, blurred-buffer/final.png-1907w.jpeg 1907w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="technique-2" tabindex="-1"><a href="#technique-2" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Technique</h3><p>A third method to render an outline is by using something that I call a <mark>blurred buffer</mark>. For this technique, the silhouette of an object gets rendered to a buffer. This silhouette buffer is then blurred which expands the silhouette which is then used to render the outline.</p><h3 id="1.-silhouette-buffer" tabindex="-1"><a href="#1.-silhouette-buffer" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>1. Silhouette Buffer</h3><p>The first step of this technique is creating the silhouette buffer. For this, each object gets rendered to a texture using a shader that outputs a plain color.</p><p>You can use the color white for all silhouettes, allowing you to choose a single color for all outlines at the end by multiplying with the desired outline color. Alternatively, you can render each object silhouette with a specific color if you want each object to have a different colored outline.</p><h3 id="2.-blur-pass" tabindex="-1"><a href="#2.-blur-pass" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>2. Blur Pass</h3><p>The blur pass is used for expanding the silhouette buffer. This is usually done using a box blur or gaussian blur. To improve performance, the silhouette buffer can be <mark>scaled down</mark> before blurring. This is advantageous because blur passes can be expensive, having to process multiple pixels per pixel since they work by taking a (weighted) average of the pixels surrounding a given pixel.</p><p><picture><source type="image/webp" srcset="blurred-buffer/downscale.png-400w.webp 400w, blurred-buffer/downscale.png-800w.webp 800w, blurred-buffer/downscale.png-1200w.webp 1200w, blurred-buffer/downscale.png-1920w.webp 1920w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-400w.jpeg" width="1920" height="1080" srcset="blurred-buffer/downscale.png-400w.jpeg 400w, blurred-buffer/downscale.png-800w.jpeg 800w, blurred-buffer/downscale.png-1200w.jpeg 1200w, blurred-buffer/downscale.png-1920w.jpeg 1920w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>Additionally, the blur pass should be done in <mark>2 passes</mark>. This brings down the complexity of the algorithm from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>O</span><span>(</span><span><span>N</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span><span>)</span></span></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>2</mn><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(2N)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>O</span><span>(</span><span>2</span><span>N</span><span>)</span></span></span></span>. This can be done if the used blur algorithm is a so-called <a href="https://en.wikipedia.org/wiki/Separable_filter" target="_blank" rel="noopener noreferrer">separable filter</a> which is the case both for a box blur and a gaussian blur. When doing the blur in 2 passes, the pixels get first blurred vertically, and then the vertically-blurred buffer gets blurred horizontally resulting in the final blur.</p><p>A simple seperable box blur can be implemented by taking the non-weighted average around a given pixel. For a gaussian blur, the used kernel will be a gaussian kernel so that the weighted-average will be taken.</p><pre><code>
<span>half4</span> sum <span>=</span> <span>0</span><span>;</span>
<span>int</span> samples <span>=</span> <span>2</span> <span>*</span> _KernelSize <span>+</span> <span>1</span><span>;</span>
<span>for</span> <span>(</span><span>float</span> y <span>=</span> <span>0</span><span>;</span> y <span>&lt;</span> samples<span>;</span> y<span>++</span><span>)</span>
<span>{</span>
    <span>float2</span> offset <span>=</span> <span>float2</span><span>(</span><span>0</span><span>,</span> y <span>-</span> _KernelSize<span>)</span><span>;</span>
    sum <span>+=</span> <span>SAMPLE_TEXTURE2D</span><span>(</span>_MainTex<span>,</span> sampler_MainTex<span>,</span> IN<span>.</span>uv <span>+</span> offset <span>*</span> _MainTex_TexelSize<span>.</span>xy<span>)</span><span>;</span>
<span>}</span>
<span>return</span> sum <span>/</span> samples<span>;</span>


<span>half4</span> sum <span>=</span> <span>0</span><span>;</span>
<span>int</span> samples <span>=</span> <span>2</span> <span>*</span> _KernelSize <span>+</span> <span>1</span><span>;</span>
<span>for</span> <span>(</span><span>float</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> samples<span>;</span> x<span>++</span><span>)</span>
<span>{</span>
    <span>float2</span> offset <span>=</span> <span>float2</span><span>(</span>x <span>-</span> _KernelSize<span>,</span> <span>0</span><span>)</span><span>;</span>
    sum <span>+=</span> <span>SAMPLE_TEXTURE2D</span><span>(</span>_MainTex<span>,</span> sampler_MainTex<span>,</span> IN<span>.</span>uv <span>+</span> offset <span>*</span> _MainTex_TexelSize<span>.</span>xy<span>)</span><span>;</span>
<span>}</span>
<span>return</span> sum <span>/</span> samples<span>;</span></code></pre><p>The outline width is controlled by the _KernelSize parameter of the blur shader.</p><h3 id="3.-outline-pass" tabindex="-1"><a href="#3.-outline-pass" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>3. Outline Pass</h3><p>After the blur pass, the blurred silhouette gets combined with the original scene to form the outline.</p><p><picture><source type="image/webp" srcset="blurred-buffer/outline-only.png-400w.webp 400w, blurred-buffer/outline-only.png-800w.webp 800w, blurred-buffer/outline-only.png-1200w.webp 1200w, blurred-buffer/outline-only.png-1920w.webp 1920w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-400w.jpeg" width="1920" height="1080" srcset="blurred-buffer/outline-only.png-400w.jpeg 400w, blurred-buffer/outline-only.png-800w.jpeg 800w, blurred-buffer/outline-only.png-1200w.jpeg 1200w, blurred-buffer/outline-only.png-1920w.jpeg 1920w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><p>Using a blurred buffer is great for having soft or glowing outlines, but the buffer can also be stepped to render a hard outline.</p><p><picture><source type="image/webp" srcset="blurred-buffer/outline-result.png-400w.webp 400w, blurred-buffer/outline-result.png-800w.webp 800w, blurred-buffer/outline-result.png-1200w.webp 1200w, blurred-buffer/outline-result.png-1904w.webp 1904w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-400w.jpeg" width="1904" height="547" srcset="blurred-buffer/outline-result.png-400w.jpeg 400w, blurred-buffer/outline-result.png-800w.jpeg 800w, blurred-buffer/outline-result.png-1200w.jpeg 1200w, blurred-buffer/outline-result.png-1904w.jpeg 1904w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="masking-1" tabindex="-1"><a href="#masking-1" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Masking</h3><p>Just like for the vertex extrusion method, a stencil mask can be used to make sure the outline only gets rendered behind the geometry.</p><blockquote><p><strong>üí¨ Blurred buffer</strong> outlines are great for soft and glowy outlines but can have a bigger impact on performance compared to other methods.</p></blockquote><h2 id="jump-flood-algorithm" tabindex="-1"><a href="#jump-flood-algorithm" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Jump Flood Algorithm</h2><p>The fourth method is to use the <mark>Jump Flood algorithm</mark> to render outlines. The main advantage of this technique is that it can render really wide outlines, at a very reasonable performance cost. I won&#39;t go into details at this time since the technique has a good explanation in this <a href="https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9" target="_blank" rel="noopener noreferrer">article from Ben Golus</a>.</p><video width="50%" title="Two-pass box blur effect." loop="" autoplay="" playsinline="" muted="true"><source src="jump-flood/jump-flood.mp4" type="video/mp4"/></video><blockquote><p><strong>üí¨ Jump flood</strong> outlines are a great option when you need performant, wide outlines.</p></blockquote><h2 id="edge-detection" tabindex="-1"><a href="#edge-detection" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Edge Detection</h2><p><picture><source type="image/webp" srcset="edge-detection/final.png-400w.webp 400w, edge-detection/final.png-800w.webp 800w, edge-detection/final.png-1200w.webp 1200w, edge-detection/final.png-1903w.webp 1903w" sizes="(min-width: 30em) 50vw, 100vw"/><img alt="Edge detection outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-400w.jpeg" width="1903" height="562" srcset="edge-detection/final.png-400w.jpeg 400w, edge-detection/final.png-800w.jpeg 800w, edge-detection/final.png-1200w.jpeg 1200w, edge-detection/final.png-1903w.jpeg 1903w" sizes="(min-width: 30em) 50vw, 100vw"/></picture></p><h3 id="technique-3" tabindex="-1"><a href="#technique-3" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Technique</h3><p>A fifth method is to use an edge-detection pass for rendering outlines. This full-screen pass draws lines by <mark>detecting discontinuities</mark> in the scene and rendering an outline between areas that have a large enough discontinuity between them. Discontinuities can be detected between the depth buffer value, the normal vector, the albedo color or any other data that is made available.</p><h3 id="detection-of-discontinuity" tabindex="-1"><a href="#detection-of-discontinuity" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Detection of discontinuity</h3><h4>Roberts cross</h4><p>Detecting discontinuities can be done by using an edge detection operator such as the <a href="https://en.wikipedia.org/wiki/Roberts_cross" target="_blank" rel="noopener noreferrer">Roberts cross operator</a>. This operator works as a differential operator by calculating the sum of the squares of the differences between diagonal pixels resulting in a cross-like pattern. In practice, edge detection operators can be applied by convolving the original image with kernels. There are 2 kernels, one for the x direction and one for the y direction. For Roberts cross, the diagonal pixels get sampled and convolved with these kernels. The kernels have a size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>x</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">2x2</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>2</span><span>x</span><span>2</span></span></span></span>.</p><pre><code><span>static</span> <span>const</span> <span>int</span> RobertsCrossX<span>[</span><span>4</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span>
    <span>0</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span>

<span>static</span> <span>const</span> <span>int</span> RobertsCrossY<span>[</span><span>4</span><span>]</span> <span>=</span> <span>{</span>
    <span>0</span><span>,</span> <span>1</span><span>,</span>
    <span>-</span><span>1</span><span>,</span> <span>0</span>
<span>}</span><span>;</span></code></pre><p>These kernels can then be used as follows.</p><pre><code>horizontal <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> RobertsCrossX<span>[</span><span>0</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>3</span><span>]</span> <span>*</span> RobertsCrossX<span>[</span><span>3</span><span>]</span><span>;</span> 

vertical <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> RobertsCrossY<span>[</span><span>2</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>1</span><span>]</span> <span>*</span> RobertsCrossY<span>[</span><span>1</span><span>]</span><span>;</span> 

edge <span>=</span>  <span>sqrt</span><span>(</span><span>dot</span><span>(</span>horizontal<span>,</span> horizontal<span>)</span> <span>+</span> <span>dot</span><span>(</span>vertical<span>,</span> vertical<span>)</span><span>)</span><span>;</span></code></pre><p>Roberts cross is a very simple operator but can already give nice results. The operator only needs 4 samples around a given pixel.</p><h4>Sobel operator</h4><p>Another method is to use a <a href="https://en.wikipedia.org/wiki/Sobel_operator" target="_blank" rel="noopener noreferrer">Sobel operator</a>. Again, 2 kernels are used but this time the kernels have a size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>x</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">3x3</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>3</span><span>x</span><span>3</span></span></span></span>.</p><pre><code><span>static</span> <span>const</span> <span>int</span> SobelX<span>[</span><span>9</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span>
    <span>2</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>2</span><span>,</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span>

<span>static</span> <span>const</span> <span>int</span> SobelY<span>[</span><span>9</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>,</span>
    <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span>
    <span>-</span><span>1</span><span>,</span> <span>-</span><span>2</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span></code></pre><p>This time, 9 samples are used around a given pixel. The Sobel kernels can be used like this.</p><pre><code>horizontal <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> SobelX<span>[</span><span>0</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> SobelX<span>[</span><span>2</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>3</span><span>]</span> <span>*</span> SobelX<span>[</span><span>3</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>4</span><span>]</span> <span>*</span> SobelX<span>[</span><span>4</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>5</span><span>]</span> <span>*</span> SobelX<span>[</span><span>5</span><span>]</span><span>;</span> 
horizontal <span>+=</span> samples<span>[</span><span>7</span><span>]</span> <span>*</span> SobelX<span>[</span><span>7</span><span>]</span><span>;</span> 

vertical <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> SobelY<span>[</span><span>0</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>1</span><span>]</span> <span>*</span> SobelY<span>[</span><span>1</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> SobelY<span>[</span><span>2</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>5</span><span>]</span> <span>*</span> SobelY<span>[</span><span>5</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>6</span><span>]</span> <span>*</span> SobelY<span>[</span><span>6</span><span>]</span><span>;</span> 
vertical <span>+=</span> samples<span>[</span><span>7</span><span>]</span> <span>*</span> SobelY<span>[</span><span>7</span><span>]</span><span>;</span> 

edge <span>=</span> <span>sqrt</span><span>(</span><span>dot</span><span>(</span>horizontal<span>,</span> horizontal<span>)</span> <span>+</span> <span>dot</span><span>(</span>vertical<span>,</span> vertical<span>)</span><span>)</span><span>;</span></code></pre><p>You can read this <a href="https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters/" target="_blank" rel="noopener noreferrer">blog post on Sobel filters</a> if you want to learn more about how Sobel filters work.</p><h3 id="sources-of-discontinuity" tabindex="-1"><a href="#sources-of-discontinuity" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Sources of discontinuity</h3><p>A common approach is to look for discontinuities in the textures that the render pipeline generates for the scene such as the depth texture, normals texture and color texture.</p><p>During the edge-detection pass, these textures are sampled and discontinuities are detected using the edge detection operators mentioned earlier. The resulting edge that is drawn can be caused by any discontinuity that was found in one of the 3 buffers. With this technique, the outline gets applied to all the objects that write to these buffers and so you have less control over the outlines on a per-object basis. In the image below, edge contributions by <mark>depth/normals/color</mark> are represented by the color red/green/blue respectively.</p><p>Allowing discontinuities to be detected from different sources makes for a more robust outlining system. In the debug image above you can see that while some edges would be detected by all three discontinuity sources, a lot of them only get picked up from a contribution of a specific discontinuity source. Each discontinuity source can be given a different weight and different thresholds can be used for each of them, allowing you to control the visual of the outline.</p><h3 id="edge-detection-modulation" tabindex="-1"><a href="#edge-detection-modulation" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Edge detection modulation</h3><p>Usually, just using an edge detection operator on the discontinuity source buffers is not enough to get a result without artifacts. Some <mark>modulation</mark> has to be done to get rid of these artifacts. For example, since the depth buffer is <a href="https://developer.nvidia.com/content/depth-precision-visualized" target="_blank" rel="noopener noreferrer">implemented non-linearly</a> in a lot of render pipelines, two objects 1m apart located close to the camera will have a larger depth difference than two objects 1m apart located far away from the camera. To accommodate for this, the threshold used for detecting discontinuities in depth can be modulated by the depth buffer itself so that geometry located close to the camera will need to have a larger discontinuity in depth value before being detected as an edge.</p><pre><code>depthThreshold <span>*=</span> _DepthDistanceModulation <span>*</span> <span>SampleSceneDepth</span><span>(</span>uv<span>)</span><span>;</span></code></pre><p>A second common artifact is unwanted edges showing up on objects at small <a href="https://en.wikipedia.org/wiki/Angle_of_incidence_(optics)#Grazing_angle_or_glancing_angle" target="_blank" rel="noopener noreferrer">grazing angles</a>. To resolve this, you can modulate with a mask that is generated from the dot product between the normal vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span> and the view direction <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>V</span></span></span></span>. This is the same fresnel mask that was used in the initial outlining technique using a rim effect.</p><pre><code><span>float</span> fresnel <span>=</span> <span>pow</span><span>(</span><span>1.0</span> <span>-</span> <span>saturate</span><span>(</span><span>dot</span><span>(</span>normalWS<span>,</span> viewWS<span>)</span><span>)</span><span>,</span> _Power<span>)</span><span>;</span>
<span>float</span> grazingAngleMask <span>=</span> <span>saturate</span><span>(</span><span>(</span>fresnel <span>+</span> _GrazingAngleMaskPower <span>-</span> <span>1</span><span>)</span> <span>/</span> _GrazingAngleMaskPower<span>)</span><span>;</span>
depthThreshold <span>*=</span> <span>1</span> <span>+</span> <span>smoothstep</span><span>(</span><span>0</span><span>,</span> <span>1</span> <span>-</span> _GrazingAngleMaskHardness<span>,</span> grazingAngleMask<span>)</span><span>;</span></code></pre><p>Other modulation techniques can be used, depending on the visual fidelity you want to achieve but these depend on the specific effect that you&#39;re after.</p><h3 id="custom-discontinuity-source" tabindex="-1"><a href="#custom-discontinuity-source" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Custom discontinuity source</h3><p>It is also possible to provide the outline shader with a custom discontinuity source. This would be a render texture that you create yourself during the render process, containing custom data that you wish to use to generate outlines. The advantage is that since you control what writes to this custom buffer, you can control which objects receive an outline.</p><p>For example in the scene above, the discontinuity source is generated by rendering the vertex colors of a mesh to a texture. Other techniques that come to mind are coloring faces based on their world position or creating a custom buffer that combines both information from the depth buffer and the normals buffer.</p><blockquote><p>üí° Want more info? Check out <a href="https://linework.ameye.dev/section-map" target="_blank" rel="noopener noreferrer">https://linework.ameye.dev/section-map</a>.</p></blockquote><blockquote><p><strong>üí¨ Edge detection</strong> outlines are good when you need a full-screen outlining effect. Some finetuning is needed to prevent lines from showing up where you don&#39;t want them to.</p></blockquote><h2 id="conclusion" tabindex="-1"><a href="#conclusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Conclusion</h2><p>There you go, 5 ways to draw an outline. They all have their benefits, making trade-offs between performance, visual fidelity and manual setup that is required.</p><h2 id="credits" tabindex="-1"><a href="#credits" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Credits</h2><blockquote><p><strong>üí¨</strong> The Sailor Moon 3D models used in this post were made by <em>premudraya</em> over on Sketchfab.</p></blockquote><blockquote><p><strong>üí¨</strong> The Zelda 3D model used in this post was made by <em>theStoff</em> over on Sketchfab.</p></blockquote><h2 id="additional-resources" tabindex="-1"><a href="#additional-resources" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">#</span> </a>Additional Resources</h2><h3 id="vertex-extrusion" tabindex="-1"><a href="#vertex-extrusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Vertex Extrusion</h3><p><a href="https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity/#working-in-clip-space" target="_blank" rel="noopener noreferrer">https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity</a></p><h3 id="jump-flood-algorithm" tabindex="-1"><a href="#jump-flood-algorithm" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Jump Flood Algorithm</h3><p><a href="https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9" target="_blank" rel="noopener noreferrer">https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9</a></p><h3 id="edge-detection" tabindex="-1"><a href="#edge-detection" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span> <span aria-hidden="true">##</span> </a>Edge Detection</h3><p><a href="https://roystan.net/articles/outline-shader.html" target="_blank" rel="noopener noreferrer">https://roystan.net/articles/outline-shader.html</a></p><p><a href="https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters/" target="_blank" rel="noopener noreferrer">https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters</a></p><p>Published <time>August 2021</time></p></div></div></div>
  </body>
</html>
