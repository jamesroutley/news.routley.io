<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/">Original</a>
    <h1>Seven basic rules for causal inference</h1>
    
    <div id="readability-page-1" class="page"><div>


<main role="main">
  <section>
    <article>
      
      <section>
        


<div id="introduction">

<p>In this blog post I will describe seven basic rules that govern the relationship between causal mechanisms in the real world and associations/correlations we can observe in data. To make each rule as easy as possible to understand, I will describe each rule both in words and in causal graph and logic terms, and I will offer some very simple simulation R code for each rule to demonstrate how it works in practice.</p>
<p>These seven rules represent basic building blocks of causal inference. Most causal analysis procedures involve one or more of these rules to some extent. If you are completely new to formal causal inference, learning these rules can serve as a springboard to learn more complicated things. If you apply causal inference regularly in your own research then you might find this post useful as a cheat sheet. For a much more detailed introduction to causal inference, see <span>Hernán and Robins (<a href="#ref-Hernan2020">2020</a>)</span>, and the <a href="https://www.edx.org/learn/data-analysis/harvard-university-causal-diagrams-draw-your-assumptions-before-your-conclusions?index=product&amp;queryID=a52aac6e59e1576c59cb528002b59be0&amp;position=1&amp;linked_from=autocomplete&amp;c=autocomplete">Causal Diagrams course</a> from HarvardX.</p>
</div>
<div id="four-fundamental-causal-structures">

<p>A causal graph is a depiction of a causal mechanism between variables. In the graph, variables (nodes) are drawn as circles ⚪ (or sometimes as squares), and the causal relationships (paths) between these variables are drawn as arrows → that point from the thing causing (causal ancestor) to the thing being caused (causal descendant).</p>
<p>Any causal graph, no matter how complicated, can be broken down into four elemental building blocks. The blocks are defined by the type of path that can be traced between the variables. All the rules that I will describe below deal with one or more of these building blocks, so it is useful to start by stating and describing them. By recognizing which blocks we are working with in any given instance we will know which causal inference rules are relevant.</p>
<div id="complete-independence.">
<h2>1. Complete independence.</h2>
<p>No path can be traced between A and B.</p>
<p><img src="https://push.cx/causal_independence.svg"/></p>
</div>
<div id="chain">
<h2>2. Chain</h2>
<p>In causal chains, a directed path can be traced from A to B, such that all arrows point from A to B. Chain paths are sometimes called an “open path”, which means that this type of graph transmits correlation between A and B (see rule 2). When a chain involves three or more variables, the variables M linking A and B are often called mediators.</p>
<p><img src="https://push.cx/a_causes_b.svg"/></p>
<p><img src="https://push.cx/mediated_cause.svg"/></p>
</div>
<div id="fork">
<h2>3. Fork</h2>
<p>In a causal fork, an undirected path (not all arrows run in the same direction) can be traced from A to B through a common causal ancestor C. C is often called a confounder variable. Fork paths are “open” and transmit correlation between A and B (see rule 3).</p>
<p><img src="https://push.cx/confounder.svg"/></p>
</div>
<div id="collider">
<h2>4. Collider</h2>
<p>In a causal collider, an undirected path (not all arrows run in the same direction) can be traced from A to B through a causal descendant D. D is often called a collider variable. Collider paths are “closed” and do not transmit correlation between A and B (see rule 1).</p>
<p><img src="https://push.cx/collider.svg"/></p>
</div>
</div>
<div id="seven-basic-rules-for-causal-inference">


<div id="rule-2-causal-influence-creates-correlation">
<h2>Rule 2: Causal influence creates correlation</h2>
<p>If A is a cause of B, or if B is a cause of A, then A and B will be correlated in data.</p>
<p><em>If <img src="https://push.cx/a_causes_b.svg"/> or <img src="https://push.cx/b_causes_a.svg"/> then A ~ B.</em></p>
<pre><code># Rule 2
n=10000  # Number of data points
a &lt;- rnorm(n, 0, 1)  # A is a random variable
b &lt;- a + rnorm(n, 0, 1)  # B is a function of A
plot(a, b)  </code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-2-1.png" width="480"/></p>
<pre><code>cor(a, b)  # Correlation between A and B</code></pre>
<pre><code>## [1] 0.71</code></pre>
<p>This also applies if A causes M, and M in turn causes B (mediation).</p>
<p><em>If <img src="https://push.cx/mediated_cause.svg"/> then A ~ B.</em></p>
<pre><code># Rule 2 (mediation)
n=10000  # Number of data points
a &lt;- rnorm(n, 0, 1)  # A is a random variable
m &lt;- a + rnorm(n, 0, 1)  # M is a function of A
b &lt;- m + rnorm(n, 0, 1)  # B is a function of M
plot(a, b)  </code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-3-1.png" width="480"/></p>
<pre><code>cor(a, b)  # Correlation between A and B</code></pre>
<pre><code>## [1] 0.58</code></pre>
</div>
<div id="rule-3-confounding-creates-correlation">
<h2>Rule 3: Confounding creates correlation</h2>
<p>If A and B share a common ancestor C (causal fork), A and B will be correlated in data. This phenomenon is often called confounding, or the “third variable problem”.</p>
<p><em>If <img src="https://push.cx/confounder.svg"/> then A ~ B.</em></p>
<pre><code># Rule 3
n=10000  # Number of data points
c &lt;- rnorm(n, 0, 1)  # C is a random variable
a &lt;- c + rnorm(n, 0, 1)  # A is a function of C
b &lt;- c + rnorm(n, 0, 1)  # B is a function of C
plot(a, b)  </code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-4-1.png" width="480"/></p>
<pre><code>cor(a, b)  # Correlation between A and B</code></pre>
<pre><code>## [1] 0.49</code></pre>
<p>The rule also applies if the effects of C on A and/or B are mediated through other variables.</p>
<p><img src="https://push.cx/mediated_confounder.svg"/></p>
</div>
<div id="rule-4-random-manipulation-protects-a-variable-from-causal-influence">
<h2>Rule 4: Random manipulation protects a variable from causal influence</h2>
<p>When we are able to randomly allocate the values of A - such as in a randomized controlled experiment where A is the manipulation variable - no other variable can influence A.</p>
<p><img src="https://push.cx/random_manipulation.svg"/></p>
<p>The notation <em>do(A)</em> refers to randomizing the values of A. Put differently, with complete experimental control and randomization we make sure that no variable is allowed to influence the values of A.</p>
</div>
</div>
<div id="adjustment-rules">

<p>To <em>adjust for</em> a variable X means to look at relationships in data that contain only a subset or single value of X. It can also mean to look at relationships for all the values of X separately. Adjustment goes by a number of different names in the sciences, including “control for”, “condition on”, “hold constant”, “stratify”, “select”, etc.</p>
<p>In the figures below, a square box around a variable node indicates that this variable is being controlled/adjusted for.</p>
<div id="rule-5-controlling-for-a-confounder-blocks-correlation-arising-from-that-confounder">
<h2>Rule 5: Controlling for a confounder blocks correlation arising from that confounder</h2>
<p>If A and B share a common ancestor C (causal fork), the confounding correlation between A and B that is created by C (rule 3) is removed if C is controlled for.</p>
<p><em>If <img src="https://push.cx/confounder_controlled_for.svg"/> then A ⫫ B.</em></p>
<pre><code># Rule 5
n=10000  # Number of data points
c &lt;- rnorm(n, 0, 1)  # C is a random variable
a &lt;- c + rnorm(n, 0, 1)  # A is a function of C
b &lt;- c + rnorm(n, 0, 1)  # B is a function of C
x &lt;- lm(b~c)
y &lt;- lm(a~c)
plot(x$residuals, y$residuals) </code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-5-1.png" width="480"/></p>
<pre><code>cor(x$residuals, y$residuals)  # Correlation between A and B, controlling for C</code></pre>
<pre><code>## [1] 0.015</code></pre>
</div>

<div id="rule-7-controlling-for-a-collider-leads-to-correlation">
<h2>Rule 7: Controlling for a collider leads to correlation</h2>
<p>If A and B share a causal descendant (collider) D, and D is controlled for, A and B will become correlated in the data. This is often referred to as “conditioning on a collider”, or collider bias.</p>
<p><em>If <img src="https://push.cx/collider_controlled_for.svg"/> then A ~ B.</em></p>
<pre><code># Rule 7
n=10000  # Number of data points
a &lt;- rnorm(n, 0, 1)  # A is a random variable
b &lt;- rnorm(n, 0, 1)  # B is a random variable
d &lt;- a + b + rnorm(n, 0, 1)  # D is a function of A and B
x &lt;- lm(a~d)
y &lt;- lm(b~d)
plot(x$residuals, y$residuals) </code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-7-1.png" width="480"/></p>
<pre><code>cor(x$residuals, y$residuals)  # Correlation between A and B, controlling for D</code></pre>
<pre><code>## [1] -0.5</code></pre>
</div>
<div id="rule-8-controlling-for-a-causal-descendant-partially-controls-for-the-ancestor">
<h2>Rule 8: Controlling for a causal descendant (partially) controls for the ancestor</h2>
<p>If B is a descendant of A and B is controlled for, A is also (partially) controlled for.</p>
<p><img src="https://push.cx/control_for_descendant.svg"/></p>
<p>The degree to which A is controlled when B is controlled for generally depends on the how reliably A causes B.</p>
<p>In the example below, C is a confounder of A and B, but the confounding influence can partially be blocked by controlling for CM.</p>
<p><img src="https://push.cx/rule_8_example.svg"/></p>
<p>If CM is a semi-reliable measure of C, some correlation between A and B is removed by controlling for CM, but not as much as when controlling for C:</p>
<pre><code># Rule 5
n=10000  # Number of data points
# 2*c used in equations to make change in relationship more visible.
c &lt;- rnorm(n, 0, 1)  # C is a random variable
a &lt;- 2*c + rnorm(n, 0, 1)  # A is a function of C
b &lt;- 2*c + rnorm(n, 0, 1)  # B is a function of C
cm &lt;- 2*c + rnorm(n, 0, 1) # CM is a function of C
# Control for C
ac &lt;- lm(b~c)
bc &lt;- lm(a~c)
# Control for CM
acm &lt;- lm(a~cm)
bcm &lt;- lm(b~cm)
# Plot relationship between a and b while...
par(mfrow=c(1,3)) 
plot(a,b, main = &#34;no control&#34;)  # controlling for nothing
plot(acm$residuals, bcm$residuals, main = &#34;controlling for CM&#34;)  # controlling for CM
plot(ac$residuals, bc$residuals, main = &#34;controlling for C&#34;)  # controlling for C</code></pre>
<p><img src="https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/index_files/figure-html/unnamed-chunk-8-1.png" width="960"/></p>
<pre><code># Correlation between a and b while...
cor(a,b) # controlling for nothing</code></pre>
<pre><code>## [1] 0.8</code></pre>
<pre><code>cor(acm$residuals, bcm$residuals)  # controlling for CM</code></pre>
<pre><code>## [1] 0.44</code></pre>
<pre><code>cor(ac$residuals, bc$residuals)  # controlling for C</code></pre>
<pre><code>## [1] 0.0021</code></pre>
</div>
</div>

<div id="important-assumptions">

<p>The above rules only hold if some important assumptions are met, which I will list below but not explain in detail. For details, see <span>Hernán and Robins (<a href="#ref-Hernan2020">2020</a>)</span>.</p>
<p><strong>No spurious correlation:</strong> Correlation is not caused by random accident. The law of large numbers dictate that the more data we have, the more credible this assumption is.</p>
<p><strong>Consistency:</strong> The values of A you see are the actual values of A, or “the values of treatment under comparison correspond to well-defined interventions that, in turn, correspond to the versions of treatment in the data” <span>Hernán and Robins (<a href="#ref-Hernan2020">2020</a>)</span>.</p>
<p><strong>Exchangeability:</strong> “the conditional probability of receiving every value of treatment, though not decided by the investigators, depends only on measured covariates” <span>Hernán and Robins (<a href="#ref-Hernan2020">2020</a>)</span>.</p>
<p><strong>Positivity:</strong> “the probability of receiving every value of treatment conditional on L is greater than zero, i.e., positive” <span>Hernán and Robins (<a href="#ref-Hernan2020">2020</a>)</span>.</p>
<p><strong>Faithfulness:</strong> The causal effect does not vary over groups in a way that makes it average to 0 in the data. A does not have a positive effect 50% of the time and an identically powerful negative effect 50% of the time, which would average out to an effect of 0 in the population.</p>
<p>If either of these assumptions are not met, it can potentially break the relationship between causal effect and observed data described by these rules.</p>
</div>
<div id="references">

<div id="refs">
<p>
Hernán, Miguel, and James Robins. 2020. <em>Causal <span>Inference</span>: <span>What If</span>.</em> Boca Raton: Chapman &amp; Hall/CRC.
</p>
</div>
</div>

        
        <details closed="">
  <dl>
    <dt>Posted on:</dt>
    <dd>August 13, 2024</dd>
  </dl>
  <dl>
    <dt>Length:</dt>
    <dd>10 minute read, 2034 words</dd>
  </dl>
  
  
  
  <dl>
    <dt>Tags:</dt>
    <dd> <a href="https://pedermisager.org/tags/causal-inference">causal inference</a>  <a href="https://pedermisager.org/tags/causal-graphs">causal graphs</a>  <a href="https://pedermisager.org/tags/correlation">correlation</a> </dd>
  </dl>
  
  <dl>
    <dt>See Also:</dt>
    
    <dd><a href="https://push.cx/blog/why_does_correlation_not_equal_causation/">Why does correlation not equal causation?</a></dd>
    
    <dd><a href="https://push.cx/blog/fifty-ways-to-leave-your-model/">Fifty ways to leave your model</a></dd>
    
  </dl>
</details>

      </section>
      
    </article>
    
      


    
  </section>
</main>


      </div></div>
  </body>
</html>
