<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://openai.com/blog/dall-e-now-available-in-beta/">Original</a>
    <h1>DALL·E Now Available in Beta</h1>
    
    <div id="readability-page-1" class="page"><article id="post-dall-e-now-available-in-beta">

  

  <section>
  <div>
    <section>
      
      <!--kg-card-begin: markdown--><div>
<p>We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.</p>

</div>
<p><a href="https://openai.com/dall-e-2/">DALL·E</a>, the AI system that creates realistic images and art from a description in natural language, is now available in beta. Today we’re beginning the process of inviting 1 million people from our waitlist over the coming weeks.</p>
<p>Every DALL·E user will receive 50 free credits during their first month of use and 15 free credits every subsequent month. Each credit can be used for one original DALL·E prompt generation — returning four images — or an edit or variation prompt, which returns three images.</p>

<p>DALL·E allows users to create quickly and easily, and artists and creative professionals are using DALL·E to inspire and accelerate their creative processes. We’ve already seen <a href="https://openai.com/blog/dall-e-2-extending-creativity/">people use DALL·E</a> to make music videos for young cancer patients, create magazine covers, and bring novel concepts to life.</p>
<p>Other features include:</p>
<ul>
<li><strong>Edit</strong> allows users to make realistic and context-aware edits to images they generate with DALL·E or images they upload using a natural language description.</li>
<li><strong>Variations</strong> can take an image generated by DALL·E or an image uploaded by a user and create different variations of it inspired by the original.</li>
<li><strong>My Collection</strong> allows users to save generations right in the DALL·E platform.</li>
</ul>
<h2 id="pricing">Pricing</h2>
<p>In this first phase of the beta, users can buy additional DALL·E credits in 115-credit increments (460 images) for $15 on top of their free monthly credits. One credit is applied each time a prompt is entered and a user hits “generate” or “variations.”</p>
<p>As we learn more and gather user feedback, we plan to explore other options that will align with users’ creative processes.</p>
<h2 id="using-dall%C2%B7e-for-commercial-projects">Using DALL·E for commercial projects</h2>
<p>Starting today, users get full usage rights to commercialize the images they create with DALL·E, including the right to reprint, sell, and merchandise. This includes images they generated during the research preview.</p>
<p>Users have told us that they are planning to use DALL·E images for commercial projects, like illustrations for children’s books, art for newsletters, concept art and characters for games, moodboards for design consulting, and storyboards for movies.</p>
<h2 id="safety">Safety</h2>
<p>Prior to making DALL·E available in beta, we’ve worked with researchers, artists, developers, and other users to learn about risks and have taken steps to improve our safety systems based on learnings from the research preview, including:</p>
<ul>
<li><strong>Curbing misuse</strong>: To minimize the risk of DALL·E being misused to create deceptive content, we reject image uploads containing realistic faces and attempts to create the likeness of public figures, including celebrities and prominent political figures. We also used advanced techniques to prevent photorealistic generations of real individuals’ faces.</li>
<li><strong>Preventing harmful images</strong>: We’ve made our content filters more accurate so that they are more effective at blocking images that violate our <a href="https://labs.openai.com/policies/content-policy">content policy</a> — which does not allow users to generate violent, adult, or political content, among other categories — while still allowing creative expression. We also limited DALL·E’s exposure to these concepts by removing the most explicit content from its training data.</li>
<li><strong>Reducing bias</strong>: We implemented <a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/">a new technique</a> so that DALL·E generates images of people that more accurately reflect the diversity of the world’s population. This technique is applied at the system level when DALL·E is given a prompt about an individual that does not specify race or gender, like “CEO.”</li>
<li><strong>Monitoring</strong>: We will continue to have automated and human monitoring systems to help guard against misuse.</li>
</ul>
<h2 id="subsidized-access-for-qualifying-artists">Subsidized access for qualifying artists</h2>
<p>We hope to make DALL·E as accessible as possible. Artists who are in need of financial assistance will be able to apply for subsidized access. Please fill out <a href="https://docs.google.com/forms/d/e/1FAIpQLSfJzXwRXbyk3vwUtkoIVe17d4YiZ8gstikDUPCaERPqMZ8GFQ/viewform">this interest form</a> if you’d like to be notified once more details are available.</p>
<p>We are excited to see what people create with DALL·E and look forward to users’ feedback during this beta period.</p>
</section>
  </div>
</section>
  






</article></div>
  </body>
</html>
