<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gist.github.com/arch1t3cht/b5b9552633567fa7658deee5aec60453/">Original</a>
    <h1>What you need to know before touching a video file</h1>
    
    <div id="readability-page-1" class="page"><div>
  <div id="file-video_noob_guide-md">
      
      <div id="file-video_noob_guide-md-readme" tabindex="0" role="region" aria-label="video_noob_guide.md content, created by arch1t3cht on 08:23PM on May 22, 2025.">
    <article itemprop="text">
<p dir="auto">Hanging out in subtitling and video re-editing communities,
I see my fair share of novice video editors and video encoders,
and see plenty of them make the classic beginner mistakes when it comes to working with videos.
A man can only read &#34;Use Handbrake to convert your mkv to an mp4 :)&#34; so many times before losing it,
so I am writing this article to channel the resulting psychic damage into something productive.</p>
<p dir="auto">If you are new to working with videos (or, let&#39;s face it, even if you aren&#39;t),
please read through this guide to avoid making mistakes that can cost you lots of computing power, storage space, or video quality.</p>
<p dir="auto">This guide is quite long.
This is hard to avoid since videos are <em>really, really complicated</em>,
and there are lots of misconceptions to clear up.
I have tried to keep the different sections as independent as possible so you do not have to read the whole thing at once.</p>
<div dir="auto"><h2 dir="auto">The Anatomy of a Video File and Remuxing vs. Reencoding</h2><a id="user-content-the-anatomy-of-a-video-file-and-remuxing-vs-reencoding" aria-label="Permalink: The Anatomy of a Video File and Remuxing vs. Reencoding" href="#the-anatomy-of-a-video-file-and-remuxing-vs-reencoding"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Let&#39;s start out with the most important thing:
The mistake I see the most and that causes experienced users the most pain to see.</p>
<p dir="auto">To efficiently work with video files, you need to know the (extreme) basics of how video files are stored:
When you download video files or copy them somewhere, you may come across various types of videos.
You&#39;ll probably see file extensions like <code>.mp4</code> or <code>.mkv</code> (or many others like <code>.webm</code>, <code>.mov</code>, <code>.avi</code>, <code>.m2ts</code>, and so on).
As a newcomer to video you might be tempted to think that this file extension is what determines the video format.
You might have found an <code>mkv</code> file somewhere and noticed that Vegas or Premiere cannot open it,
so you searched for ways to convert your <code>mkv</code> file to an <code>mp4</code> file.</p>
<p dir="auto">While this is technically not wrong, it&#39;s far from the full story and can cause lots of misconceptions.
In reality, all these formats are so-called <em>container formats</em>.
The job of an <code>mkv</code> or <code>mp4</code> file is not to compress and encode the video,
but to take an already compressed video stream and package it in a way that makes it easier for video players to play them.
Container formats are responsible for tasks like storing multiple audio or subtitle tracks (or even video tracks!) in the same file,
storing metadata like chapters or which tracks have which languages,
and various other technical things.
However, while they <em>store</em> the video (and audio), they&#39;re not the formats that actually <em>encode</em> it.</p>
<p dir="auto"><em>Actual</em> video coding formats are formats like H.264 (also known as AVC) or H.265 (also known as HEVC).
Sometimes they&#39;re also called <em>codecs</em>, short for &#34;encode, decode&#34;.<sup><a href="#user-content-fn-codec-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-codec-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>
H.264 and H.265 are the most common coding formats, but you may also run into some others like VP9 and AV1 (e.g. in YouTube rips) or Apple ProRes.
These are the formats that handle the actual encoding of the video,
which is the much, much, <em>much</em> harder part.
A raw video file is <em>massive</em>, so these formats use lots of very clever and complicated tricks
to store the video as efficiently as possible while losing as little quality as possible.
In particular, this means that these formats are usually <em>lossy</em>,
i.e. that video encoding programs will cause slight changes in the video in order to be able to compress it more efficiently.
However, figuring out how to make a video as small as possible while sacrificing as little quality as possible
is <em>very hard</em>, which is why encoding a video takes a lot of time and computing power.
This is why rendering a video takes as long as it does.</p>
<p dir="auto">Note that <em>H.264</em>  is different from <em>x264</em>, which you may also have heard of. <em>H.264</em> is the coding format itself,
while <em>x264</em> is a specific program that can encode to H.264.
The same is true for H.265 and x265.
You will see later on in this article why this distinction matters a lot.</p>
<p dir="auto">So, to summarize:
A video file is actually comprised of a <em>container format</em> (like <code>mkv</code> or <code>mp4</code>), which itself contains an actual video stream.
Changing the container format is simple: You just rip out the video stream and stick it into another container.
(Well, it&#39;s a little more complicated than that. But the point is: The container format is not the one that encodes the actual video, so you can switch container formats without encoding the video from scratch.)
Changing the underlying coding format, however, or recompressing the video to change the file size,
is harder and will a) take time and computing power, and b) lose video quality.</p>
<p dir="auto">The process of decoding a video stream and encoding it again using the same or a different coding format is called <em>reencoding</em>.
Changing the surrounding container format, on the other hand, is called <em>remuxing</em> (Deriving from &#34;multiplexing&#34;, which refers to sticking multiple audio or video streams into the same file).</p>
<p dir="auto">This is <em>extremely important</em> to know when working with videos!
If you try to convert your <code>mkv</code> file to an <code>mp4</code> to open it in Premiere by sticking it into a converter like Handbrake (or, worse, some online conversion tool) without knowing what you&#39;re doing,
you may end up reencoding your video instead, which will not only take much, much longer,
but also greatly hurt your video&#39;s quality.</p>
<p dir="auto">Instead, chances are that you can just remux your video to an <code>mp4</code> instead, leaving the underlying encoded video stream untouched.
Now, granted, there are some subtleties here, in particular to do with frame rates (more on this later),
but the point is: lots of simple-looking &#34;conversion&#34; methods (like Handbrake, random converter websites, etc.) will actually reencode the video,
which you want to avoid as much as possible.
Knowing how a video file is structured, and what tools you can use to work with them (again, more on this later)
will help you avoid many of these mistakes.</p>

<p dir="auto">Next, let&#39;s talk about the concept of &#34;video quality&#34;, which I myself already invoked above.
I don&#39;t think there is any other concept in video with as many misconceptions about it as video quality,
and once again misunderstanding it can cause you to make many avoidable mistakes.
This is important for both encoding your own videos <em>and</em> for <em>selecting</em> which source footage you want to work with.</p>
<p dir="auto">Here is a list of things that people commonly associate with a video&#39;s quality:</p>
<ul dir="auto">
<li>Its resolution (1080p/720p/4k/etc.)</li>
<li>Its frame rate (24fps / 60fps / 144fps / etc.)</li>
<li>Its bit depth (8bit / 10bit / etc.)</li>
<li>Its file size or its bitrate (i.e. file size divided by duration)</li>
<li>Its file format (<code>.mkv</code> / <code>.mp4</code> / etc.)</li>
<li>Its video coding format (H.264 / H.265 / etc.)</li>
<li>The program used to encode the video (x264 / x265 / NVENC / etc.)</li>
<li>The settings used to encode the video</li>
<li>The video&#39;s source (Blu-ray / Web Stream / etc.)</li>
<li>The video&#39;s colors (brightness / contrast / saturation / etc.)</li>
<li>The video&#39;s color space and range (i.e. whether it&#39;s in HDR)</li>
<li>How sharp or blurry the video is</li>
</ul>
<p dir="auto">If you&#39;ve paid attention in the previous section, you should know that at least some of these points, like the file format one, cannot be true (but it&#39;s still a misconception I sometimes see!).
But, in fact, the truth is that none of these things are necessarily related to a video&#39;s quality!
The program used to encode the video combined with the settings used in them gets the closest, but only in specific scenarios.</p>
<p dir="auto">Why is this? Well, let&#39;s go through them one by one (but in a slightly different order to make things easier to present).</p>
<div dir="auto"><h4 dir="auto">The Encoding Program and its Settings</h4><a id="user-content-the-encoding-program-and-its-settings" aria-label="Permalink: The Encoding Program and its Settings" href="#the-encoding-program-and-its-settings"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Like I said, these two combined are what gets closest to being directly related to the video&#39;s &#34;quality&#34;.
Why they matter is probably obvious once one mentions them as a variable:
Of course different encoding programs can encode a video in different ways, and different settings will make them do it differently.
But the real lesson to learn here is that these are even parameters in the first place!
This is something that even semi-experienced users sometimes miss (for example, I did so when I was starting out!):
It&#39;s easy to think that <code>ffmpeg -i myvideo.mp4 myencodedvideo.mp4</code> is the only way to reencode a video (maybe sprinkle in <code>-preset slow</code> if you&#39;re feeling like an expert), without realizing that this will use a fixed (low) quality setting that could be adjusted with further settings.</p>
<p dir="auto">So, I really cannot stress enough that the encoding <em>settings</em> (including the tool used) matter the most when it comes to a video&#39;s quality.
This mainly manifests itself in two ways:</p>
<ol dir="auto">
<li>
<p dir="auto">The tool used.
When it comes to encoding H.264 or H.265, the best encoders without any competition<sup><a href="#user-content-fn-x264best-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-x264best-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> are x264 and x265.
When you are in any situation where you can afford it, you should be using one of these encoders.
Most video editing programs allow you to select them (and programs like ffmpeg or Handbrake (though ideally you shouldn&#39;t use the latter) use them internally).</p>
<p dir="auto">Most importantly, hardware encoders like NVENC aren&#39;t useful when targeting quality and efficiency.
They aren&#39;t as sophisticated as x264/5 and are geared more towards low latency and high throughput.
Again, this is very important to realize, and it&#39;s the main reason why I am stressing this so much.
Hardware encoding certainly has its place in scenarios like streaming
where latency matters much more than efficiency or quality,
but when your goal is to output a high-quality encode, you shouldn&#39;t ever use it.</p>
</li>
<li>
<p dir="auto">The quality setting.
In x264/x265, the main knob to fiddle with to control quality is the setting called CRF (short for Constant Rate Factor).
Lower CRF means higher quality (i.e. less quality loss when encoding) at the cost of higher file size.</p>
</li>
</ol>
<p dir="auto">My main point here is not really how to use the CRF setting, but mainly that it exists in the first place,
and that it above everything else controls the output quality of your video.<sup><a href="#user-content-fn-crfbitrate-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-crfbitrate-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
<p dir="auto">There are lots of other settings in x264/x265 that experts can use to precisely tweak their encodes,
but if you don&#39;t know what you&#39;re doing I&#39;d recommend not touching them at all.
Once again, my main point here is really just that <strong>encoding settings affect output quality</strong>.</p>
<p dir="auto">Now, I said above that these parameters are what gets closest to the video quality, but only in specific scenarios.
Why is this?
Well, what I mean by this is all that the encoding settings can affect is how closely the encoded video resembles the input video,
i.e. how much quality is lost at the encoding step.
If your input video is already bad, then reencoding it with perfect settings will not fix it.
This may seem obvious, but it highlights how video quality has multiple different facets.
Say you are choosing what footage to use as a base for your encode or edit,
and have the choice between two sources,
where one has a much higher bitrate than the other.
Usually, you would choose the source with the higher bitrate,
but this only makes sense if the two sources were encoded from the same underlying source (or at least similar ones)!
It&#39;s very possible that the higher-bitrate source had some other destructive processing applied to it (say, sharpening, a bad upscale, lowpassing, etc. - more on these later).
In cases like these, you may want to choose the lower-bitrate source instead, if it&#39;s at least encoded from a clean base.</p>
<p dir="auto">So, as a summary, the <em>quality loss</em> of an encode is controlled by the encoding tool and settings,
but the quality of an <em>existing video</em> is affected by every single step
that happened between it being first recorded or rendered and it arriving on your hard drive.</p>
<div dir="auto"><h3 dir="auto">Interlude: So Then, What is Quality Actually?</h3><a id="user-content-interlude-so-then-what-is-quality-actually" aria-label="Permalink: Interlude: So Then, What is Quality Actually?" href="#interlude-so-then-what-is-quality-actually"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">I&#39;ve now spent a long time talking about what quality <em>isn&#39;t</em>,
as well as what quality is <em>affected</em> by, so it might be time to try to formulate an actual definition of quality.</p>
<p dir="auto">We already got pretty close with our discussion of encoding some video from a given source,
with the goal of getting an output that differs from the input as little as possible.
<em>That</em> is what quality is:
The quality of an encoded and processed video is a measure of how closely it resembles the source it was created from.</p>
<p dir="auto">Again, this sounds extremely obvious once you spell it out, but it has huge consequences that may not be clear to everyone!
Most importantly, quality can only ever be measured relative to some <em>reference</em>,
some kind of ground truth.
Without a ground truth, everything becomes subjective.</p>
<p dir="auto">Secondly, this now says something about the &#34;quality&#34; of videos you may come across in the wild (i.e. ones that weren&#39;t encoded by you):
When you have two or more possible sources for the same footage (say, a movie or a show) available,
and want to evaluate their quality,
what matters is which of them is closer to the original footage they were both created from.
In the case of a movie, this would be the original master.
Once again, this may sound obvious, but we will see soon how many misconceptions are formed from not understanding this principle.</p>
<p dir="auto">Finally, I need to talk about the word &#34;closer&#34; in this new definition, which is actually doing a <em>lot</em> of heavy lifting.
What &#34;closer&#34; really means here is very complicated, which is why I left it somewhat vague on purpose.
There are lots of ways to compare how close two videos are
(and that&#39;s assuming that they have the same resolution, frame rate, colors, etc),
but none of them are perfect.
In particular, there are many automated &#34;objective&#34; metrics (you may have heard of PSNR, SSIM, VMAF, etc.).
These are very important for encoding programs to function at all,
but it&#39;s important to realize that <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" rel="nofollow">no automated metric is perfect</a>,
and they all have their own strengths and weaknesses.</p>
<p dir="auto">Because of this, video &#34;quality&#34; will always entail some degree of subjectivity.
Still, there are some thing that are almost certainly wrong, and you&#39;ll see some of them in the following sections.</p>

<p dir="auto">You should now have a decent idea of what quality actually means, and what it&#39;s determined by.
Still, I want to spell out explicitly why various other parameters do not directly correlate to quality,
and clear up associated misconceptions.
So, let&#39;s go through them one by one.</p>

<p dir="auto">This should hopefully be clear from the section on encoding settings.
Yes, more bits usually means better encode quality <em>if</em> everything else stays the same,
but ultimately the full package of encoding settings (which bitrate can be <em>one</em> of) is what matters.
Different encoders or settings will result in different efficiency levels,
so you can have two encodes of the same quality and different file sizes or vice-versa.
For example, NVENC allows very fast encoding at the expense of larger file sizes,
so an x264 encode (with decent settings) will get you much smaller files of the same quality
(but will of course take much longer).</p>
<div dir="auto"><h4 dir="auto">Video Coding Format (H.264 / H.265 / AV1 / etc.)</h4><a id="user-content-video-coding-format-h264--h265--av1--etc" aria-label="Permalink: Video Coding Format (H.264 / H.265 / AV1 / etc.)" href="#video-coding-format-h264--h265--av1--etc"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Again, hopefully this should mostly be clear now:
What matters is the <em>tool</em> used to encode the video (and its settings), not the format it encodes to.
A more advanced format will allow for more techniques to efficiently encode a video,
but that only matters if the encoding program properly makes use of them.</p>
<p dir="auto">In particular, there is an often quoted factoid that &#34;HEVC is 50% more efficient than AVC&#34;,
which in reality is just plain wrong.
H.265 (that is, current standard H.265 encoders) does usually provide an efficiency gain over H.264 (that is, current standard H.264 encoders),
but if it does it&#39;s by far less than 50%.
And, as always, the format is just one facet of the full &#34;Encoder and settings used&#34; package.
On pirate sites I sometimes see comments like &#34;I want to download this, but it&#39;s AVC. Is there an HEVC version somewhere?&#34;,
and I hope that I don&#39;t have to explain anything further about why that makes no sense.</p>
<p dir="auto">Another important point is that the strengths and weaknesses of encoding tooling can greatly differ based on the level of quality you&#39;re targeting.
AV1 is the current new and fancy coding format,
and modern AV1 encoders (when used correctly) can yield incredible efficiency gains over x264/5 <em>on low-fidelity encodes</em>.
However, for high-quality encodes (i.e. targeting visual transparency),
x264 and x265 are still far ahead.
It&#39;s for reasons like these that it&#39;s very hard to make blanket statements on the efficiencies of different encoders.</p>
<p dir="auto">One final thing to mention here is that the coding format <em>will</em> affect how difficult it is to <em>decode</em> your video.
Older or smaller devices may struggle to decode more advanced formats like AV1 or even H.265 (or specific profiles of formats like 10bit H.264).
This doesn&#39;t directly affect quality, but it may be important to mention for people that plan on making their own encodes:
If you&#39;re targeting high player compatibility, you may need to keep this in mind and (for example) release an 8bit H.264 version alongside your main release.</p>
<div dir="auto"><h4 dir="auto">The File Format (.mkv / .mp4)</h4><a id="user-content-the-file-format-mkv--mp4" aria-label="Permalink: The File Format (.mkv / .mp4)" href="#the-file-format-mkv--mp4"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Hopefully I don&#39;t have to say anything more here.
Read the first section again if this is not yet clear to you.
But I <em>have</em> seen &#34;This is an mp4 file, can someone upload an mkv file instead?&#34; more than once,
which is why I need to spell this out here.
If this was you, look through the later sections to see how to fix these things for yourself.</p>

<p dir="auto">This may be the biggest misconception of them all:
Many people effectively think that resolution is the <em>only</em> thing that controls a video&#39;s quality.
Maybe it&#39;s because of how YouTube and many other streaming platforms expose resolution as the only setting to change &#34;quality&#34;.
Either way, this is not the case.
We&#39;ve already seen why this is true in general, but let&#39;s go over some specific cases:</p>
<ul dir="auto">
<li>
<p dir="auto">Often, people downscale videos to some lower resolution in order to save file size.
For example, if they have some 1080p video that, when run through their encoder,
results in a 1GB file while they&#39;d like their file to only be 500MB,
they&#39;d try to render it to a 720p video instead.</p>
<p dir="auto">But, as we&#39;ve seen by now, this is usually not the right way to go about it.
If your main goal is to bring down the file size,
this can be done much better by adjusting the encoding settings instead:</p>
<p dir="auto">Different parts and scenes of a video will be easier or harder to compress.
Scenes without a lot of motion or flat scenes without lots of details or grain will be easier to encode
than scenes with lots of moving elements.
Encoders know this and are able to intelligently allocate bits where they are most needed,
focusing on <em>visual</em> quality rather than a uniformly fixed level of precision.</p>
<p dir="auto">By leaving the quality reduction to the encoder instead of downscaling before encoding,
the encoder can decide where to save bits,
rather than being forced to lose detail <em>everywhere</em>.
This will often result in a much better-looking result at the same file size.</p>
<p dir="auto">Additionally, encoding downscaled video isn&#39;t actually as efficient as one might think,
at least not with modern encoding formats:
Since all the elements in the video get squished down, there&#39;ll be more small details in the same region of space,
which makes them harder to encode.</p>
<p dir="auto">Now, if you&#39;re targeting <em>extremely</em> small file sizes,
so that achieving these at (say) 1080p with very low bitrates is impossible without extremely visible artifacts,
then you could consider reducing the resolution to make the artifacts more uniform.
But resolution definitely shouldn&#39;t be the <em>first</em> knob you reach for to adjust file size:
That should be the CRF or bitrate.</p>
</li>
<li>
<p dir="auto">Sometimes, some geniuses decide to use that new and fancy AI upscaling software they saw marketed somewhere
to &#34;improve&#34; some video and upscale it to some higher resolution like 4k,
and probably add a bunch of sharpening and whatnot in the process.
I could write an entire article about AI upscaling alone
(in fact, <a href="https://gist.github.com/arch1t3cht/656c4ccec31af7a3f75555efe157d9e2">I have</a>),
but to keep things short:
We&#39;ve established that <em>quality</em> measures how close some video is to the source it originally came from.
Applying <em>any</em> kind of post-processing<sup><a href="#user-content-fn-postprocessing-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-postprocessing-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> to the video can only ever take it further away from the source,
not closer, and upscaling (AI or not) is no exception.
Any kind of &#34;detail&#34; you may see the upscale add can only be invented, not added:
The upscale fundamentally only has its input to work with, any extra data has to be pulled out of thin air.
And no, I don&#39;t want to hear that <em>your</em> AI upscaling model is actually really good and better than the other ones,
so it&#39;s actually okay to upscale with it.
This is not a question of how good the upscaling process is,
it&#39;s the process of upscaling itself that&#39;s already inherently lossy.</p>
<p dir="auto">There are some extra nuances here (read the linked post for some of them) and AI is not <em>inherently</em> bad,
but please just trust me as a more experienced person when I tell you that
<strong>you should not upscale videos just for the sake of upscaling them</strong>.</p>
</li>
</ul>
<ul dir="auto">
<li>
<p dir="auto">These lessons about resolution also matter when it comes to <em>choosing</em> sources.
Once again, <em>quality</em> refers to how close a video is to its original source,
and it&#39;s very much possible for that original source to itself have a low resolution.</p>
<p dir="auto">This is especially relevant for digital anime, which is often produced at some resolution below 1080p.
Even in 2025, production resolutions like 720p or 1500x844 are still very common,
with the 1080p release being upscaled (usually using conventional methods, not AI) from that.</p>
<p dir="auto">Usually this is not too important to the end user,
but it does mean that if you see a new fancy 4k release of some digitally animated show being advertised,
the chances are extremely high that this is not <em>truly</em> 4k,
and instead just upscaled from whatever 1080p master they had before.
Note, though, that anime movies or shows that were originally animated on film can be a different story,</p>
<p dir="auto">Similarly, this is very relevant for digitally animated shows that were originally released on DVD.
For a good portion of shows from that era, there exist 1080p Blu-Rays that are extremely badly upscaled,
so that the DVD will be a much better source.
(However, DVDs bring a <em>ton</em> of other complications with them,
so in the end you should pray that someone else has already done the work of making a proper encode for you.)
There are also plenty of shows where this isn&#39;t the case,
especially if the Blu-ray is a better rescan of a film or if the show has a LaserDisc release,
but the general takeaway is that &#34;higher resolution does not automatically mean better&#34; also extends to official releases.</p>
</li>
</ul>
<p dir="auto">So, as a summary, keep in mind that resolution is not the same as quality.
A higher resolution may not mean better quality, and lowering the resolution may not be the best way to save file size.</p>

<p dir="auto">This is fairly similar to the resolution story, so there&#39;s not much more to say here.
Just like AI upscaling just for the sake of upscaling, frame interpolation is bad.
There&#39;s not even any nuance here this time, just don&#39;t do it. (Do I need to spell out what &#34;quality&#34; means again?)
Movies and TV shows are usually 24fps (well, often they&#39;re actually 23.976fps<sup><a href="#user-content-fn-fracfps-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-fracfps-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>, but you get the idea),
so if you find a source somewhere that has some different frame rate, double-check if that is the correct one.</p>
<div dir="auto"><h4 dir="auto">Bit Depth (8bit / 10bit / etc.)</h4><a id="user-content-bit-depth-8bit--10bit--etc" aria-label="Permalink: Bit Depth (8bit / 10bit / etc.)" href="#bit-depth-8bit--10bit--etc"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This is a tricky one, and I am mainly mentioning it to talk about a very specific technique in encoding.</p>
<p dir="auto">Bit depth is a slightly more niche concept, so I&#39;ll explain it just in case:
Bit depth refers to how many color values are possible for each pixel.
Almost all images and videos you&#39;ll come across are 8bit.
For RGB colors, this would mean 256 red/green/blue color values per pixel,
which results in <code>256 * 256 * 256 = 16777216</code> total possible RGB color values.
In reality, video colors are not <em>actually</em> stored in RGB,
and usually do not exhaust their full available range of values,
but for getting a basic intuition this is not too important.</p>
<p dir="auto">However, it&#39;s also possible for videos to have a higher bit depth like 10bit or 12bit.
Apart from masters, this is common for HDR video.</p>
<p dir="auto">In principle, the same rules as for resolution and frame rate apply:
Don&#39;t change any aspects of your video without a good reason,
so don&#39;t change the bit depth either if you can avoid it.
That said, it <em>is</em> common in video encoding to actually encode footage at a bit depth higher than the source&#39;s.
This is due to intricacies of video encoding that are too complicated to explain here,
but the upshot is that encoding at a higher bit depth can actually result in an <em>increase</em> in efficiency.
This is why you may see 10bit encodes of 8bit footage:
These do not mean that there was a 10bit source somewhere,
they&#39;re just encoded in this way because it was more efficient.</p>
<p dir="auto">This doesn&#39;t contradict our philosophy of not changing anything without good reason,
it just means that there is a &#34;good reason&#34; in this case.
In particular, this is feasible here because, unlike with resolution or frame rate, increasing bit depth is not a destructive process (when done correctly)<sup><a href="#user-content-fn-scaledestructive-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-scaledestructive-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>.</p>
<p dir="auto">(If you&#39;re interested in <em>why</em> encoding at a higher bit depth is more efficient, here&#39;s an attempt at a basic explanation:
Intuitively, you might be confused about this, since adding more bits ought to correspond to more bits to store,
which results in more required file size.
But the important thing to realize is that the &#34;bit depth&#34; in modern video coding formats is not actually
what controls the level of precision with which pixel values (or, in reality, DCT coefficients) are stored.
That level of precision is controlled by the quantization level, which is a different parameter.
(And that is in fact the main knob that encoders turn to regulate bit rate and quality.)
Instead, the actual bit depth controls the level of precision at which all mathematical operations
(like motion prediction and DCTs) are performed, as well as the allowable scale for the quantization level.
Encoding at a higher bit depth means that operations are performed with more precision,
which makes certain encoding techniques more precise and hence more efficient, which in turn saves space.
However, raising the bit depth also means that slightly more bits need to be spent to encode the actual quantization factor (and other elements),
so at some point you do get diminishing returns.
Empirically it turns out that encoding at 10bit works pretty well for 8bit content, but that encoding at 12bit is not worth it.)</p>
<div dir="auto"><h4 dir="auto">The Video&#39;s Source (Blu-ray / Web Stream / etc.)</h4><a id="user-content-the-videos-source-blu-ray--web-stream--etc" aria-label="Permalink: The Video&#39;s Source (Blu-ray / Web Stream / etc.)" href="#the-videos-source-blu-ray--web-stream--etc"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This is another slightly tricky one.
<em>Usually</em>, a Blu-ray release of some footage will be better than a web version from the same source,
on account of having a much higher bit rate.
However, this doesn&#39;t <em>always</em> need to be the case:
The fact that various post-processing operations can affect the quality of the video also applies to the authoring stage
(that is, the process of taking a show or movie&#39;s master, and putting it onto a Blu-ray,
performing all the necessary conversion and compression that this entails),
and it is very much possible for a Blu-ray release to have some destructive filtering applied to it that the web releases do not (or for the Blu-ray release to just have terrible encoding settings).
Different web streams from different sites, or different Blu-rays from different authoring companies can be different too.</p>
<p dir="auto">Again, this is especially relevant in anime, where some Blu-ray authoring companies apply a blur to the video before encoding it, which hurts quality<sup><a href="#user-content-fn-lowpass-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-lowpass-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup>.</p>
<p dir="auto">If you&#39;re just starting out in working with video,
it may be hard to judge for yourself which source is better,
but the main thing I want to convey here is that &#34;Blu-ray&#34; does not automatically have to mean &#34;better quality&#34;.
Always try to manually evaluate sources using your eyes,
or ask someone more experienced for advice on which source to pick (see below for some resources on this).</p>

<p dir="auto">HDR (High Dynamic Range) is another complicated topic.
What I mainly want to convey here is that, once again, HDR does not <em>automatically</em> mean &#34;better than SDR&#34;.
If there are HDR and SDR sources of some footage available,
it all depends on how they were created, and from what kind of common source (if there is one).
It&#39;s possible for the SDR version to be a direct tonemap of the HDR one (in which case the HDR version is the objectively better source) or for the HDR version to have been inverse tonemapped from the SDR one (in which case it&#39;s the other way around), or for them to have both been created from some base source (in which case it depends on <em>how</em>).
For example, it is not uncommon for official HDR releases of some footage to never actually reach a brightness above 100 nits,
and hence be no better than the SDR version.</p>
<p dir="auto">In particular, you should be very suspicious of any HDR (or Dolby Vision) source you may find for a video that wasn&#39;t officially released in HDR anywhere.
It&#39;s very much possible that this &#34;HDR&#34; version was created artificially from the SDR version by whoever released it,
in which case (just like an AI upscale) there&#39;s no reason to use it over the base SDR version.</p>
<p dir="auto">Again, HDR is a very complex topic and these things can be very hard to evaluate as a newcomer, but the important thing is to know that this subtlety exists in the first place.
If the SDR version looks decent, you may just want to save yourself (and your viewers, if there are any) the trouble of dealing with HDR and work with the SDR version.</p>

<p dir="auto">As I have already repeated ad nauseam,
the goal of video encoding is to change the source as little as possible.
Just like you shouldn&#39;t change the resolution or frame rate without a good reason,
the same applies to colors.
I sometimes see releases where people &#34;improved the colors :)&#34;,
and it turns out that what they really did was fiddle with the brightness and saturation sliders until it looked &#34;better&#34;
(read: brighter and more vibrant).<sup><a href="#user-content-fn-colorfix-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-colorfix-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup>
But doing this is the opposite of staying true to the source.
Color grading is very important for editing photos or raw footage,
but when you&#39;re working with footage that was <em>already</em> edited and mastered by the artists,
any further &#34;color corrections&#34; go against the artistic intent.</p>
<p dir="auto">In short, remember that &#34;brighter and more saturated&#34; does not mean &#34;better&#34;.</p>
<p dir="auto">Finally, while we&#39;re on the topic of colors:
When you run an encode, especially from some kind of video editing software,
make sure to make a direct comparison of some output frames to the corresponding input frames
<em>using good viewing software</em> (i.e. mpv or vs-preview, see below).
If you see a noticeable color mismatch, this may be due to some misconfiguration in your editing software or project
(like the color matrix or color range)
that you will need to look into.</p>

<p dir="auto">Last but definitely not least, we have another one of the bigger misconceptions.
Many people think that &#34;sharp&#34; means &#34;higher quality&#34; and, in particular, that &#34;blurry&#34; means &#34;lower quality&#34;.
While it&#39;s true that a lower quality encode can manifest itself in more noise around lines,
and that reducing the resolution (which we&#39;ve already established you probably shouldn&#39;t do) will automatically mean that lines can no longer be as sharp,
this is far from a one-to-one correspondence.</p>
<p dir="auto">In reality, the exact same thing as for resolutions, frame rates, or colors applies.
You want to stay as close to your original video as possible.
If some elements of the original video are comparatively blurry, chances are that they&#39;re <em>meant</em> to be blurry.
(Or, at the very least, any kind of sharpening process will not be able to distinguish
between elements that are meant to be blurry and ones that aren&#39;t.)</p>
<p dir="auto">Hence, just like you shouldn&#39;t fiddle with color sliders just to &#34;improve the colors&#34;,
you shouldn&#39;t slap a sharpening filter on top of your video just to &#34;make it sharper :)&#34;.
This will only take your video further away from the source, not closer.<sup><a href="#user-content-fn-sharpening-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-sharpening-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup></p>
<p dir="auto">It&#39;s true that to the layman viewer&#39;s eye, sharper content will look more appealing.
But once you know what to look for, you will see that sharpening creates a lot of ugly artifacts like
line warping or <a href="https://en.wikipedia.org/wiki/Ringing_artifacts" rel="nofollow">haloing</a>.
Like with upscaling, please just take my word for it when I tell you that <strong>prioritizing sharpness above all else is not a good idea</strong>.</p>

<p dir="auto">Now, that was a lot of text, but unfortunately it was needed.
Video is very, <em>very</em> complicated, and this was just the tip of the tip of the iceberg.
In case that was too much information to dump on you all at once, let me summarize the most important takeaways:</p>
<ul dir="auto">
<li>You cannot judge a video&#39;s quality just by looking at its resolution and file size.</li>
<li>If in any way possible, use x264 or x265 to encode your video.
Use the CRF setting to adjust quality vs. file size instead of jumping directly to downscaling.</li>
<li>You should not change any aspect of your video unless you know exactly what you&#39;re doing
(and the target audience of this post does not).
This affects resolution, frame rate, colors, sharpness, and any other postprocessing filters you might think of applying.</li>
</ul>
<div dir="auto"><h3 dir="auto">Learning to Spot Quality Loss</h3><a id="user-content-learning-to-spot-quality-loss" aria-label="Permalink: Learning to Spot Quality Loss" href="#learning-to-spot-quality-loss"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">As a novice video encoder, it may be hard to see quality loss in the beginning.
You may come across images or comparisons where some experienced encoder says &#34;Oh my god this looks terrible!!&#34; while you&#39;re thinking &#34;Are those the same picture?&#34;.</p>
<p dir="auto">But don&#39;t worry, this is normal.
You have to know what to look for in an image, and you have to train your eyes to look for it.
(But know that this is cursed knowledge. Once you learn how to spot artifacts, you can never look at video the same again.)
A full guide on how to spot video artifacts would take up an entire second article with many example images,
but as a short summary, here is a list of areas you should focus on most:</p>
<ul dir="auto">
<li>Dark areas, especially dark gradients</li>
<li>Strong colors, in particular black edges on deep and dark reds</li>
<li>Areas with lots of (static or dynamic) grain or texture</li>
<li>The spaces <em>around</em> sharp lines and edges.
Don&#39;t look at the edges themselves, instead look for noise <em>next</em> to them.
In particular, look for bright &#34;halos&#34; around edges (also called <a href="https://en.wikipedia.org/wiki/Ringing_artifacts" rel="nofollow">ringing</a>)</li>
<li>In particular, look for noise next to sharp full-resolution elements like on-screen text</li>
<li>Image borders</li>
</ul>
<p dir="auto">Keep in mind that what constitutes acceptable quality loss is always in the eye of the beholder,
and that that is a two-way street.
If you are creating encodes mainly for yourself, and you yourself cannot see any quality loss, then there&#39;s no reason to worry about it even if someone else tells you it&#39;s visible.
However, on the other hand, you also shouldn&#39;t criticize anyone for releasing high file size encodes to prevent quality loss just because <em>you</em> can&#39;t see the artifacts they would prevent.</p>

<p dir="auto">This section is a bit more advanced than the other sections.
You can skip it on your first time reading, if you prefer, or only read the summary at the end of the section.</p>
<p dir="auto">There are some things that can go wrong when modifying a video that you should be aware about.
They shouldn&#39;t happen with the workflows described below,
but if you use a different workflow and/or add extra steps, you may run into these.</p>
<p dir="auto">I have mentioned above how videos are (usually) not actually stored as RGB,
and this is where this becomes relevant.
The colors of video frames are usually stored in a different color space called YCbCr.
Here, the &#34;Y&#34; part is called &#34;luma&#34; and more or less represents a pixel&#39;s &#34;brightness&#34;,
while the &#34;Cb&#34; and &#34;Cr&#34; parts are called &#34;chroma&#34; and represent the color tone.
This goes all the way back to how analog color television had to be built in a way that is backwards-compatible with black-and-white television,
but we&#39;re stuck with it now.</p>
<p dir="auto">Moreover, the chroma part of the video is often stored at half the resolution (in both directions) of the luma part.
This is called &#34;chroma subsampling&#34;.
For example, a typical 1920x1080 video would be stored as <code>1920*1080</code> luma values and two sets of <code>960*540</code> chroma values.
When playing the decoded video, your media player first needs to upscale the two 960x540 chroma &#34;planes&#34; to 1920x1080.
Once again, this mostly has historical reasons nowadays.</p>
<p dir="auto">Check this <a href="https://slow.pics/c/FHxrfYwm?image-fit=none" rel="nofollow">comparison</a> for an example of how an RGB image splits into Y/Cb/Cr parts.</p>
<p dir="auto">Now, why do you need to know this?
Well, the problem is that there is <em>more than one way</em> to convert an RGB<sup><a href="#user-content-fn-rgb-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-rgb-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup> image to YCbCr and back.
The most relevant of these two are called BT.601 and BT.709.
Both of these specify a &#34;matrix&#34; (if you don&#39;t know linear algebra, just think of it as a &#34;formula&#34;) that can be used to compute a YCbCr value from an RGB value and vice-versa.
Howver, converting a given YCbCr value to RGB via BT.601 will give a different RGB color than BT.709!</p>
<p dir="auto">Out of these two color matrices, BT.601 is the older one.
It was used for old SD-era content like DVDs.
BT.709, on the other hand, is the newer matrix.
The vast majority of videos you will run into (say: movies and TV shows that were produced in 720p or higher, screen captures, most YouTube videos<sup><a href="#user-content-fn-ytmatrix-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-ytmatrix-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">11</a></sup>, etc.) should be BT.709.
One notable exception here is HDR video, but dealing with that properly is an entirely different beast of its own and is outside the scope of this post.</p>
<p dir="auto">However, some old software (including ffmpeg!) may still default to using BT.601 in certain cases even when BT.709 should be used instead.
This is why it is important to know about this distinction.</p>
<p dir="auto">Now, a media player playing back a video file needs to <em>know</em> which color matrix (BT.601 or BT.709) a video uses.
For a &#34;well-behaved&#34; video, this is specified in the video&#39;s metadata, but unfortunately many videos <em>aren&#39;t</em> this well-behaved.
(And many video editing or encoding programs do not always store this information in the metadata of the videos they output.)</p>
<p dir="auto">If the media player does not know what color matrix a video file uses, it has to guess based on the information it has, like e.g. the video&#39;s resolution.
For example, some video players may guess that an untagged (i.e. with no specified matrix) video uses BT.601 if its height is less than, say, 600 (suggesting that this is an SD era video).</p>
<p dir="auto">This can already cause some suprising behavior!
Let&#39;s say you have an untagged 1080p video, which you then downscale to 480p (which I have explained above may be a bad idea, but that&#39;s beside the point here).
If you open the 1080p video and the 480p video side by side in such a media player,
the two videos will be displayed with different colors!</p>
<p dir="auto">If you were seeing this without knowing what&#39;s going on, you might be lead to conclude that the video encoder is somehow changing the colors,
but the reality is that the change in resolution is causing the media player to guess a different color matrix.
Hence, you can solve this by tagging both your input and your output video as BT.709.
(If you tag the input video as BT.709, most encoders should should also copy this to your output video.)</p>
<p dir="auto">For reasons like these, this topic can cause great headaches, but the upshot is:
<strong>If you see your reencode somehow changing colors, check your input and output video&#39;s color matrices.</strong>
If your source video is untagged, it can be hard to figure out what color matrix it <em>should</em> have,
but when in doubt you can at least make sure that your output has the same matrix as your input
(or, if your input is untagged, the same matrix as what a player like mpv would guess).
Or, of course, you can ask someone more experienced for advice.</p>
<p dir="auto">You can check a file&#39;s color matrix in MediaInfo (see the section below for the tools mentioned here),
and you can edit it in MKVToolNix.
To see what color matrix mpv assumes on your video, open your video in mpv, press <code>i</code>, and check the <code>Colormatrix: </code> field under the &#34;Video&#34; section (<em>not</em> the &#34;Display&#34; section).</p>

<p dir="auto">Unfortunately, the story does not end with the color matrix.
The matrix is just one of multiple parameters that specify how to interpret a video&#39;s colors.
The full list of parameters is:</p>
<ul dir="auto">
<li>The color matrix (BT.709 / BT.601 / BT.2020 / etc.). Note that BT.601 is sometimes also called SMPTE170M or BT.470BG.</li>
<li>The color range (Limited or Full)</li>
<li>The transfer characteristics, or gamma (BT.709 / BT.601 / BT.1886 / sRGB / PQ / HLG / etc.)<sup><a href="#user-content-fn-transfer-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-transfer-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">12</a></sup></li>
<li>The primaries (BT.709 / BT.601 / BT.2020 / etc.)</li>
<li>The chroma location (Left or Center Left / Center / Top Left / etc.)</li>
</ul>
<p dir="auto">Yes, codes like &#34;BT.709&#34; can refer to <em>multiple</em> of these parameters.
But this doesn&#39;t cause much confusion in my experience, since most programs make a clear distinction between matrix, transfer, and primaries.
If you hear someone talk about &#34;a BT.709 video&#34; (without specifying whether they mean matrix, transfer, or primaries),
they probably mean the matrix.
(A video with a BT.709 matrix does not need to automatically have BT.709 transfer and primaries (it could have sRGB instead, for example), but if you see a video tagged with a mix of BT.709 and BT.601 that usually means that something went wrong <em>somewhere</em>.)</p>
<p dir="auto">All of these five parameters are values that are necessary to properly interpret a video&#39;s colors,
and that <em>should</em> be provided as metadata but often aren&#39;t.
Luckily, if you&#39;re editing a video, you generally only need to worry about the matrix, range, and chroma location - the other two (transfer and primaries) are less likely to break.</p>
<p dir="auto">We have already talked about the matrix, so let&#39;s continue with the range.
The vast majority of videos you&#39;re dealing with will have a &#34;Limited&#34; range.
The color range should also not break when reencoding video with, say, ffmpeg, but I <em>have</em> seen issues with color range when working with video editors like Vegas.
When you see your output colors being much darker or much brighter than your input, check the color range settings of your editing program.</p>
<p dir="auto">Finally, there is the chroma location.
This is the most subtle of all of these, since it&#39;s harder to notice issues with it,
but it may also be the one with the highest risk of breaking - especially when working with video editing programs.</p>
<p dir="auto">When applying chroma subsampling (which, as you hopefully remember, is the process of scaling down the chroma by a factor of two in each direction), there are multiple ways to perform the downscale process.
Ultimately, what you need to do is turn each 2x2 group of four chroma values into a single value.
One way to do this would be to simply take the top left pixel of each 2x2 group.
Alternatively, one could average all four pixel values together and obtain a new value that could be interpreted as the interpolated &#34;middle&#34; value of the 2x2 square.
These two methods result in different alignments of the chroma sample grid relative to the video&#39;s pixel grid:
A chroma value could either &#34;come from&#34; the top left of a 2x2 square of luma values, or from the &#34;middle&#34; (or from some other location).
This is called the &#34;chroma location&#34;, and it is yet another parameter that media players need to know to play a file back properly:
When scaling the chroma back to the luma&#39;s full resolution, the scaling process needs to factor in the chroma location in order to not introduce a shift relative to the original chroma.</p>
<p dir="auto">For reasons that I have not yet been able to uncover, the standard chroma location for most videos is actually &#34;center left&#34;,
i.e. in the middle between left two samples of the four luma samples.
Hence, video players (or at least good players like mpv) will default to &#34;center left&#34; chroma when a video&#39;s chroma location is not tagged.
However, a lot of video processing software does not handle chroma location correctly, e.g. often using a chroma location of &#34;center&#34; instead.
Because of this, depending on your workflow, editing a video may sometimes introduce a &#34;chroma shift&#34; where the chroma ends up shifted by some small amount relative to the luma.
This can be hard to spot to a novice video encoder, but it manifests in colored lines consistently having a slightly different color on one side of the line than on the other side.
As before, chroma location issues can usually be fixed by tagging your videos and/or configuring your tools correctly (and by asking a more experienced person if necessary).</p>
<p dir="auto"><strong>In summary</strong>: Depending on your workflow, processing your video may have a risk of breaking your video&#39;s color matrix, color range, or chroma location. (And, moreover, it is possible for your sources to have broken or mistagged matrices, ranges, or chroma locations. But if you are starting out it may be better not to worry about that part, and to just ensure that you aren&#39;t introducing any <em>additional</em> problems involving these parameters.) These issues can manifest as follows:</p>
<ul dir="auto">
<li>Wrong (usually mistagged or untagged) color matrices:
Generally manifests in colors slightly changing in hue and intensity.
See <a href="https://slow.pics/c/ILKT9eMG" rel="nofollow">this comparison</a> for an example.
This can usually be fixed by tagging your input correctly.</li>
<li>Wrong color range:
This will manifest in colors becoming much less saturated or more saturated throughout.
See <a href="https://slow.pics/c/wMsTpPsP" rel="nofollow">this comparison</a> for an example.
Color range issues should be fairly rare for normal reencodes, but can happen when using a misconfigured video editor.</li>
<li>Chroma shift:
See <a href="https://slow.pics/c/HUDn94wt" rel="nofollow">this comparison</a> for an example.
This one can be hard to spot for beginners.
The easiest way to spot a shift with a given reference is to (zoom in a lot and) look at areas with very strong colors.
Spotting a chroma shift without a reference is even harder,
but in this comparison you can see that diagonal lines on the &#34;chroma shift&#34; image have a slight reddish glow on the right side and a blue-ish glow on the left side.
When this glow is consistent throughout the entire video, that may be indicative of a chroma shift.
(Make sure to not confuse an intentionally added chromatic abberation effect for a chroma shift, though.<sup><a href="#user-content-fn-ca-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-ca-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">13</a></sup>)
How to fix a chroma shift can depend a lot based on your workflow (so figuring out where it is introduced should be your first step), but tagging your input video and checking your editing software&#39;s configuration will definitely help.
If you cannot figure out how to configure your software to avoid a chroma shift, you can try retagging your output.</li>
</ul>
<p dir="auto">This section was far more technical than the rest, but the good news is that you do not need to understand all of it right away.
The important parts to remember are that processing a video can cause some issues related to color spaces.
When trying out a new workflow, it may be a good idea to compare an output frame to the corresponding input frame and look for any color mismatches that look like the ones in the examples above.
If you don&#39;t see any, you can forget everything you read in this section.
If you do find something, this section may help you to fix it.</p>

<p dir="auto">When you&#39;re working on an anime or some other media that is not in your target audience&#39;s language,
you will need to add subtitles, in which case there are a couple of things you should know.</p>
<p dir="auto">The most powerful format for subtitles is Advanced SubStation Alpha, or ASS for short<sup><a href="#user-content-fn-ass-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-ass-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup>.
ASS subtitles not only allow showing subtitles for spoken dialogue
but also creating translations for on-screen text that blend in seamlessly with the original video.
Even if you do not plan to make subtitles like these themselves,
you probably want to ship subtitles you downloaded from somewhere, which will probably be in the ASS format.</p>
<p dir="auto">One important thing to know is that the only container format that really supports ASS subtitles is mkv.
If, for some reason (probably because you&#39;re targeting some kind of streaming),
you do not want to release an mkv file in the end,
you will need to hardsub.
See below for the best way to do this.</p>
<p dir="auto">Secondly, if your goal is to edit your video,
you will have to think about how to match your subtitles to your edit.
There is no good automated solution here.
Your options are basically:</p>
<ol dir="auto">
<li>Manually retime the subtitles in a program like Aegisub, or</li>
<li>Hardsub the subtitles and edit the hardsubbed video.</li>
</ol>
<p dir="auto">In general, you should avoid hardsubbing when possible, since it</p>
<ul dir="auto">
<li>involves reencoding, and hence introduces quality loss,</li>
<li>takes time (which may not be a problem when you are only editing your video once,
but becomes increasingly annoying if you want to make incremental fixes later on),</li>
<li>makes it much harder for anyone, including yourself, to change some aspect of the subtitles later on.</li>
</ul>
<p dir="auto">However, retiming all subtitles yourself for a quick edit is also a lot of effort.
In the end, the choice is yours.
If you do end up hardsubbing, make sure you do it correctly.
Read the later sections for how.</p>
<div dir="auto"><h2 dir="auto">Recommended Tools and Workflows</h2><a id="user-content-recommended-tools-and-workflows" aria-label="Permalink: Recommended Tools and Workflows" href="#recommended-tools-and-workflows"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">I&#39;ve now talked a lot about what you <em>shouldn&#39;t</em> do, so what should you do instead?
This section contains some useful tools, as well as workflows to do certain things the right way.</p>

<ul dir="auto">
<li>
<p dir="auto"><a href="https://mediaarea.net/en/MediaInfo" rel="nofollow">MediaInfo</a>: If you install one tool from this list, you should install this one, which is why it&#39;s listed at the top.
Step 0 in anything to do with video is finding out what exactly you are working with, and MediaInfo will tell you exactly that.
Open a file in MediaInfo and switch the view to &#34;Text&#34; at the top to see all important data.
If you ever need help from someone more experienced with video, sending them a proper MediaInfo dump of your file is a great way to get them into a good mood.</p>
</li>
<li>
<p dir="auto"><a href="https://mpv.io" rel="nofollow">mpv</a> is the single best media player out there, and ideally you should use it.
MPC-HC (if you get the actual <a href="https://github.com/clsid2/mpc-hc/releases">latest version</a>) is alright too,
but mpv is the definite best.
In particular, VLC is not recommended.</p>
<p dir="auto">Apart from simply watching the video, mpv can also make screenshots and encode videos for you.
The latter in particular is very helpful for hardsubbing.</p>
</li>
<li>
<p dir="auto"><a href="https://ffmpeg.org" rel="nofollow">ffmpeg</a> is your Swiss army knife for everything to do with video,
from inspecting to encoding and remuxing.
(Though you should know that it&#39;s usually not actually ffmpeg itself that&#39;s doing the encoding.
When you encode to H.264/H.265 with ffmpeg, ffmpeg is actually calling x264/x265 internally.
I&#39;m mainly bringing this up because it bothers me how everyone praises ffmpeg for being good at encoding when it&#39;s really x264/5,
but this also means that you should check the x264/5 documentation if you need help with encoding, not ffmpeg&#39;s.)</p>
<p dir="auto">Note that ffmpeg is kind of a jack of all trades, master of none.
It can do a lot of things fairly well,
but for specific tasks there are often specialized tools available that do it even better.</p>
<p dir="auto">FFmpeg is a <em>command-line tool</em>.
If you have never used a command-line tool before, read <a href="https://developer.mozilla.org/en-US/docs/Learn_web_development/Getting_started/Environment_setup/Command_line" rel="nofollow">this page</a> for a quick primer.</p>
<p dir="auto">Before you start complaining about how complicated ffmpeg is and how arcane its syntax is,
do yourself a favor and read the start of <a href="https://ffmpeg.org/ffmpeg.html" rel="nofollow">its documentation</a>.
It turns out that reading the (f.) manual actually helps a lot!</p>
</li>
<li>
<p dir="auto">Use <a href="https://slow.pics" rel="nofollow">SlowPics</a> if you want to share image comparisons.
There are also ways to <a href="https://jaded-encoding-thaumaturgy.github.io/JET-guide/master/misc/comparison/" rel="nofollow">automatically upload comparisons to SlowPics</a> using <a href="https://github.com/Jaded-Encoding-Thaumaturgy/vs-preview/">vs-preview</a>, but those are a bit more involved.</p>
<p dir="auto">When looking at a SlowPics comparison, uncheck &#34;Show border&#34; and &#34;Smooth scaling&#34; at the bottom and use the clicker comparison rather than a slider. Use the number keys (1/2/3/etc) to switch between images.</p>
</li>
<li>
<p dir="auto"><a href="https://mkvtoolnix.download/downloads.html#windows" rel="nofollow">MKVToolNix</a> for muxing mkv files.
You can do this with ffmpeg too, but MKVToolNix has a GUI if you need one (and is better in certain ways).</p>
</li>
<li>
<p dir="auto"><a href="https://www.videohelp.com/software/MKVExtractGUI-2" rel="nofollow">MKVExtractGUI</a> or <a href="https://www.videohelp.com/software/MKVcleaver" rel="nofollow">MKVcleaver</a> to extract tracks from mkv files (or learn how to do it with ffmpeg).</p>
</li>
<li>
<p dir="auto"><a href="https://aegisub.org" rel="nofollow">Aegisub</a> to edit subtitles.
Note that you can also simply open <code>.srt</code> or <code>.ass</code> subtitles in a text editor like Notepad
if you need to quickly check something,
but if you want to do actual editing or timing you should use a proper tool like Aegisub.</p>
</li>
<li>
<p dir="auto"><a href="https://www.videohelp.com/software/MkvToMp4" rel="nofollow">MkvToMp4</a> for remuxing an <code>.mkv</code> file to an <code>.mp4</code> with a proper constant frame rate (see below).</p>
</li>
</ul>

<ul dir="auto">
<li>Avoid using Handbrake if possible.
Handbrake has a lot of footguns like suddenly changing the frame rate or adding interlacing.
I would recommend you to just learn basic ffmpeg usage instead.
If you must use a GUI, try <a href="https://github.com/staxrip/staxrip">Staxrip</a>.</li>
<li>Don&#39;t use any file conversion websites.
Those all just use ffmpeg under the hood anyway,
so you&#39;d be better off just spending the 10 minutes to learn how to use ffmpeg directly.
Hopefully I don&#39;t need to tell you that you shouldn&#39;t fall for any <a href="https://compresto.app" rel="nofollow">30$ x264/ffmpeg wrappers</a> either.</li>
<li>Don&#39;t use Topaz AI, Anime4k, RealESRGAN, RIFE, etc. Trust me, just don&#39;t.</li>
<li>Don&#39;t use imgsli for image comparisons, it (lossily) converts its images to JPEG which invalidates any comparisons.
Use SlowPics (linked above), and try not to use the slider feature there either.
You can spot a lot more differences by switching the full images back and forth than with a slider.</li>
</ul>

<p dir="auto">Finally, let me explain a few things you <em>should</em> do.</p>
<p dir="auto">If you&#39;ve read the previous sections, you&#39;ll know that reencoding a video will hurt its quality
(and reencoding it over and over will hurt its quality even more, since later encodes will spend bits to reproduce the artifacts introduced in the previous encodes).
Hence, you should make sure that you only reencode when absolutely necessary,
and do all other necessary conversions through remuxing.
Ideally, that would mean (lossily) reencoding only once, at the very end of your workflow.
If your editing software does not allow encoding using x264/x265, you can export a lossless render from it and then encode that lossless render with ffmpeg.</p>
<p dir="auto">Sometimes, you cannot easily avoid reencoding an additional time at some other step in your workflow.
If this happens, at least make sure that your intermediary encodes are either lossless, or as close to lossless as possible.
Unfortunately, I have not yet found a reliable way to encode a lossless file that common editing programs can open
(if you know one, let me know!),
but at the very least you can make an x264 encode with <code>-crf 1</code>.</p>
<p dir="auto">To make an <em>actually</em> lossless encode with <code>x264</code> you can add <code>-qp 0</code> instead of a <code>-crf</code> argument,
but be aware that not all programs will be able to open such a file.</p>

<p dir="auto">The simplest way to encode a video is using ffmpeg.
More advanced users will encode using x264 or x265 directly, but ffmpeg is fine for beginners.</p>
<p dir="auto">A basic template command to reencode a video is simply<sup><a href="#user-content-fn-encodetemplate-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-encodetemplate-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup></p>
<pre><code>ffmpeg -i yourinput.mkv -c copy -c:v x264 -preset slower -crf 20 youroutput.mkv
</code></pre>
<p dir="auto">As explained in the first section, adjust the CRF to control the quality at the expense of file size.
If you&#39;re encoding anime or animation, you may want to bump up the bframes by adding <code>-x264-params bframes=8</code>
(which will save a bit of file size but take longer to encode).
Other than that, <strong>do not touch any other settings you do not understand</strong>.
In particular, do not use <code>-tune animation</code> for anime; that tune is targeted towards extremely flat animation,
so it will be counterproductive on anime, which usually has a fair amount of grain and texture.</p>
<p dir="auto">A good way to think of video encoding is as a three-way tradeoff between file size, quality, and encoding speed.
You can decrease the file size, but only at the expense of quality or encoding speed,
and similarly for the other two factors.
The <code>crf</code> setting is used to regulate between quality and (decrease in) file size.
The <code>preset</code> setting controls the encoding speed, and hence the efficiency.
A faster preset will mean a faster encode, but also a larger and lower-quality one.</p>
<p dir="auto">Be aware that the visual quality of a given CRF value will depend on the resolution you&#39;re encoding at.
CRF 18 at 1080p behaves differently from CRF 18 at 480p.
The best way to pick a CRF for your encode is just to run a few sample encodes and compare the results.</p>

<p dir="auto">Hopefully you can figure this out with the tools linked above (MKVToolNix being the easiest way).
All I really want to say here is that if you are muxing in ASS subtitles,
you need to add all the fonts used in the subtitles as attachments.
Aegisub has a font collector that can collect all the fonts used in a file.
If you don&#39;t want to install the fonts, you can use a font manager like <a href="https://fontba.se" rel="nofollow">FontBase</a> (add the folder with all fonts as a &#34;watched folder&#34;) to temporarily activate them without installing them.</p>

<p dir="auto">This is more tricky and the main reason why this section exists.
In principle, muxing an mp4 file is easy: Just run <code>ffmpeg -i yourinput.mkv -c copy youroutput.mp4</code>.
However, chances are that the reason you are remuxing to an mp4 file is so that you can import your video into your favorite video editing program.
In that case, remuxing using ffmpeg can cause some problems with the frame rate.</p>
<p dir="auto">Most videos you&#39;ll come across have a constant fractional framerate of 24000/1001 (which is approximately 23.976) frames per second.
But this is actually a bit of a lie: A lot of times the frame rates aren&#39;t <em>truly</em> constant
(and, in fact, in mkv files they often <em>cannot</em> be).
For certain technical reasons, frame timestamps often need to be rounded,
which causes ever-so-slight deviations from the constant 24000/1001 frames per second.
Video players handle this completely fine, so that you&#39;d never even notice it as a normal (or even experienced) user.
However, some video editing programs can be extremely picky about these frame rates,
and introduce stuttering when the frame rate is not <em>truly</em> constant.</p>
<p dir="auto">Since mkv files fundamentally cannot have a true constant frame rate of 24000/1001,
remuxing to mp4 using ffmpeg will also result in a frame rate that is not truly constant.
You can see this in MediaInfo in the <code>Frame rate mode</code> entry.<sup><a href="#user-content-fn-mediainfoframerate-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-mediainfoframerate-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">16</a></sup></p>
<p dir="auto">There exist a couple of ways to fix this:</p>
<ol dir="auto">
<li>
<p dir="auto"><a href="https://www.videohelp.com/software/MkvToMp4" rel="nofollow">MkvToMp4</a> is a GUI application that can remux an mkv to an mp4 file
and force a constant frame rate if applicable.
While I haven&#39;t audited it in detail myself,
I know video editors who have used it for a long time and haven&#39;t had issues with it.
Note that it only supports H.264, not H.265, though.</p>
</li>
<li>
<p dir="auto">With the right incantation, you can also force a constant frame rate in ffmpeg.
The best one I could come up with needs two invocations, though:</p>
<pre><code>ffmpeg -i yourinput.mkv -c copy -video_track_timescale 24000 intermediary.mp4
ffmpeg -i intermediary.mp4 -c copy -bsf:v &#34;setts=dts=1001*round(DTS/1001):pts=1001*round(PTS/1001)&#34; out.mp4
</code></pre>
<p dir="auto">If your source video is, say, 30000/1001 fps instead of 24000/1001,
replace the 24000 in the first call with the appropriate numerator.</p>
<p dir="auto">There also exists a tool called <a href="https://github.com/nu774/mp4fpsmod">mp4fpsmod</a> that can force mp4 frame rates,
but I found the ffmpeg call to be more reliable when the first frame does not start at timestamp 0.</p>
</li>
</ol>

<p dir="auto">Use mpv to hardsub:</p>
<pre><code>mpv --no-config yourinput.mkv -o youroutput.mkv --audio=no --ovc=libx264 --ovcopts=preset=slower,crf=20,bframes=8
</code></pre>
<p dir="auto">Adjust the encoding settings accordingly, of course.</p>
<p dir="auto">This will hardsub the track marked as the default, add e.g. <code>--sid=0</code> or <code>--slang=eng</code> to select a different track.
Hardsubbing is an extra encoding step, and like explained above you want to reencode as few times as possible.
Hence, either make sure that hardsubbing happens at the end of the workflow from a lossless source,
or output a (near) lossless encode when hardsubbing (e.g. by setting the CRF to 1).</p>

<p dir="auto">This is a bonus section meant to prevent some slightly more advanced misconceptions.
If you don&#39;t know what the term &#34;interlacing&#34; means, you can safely skip this section.</p>
<p dir="auto">If you <em>do</em> know what interlacing means,
the main thing I want to get across here is that not all interlacing is the same,
and in particular that the answer to seeing footage that looks &#34;interlaced&#34; is not always to run a deinterlacer.</p>
<p dir="auto">When working with movies and TV shows,
it is actually much more likely for interlaced-looking footage to really be <em>telecined</em>.<sup><a href="#user-content-fn-telecine-1ac27315a113f5ac88cc6f37fd0a8fdc" id="user-content-fnref-telecine-1ac27315a113f5ac88cc6f37fd0a8fdc" data-footnote-ref="" aria-describedby="footnote-label">17</a></sup>.
What this means exactly is outside the scope of this article,
but you can read <a href="https://fieldbased.media" rel="nofollow">fieldbased.media</a> or <a href="https://wobbly.encode.moe/gettingstarted/primer.html" rel="nofollow">the Wobbly guide</a> for more information.
The important takeaway is that telecining can (almost) be losslessly reversed (though it may need manual processing),
and that running a deinterlacer on telecined footage will throw away half the vertical resolution while still keeping the frame rate stutters.
When you see footage that shows combing, please consult some more experienced person before blindly running a deinterlacer on it.</p>

<p dir="auto">The above should cover everything you need to know as a beginner.
If you like to suffer and are interested in learning more about multimedia and encoding,
the  <a href="https://jaded-encoding-thaumaturgy.github.io/JET-guide/master/" rel="nofollow">JET Guide</a> can be a good place to start.
In particular, it contains a big <a href="https://jaded-encoding-thaumaturgy.github.io/JET-guide/master/resources/" rel="nofollow">list of resources</a> that link other good guides.</p>

</article>
  </div>

  </div>
</div></div>
  </body>
</html>
