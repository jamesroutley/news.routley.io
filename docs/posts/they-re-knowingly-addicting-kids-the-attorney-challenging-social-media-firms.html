<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theguardian.com/us-news/2024/jan/25/kids-addicted-social-media-congress-meta-tiktok-snap">Original</a>
    <h1>&#39;They&#39;re knowingly addicting kids&#39;: the attorney challenging social media firms</h1>
    
    <div id="readability-page-1" class="page"><div id="maincontent"><div><p>Next week, executives from some of the biggest social media firms will be called before the <a href="https://www.theguardian.com/us-news/us-congress" data-link-name="in body link" data-component="auto-linked-tag">US Congress</a> to answer questions about their “failure to protect” children who use their platforms.</p><figure id="4d0feb1d-88b3-44b1-b49d-001afe7157e9" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&#34;richLinkIndex&#34;:1,&#34;element&#34;:{&#34;_type&#34;:&#34;model.dotcomrendering.pageElements.RichLinkBlockElement&#34;,&#34;prefix&#34;:&#34;Related: &#34;,&#34;text&#34;:&#34;‘Fundamentally against their safety’: the social media insiders fearing for their kids&#34;,&#34;elementId&#34;:&#34;4d0feb1d-88b3-44b1-b49d-001afe7157e9&#34;,&#34;role&#34;:&#34;richLink&#34;,&#34;url&#34;:&#34;https://www.theguardian.com/lifeandstyle/2024/jan/18/tech-workers-kids-social-media-screen-time&#34;},&#34;ajaxUrl&#34;:&#34;https://api.nextgen.guardianapps.co.uk&#34;,&#34;format&#34;:{&#34;display&#34;:0,&#34;theme&#34;:0,&#34;design&#34;:15}}" config="{&#34;renderingTarget&#34;:&#34;Web&#34;,&#34;darkModeAvailable&#34;:false}"><div data-print-layout="hide" data-link-name="rich-link-1 | 1" data-component="rich-link" data-name="placeholder"></div></gu-island></figure><p>In attendance will be Matthew P Bergman, founding attorney of the Social Media Victims Law Center – a law firm dedicated exclusively to representing the families of children allegedly harmed by social media. The firm has filed cases against platforms including Meta, Snap, TikTok, and Discord.</p><p>Bergman, who has been practicing law since 1991,<strong> </strong>had a storied career in asbestos litigation before turning his attention to social media. Inspired by the testimony of Facebook whistleblower <a href="https://www.theguardian.com/technology/2021/oct/24/frances-haugen-i-never-wanted-to-be-a-whistleblower-but-lives-were-in-danger" data-link-name="in body link">Frances Haugen</a>, Berman said he noticed a number of parallels between social media and asbestos. Both are products initially thought to be beneficial before being exposed as detrimental to human health, he said. The corporations involved brazenly tried to cover up the harms they knew were coming, he added.</p><p>“The confluence of these things made me think that this really was asbestos all over again,” Bergman said. “I saw this as an opportunity to do something different with my legal career – something more proactive.”</p><p>Lawsuits against social media firms over alleged harms have long struggled to see their day in court due to section 230 of the 1996 Communications Decency Act, a federal law in the US that shields online platforms from liability for illegal actions of their users. With this in mind, Bergman took on a different tack, modeled after his days in asbestos litigation. Rather than arguing against content on the platforms, his firm leans on product liability laws and argues that the products are harmful by design.</p><p>“We’re not winning yet – we’re just getting in the game,” Bergman said. “It’s clear that this is going to be a long, hard fight.”</p><p>The Guardian spoke with Bergman about similarities between his history in asbestos litigation, his present focus on social media firms and his expectations for the upcoming Senate hearing.</p><p><strong>Can you start by talking about how the Social Media Victims Law Center came to exist?</strong></p><p>I founded the Social Media Victims Law Center in the fall of 2021. I had spent a career recovering money for injured victims, including over $1bn for asbestos victims over more than 20 years. But I reached the stage in life where I wanted to do something to not just compensate victims, but to stop people from becoming victims in the first place.</p><p>It coincided with the testimony of Francis Haugen before the Senate commerce committee, where she for the first time made clear what a lot of us suspected: that social media companies knowingly design products to addict kids – as well as the surgeon general’s <a href="https://www.hhs.gov/about/news/2023/05/23/surgeon-general-issues-new-advisory-about-effects-social-media-use-has-youth-mental-health.html" data-link-name="in body link">advisory on the youth mental health crisis</a> in the US, and around the world.</p><p><strong>What similarities have you seen between your career in asbestos litigation and your efforts to take on social media harms?</strong></p><p>These were some of the same dynamics that I had litigated in asbestos – namely, a ubiquitous product that is at least initially seen as a very good thing. When social media first came out, they thought this was going to save the world, that it was going to be a change for the better. With social media, like asbestos, you have a cause-and-effect relationship between a product and a disease manifesting in terms of a public health crisis. Whereas asbestos was the largest industrial carcinogen that was ever exposed to workers around the world, with social media we see a public health crisis emerging in the form of youth mental health and suicidality, as well as sexual abuse arising from social media.</p><p>As in asbestos, you also have outrageous corporate misconduct. The reason the asbestos companies took the hits that they did was because their documents showed that they knowingly exposed workers to a product that they had actual knowledge was going to kill them. And what we’ve seen from the social media companies is the same level of culpability. You look at Francis Haugen’s documents and see that they know their products make <a href="https://www.theguardian.com/technology/2023/nov/07/meta-facebook-employee-congress-testimony-instagram-child-harm-social-media" data-link-name="in body link">young girls feel worse</a> and give kids an addict’s mentality. We are seeing the same kinds of smoking gun documents that we saw in asbestos litigation.</p><p><strong>I know you’ve talked about a lot of the similarities between your asbestos litigation and social media. Are there any key differences or changes you’ve had to make to strategy?</strong></p><p>One of the key differences is that in asbestos litigation, the outrageous misconduct typically occurred decades before the manifestation of the disease in the exposed worker, whereas there is no latency period with social media.</p><p>The other difference is that we’re talking about young, vulnerable kids. The generation of clients that I previously represented – while they didn’t know about asbestos, they understood they may have to work a dangerous job to put food on the table for their family. In this case, the exposed cohort are kids that, by virtue of basic neurology, do not have the reasoning power to make that kind of cost-benefit analysis.</p><p>The third major difference is that nobody is addicted to asbestos. People worked around it without knowing about it. In this case, we know that social media is addictive. We thought until about a year ago that this was a behavioral addiction, but new evidence is suggesting that there is an actual physiological addiction and that among adolescents, there’s differential brain development in the hypothalamus based upon frequency of social media use.</p><p>I think these differences make social media much more morally reprehensible than asbestos – which is a hard thing to say, because I spent a career representing people who were dying because of asbestos companies’ misconduct. But I always say the conduct of the social media industry makes the asbestos companies and their CEOs look like a bunch of Boy Scouts.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-20">skip past newsletter promotion</a><p id="EmailSignup-skip-link-20" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p><strong>What about their behavior makes you say that? Is it just that they’re targeting such a vulnerable group of victims, or is it their legal strategies?</strong></p><p>Well, they’re addicting kids and they know it. They know the dopamine response diminishes over time as a young brain becomes habituated to particular stimuli, so the algorithms are designed to provide more and more discordant, disturbing and outrageous material in order to keep that level of engagement.</p><p>The other is that they are intentionally designed to take advantage of adolescents’ need for social acceptance and social status with gamification features such as Snap streaks, or how many friends you have, or how often you are engaged with directly. We now understand that the dopamine response to a “like” on social media for a 14-year-old is a similar response to a bump of cocaine of an older person. So it is not only a physiological process, but also a sociological process.</p><p><strong>Could you speak generally about your legal strategies with social media firms and how they are different from people attempting to go up against these companies in the past?</strong></p><p>Past attempts have focused more on inadequate content moderation – that the companies allowed a third party to post bullying, harassment or salacious content and didn’t remove it. That falls within traditional publishing protections, which are protected by section 230, so the courts have held up until now. To get around this, you’d have to focus on the design, which is what we are trying to do.</p><p><strong>Is this strategy similar to your asbestos career, in terms of focusing on failure to warn and product liability?</strong></p><p>Yes, the theory behind product liability is that you place the duty of creating a safe product in the hands of the party most able to make that product safe to manufacture. It’s basic Milton Friedman, Richard Posner economics; it’s not liberal woo-woo stuff.</p><p>What we are doing is seeking to adapt 1950s product liability concepts to 21st century products – by definition, it’s pouring old wine into new bottles, but that’s what lawyers do.</p><p><strong>You’ve talked a lot about your background with asbestos, but is there any other precedent for the kind of movement we’re seeing against </strong><strong>big </strong><strong>tech? I’ve seen it compared to tobacco and opioids.</strong></p><p>Just as social media companies have designed their algorithms to be addictive, we know tobacco companies knowingly manipulated nicotine levels in their products to make them more addictive – so there is a similarity there. The other similarity is that the tobacco companies marketed to young people, because they knew that lifetime smokers are often people that start smoking in their teens.</p><p><strong>It feels like there is generally a lot more support from both the public and legislators to rein in </strong><strong>big </strong><strong>tech recently, compared to the more free</strong><strong>wheeling early days of the internet. Why do you think the tide is turning on that?</strong></p><p>When the internet came out, it was greeted with a lot of optimism – we thought it was this thing that was going to bring people together, and make us a closer and more prosperous society. The addictiveness of the algorithmic design was really unknown. One of the reasons for that is because these companies have operated under this veil of immunity [due to section 230] and avoid the kind of public scrutiny that other companies have.</p><p>It took a while for the harms associated with social media to publicly manifest and be identified. In the 90s, there was a landmark hearing in which CEOs of tobacco companies stood in front of Congress and testified they did not believe that nicotine was addictive. I think the upcoming hearing has the possibility of the same level of historic significance – and hopefully, the same level of cure.</p></div></div></div>
  </body>
</html>
