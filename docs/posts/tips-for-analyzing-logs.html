<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jvns.ca/blog/2022/12/07/tips-for-analyzing-logs/">Original</a>
    <h1>Tips for analyzing logs</h1>
    
    

<p>Hello! I&rsquo;ve been working on writing a zine about debugging for a while now
(we&rsquo;re getting close to finishing it!!!!), and one of the pages is about
analyzing logs. I <a href="https://mastodon.social/@b0rk/109473352725574776">asked for some tips on Mastodon</a>
and got WAY more tips than could fit on the page, so I thought I&rsquo;d write a
quick blog post.</p>

<p>I&rsquo;m going to talk about log analysis in the context of distributed systems
debugging (you have a bunch of servers with different log files and you need to
work out what happened) since that&rsquo;s what I&rsquo;m most familiar with.</p>

<h3 id="search-for-the-request-s-id">search for the request&rsquo;s ID</h3>

<p>Often log lines will include a request ID. So searching for the request ID
of a failed reques will show all the log lines for that request.</p>

<p>This is a GREAT way to cut things down, and it&rsquo;s one of the first helpful tips
I got about distributed systems debugging &ndash; I was staring at a bunch of graphs
on a dashboard fruitlessly trying to find patterns, and a coworker gave me the
advice (&ldquo;julia, try looking at the logs for a failed request instead!&rdquo;).  That
turned out to be WAY more effective in that case.</p>

<h3 id="correlate-between-different-systems">correlate between different systems</h3>

<p>Sometimes one set of logs doesn&rsquo;t have the information you need, but you can
get that information from a different service&rsquo;s logs about the same request.</p>

<p>If you&rsquo;re lucky, they&rsquo;ll both share a request ID.</p>

<p>More often, you&rsquo;ll need to manually piece together context from clues and the timestamps of the request.</p>

<p>This is really annoying but I&rsquo;ve found that often it&rsquo;s worth it and gets me a key piece of information.</p>

<h3 id="beware-of-time-issues">beware of time issues</h3>

<p>If you&rsquo;re trying to correlate events based on time, there are a couple of things to be aware of:</p>

<ul>
<li>sometimes the time in a logging system is based on the time the log was
<strong>ingested</strong>, not the time that the event actually happened. Sometimes you
have to write a date parser to get the actual time the event happened.</li>
<li>different machines can have slightly skewed clocks</li>
</ul>

<h3 id="build-a-timeline">build a timeline</h3>

<p>Keeping all of the information straight in your head can get VERY confusing, so
I find it helpful to keep a debugging document where I copy and paste bits of
information.</p>

<p>This might include:</p>

<ul>
<li>key error messages</li>
<li>links to relevant dashboards / log system searches</li>
<li>pager alerts</li>
<li>graphs</li>
<li>human actions that were taken (&ldquo;right before this message, we restarted the load balancer&hellip;&rdquo;)</li>
<li>my interpretation of various messages (&ldquo;I think this was caused by&hellip;&rdquo;)</li>
</ul>

<h3 id="reformat-them-into-a-table">reformat them into a table</h3>

<p>Sometimes I&rsquo;ll reformat the log lines to just print out the information I&rsquo;m
interested in, to make it easier to scan. I&rsquo;ve done this on the command line
with a simple <code>awk</code> commmand:</p>

<pre><code>cat ... | awk '{print $5 - $8}'
</code></pre>

<p>but also with fancy log analysis tools (like Splunk) that let you make a table on the web</p>

<h3 id="check-that-a-suspicious-error-is-actually-new">check that a &ldquo;suspicious&rdquo; error is actually new</h3>

<p>Sometimes I&rsquo;ll notice a suspicious error in the logs and think &ldquo;OH THERE&rsquo;S THE
CULPRIT!!!&ldquo;. But when I search for that message to make sure that it&rsquo;s actually
new, I&rsquo;ll find out that this error actually happens constantly during normal
operation, and that it&rsquo;s completely unrelated to the (new) situation that I&rsquo;m
dealing with.</p>

<h3 id="use-the-logs-to-make-a-graph">use the logs to make a graph</h3>

<p>Some log analysis tools will let you turn your log lines into a graph to detect
patterns.</p>

<p>You can also make a quick histogram with <code>grep</code> and <code>sort</code>. For example  I&rsquo;ve
often done something like:</p>

<pre><code>grep -o (some regex) | sort | uniq -c | sort -n
</code></pre>

<p>to count how many of each line matching my regular expression there are</p>

<h3 id="filter-out-irrelevant-lines">filter out irrelevant lines</h3>

<p>You can remove irrelevant lines with <code>grep</code> like this:</p>

<pre><code>cat file | grep -v THING1 | grep -v THING2 | grep -v THING3 | grep -v THING4
</code></pre>

<p><small>
for the reply guys: yes, we all know you don&rsquo;t need to use <code>cat</code> here :)
</small></p>

<p>Or if your log system has some kind of query language, you can search for <code>NOT THING1 AND NOT THING2 ...</code></p>

<h3 id="find-the-first-error">find the first error</h3>

<p>Often an error causes a huge cascade of related errors. Digging into the
later errors can waste a lot of your time &ndash; you need to start by finding the
<strong>first</strong> thing that triggered the error. Often you don&rsquo;t need to understand
the exact deals of why the 15th thing in the error cascade failed, you can just
fix the original problem and move on.</p>

<h3 id="scroll-through-the-log-really-fast">scroll through the log really fast</h3>

<p>If you already have an intuition for what log lines for this service <em>should</em>
normally look like, sometimes scrolling through them really fast will reveal
something that looks off.</p>

<h3 id="turn-the-log-level-up-or-down">turn the log level up (or down)</h3>

<p>Sometimes turning up the log level will give you a key error message that
explains everything.</p>

<p>But other times, you&rsquo;ll get overwhelmed by a million irrelevant messages
because the log level is set to <code>INFO</code>, and you need to turn the log level down.</p>

<h3 id="put-it-in-a-spreadsheet-database">put it in a spreadsheet/database</h3>

<p>I&rsquo;ve never tried this myself, but a couple of people suggested copying parts of
the logs into a spreadsheet (with the timestamp in a different column) to make
it easier to filter / sort.</p>

<p>You could also put the data into SQLite or something (maybe with <a href="https://sqlite-utils.datasette.io/en/stable/">sqlite-utils</a>?) if you want to
be able to run SQL queries on your logs.</p>

<h3 id="on-generating-good-logs">on generating good logs</h3>

<p>A bunch of people also had thoughts on how to <strong>output</strong> easier-to-analyze
logs. This is a bigger topic than a few bullet points but here are a few quick
things:</p>

<ul>
<li>use a standard schema/format to make them easier to parse</li>
<li>include a transaction ID/request ID, to make it easier to filter for all lines related to a single transaction/request</li>
<li>include relevant information. For example,  &ldquo;ERROR: Invalid msg size&rdquo; is less helpful than &ldquo;ERROR: Invalid msg size. Msg-id 234, expected size 54, received size 0&rdquo;.</li>
<li>avoid logging personally identifiable information</li>
<li>use a logging framework instead of using <code>print</code> statements (this helps you have things like log levels and a standard structure)</li>
</ul>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>Let me know on Twitter/Mastodon if there&rsquo;s anything I missed! I might edit this to add a
couple more things.</p>

  </body>
</html>
