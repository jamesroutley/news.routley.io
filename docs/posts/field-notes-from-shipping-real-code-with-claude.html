<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude">Original</a>
    <h1>Field Notes from Shipping Real Code with Claude</h1>
    
    <div id="readability-page-1" class="page"><div>
      <article>
        <a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude"><time datetime="June 7, 2025">June 7, 2025</time></a>
        
        

<h2 id="vibe-coding-isnt-just-a-vibe">Vibe Coding Isn‚Äôt Just a Vibe</h2>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/8da4f924-0f2a-44c4-91f6-d285ace5e8a4.jpg" alt="Shimmering Substance - Jackson Pollock" width="2412" height="3000" data-action="zoom"/><span>Shimmering Substance - Jackson Pollock</span></p>
<blockquote>
<p>You can read the <a href="https://chatgpt.com/share/6844eaae-07d0-8001-a7f7-e532d63bf8a3">conversation I had with ChatGPT</a> while preparing drafts of this post.</p>
<p>Comments and discussion on the <a href="https://news.ycombinator.com/item?id=44211417">related HN post</a>.</p>
</blockquote>
<p>Think of this post as your field guide to a new way of building software. By the time you finish reading, you‚Äôll understand not just the how but the why behind AI-assisted development that actually works.</p>
<h3 id="heres-what-youre-going-to-learn">Here‚Äôs What You‚Äôre Going to Learn</h3>
<p>First, we‚Äôll explore how to genuinely achieve that mythical 10x productivity boost‚Äînot through magic, but through deliberate practices that amplify AI‚Äôs strengths while compensating for its weaknesses. You‚Äôll discover why some developers ship features in hours while others fight their AI tools for days.</p>
<p>Next, I‚Äôll walk you through the exact infrastructure we use at Julep to ship production code daily with Claude‚Äôs help. This isn‚Äôt theoretical‚Äîit‚Äôs battle-tested on a codebase serving real users with real money on the line. You‚Äôll see our <code>CLAUDE.md</code> templates, our commit strategies, and the guardrails that keep us from shipping disasters.</p>
<p>Most importantly, you‚Äôll understand why writing your own tests remains absolutely sacred, even (especially) in the age of AI. This single principle will save you from the midnight debugging sessions that plague developers who hand over too much control to their AI assistants.</p>
<p>We‚Äôll explore the three distinct modes of AI-assisted development, each with its own rhythms and rules. Like a musician learning when to play forte versus pianissimo, you‚Äôll develop an intuition for when to let AI lead versus when to take firm control.</p>
<blockquote>
<p><strong>But here‚Äôs the real insight:</strong> Good development practices aren‚Äôt just nice-to-haves anymore‚Äîthey‚Äôre the difference between AI that amplifies your capabilities and AI that amplifies your chaos. The research bears this out dramatically. <a href="#footnote-18WB" id="ref-18WB" role="doc-noteref"><sup>1</sup></a>Teams using rigorous practices deploy 46 times more frequently and are 440 times faster from commit to deployment. When you add AI to disciplined practices, these numbers don‚Äôt just add‚Äîthey multiply.</p>
</blockquote>
<h2 id="why-this-post-exists-from-meme-to-method">Why This Post Exists: From Meme to Method</h2>
<p>Let me take you back to when this all started. <a href="#footnote-28WB" id="ref-28WB" role="doc-noteref"><sup>2</sup></a><em>Andrej Karpathy</em> <a href="#footnote-38WB" id="ref-38WB" role="doc-noteref"><sup>3</sup></a>tweeted about ‚Äúvibe-coding‚Äù‚Äîthis idea of letting AI write your code while you just vibe. The developer community had a good laugh. It sounded like the ultimate developer fantasy: kick back, sip coffee, let the machines do the work.</p>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/e482b99a-9e1e-4f5b-b968-0bf6255566d2.png" alt="The birth of ‚Äúvibe coding‚Äù" width="716" height="553" data-action="zoom"/><span>The birth of ‚Äúvibe coding‚Äù</span></p>
<p>Then <em>Anthropic</em> <a href="https://www.anthropic.com/news/claude-3-7-sonnet">released Sonnet 3.7 and Claude Code</a>, and something unexpected happened. The joke stopped being funny because it started being‚Ä¶ possible? Of course, our trusty friend <a href="https://www.cursor.com/">Cursor</a> had been around awhile but this new interface finally felt like <em>true vibe coding</em>.</p>
<p>At <a href="https://git.new/julep">Julep</a>, we build AI workflow orchestration. Our backend has years of accumulated decisions, patterns, and occasional technical debt. We have taken the utmost care to keep code quality high, and ample documentation for ourselves. However, the sheer size, and historical context of <em>why</em> different parts of the code are organized the way they are takes weeks for a good engineer to grok. Without proper guardrails when using Claude, you‚Äôre basically playing whack-a-mole with an overeager intern.</p>
<blockquote>
<p>This post shares what actually works. These are patterns forged in the fire of actual deploys, 3 AM debugging sessions, and the unforgiving reality of users who expect their workflows to actually work.</p>
</blockquote>
<h2 id="understanding-vibe-coding">Understanding Vibe-Coding</h2>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/e771b36e-bdb6-4c99-8949-0a3583bc6259.png" alt="‚Äòpls fix‚Äô" width="716" height="658" data-action="zoom"/><span>‚Äòpls fix‚Äô</span></p>
<p><a href="#footnote-48WB" id="ref-48WB" role="doc-noteref"><sup>4</sup></a><em>Steve Yegge</em> brilliantly coined the term <em>CHOP</em>‚ÄîChat-Oriented Programming in a slightly-dramatic-titled post <a href="https://sourcegraph.com/blog/the-death-of-the-junior-developer">‚ÄúThe death of the junior developer‚Äù</a>. It‚Äôs a perfect description of the surface mechanics: you chat with an AI until code materializes.</p>
<p>Think of traditional coding like sculpting marble. You start with a blank block and carefully chisel away, line by line, function by function. Every stroke is deliberate, every decision yours. It‚Äôs satisfying but slow.</p>
<p>Vibe-coding is more like conducting an orchestra. You‚Äôre not playing every instrument‚Äîyou‚Äôre directing, shaping, guiding. The AI provides the raw musical talent, but without your vision, it‚Äôs just noise. With your direction, it becomes a symphony.</p>
<p>There are three distinct postures you can take when vibe-coding, each suited to different moments in the development cycle:</p>
<ol type="1">
<li><p><strong>AI as First-Drafter</strong>: Here, AI generates initial implementations while you focus on architecture and design. It‚Äôs like having a junior developer who can type at the speed of thought but needs constant guidance. Perfect for boilerplate, CRUD operations, and standard patterns.</p></li>
<li><p><strong>AI as Pair-Programmer</strong>: This is the sweet spot for most development. You‚Äôre actively collaborating, bouncing ideas back and forth. The AI suggests approaches, you refine them. You sketch the outline, AI fills in details. It‚Äôs like pair programming with someone who has read every programming book ever written but has never actually shipped code.</p></li>
<li><p><strong>AI as Validator</strong>: Sometimes you write code and want a sanity check. AI reviews for bugs, suggests improvements, spots patterns you might have missed. Think of it as an incredibly well-read code reviewer who never gets tired or cranky.</p></li>
</ol>
<blockquote>
<p>The crucial insight is this: you shift from being a writer to being an editor. Instead of crafting every line, you‚Äôre reviewing, refining, directing. But‚Äîand this cannot be overstated‚Äîyou remain the architect. Claude is your intern with encyclopedic knowledge but zero context about your specific system, your users, your business logic.</p>
</blockquote>
<h2 id="the-three-modes-of-vibe-coding-a-practical-framework">The Three Modes of Vibe-Coding: A Practical Framework</h2>
<p>After months of experimentation and more than a few production incidents, I‚Äôve settled on three distinct modes of operation. Each has its own rhythm, its own guardrails, and its own optimal use cases.</p>
<h3 id="mode-1-the-playground">Mode 1: <em>The Playground</em></h3>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/ede9227b-cd8d-4505-ba93-21c9c7fcb31a.png" alt="Lighter Fluid" width="658" height="268" data-action="zoom"/><span>Lighter Fluid</span></p>
<p><strong>When to use it</strong>: Weekend hacks, personal scripts, proof-of-concepts, and those ‚ÄúI wonder if‚Ä¶‚Äù moments that make programming fun.</p>
<p>In <em>Playground Mode</em>, you embrace the chaos. There‚Äôs zero ceremony, no extensive documentation, no careful guardrails. Claude writes 80-90% of the code while you provide just enough steering to keep things on track. It‚Äôs liberating and slightly terrifying.</p>
<p>Here‚Äôs what Playground Mode looks like in practice: You have an idea for a script to analyze your Spotify listening history. You open Claude, describe what you want in plain English, and watch as it generates a complete solution. No <code>CLAUDE.md</code> file, no careful prompting‚Äîjust raw, unfiltered AI assistance.</p>
<p>The beauty of Playground Mode is its speed. You can go from idea to working prototype in minutes. The danger is that this cowboy coding style is absolutely inappropriate for anything that matters. Use it for experiments, never for production. Trust me, while the amazing folks preaching otherwise, good engineering principles still matter, <a href="https://www.ikangai.com/vibe-coding-in-software-engineering/">now more than ever</a>.</p>
<h3 id="mode-2-pair-programming">Mode 2: <em>Pair Programming</em></h3>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/d84d1867-c2b4-4ef9-8904-b7c69cf12154.webp" alt="Compiling" width="413" height="360" data-action="zoom"/><span>Compiling</span></p>
<p><strong>When to use it</strong>: Projects under <em>~5,000 lines of code</em>, side projects with real users, demos (you don‚Äôt want to break), or well-scoped small services in larger systems.</p>
<p>This is where vibe-coding starts to shine for real work. You need structure, but not so much that it slows you down. The key innovation here is the <code>CLAUDE.md</code> file‚Äîcustom documentation that Claude automatically reads when invoked. From Anthropic‚Äôs <a href="https://www.anthropic.com/engineering/claude-code-best-practices">Best practices for Claude Code</a>:</p>
<blockquote>
<p>CLAUDE.md is a special file that Claude automatically pulls into context when starting a conversation. This makes it an ideal place for documenting:</p>
<ul>
<li>Common bash commands<br/>
</li>
<li>Core files and utility functions<br/>
</li>
<li>Code style guidelines<br/>
</li>
<li>Testing instructions<br/>
</li>
<li>Repository etiquette (e.g., branch naming, merge vs.¬†rebase, etc.)<br/>
</li>
<li>Developer environment setup (e.g., pyenv use, which compilers work)<br/>
</li>
<li>Any unexpected behaviors or warnings particular to the project<br/>
</li>
<li>Other information you want Claude to remember</li>
</ul>
</blockquote>
<p>Instead of repeatedly explaining your project‚Äôs conventions, you document them once. Here‚Äôs a real example from a recent side project:</p>
<pre><code><span>## Project: Analytics Dashboard  </span>

This is a Next.js dashboard for visualizing user analytics. We follow  
these conventions to maintain consistency:  

<span>### Architecture Decisions  </span>
<span>-</span> Server Components by default, Client Components only when necessary  
<span>-</span> tRPC for type-safe API calls  
<span>-</span> Prisma for database access with explicit select statements  
<span>-</span> Tailwind for styling (no custom CSS files)  

<span>### Code Style  </span>
<span>-</span> Formatting: Prettier with 100-char lines  
<span>-</span> Imports: sorted with simple-import-sort  
<span>-</span> Components: Pascal case, co-located with their tests  
<span>-</span> Hooks: always prefix with &#39;use&#39;  

<span>### Patterns to Follow  </span>
<span>-</span> Data fetching happens in Server Components  
<span>-</span> Client Components receive data as props  
<span>-</span> Use Zod schemas for all external data  
<span>-</span> Error boundaries around every data display component  

<span>### What NOT to Do  </span>
<span>-</span> Don&#39;t use useEffect for data fetching  
<span>-</span> Don&#39;t create global state without explicit approval  
<span>-</span> Don&#39;t bypass TypeScript with &#39;any&#39; types  </code></pre>
<p>With this context, Claude becomes remarkably effective. It‚Äôs like the difference between explaining your project to a new hire every single day versus having them read the onboarding docs once.</p>
<p>But <em>Pair Programming Mode</em> requires more than just documentation. You need to actively guide the AI with what I call ‚Äúanchor comments‚Äù‚Äîbreadcrumbs that prevent Claude from wandering into the wilderness:</p>
<pre><code>



<span>export</span> <span><span>function</span> <span>DataTable</span>(<span>{ items }: DataTableProps</span>) </span>{  
  
  ...  
}  </code></pre>
<p>These comments serve a dual purpose: they guide the AI and document your code for humans. It‚Äôs documentation that pays dividends in both directions. The <strong>key distinction</strong> between such ‚Äúanchor comments‚Äù and regular comments: these are <em>written</em>, <em>maintained</em>, and <em>meant to be used</em> by Claude itself. Here‚Äôs an <em>actual snippet</em> from our <a href="https://github.com/julep-ai/julep/blob/dev/AGENTS.md">project‚Äôs CLAUDE.md</a>:</p>
<pre><code><span>## Anchor comments  </span>

Add specially formatted comments throughout the codebase, where appropriate, for yourself as inline knowledge that can be easily <span>`grep`</span>ped for.  

<span>### Guidelines:  </span>

<span>-</span> Use <span>`AIDEV-NOTE:`</span>, <span>`AIDEV-TODO:`</span>, or <span>`AIDEV-QUESTION:`</span> (all-caps prefix) for comments aimed at AI and developers.  
<span>-</span> Keep them concise (‚â§ 120 chars).  
<span>-</span> <span>**Important:**</span> Before scanning files, always first try to <span>**locate existing anchors**</span> <span>`AIDEV-*`</span> in relevant subdirectories.  
<span>-</span> <span>**Update relevant anchors**</span> when modifying associated code.  
<span>-</span> <span>**Do not remove `AIDEV-NOTE`s**</span> without explicit human instruction.  

Example:  
<span># AIDEV-NOTE: perf-hot-path; avoid extra allocations (see ADR-24)  </span>
async def render<span>_feed(...):  
    ...  </span></code></pre>
<h3 id="mode-3-productionmonorepo-scale">Mode 3: <em>Production/Monorepo Scale</em></h3>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/97c55ab9-c876-4018-841f-ee014757e908.webp" alt="RTFM" width="350" height="434" data-action="zoom"/><span>RTFM</span></p>
<p><strong>When to use it</strong>: Large codebases, systems with real users, anything where bugs cost money or reputation.</p>
<p>Claude can generate tremendous amounts of code, but integrating it into a complex system requires careful orchestration.</p>
<p>Let me start with a big caveat: <strong>vibe coding at this scale does NOT scale very well,</strong> yet. I definitely do see these systems getting significantly better at handling larger codebases <em>but</em>, for them to be effective, significant effort is needed to help them navigate, understand, and <em>safely</em> hack on them without getting lost in a maze. Generally speaking, it‚Äôs better to section them into individual services, and <a href="#footnote-58WB" id="ref-58WB" role="doc-noteref"><sup>5</sup></a>sub modules when possible.</p>
<p>As a universal principle, good engineering practices apply to large-scale projects, vibe coded or not. For example, at production scale, boundaries become critical. Every integration point needs explicit documentation:</p>
<pre><code>



<span>@router.get(<span><span>&#34;/users/{user_id}/feed&#34;</span></span>)  </span>
<span>async</span> <span><span>def</span> <span>get_user_feed</span>(<span>user_id: UUID</span>) -&gt; FeedResponse:</span>  
    
    
    ...  </code></pre>
<p>Without these boundaries, Claude will happily ‚Äúimprove‚Äù your API and break every client in production. Bottom line: larger projects should <em>definitely</em> start adopting vibe coding in parts, and adopt methodologies that enhance that experience but, don‚Äôt expect to land large features reliably just yet. (as of <em>June 7, 2025 / AI epoch</em>)</p>
<h2 id="infrastructure-the-foundation-of-sustainable-ai-development">Infrastructure: The Foundation of Sustainable AI Development</h2>
<h3 id="claude.md-your-single-source-of-truth"><code>CLAUDE.md</code>: Your Single Source of Truth</h3>
<p>Let me be absolutely clear about this: <code>CLAUDE.md</code> is not optional documentation. Every minute you spend updating it saves an hour of cleanup later.</p>
<p>Think of <code>CLAUDE.md</code> as a constitution for your codebase. It establishes the fundamental laws that govern how code should be written, how systems interact, and what patterns to follow or avoid. Organizations that invest in developing the skills and capabilities of their teams get better outcomes‚Äîand your <code>CLAUDE.md</code> is that investment crystallized into documentation.</p>
<p>Here‚Äôs an abridged version of <a href="https://github.com/julep-ai/julep/blob/dev/AGENTS.md">our production <code>CLAUDE.md</code></a> structure, refined over thousands of AI-assisted commits:</p>
<pre><code><span># CLAUDE.md - Julep Backend Service  </span>

<span>## The Golden Rule  </span>
When unsure about implementation details, ALWAYS ask the developer.  

<span>## Project Context  </span>
Julep enables developers to build stateful AI agents using declarative  
workflows.  

<span>## Critical Architecture Decisions  </span>

<span>### Why Temporal?  </span>
We use Temporal for workflow orchestration because:  
<span>1.</span> Workflows can run for days/weeks with perfect reliability  
<span>2.</span> Automatic recovery from any failure point  

<span>### Why PostgreSQL + pgvector?  </span>
<span>1.</span> ACID compliance for workflow state (can&#39;t lose user data)  
<span>2.</span> Vector similarity search for agent memory  

<span>### Why TypeSpec?  </span>
Single source of truth for API definitions:  
<span>-</span> OpenAPI specs  
<span>-</span> TypeScript/Python clients  
<span>-</span> Validation schemas  

<span>## Code Style and Patterns  </span>

<span>### Anchor comments  </span>

Add specially formatted comments throughout the codebase, where appropriate, for yourself as inline knowledge that can be easily <span>`grep`</span>ped for.  

<span>### Guidelines:  </span>

<span>-</span> Use <span>`AIDEV-NOTE:`</span>, <span>`AIDEV-TODO:`</span>, or <span>`AIDEV-QUESTION:`</span> (all-caps prefix) for comments aimed at AI and developers.  
<span>-</span> <span>**Important:**</span> Before scanning files, always first try to <span>**grep for existing anchors**</span> <span>`AIDEV-*`</span> in relevant subdirectories.  
<span>-</span> <span>**Update relevant anchors**</span> when modifying associated code.  
<span>-</span> <span>**Do not remove `AIDEV-NOTE`s**</span> without explicit human instruction.  
<span>-</span> Make sure to add relevant anchor comments, whenever a file or piece of code is:  
<span>  *</span> too complex, or  
<span>  *</span> very important, or  
<span>  *</span> confusing, or  
<span>  *</span> could have a bug  

<span>## Domain Glossary (Claude, learn these!)  </span>

<span>-</span> <span>**Agent**</span>: AI entity with memory, tools, and defined behavior  
<span>-</span> <span>**Task**</span>: Workflow definition composed of steps (NOT a Celery task)  
<span>-</span> <span>**Execution**</span>: Running instance of a task  
<span>-</span> <span>**Tool**</span>: Function an agent can call (browser, API, etc.)  
<span>-</span> <span>**Session**</span>: Conversation context with memory  
<span>-</span> <span>**Entry**</span>: Single interaction within a session  

<span>## What AI Must NEVER Do  </span>

<span>1.</span> <span>**Never modify test files**</span> - Tests encode human intent  
<span>2.</span> <span>**Never change API contracts**</span> - Breaks real applications  
<span>3.</span> <span>**Never alter migration files**</span> - Data loss risk  
<span>4.</span> <span>**Never commit secrets**</span> - Use environment variables  
<span>5.</span> <span>**Never assume business logic**</span> - Always ask  
<span>6.</span> <span>**Never remove AIDEV- comments**</span> - They&#39;re there for a reason  

Remember: We optimize for maintainability over cleverness.  
When in doubt, choose the boring solution.  </code></pre>
<p>This document becomes the shared context between you and Claude. It‚Äôs like having a senior developer whispering guidance in Claude‚Äôs ear throughout the coding session.</p>

<p>As your codebase grows, CLAUDE.md alone isn‚Äôt enough. You need inline guidance‚Äîwhat I call anchor comments. These serve as local context that prevents AI from making locally bad decisions.</p>
<p>Think of your codebase as a city and anchor comments as street signs. Without them, even smart visitors get lost. Here‚Äôs how we use them effectively:</p>
<pre><code>

<span><span>def</span> <span>get_user_feed</span>(<span>user_id: UUID, cached_data: FeedCache</span>) -&gt; List[FeedItem]:</span>  
    
    items = cached_data.items[:]  

    
    

    
    
    filtered = [item <span>for</span> item <span>in</span> items <span>if</span> user_has_access(user_id, item)]  

    <span>return</span> filtered  </code></pre>
<p>These comments create a narrative that helps both AI and humans understand not just what the code does, but why it does it that way.</p>
<h3 id="git-workflows-for-ai-development">Git Workflows for AI Development</h3>
<p>One of the most underappreciated aspects of AI-assisted development is how it changes your git workflow. You‚Äôre now generating code at a pace that can quickly pollute your git history if you‚Äôre not careful.</p>
<p>It really only applies to very large codebases because it is <em>not</em> a very straightforward tool, but I recommend using <a href="https://www.anthropic.com/engineering/claude-code-best-practices#c-use-git-worktrees">git worktrees</a> to create isolated environments for AI experiments:</p>
<pre><code>
git worktree add ../ai-experiments/cool-feature -b ai/cool-feature  


<span>cd</span> ../ai-experiments/cool-feature  



<span>cd</span> ../main-repo  
git cherry-pick abc123  


git worktree remove ../ai-experiments/cool-feature  </code></pre>
<blockquote>
<p><strong>Pro tip</strong>: Read about <a href="https://dev.to/yankee/practical-guide-to-git-worktree-58o0">how to use worktrees</a>, and check out the nifty <a href="https://github.com/taecontrol/wt"><code>wt</code></a> tool.</p>
</blockquote>
<p>This approach gives you the best of both worlds: Claude can experiment freely while your main branch history stays clean and meaningful.</p>
<p>For commit messages, we‚Äôve standardized on tagging AI-assisted commits:</p>
<pre><code>feat: implement user feed caching [AI]  

- Add Redis-based cache for user feeds  
- Implement cache warming on user login  
- Add metrics for cache hit rate  

AI-assisted: core logic generated, tests human-written  </code></pre>
<p>This transparency helps during code review‚Äîreviewers know to pay extra attention to AI-generated code.</p>
<h2 id="the-sacred-rule-humans-write-tests">The Sacred Rule: Humans Write Tests</h2>
<p>Now we come to the most important principle in AI-assisted development. It‚Äôs so important that I‚Äôm going to repeat it in multiple ways until it‚Äôs burned into your memory:</p>
<p><strong>Never. Let. AI. Write. Your. Tests.</strong></p>
<p>Tests are not just code that verifies other code works. Tests are executable specifications. They encode your actual intentions, your edge cases, your understanding of the problem domain. High performers excel at both speed and stability‚Äîthere‚Äôs no trade-off. Tests are how you achieve both.</p>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/5dd77e55-5b53-412a-a169-e61d88eff60a.png" alt="Beware‚Ä¶" width="625" height="625" data-action="zoom"/><span>Beware‚Ä¶</span></p>
<p>Let me illustrate why this matters with an example. Let‚Äôs say we asked Claude to implement a rate limiter:</p>
<pre><code><span><span>class</span> <span>RateLimiter</span>:</span>  
    <span><span>def</span> <span>__init__</span>(<span>self, max_requests: <span>int</span>, window_seconds: <span>int</span></span>):</span>  
        self.max_requests = max_requests  
        self.window_seconds = window_seconds  
        self.requests = defaultdict(<span>list</span>)  

    <span><span>def</span> <span>is_allowed</span>(<span>self, user_id: <span>str</span></span>) -&gt; bool:</span>  
        now = time.time()  
        user_requests = self.requests[user_id]  

        
        self.requests[user_id] = [  
            req_time <span>for</span> req_time <span>in</span> user_requests  
            <span>if</span> now - req_time &lt; self.window_seconds  
        ]  

        <span>if</span> <span>len</span>(self.requests[user_id]) &lt; self.max_requests:  
            self.requests[user_id].append(now)  
            <span>return</span> <span>True</span>  
        <span>return</span> <span>False</span>  </code></pre>
<p>Looks reasonable, right? Claude even helpfully generated tests:</p>
<pre><code><span><span>def</span> <span>test_rate_limiter</span>():</span>  
    limiter = RateLimiter(max_requests=<span>3</span>, window_seconds=<span>60</span>)  

    <span>assert</span> limiter.is_allowed(<span>&#34;user1&#34;</span>) == <span>True</span>  
    <span>assert</span> limiter.is_allowed(<span>&#34;user1&#34;</span>) == <span>True</span>  
    <span>assert</span> limiter.is_allowed(<span>&#34;user1&#34;</span>) == <span>True</span>  
    <span>assert</span> limiter.is_allowed(<span>&#34;user1&#34;</span>) == <span>False</span>  </code></pre>
<p>But here‚Äôs what Claude‚Äôs tests missed‚Äîwhat only a human who understands the business requirements would test: Claude‚Äôs implementation has a memory leak. Users who hit the API once and never return leave their data in memory forever. The AI-generated tests check the happy path but miss this critical production concern.</p>
<p><img src="https://cdn.blot.im/blog_b4f0291594b44dc8a105111fe0e6e166/_image_cache/a4c32be3-f91c-44e3-aebd-c65f50fbd379.png" alt="Vibe coding at its best" width="400" height="144" data-action="zoom"/><span>Vibe coding at its best</span></p>
<p>This is why humans write tests. We understand the context, the production environment, the edge cases that matter. At Julep, our rule is absolute:</p>
<pre><code><span>## Testing Discipline  </span>

| What | AI CAN Do | AI MUST NOT Do |  
|------|-----------|----------------|  
| Implementation | Generate business logic | Touch test files |  
| Test Planning | Suggest test scenarios | Write test code |  
| Debugging | Analyze test failures | Modify test expectations |  

If an AI tool touches a test file, the PR gets rejected. No exceptions.  </code></pre>
<p>Your tests are your specification. They‚Äôre your safety net. They‚Äôre the encoded wisdom of every bug you‚Äôve fixed and every edge case you‚Äôve discovered. Guard them zealously.</p>
<h2 id="scaling-without-drowning-token-economics-and-context-management">Scaling Without Drowning: Token Economics and Context Management</h2>
<p>One of the most counterintuitive lessons in AI-assisted development is that being stingy with context to save tokens actually costs you more. It‚Äôs like trying to save money on gas by only filling your tank halfway‚Äîyou just end up making more trips to the gas station.</p>
<p>Token budgets matter. Provide focused prompts, reduce diff length, and avoid large-file bloat by summarizing intent in advance. But ‚Äúfocused‚Äù doesn‚Äôt mean ‚Äúminimal‚Äù‚Äîit means ‚Äúrelevant and complete.‚Äù</p>
<p>Let me show you the false economy of starved prompts:</p>
<p><strong>Starved Prompt Attempt:</strong></p>
<pre><code>&#34;Add caching to the user endpoint&#34;  </code></pre>
<p><strong>Claude‚Äôs Response:</strong> Implements caching‚Ä¶ but:</p>
<ul>
<li>Uses in-memory cache (won‚Äôt work with multiple servers)<br/>
</li>
<li>No cache invalidation strategy<br/>
</li>
<li>No metrics or monitoring<br/>
</li>
<li>No consideration of cache stampede</li>
</ul>
<p><strong>Result:</strong> 3 more rounds of fixes, <em>4x the tokens spent</em>.</p>
<p><strong>Proper Context-Rich Prompt:</strong></p>
<pre><code>Add Redis caching to the GET /users/{id} endpoint.  

Context:  
- This endpoint serves 50k requests/minute  
- We run 12 API servers behind a load balancer  
- User data changes infrequently (few times per day)  
- We already have Redis at cache.redis.internal:6379  
- Use our standard cache key pattern: &#34;user:v1:{id}&#34;  
- Include cache hit/miss metrics (we use Prometheus)  
- Implement cache-aside pattern with 1 hour TTL  
- Handle cache stampede with probabilistic early expiration  

See our caching guide: docs/patterns/caching.md  </code></pre>
<p>The lesson? Front-load context to avoid iteration cycles. Think of tokens like investing in good tools‚Äîthe upfront cost pays for itself many times over.</p>
<p>In fact, I recommend that all projects should routinely ask Claude to look through the codebase changes, and add context to <code>CLAUDE.md</code></p>
<h3 id="fresh-sessions-and-mental-models">Fresh Sessions and Mental Models</h3>
<p>Here‚Äôs another counterintuitive practice: use fresh Claude sessions for distinct tasks. It‚Äôs tempting to keep one long-running conversation, but this leads to context pollution.</p>
<p>Think of it like this: you wouldn‚Äôt use the same cutting board for vegetables after cutting raw chicken. Similarly, don‚Äôt use the same Claude session for database migrations after discussing frontend styling. The context bleeds through in subtle ways.</p>
<p>Our rule: One task, one session. When the task is done, start fresh. This keeps Claude‚Äôs ‚Äúmental model‚Äù clean and focused.</p>
<h2 id="case-study-shipping-structured-errors-in-production">Case Study: Shipping Structured Errors in Production</h2>
<p>Let me walk you through a real refactoring we did at Julep that showcases production-scale vibe-coding. We needed to replace our ad-hoc error handling with a structured error hierarchy across 500+ endpoints.</p>
<p><strong>The Human Decisions (The Why):</strong></p>
<p>First, we had to decide on our error taxonomy. This is pure architectural work‚ÄîClaude can‚Äôt make these decisions because they involve understanding our business, our users, and our operational needs:</p>
<pre><code># SPEC.md - Error Hierarchy Design (Human-Written)  

## Error Philosophy  
- Client errors (4xx) must include actionable feedback  
- System errors (5xx) must include trace IDs for debugging  
- All errors must be JSON-serializable  
- Error codes must be stable (clients depend on them)  

## Hierarchy  
BaseError  
‚îú‚îÄ‚îÄ ClientError (4xx)  
‚îÇ   ‚îú‚îÄ‚îÄ ValidationError  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SchemaValidationError - Request doesn&#39;t match schema  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BusinessRuleError - Valid schema, invalid business logic  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RateLimitError - Too many requests  
‚îÇ   ‚îî‚îÄ‚îÄ AuthError  
‚îÇ       ‚îú‚îÄ‚îÄ AuthenticationError - Who are you?  
‚îÇ       ‚îî‚îÄ‚îÄ AuthorizationError - You can&#39;t do that  
‚îî‚îÄ‚îÄ SystemError (5xx)  
    ‚îú‚îÄ‚îÄ DatabaseError - Connection, timeout, deadlock  
    ‚îú‚îÄ‚îÄ ExternalServiceError - APIs, webhooks failing  
    ‚îî‚îÄ‚îÄ InfrastructureError - Disk full, OOM, etc.  

## Error Response Format  
{  
  &#34;error&#34;: {  
    &#34;code&#34;: &#34;VALIDATION_FAILED&#34;,     // Stable code for clients  
    &#34;message&#34;: &#34;Email already exists&#34;, // Human-readable  
    &#34;details&#34;: { ... },               // Structured data  
    &#34;trace_id&#34;: &#34;abc-123-def&#34;         // For debugging  
  }  
}  </code></pre>
<p><strong>The AI Execution (The How):</strong></p>
<p>With the specification clear, we unleashed Claude on the mechanical refactoring:</p>
<pre><code><span>### Prompt to Claude:  </span>

Refactor our error handling to match SPEC.md.  

Current state:  
<span>-</span> raise ValueError(&#34;Invalid email&#34;)  
<span>-</span> return {&#34;error&#34;: &#34;Something went wrong&#34;}, 500  

Target state:  
<span>-</span> Use error hierarchy from SPEC.md  
<span>-</span> Include proper error codes  
<span>-</span> Add trace<span>_id to all 5xx errors  

Start with the auth module. Show me the plan before implementing.  </span></code></pre>
<p>Claude‚Äôs plan was solid:</p>
<pre><code>1. Create error hierarchy in `common/errors.py`  
2. Create error response formatter  
3. Update each module systematically  
4. Add error handling middleware  </code></pre>
<p>Claude was able to handle the tedious work of finding and updating 500+ error sites, while we focused on reviewing:</p>
<pre><code>
<span>if</span> <span>not</span> user:  
    <span>raise</span> Exception(<span>&#34;User not found&#34;</span>)  


<span>if</span> <span>not</span> user:  
    <span>raise</span> AuthenticationError(  
        message=<span>&#34;User not found&#34;</span>,  
        code=<span>&#34;USER_NOT_FOUND&#34;</span>,  
        details={<span>&#34;identifier&#34;</span>: email}  
    )  </code></pre>
<blockquote>
<p>Combined with our carefully written <code>CLAUDE.md</code> file, meticulous docs, regularly updated anchor comments, and clear instructions, results:</p>
<ul>
<li>Time: 4 hours instead of 2 days<br/>
</li>
<li>Coverage: All 500+ error sites updated</li>
</ul>
</blockquote>
<h2 id="leadership-and-culture-in-the-ai-era">Leadership and Culture in the AI Era</h2>
<p>Your role as a senior engineer has fundamentally shifted. You‚Äôre no longer just writing code‚Äîyou‚Äôre curating knowledge, setting boundaries, and teaching both humans and AI systems how to work effectively.</p>
<p>Lean management and continuous delivery practices help improve software delivery performance, which in turn improves organizational performance‚Äîand this includes how you manage AI collaboration.</p>
<h3 id="the-new-onboarding-checklist">The New Onboarding Checklist</h3>
<p>When new developers join our team, they get two onboarding tracks: one for humans, one for working with AI. Here‚Äôs our combined checklist:</p>
<p><strong>Week 1: Foundation</strong></p>
<pre><code>‚ñ° Read team CLAUDE.md files (start with root, then service-specific)  
‚ñ° Set up development environment  
‚ñ° Make first PR (human-written, no AI)  </code></pre>
<p><strong>Week 2: Guided AI Collaboration</strong></p>
<pre><code>‚ñ° Set up Claude with team templates  
‚ñ° Complete &#34;toy problem&#34; with AI assistance  
‚ñ° Practice prompt patterns  
‚ñ° Create first AI-assisted PR (with supervision)  </code></pre>
<p><strong>Week 3: Independent Work</strong></p>
<pre><code>‚ñ° Ship first significant AI-assisted feature  
‚ñ° Write tests for another developer&#39;s AI output  
‚ñ° Lead one code review session  </code></pre>
<h3 id="building-a-culture-of-transparency">Building a Culture of Transparency</h3>
<p>One cultural shift that‚Äôs essential: normalize disclosure of AI assistance. We‚Äôre not trying to hide that we use AI‚Äîwe‚Äôre trying to use it responsibly. Every commit message that includes AI work gets tagged:</p>
<pre><code>











</code></pre>
<p>This transparency serves multiple purposes:</p>
<ol type="1">
<li>Reviewers know to pay extra attention<br/>
</li>
<li>Future debuggers understand the code‚Äôs provenance<br/>
</li>
<li>No one feels shame about using available tools</li>
</ol>
<p>Creating an environment where developers can leverage AI effectively, without fear or shame, is part of building that high-performing culture.</p>
<h2 id="things-claude-should-never-touch-carved-in-stone">Things Claude Should Never Touch (Carved in Stone)</h2>
<p>Let‚Äôs be crystal clear about boundaries. These aren‚Äôt suggestions‚Äîthey‚Äôre commandments. Violate them at your peril.</p>
<h3 id="the-sacred-list-of-never-touch">The Sacred List of Never-Touch</h3>
<p><strong>‚ùå Test Files</strong></p>
<pre><code>

<span><span>def</span> <span>test_critical_business_logic</span>():</span>  
    <span>&#34;&#34;&#34;This test encodes $10M worth of domain knowledge&#34;&#34;&#34;</span>  
    <span>pass</span>  </code></pre>
<p>Tests encode human understanding. They‚Äôre your safety net, your specification, your accumulated wisdom. When Claude writes tests, it‚Äôs just verifying that the code does what the code does‚Äînot what it should do.</p>
<p><strong>‚ùå Database Migrations</strong></p>
<pre><code>


<span>ALTER</span> <span>TABLE</span> <span>users</span> <span>ADD</span> <span>COLUMN</span> subscription_tier <span>VARCHAR</span>(<span>20</span>);  
<span>UPDATE</span> <span>users</span> <span>SET</span> subscription_tier = <span>&#39;free&#39;</span> <span>WHERE</span> subscription_tier <span>IS</span> <span>NULL</span>;  
<span>ALTER</span> <span>TABLE</span> <span>users</span> <span>ALTER</span> <span>COLUMN</span> subscription_tier <span>SET</span> <span>NOT</span> <span>NULL</span>;  </code></pre>
<p>Migrations are irreversible in production. They require understanding of data patterns, deployment timing, and rollback strategies that AI cannot grasp.</p>
<p><strong>‚ùå Security-Critical Code</strong></p>
<pre><code>

<span><span>def</span> <span>validate_token</span>(<span>token: <span>str</span></span>) -&gt; Optional[UserClaims]:</span>  
    
    
    </code></pre>
<p><strong>‚ùå API Contracts Without Versioning</strong></p>
<pre><code>


<span>paths:</span>  
  <span>/api/v1/users/{id}:</span>  
    <span>get:</span>  
      <span>responses:</span>  
        <span>200:</span>  
          <span>schema:</span>  
            <span>$ref:</span> <span>&#39;#/definitions/UserResponse&#39;</span>  </code></pre>
<p><strong>‚ùå Configuration and Secrets</strong></p>
<pre><code>
DATABASE_URL = os.environ[<span>&#34;DATABASE_URL&#34;</span>]  
STRIPE_SECRET_KEY = os.environ[<span>&#34;STRIPE_SECRET_KEY&#34;</span>]  
FEATURE_FLAGS = {  
    <span>&#34;new_pricing&#34;</span>: <span>False</span>,  
}  </code></pre>
<h3 id="the-hierarchy-of-ai-mistakes">The Hierarchy of AI Mistakes</h3>
<p>Not all AI mistakes are equal. Here‚Äôs how we categorize them:</p>
<p><strong>Level 1: Annoying but Harmless</strong></p>
<ul>
<li>Wrong formatting (your linter will catch it)<br/>
</li>
<li>Verbose code (refactor later)<br/>
</li>
<li>Suboptimal algorithms (profile will reveal)</li>
</ul>
<p><strong>Level 2: Expensive to Fix</strong></p>
<ul>
<li>Breaking internal APIs (requires coordination)<br/>
</li>
<li>Changing established patterns (confuses team)<br/>
</li>
<li>Adding unnecessary dependencies (bloat)</li>
</ul>
<p><strong>Level 3: Career-Limiting</strong></p>
<ul>
<li>Modifying tests to make them pass<br/>
</li>
<li>Breaking API contracts<br/>
</li>
<li>Leaking secrets or PII<br/>
</li>
<li>Corrupting data migrations</li>
</ul>
<p>Your guardrails should be proportional to the mistake level. Level 1 mistakes teach juniors. Level 3 mistakes teach you to update your LinkedIn.</p>
<h2 id="the-future-of-development-where-this-is-heading">The Future of Development: Where This Is Heading</h2>
<p>As I write this in 2025, we‚Äôre in the awkward adolescence of AI-assisted development. The tools are powerful but clumsy, like a teenager who just hit a growth spurt. But the trajectory is clear, and it‚Äôs accelerating.</p>
<p>Good documentation is foundational for successfully implementing DevOps capabilities. In the AI age, documentation isn‚Äôt just helpful‚Äîit‚Äôs the interface between human intent and AI capability. The teams that excel will be those who treat documentation as code, who maintain their CLAUDE.md files with the same rigor as their test suites.</p>
<p>What I see coming:</p>
<ul>
<li>AI that understands entire codebases, not just files<br/>
</li>
<li>Persistent memory across sessions and projects<br/>
</li>
<li>Proactive AI that suggests improvements without prompting<br/>
</li>
<li>AI that learns your team‚Äôs patterns and preferences</li>
</ul>
<p>But even as capabilities expand, the fundamentals remain: humans set direction, AI provides leverage. We‚Äôre tool users, and these are simply the most powerful tools we‚Äôve ever created.</p>
<h2 id="the-bottom-line-start-here-start-today">The Bottom Line: Start Here, Start Today</h2>
<p>If you‚Äôve made it this far, you‚Äôre probably feeling a mix of excitement and trepidation. That‚Äôs the right response. AI-assisted development is powerful, but it requires discipline and intentionality.</p>
<p>Here‚Äôs your action plan:</p>
<p><strong>Today:</strong></p>
<ol type="1">
<li>Create a CLAUDE.md for your current project<br/>
</li>
<li>Add three anchor comments <strong>yourself</strong> to your gnarliest code<br/>
</li>
<li>Try one AI-assisted feature with proper boundaries</li>
</ol>
<p><strong>This Week:</strong></p>
<ol type="1">
<li>Establish AI commit message conventions with your team<br/>
</li>
<li>Run an AI-assisted coding session with a junior developer<br/>
</li>
<li>Write tests for one piece of AI-generated code</li>
</ol>
<p><strong>This Month:</strong></p>
<ol type="1">
<li>Measure your deployment frequency before/after AI adoption<br/>
</li>
<li>Create a prompt pattern library for common tasks<br/>
</li>
<li>Run a team retrospective on AI-assisted development</li>
</ol>
<p>The most important thing? Start. Start small, start careful, but start. The developers who master this workflow aren‚Äôt necessarily smarter or more talented‚Äîthey‚Äôre just the ones who started earlier and learned from more mistakes.</p>
<p>Software delivery performance predicts organizational performance. In an industry where speed and quality determine success, AI assistance isn‚Äôt a nice-to-have‚Äîit‚Äôs a competitive necessity. But only if you do it right.</p>
<p>Vibe-coding, despite its playful name, is serious business. It‚Äôs a new way of thinking about software development that amplifies human capabilities rather than replacing them. Master it, and you‚Äôll ship better software faster than you ever thought possible. Ignore it, and you‚Äôll watch competitors lap you while you‚Äôre still typing boilerplate.</p>
<p>The tools are here. The patterns are proven. The only question is: will you be conducting the orchestra, or still playing every instrument yourself?</p>
<h3 id="ready-to-dive-in-resources-to-get-started">Ready to Dive In? Resources to Get Started:</h3>
<p>üìÑ <strong>Our Battle-Tested CLAUDE.md Template:</strong></p>
<p>ü§ù <strong>Questions? Find me on Twitter:</strong> <a href="https://twitter.com/diwanksingh">@diwanksingh</a></p>
<p>üí¨ <strong>Join the Discussion:</strong> Share your own patterns and learnings</p>
<p>üìö <strong>Recommended reading:</strong></p>
<ul>
<li>Peter Senge ‚Äì <em><a href="">The Fifth Discipline</a></em> (2010)<br/>
</li>
<li><em><a href="https://addyo.substack.com/p/future-proofing-your-software-engineering?utm_source=chatgpt.com">‚ÄúBeyond the 70 %: Maximising the Human 30 % of AI-Assisted Coding‚Äù</a></em> (Mar 13 2025) ‚Äì Addy Osmani<br/>
</li>
<li>Mark Richards &amp; Neal Ford ‚Äì <em><a href="https://books.google.com/books/about/Fundamentals_of_Software_Architecture.html">Fundamentals of Software Architecture</a></em>, 2nd ed.¬†(2025)<br/>
</li>
<li>Nicole Forsgren, Jez Humble, Gene Kim - <em><a href="https://itrevolution.com/product/accelerate/">Accelerate: The Science of Lean Software and DevOps</a></em></li>
</ul>
<p><strong>Remember</strong>: perfect is the enemy of shipped. Start with one small project, establish your boundaries, and iterate. The future of development is here‚Äîit‚Äôs just not evenly distributed yet.</p>
<blockquote>
<p>Be part of the distribution.</p>
</blockquote>

        
        <a href="https://diwank.space/tagged/vibe-engineering" rel="tag">Vibe Engineering</a>
        </article>
    </div></div>
  </body>
</html>
