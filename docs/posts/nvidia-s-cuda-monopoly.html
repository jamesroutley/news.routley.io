<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://matt-rickard.com/nvidias-cuda-monopoly">Original</a>
    <h1>Nvidia&#39;s CUDA Monopoly</h1>
    
    <div id="readability-page-1" class="page"><div id="__next"><div><div><p><span><div><article><div><p>CUDA (Compute Unified Device Architecture) is a closed-source low-level API that interfaces software with NVIDIA GPUs.</p><p>CUDA is a major moat for NVIDIA. It’s part of why NVIDIA GPUs command such a premium over other hardware (and are perpetually in short supply).</p><p>A few reasons why the monopoly exists:</p><ul><li><strong>Hardware/software synergy. </strong>NVIDIA has consistently shipped the fastest hardware) and software. It’s been difficult for other companies to build this flywheel (software companies don’t have the hardware capabilities, and vice versa). Open-source libraries are magnitudes slower.</li><li><strong>First mover. </strong>NVIDIA introduced CUDA in 2006. Both consumers and enterprises were locked in by designing their applications for CUDA.</li></ul><p>And how it could be disrupted in the future:</p><ul><li><strong>Alternative Open Standards / Abstraction Layer. </strong>OpenAI released <a href="https://openai.com/research/triton" rel="noopener noreferrer nofollow">Triton</a>, and PyTorch 2.0 utilizes Triton (via TorchInductor). Today they only act as a compilation layer over CUDA, but in the future, they might support other platforms (or bypass CUDA directly).</li><li><strong>Competing product. </strong>NVIDIA has managed to ship the best products over the last decade. But there’s still a chance that other big tech companies could build a compelling alternative. Cloud providers are building their own chips and have specific data on workloads as feedback for architecture and design.</li><li><strong>Specialized Hardware. </strong>Custom hardware accelerators, like Google’s TPU (Tensor Processing Unit), could become more popular than general-purpose GPUs.</li><li><strong>CPU-bound. </strong>While GPUs are ideal for AI because they excel at matrix multiplication (among other things), there’s potentially a future where small models can run “good enough” on CPUs.</li></ul></div></article></div><div><div><div><p>Daily posts on startups, engineering, and AI</p></div></div></div></span></p></div></div></div></div>
  </body>
</html>
