<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://invariantlabs.ai/blog/mcp-github-vulnerability">Original</a>
    <h1>GitHub MCP exploited: Accessing private repositories via MCP</h1>
    
    <div id="readability-page-1" class="page"><div>
  <p><img src="https://invariantlabs.ai/images/mcp-github.svg"/></p>
<p>Invariant has discovered a critical vulnerability affecting the widely-used <a href="https://github.com/github/github-mcp-server">GitHub MCP integration</a> (14k stars on GitHub). The vulnerability allows an attacker to hijack a user&#39;s agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories.</p>
<p>The issue is among the first, discovered by Invariant&#39;s automated security scanners for detecting so-called <em>Toxic Agent Flows</em>. In such a scenario, an agent is manipulated into performing unintended actions, such as leaking data or executing malicious code. For more information, <a href="#detecting-toxic-agent-flows">see below</a>.</p>
<p>It is highly relevant to raise awareness about this issue at this time, as the industry is racing to deploy coding agents and IDEs widely, potentially exposing users to similar attacks on critical software development tools.</p>
<h2>Contents</h2>
<ul>
<li><a href="#attack-setup">Attack Setup</a></li>
<li><a href="#attack-demonstration">Attack Demonstration</a></li>
<li><a href="#detecting-toxic-agent-flows">Detecting Toxic Agent Flows</a></li>
<li><a href="#mitigations">Mitigations</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="attack-setup">Attack Setup</h2>

<p>In this attack setup, the user is using an MCP client like Claude Desktop with the <a href="https://github.com/github/github-mcp-server">Github MCP server</a> connected to their account. </p>
<p>We assume the user has created two repositories:</p>
<ul>
<li><strong><code>&lt;user&gt;/public-repo</code></strong>: A publicly accessible repository, allowing everyone on GitHub to create issues and bug reports.</li>
<li><strong><code>&lt;user&gt;/private-repo</code></strong>: A private repository, e.g. with proprietary code or private company data.</li>
</ul>
<p>By standard GitHub rules, an attacker can now create a malicious issue on the public repository, containing a prompt injection waiting for the agent to interact.</p>
<p>The actual attack triggers as soon as the user and owner of the GitHub account queries their agent with a benign request, such as <em>Have a look at the open issues in <code>&lt;user&gt;/public-repo</code></em>, which will lead to the agent fetching the issues from the public repository and getting injected.</p>
<p>See below for an illustration of the ensuing flow.</p>
<p><img src="https://invariantlabs.ai/images/mcp-github-setup.svg"/></p>
<p>As shown here, as soon as the agent encounters the malicious GitHub issue, it can be coerced into pulling private repository data into context, and leaking it in an autonomously-created PR in the public repository, freely accessible to the attacker or anyone else.</p>
<p><strong>Toxic Flows</strong> We call this use of indirect prompt injection to trigger a malicious tool use sequence, a <em>toxic agent flow</em>. We have found this vulnerability by applying Invariant&#39;s security analyzer to GitHub MCP, allowing us to automate the process of discovering the flow in the wild.</p>
<h2 id="attack-demonstration">Attack Demonstration</h2>

<p>To illustrate more concretely, we implement this attack practically using a set of demo repositories:</p>
<ul>
<li><code>ukend0464/pacman</code>: A public repository with a simple implementation of a Pacman game (<a href="https://github.com/ukend0464/pacman">available here</a>)</li>
<li>Multiple private repositories containing personal projects and sensitive information about the user.</li>
</ul>
<p><strong>&#39;About The Author&#39; injection</strong> We now place a <a href="https://github.com/ukend0464/pacman/issues/1">malicious issue</a> in the public repository, which is accessible to the attacker. The issue contains a payload that will be executed by the agent as soon as it queries the public repository&#39;s list of issues.</p>
<p><img src="https://invariantlabs.ai/images/mcp-gh-issue.png" alt="A malicious GitHub issue injecting the agent"/></p>
<p><strong>User Interaction</strong> To trigger the attack, the user merely prompts <a href="https://www.anthropic.com/news/claude-4">Claude 4 Opus</a> with the following request:</p>
<p><img src="https://invariantlabs.ai/images/mcp-claude-prompt.png" alt="Claude prompt used to trigger the attack"/></p>
<p>Claude then uses the GitHub MCP integration to follow the instructions. Throughout this process, Claude Desktop by default requires the user to confirm individual tool calls. However, many users already opt for an “Always Allow” confirmation policy when using agents, and stop monitoring individual actions.</p>
<p><strong>Attack Rollout</strong> The agent now goes through the list of issues until it finds the attack payload. It willingly pulls private repository data into context, and leaks it into a <a href="https://github.com/ukend0464/pacman/pull/2">pull request</a> of the <code>pacman</code> repo, which is freely accessible to the attacker since it is public.</p>
<p>The pull request contains the following new information:</p>
<p><img src="https://invariantlabs.ai/images/mcp-gh-pr.png" alt="commit where the agent leaks private data"/></p>
<p>We thus successfully exfiltrated several pieces of <strong>private information</strong> about our user <code>ukend0464</code>: information about their private repositories, such as <code>Jupiter Star</code>, their plan to relocate to South America, and even their salary.</p>
<p>Below, we include a screenshot of the full chat with the agent, showing its reasoning and tool use sequence in action.</p>

<p><a href="https://explorer.invariantlabs.ai/trace/5f3f3f3c-edd3-4ba7-a35f-c1664d993a89" target="_blank">
<img src="https://invariantlabs.ai/images/full-chat.png" alt="Full chat with the agent, showing the attack in action"/>
<b>
    <img src="https://invariantlabs.ai/theme/images/logo.svg" alt="Invariant logo"/>See full agent trace in Invariant Explorer.
</b>
</a></p>
<h2 id="detecting-toxic-agent-flows">Detecting Toxic Agent Flows</h2>

<p>Unlike previously-discovered <a href="https://invariantlabs.ai/blog/blog/mcp-security-notification-tool-poisoning-attacks.html">tool poisoning attacks</a> with MCP, this vulnerability does not require the MCP tools themselves to be compromised. Instead, the issue emerges even with fully trusted tools, as agents can be exposed to untrusted information when connected to external platforms like GitHub.</p>
<p>Understanding, analyzing, and mitigating such issues in agentic systems is a highly complex undertaking that&#39;s difficult to perform manually and at scale. To address this challenge, Invariant has developed <strong>automated methods for detecting toxic agent flows</strong>, enabling organizations to identify and model potential threats before they can be exploited by malicious actors.</p>
<p>If you&#39;re interested in conducting a comprehensive threat analysis of your agent systems and tools, please contact us at <a href="https://invariantlabs.ai/cdn-cgi/l/email-protection#75101407190c141616100606351c1b0314071c141b01191417065b141c"><span data-cfemail="c8ada9baa4b1a9ababadbbbb88a1a6bea9baa1a9a6bca4a9aabbe6a9a1">[email protected]</span></a>. We&#39;ll be happy to onboard you to our early access security program. Below is a preview of our security analyzer in action.</p>
<figure>
    <img src="https://invariantlabs.ai/images/toxic-flows-preview.png" alt="Toxic flows preview"/>
    <figcaption>Preview: Invariant&#39;s security analyzer for proactively detecting toxic agent flows.</figcaption>
</figure>

<h2 id="mitigations">Scope and Mitigations</h2>

<p>While our experiments focused on Claude Desktop, the vulnerability is not specific to any particular agent or MCP client. It affects any agent that uses the GitHub MCP server, regardless of the underlying model or implementation.</p>
<p>Importantly, <strong>this is not a flaw in the GitHub MCP server code itself</strong>, but rather a fundamental architectural issue that must be addressed at the agent system level. This means that GitHub alone cannot resolve this vulnerability through server-side patches.</p>
<p>We thus recommend the following two key mitigation strategies to prevent such attacks and strengthen the security posture of your agent systems.</p>
<p><img src="https://invariantlabs.ai/images/flow-grid.svg" alt="Enforce Dataflow Rules"/></p>
<h4>1. Implement Granular Permission Controls</h4>
<p>When using MCP integrations like GitHub&#39;s, it&#39;s critical to limit agent access to only the repositories it needs to interact with—following the principle of least privilege. While traditional token-based permissions offer some protection, they often impose rigid constraints that limit an agent&#39;s functionality.</p>
<p>For more effective security without sacrificing capability, we recommend implementing dynamic <strong>runtime security layers</strong> specifically designed for agent systems. Solutions like <strong><a href="https://explorer.invariantlabs.ai/docs/guardrails/">Invariant Guardrails</a></strong> provide context-aware access control that adapts to your agent&#39;s workflow while enforcing security boundaries. </p>
<p>To illustrate, here&#39;s an example policy that prevents cross-repository information leaks using Invariant Guardrails:</p>
<div><pre><span></span><code><span>raise</span> <span>Violation</span><span>(</span><span>&#34;You can access only one repo per session.&#34;</span><span>)</span> <span>if</span><span>:</span>
    <span>(</span><span>call_before</span><span>:</span> <span>ToolCall</span><span>)</span> <span>-&gt;</span> <span>(</span><span>call_after</span><span>:</span> <span>ToolCall</span><span>)</span>

    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>name</span> <span>in</span> <span>(</span><span>...</span><span>set</span> <span>of</span> <span>repo</span> <span>actions</span><span>)</span>
    <span>call_after</span><span>.</span><span>function</span><span>.</span><span>name</span> <span>in</span> <span>(</span><span>...</span><span>set</span> <span>of</span> <span>repo</span> <span>actions</span><span>)</span>

    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>&#34;repo&#34;</span><span>]</span> <span>!=</span> <span>call_after</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>&#34;repo&#34;</span><span>]</span> <span>or</span>
    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>&#34;owner&#34;</span><span>]</span> <span>!=</span> <span>call_after</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>&#34;owner&#34;</span><span>]</span>
</code></pre></div>

<p>You can find the complete policy <a href="https://invariantlabs.ai/images/github_policy.txt">here</a>. See the <a href="https://explorer.invariantlabs.ai/docs/mcp-scan/">MCP-scan documentation</a>, for more information on how to apply this policy to your MCP deployments.</p>
<p>This approach effectively restricts an agent to working with only one repository per session, preventing cross-repository information leakage while maintaining full functionality within authorized boundaries.</p>
<p>To experiment more with Guardrails, you can also use the <a href="https://explorer.invariantlabs.ai/playground/">Guardrails Playground</a> to test policies before deploying them.</p>
<p><img src="https://invariantlabs.ai/images/explorer-icon.svg" alt="Inspect with Explorer"/></p>
<h4>2. Conduct Continuous Security Monitoring</h4>
<p>Beyond preventative measures, implement robust monitoring solutions to detect and respond to potential security threats in real time. We recommend deploying specialized security scanners such as Invariant&#39;s <a href="https://explorer.invariantlabs.ai/docs/mcp-scan/">MCP-scan</a> to continuously audit interactions between agents and MCP systems.</p>
<p>The recently introduced <a href="https://github.com/invariantlabs-ai/mcp-scan?tab=readme-ov-file#proxy">proxy mode in MCP-scan</a> significantly simplifies this process by enabling real-time security scanning of MCP connections without requiring modifications to your existing agent infrastructure. Simply route your MCP traffic through the proxy to gain immediate visibility and real-time scanning for potential security violations.</p>
<p>Implementing comprehensive monitoring also creates an audit trail that helps identify potential vulnerabilities, detect exploitation attempts, and ensure your agent systems remain protected against emerging attacks.</p>
<h3>Why Model Alignment Is Not Enough</h3>
<p>As demonstrated by our findings, even state-of-the-art aligned models are vulnerable to these attacks. In our experiments, we used <a href="https://www.anthropic.com/news/claude-4">Claude 4 Opus</a>, a very recent, highly aligned and secure AI model. Despite its robust safety training, the agent was still susceptible to manipulation through relatively simplistic prompt injections. Similarly, many off-the-shelf prompt injection detector defenses, fail to catch this attack.</p>
<p>The vulnerability persists because the security of agent systems is fundamentally contextual and environment-dependent. While general model alignment training creates some guardrails, it cannot anticipate the specific security requirements of every deployment scenario or organizational context. Security measures must be implemented at the system level, complementing model-level safeguards.</p>
<h2 id="conclusion">Conclusion</h2>

<p>In this blog post, we have shown a critical vulnerability affecting the GitHub MCP server, allowing attackers to hijack a user&#39;s agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories. The vulnerability is among the first discovered by Invariant&#39;s security analyzer for detecting toxic agent flows.</p>
<p>While the vulnerability that we uncover is specific to GitHub MCP, similar attacks keep emerging in other settings. For instance, <a href="https://www.legitsecurity.com/">Legit Security</a> recently reported a vulnerability in <a href="https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo">GitLab Duo</a>.
 <!-- As LLMs improve, at agentic behavior, we are giving them more powerful tools to fully unlock new powerful agentic workflows. Unfortunately, those come together with possible _toxic flows_. -->
</p>
<p>It is crucial to safeguard agent systems and MCP integrations using designated security scanners such as Invariant&#39;s <a href="https://invariantlabs.ai/blog/blog/introducing-mcp-scan">MCP-scan</a> and <a href="https://explorer.invariantlabs.ai/docs/guardrails/">Guardrails</a> to ensure responsible deployment at scale.</p>
<p><strong>Work With Us</strong></p>
<p>If you are interested in learning more about how to secure your agent systems, please reach out to us at <a href="https://invariantlabs.ai/cdn-cgi/l/email-protection#ee8b8f9c82978f8d8d8b9d9dae8780988f9c878f809a828f8c9dc08f87"><span data-cfemail="761317041a0f171515130505361f180017041f1718021a17140558171f">[email protected]</span></a>. We are happy to onboard you to our early access security program, and help you secure your agent systems.</p>       
    </div></div>
  </body>
</html>
