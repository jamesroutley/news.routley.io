<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://composio.dev/blog/gemini-2-5-pro-vs-claude-3-7-sonnet-coding-comparison/">Original</a>
    <h1>Gemini 2.5 Pro vs. Claude 3.7 Sonnet: Coding Comparison</h1>
    
    <div id="readability-page-1" class="page"><div id="content">

			<!-- 1.4 uicore_before_content -->
<div id="primary">

	        <main id="main">
			<div>


                				<div>

                    <article id="post-11443">
                            
                            <div>
                            
<p>Google just launched Gemini 2.5 Pro on March 26th, claiming to be the best in coding, reasoning and overall everything. But I mostly care about how the model compares against the best available coding model, Claude 3.7 Sonnet (thinking), released at the end of February, which I have been using, and it has been a great experience.</p>



<p>Let‚Äôs compare these two coding models and see if I need to change my favourite coding model or if Claude 3.7 still holds.</p>



<h2 id="h-tl-dr">TL;DR</h2>



<p>If you want to jump straight to the conclusion, I‚Äôd say go for <strong>Gemini 2.5 Pro</strong>, it‚Äôs better at coding, has one million in context window as compared to Claude‚Äôs 200k, and you can get it for free (a big plus). However, Claude‚Äôs 3.7 Sonnet is not that far behind. Though at this point there‚Äôs no point using it over Gemini 2.5 Pro.</p>



<p>Just an article ago, <a href="https://composio.dev/blog/claude-3-7-sonnet-vs-grok-3-vs-o3-mini-high/">Claude 3.7 Sonnet</a> was the default answer to every model comparison, and this remained the same for quite some time. But here you go, Gemini 2.5 Pro takes the lead. </p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8x1u552q65y2kdo9whe0.png" alt=""/></figure>



<h2 id="h-brief-on-gemini-2-5-pro">Brief on Gemini 2.5 Pro</h2>



<p>Gemini 2.5 Pro, an experimental thinking model, became the talk of the town within a week of its release. Everyone‚Äôs talking about this model on Twitter (X) and YouTube. It‚Äôs trending everywhere, like seriously. The first model from Google to receive such fanfare.</p>



<p>And it is <strong>#1 in the LMArena</strong> just like that. But what does this mean? It means that this model is killing all the other models in coding, math, Science, Image understanding, and other areas.</p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zf0c4kp8j091hzerwjto.png" alt=""/></figure>



<p>Gemini 2.5 pro comes with a <strong>1 million token context window,</strong> with a 2 million context window coming soon. ü§Ø</p>



<p>You can check out other folks like <a href="https://www.youtube.com/@t3dotgg">Theo-t3</a> talking about this model to get a bit more insight into it:</p>



<figure><p>
<iframe title="Google won. (Gemini 2.5 Pro is INSANE)" width="1000" height="563" src="https://www.youtube.com/embed/A0V4km88tFc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>It is the best coding model to date, with an accuracy of about 63.8% on the SWE bench. This is definitely higher than our previous top coding model, Claude 3.7 Sonnet, which had an accuracy of about 62.3%.</p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ce6yvu56s5wff9iiod8l.png" alt=""/></figure>



<p>This is a quick demo Google shared on this model of building a dinosaur game.</p>



<figure><p>
<iframe title="Gemini 2.5: Create your own dinosaur game from a single line prompt" width="1000" height="563" src="https://www.youtube.com/embed/RLCBSpgos6s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Here‚Äôs a quick benchmark of this model on Reasoning, Mathematics, and Science. This confirms that the model is not just suitable for coding but also for all your other needs. They claim it‚Äôs an all-rounder. ü§∑‚Äç‚ôÇÔ∏è</p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/22b0a4ffg37ev7w9o7we.png" alt=""/></figure>



<p>This is all cool, and I‚Äôll confirm the claim, but in this article, I will mainly be comparing the model on coding, and let‚Äôs see how well it performs compared to Claude 3.7 Sonnet.</p>



<h2 id="h-coding-problems">Coding Problems</h2>



<p>Let‚Äôs compare these two models in coding. We‚Äôll do a total of 4 tests, mainly on WebDev, animation and a tricky LeetCode question.</p>



<h3 id="h-1-flight-simulator">1. Flight Simulator</h3>



<p><strong>Prompt:</strong> Create a simple flight simulator using JavaScript. The simulator should feature a basic plane that can take off from a flat runway. The plane‚Äôs movement should be controlled with simple keyboard inputs (e.g., arrow keys or WASD). Additionally, it generates a basic cityscape using blocky structures, similar to Minecraft.</p>



<p><strong>Response from Gemini 2.5 Pro</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/5fc44c03fde651f5bea7008919377c1d">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/flight_sim_gemini_2-1.mp4"></video></figure>



<p>I definitely got exactly what I asked for, with everything functioning, from plane movements to the basic Minecraft-styled block buildings. I can‚Äôt really complain about anything here. 10/10 for this one. </p>



<p><strong>Response from Claude 3.7 Sonnet</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/b22a2d583f1a56beb2df2dcf636a1a88">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/flight_sim_claude.mp4"></video></figure>



<p>I can see some issues with this one. The plane clearly faces sideways, and I don‚Äôt know why. Again, it was out of control once it took off and went clearly outside the city. Basically, I‚Äôd say we didn‚Äôt really get a completely working flight simulator here.</p>



<p><strong>Summary:</strong></p>



<p>It‚Äôs fair to say that Gemini 2.5 really got this correct in one shot. But the issues with the Claude 3.7 Sonnet code aren‚Äôt really that big to resolve. Yeah, we didn‚Äôt really get the output as expected, and it‚Äôs definitely not close to what Gemini 2.5 Pro got us.</p>



<h3 id="h-2-rubik-s-cube-solver">2. Rubik‚Äôs Cube Solver</h3>



<p>This is one of the toughest questions for LLMs. I‚Äôve tried it with many other LLMs, but none could correct it. Let‚Äôs see how these two models do this one.</p>



<p><strong>Prompt:</strong> Build a simple 3D Rubik‚Äôs Cube visualizer and solver in JavaScript using Three.js. The cube should be a 3√ó3 Rubik‚Äôs Cube with standard colours. Have a scramble button that randomly scrambles the cube. Include a solve function that animates the solution step by step. Allow basic mouse controls to rotate the view.</p>



<p><strong>Response from Gemini 2.5 Pro</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/1c7ed9967d03c6f5f9b8fd2ad46bcba1">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/rubiks_cube_gemini_2.mp4"></video></figure>



<p>It‚Äôs impressive that it could do something this hard in one shot. With the 1 million token context window, I can truly see how powerful this model seems to be.</p>



<p><strong>Response from Claude 3.7 Sonnet</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/e4c12edb3384323be43f1196522eb6f2">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/rubiks_cube_claude_3.7.mp4"></video></figure>



<p>Again, I was kind of disappointed that it had the same issue as some other LLMs: failing with the colours and completely failing to solve the cube. I did try to help it come up with the answer, but it didn‚Äôt really help.</p>



<p><strong>Summary:</strong></p>



<p>Here again, Gemini 2.5 Pro takes the lead. And the best part is that all of it was done in one shot. Claude 3.7 was really disappointing, as it could not get this one correct, despite being one of the finest coding models out there.</p>



<h3 id="h-3-ball-bouncing-inside-a-spinning-4d-tesseract">3. Ball Bouncing Inside a Spinning 4D Tesseract</h3>



<p><strong>Prompt:</strong> Create a simple JavaScript script that visualizes a ball bouncing inside a rotating 4D tesseract. When the ball collides with a side, highlight that side to indicate the impact.</p>



<p><strong>Response from Gemini 2.5 Pro</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/866c2207af82416edfb240818c3ddf73">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/gemini_2.5_tesserect.mp4"></video></figure>



<p>I cannot notice a single issue in the output. The ball and the collision physics all work perfectly, even the part where I asked it to highlight the collision side works. This free model seems to be insane for coding. üî•</p>



<p><strong>Response from Claude 3.7 Sonnet</strong></p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/b54d5b5bda033f6784637c19c50a845b">Link</a></p>



<p>Here‚Äôs the output of the program:</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2025/03/claude-bouncing-ball-1.mp4"></video></figure>



<p>Wow, finally, Claude 3.7 Sonnet got an answer correct. It also added colors to each side, but who asked for it? ü§∑‚Äç‚ôÇÔ∏è Nevertheless, I can‚Äôt really complain much here, as the main functionality seems to work just fine.</p>



<p><strong>Summary:</strong></p>



<p>The answer is evident this time. Both models got the answer correct, implementing everything I asked for. I won‚Äôt really say that I like the output of Claude 3.7 Sonnet more, but it definitely put in quite some work compared to Gemini 2.5 Pro.</p>



<h3 id="h-4-leetcode-problem">4. LeetCode Problem</h3>



<p>For this one, let‚Äôs do a quick LeetCode check with to see how these models handle solving a tricky LeetCode question with an <strong>acceptance rate of just 14.9%</strong>: <a href="https://leetcode.com/problems/maximum-value-sum-by-placing-three-rooks-i/description/">Maximum Value Sum by Placing 3 Rooks</a>.</p>



<p>Claude 3.7 Sonnet is known to be super good at solving LC questions. If you want to see how <strong>Claude 3.7</strong> compares to some top models like <strong>Grok 3</strong> and <strong>o3-mini-high</strong>, check out this blog post:</p>



<p><a href="https://composio.dev/blog/claude-3-7-sonnet-vs-grok-3-vs-o3-mini-high/">Claude 3.7 Sonnet vs. Grok 3 vs. o3-mini-high: Coding comparison</a></p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>Prompt:</span></span>
<span></span>
<span><span>You are given a m x n 2D array board representing a chessboard, where board[</span><span>i</span><span>][j] represents the value of the cell (i, j).</span></span>
<span></span>
<span><span>Rooks in the same row or column attack each other. You need to place three rooks on the chessboard such that the rooks do not attack each other.</span></span>
<span></span>
<span><span>Return the maximum sum of the cell values on which the rooks are placed.</span></span>
<span></span>
<span><span>Example 1:</span></span>
<span></span>
<span><span>Input: board = [[</span><span>-3,1,1,1</span><span>],[</span><span>-3,1,-3,1</span><span>],[</span><span>-3,2,1,1</span><span>]]</span></span>
<span><span>Output: 4</span></span>
<span><span>Explanation:</span></span>
<span><span>We can place the rooks in the cells (0, 2), (1, 3), and (2, 1) for a sum of 1 + 1 + 2 = 4.</span></span>
<span></span>
<span><span>Example 2:</span></span>
<span></span>
<span><span>Input: board = [[</span><span>1,2,3</span><span>],[</span><span>4,5,6</span><span>],[</span><span>7,8,9</span><span>]]</span></span>
<span><span>Output: 15</span></span>
<span><span>Explanation:</span></span>
<span><span>We can place the rooks in the cells (0, 0), (1, 1), and (2, 2) for a sum of 1 + 5 + 9 = 15.</span></span>
<span></span>
<span><span>Example 3:</span></span>
<span></span>
<span><span>Input: board = [[</span><span>1,1,1</span><span>],[</span><span>1,1,1</span><span>],[</span><span>1,1,1</span><span>]]</span></span>
<span><span>Output: 3</span></span>
<span><span>Explanation:</span></span>
<span><span>We can place the rooks in the cells (0, 2), (1, 1), and (2, 0) for a sum of 1 + 1 + 1 = 3.</span></span>
<span></span>
<span><span>Constraints:</span></span>
<span></span>
<span><span>3 &lt;= m == board.length &lt;= 100</span></span>
<span><span>3 &lt;= n == board[</span><span>i</span><span>].length &lt;= 100</span></span>
<span><span>-109 &lt;= board[</span><span>i</span><span>][j] &lt;= 109</span></span>
<span></span>
<span></span></code></pre></div>



<p><strong>Response from Gemini 2.5 Pro</strong></p>



<p>Given how easily it answered all three of the coding questions we tested, I have quite high hopes for this model.</p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/6e1fd99d04a10a3ff7d82934770387d7">Link</a></p>



<p>It did take quite some time to answer this one, though, and the code it wrote is kind of super complex to make sense of. I think it answered it more complicated than required. But still, the main thing we‚Äôre looking for is to see if it can answer it correctly.</p>



<p>As expected, it also answered this tough LeetCode question in one shot. This is one of the questions I got stuck on when learning DSA. I‚Äôm not sure if I‚Äôm happy it did. </p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/avp4adkc0d9gij4bff8d.png" alt=""/></figure>



<p><strong>Response from Claude 3.7 Sonnet</strong></p>



<p>I hope this model will crush this one, as in all the other coding tests I‚Äôve done, Claude 3.7 Sonnet has answered all of the LeetCode questions correctly.</p>



<p>You can find the code it generated here: <a href="https://gist.github.com/shricodev/5730c52c5b057cd2098d4a04674338b6">Link</a></p>



<p>It did write correct code but got TLE, but if I have to compare the code‚Äôs simplicity, I‚Äôd say this model made the code simpler and easier to understand.</p>



<figure><img decoding="async" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fxxc2mfzbcvmt3anak3n.png" alt=""/></figure>



<p><strong>Summary:</strong></p>



<p>Gemini 2.5 got the answer correct and also wrote the code in the expected time complexity, but Claude 3.7 Sonnet fell into TLE. If I have to compare the code simplicity, Claude 3.7‚Äôs generated code seems to be better.</p>



<h2 id="h-conclusion">Conclusion</h2>



<p>For me, Gemini 2.5 Pro is the winner. We‚Äôve compared two models that are said to be the best at coding. The big difference I see in the model stats is just that Gemini 2.5 Pro has a slightly higher context window, but let‚Äôs not forget that this is an experimental model, and improvements are still on the way.</p>



<p>Imagine this model‚Äôs performance after a <strong>2M token context window.</strong></p>



<p>Google‚Äôs been killing it recently with such solid models, previously with the Gemma 3 27B model, a super lightweight model with unbelievable results, and now with this beast of a model, Gemini 2.5 Pro.</p>



<p>By the way, if you are here, Composio is building the skill repository for agents. You can connect LLMs to any application from Gmail to Asana and get things done quickly. You can use <a href="https://mcp.composio.dev">MCP servers</a>, or directly add the <a href="https://docs.composio.dev/tool-calling/introduction">tools to LLMs</a> in the traditional agentic way.</p>
                        </div><!-- .entry-content -->

                                                <!-- .entry-footer -->
                        
                    </article><!-- #post-11443 -->
                    
<!-- #comments -->
                </div>
                    </div>
            </main>
    	
</div><!-- #primary -->


	</div></div>
  </body>
</html>
