<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Oct/14/nvidia-dgx-spark/">Original</a>
    <h1>Nvidia DGX Spark: great hardware, early days for the ecosystem</h1>
    
    <div id="readability-page-1" class="page"><div>


<div data-permalink-context="/2025/Oct/14/nvidia-dgx-spark/">

<p>14th October 2025</p>



<p>NVIDIA sent me a preview unit of their new <a href="https://www.nvidia.com/en-us/products/workstations/dgx-spark/">DGX Spark</a> desktop “AI supercomputer”. I’ve never had hardware to review before! You can consider this my first ever sponsored post if you like, but they did not pay me any cash and aside from an embargo date they did not request (nor would I grant) any editorial input into what I write about the device.</p>
<p>The device retails for around $4,000. They officially go on sale tomorrow.</p>
<p>First impressions are that this is a snazzy little computer. It’s similar in size to a Mac mini, but with an exciting textured surface that feels refreshingly different and a little bit <a href="https://www.indiewire.com/awards/industry/devs-cinematography-rob-hardy-alex-garland-1234583396/">science fiction</a>.</p>
<p><img src="https://static.simonwillison.net/static/2025/nvidia-spark.jpg" alt="A rectangular small computer, sitting horizontally on a box. It is about the width of a Mac Mini. It has a NVIDIA logo on  a reflective handle portion, then textured silver metal front, then another reflective handle at the other end. It&#39;s pretty and a bit weird looking. It sits on the box it came in, which has NVIDIA DGX Spark written on it in white text on green."/></p>
<p>There is a <em>very</em> powerful machine tucked into that little box. Here are the specs, which I had Claude Code figure out for me by <a href="https://gist.github.com/simonw/021651a14e6c5bf9876c9c4244ed6c2d">poking around on the device itself</a>:</p>
<blockquote>
<p><strong>Hardware Specifications</strong></p>
<ul>
<li>Architecture: aarch64 (ARM64)</li>
<li>CPU: 20 cores
<ul>
<li>10x Cortex-X925 (performance cores)</li>
<li>10x Cortex-A725 (efficiency cores)</li>
</ul>
</li>
<li>RAM: 119 GB total (112 GB available)—<em>I’m not sure why Claude reported it differently here, the machine is listed as 128GB—it could be a <a href="https://news.ycombinator.com/item?id=45586776#45588329">128GB == 119GiB thing</a>.</em>
</li>
<li>Storage: 3.7 TB (6% used, 3.3 TB available)</li>
</ul>
<p><strong>GPU Specifications</strong></p>
<ul>
<li>Model: NVIDIA GB10 (Blackwell architecture)</li>
<li>Compute Capability: sm_121 (12.1)</li>
<li>Memory: 119.68 GB</li>
<li>Multi-processor Count: 48 streaming multiprocessors</li>
<li>Architecture: Blackwell</li>
</ul>
</blockquote>
<p>Short version: this is an ARM64 device with 128GB of memory that’s available to both the GPU and the 20 CPU cores at the same time, strapped onto a 4TB NVMe SSD.</p>
<p>The Spark is firmly targeted at “AI researchers”. It’s designed for both training and running models.</p>
<h4 id="the-tricky-bit-cuda-on-arm64">The tricky bit: CUDA on ARM64</h4>
<p>Until now almost all of my own model running experiments have taken place on a Mac. This has gotten far less painful over the past year and a half thanks to the amazing work of the <a href="https://simonwillison.net/tags/mlx/">MLX</a> team and community, but it’s still left me deeply frustrated at my lack of access to the NVIDIA CUDA ecosystem. I’ve lost count of the number of libraries and tutorials which expect you to be able to use Hugging Face Transformers or PyTorch with CUDA, and leave you high and dry if you don’t have an NVIDIA GPU to run things on.</p>
<p>Armed (ha) with my new NVIDIA GPU I was excited to dive into this world that had long eluded me... only to find that there was another assumption baked in to much of this software: x86 architecture for the rest of the machine.</p>
<p>This resulted in all kinds of unexpected new traps for me to navigate. I eventually managed to get a PyTorch 2.7 wheel for CUDA on ARM, but failed to do so for 2.8. I’m not confident there because the wheel itself is unavailable but I’m finding navigating the PyTorch ARM ecosystem pretty confusing.</p>
<p>NVIDIA are trying to make this easier, with mixed success. A lot of my initial challenges got easier when I found their <a href="https://docs.nvidia.com/dgx/dgx-spark/nvidia-container-runtime-for-docker.html">official Docker container</a>, so now I’m figuring out how best to use Docker with GPUs. Here’s the current incantation that’s been working for me:</p>
<div><pre>docker run -it --gpus=all \
  -v /usr/local/cuda:/usr/local/cuda:ro \
  nvcr.io/nvidia/cuda:13.0.1-devel-ubuntu24.04 \
  bash</pre></div>
<p>I have not yet got my head around the difference between CUDA 12 and 13. 13 appears to be very new, and a lot of the existing tutorials and libraries appear to expect 12.</p>
<h4 id="the-missing-documentation-isn-t-missing-any-more">The missing documentation isn’t missing any more</h4>
<p>When I first received this machine around a month ago there was very little in the way of documentation to help get me started. This meant climbing the steep NVIDIA+CUDA learning curve mostly on my own.</p>
<p>This has changed <em>substantially</em> in just the last week. NVIDIA now have extensive guides for getting things working on the Spark and they are a huge breath of fresh air—exactly the information I needed when I started exploring this hardware.</p>
<p>Here’s the <a href="https://developer.nvidia.com/topics/ai/dgx-spark">getting started guide</a> and the essential collection of <a href="https://build.nvidia.com/spark">playbooks</a>. There’s still a lot I haven’t tried yet just in this official set of guides.</p>
<h4 id="claude-code-for-everything">Claude Code for everything</h4>
<p><a href="https://www.claude.com/product/claude-code">Claude Code</a> was an absolute lifesaver for me while I was trying to figure out how best to use this device. My Ubuntu skills were a little rusty, and I also needed to figure out CUDA drivers and Docker incantations and how to install the right versions of PyTorch. Claude 4.5 Sonnet is <em>much better than me</em> at all of these things.</p>
<p>Since many of my experiments took place in disposable Docker containers I had no qualms at all about running it in YOLO mode:</p>
<div><pre>IS_SANDBOX=1 claude --dangerously-skip-permissions</pre></div>

<p>The <code>IS_SANDBOX=1</code> environment variable stops Claude from complaining about running as root.</p>

<details><summary>Before I found out about IS_SANDBOX</summary>



<p>Claude understandably won’t let you do this as root, even in a Docker container, so I found myself using the following incantation in a fresh <code>nvcr.io/nvidia/cuda:13.0.1-devel-ubuntu24.04</code> instance pretty often:</p>
<div><pre>apt-get update <span>&amp;&amp;</span> apt-get install -y sudo
<span><span>#</span> pick the first free UID &gt;=1000</span>
U=<span><span>$(</span>for i <span>in</span> <span><span>$(</span>seq 1000 65000<span>)</span></span><span>;</span> <span>do</span> <span>if</span> <span>!</span> getent passwd <span>$i</span> <span>&gt;</span>/dev/null<span>;</span> <span>then</span> <span>echo</span> <span>$i</span><span>;</span> <span>break</span><span>;</span> <span>fi</span><span>;</span> done<span>)</span></span>
<span>echo</span> <span><span>&#34;</span>Chosen UID: <span>$U</span><span>&#34;</span></span>
<span><span>#</span> same for a GID</span>
G=<span><span>$(</span>for i <span>in</span> <span><span>$(</span>seq 1000 65000<span>)</span></span><span>;</span> <span>do</span> <span>if</span> <span>!</span> getent group <span>$i</span> <span>&gt;</span>/dev/null<span>;</span> <span>then</span> <span>echo</span> <span>$i</span><span>;</span> <span>break</span><span>;</span> <span>fi</span><span>;</span> done<span>)</span></span>
<span>echo</span> <span><span>&#34;</span>Chosen GID: <span>$G</span><span>&#34;</span></span>
<span><span>#</span> create user+group</span>
groupadd -g <span><span>&#34;</span><span>$G</span><span>&#34;</span></span> devgrp
useradd -m -u <span><span>&#34;</span><span>$U</span><span>&#34;</span></span> -g <span><span>&#34;</span><span>$G</span><span>&#34;</span></span> -s /bin/bash dev
<span><span>#</span> enable password-less sudo:</span>
<span>printf</span> <span><span>&#39;</span>dev ALL=(ALL) NOPASSWD:ALL\n<span>&#39;</span></span> <span>&gt;</span> /etc/sudoers.d/90-dev-nopasswd
chmod 0440 /etc/sudoers.d/90-dev-nopasswd
<span><span>#</span> Install npm</span>
DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get install -y npm
<span><span>#</span> Install Claude</span>
npm install -g @anthropic-ai/claude-code</pre></div>
<p>Then switch to the <code>dev</code> user and run Claude for the first time:</p>
<div><pre>su - dev
claude --dangerously-skip-permissions</pre></div>

</details></div>



</div></div>
  </body>
</html>
