<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://xnacly.me/posts/2024/rust-pldev/">Original</a>
    <h1>Why I love Rust for tokenising and parsing</h1>
    
    <div id="readability-page-1" class="page"><div><blockquote><p>I am currently writing a analysis tool for Sql: <a href="https://github.com/xnacly/sqleibniz"><code>sqleibniz</code></a>, specifically for the sqlite
dialect.</p><p>The goal is to perform static analysis for sql input, including: syntax
checks, checks if tables, columns and functions exist. Combining this with an
embedded sqlite runtime and the ability to assert conditions in this runtime,
creates a really great dev experience for sql.</p><p>Furthermore, I want to be able to show the user high quality error messages
with context, explainations and the ability to mute certain diagnostics.</p><p>This analysis includes the stages of lexical analysis/tokenisation, the
parsing of SQL according to the sqlite documentation<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> and
the analysis of the resulting constructs.</p><p>After completing the static analysis part of the project, I plan on writing a
lsp server for sql, so stay tuned for that.</p></blockquote><p>In the process of the above, I need to write a tokenizer and a parser - both
for SQL. While I am nowhere near completion of sqleibniz, I still made some
discoveries around rust and the handy features the language provides for
developing said software.</p><h2 id="macros">Macros</h2><p>Macros work different in most languages. However they are used for mostly the
same reasons: code deduplication and less repetition.</p><h3 id="abstract-syntax-tree-nodes">Abstract Syntax Tree Nodes</h3><p>A node for a statement in <code>sqleibniz</code> implementation is defined as follows:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span>
</span></span><span><span>2</span><span><span>#[derive(Debug)]</span>
</span></span><span><span>3</span><span><span>/// holds all literal types, such as strings, numbers, etc.
</span></span></span><span><span>4</span><span><span></span><span>pub</span> <span>struct</span> <span>Literal</span> {
</span></span><span><span>5</span><span>    <span>pub</span> t: <span>Token</span>,
</span></span><span><span>6</span><span>}
</span></span></code></pre></div><p>Furthermore all nodes are required to implement the <code>Node</code>-trait, this trait
is returned by all parser functions and is later used to analyse the contents
of a statement:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>pub</span> <span>trait</span> Node: <span>std</span>::fmt::Debug {
</span></span><span><span>2</span><span>    <span>fn</span> <span>token</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>Token</span>;
</span></span><span><span>3</span><span>}
</span></span></code></pre></div><h4 id="code-duplication">Code duplication</h4><p>Thus every node not only has to be defined, but an implementation for the
<code>Node</code>-trait has to be written. This requires a lot of code duplication and
rust has a solution for that.</p><p>I want a macro that is able to:</p><ul><li>define a structure with a given identifier and a doc comment</li><li>add arbitrary fields to the structure</li><li>satisfying the <code>Node</code> trait by implementing <code>fn token(&amp;self) -&gt; &amp;Token</code></li></ul><p>Lets take a look at the full code I need the macro to produce for the
<code>Literal</code> and the <code>Explain</code> nodes. While the first one has no further fields
except the <code>Token</code> field <code>t</code>, the second node requires a child field with a
type.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>#[derive(Debug)]</span>
</span></span><span><span> 2</span><span><span>/// holds all literal types, such as strings, numbers, etc.
</span></span></span><span><span> 3</span><span><span></span><span>pub</span> <span>struct</span> <span>Literal</span> {
</span></span><span><span> 4</span><span>    <span>/// predefined for all structures defined with the node! macro
</span></span></span><span><span> 5</span><span><span></span>    <span>pub</span> t: <span>Token</span>,
</span></span><span><span> 6</span><span>}
</span></span><span><span> 7</span><span><span>impl</span> Node <span>for</span> Literal {
</span></span><span><span> 8</span><span>    <span>fn</span> <span>token</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>Token</span> {
</span></span><span><span> 9</span><span>        <span>&amp;</span>self.t
</span></span><span><span>10</span><span>    }
</span></span><span><span>11</span><span>}
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span>
</span></span><span><span>14</span><span><span>#[derive(Debug)]</span>
</span></span><span><span>15</span><span><span>/// Explain stmt, see: https://www.sqlite.org/lang_explain.html
</span></span></span><span><span>16</span><span><span></span><span>pub</span> <span>struct</span> <span>Explain</span> {
</span></span><span><span>17</span><span>    <span>/// predefined for all structures defined with the node! macro
</span></span></span><span><span>18</span><span><span></span>    <span>pub</span> t: <span>Token</span>,
</span></span><span><span>19</span><span>    <span>pub</span> child: <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> Node<span>&gt;&gt;</span>,
</span></span><span><span>20</span><span>}
</span></span><span><span>21</span><span><span>impl</span> Node <span>for</span> Explain {
</span></span><span><span>22</span><span>    <span>fn</span> <span>token</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>Token</span> {
</span></span><span><span>23</span><span>        <span>&amp;</span>self.t
</span></span><span><span>24</span><span>    }
</span></span><span><span>25</span><span>}
</span></span></code></pre></div><p>I want the above to be generated from the following two calls:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span>node!(
</span></span><span><span>2</span><span>    Literal,
</span></span><span><span>3</span><span>    <span>&#34;holds all literal types, such as strings, numbers, etc.&#34;</span>,
</span></span><span><span>4</span><span>);
</span></span><span><span>5</span><span>node!(
</span></span><span><span>6</span><span>    Explain,
</span></span><span><span>7</span><span>    <span>&#34;Explain stmt, see: https://www.sqlite.org/lang_explain.html&#34;</span>,
</span></span><span><span>8</span><span>    child: <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> Node<span>&gt;&gt;</span>,
</span></span><span><span>9</span><span>);
</span></span></code></pre></div><h4 id="code-deduplication-with-macros">Code deduplication with macros</h4><p>The macro for that is fairly easy, even if the rust macro docs arent that good:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span>macro_rules<span>!</span> node {
</span></span><span><span> 2</span><span>    (<span>$node_name</span>:<span>ident</span>,<span>$documentation</span>:<span>literal</span>,<span>$($field_name</span>:<span>ident</span>:<span>$field_type</span>:<span>ty</span>),<span>*</span>) <span>=&gt;</span> {
</span></span><span><span> 3</span><span>        <span>#[derive(Debug)]</span>
</span></span><span><span> 4</span><span>        <span>#[doc = $documentation]</span>
</span></span><span><span> 5</span><span>        <span>pub</span> <span>struct</span> <span>$node_name</span> {
</span></span><span><span> 6</span><span>            <span>/// predefined for all structures defined with the node! macro, holds the token of the ast node
</span></span></span><span><span> 7</span><span><span></span>            <span>pub</span> t: <span>Token</span>,
</span></span><span><span> 8</span><span>            <span>$(</span>
</span></span><span><span> 9</span><span>                <span>pub</span> <span>$field_name</span>: <span>$field_type</span>,
</span></span><span><span>10</span><span>            )<span>*</span>
</span></span><span><span>11</span><span>        }
</span></span><span><span>12</span><span>        <span>impl</span> Node <span>for</span> <span>$node_name</span> {
</span></span><span><span>13</span><span>            <span>fn</span> <span>token</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>Token</span> {
</span></span><span><span>14</span><span>                <span>&amp;</span>self.t
</span></span><span><span>15</span><span>            }
</span></span><span><span>16</span><span>        }
</span></span><span><span>17</span><span>    };
</span></span><span><span>18</span><span>}
</span></span></code></pre></div><p>Lets disect this macro. The Macro argument/metavariable definition starts with
<code>$node_name:ident,$documentation:literal</code>:</p><div><pre tabindex="0"><code data-lang="text"><span><span> 1</span><span>$node_name : ident , $documentation : literal
</span></span><span><span> 2</span><span>^^^^^^^^^^ ^ ^^^^^ ^
</span></span><span><span> 3</span><span>|          | |     |
</span></span><span><span> 4</span><span>|          | |     metavariable delimiter
</span></span><span><span> 5</span><span>|          | |
</span></span><span><span> 6</span><span>|          | metavariable type
</span></span><span><span> 7</span><span>|          |
</span></span><span><span> 8</span><span>|          metavariable type delimiter
</span></span><span><span> 9</span><span>|
</span></span><span><span>10</span><span>metavariable name
</span></span></code></pre></div><p>Meaning, we define the first metavariable of the macro to be a valid
identifier rust accepts and the second argument to be a literal. A literal
refers to a literal expression, such as chars, strings or raw strings.</p><p>The tricky part that took me some time to grasp is the way of defining
repetition of metavariables in macros, specifically <code>$($field_name:ident:$field_type:ty),*</code>.</p><div><pre tabindex="0"><code data-lang="text"><span><span>1</span><span>$($field_name:ident:$field_type:ty),*
</span></span><span><span>2</span><span>^^                 ^              ^ ^
</span></span><span><span>3</span><span>|                  |              | | 
</span></span><span><span>4</span><span>|                  metavariable   | repetition  
</span></span><span><span>5</span><span>|                  delimiter      | (any) 
</span></span><span><span>6</span><span>|                                 | 
</span></span><span><span>7</span><span>     sub group of metavariables
</span></span></code></pre></div><p>As I understand, we define a subgroup in our metavarible definition and
postfix it with its repetition. We use <code>:</code> to delimit inside the metavariable
sub-group, this enables us to write the macro in a convienient <code>field_name: type</code> way:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span>node!(
</span></span><span><span>2</span><span>    Example,
</span></span><span><span>3</span><span>    <span>&#34;Example docs&#34;</span>, 
</span></span><span><span>4</span><span>
</span></span><span><span>5</span><span>    <span>// sub group start
</span></span></span><span><span>6</span><span><span></span>    field_name: <span>&amp;</span><span>&#39;static</span> <span>str</span>,
</span></span><span><span>7</span><span>    field_name1: <span>String</span>
</span></span><span><span>8</span><span>    <span>// sub group end
</span></span></span><span><span>9</span><span><span></span>);
</span></span></code></pre></div><p>We can use the <code>$(...)*</code> syntax to “loop over” our sub grouped metavariables,
and thus create all fields with their respective names and types:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>pub</span> <span>struct</span> <span>$node_name</span> {
</span></span><span><span>2</span><span>    <span>pub</span> t: <span>Token</span>,
</span></span><span><span>3</span><span>    <span>$(</span>
</span></span><span><span>4</span><span>        <span>pub</span> <span>$field_name</span>: <span>$field_type</span>,
</span></span><span><span>5</span><span>    )<span>*</span>
</span></span><span><span>6</span><span>}
</span></span></code></pre></div><div id="callout"><h3>Tip</h3><p>See
<a href="https://doc.rust-lang.org/reference/macros-by-example.html#repetitions">Repetitions</a>
for the metavariable repetition documentation.</p></div><p>Remember: the <code>$documentation</code> metavariable holds a literal containing our doc
string we want to generate for our node - we now use the <code>#[doc = ...]</code>
annotation instead of the commonly known <code>/// ...</code> syntax to pass our macro
metavariable to the compiler:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>#[doc = $documentation]</span>
</span></span><span><span>2</span><span><span>pub</span> <span>struct</span> <span>$node_name</span> {
</span></span><span><span>3</span><span>    <span>// ...
</span></span></span><span><span>4</span><span><span></span>}
</span></span></code></pre></div><p>I’d say the trait implementation for each node is pretty self explanatory.</p><h3 id="testing">Testing</h3><p>Lets start off with me saying: I love table driven tests and the way Go allows
to write them:</p><div><pre tabindex="0"><code data-lang="go"><span><span> 1</span><span><span>func</span> <span>TestLexerWhitespace</span>(t <span>*</span>testing.T) {
</span></span><span><span> 2</span><span>    cases <span>:=</span> []<span>string</span>{<span>&#34;&#34;</span>,<span>&#34;\t&#34;</span>, <span>&#34;\r\n&#34;</span>, <span>&#34; &#34;</span>}
</span></span><span><span> 3</span><span>    <span>for</span> _, c <span>:=</span> <span>range</span> cases {
</span></span><span><span> 4</span><span>        t.<span>Run</span>(c, <span>func</span> (t <span>*</span>testing.T) {
</span></span><span><span> 5</span><span>            l <span>:=</span> Lexer{}
</span></span><span><span> 6</span><span>            l.<span>init</span>(c)
</span></span><span><span> 7</span><span>            l.<span>run</span>()
</span></span><span><span> 8</span><span>        })
</span></span><span><span> 9</span><span>    }
</span></span><span><span>10</span><span>}
</span></span></code></pre></div><p>In Go, I define an array of cases and just execute a test function for each
case <code>c</code>. As far as I know, Rust does not offer a similar test method - so
made one 😼.</p><h4 id="lexer--tokenizer-tests">Lexer / Tokenizer Tests</h4><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>#[cfg(test)]</span>
</span></span><span><span> 2</span><span><span>mod</span> should_pass {
</span></span><span><span> 3</span><span>    test_group_pass_assert! {
</span></span><span><span> 4</span><span>        string,
</span></span><span><span> 5</span><span>        string: <span>&#34;&#39;text&#39;&#34;</span><span>=</span>vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;text&#34;</span>))],
</span></span><span><span> 6</span><span>        empty_string: <span>&#34;&#39;&#39;&#34;</span><span>=</span>vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;&#34;</span>))],
</span></span><span><span> 7</span><span>        string_with_ending: <span>&#34;&#39;str&#39;;&#34;</span><span>=</span>vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;str&#34;</span>)), Type::Semicolon]
</span></span><span><span> 8</span><span>    }
</span></span><span><span> 9</span><span>
</span></span><span><span>10</span><span>    <span>// ...
</span></span></span><span><span>11</span><span><span></span>}
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span><span>#[cfg(test)]</span>
</span></span><span><span>14</span><span><span>mod</span> should_fail {
</span></span><span><span>15</span><span>    test_group_fail! {
</span></span><span><span>16</span><span>        empty_input,
</span></span><span><span>17</span><span>        empty: <span>&#34;&#34;</span>,
</span></span><span><span>18</span><span>        empty_with_escaped: <span>&#34;</span><span>\\</span><span>&#34;</span>,
</span></span><span><span>19</span><span>        empty_with_space: <span>&#34; </span><span>\t\n\r</span><span>&#34;</span>
</span></span><span><span>20</span><span>    }
</span></span><span><span>21</span><span>
</span></span><span><span>22</span><span>    <span>// ...
</span></span></span><span><span>23</span><span><span></span>}
</span></span></code></pre></div><p>Executing these via <code>cargo test</code>, results in the same output I love from table
driven tests in Go, each function having its own log and feedback
(<code>ok</code>/<code>fail</code>):</p><div><pre tabindex="0"><code data-lang="text"><span><span> 1</span><span>running 68 tests
</span></span><span><span> 2</span><span>test lexer::tests::should_pass::string::empty_string ... ok
</span></span><span><span> 3</span><span>test lexer::tests::should_pass::string::string ... ok
</span></span><span><span> 4</span><span>test lexer::tests::should_pass::string::string_with_ending ... ok
</span></span><span><span> 5</span><span>test lexer::tests::should_fail::empty_input::empty ... ok
</span></span><span><span> 6</span><span>test lexer::tests::should_fail::empty_input::empty_with_escaped ... ok
</span></span><span><span> 7</span><span>test lexer::tests::should_fail::empty_input::empty_with_space ... ok
</span></span><span><span> 8</span><span>
</span></span><span><span> 9</span><span>test result: ok. 68 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; 
</span></span><span><span>10</span><span>finished in 0.00s
</span></span></code></pre></div><p>The macro accepts the name of the test group, for example: <code>booleans</code> and
<code>string</code> and a list of input and expected output pairs. The input is passed to
the <code>Lexer</code> initialisation and the output of the <code>Lexer.run()</code> is compared
against the expected output. Inlining the <code>test_group_pass_assert!</code> call for
<code>string</code> results in the code below. Before asserting the equality of the
resulting token types and the expected token types, a transformation is
necessary, I map over the token vector and only return their types.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>mod</span> string {
</span></span><span><span> 2</span><span>    <span>use</span> <span>crate</span>::{lexer, types::Type};
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span>    <span>#[test]</span>
</span></span><span><span> 5</span><span>    <span>fn</span> <span>string</span>() {
</span></span><span><span> 6</span><span>        <span>let</span> input <span>=</span> <span>&#34;&#39;text&#39;&#34;</span>.as_bytes().to_vec();
</span></span><span><span> 7</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;lexer_tests_pass&#34;</span>);
</span></span><span><span> 8</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span> 9</span><span>        assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>10</span><span>        assert_eq!(
</span></span><span><span>11</span><span>            toks.into_iter().map(<span>|</span>tok<span>|</span> tok.ttype).collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(),
</span></span><span><span>12</span><span>            (vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;text&#34;</span>))])
</span></span><span><span>13</span><span>        );
</span></span><span><span>14</span><span>    }
</span></span><span><span>15</span><span>
</span></span><span><span>16</span><span>    <span>#[test]</span>
</span></span><span><span>17</span><span>    <span>fn</span> <span>empty_string</span>() {
</span></span><span><span>18</span><span>        <span>let</span> input <span>=</span> <span>&#34;&#39;&#39;&#34;</span>.as_bytes().to_vec();
</span></span><span><span>19</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;lexer_tests_pass&#34;</span>);
</span></span><span><span>20</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>21</span><span>        assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>22</span><span>        assert_eq!(
</span></span><span><span>23</span><span>            toks.into_iter().map(<span>|</span>tok<span>|</span> tok.ttype).collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(),
</span></span><span><span>24</span><span>            (vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;&#34;</span>))])
</span></span><span><span>25</span><span>        );
</span></span><span><span>26</span><span>    }
</span></span><span><span>27</span><span>
</span></span><span><span>28</span><span>    <span>#[test]</span>
</span></span><span><span>29</span><span>    <span>fn</span> <span>string_with_ending</span>() {
</span></span><span><span>30</span><span>        <span>let</span> input <span>=</span> <span>&#34;&#39;str&#39;;&#34;</span>.as_bytes().to_vec();
</span></span><span><span>31</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;lexer_tests_pass&#34;</span>);
</span></span><span><span>32</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>33</span><span>        assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>34</span><span>        assert_eq!(
</span></span><span><span>35</span><span>            toks.into_iter().map(<span>|</span>tok<span>|</span> tok.ttype).collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(),
</span></span><span><span>36</span><span>            (vec![Type::<span>String</span>(<span>String</span>::from(<span>&#34;str&#34;</span>)), Type::Semicolon])
</span></span><span><span>37</span><span>        );
</span></span><span><span>38</span><span>    }
</span></span><span><span>39</span><span>}
</span></span></code></pre></div><p>The counter part <code>test_group_fail!</code> for <code>empty_input!</code> produces the code below.
The main difference being the assertion of the resulting token vector to be
empty and the <code>Lexer.errors</code> field to contain at least on error.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>mod</span> empty_input {
</span></span><span><span> 2</span><span>    <span>use</span> <span>crate</span>::lexer;
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span>    <span>#[test]</span>
</span></span><span><span> 5</span><span>    <span>fn</span> <span>empty</span>() {
</span></span><span><span> 6</span><span>        <span>let</span> source <span>=</span> <span>&#34;&#34;</span>.as_bytes().to_vec();
</span></span><span><span> 7</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>source, <span>&#34;lexer_tests_fail&#34;</span>);
</span></span><span><span> 8</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span> 9</span><span>        assert_eq!(toks.len(), <span>0</span>);
</span></span><span><span>10</span><span>        assert_ne!(l.errors.len(), <span>0</span>);
</span></span><span><span>11</span><span>    }
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span>    <span>#[test]</span>
</span></span><span><span>14</span><span>    <span>fn</span> <span>empty_with_escaped</span>() {
</span></span><span><span>15</span><span>        <span>let</span> source <span>=</span> <span>&#34;</span><span>\\</span><span>&#34;</span>.as_bytes().to_vec();
</span></span><span><span>16</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>source, <span>&#34;lexer_tests_fail&#34;</span>);
</span></span><span><span>17</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>18</span><span>        assert_eq!(toks.len(), <span>0</span>);
</span></span><span><span>19</span><span>        assert_ne!(l.errors.len(), <span>0</span>);
</span></span><span><span>20</span><span>    }
</span></span><span><span>21</span><span>
</span></span><span><span>22</span><span>    <span>#[test]</span>
</span></span><span><span>23</span><span>    <span>fn</span> <span>empty_with_space</span>() {
</span></span><span><span>24</span><span>        <span>let</span> source <span>=</span> <span>&#34; </span><span>\t\n\r</span><span>&#34;</span>.as_bytes().to_vec();
</span></span><span><span>25</span><span>        <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>source, <span>&#34;lexer_tests_fail&#34;</span>);
</span></span><span><span>26</span><span>        <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>27</span><span>        assert_eq!(toks.len(), <span>0</span>);
</span></span><span><span>28</span><span>        assert_ne!(l.errors.len(), <span>0</span>);
</span></span><span><span>29</span><span>    }
</span></span><span><span>30</span><span>}
</span></span></code></pre></div><p>Lets take a look at the macros itself, I will not go into detail around the
macro definition - simply because I explained the meta variable declaration in
the previous <a href="#code-deduplication-with-macros">chapter</a>. The first macro is
uesd for the assertions of test with valid inputs - <code>test_group_pass_assert!</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span>macro_rules<span>!</span> test_group_pass_assert {
</span></span><span><span> 2</span><span>    (<span>$group_name</span>:<span>ident</span>,<span>$($ident</span>:<span>ident</span>:<span>$input</span>:<span>literal</span><span>=</span><span>$expected</span>:<span>expr</span>),<span>*</span>) <span>=&gt;</span> {
</span></span><span><span> 3</span><span>    <span>mod</span> <span>$group_name</span> {
</span></span><span><span> 4</span><span>        <span>use</span> <span>crate</span>::{lexer, types::Type};
</span></span><span><span> 5</span><span>
</span></span><span><span> 6</span><span>        <span>$(</span>
</span></span><span><span> 7</span><span>            <span>#[test]</span>
</span></span><span><span> 8</span><span>            <span>fn</span> <span>$ident</span>() {
</span></span><span><span> 9</span><span>                <span>let</span> input <span>=</span> <span>$input</span>.as_bytes().to_vec();
</span></span><span><span>10</span><span>                <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;lexer_tests_pass&#34;</span>);
</span></span><span><span>11</span><span>                <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>12</span><span>                assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>13</span><span>                assert_eq!(toks.into_iter().map(<span>|</span>tok<span>|</span> tok.ttype).collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(), <span>$expected</span>);
</span></span><span><span>14</span><span>            }
</span></span><span><span>15</span><span>        )<span>*</span>
</span></span><span><span>16</span><span>        }
</span></span><span><span>17</span><span>    };
</span></span><span><span>18</span><span>}
</span></span></code></pre></div><p>While the second is used for invalid inputs and edge case testing with expected
errors - <code>test_group_fail!</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span>macro_rules<span>!</span> test_group_fail {
</span></span><span><span> 2</span><span>    (<span>$group_name</span>:<span>ident</span>,<span>$($name</span>:<span>ident</span>:<span>$value</span>:<span>literal</span>),<span>*</span>) <span>=&gt;</span> {
</span></span><span><span> 3</span><span>        <span>mod</span> <span>$group_name</span> {
</span></span><span><span> 4</span><span>        <span>use</span> <span>crate</span>::lexer;
</span></span><span><span> 5</span><span>        <span>$(</span>
</span></span><span><span> 6</span><span>            <span>#[test]</span>
</span></span><span><span> 7</span><span>            <span>fn</span> <span>$name</span>() {
</span></span><span><span> 8</span><span>                <span>let</span> source <span>=</span> <span>$value</span>.as_bytes().to_vec();
</span></span><span><span> 9</span><span>                <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>source, <span>&#34;lexer_tests_fail&#34;</span>);
</span></span><span><span>10</span><span>                <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>11</span><span>                assert_eq!(toks.len(), <span>0</span>);
</span></span><span><span>12</span><span>                assert_ne!(l.errors.len(), <span>0</span>);
</span></span><span><span>13</span><span>            }
</span></span><span><span>14</span><span>         )<span>*</span>
</span></span><span><span>15</span><span>        }
</span></span><span><span>16</span><span>    };
</span></span><span><span>17</span><span>}
</span></span></code></pre></div><h4 id="parser-tests">Parser Tests</h4><p>I use the same concepts and almost the same macros in the <code>parser</code> module to
test the results the parser produces, but this time focussing on edge cases and
full sql statements. For instance the tests expected to pass and to fail for
the <code>EXPLAIN</code> sql statement:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>#[cfg(test)]</span>
</span></span><span><span> 2</span><span><span>mod</span> should_pass {
</span></span><span><span> 3</span><span>    test_group_pass_assert! {
</span></span><span><span> 4</span><span>        sql_stmt_prefix,
</span></span><span><span> 5</span><span>        explain: <span>r</span>#<span>&#34;EXPLAIN VACUUM;&#34;</span>#<span>=</span>vec![Type::Keyword(Keyword::<span>EXPLAIN</span>)],
</span></span><span><span> 6</span><span>        explain_query_plan: <span>r</span>#<span>&#34;EXPLAIN QUERY PLAN VACUUM;&#34;</span>#<span>=</span>vec![Type::Keyword(Keyword::<span>EXPLAIN</span>)]
</span></span><span><span> 7</span><span>    }
</span></span><span><span> 8</span><span>}
</span></span><span><span> 9</span><span>
</span></span><span><span>10</span><span><span>#[cfg(test)]</span>
</span></span><span><span>11</span><span><span>mod</span> should_fail {
</span></span><span><span>12</span><span>    test_group_fail! {
</span></span><span><span>13</span><span>        sql_stmt_prefix,
</span></span><span><span>14</span><span>        explain: <span>r</span>#<span>&#34;EXPLAIN;&#34;</span>#,
</span></span><span><span>15</span><span>        explain_query_plan: <span>r</span>#<span>&#34;EXPLAIN QUERY PLAN;&#34;</span>#
</span></span><span><span>16</span><span>    }
</span></span><span><span>17</span><span>}
</span></span></code></pre></div><p>Both macros get the <code>sql_stmt_prefix</code> as their module names, because thats the
function, in the parser, responsible for the <code>EXPLAIN</code> statement. The failing
tests check wheter the parser correctly asserts the conditions the sql standard
lays out, see <a href="https://www.sqlite.org/syntax/sql-stmt.html">sqlite - sql-stmt</a>.
Specifically, either that a statement follows after the <code>EXPLAIN</code> identifier or
the <code>QUERY PLAN</code> and a statement follow.</p><p>The difference between these tests and the tests for the lexer are in the way
the assertions are made. Take a look at the code the macros produce:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>#[cfg(test)]</span>
</span></span><span><span> 2</span><span><span>mod</span> should_pass {
</span></span><span><span> 3</span><span>    <span>mod</span> sql_stmt_prefix {
</span></span><span><span> 4</span><span>        <span>use</span> <span>crate</span>::{lexer, parser::Parser, types::Keyword, types::Type};
</span></span><span><span> 5</span><span>
</span></span><span><span> 6</span><span>        <span>#[test]</span>
</span></span><span><span> 7</span><span>        <span>fn</span> <span>explain</span>() {
</span></span><span><span> 8</span><span>            <span>let</span> input <span>=</span> <span>r</span><span>#&#34;EXPLAIN VACUUM;&#34;#</span>.as_bytes().to_vec();
</span></span><span><span> 9</span><span>            <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>10</span><span>            <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>11</span><span>            assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>12</span><span>            <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>13</span><span>            <span>let</span> ast <span>=</span> parser.parse();
</span></span><span><span>14</span><span>            assert_eq!(parser.errors.len(), <span>0</span>);
</span></span><span><span>15</span><span>            assert_eq!(
</span></span><span><span>16</span><span>                ast.into_iter()
</span></span><span><span>17</span><span>                    .map(<span>|</span>o<span>|</span> o.unwrap().token().ttype.clone())
</span></span><span><span>18</span><span>                    .collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(),
</span></span><span><span>19</span><span>                (vec![Type::Keyword(Keyword::<span>EXPLAIN</span>)])
</span></span><span><span>20</span><span>            );
</span></span><span><span>21</span><span>        }
</span></span><span><span>22</span><span>
</span></span><span><span>23</span><span>        <span>#[test]</span>
</span></span><span><span>24</span><span>        <span>fn</span> <span>explain_query_plan</span>() {
</span></span><span><span>25</span><span>            <span>let</span> input <span>=</span> <span>r</span><span>#&#34;EXPLAIN QUERY PLAN VACUUM;&#34;#</span>.as_bytes().to_vec();
</span></span><span><span>26</span><span>            <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>27</span><span>            <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>28</span><span>            assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>29</span><span>            <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>30</span><span>            <span>let</span> ast <span>=</span> parser.parse();
</span></span><span><span>31</span><span>            assert_eq!(parser.errors.len(), <span>0</span>);
</span></span><span><span>32</span><span>            assert_eq!(
</span></span><span><span>33</span><span>                ast.into_iter()
</span></span><span><span>34</span><span>                    .map(<span>|</span>o<span>|</span> o.unwrap().token().ttype.clone())
</span></span><span><span>35</span><span>                    .collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(),
</span></span><span><span>36</span><span>                (vec![Type::Keyword(Keyword::<span>EXPLAIN</span>)])
</span></span><span><span>37</span><span>            );
</span></span><span><span>38</span><span>        }
</span></span><span><span>39</span><span>    }
</span></span><span><span>40</span><span>}
</span></span></code></pre></div><p>As shown, the <code>test_group_pass_assert!</code> macro in the <code>parser</code> module starts
with the same <code>Lexer</code> initialisation and empty error vector assertion. However,
the next step is to initialise the <code>Parser</code> structure and after parsing assert
the outcome - i.e. no errors and nodes with the correct types.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>#[cfg(test)]</span>
</span></span><span><span> 2</span><span><span>mod</span> should_fail {
</span></span><span><span> 3</span><span>    <span>mod</span> sql_stmt_prefix {
</span></span><span><span> 4</span><span>        <span>use</span> <span>crate</span>::{lexer, parser::Parser};
</span></span><span><span> 5</span><span>        <span>#[test]</span>
</span></span><span><span> 6</span><span>        <span>fn</span> <span>explain</span>() {
</span></span><span><span> 7</span><span>            <span>let</span> input <span>=</span> <span>r</span><span>#&#34;EXPLAIN;&#34;#</span>.as_bytes().to_vec();
</span></span><span><span> 8</span><span>            <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span> 9</span><span>            <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>10</span><span>            assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>11</span><span>            <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span>12</span><span>            <span>let</span> _ <span>=</span> parser.parse();
</span></span><span><span>13</span><span>            assert_ne!(parser.errors.len(), <span>0</span>);
</span></span><span><span>14</span><span>        }
</span></span><span><span>15</span><span>
</span></span><span><span>16</span><span>        <span>#[test]</span>
</span></span><span><span>17</span><span>        <span>fn</span> <span>explain_query_plan</span>() {
</span></span><span><span>18</span><span>            <span>let</span> input <span>=</span> <span>r</span><span>#&#34;EXPLAIN QUERY PLAN;&#34;#</span>.as_bytes().to_vec();
</span></span><span><span>19</span><span>            <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span>20</span><span>            <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>21</span><span>            assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>22</span><span>            <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span>23</span><span>            <span>let</span> _ <span>=</span> parser.parse();
</span></span><span><span>24</span><span>            assert_ne!(parser.errors.len(), <span>0</span>);
</span></span><span><span>25</span><span>        }
</span></span><span><span>26</span><span>    }
</span></span><span><span>27</span><span>}
</span></span></code></pre></div><p>The <code>test_group_fail!</code> macro also extends the same macro from the <code>lexer</code>
module and appends the check for errors after parsing. Both <code>macro_rules!</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span>macro_rules<span>!</span> test_group_pass_assert {
</span></span><span><span> 2</span><span>    (<span>$group_name</span>:<span>ident</span>,<span>$($ident</span>:<span>ident</span>:<span>$input</span>:<span>literal</span><span>=</span><span>$expected</span>:<span>expr</span>),<span>*</span>) <span>=&gt;</span> {
</span></span><span><span> 3</span><span>    <span>mod</span> <span>$group_name</span> {
</span></span><span><span> 4</span><span>        <span>use</span> <span>crate</span>::{lexer, parser::Parser, types::Type, types::Keyword};
</span></span><span><span> 5</span><span>        <span>$(</span>
</span></span><span><span> 6</span><span>            <span>#[test]</span>
</span></span><span><span> 7</span><span>            <span>fn</span> <span>$ident</span>() {
</span></span><span><span> 8</span><span>                <span>let</span> input <span>=</span> <span>$input</span>.as_bytes().to_vec();
</span></span><span><span> 9</span><span>                <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>10</span><span>                <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>11</span><span>                assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span>                <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_pass&#34;</span>);
</span></span><span><span>14</span><span>                <span>let</span> ast <span>=</span> parser.parse();
</span></span><span><span>15</span><span>                assert_eq!(parser.errors.len(), <span>0</span>);
</span></span><span><span>16</span><span>                assert_eq!(ast.into_iter()
</span></span><span><span>17</span><span>                    .map(<span>|</span>o<span>|</span> o.unwrap().token().ttype.clone())
</span></span><span><span>18</span><span>                    .collect::<span>&lt;</span><span>Vec</span><span>&lt;</span>Type<span>&gt;&gt;</span>(), <span>$expected</span>);
</span></span><span><span>19</span><span>            }
</span></span><span><span>20</span><span>        )<span>*</span>
</span></span><span><span>21</span><span>        }
</span></span><span><span>22</span><span>    };
</span></span><span><span>23</span><span>}
</span></span><span><span>24</span><span>
</span></span><span><span>25</span><span>macro_rules<span>!</span> test_group_fail {
</span></span><span><span>26</span><span>    (<span>$group_name</span>:<span>ident</span>,<span>$($ident</span>:<span>ident</span>:<span>$input</span>:<span>literal</span>),<span>*</span>) <span>=&gt;</span> {
</span></span><span><span>27</span><span>    <span>mod</span> <span>$group_name</span> {
</span></span><span><span>28</span><span>        <span>use</span> <span>crate</span>::{lexer, parser::Parser};
</span></span><span><span>29</span><span>        <span>$(</span>
</span></span><span><span>30</span><span>            <span>#[test]</span>
</span></span><span><span>31</span><span>            <span>fn</span> <span>$ident</span>() {
</span></span><span><span>32</span><span>                <span>let</span> input <span>=</span> <span>$input</span>.as_bytes().to_vec();
</span></span><span><span>33</span><span>                <span>let</span> <span>mut</span> l <span>=</span> lexer::Lexer::new(<span>&amp;</span>input, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span>34</span><span>                <span>let</span> toks <span>=</span> l.run();
</span></span><span><span>35</span><span>                assert_eq!(l.errors.len(), <span>0</span>);
</span></span><span><span>36</span><span>
</span></span><span><span>37</span><span>                <span>let</span> <span>mut</span> parser <span>=</span> Parser::new(toks, <span>&#34;parser_test_fail&#34;</span>);
</span></span><span><span>38</span><span>                <span>let</span> _ <span>=</span> parser.parse();
</span></span><span><span>39</span><span>                assert_ne!(parser.errors.len(), <span>0</span>);
</span></span><span><span>40</span><span>            }
</span></span><span><span>41</span><span>        )<span>*</span>
</span></span><span><span>42</span><span>        }
</span></span><span><span>43</span><span>    };
</span></span><span><span>44</span><span>}
</span></span></code></pre></div><h3 id="macro-pitfalls">Macro Pitfalls</h3><ul><li><code>rust-analyzer</code> plays badly inside <code>macro_rules!</code><ul><li>no real intellisense</li><li>no goto definition</li><li>no hover for signatures of literals and language constructs</li></ul></li><li><code>cargo fmt</code> does not format or indent inside of <code>macro_rules!</code> and macro invokations</li><li><code>treesitter</code> (yes I use neovim, btw 😼) and <code>chroma</code> (used on this site)
sometimes struggle with syntax highlighting of <code>macro_rules!</code></li><li>documentation is sparse at best</li></ul><h2 id="matching-characters">Matching Characters</h2><p>When writing a lexer, comparing characters is the part everything else depends
on. Rust makes this enjoyable via the <code>matches!</code> macro and the patterns the
<code>match</code> statement accepts. For instance, checking if the current character is
a valid sqlite number can be done by a simple <code>matches!</code> macro invocation:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>/// Specifically matches https://www.sqlite.org/syntax/numeric-literal.html
</span></span></span><span><span> 2</span><span><span></span><span>fn</span> <span>is_sqlite_num</span>(<span>&amp;</span>self) -&gt; <span>bool</span> {
</span></span><span><span> 3</span><span>    matches!(self.cur(), 
</span></span><span><span> 4</span><span>             <span>// exponent notation with +-
</span></span></span><span><span> 5</span><span><span></span>             <span>&#39;+&#39;</span> <span>|</span> <span>&#39;-&#39;</span> <span>|</span>
</span></span><span><span> 6</span><span>             <span>// sqlite allows for separating numbers by _
</span></span></span><span><span> 7</span><span><span></span>             <span>&#39;_&#39;</span> <span>|</span>
</span></span><span><span> 8</span><span>             <span>// floating point
</span></span></span><span><span> 9</span><span><span></span>             <span>&#39;.&#39;</span> <span>|</span>
</span></span><span><span>10</span><span>             <span>// hexadecimal
</span></span></span><span><span>11</span><span><span></span>             <span>&#39;a&#39;</span><span>..=</span><span>&#39;f&#39;</span> <span>|</span> <span>&#39;A&#39;</span><span>..=</span><span>&#39;F&#39;</span> <span>|</span>
</span></span><span><span>12</span><span>             <span>// decimal
</span></span></span><span><span>13</span><span><span></span>             <span>&#39;0&#39;</span><span>..=</span><span>&#39;9&#39;</span>)
</span></span><span><span>14</span><span>}
</span></span></code></pre></div><p>Similarly testing for identifiers is as easy as the above:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>fn</span> <span>is_ident</span>(<span>&amp;</span>self, c: <span>char</span>) -&gt; <span>bool</span> {
</span></span><span><span>2</span><span>    matches!(c, <span>&#39;a&#39;</span><span>..=</span><span>&#39;z&#39;</span> <span>|</span> <span>&#39;A&#39;</span><span>..=</span><span>&#39;Z&#39;</span> <span>|</span> <span>&#39;_&#39;</span> <span>|</span> <span>&#39;0&#39;</span><span>..=</span><span>&#39;9&#39;</span>)
</span></span><span><span>3</span><span>}
</span></span></code></pre></div><p>Symbol detection in the main loop of the lexer works exactly the same:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>pub</span> <span>fn</span> <span>run</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>Vec</span><span>&lt;</span>Token<span>&gt;</span> {
</span></span><span><span> 2</span><span>    <span>let</span> <span>mut</span> r <span>=</span> vec![];
</span></span><span><span> 3</span><span>    <span>while</span> <span>!</span>self.is_eof() {
</span></span><span><span> 4</span><span>        <span>match</span> self.cur() {
</span></span><span><span> 5</span><span>            <span>// skipping whitespace
</span></span></span><span><span> 6</span><span><span></span>            <span>&#39;\t&#39;</span> <span>|</span> <span>&#39;\r&#39;</span> <span>|</span> <span>&#39; &#39;</span> <span>|</span> <span>&#39;\n&#39;</span> <span>=&gt;</span> {}
</span></span><span><span> 7</span><span>            <span>&#39;*&#39;</span> <span>=&gt;</span> r.push(self.single(Type::Asteriks)),
</span></span><span><span> 8</span><span>            <span>&#39;;&#39;</span> <span>=&gt;</span> r.push(self.single(Type::Semicolon)),
</span></span><span><span> 9</span><span>            <span>&#39;,&#39;</span> <span>=&gt;</span> r.push(self.single(Type::Comma)),
</span></span><span><span>10</span><span>            <span>&#39;%&#39;</span> <span>=&gt;</span> r.push(self.single(Type::Percent)),
</span></span><span><span>11</span><span>            _ <span>=&gt;</span> {
</span></span><span><span>12</span><span>                <span>// omitted error handling for unknown symbols
</span></span></span><span><span>13</span><span><span></span>                panic!(<span>&#34;whoops&#34;</span>);
</span></span><span><span>14</span><span>            } 
</span></span><span><span>15</span><span>        }
</span></span><span><span>16</span><span>        self.advance();
</span></span><span><span>17</span><span>    }
</span></span><span><span>18</span><span>    r
</span></span><span><span>19</span><span>}
</span></span></code></pre></div><p>Patterns in <code>match</code> statement and <code>matches</code> blocks are arguably the most
useful feature of Rust.</p><h2 id="matching-tokens">Matching Tokens</h2><p>Once the lexer converts the character stream into a stream of <code>Token</code> structure
instances with positional and type information, the parser can consume this
stream and produce an abstract syntax tree. The parser has to recognise
patterns in its input by detecting token types. This again is a case where
Rusts <code>match</code> statement shines.</p><p>Each <code>Token</code> contains a <code>t</code> field for its type, see below.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>pub</span> <span>use</span> self::keyword::Keyword;
</span></span><span><span> 2</span><span>
</span></span><span><span> 3</span><span><span>#[derive(Debug, PartialEq, Clone)]</span>
</span></span><span><span> 4</span><span><span>pub</span> <span>enum</span> <span>Type</span> {
</span></span><span><span> 5</span><span>    Keyword(keyword::Keyword),
</span></span><span><span> 6</span><span>    Ident(<span>String</span>),
</span></span><span><span> 7</span><span>    Number(<span>f64</span>),
</span></span><span><span> 8</span><span>    <span>String</span>(<span>String</span>),
</span></span><span><span> 9</span><span>    Blob(<span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span>),
</span></span><span><span>10</span><span>    Boolean(<span>bool</span>),
</span></span><span><span>11</span><span>    ParamName(<span>String</span>),
</span></span><span><span>12</span><span>    Param(<span>usize</span>),
</span></span><span><span>13</span><span>
</span></span><span><span>14</span><span>    Dot,
</span></span><span><span>15</span><span>    Asteriks,
</span></span><span><span>16</span><span>    Semicolon,
</span></span><span><span>17</span><span>    Percent,
</span></span><span><span>18</span><span>    Comma,
</span></span><span><span>19</span><span>
</span></span><span><span>20</span><span>    Eof,
</span></span><span><span>21</span><span>}
</span></span></code></pre></div><p>Lets look at the <code>sql_stmt_prefix</code> method of the parser. This function parses
the <code>EXPLAIN</code> statement, which - according to the sqlite documentation -
prefixes all other sql statements, hence the name. The corresponding syntax
diagram is shown below:</p><p><img src="https://xnacly.me/rust_lex_parse/sql_stmt.png" alt="sql_stmt syntax diagram"/></p><p>The implementation follows this diagram. The <code>Explain</code> stmt is optional, thus
if the current token type does not match <code>Type::Keyword(Keyword::EXPLAIN)</code>, we
call the <code>sql_stmt</code> function to processes the statements on the right of
the syntax diagram.</p><p>If the token matches it gets consumed and the next check is for the second
possible path in the <code>EXPLAIN</code> diagram: <code>QUERY PLAN</code>. This requires both the
<code>QUERY</code> and the <code>PLAN</code> keywords consecutively - both are consumed.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>impl</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> Parser<span>&lt;</span><span>&#39;a</span><span>&gt;</span> {
</span></span><span><span> 2</span><span>    <span>fn</span> <span>sql_stmt_prefix</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> Node<span>&gt;&gt;</span> {
</span></span><span><span> 3</span><span>        <span>match</span> self.cur()<span>?</span>.ttype {
</span></span><span><span> 4</span><span>            Type::Keyword(Keyword::<span>EXPLAIN</span>) <span>=&gt;</span> {
</span></span><span><span> 5</span><span>                <span>let</span> <span>mut</span> e <span>=</span> Explain {
</span></span><span><span> 6</span><span>                    t: <span>self</span>.cur()<span>?</span>.clone(),
</span></span><span><span> 7</span><span>                    child: <span>None</span>,
</span></span><span><span> 8</span><span>                };
</span></span><span><span> 9</span><span>                self.advance(); <span>// skip EXPLAIN
</span></span></span><span><span>10</span><span><span></span>
</span></span><span><span>11</span><span>                <span>// path for EXPLAIN-&gt;QUERY-&gt;PLAN
</span></span></span><span><span>12</span><span><span></span>                <span>if</span> self.is(Type::Keyword(Keyword::<span>QUERY</span>)) {
</span></span><span><span>13</span><span>                    self.consume(Type::Keyword(Keyword::<span>QUERY</span>));
</span></span><span><span>14</span><span>                    self.consume(Type::Keyword(Keyword::<span>PLAN</span>));
</span></span><span><span>15</span><span>                } <span>// else path is EXPLAIN-&gt;*_stmt
</span></span></span><span><span>16</span><span><span></span>
</span></span><span><span>17</span><span>                e.child <span>=</span> self.sql_stmt();
</span></span><span><span>18</span><span>                <span>Some</span>(<span>Box</span>::new(e))
</span></span><span><span>19</span><span>            }
</span></span><span><span>20</span><span>            _ <span>=&gt;</span> self.sql_stmt(),
</span></span><span><span>21</span><span>        }
</span></span><span><span>22</span><span>    }
</span></span><span><span>23</span><span>}
</span></span></code></pre></div><p>This shows the basic usage of pattern matching in the parser. An other
example is the <code>literal_value</code> function, its sole purpose is to create the
<code>Literal</code> node for all literals.</p><p><img src="https://xnacly.me/rust_lex_parse/literal_value.png" alt="literal_value syntax diagram"/></p><p>It discards most embedded enum values, but checks for some specific keywords,
because they are considered keywords, while being literals:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>impl</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> Parser<span>&lt;</span><span>&#39;a</span><span>&gt;</span> {
</span></span><span><span> 2</span><span>    <span>/// see: https://www.sqlite.org/syntax/literal-value.html
</span></span></span><span><span> 3</span><span><span></span>    <span>fn</span> <span>literal_value</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> Node<span>&gt;&gt;</span> {
</span></span><span><span> 4</span><span>        <span>let</span> cur <span>=</span> self.cur()<span>?</span>;
</span></span><span><span> 5</span><span>        <span>match</span> cur.ttype {
</span></span><span><span> 6</span><span>            Type::<span>String</span>(_)
</span></span><span><span> 7</span><span>            <span>|</span> Type::Number(_)
</span></span><span><span> 8</span><span>            <span>|</span> Type::Blob(_)
</span></span><span><span> 9</span><span>            <span>|</span> Type::Keyword(Keyword::<span>NULL</span>)
</span></span><span><span>10</span><span>            <span>|</span> Type::Boolean(_)
</span></span><span><span>11</span><span>            <span>|</span> Type::Keyword(Keyword::<span>CURRENT_TIME</span>)
</span></span><span><span>12</span><span>            <span>|</span> Type::Keyword(Keyword::<span>CURRENT_DATE</span>)
</span></span><span><span>13</span><span>            <span>|</span> Type::Keyword(Keyword::<span>CURRENT_TIMESTAMP</span>) <span>=&gt;</span> {
</span></span><span><span>14</span><span>                <span>let</span> s: <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> Node<span>&gt;&gt;</span> <span>=</span> <span>Some</span>(<span>Box</span>::new(Literal { t: <span>cur</span>.clone() }));
</span></span><span><span>15</span><span>                self.advance();
</span></span><span><span>16</span><span>                s
</span></span><span><span>17</span><span>            }
</span></span><span><span>18</span><span>            _ <span>=&gt;</span> {
</span></span><span><span>19</span><span>                <span>// omitted error handling for invalid literals
</span></span></span><span><span>20</span><span><span></span>                panic!(<span>&#34;whoops&#34;</span>);
</span></span><span><span>21</span><span>            }
</span></span><span><span>22</span><span>        }
</span></span><span><span>23</span><span>    }
</span></span><span><span>24</span><span>}
</span></span></code></pre></div><h2 id="fancy-error-display">Fancy error display</h2><blockquote><p>While the implementation itself is repetitive and not that interesting, I still
wanted to showcase the way both the lexer and the parser handle errors and how
these errors are displayed to the user. A typical error would be to miss a
semicolon at the end of a sql statement:</p><div><pre tabindex="0"><code data-lang="sql"><span><span>1</span><span><span>-- ./vacuum.sql
</span></span></span><span><span>2</span><span><span>-- rebuilding the database into a new file
</span></span></span><span><span>3</span><span><span></span><span>VACUUM</span> <span>INTO</span> <span>&#39;optimized.db&#39;</span>
</span></span></code></pre></div><p>Passing this file to <code>sqleibniz</code> promptly errors:</p><p><img src="https://xnacly.me/rust_lex_parse/vacuum_err.png" alt="vacuum error"/></p></blockquote><h2 id="optionals">Optionals</h2><p>Rust error handling is fun to do and propagation with the <code>?</code>-Operator just
makes sense. But Rust goes even further, not only can I modify the value inside
of the <code>Option</code> if there is one, I can even check conditions or provide default
values.</p><h3 id="is_some_and">is_some_and</h3><p>Sometimes you simply need to check if the next character of the input stream
is available and passes a predicate. <code>is_some_and</code> exists for this reason:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>fn</span> <span>next_is</span>(<span>&amp;</span><span>mut</span> self, c: <span>char</span>) -&gt; <span>bool</span> {
</span></span><span><span>2</span><span>    self.source
</span></span><span><span>3</span><span>        .get(self.pos <span>+</span> <span>1</span>)
</span></span><span><span>4</span><span>        .is_some_and(<span>|</span>cc<span>|</span> <span>*</span>cc <span>==</span> c <span>as</span> <span>u8</span>)
</span></span><span><span>5</span><span>}
</span></span><span><span>6</span><span>
</span></span><span><span>7</span><span><span>fn</span> <span>is</span>(<span>&amp;</span>self, c: <span>char</span>) -&gt; <span>bool</span> {
</span></span><span><span>8</span><span>    self.source.get(self.pos).is_some_and(<span>|</span>cc<span>|</span> <span>*</span>cc <span>as</span> <span>char</span> <span>==</span> c)
</span></span><span><span>9</span><span>}
</span></span></code></pre></div><p>The above is really nice to read, the following not so much:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>fn</span> <span>next_is</span>(<span>&amp;</span><span>mut</span> self, c: <span>char</span>) -&gt; <span>bool</span> {
</span></span><span><span> 2</span><span>    <span>match</span> self.source.get(self.pos <span>+</span> <span>1</span>) {
</span></span><span><span> 3</span><span>        <span>Some</span>(cc) <span>=&gt;</span> <span>*</span>cc <span>==</span> c <span>as</span> <span>u8</span>,
</span></span><span><span> 4</span><span>        _ <span>=&gt;</span> <span>false</span>,
</span></span><span><span> 5</span><span>    }
</span></span><span><span> 6</span><span>}
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span>fn</span> <span>is</span>(<span>&amp;</span>self, c: <span>char</span>) -&gt; <span>bool</span> {
</span></span><span><span> 9</span><span>    <span>match</span> self.source.get(self.pos) {
</span></span><span><span>10</span><span>        <span>Some</span>(cc) <span>=&gt;</span> <span>*</span>cc <span>as</span> <span>char</span> <span>==</span> c,
</span></span><span><span>11</span><span>        _ <span>=&gt;</span> <span>false</span>,
</span></span><span><span>12</span><span>    }
</span></span><span><span>13</span><span>}
</span></span></code></pre></div><h3 id="map">map</h3><p>Since the input is a Vector of <code>u8</code>, not a Vector of <code>char</code>, this conversion is done with <code>map</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>fn</span> <span>next</span>(<span>&amp;</span>self) -&gt; <span>Option</span><span>&lt;</span><span>char</span><span>&gt;</span> {
</span></span><span><span>2</span><span>    self.source.get(self.pos <span>+</span> <span>1</span>).map(<span>|</span>c<span>|</span> <span>*</span>c <span>as</span> <span>char</span>)
</span></span><span><span>3</span><span>}
</span></span></code></pre></div><p>Instead of unwrapping and rewrapping the updated value:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>fn</span> <span>next</span>(<span>&amp;</span>self) -&gt; <span>Option</span><span>&lt;</span><span>char</span><span>&gt;</span> {
</span></span><span><span>2</span><span>    <span>match</span> self.source.get(self.pos <span>+</span> <span>1</span>) {
</span></span><span><span>3</span><span>        <span>Some</span>(c) <span>=&gt;</span> <span>Some</span>(<span>*</span>c <span>as</span> <span>char</span>),
</span></span><span><span>4</span><span>        _ <span>=&gt;</span> <span>None</span>,
</span></span><span><span>5</span><span>    }
</span></span><span><span>6</span><span>}
</span></span></code></pre></div><h3 id="map_or">map_or</h3><p>In a similar fashion, the sqleibniz parser uses <code>map_or</code> to return
the check for a type, but only if the current token is <code>Some</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>fn</span> <span>next_is</span>(<span>&amp;</span>self, t: <span>Type</span>) -&gt; <span>bool</span> {
</span></span><span><span>2</span><span>    self.tokens
</span></span><span><span>3</span><span>        .get(self.pos <span>+</span> <span>1</span>)
</span></span><span><span>4</span><span>        .map_or(<span>false</span>, <span>|</span>tok<span>|</span> tok.ttype <span>==</span> t)
</span></span><span><span>5</span><span>}
</span></span><span><span>6</span><span>
</span></span><span><span>7</span><span><span>fn</span> <span>is</span>(<span>&amp;</span>self, t: <span>Type</span>) -&gt; <span>bool</span> {
</span></span><span><span>8</span><span>    self.cur().map_or(<span>false</span>, <span>|</span>tok<span>|</span> tok.ttype <span>==</span> t)
</span></span><span><span>9</span><span>}
</span></span></code></pre></div><p>Again, replacing the not so idiomatic solutions:</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>fn</span> <span>next_is</span>(<span>&amp;</span>self, t: <span>Type</span>) -&gt; <span>bool</span> {
</span></span><span><span> 2</span><span>    <span>match</span> self.tokens.get(self.pos <span>+</span> <span>1</span>) {
</span></span><span><span> 3</span><span>        <span>None</span> <span>=&gt;</span> <span>false</span>,
</span></span><span><span> 4</span><span>        <span>Some</span>(token) <span>=&gt;</span> token.ttype <span>==</span> t,
</span></span><span><span> 5</span><span>    }
</span></span><span><span> 6</span><span>}
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span>fn</span> <span>is</span>(<span>&amp;</span>self, t: <span>Type</span>) -&gt; <span>bool</span> {
</span></span><span><span> 9</span><span>    <span>if</span> <span>let</span> <span>Some</span>(tt) <span>=</span> self.cur() {
</span></span><span><span>10</span><span>        <span>return</span> tt.ttype <span>==</span> t;
</span></span><span><span>11</span><span>    }
</span></span><span><span>12</span><span>    <span>false</span>
</span></span><span><span>13</span><span>}
</span></span></code></pre></div><h2 id="iterators-">Iterators 💖</h2><h3 id="filtering-characters">Filtering characters</h3><p>Rust number parsing does not allow <code>_</code>, sqlite number parsing
accepts <code>_</code>, thus the lexer also consumes them, but filters these
characters before parsing the input via the rust number parsing
logic:</p><div><pre tabindex="0"><code data-lang="rust"><span><span>1</span><span><span>let</span> <span>str</span> <span>=</span> self
</span></span><span><span>2</span><span>    .source
</span></span><span><span>3</span><span>    .get(start<span>..</span>self.pos)
</span></span><span><span>4</span><span>    .unwrap_or_default()
</span></span><span><span>5</span><span>    .iter()
</span></span><span><span>6</span><span>    .map(<span>|</span>c<span>|</span> <span>*</span>c <span>as</span> <span>char</span>)
</span></span><span><span>7</span><span>    .filter(<span>|</span>c<span>|</span> <span>*</span>c <span>!=</span> <span>&#39;_&#39;</span>)
</span></span><span><span>8</span><span>    .collect::<span>&lt;</span><span>String</span><span>&gt;</span>();
</span></span></code></pre></div><div id="callout"><h3>Tip</h3><p>I know you aren’t supposed to use <code>unwrap</code> and all derivates,
however in this situation the parser either way does not accept
empty strings as valid numbers, thus it will fail either way on
the default value.</p></div><p>In go i would have to first iterate the character list with a for
loop and write each byte into a string buffer (in which each write
could fail btw, or at least can return an <code>error</code>) and afterwards
I have to create a <code>string</code> from the <code>strings.Builder</code> structure.</p><div><pre tabindex="0"><code data-lang="go"><span><span>1</span><span>s <span>:=</span> source[start:l.pos]
</span></span><span><span>2</span><span>b <span>:=</span> strings.Builder{}
</span></span><span><span>3</span><span>b.<span>Grow</span>(<span>len</span>(s))
</span></span><span><span>4</span><span><span>for</span> _, c <span>:=</span> <span>range</span> s {
</span></span><span><span>5</span><span>    <span>if</span> c <span>!=</span> <span>&#39;_&#39;</span> {
</span></span><span><span>6</span><span>        b.<span>WriteByte</span>(c)
</span></span><span><span>7</span><span>    }
</span></span><span><span>8</span><span>}
</span></span><span><span>9</span><span>s = b.<span>String</span>()
</span></span></code></pre></div><h3 id="checking-characters">Checking characters</h3><p>Sqlite accepts hexadecimal data as blobs: <code>x&#39;&lt;hex&gt;&#39;</code>, to verify
the input is correct, I have to check every character in this
array to be a valid hexadecimal. Furthermore I need positional
information for correct error display, for this I reuse the
<code>self.string()</code> method and use the <code>chars()</code> iterator creating
function and the <code>enumerate</code> function.</p><div><pre tabindex="0"><code data-lang="rust"><span><span> 1</span><span><span>if</span> <span>let</span> <span>Ok</span>(str_tok) <span>=</span> self.string() {
</span></span><span><span> 2</span><span>    <span>if</span> <span>let</span> Type::<span>String</span>(<span>str</span>) <span>=</span> <span>&amp;</span>str_tok.ttype {
</span></span><span><span> 3</span><span>        <span>let</span> <span>mut</span> had_bad_hex <span>=</span> <span>false</span>;
</span></span><span><span> 4</span><span>        <span>for</span> (idx, c) <span>in</span> <span>str</span>.chars().enumerate() {
</span></span><span><span> 5</span><span>            <span>if</span> <span>!</span>c.is_ascii_hexdigit() {
</span></span><span><span> 6</span><span>                <span>// error creation and so on omitted here 
</span></span></span><span><span> 7</span><span><span></span>                had_bad_hex <span>=</span> <span>true</span>;
</span></span><span><span> 8</span><span>                <span>break</span>;
</span></span><span><span> 9</span><span>            }
</span></span><span><span>10</span><span>        }
</span></span><span><span>11</span><span>        <span>if</span> had_bad_hex {
</span></span><span><span>12</span><span>            <span>break</span>;
</span></span><span><span>13</span><span>        }
</span></span><span><span>14</span><span>
</span></span><span><span>15</span><span>        <span>// valid hexadecimal data in blob
</span></span></span><span><span>16</span><span><span></span>    }
</span></span><span><span>17</span><span>} <span>else</span> {
</span></span><span><span>18</span><span>    <span>// error handling omitted
</span></span></span><span><span>19</span><span><span></span>}
</span></span></code></pre></div><p>The error display produces the following error if an invalid
character inside of a blob is found:</p><p><img src="https://xnacly.me/rust_lex_parse/bad_blob.png" alt="invalid blob data"/></p><div id="callout"><h3>Info</h3><p>Thanks for reading this far 😼.</p><p>If you found an error (technical or semantic), please email me a nudge in the
right direction at <a href="mailto://contact@xnacly.me">contact@xnacly.me</a>
(<code>contact@xnacly.me</code>).</p></div></div></div>
  </body>
</html>
