<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.ian.stapletoncordas.co/2024/02/a-retrospective-on-requests">Original</a>
    <h1>A Retrospective on Requests</h1>
    
    <div id="readability-page-1" class="page"><div>
<section id="content">
  <header>
    <h2>
      <a href="https://blog.ian.stapletoncordas.co/2024/02/a-retrospective-on-requests" rel="bookmark" title="Permalink to \" a="" retrospective="" on="" requests\''="">A Retrospective on Requests</a></h2>
    
  </header>


  <!-- Rendered Content [[[ -->
  <div>
    <p>After writing my <a href="https://blog.ian.stapletoncordas.co/2024/01/a-retrospective-on-github3py">thoughts on github3.py</a> down here, someone was asking about
Python libraries that people recommend new Python developers read for learning
how to structure code and use the packaging systems. My initial reaction was
&#34;Don&#39;t listen to folks that tell you to read <tt><span>python-requests</span></tt> as a good example.&#34; When
asked for explanation, I gave it but realized that most people only know that
Requests does the right things for them for TLS and some other HTTP behaviour,
but I doubt anyone understands just how bad the project is internally.</p>
<div id="api-design">
<h2>API Design</h2>
<p>One thing many people can likely agree on is the design of the interface for
<tt><span>python-requests</span></tt> is (mostly) intuitive and lends itself to rapid development,
prototyping, and is very nice when working in a REPL. If you&#39;re unfamiliar,
here are some examples:</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span># Basic HTTP GET</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://requests.readthedocs.io/en/latest/&#34;</span>
<span>r</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
<span>print</span><span>(</span><span>r</span><span>.</span><span>text</span><span>)</span>

<span># Does the right thing with TLS</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://expired.badssl.com/&#34;</span>
<span>try</span><span>:</span>
   <span>r</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
<span>except</span> <span>requests</span><span>.</span><span>exceptions</span><span>.</span><span>SSLError</span><span>:</span>
   <span>print</span><span>(</span><span>&#34;Unable to verify expired certificate&#34;</span><span>)</span>


<span># POSTing JSON data easily without having to encode it yourself or specify</span>
<span># headers</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://httpbin.org/post&#34;</span>
<span>r</span> <span>=</span> <span>requests</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>json</span><span>=</span><span>{</span><span>&#34;some&#34;</span><span>:</span> <span>&#34;data&#34;</span><span>})</span>
</pre></div>
<p>The one problem here is how often people <em>stop</em> at the functions defined at
the root of the module. The way these functions work is by each instantiating
a new <tt>requests.Session</tt>. The <tt>Session</tt> object is so often forgotten and
ignored but can dramatically improve one&#39;s experience with <tt><span>python-requests</span></tt>. It is what
provides connection pooling (so if you&#39;re making repeated calls to the same
domain, it will attempt to keep connections alive for you, pool them, and
reuse them so there&#39;s less time spent setting up a connection) it provides a
way to configure many of the other aspects of the request that you otherwise
need to pass as function parameters, and many other ergonomic benefits.</p>
<div id="what-s-wrong-with-the-api">
<h3>What&#39;s Wrong with the API</h3>
<p>Well for one thing, what you see here is far from all of the API surface area.
There are <em>many</em> more parameters to the function, some of which cooperate with
each other and some of which don&#39;t. Above we already had the example of
sending JSON data; but before that many people have relied on other data
serialization formats. The next simplest looking one is
<tt><span>application/x-www-form-urlencoded</span></tt>. An example of how to do that with
<tt><span>python-requests</span></tt> is:</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span>s</span><span>:</span> <span>requests</span><span>.</span><span>Session</span> <span>=</span> <span>requests</span><span>.</span><span>Session</span><span>()</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://httpbin.org/post&#34;</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>data</span><span>=</span><span>{</span><span>&#34;urlencode&#34;</span><span>,</span> <span>&#34;me&#34;</span><span>})</span>
</pre></div>
<p>After that, because <tt><span>python-requests</span></tt> heavily depends on <tt>urllib3</tt>, we can easily
support <tt><span>multipart/form-data</span></tt>. That can be done in a few ways:</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span>s</span><span>:</span> <span>requests</span><span>.</span><span>Session</span> <span>=</span> <span>requests</span><span>.</span><span>Session</span><span>()</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://httpbin.org/post&#34;</span>
<span># Let&#39;s just send a file</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>files</span><span>=</span><span>{</span><span>&#34;fileA&#34;</span><span>:</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>&#34;rb&#34;</span><span>)})</span>
<span># NOTE: Do not use files this way, this is purely for simplicity of example</span>
<span># code</span>

<span># Let&#39;s send a file and some other form elements</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span>
   <span>url</span><span>,</span>
   <span>data</span><span>=</span><span>{</span><span>&#34;wait&#34;</span><span>:</span> <span>&#34;is this urlencoded too?&#34;</span><span>},</span>
   <span>files</span><span>=</span><span>{</span><span>&#34;fileA&#34;</span><span>:</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>&#34;rb&#34;</span><span>)},</span>
<span>)</span>

<span># Let&#39;s send two form fields, a basic file, and then a file with a custom</span>
<span># name, custom part content-type, and additional custom headers for the</span>
<span># part</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span>
   <span>url</span><span>,</span>
   <span>data</span><span>=</span><span>{</span><span>&#34;wait&#34;</span><span>:</span> <span>&#34;is this urlencoded too?&#34;</span><span>,</span> <span>&#34;form-encoded&#34;</span><span>:</span> <span>&#34;no&#34;</span><span>},</span>
   <span>files</span><span>=</span><span>{</span>
      <span>&#34;fileA&#34;</span><span>:</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>&#34;rb&#34;</span><span>),</span>
      <span>&#34;fileB&#34;</span><span>:</span> <span>(</span>
         <span>&#34;custom-filename.xml&#34;</span><span>,</span>
         <span>open</span><span>(</span><span>other_filename</span><span>,</span> <span>&#34;rb&#34;</span><span>),</span>
         <span>&#34;application/xml&#34;</span><span>,</span>
         <span>{</span><span>&#34;X-Custom-Part-Header&#34;</span><span>:</span> <span>&#34;value&#34;</span><span>},</span>
   <span>},</span>
<span>)</span>
</pre></div>
<p>If you&#39;re unavailable, these will look like:</p>
<div><pre><span></span>Content-Length: ...
Content-Type: multipart/form-data; boundary=---------------------------9051914041544843365972754266

-----------------------------9051914041544843365972754266
Content-Disposition: form-data; name=&#34;wait&#34;

is this urlencoded too?
-----------------------------9051914041544843365972754266
Content-Disposition: form-data; name=&#34;form-encoded&#34;

no
-----------------------------9051914041544843365972754266
Content-Disposition: form-data; name=&#34;fileA&#34;; filename=&#34;a.txt&#34;
Content-Type: text/plain

Content of a.txt.

-----------------------------9051914041544843365972754266
Content-Disposition: form-data; name=&#34;fileB&#34;; filename=&#34;custom-filename.xml&#34;
Content-Type: application/xml
X-Custom-Part-Header: value

&lt;root&gt;&lt;elems&gt;&lt;elem&gt;Item&lt;/elem&gt;&lt;/elems&gt;&lt;/root&gt;

-----------------------------9051914041544843365972754266--
</pre></div>
<p>This is primarily the last one but it has all the items because each request
builds upon the last.</p>
<p>Using <tt>data</tt> here, makes things confusing for a lot of people. Some expect
that value to be URL form encoded but it doesn&#39;t. Sometimes they expect that a
file in <tt>files</tt> be URL form encoded. And yes, these use-cases are documented
but if people don&#39;t know that they want to use <tt><span>multipart/form-data</span></tt>
encoding, they might not look at the section that describes that interaction.</p>
<p>Furthermore, what happens if someone does:</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span>s</span><span>:</span> <span>requests</span><span>.</span><span>Session</span> <span>=</span> <span>requests</span><span>.</span><span>Session</span><span>()</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://httpbin.org/post&#34;</span>
<span># This is broken, if you see this searching for how to handle things, don&#39;t</span>
<span># copy this but read below</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>json</span><span>=</span><span>{</span><span>&#34;a&#34;</span><span>:</span> <span>&#34;b&#34;</span><span>},</span> <span>files</span><span>=</span><span>{</span><span>&#34;fileA&#34;</span><span>:</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>&#34;rb&#34;</span><span>)})</span>
</pre></div>
<p>I expect no one could guess what the interaction <strong>unless</strong> they&#39;ve already
encountered this. The actual behaviour here is that the <tt>json</tt> argument is
completely ignored (well <a href="https://github.com/psf/requests/blob/96b22fa18c00831656ee4b286bf1c9062459b00a/src/requests/models.py#L494-L570">not completely</a>, we serialize the data and then throw it
away).</p>
<p>This leads to one other way in which users can easily frustrate themselves:</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span>s</span><span>:</span> <span>requests</span><span>.</span><span>Session</span> <span>=</span> <span>requests</span><span>.</span><span>Session</span><span>()</span>
<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;https://httpbin.org/post&#34;</span>
<span># This is broken, if you see this searching for how to handle things, don&#39;t</span>
<span># copy this but read below</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>json</span><span>=</span><span>{</span><span>&#34;a&#34;</span><span>:</span> <span>&#34;b&#34;</span><span>},</span> <span>headers</span><span>=</span><span>{</span><span>&#34;Content-Type&#34;</span><span>:</span> <span>&#34;application/xml&#34;</span><span>})</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>files</span><span>=</span><span>{</span><span>&#34;a&#34;</span><span>:</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>&#34;rb&#34;</span><span>)},</span> <span>headers</span><span>=</span><span>{</span><span>&#34;Content-Type&#34;</span><span>:</span> <span>&#34;multipart/form-data&#34;</span><span>})</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>data</span><span>=</span><span>{</span><span>&#34;form&#34;</span><span>:</span> <span>&#34;encoded&#34;</span><span>},</span> <span>headers</span><span>=</span><span>{</span><span>&#34;Content-Type&#34;</span><span>:</span> <span>&#34;multipart/form-data&#34;</span><span>})</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>url</span><span>,</span> <span>data</span><span>=</span><span>{</span><span>&#34;form&#34;</span><span>:</span> <span>&#34;encoded&#34;</span><span>},</span> <span>headers</span><span>=</span><span>{</span><span>&#34;Content-Length&#34;</span><span>:</span> <span>&#34;1000000&#34;</span><span>})</span>
<span># This may not do what some people expect. Many people tend to expect this</span>
<span># to  **replace** c=d to the query string, but instead it appends c=e so</span>
<span># the query string becomes a=b&amp;c=d&amp;c=e. In reality, there&#39;s no intuitive</span>
<span># behaviour here for everyone</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>post</span><span>(</span><span>&#34;https://httpbin.org/get?a=b&amp;c=d&#34;</span><span>,</span> <span>params</span><span>=</span><span>{</span><span>&#34;c&#34;</span><span>:</span> <span>&#34;e&#34;</span><span>})</span>
</pre></div>
<p>If you specify your own header above but are relying on Requests to serialize
native Python objects for you, you risk using the wrong Content-Type which
will cause at best <tt>400 Bad Request</tt> responses and at worst, <em>very</em> wrong
behaviour in a server. If you override the <tt><span>Content-Length</span></tt> header, that can
cause many other issues including intermediaries either terminating your
request before it reaches the destination, or them rewriting the header
(depending on the type of intermediary). Either way, it&#39;s not the behaviour
<em>indicated</em> by the code.</p>
</div>
<div id="how-could-it-be-better">
<h3>How Could It Be Better?</h3>
<p>This is a great API for a proof of concept and it makes things simple. That
said, it hides a lot of what it does and in some ways that causes issues for
users.</p>
<p>There are many ways this could be improved for users. There&#39;s no one right
answer here. Here are some ideas though that can help with some of the
problems above:</p>
<ol>
<li><p>Keep the semi-functional API but change how the parameters work:</p>
<ol>
<li>Get rid of <tt>json</tt> and <tt>files</tt>, consolidate everything into <tt>data</tt> <strong>but</strong>
provide classes like <tt>JSONData</tt> or <tt>MultipartFormData</tt> or
<tt>UrlEncodedFormData</tt> which can take the basic Python structures. These
classes would all implement a <a href="https://peps.python.org/pep-0544/">protocol</a> (or interface/<a href="https://docs.python.org/3/library/abc.html">abstract base class</a>)
allowing users that care about customizing aspects of this to do so. It&#39;s
them very explicit and obvious what the behaviour is.</li>
</ol>
<ol>
<li>Make the class above responsible for validating that conflicting headers
have not been specified and raising an exception otherwise. (Ideally this
logic is baked into the class users would inherit from so they need specify
an attribute with the headers they care about (with reasonable defaults)
and the base class would do the rest.)</li>
</ol>
<ol>
<li>Provide something a bit nicer than the class names suggested above that
is still clear enough</li>
</ol>
</li>
</ol>
<ol>
<li><p>Choose something a bit more familiar to other languages:</p>
<ol>
<li>Many other languages have a Request object that can be built up and
operated on. Many have excellent APIs around the way headers can be
manipulated.</li>
</ol>
<ol>
<li>Provide a builder object for the Request object to easily chain methods
together (this looks like the builders in <a href="https://cryptography.io/en/latest/">pyca/cryptography</a> or more
generically <a href="https://en.wikipedia.org/wiki/Builder_pattern">the builder pattern</a>)</li>
</ol>
</li>
</ol>
<p>I think the first would be the least disruptive and most likely to be accepted
by users, but to make it work well, I&#39;d be pretty firm about <tt>data</tt> not
accepting anything that doesn&#39;t implement the protocol.</p>
<p>The latter feels better long term though because I don&#39;t know many developers
that only work in Python and never in another language such that they haven&#39;t
seen the benefits of that pattern.</p>
</div>
</div>
<div id="tls-just-works">
<h2>TLS Just Worksâ„¢</h2>
<p>The feature that I think attracted <strong>most</strong> people to <tt><span>python-requests</span></tt> initially was how
easy it was to get verified TLS by default. This was not easy with
<tt>httplib</tt>/<tt>http.client</tt> or <tt>urllib</tt>, <tt>urllib2</tt>/<tt>urllib.request</tt> at
the time. <tt>httplib2</tt> and <tt>urllib3</tt> (both third-party HTTP clients) made it
easy to get verified TLS <em>if</em> you knew where your TLS trust bundle was. But
many users didn&#39;t. So the additional thing <tt><span>python-requests</span></tt> did was create <tt>certifi</tt>
to package the <a href="https://wiki.mozilla.org/index.php?title=CA/IncludedCertificates&amp;redirect=no">Mozilla Trust Bundle</a> and rely on that as well to always
provide a reliable source for a CA root trust bundle.</p>
<div id="until-it-doesn-t">
<h3>... Until It Doesn&#39;t</h3>
<p>Mozilla licenses most things under <a href="https://www.mozilla.org/en-US/MPL/2.0/">MPL 2.0</a> which is often argued about
whether or not it&#39;s permissible within various companies under policies (if
they have any) around open source libraries.</p>
<p>Further, many people create things that live in zip files as executables with
<tt><span>python-requests</span></tt> and Python&#39;s handling of files that are not python containing data that
are packaged appropriately and need to be accessed from that zip file from
code inside the zip file is not the greatest.</p>
<p>Additionally, people build those things but don&#39;t consider that potentially
someone might need to provide alternative settings for TLS:</p>
<ul>
<li>They might be talking to an internal hosted instance with a private CA and
private chain of trust. <tt>certifi</tt> will not be helpful there.</li>
<li>They may need to provide a client certificate and key to perform mutual TLS
authentication (a.k.a., mTLS).</li>
</ul>
<p>To remedy this, <tt><span>python-requests</span></tt> added support for the environment variables
<tt>CURL_CA_BUNDLE</tt> and <tt>REQUESTS_CA_BUNDLE</tt> to solve the first point. Great!
Fantastic! Except that up until recently, if you did <tt>export
REQUESTS_CA_BUNDLE=</tt> you effectively disabled all TLS verification for
anything using <tt><span>python-requests</span></tt> that sees that exported environment variable.</p>
</div>
<div id="and-it-s-a-bit-too-limited">
<h3>... And It&#39;s a Bit Too Limited</h3>
<p>When <tt><span>python-requests</span></tt> was created there was no <tt>ssl.SSLContext</tt> object in Python, and
only after Python 2.7&#39;s lifespan was increased did it get backported to 2.7.
Even still, it&#39;s continued to become a better and better interface to
configuring TLS for Python. We&#39;ve never had a good way to integrate that into
<tt><span>python-requests</span></tt> because of how that could interact with existing settings and
configurations. To make it easy to use, we&#39;d likely have to release a new
major version and create significant breaking changes. As it stands, the
current maintainers do not have enough time to:</p>
<ul>
<li>Implement those changes</li>
<li>Coach and review contributions for those changes</li>
<li>Handle the influx of people complaining about the changes or needing
assistance upgrading <a href="#footnote-1" id="footnote-reference-1">[1]</a></li>
</ul>
</div>
</div>
<div id="cookies">
<h2>Cookies</h2>
<p>Python comes with <tt>http.cookies</tt> and <tt>http.cookiejar</tt> and has had versions
of those since Python 2. For almost as long, there has been a custom cookie
jar implementation for <tt><span>python-requests</span></tt>. The idea is to make the cookie jar feel like a
Python dictionary. This might seem like a great ergonomic design, except that
it&#39;s possible for two different domains to set cookies in the same Session
with the same name, for example:</p>
<div><pre><span></span>Set-Cookie: sessionId=38afes7a8; Domain=example.com; Path=/user/home; HttpOnly; Secure; SameSite=strict
</pre></div>
<div><pre><span></span>Set-Cookie: sessionId=29bedt6b9; Domain=google.com; Path=/; HttpOnly; Secure; SameSite=strict
</pre></div>
<p>So if you use the same <tt>requests.Session</tt> for these cookies, how do you then
access the cookie jar by cookie name (e.g., <tt>sessionId</tt>)? You get an
exception!</p>
<p>That&#39;s not intuitive at all and it&#39;s why most (if not all) cookie jar
implementations in languages always want you to use a real method that
requires the domain name.</p>
<p>Ignoring the poorly thought out user experience, there&#39;s also a problem of
cookie jar policies not working correctly with the <tt><span>python-requests</span></tt> cookie jar and no
way to set a default one without significantly more work - so for the people
who do care, their lives are measurably worse than if the library hadn&#39;t tried
to handle cookies at all.</p>
</div>
<div id="timeouts">
<h2>Timeouts</h2>
<p><tt><span>python-requests</span></tt> supports setting timeouts per request, e.g.,</p>
<div><pre><span></span><span>import</span> <span>requests</span>

<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;...&#34;</span>
<span>s</span><span>:</span> <span>requests</span><span>.</span><span>Session</span> <span>=</span> <span>requests</span><span>.</span><span>Session</span><span>()</span>
<span># Timeout if connecting to the remote takes more than 2 seconds, or if it</span>
<span># takes more than 2 seconds for the remote to write bytes in response</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>timeout</span><span>=</span><span>2</span><span>)</span>
<span># Timeout after 2s during connect, after 10s if no data written</span>
<span>r</span> <span>=</span> <span>s</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>timeout</span><span>=</span><span>(</span><span>2</span><span>,</span> <span>10</span><span>))</span>
</pre></div>
<p>This works well, except, once again when the behaviour is surprising to the
user.</p>
<p><tt><span>python-requests</span></tt> will try each record in a DNS lookup when trying to connect to a
remote. If this is unclear to you, a DNS lookup on a domain can return
multiple results, e.g.,</p>
<div><pre><span></span>; &lt;&lt;&gt;&gt; DiG 9.18.20 &lt;&lt;&gt;&gt; salesforce.com
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 22322
;; flags: qr rd ra; QUERY: 1, ANSWER: 8, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; QUESTION SECTION:
;salesforce.com.                        IN      A

;; ANSWER SECTION:
salesforce.com.         120     IN      A       184.31.10.133
salesforce.com.         120     IN      A       184.31.3.130
salesforce.com.         120     IN      A       104.109.10.129
salesforce.com.         120     IN      A       184.25.179.132
salesforce.com.         120     IN      A       23.1.35.132
salesforce.com.         120     IN      A       23.1.99.130
salesforce.com.         120     IN      A       104.109.11.129
salesforce.com.         120     IN      A       23.1.106.133

;; Query time: 63 msec
;; MSG SIZE  rcvd: 171
</pre></div>
<p>So if we were making a request to <tt>salesforce.com</tt>, and the first seven IP
addresses were unreachable, you would be waiting approximately 14 seconds at
worst. Further if that eighth takes 1.8 seconds, your real-time wait (also
known as &#34;wall clock&#34;) is at least 15.8 seconds before you start receiving
data. If you have a different read timeout, the server can take almost up to
that to send the data. So let&#39;s say <tt>23.1.106.133</tt> takes 14 seconds to write
it&#39;s first byte and your timeout is set to 15 seconds, then your wall clock
experience is over 30 seconds. That&#39;s very different from 17 seconds like you
might otherwise expect.</p>
</div>
<div id="retries">
<h2>Retries</h2>
<p>Today, if you revisit the <a href="https://blog.ian.stapletoncordas.co/2024/02/requests-sslerror">SSLError example</a> and inspect
that exception itself you&#39;ll see something like:</p>
<div><pre><span></span>requests.exceptions.SSLError: HTTPSConnectionPool(host=&#39;expired.badssl.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError (SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)&#39;)))
</pre></div>
<p>This is quite difficult to read, but allow me to briefly parse this for you:</p>
<ol>
<li>First we caught a <tt>SSLCertVerificationError</tt> and re-raised that as an
<tt>SSLError</tt> with the original exception wrapped inside</li>
<li>Then we caught the <tt>SSLError</tt> in the retry logic built into <tt>urllib3</tt>
and realized we were out of retries so we wrapped the <tt>SSLError</tt> and
raised a <tt>MaxRetryError</tt> exception indicating we&#39;d exhausted retries</li>
<li>Then requests caught the <tt>MaxRetryError</tt>, inspected it and raised an
<tt>SSLError</tt> of it&#39;s own.</li>
</ol>
<p>What I want to emphasize here is point 2. This trips up so many users because
they see <tt>Max retries exceeded with url:</tt> and didn&#39;t explicitly configure
retries so they assume <tt><span>python-requests</span></tt> is doing something intelligent. It&#39;s not, it&#39;s
setting <tt>max_retries=0</tt> by default.</p>
<p>To be clear, this isn&#39;t related to us attempting to connect to multiple
addresses in a DNS record either. This is purely, &#34;we&#39;ve established a
connection and are retrying the request&#34;.</p>
<p>There are a few ways to configure retries today in <tt><span>python-requests</span></tt> that <a href="https://blog.ian.stapletoncordas.co/2014/12/retries-in-requests">I&#39;ve
already documented here</a>. What would be better would be to not have to reach
into <tt>urllib3</tt> at all. Further, it would be significantly better if the
exceptions weren&#39;t converted to strings such that after a layer or two you no
longer can inspect the exceptions themselves. Again, if I show some examples
of the exception above:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>sslerr</span>
<span>SSLError</span><span>(</span><span>MaxRetryError</span><span>(</span><span>&#34;HTTPSConnectionPool(host=&#39;expired.badssl.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)&#39;)))&#34;</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>sslerr</span><span>.</span><span>args</span>
<span>(</span><span>MaxRetryError</span><span>(</span><span>&#34;HTTPSConnectionPool(host=&#39;expired.badssl.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)&#39;)))&#34;</span><span>),)</span>
<span>&gt;&gt;&gt;</span> <span>sslerr</span><span>.</span><span>args</span><span>[</span><span>0</span><span>]</span>
<span>MaxRetryError</span><span>(</span><span>&#34;HTTPSConnectionPool(host=&#39;expired.badssl.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)&#39;)))&#34;</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>sslerr</span><span>.</span><span>args</span><span>[</span><span>0</span><span>]</span><span>.</span><span>args</span>
<span>&#34;HTTPSConnectionPool(host=&#39;expired.badssl.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)&#39;)))&#34;</span>
</pre></div>
<p>This hides a great deal of information from the user which is not present in
either the <tt>SSLError</tt> or <tt>MaxRetryError</tt> exception instances.</p>
<p>Without being able to introspect things you don&#39;t get a great way of detecting
what happened in your code to more intelligently handle an exception.</p>
<p>To be clear, <tt>urllib3</tt> &#39;s retries are <em>excellent</em>, but for <tt><span>python-requests</span></tt> users, it
doesn&#39;t behave exactly as they&#39;d expect. They don&#39;t get any information about
what happened and they have very little visibility into how it all works since
it happens in a different place. Furthermore, if they have some code that
integrates with a <tt>Session</tt> object to authenticate or track a rate-limit,
then this does not interact with that at all. As a result, a lot of
functionality is lost when those users end up using <tt>urllib3</tt> retries
(because there are no <tt><span>python-requests</span></tt> retries).</p>
<p>As an interim to anything improving in <tt><span>python-requests</span></tt> (which it likely won&#39;t), I
<strong>strongly</strong> recommend <a href="https://github.com/hynek/stamina">stamina</a></p>
<!-- commented out

.. _urllib3-maxretry-sslerror
.. code-block:: python

   import urllib3
   import urllib3.exceptions

   pm = urllib3.PoolManager()
   try:
       pm.request("GET", "https://expired.badssl.com")
   except urllib3.exceptions.MaxRetryError as err:
       print(f"{err=}")
       print(f"{err.url=}")
       print(f"{err.reason=}")
       print(f"{err.reason.args}")
       print(f"{err.reason.args[0].errno=} {err.reason.args[0].library=} "
             f"{err.reason.args[0].verify_code=} "
             f"{err.reason.args[0].verify_message=}")

This prints:

.. code-block:: text
   :linenos:

   err=MaxRetryError("HTTPSConnectionPool(host='expired.badssl.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)')))")
   err.url='/'
   err.reason=SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)'))
   (SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)'),)
   err.reason.args[0].errno=1 err.reason.args[0].library='SSL' err.reason.args[0].verify_code=10 err.reason.args[0].verify_message='certificate has expired'

Which I share to show how much more usable that is for introspection of an
error and smart error handling. Even still -->
</div>
<div id="transport-adaptors">
<h2>Transport Adaptors</h2>
<p>Transport Adapters <a href="#footnote-2" id="footnote-reference-2">[2]</a>  were a great idea that were introduced in 1.0. These
were intended to help users customize the behaviour of things and allow them
to support URI schemes other than <tt>http</tt> and <tt>https</tt> (e.g., <tt>file</tt>,
<tt>unix</tt>). This is an undisputed success (with a bunch of bumps along the
way). There are libraries that implement those two popular schemes already.</p>
<p>Where things tend to fall apart is when you look at what can be specified in a
Transport Adapter. <tt><span>python-requests</span></tt> uses a <tt>urllib3.PoolManager</tt> for the default
<tt>HTTPAdapter</tt>. There are configuration options for that manager that are
configurable in the default adapter so folks who know they need to alter those
can create a new one with the values they want to use. The problem occurs when
there are other options or request parameters that at this point <em>need</em> to be
specified at the adapter layer. If there are additional options you want to
configure on the connection&#39;s socket, you need to effectively sub-class the
<tt>HTTPAdapter</tt> to add things to the initialization of the <tt>PoolManager</tt>.
<a href="#footnote-3" id="footnote-reference-3">[3]</a>.</p>
<p>If you&#39;ve ever used Golang&#39;s <tt>net/http</tt> library, you may have seen that the
<tt>Client</tt> type has a <tt>Transport</tt> member defined as an interface
<tt>RoundTripper</tt> <a href="#footnote-4" id="footnote-reference-4">[4]</a>. A popular pattern looks like:</p>
<div><pre><span></span><span>import</span><span> </span><span>&#34;net/http&#34;</span>

<span>type</span><span> </span><span>CustomTransport</span><span> </span><span>struct</span><span> </span><span>{</span>
<span>   </span><span>T</span><span> </span><span>http</span><span>.</span><span>RoundTripper</span>
<span>}</span>

<span>func</span><span> </span><span>(</span><span>t</span><span> </span><span>CustomTransport</span><span>)</span><span> </span><span>RoundTrip</span><span>(</span><span>req</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>(</span><span>*</span><span>http</span><span>.</span><span>Response</span><span>,</span><span> </span><span>error</span><span>)</span><span> </span><span>{</span>
<span>   </span><span>newReq</span><span> </span><span>:=</span><span> </span><span>modifyRequest</span><span>(</span><span>req</span><span>)</span>
<span>   </span><span>return</span><span> </span><span>t</span><span>.</span><span>T</span><span>.</span><span>RoundTrip</span><span>(</span><span>req</span><span>)</span>
<span>}</span>

<span>func</span><span> </span><span>modifyRequest</span><span>(</span><span>req</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span> </span><span>{</span>
<span>   </span><span>reqCopy</span><span> </span><span>:=</span><span> </span><span>new</span><span>(</span><span>http</span><span>.</span><span>Request</span><span>)</span>
<span>   </span><span>*</span><span>reqCopy</span><span> </span><span>=</span><span> </span><span>*</span><span>req</span>
<span>   </span><span>// Do something with copy</span>
<span>   </span><span>return</span><span> </span><span>reqCopy</span>
<span>}</span>

<span>func</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span>
<span>   </span><span>client</span><span> </span><span>:=</span><span> </span><span>&amp;</span><span>http</span><span>.</span><span>Client</span><span>{</span>
<span>      </span><span>Transport</span><span>:</span><span> </span><span>CustomTransport</span><span>{</span><span>http</span><span>.</span><span>DefaultClient</span><span>.</span><span>Transport</span><span>},</span>
<span>   </span><span>}</span>
<span>}</span>
</pre></div>
<p>This is very easy to compose multiple transports. Behaviour like this is not
easily or readily implemented with <tt><span>python-requests</span></tt>. It&#39;s possible depending on how you
structure things or need them to work, but by and large, most people can&#39;t do
this because of what they tend to want to change in their custom adapter. This
means that if you find yourself needing a custom adapter, you suddenly need to
understand a lot more about both <tt><span>python-requests</span></tt> and <tt>urllib3</tt> as well as how the
adapter is used in <tt><span>python-requests</span></tt>. This is the right idea, but the wrong
implementation and at this point, it&#39;s very hard to fix without breaking lots
of users.</p>
</div>
<div id="request-preparation">
<h2>Request Preparation</h2>
<p>As you may have guessed from my <a href="https://blog.ian.stapletoncordas.co/2024/01/a-retrospective-on-github3py">thoughts on github3.py</a>, I have strong
opinions about things that need to be simple. Today, under the covers the API
functional parameters are converted to a <tt>Request</tt> object which is then
&#34;prepared&#34; into a <tt>PreparedRequest</tt>. The <tt>PreparedRequest</tt> is mutable and
is what does all of the preparation. All of the code that prepares thing is
tied to the <tt>PreparedRequest</tt> class. Organization aside, these classes are
intended to be the interface for people who want to do things very differently
from how <tt><span>python-requests</span></tt> intends. Do you want to do weird things with your URL? Use
a <tt>Request</tt>, <tt>prepare()</tt> it, then <tt>Session.send()</tt> it. What could go
wrong? Well:</p>
<ul>
<li>authentication is stored as a property on a <tt>Session</tt>, is a parameter to
the functional API, and is also something you can attach to a <tt>Request</tt></li>
<li>likewise, a <tt>Session</tt> stores cookies and will attach them to appropriate
requests (based on the cookie settings) and you can pass cookies into your
request</li>
<li>headers can be set on a <tt>Session</tt> and are sent into a <tt>Request</tt> as well</li>
</ul>
<p>So what happens when you need to use this flow? Well, for that reason we added
<tt>Session.prepare_request</tt> but still there are issues people run into. Some
people use this flow to avoid aspects of a <tt>Session</tt> but the most reliable
way of getting what you expect from the flow is to involve the <tt>Session</tt>.</p>
</div>
<div id="authentication">
<h2>Authentication</h2>
<p>By and large, this actually typically works pretty well. If you&#39;re using a
<tt>Session</tt> to only ever talk to one remote, you can attach the authentication
to the <tt>Session</tt> and have it applied to every request. If you&#39;re not, the
basic authentication types that you can attach to a request don&#39;t really
understand that. It is trivial to write something, however, that does
understand that as an authentication handler for Requests (<a href="https://toolbelt.readthedocs.io/en/latest/authentication.html#authhandler">requests-toolbelt
has a handler for this</a>). Beyond that, as I alluded to above when talking
about retries, if you want to leverage the excellent retry logic baked into
urllib3, you no longer get the authentication handler to apply it&#39;s context to
a new request. So even the toolbelt&#39;s authentication handler couldn&#39;t handle
the case where you&#39;ve told it how to manage credentials for 2 or more domains
and one redirects you to the other. If urllib3 handles that redirect as part
of it&#39;s retry logic, then you&#39;ll likely end up with an exception instead of a
response that can trigger the re-authentication flow.</p>
</div>
<div id="internal-design-may-be-artful-but-it-s-not-good-software">
<h2>Internal Design May Be Artful, But It&#39;s Not Good Software</h2>
<p>After receiving our first security disclosure, I was told that Requests wasn&#39;t
a serious project but instead one person&#39;s art project and thus we shouldn&#39;t
fix the vulnerability. This was despite the project being touted as being used
by multiple international government agencies, political campaigns, and
boasting about it&#39;s #1 download spot on PyPI. So when I say it might be
artful, I&#39;m trying to take a neutral stance on what is art and what isn&#39;t art
and whether the internals of Requests are actually beautiful art.</p>
<p>As far as I&#39;m concerned, the factoring of the code is very poor. It makes it
borderline unmaintainable.</p>
<div id="sessionredirectmixin">
<h3><tt>SessionRedirectMixin</tt></h3>
<p>Requests handles redirects because early on, urllib3 either didn&#39;t or it&#39;s
handling elided the intermediate request and response history hiding it from
the user (I really don&#39;t remember which). Either way, in the great 1.0
refactor that pissed off nearly every user and wiped out all of the hard
fought test coverage, we got a <a href="https://en.wikipedia.org/wiki/Mixin">mixin class</a> that is only ever mixed into a
single class which it shares a module with. The class has a lot of redirect
logic in it and it expects a lot of methods and properties that are defined on
the class it&#39;s mixed into. In other words, it&#39;s not really a mixin. It&#39;s also
not a neat abstraction or useful refactoring.</p>
<p>I think it could have been a step in the right direction with code that didn&#39;t
expect to have the ability to make a new request but instead took
&#34;configuration&#34; and spat out an instruction to the Session as to what to do
next (follow the redirect, stop due to a non-redirect status, etc.). That is
not what we got.</p>
</div>
<div id="utils">
<h3>utils</h3>
<p>Requests has always had modules intended for its use and only its use. At some
point, we tried to document them for ourselves and that led to people using
them externally and then filing bugs against them. This is a perfect example
of 3 adults who did not consent explicitly to the use, but Python says that we
must have because we didn&#39;t hide them well enough.</p>
</div>
<div id="connection-pooling">
<h3>Connection Pooling</h3>
<p>One feature requests always advertised as if it was its own was connection
pooling. However, that feature was always based entirely on urllib3&#39;s
connection pooling logic. And on top of that, we didn&#39;t even use it correctly.</p>
<p>Today, each Transport Adapter instantiates its own <a href="https://urllib3.readthedocs.io/en/stable/reference/urllib3.poolmanager.html#urllib3.PoolManager">PoolManager</a>. This is to
avoid having to manage <a href="https://urllib3.readthedocs.io/en/stable/reference/urllib3.connectionpool.html">Connection Pools</a> in the Transport Adapter. However,
a single Pool Manager could be used for both adapters without issue. There&#39;s
no security reason not to do this and certainly no performance reason to
prefer separate pools.</p>
</div>
</div>
<div id="requests-often-believes-it-knows-better-than-urllib3">
<h2>Requests Often Believes It Knows Better than urllib3</h2>
<p>Until <a href="https://github.com/psf/requests/pull/6226/files">recently</a>, Requests worked around urllib3 to do chunked
transfer-encoding requests. This required digging into urllib3 a bit more than
that library reasonably expects users to do and introduced bugs long term as
urllib3 continued to evolve. On its face this is one of those technical debt
items that makes sense in the moment but in reality should have been
contributed to urllib3 and then immediately removed from Requests.</p>
<p>I can speak for the fact that we (the current maintainers) just don&#39;t have
that kind of time but this ties back into a post I wrote recently about <a href="https://blog.ian.stapletoncordas.co/2023/11/no-should-be-your-default">saying
no</a>. If I had known better, I would absolutely have argued against
accepting this in <tt><span>python-requests</span></tt> at all. That would have provided some pressure to
move this to urllib3 directly and make it work for <tt><span>python-requests</span></tt> rather than the
opposite way things happened.</p>
</div>
<div id="proxies">
<h2>Proxies</h2>
<p>While <tt><span>python-requests</span></tt> can handle proxies, it can&#39;t handle sophisticated proxies that
modern businesses rely on as well. Specifically, its support for TLS over
HTTPS proxies is very poor. In order to support internal proxies that likely
have their own trust bundles, we would need to significantly change the API of
Requests. There are many ways we could do this, but every time we add to the
API, it adds to the maintenance burden and it invariably upsets someone.</p>
<p>There was a very promising <a href="https://github.com/psf/requests/pull/5665">pull request to add support for HTTPS proxies</a>
and it does <em>the right thing</em> by relying on the logic in urllib3. However,
adding that support correctly creates a conundrum. How do we support those
custom TLS bundles? The change goes about this by expanding the API by adding
a parameter to the API. The number of parameters to the request methods is
already huge and there is no end of drift between the documentation of those
parameters on the various places they&#39;re supported.</p>
<p>My preference here is to do something that makes what is happening clearer,
but that&#39;s also a different kind of API expansion. More directly, I&#39;d like to
continue supporting the current way of specifying proxies as a dictionary
mapping the protocol to the proxy URI and then translate that to a dictionary
that maps the protocol to an object that holds the configuration. Then for
folks that know what they need for this, they can instead reach for that
object directly, e.g.,</p>
<div><pre><span></span><span>import</span> <span>ssl</span>

<span>import</span> <span>requests</span>
<span>from</span> <span>requests.proxies</span> <span>import</span> <span>Proxies</span> <span>Proxy</span>

<span>proxy_ssl_context</span> <span>=</span> <span>ssl</span><span>.</span><span>SSLContext</span><span>()</span>
<span>proxy_ssl_context</span><span>.</span><span>load_verify_location</span><span>(</span><span>cafile</span><span>=</span><span>&#34;/etc/pki/corp.net/cacerts.pem&#34;</span><span>)</span>
<span>proxy_ssl_context</span><span>.</span><span>verify_mode</span> <span>=</span> <span>ssl</span><span>.</span><span>CERT_REQUIRED</span>

<span>url</span><span>:</span> <span>str</span> <span>=</span> <span>&#34;...&#34;</span>
<span>proxies</span> <span>=</span> <span>Proxies</span><span>.</span><span>from_dict</span><span>({</span>
   <span>&#34;http&#34;</span><span>:</span> <span>&#34;http://plain.proxy&#34;</span><span>,</span>
   <span>&#34;https&#34;</span><span>:</span> <span>Proxy</span><span>(</span>
      <span>uri</span><span>=</span><span>&#34;https://encrypted.proxy&#34;</span><span>,</span>
      <span>ssl_context</span><span>=</span><span>proxy_ssl_context</span><span>,</span>
   <span>),</span>
<span>})</span>
<span>r</span><span>:</span> <span>requests</span><span>.</span><span>Response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>proxies</span><span>=</span><span>proxies</span><span>)</span>
</pre></div>
<p>Under the covers, any dictionary that was the prior API would be transparently
converted to this <tt>Proxies</tt> object. The difficulty here is that <tt>Session</tt>
has an attribute called <tt>proxies</tt> and people expect it to be a dictionary
(reasonably so because that&#39;s what it has been for roughly a decade). This
brings us then to the next pattern I truly abhor.o</p>
</div>
<div id="compatibility-objects-that-pretend-to-be-standard-types">
<h2>Compatibility Objects That Pretend To Be Standard Types</h2>
<p>So many things were initially designed to be a simple built-in type in Python
and as the user base grew we found that to be insufficient. We always need
something that gives us the ability to do things that give users an escape
hatch of sorts to do more complex things.</p>
<p>To then preserve backwards compatibility, we reach for the ability to
implement those interfaces into the new objects and pretend that the code
relying on the old thing will just continue to work. This almost always goes
sideways eventually.</p>
<p>For one thing, the already often incorrect typeshed hints for <tt><span>python-requests</span></tt> are
immediately wrong again. For another, people tend to make changes in <tt><span>python-requests</span></tt> as
drive-by contributions that end up breaking these subtly which we don&#39;t
discover for quite a while because they&#39;re so subtle.</p>
</div>
<div id="test-coverage-is-abysmal">
<h2>Test Coverage Is Abysmal</h2>
<p>Of course, everything above is both a contributing factor to and a result of
the abysmal test coverage in <tt><span>python-requests</span></tt>. The measure of coverage may not itself be
horrible. But the test cases are not an appropriate number of permutations to
determine the behaviour of some of the things users try that are not wise or
advisable. As a result, sometimes something appears to work for a given user
and when something else changes subtly it is broken. In reality, the API
should have been designed to prevent those things from ever working but that
never happened and breaking that now would appear to many as a violation of
backwards compatibility.</p>
</div>
<div id="stable-apis-and-behaviour">
<h2>Stable APIs and Behaviour</h2>
<p>Last but not least, after 1.0 there was a very concerted effort to not break
users like that again, ever. That has led to a significant amount of friction
in <tt><span>python-requests</span></tt>. We struggle often to be able to make an informed decision about
what will not cause issues for users versus what will. This means that
completely reasonable requests are blocked until we have the time and ability
to make a backwards incompatible release (e.g., 3.0 - which itself already has
a lot of baggage tied to it). This leads invariably to frustrated users and
maintainers.</p>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>There&#39;s a lot of history in <tt><span>python-requests</span></tt>. There&#39;s a lot of reasons for it to have
existed but there&#39;s also a lot of reasons why despite it&#39;s &#34;for Humans&#34;
tag line, it really doesn&#39;t feel that way for a lot of people.</p>
<p>There&#39;s a lot that can be improved, but really if you&#39;re asking yourself why
hasn&#39;t it been just look back at the very last section. The project
effectively has had it&#39;s feet cemented to the ground by one very disruptive
release many years ago and hasn&#39;t been able to move on. Similarly, we&#39;d love
to fix a lot of these, and I&#39;ve started countless times to try to redesign
things with backwards compatibility to allow us to move past these, but those
changes are huge refactors that we just don&#39;t have the appetite for as a team
of three. Beyond that, we struggle with what to name the next version.</p>
<p>A lot of promises were made without any apparent intention of following
through on them for a 3.0 release. <a href="#footnote-5" id="footnote-reference-5">[5]</a> And now, if we were to release a 3.0,
we&#39;d have to explain why all that promised work wasn&#39;t done (and to the folks
that sent money, what happened to their money).</p>
<p>In short, the project feels dead. That&#39;s a shame, but that&#39;s my feeling on the
matter. It&#39;s hard to introduce new, necessary, and beneficial features. It&#39;s
hard to fix gnarly bugs. It&#39;s hard to improve the user experience and it&#39;s
consistently been because of one particular person over the years. A few of us
have tried to bring that stability but it has never seemed to be enough.</p>
</div>


  </div>
  <!-- Rendered Content ]]] -->
  <!-- Footer Post Info [[[ -->
  
  <!-- Footer Post Info ]]] -->
</section>
<!-- Table of Contents [[[ -->
<!--
<aside class="toc-drawer">
  <nav class="toc">
    <div class="toc-sticky toc-scroll">
      
    </div>
  </nav>
</aside>
-->
<!-- Table of Contents ]]] -->
    </div></div>
  </body>
</html>
