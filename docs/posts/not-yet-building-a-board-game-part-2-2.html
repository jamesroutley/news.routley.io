<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.cyang.page/blog/3tier_tla_part_2">Original</a>
    <h1>Not yet building a board game, part 2/2</h1>
    
    <div id="readability-page-1" class="page"><div lang="en">
    <header>
        
        <h3>at least I tried…</h3>
        
    </header>
    
<p>
Continue from <a href="https://blog.cyang.page/3tier_tla_part_1/">part 1</a></p>
<p>
Until now we’ve only checked that the client requests will “eventually” be processed. Works fine, but not realistic, usually clients would not want to wait long.</p>
<p>
We improve our model to be more realistic and detailed, here are the full <a href="https://gist.github.com/cyang-el/c34272279623135dd6e36beb0826b493">.tla</a> and <a href="https://gist.github.com/cyang-el/c34272279623135dd6e36beb0826b493">.cfg</a> files.</p>
<h2 id="tick">
tick
</h2>
<p>
Before doing anything, we need to add “time” into our model,</p>
<p>
We do that by introducing ticks into our model, by first adding a variable <code>t</code>, it increments at every “next” step.</p>
<p>
While we’re at it, I also added an key-value map <code>age</code> tracking how many ticks has a pending request been hanging out in our system, as its time spent should also increment together with tick.</p>
<div>
<div>
<pre><code><span><span>Tick ==
</span></span><span><span>  /\ t&#39; = t + 1
</span></span><span><span>  /\ age&#39; = [rq \in pReq |-&gt; age[rq] + 1]</span></span></code></pre>
</div>
</div>
<h2 id="metrics">
metrics
</h2>
<p>
I also added some other <del>lazily named</del> SLA metrics to our system, they are</p>
<ul>
<li>total number of requets: tReq</li>
<li>client requests made, i.e. inbound buffer: cReq</li>
<li>number of timedout requests: toutReq</li>
<li>average ticks spent finishing: avgTime</li>
<li>maximum number of requests being processed (queued) by any one sever: maxLoad</li>
</ul>
<p>Wrapping these into a “metrics object” by,</p>
<div>
<div>
<pre><code><span><span>mtrcs \in [
</span></span><span><span> tReq: Nat,
</span></span><span><span> cReq: Nat,
</span></span><span><span> toutReq: Nat,
</span></span><span><span> avgTime: Nat,
</span></span><span><span> maxLoad: Nat
</span></span><span><span>]</span></span></code></pre>
</div>
</div>
<h2 id="client-request">
client request
</h2>
<p>
Now we model what happens when a client makes a request more realistically,</p>
<p>
First, there’s usually rate limiting, here we are saying that a client should not be requesting more often than 1 tick,</p>
<div>
<div>
<pre><code><span><span>NewReq(c) ==
</span></span><span><span>  /\ t &gt;= lastReq[c] + ReqRate</span></span></code></pre>
</div>
</div>
<p>
and then I want to add something I feel is sometimes mentioned too little when designing some sort of load guard for systems, <a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a>.</p>
<p>
We want to only allow client request to take place when there’s less than 10 requests pending in our system.</p>
<div>
<div>
<pre><code><span><span>  /\ Cardinality(pReq) &lt; 10</span></span></code></pre>
</div>
</div>
<p>
We build a request “object” by assigning an <strong>nid</strong> that’s just an incrementing number for the total amount of requests that’s been created, along with the client who lauched it and the time. Notice the use of <strong>LET…IN</strong> syntax here, it’s the same as the ones in OCaml, think of it as Ruby/Python’s default arguments, which we use to introduce some calculated values into the proceeding context.</p>
<div>
<div>
<pre><code><span><span>  /\ LET
</span></span><span><span>     nid == mtrcs.tReq + 1
</span></span><span><span>     req == [c |-&gt; c, id |-&gt; nid, subTime |-&gt; t]
</span></span><span><span>     IN</span></span></code></pre>
</div>
</div>
<p>
And then we update the next states when a new request happens,</p>
<ol>
<li>we add the new request to the collection of made client request, i.e. inbound buffer, cReq,</li>
<li>also add the request to the collection of pending requests pReq,</li>
<li>setting the initial “age” of the request to “0”,</li>
<li>and increment the total number of requests in our metrics,</li>
</ol>
<div>
<div>
<pre><code><span><span>  /\ cReq&#39; = cReq \union {[c |-&gt; c, id |-&gt; nid]}
</span></span><span><span>  /\ pReq&#39; = pReq \union {req}
</span></span><span><span>  /\ age&#39; = age @@ (req :&gt; 0)
</span></span><span><span>  /\ lastReq&#39; = [lastReq EXCEPT ![c] = t]
</span></span><span><span>  /\ mtrcs&#39; = [mtrcs EXCEPT !.tReq = nid]</span></span></code></pre>
</div>
</div>
<h2 id="server">
server
</h2>
<h3 id="picks-up-request">
picks up request
</h3>
<p>
We start by checking</p>
<ol>
<li>there are still client requet in the inbound buffer</li>
<li>picking a server that’s with capacity</li>
</ol>
<div>
<div>
<pre><code><span><span>Accept ==
</span></span><span><span>  /\ cReq /= {}
</span></span><span><span>  /\ \E s \in Srv :
</span></span><span><span>      /\ Cardinality({r \in sProc : r.s = s}) &lt; SrvCap</span></span></code></pre>
</div>
</div>
<p>
Then the server takes the oldest request and tags itself to the request and then put it into the server queue before removing the request from the inbound buffer,</p>
<div>
<div>
<pre><code><span><span>/\ LET
</span></span><span><span>   oReq == CHOOSE r \in cReq :
</span></span><span><span>           \A o \in cReq : r.id &lt;= o.id
</span></span><span><span>   sReq == [c |-&gt; oReq.c, id |-&gt; oReq.id, s |-&gt; s,
</span></span><span><span>           arrTime |-&gt; t]
</span></span><span><span> IN
</span></span><span><span> /\ sQueue&#39; = sQueue \union {sReq}
</span></span><span><span> /\ cReq&#39; = cReq \ {oReq}</span></span></code></pre>
</div>
</div>
<h3 id="process-request">
process request
</h3>
<p>
The server takes the oldest request from its queue and then starts processing it, we represent this by putting the request into the server’s process set and initialize the progress counter for the process to be “0”.</p>
<div>
<div>
<pre><code><span><span>  Start ==
</span></span><span><span>  /\ sQueue /= {}
</span></span><span><span>    /\ LET
</span></span><span><span>  oReq == CHOOSE r \in sQueue :
</span></span><span><span>    \A o \in sQueue : r.arrTime &lt;= o.arrTime
</span></span><span><span>    procReq == [c |-&gt; oReq.c, id |-&gt; oReq.id, s |-&gt; oReq.s,
</span></span><span><span>                sTime |-&gt; t]
</span></span><span><span>    IN
</span></span><span><span>  /\ sProc&#39; = sProc \union {procReq}
</span></span><span><span>       /\ progress&#39; = progress @@ (procReq :&gt; 0)
</span></span><span><span>       /\ sQueue&#39; = sQueue \ {oReq}</span></span></code></pre>
</div>
</div>
<p>
And then we need to describe how the progress move forward with the server processing the request, we do so by incrementing the progress, note that the time it takes for a process to finish is a constant here,</p>
<div>
<div>
<pre><code><span><span>  Proc ==
</span></span><span><span>  /\ sProc /= {}
</span></span><span><span>    /\ \E r \in sProc :
</span></span><span><span>        /\ progress[r] &lt; ProcTime
</span></span><span><span>        /\ progress&#39; = [progress EXCEPT ![r] = @ + 1]</span></span></code></pre>
</div>
</div>
<p>
we should update the server loading metric with each tick, in <strong>Tick</strong>, including what we have already put in, the whole tick increment looks like,</p>
<div>
<div>
<pre><code><span><span>  Tick ==
</span></span><span><span>    /\ t&#39; = t + 1
</span></span><span><span>    /\ age&#39; = [rq \in pReq |-&gt; age[rq] + 1]
</span></span><span><span>    /\ LET
</span></span><span><span>         loads == {Cardinality({rq \in sProc : rq.s = s}) : s \in Srv}
</span></span><span><span>         mLoad == IF loads = {} THEN 0 ELSE Max(loads)
</span></span><span><span>       IN
</span></span><span><span>       /\ mtrcs&#39; = [mtrcs EXCEPT
</span></span><span><span>                   !.maxLoad = IF mLoad &gt; @ THEN mLoad ELSE @]</span></span></code></pre>
</div>
</div>
<h3 id="finish-processing-a-request">
finish processing a request
</h3>
<p>
For any request that’s currently being processed, if its process time has reached the constant process time specified by us, we consider that process to be done.</p>
<div>
<div>
<pre><code><span><span>  Finish ==
</span></span><span><span>    /\ \E req \in sProc :
</span></span><span><span>        /\ progress[req] &gt;= ProcTime
</span></span><span><span>        /\ LET
</span></span><span><span>             pr == CHOOSE p \in pReq : p.c = req.c /\ p.id = req.id</span></span></code></pre>
</div>
</div>
<p>
As a request has been successfully processed, we log some metrics, for instance the response time,</p>

<p>
then we can create our response,</p>
<div>
<div>
<pre><code><span><span>  resp == [c |-&gt; req.c, id |-&gt; req.id,
</span></span><span><span>           resp |-&gt; dta[CHOOSE d \in DB : TRUE],
</span></span><span><span>           rTime |-&gt; rt]</span></span></code></pre>
</div>
</div>
<p>
and calculate the average response time,</p>
<div>
<div>
<pre><code><span><span>  oldAvg == mtrcs.avgTime
</span></span><span><span>  cnt == mtrcs.cReq
</span></span><span><span>  newAvg == IF cnt = 0
</span></span><span><span>            THEN rt
</span></span><span><span>            ELSE (oldAvg * cnt + rt) \div (cnt + 1)</span></span></code></pre>
</div>
</div>
<p>
Last step, accordingly we update our response set, pending requests, request age, server process, progress list and our metrics,</p>
<div>
<div>
<pre><code><span><span>  IN
</span></span><span><span>  /\ cResp&#39; = cResp \union {resp}
</span></span><span><span>  /\ pReq&#39; = pReq \ {pr}
</span></span><span><span>  /\ age&#39; = [x \in pReq&#39; |-&gt; age[x]]
</span></span><span><span>  /\ sProc&#39; = sProc \ {req}
</span></span><span><span>  /\ progress&#39; = [x \in sProc&#39; |-&gt; progress[x]]
</span></span><span><span>  /\ mtrcs&#39; = [mtrcs EXCEPT
</span></span><span><span>               !.cReq = @ + 1,
</span></span><span><span>               !.avgTime = newAvg]</span></span></code></pre>
</div>
</div>
<h2 id="putting-everything-together">
putting everything together
</h2>
<p>
With these, we <code>should</code> have enough to define our <strong>Next</strong> state update,</p>
<div>
<div>
<pre><code><span><span>  Next ==
</span></span><span><span>    \/ \E c \in C : NewReq(c)
</span></span><span><span>    \/ Accept
</span></span><span><span>    \/ Start
</span></span><span><span>    \/ Proc
</span></span><span><span>    \/ Finish
</span></span><span><span>    \/ Timeout
</span></span><span><span>    \/ Tick</span></span></code></pre>
</div>
</div>
<h2 id="timeout">
timeout
</h2>
<p>
Now we have the parts connected, we define how we calculate a <code>request timeout</code> based on the metrics and variables the parts are updating along the way,</p>
<p>
We first find the request that’s been in the pending queue for too long,</p>
<div>
<div>
<pre><code><span><span>  Timeout ==
</span></span><span><span>    /\ LET
</span></span><span><span>         tout == {rq \in pReq : t - rq.subTime &gt;= SrvTO}</span></span></code></pre>
</div>
</div>
<p>
If there’s any timeout requests, we create the “timeout object” and put that into our timedout request set, then we update, pending queue and request age map, then we check the inbound buffer, and server queue accordingly (we check these 2 places, as we don’t know where this request is currently at in our system)</p>
<div>
<div>
<pre><code><span><span>  IN
</span></span><span><span>  /\ tout /= {}
</span></span><span><span>  /\ timedout&#39; = timedout \union
</span></span><span><span>                 {[c |-&gt; rq.c, id |-&gt; rq.id, toTime |-&gt; t] :
</span></span><span><span>                  rq \in tout}
</span></span><span><span>  /\ pReq&#39; = pReq \ tout
</span></span><span><span>  /\ age&#39; = [rq \in pReq&#39; |-&gt; age[rq]]
</span></span><span><span>  /\ cReq&#39; = {rq \in cReq :
</span></span><span><span>             ~\E to \in tout : to.c = rq.c /\ to.id = rq.id}
</span></span><span><span>  /\ sQueue&#39; = {rq \in sQueue :
</span></span><span><span>               ~\E to \in tout : to.c = rq.c /\ to.id = rq.id}</span></span></code></pre>
</div>
</div>
<p>
similarly we check the requests the servers are currently processing, drop the timedout request if we could find any. And as before, we update the metrics accordingly,</p>
<div>
<div>
<pre><code><span><span>  /\ LET
</span></span><span><span>  toProc == {rq \in sProc :
</span></span><span><span>             \E to \in tout : to.c = rq.c /\ to.id = rq.id}
</span></span><span><span>  IN
</span></span><span><span>  /\ sProc&#39; = sProc \ toProc
</span></span><span><span>  /\ progress&#39; = [rq \in sProc&#39; |-&gt; progress[rq]]
</span></span><span><span>  /\ mtrcs&#39; = [mtrcs EXCEPT
</span></span><span><span>               !.toutReq = @ + Cardinality(tout)]</span></span></code></pre>
</div>
</div>
<h2 id="properties-and-invariants">
Properties and invariants
</h2>
<p>
This is the part I struggled the most, after some try and error and help from AI, here’s what I got.</p>
<p>
And as <a href="https://blog.cyang.page/3tier_tla_part_1/">part 1</a>, we want to have weak liveness to tell TLA+ that all these state transitions will be executed in the end, we do this by specifying Spec,</p>
<div>
<div>
<pre><code><span><span>  Spec == Init /\ [][Next]_v
</span></span><span><span>        /\ WF_v(Accept)
</span></span><span><span>        /\ WF_v(Start)
</span></span><span><span>        /\ WF_v(Proc)
</span></span><span><span>        /\ WF_v(Finish)
</span></span><span><span>        /\ WF_v(Timeout)
</span></span><span><span>        /\ WF_v(Tick)</span></span></code></pre>
</div>
</div>
<p>
The we can start to write down the things we want our specifications to guarantee, things that TLA+ will check for us.</p>
<p>
Now we can finally move on the setting the <strong>Properties</strong>, things that <strong>has a chance of happening eventually</strong>, this was very counter intuitive for me and I had to ask AI for help, the best way to explain it wuold be <strong>these are things we want to make sure that always have the possibility to happen, this makes them worth checking</strong>,</p>
<ul>
<li>“all requests are handled”, AllReqHandled</li>
<li>“no request timeout”, SomeReqTO</li>
<li>“no server overloads”, SrvsOverload</li>
</ul>
<div>
<div>
<pre><code><span><span>  AllReqHandled ==
</span></span><span><span>  [](mtrcs.tReq &gt; 0 =&gt;
</span></span><span><span>     &lt;&gt;(mtrcs.cReq + mtrcs.toutReq = mtrcs.tReq))
</span></span><span><span>
</span></span><span><span>  SomeReqTO ==
</span></span><span><span>  &lt;&gt;(mtrcs.toutReq &gt; 0)
</span></span><span><span>
</span></span><span><span>  SrvsOverload ==
</span></span><span><span>  &lt;&gt;(mtrcs.maxLoad = SrvCap * Cardinality(Srv))</span></span></code></pre>
</div>
</div>
<p>
and <strong>Invariants</strong>, things we usually want always be true (or want to break and fix in my case) , which is our timeout, 4 timeouts is the value I set it to while writing this,</p>
<div>
<div>
<pre><code><span><span>  TOThreshold ==
</span></span><span><span>    mtrcs.toutReq &lt;= 4</span></span></code></pre>
</div>
</div>
<h2 id="runtime-constraints">
runtime constraints
</h2>
<p>
Finally we run `tlc`, and it tool forever…, I went for a pizza and coffee and chatting with folks at <a href="https://www.recurse.com/scout/click?t=20cccbfea0852a9738b0c4d200b1a091">Recurse Center</a>, 4 hours passed… still going…</p>
<p>
so I need to limit the scope we are testing using constraints, this can be adjusted depending your tradeoff between how real and safe you want the verification to be v.s. how much time you want to wait, e.g.</p>
<div>
<div>
<pre><code><span><span>  Constr ==
</span></span><span><span>    /\ t &lt; 25
</span></span><span><span>    /\ mtrcs.tReq &lt; 10</span></span></code></pre>
</div>
</div>
<p>
with this setup running `tlc`, it took roughly 3-4 mins on my 32 GB RAM AMD Ryzen 7 7840 laptop, we finally got what we want,</p>
<div>
<div>
<pre><code><span><span>  ...
</span></span><span><span>  Error: Invariant TOThreshold is violated.
</span></span><span><span>  ...
</span></span><span><span>  <span>2617997</span> states generated, <span>1931144</span> distinct states found, <span>1390828</span> states left on queue.
</span></span><span><span>  The depth of the <span>complete</span> state graph search is 14.
</span></span><span><span>  Finished in 03min 01s at <span>(</span>2025-04-07 16:46:59<span>)</span></span></span></code></pre>
</div>
</div>
<p>
This is when I decided to give up… the idea of building a board game around it with any realistic scenraio would not be such a good player experience, I cannot have players waiting for so long to verify their actions, I am clearly pending it to doing something TLA+ was not meant for.</p>
<p>
Oh well… I tried, and I learned a lot. After this experience, tho not a successful one (due to me setting a not suitable goal), it only made me even more eager to invest into TLA+, there’s so much potential to be modelling a system this way, and I really like the syntax somehow, not at all thinking about switching to using <a href="https://lamport.azurewebsites.net/tla/tutorial/intro.html">PlusCal</a>.</p>

</div></div>
  </body>
</html>
