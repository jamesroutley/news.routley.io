<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.brimdata.io/blog/join-geolocation-csv-data/">Original</a>
    <h1>Joining CSV Data Without SQL: An IP Geolocation Use Case</h1>
    
    <div id="readability-page-1" class="page"><div>
  <article>
    <header>
           
        

    

  

        
    </header>

    <section>
      <p>Whether for website analytics or determining the origin of a network attack, <a href="https://en.wikipedia.org/wiki/Internet_geolocation">Internet geolocation</a> is handy technology. In brief, given an IP address associated with some network traffic, can we deduce from where on earth the traffic originated? There’s plenty of software and services out there to help provide this information, but a familiar one is the <a href="https://dev.maxmind.com/geoip/geolite2-free-geolocation-data">GeoLite2 data from MaxMind</a>. Not only is it free, it’s provided in the form of downloadable data sets. This allows us to pick it apart in interesting ways.</p>
<p>MaxMind makes their GeoLite2 data available in a couple formats, one being the common (and sometimes loathed) <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> format. They provide <a href="https://dev.maxmind.com/geoip/importing-databases/postgresql">helpful docs</a> that describe the schemas and a handy cookbook for defining SQL tables, importing the CSV data into those tables, and then performing a <a href="https://en.wikipedia.org/wiki/Join_(SQL)">join</a> between two of the data sets. This guide is super helpful, and if followed to the letter, you can experience the joy at the end of entering an IP address and getting back a city name. But before you can get there, as a prerequisite you need to enumerate all the field names and desired data types to load it into a specific structured format. Maybe there’s another way?</p>
<p>To validate the <a href="https://zed.brimdata.io/">Zed project</a>’s usefulness in real-world use cases, I often apply Zed to data sets and guides like these. In Zed’s <a href="https://zed.brimdata.io/docs">docs</a>, we sometimes speak of how it offers a <a href="https://zed.brimdata.io/docs#getting-started">gradual slope</a>. Whereas MaxMind’s guide effectively shows how “<em>Your CSV data must become <strong>this SQL</strong> to ride this ride!</em>”, Zed allows you to apply a minimal set of concepts from the <a href="https://zed.brimdata.io/docs/language">language</a>, <a href="https://zed.brimdata.io/docs/formats/zed">data model</a>, and <a href="https://zed.brimdata.io/docs/commands">tooling</a> to solve your problem.</p>
<p>Replicating these operations on the GeoLite2 data with Zed shows a nice example of this gradual slope in action. Read on to climb the slope from a quick one-shot query to a performant join that avoids the hassle of SQL tables.</p>
<h2 id="examining-the-data">Examining the Data</h2>
<p>Let’s say we’ve downloaded and unpacked the most recent <strong>GeoLite2 City: CSV Format</strong> ZIP. Much like MaxMind’s guide, we’ll focus on these three CSV files.</p>
<pre tabindex="0"><code>$ ls -l *Blocks* *en*
-rw-rw-r--@ 1 phil  staff  242435417 Oct 16 08:36 GeoLite2-City-Blocks-IPv4.csv
-rw-rw-r--@ 1 phil  staff   81213494 Oct 16 08:36 GeoLite2-City-Blocks-IPv6.csv
-rw-rw-r--@ 1 phil  staff   10036753 Oct 16 08:36 GeoLite2-City-Locations-en.csv
</code></pre><p>To peek at some sample data, we could refer to MaxMind’s description of the schemas or load the CSV files into tools like Excel or Google Sheets. However, Zed provides a handy point of entry thanks to its ability to <a href="https://zed.brimdata.io/docs/commands/zq#auto-detection">auto-detect</a> most common input formats. With a quick one-shot invocation of the <a href="https://zed.brimdata.io/docs/commands/zq"><code>zq</code></a> command-line tool, we can use Zed’s <a href="https://zed.brimdata.io/docs/language/operators/head"><code>head</code> operator</a> to see samples of the data.</p>
<pre tabindex="0"><code>$ zq -Z &#39;head&#39; GeoLite2-City-Blocks-IPv4.csv
{
    network: &#34;1.0.0.0/24&#34;,
    geoname_id: 2077456.,
    registered_country_geoname_id: 2077456.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: null,
    latitude: -33.494,
    longitude: 143.2104,
    accuracy_radius: 1000.
}

$ zq -Z &#39;head&#39; GeoLite2-City-Locations-en.csv
{
    geoname_id: 1392.,
    locale_code: &#34;en&#34;,
    continent_code: &#34;AS&#34;,
    continent_name: &#34;Asia&#34;,
    country_iso_code: &#34;IR&#34;,
    country_name: &#34;Iran&#34;,
    subdivision_1_iso_code: 2.,
    subdivision_1_name: &#34;Māzandarān&#34;,
    subdivision_2_iso_code: null,
    subdivision_2_name: null,
    city_name: &#34;Shahr&#34;,
    metro_code: null,
    time_zone: &#34;Asia/Tehran&#34;,
    is_in_european_union: 0.
}
</code></pre><p>Compared to the SQL cookbook, notice that we didn’t need to enumerate any column names or specify data types in order to read the CSV files. Much like we see with spreadsheet tools, Zed has smart default behaviors when reading CSV inputs, recognizing which fields can be treated as numbers or strings and where <code>null</code> values appear. For many one-shot queries, this treatment may be all that’s needed. For example, let’s say we wanted to see the cities in Iran.</p>
<pre tabindex="0"><code>$ zq -f text &#39;country_name==&#34;Iran&#34; | cut city_name&#39; GeoLite2-City-Locations-en.csv
Shahr
Jahan
Kaman
...
</code></pre><h2 id="richer-data-types-enable-richer-queries">Richer Data Types Enable Richer Queries</h2>
<p>Now that we’re familiar with our data, let’s revisit our original goal of mapping an IP address to its geographical location.</p>
<p>We see the “blocks” data is organized by <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR block</a>. Since it came from CSV, the <code>network</code> field starts life as a string. The SQL cookbook showed how to turn this string into a column with PostgreSQL’s <a href="https://www.postgresql.org/docs/current/datatype-net-types.html#DATATYPE-CIDR">cidr</a> type and then use their <a href="https://www.postgresql.org/docs/current/functions-net.html#FUNCTIONS-NET"><code>&gt;&gt;=</code></a> operator to check if an IP is inside such a block.</p>
<p>Keeping with the theme of a gradual slope, we can apply the equivalent Zed concepts <em>only where needed</em> and rely on the default treatment of all other fields. Here’s what happens when we <a href="https://zed.brimdata.io/docs/language/functions/cast">cast</a> the <code>network</code> field to Zed’s <a href="https://zed.brimdata.io/docs/formats/zed#1-primitive-types"><code>net</code></a> type.</p>
<pre tabindex="0"><code>$ zq -Z &#39;network:=net(network) | head&#39; GeoLite2-City-Blocks-IPv4.csv
{
    network: 1.0.0.0/24,
    geoname_id: 2077456.,
    registered_country_geoname_id: 2077456.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: null,
    latitude: -33.494,
    longitude: 143.2104,
    accuracy_radius: 1000.
}
</code></pre><p>Notice the lack of quotes around the value <code>1.0.0.0/24</code>, indicating it’s no longer treated as a string. Now a simple <a href="https://zed.brimdata.io/docs/language/search-expressions#search-logic">search</a> using Zed’s <a href="https://zed.brimdata.io/docs/language/functions/cidr_match"><code>cidr_match</code> function</a> can show us the block that covers a particular IP address.</p>
<pre tabindex="0"><code>$ zq -Z &#39;network:=net(network) | cidr_match(network, 146.243.121.22)&#39; GeoLite2-City-Blocks-IPv4.csv
{
    network: 146.243.120.0/23,
    geoname_id: 4952487.,
    registered_country_geoname_id: 6252001.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: 2777.,
    latitude: 41.7505,
    longitude: -71.2089,
    accuracy_radius: 20.
}
</code></pre><p>Type casting is but one small part of the wider topic of Zed’s <a href="https://zed.brimdata.io/docs/language/shaping">shaping and type fusion</a> features. These flexible and powerful data transformation techniques <em>can</em> provide the “enumerate-every-field-and-data-type” treatment often seen with SQL… <em>but only when you need to!</em> Since we’re already making good progress having only surgically altered one field, let’s keep going and see how far we get.</p>
<h2 id="joining-to-city-data">Joining to City Data</h2>
<p>We’ve mapped our IP address into a subnet, but that’s only gotten us details like postal code and latitude/longitude. This might be adequate for plotting points on a map, but what if we want to see a city name?</p>
<p>MaxMind’s cookbook describes the significance of the <code>geoname_id</code> field appearing in both data sets, then <a href="https://dev.maxmind.com/geoip/importing-databases/postgresql#query-our-tables">shows how to leverage it</a> to perform a <a href="https://en.wikipedia.org/wiki/Join_(SQL)">SQL join</a> to get the city detail.</p>
<p>Zed has its own <a href="https://zed.brimdata.io/docs/language/operators/join"><code>join</code> operator</a> and we can apply it here, once again without having had to turn our CSV into SQL tables. We’ll use Zed’s <a href="https://zed.brimdata.io/docs/language/operators/from"><code>file</code> operator</a> to feed our multiple data sources into the respective left and right sides of the <code>join</code>. Finally, since our program is getting longer, we’ll spread it out over multiple lines.</p>
<pre tabindex="0"><code>$ zq -Z &#39;
file GeoLite2-City-Blocks-IPv4.csv
| network:=net(network)
| cidr_match(network, 146.243.121.22)
| join (
  file GeoLite2-City-Locations-en.csv
) on geoname_id=geoname_id location:=this
&#39;

{
    network: 146.243.120.0/23,
    geoname_id: 4952487.,
    registered_country_geoname_id: 6252001.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: 2777.,
    latitude: 41.7505,
    longitude: -71.2089,
    accuracy_radius: 20.,
    location: {
        geoname_id: 4952487.,
        locale_code: &#34;en&#34;,
        continent_code: &#34;NA&#34;,
        continent_name: &#34;North America&#34;,
        country_iso_code: &#34;US&#34;,
        country_name: &#34;United States&#34;,
        subdivision_1_iso_code: &#34;MA&#34;,
        subdivision_1_name: &#34;Massachusetts&#34;,
        subdivision_2_iso_code: null,
        subdivision_2_name: null,
        city_name: &#34;Swansea&#34;,
        metro_code: 521.,
        time_zone: &#34;America/New_York&#34;,
        is_in_european_union: 0.
    }
}
</code></pre><p>SQL users know join is a big topic all its own, and indeed, there’s a <a href="https://zed.brimdata.io/docs/tutorials/join">Zed <code>join</code> tutorial</a> that walks through examples using the many available flavors. However, if the example in MaxMind’s cookbook made sense to you, hopefully you’ll find the Zed one above equally intuitive. In brief, the logic is:</p>
<ol>
<li>Filter the “blocks” input down to just the record containing our target CIDR block</li>
<li>Locate the “city” record that matches our “block” by finding shared <code>geoname_id</code> values</li>
<li>Copy the matching “city” data into our “block” record as a nested field called <code>location</code></li>
</ol>
<h2 id="wanna-jump-in-a-lake">Wanna Jump in a Lake?</h2>
<p>If all we needed was this one-shot result that our IP address is in Swansea, we’re done. We’d have saved ourselves plenty of time by not having to install database software, define tables, and load CSV files into them all as a prerequisite to running our join.</p>
<p>But what if we expect to run this kind of query repeatedly? On my aging MacBook, the query above took about 14 seconds with <code>zq</code>. Considering we read a few hundred megabytes of CSV on the fly, transformed a field, performed a CIDR match, then did a join between two data sources, maybe that’s a reasonable cost. But it’s going to add up over multiple queries.</p>
<p>This brings us to our next step up the gradual slope: The <a href="https://zed.brimdata.io/docs/commands/zed">Zed lake</a>. The Zed lake is another topic that can be explored to needed depth, but for our immediate needs we can think of it as a place to more efficiently store and query our data. With a <a href="https://zed.brimdata.io/docs/commands/zed#serve">Zed service</a> running, the following commands load our minimally-scrubbed CSV inputs into respective <a href="https://zed.brimdata.io/docs/commands/zed#data-pools">pools</a> of the lake.</p>
<pre tabindex="0"><code>$ zed create -orderby network blocks
$ zed create -orderby geoname_id locations
$ zq &#39;network:=net(network)&#39; GeoLite2-City-Blocks-IPv*.csv | zed load -use blocks -
$ zed load -use locations GeoLite2-City-Locations-en.csv
</code></pre><p>We’ve created pools called “blocks” and “locations” to hold the data from our respective CSV inputs. The <code>-orderby</code> option allows us to specify a <a href="https://zed.brimdata.io/docs/commands/zed#pool-key">pool key</a> field by which data will be sorted when stored. This has the potential to significantly speed up queries involving this field, much like a primary key does for SQL. Since we still want the benefits of the minimal casting of the <code>network</code> field in our “blocks” data, we repurpose our <code>zq</code> from earlier to perform that transform and feed that output into <code>zed load</code> to populate that pool. And since we don’t need to do any transforms on the city data, a straight call to <code>zed load</code> is adequate to populate that pool. Once loaded, all lake data is stored in Zed’s compact binary <a href="https://zed.brimdata.io/docs/formats/zng">ZNG format</a>.</p>
<p>By going through these one-time steps, we can now avoid repeating the expensive operations of CSV parsing or type casting in the future and instead jump right to executing efficient queries. Since we’re now hitting pools in the lake, the Zed query syntax changes minimally compared to what we saw with <code>zq</code> and file inputs. Let’s wrap our query with <code>time</code> and see how much faster it runs.</p>
<pre tabindex="0"><code>$ time zed query -Z &#39;
from blocks
| cidr_match(network, 146.243.121.22)
| join (
  from locations
) on geoname_id=geoname_id location:=this
&#39;

{
    network: 146.243.120.0/23,
    geoname_id: 4952487.,
    registered_country_geoname_id: 6252001.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: 2777.,
    latitude: 41.7505,
    longitude: -71.2089,
    accuracy_radius: 20.,
    location: {
        geoname_id: 4952487.,
        locale_code: &#34;en&#34;,
        continent_code: &#34;NA&#34;,
        continent_name: &#34;North America&#34;,
        country_iso_code: &#34;US&#34;,
        country_name: &#34;United States&#34;,
        subdivision_1_iso_code: &#34;MA&#34;,
        subdivision_1_name: &#34;Massachusetts&#34;,
        subdivision_2_iso_code: null,
        subdivision_2_name: null,
        city_name: &#34;Swansea&#34;,
        metro_code: 521.,
        time_zone: &#34;America/New_York&#34;,
        is_in_european_union: 0.
    }
}

real	0m0.193s
user	0m0.020s
sys	0m0.013s
</code></pre><p>Below 0.2 seconds? Not bad!</p>
<h2 id="parameters-from-the-shell">Parameters From the Shell</h2>
<p>We’ve got good momentum going, so let’s take one more step up the gradual slope and see how to generalize this approach with Zed’s <a href="https://zed.brimdata.io/docs/language/statements#operator-statements">user-defined operators</a>. This allows you to parameterize the variable portions of your logic to hide complexity and enable reusability.</p>
<p>Since the IP address is what’s changing here, we turn that into an argument <code>addr</code>. We’ll also store our program in a text file <code>loc.zed</code>.</p>
<pre tabindex="0"><code>op find_location(addr): (
  from blocks
  | cidr_match(network, addr)
  | join (
    from locations
  ) on geoname_id=geoname_id location:=this
)
</code></pre><p>Zed’s CLI tools provide a <code>-I</code> option to invoke programs from such files. Therefore we can now run the query from the shell like so.</p>
<pre tabindex="0"><code>$ zed query -Z -I loc.zed &#39;find_location(146.243.121.22)&#39;
{
    network: 146.243.120.0/23,
    geoname_id: 4952487.,
    registered_country_geoname_id: 6252001.,
    represented_country_geoname_id: null,
    is_anonymous_proxy: 0.,
    is_satellite_provider: 0.,
    postal_code: 2777.,
    latitude: 41.7505,
    longitude: -71.2089,
    accuracy_radius: 20.,
    location: {
        geoname_id: 4952487.,
        locale_code: &#34;en&#34;,
        continent_code: &#34;NA&#34;,
        continent_name: &#34;North America&#34;,
        country_iso_code: &#34;US&#34;,
        country_name: &#34;United States&#34;,
        subdivision_1_iso_code: &#34;MA&#34;,
        subdivision_1_name: &#34;Massachusetts&#34;,
        subdivision_2_iso_code: null,
        subdivision_2_name: null,
        city_name: &#34;Swansea&#34;,
        metro_code: 521.,
        time_zone: &#34;America/New_York&#34;,
        is_in_european_union: 0.
    }
}
</code></pre><p>And to achieve total shell nirvana, let’s dynamically query for our own IP and use Zed’s <a href="https://zed.brimdata.io/docs/language/operators/yield"><code>yield</code> operator</a> to see what city comes back.</p>
<pre tabindex="0"><code>$ zed query -Z -I loc.zed &#34;find_location($(curl -s ifconfig.co)) | yield location.city_name&#34;

&#34;San Francisco&#34;
</code></pre><p>As validated by the smell of sourdough bread emanating from my oven, this result is indeed correct!</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Hopefully we’ve given you a better understanding of Zed’s <em>gradual slope</em>. Whether you need a one-shot query result to get on with your day or you’re looking to build a reusable production data pipeline, Zed lets you jump on board with the appropriate level of sophistication and performance.</p>
<p>Of course, this only scratches the surface of what’s possible. In addition to the links above, here are some suggestions of other areas to explore.</p>
<ul>
<li>If you like what you see, support Zed by giving a GitHub Star <a href="https://github.com/brimdata/zed" data-show-count="true" aria-label="Star brimdata/zed on GitHub">Star</a></li>
<li><a href="https://www.brimdata.io/download/">Download</a> the Zed CLI tooling and/or the <a href="https://zui.brimdata.io/">Zui desktop app</a></li>
<li>Check out the <a href="https://github.com/brimdata/zed">Zed repo on GitHub</a></li>
<li>Read the <a href="https://www.cidrdb.org/cidr2023/papers/p52-ousterhout.pdf">Zed research paper</a></li>
</ul>

    </section>
  </article>
</div></div>
  </body>
</html>
