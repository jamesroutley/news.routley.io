<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/enjalot/latent-scope">Original</a>
    <h1>Visualize Latent Spaces</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Quickly embed, project, cluster and explore a dataset. This project is a new kind of workflow + tool for visualizing and exploring datasets through the lens of latent spaces.
<a href="https://enjalot.github.io/latent-scope/#/datasets/dadabase/explore/scopes-007" rel="nofollow"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/dadabase-explore.png?raw=true" height="480px" alt="Example exploration"/></a></p>
<p dir="auto">The power of machine learning models to encode unstructured data into high-dimensional embeddings is relatively under-explored. Retrieval Augmented Generation has taken off as a popular usecase for embeddings, but do you feel confident in your understanding of why certain data is being retrieved? Do you have a clear picture of what all is in your dataset? Latentscope is like a microscope that allows you to get a new perspective on what&#39;s happening to your data when it&#39;s embedded. You can try similarity search with different embeddings, peruse automatically labeled clusters and zoom in on individual data points all while keeping the context of your entire dataset.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-demo" aria-hidden="true" tabindex="-1" href="#demo"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Demo</h3>
<p dir="auto">This tool is meant to be run locally or on a trusted server to process data for viewing in the latent scope. You can see the result of the process in a read-only <a href="https://enjalot.github.io/latent-scope" rel="nofollow">live demo</a>:</p>
<ul dir="auto">
<li><a href="https://enjalot.github.io/latent-scope/#/datasets/datavis-misunderstood/explore/scopes-001" rel="nofollow">datavis survey responses</a> - 700 survey responses</li>
<li><a href="https://enjalot.github.io/latent-scope/#/datasets/dolly15k/explore/scopes-001" rel="nofollow">Dolly 15k</a> - 15k instructions</li>
<li><a href="https://enjalot.github.io/latent-scope/#/datasets/dadabase/explore/scopes-004" rel="nofollow">r/DadJokes</a> - 50k dad jokes</li>
<li><a href="https://enjalot.github.io/latent-scope/#/datasets/emotion/explore/scopes-001" rel="nofollow">emotion</a> - 400k emotion statements from Twitter</li>
</ul>
<p dir="auto">The source of each demo dataset is documented in the notebooks linked below. Each demo was chosen to represent different scales of data as well as some common usecases.</p>
<p dir="auto"><a href="https://enjalot.github.io/latent-scope" rel="nofollow"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/dadabase-scopes.png?raw=true" width="100%" alt="Dadabase demo scopes"/></a></p>
<h3 tabindex="-1" dir="auto"><a id="user-content-quick-start" aria-hidden="true" tabindex="-1" href="#quick-start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h3>
<p dir="auto">To get started, install the <a href="https://pypi.org/project/latentscope/" rel="nofollow">latent-scope module</a> and run the server via the Command Line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m venv venv
source venv/bin/activate
pip install latentscope
ls-init ~/local-scope-data --openai_key=XXX --mistral_key=YYY # optional api keys to enable API models 
ls-serve "><pre>python -m venv venv
<span>source</span> venv/bin/activate
pip install latentscope
ls-init <span>~</span>/local-scope-data --openai_key=XXX --mistral_key=YYY <span><span>#</span> optional api keys to enable API models </span>
ls-serve </pre></div>
<p dir="auto">Then open your browser to <a href="http://localhost:5001" rel="nofollow">http://localhost:5001</a> and start processing your first dataset!</p>
<p dir="auto">Once ingested, you will go through the following 6 steps: Embed, UMAP, Cluster, Label, Scope and Explore
<a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/1-embed.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/1-embed.png?raw=true" width="320px" alt="Embed"/></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/2-umap.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/2-umap.png?raw=true" width="320px" alt="UMAP"/></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/3-cluster.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/3-cluster.png?raw=true" width="320px" alt="Cluster"/></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/4-label.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/4-label.png?raw=true" width="320px" alt="Label"/></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/5-scope.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/5-scope.png?raw=true" width="320px" alt="Scope"/></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/enjalot/latent-scope/blob/main/documentation/6-explore.png?raw=true"><img src="https://github.com/enjalot/latent-scope/raw/main/documentation/6-explore.png?raw=true" width="320px" alt="Scope"/></a></p>
<p dir="auto">Each step focuses on the relevant choices to move you to the next step. For example choosing which embedding model you want to use to embed with, or the parameters for UMAP. It&#39;s very likely you may want to try several choices at each step, which is why the final step before &#34;Explore&#34; is to make a &#34;scope&#34;. You can make multiple scopes, as seen in the <a href="https://enjalot.github.io/latent-scope/#/datasets/dadabase/explore/scopes-004" rel="nofollow">dadabase example</a> to explore your data through different lenses (i.e. OpenAI embeddings vs. Jina v2).</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-python-interface" aria-hidden="true" tabindex="-1" href="#python-interface"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Python interface</h3>
<p dir="auto">You can also ingest data from a Pandas dataframe using the Python interface:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from latentscope import ls
df = pd.read_parquet(&#34;...&#34;)
ls.init(&#34;~/latent-scope-data&#34;) # you can also pass in openai_key=&#34;XXX&#34;, mistral_key=&#34;XXX&#34; etc.)
ls.ingest(&#34;dadabase&#34;, df, text_column=&#34;joke&#34;)
ls.serve()"><pre><span>from</span> <span>latentscope</span> <span>import</span> <span>ls</span>
<span>df</span> <span>=</span> <span>pd</span>.<span>read_parquet</span>(<span>&#34;...&#34;</span>)
<span>ls</span>.<span>init</span>(<span>&#34;~/latent-scope-data&#34;</span>) <span># you can also pass in openai_key=&#34;XXX&#34;, mistral_key=&#34;XXX&#34; etc.)</span>
<span>ls</span>.<span>ingest</span>(<span>&#34;dadabase&#34;</span>, <span>df</span>, <span>text_column</span><span>=</span><span>&#34;joke&#34;</span>)
<span>ls</span>.<span>serve</span>()</pre></div>
<p dir="auto">See these notebooks for detailed examples of using the Python interface to prepare and load data.</p>
<ul dir="auto">
<li><a href="https://github.com/enjalot/latent-scope/blob/main/notebooks/dvs-survey.ipynb">dvs-survey</a> - A small test dataset of 700 rows to quickly illustrate the process. This notebook shows how you can do every step of the process with the Python interface.</li>
<li><a href="https://github.com/enjalot/latent-scope/blob/main/notebooks/dadabase.ipynb">dadabase</a> - A more interesting (and funny) dataset of 50k rows. This notebook shows how you can preprocess a dataset, ingest it into latentscope and then use the web interface to complete the process.</li>
<li><a href="https://github.com/enjalot/latent-scope/blob/main/notebooks/dolly15k.ipynb">dolly15k</a> - Grab data from HuggingFace datasets and ingest into the process.</li>
<li><a href="https://github.com/enjalot/latent-scope/blob/main/notebooks/emotion.ipynb">emotion</a> - 400k rows of emotional tweets.</li>
</ul>
<h3 tabindex="-1" dir="auto"><a id="user-content-command-line-quick-start" aria-hidden="true" tabindex="-1" href="#command-line-quick-start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Command line quick start</h3>
<p dir="auto">When latent-scope is installed, it creates a suite of command line scripts that can be used to setup the scopes for exploring in the web application. The output of each step in the process is flat files stored in the data directory specified at init. These files are in standard formats that were designed to be ported into other pipelines or interfaces.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# like above, we make sure to install latent-scope
python -m venv venv
source venv/bin/activate
pip install latent-scope

# prepare some data
wget &#34;https://storage.googleapis.com/fun-data/latent-scope/examples/dvs-survey/datavis-misunderstood.csv&#34; &gt; ~/Downloads/datavis-misunderstood.csv

ls-init &#34;~/latent-scope-data&#34;
# ls-ingest dataset_id csv_path
ls-ingest-csv &#34;datavis-misunderstood&#34; &#34;~/Downloads/datavis-misunderstood.csv&#34;
# get a list of model ids available (lists both embedding and chat models available)
ls-list-models
# ls-embed dataset_id text_column model_id prefix
ls-embed datavis-misunderstood &#34;answer&#34; transformers-intfloat___e5-small-v2 &#34;&#34;
# ls-umap dataset_id embedding_id n_neighbors min_dist
ls-umap datavis-misunderstood embedding-001 25 .1
# ls-cluster dataset_id umap_id samples min_samples
ls-cluster datavis-misunderstood umap-001 5 5
# ls-label dataset_id text_column cluster_id model_id context
ls-label datavis-misunderstood &#34;answer&#34; cluster-001 transformers-HuggingFaceH4___zephyr-7b-beta &#34;&#34;
# ls-scope  dataset_id embedding_id umap_id cluster_id cluster_labels_id label description
ls-scope datavis-misunderstood cluster-001-labels-001 &#34;E5 demo&#34; &#34;E5 embeddings summarized by Zephyr 7B&#34;
# start the server to explore your scope
ls-serve"><pre><span><span>#</span> like above, we make sure to install latent-scope</span>
python -m venv venv
<span>source</span> venv/bin/activate
pip install latent-scope

<span><span>#</span> prepare some data</span>
wget <span><span>&#34;</span>https://storage.googleapis.com/fun-data/latent-scope/examples/dvs-survey/datavis-misunderstood.csv<span>&#34;</span></span> <span>&gt;</span> <span>~</span>/Downloads/datavis-misunderstood.csv

ls-init <span><span>&#34;</span>~/latent-scope-data<span>&#34;</span></span>
<span><span>#</span> ls-ingest dataset_id csv_path</span>
ls-ingest-csv <span><span>&#34;</span>datavis-misunderstood<span>&#34;</span></span> <span><span>&#34;</span>~/Downloads/datavis-misunderstood.csv<span>&#34;</span></span>
<span><span>#</span> get a list of model ids available (lists both embedding and chat models available)</span>
ls-list-models
<span><span>#</span> ls-embed dataset_id text_column model_id prefix</span>
ls-embed datavis-misunderstood <span><span>&#34;</span>answer<span>&#34;</span></span> transformers-intfloat___e5-small-v2 <span><span>&#34;</span><span>&#34;</span></span>
<span><span>#</span> ls-umap dataset_id embedding_id n_neighbors min_dist</span>
ls-umap datavis-misunderstood embedding-001 25 .1
<span><span>#</span> ls-cluster dataset_id umap_id samples min_samples</span>
ls-cluster datavis-misunderstood umap-001 5 5
<span><span>#</span> ls-label dataset_id text_column cluster_id model_id context</span>
ls-label datavis-misunderstood <span><span>&#34;</span>answer<span>&#34;</span></span> cluster-001 transformers-HuggingFaceH4___zephyr-7b-beta <span><span>&#34;</span><span>&#34;</span></span>
<span><span>#</span> ls-scope  dataset_id embedding_id umap_id cluster_id cluster_labels_id label description</span>
ls-scope datavis-misunderstood cluster-001-labels-001 <span><span>&#34;</span>E5 demo<span>&#34;</span></span> <span><span>&#34;</span>E5 embeddings summarized by Zephyr 7B<span>&#34;</span></span>
<span><span>#</span> start the server to explore your scope</span>
ls-serve</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-repository-overview" aria-hidden="true" tabindex="-1" href="#repository-overview"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Repository overview</h3>
<p dir="auto">This repository is currently meant to run locally, with a React frontend that communicates with a python server backend. We support several popular open source embedding models that can run locally as well as proprietary API embedding services. Adding new models and services should be quick and easy.</p>
<p dir="auto">To learn more about customizing, extending and contributing see <a href="https://github.com/enjalot/latent-scope/blob/main/documentation/DEVELOPMENT.md">DEVELOPMENT.md</a></p>
<h3 tabindex="-1" dir="auto"><a id="user-content-design-principles" aria-hidden="true" tabindex="-1" href="#design-principles"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Design principles</h3>
<p dir="auto">This tool is meant to be a part of a larger process. Something that hopefully helps you see things in your data that you wouldn&#39;t otherwise have. That means it needs to be easy to get data in, and easily get useful data out.</p>
<ol dir="auto">
<li>Flat files</li>
</ol>
<ul dir="auto">
<li>All of the data that drives the app is stored in flat files. This is so that both final and intermediate outputs can easily be exported for other uses. It also makes it easy to see the status of any part of the process.</li>
</ul>
<ol start="2" dir="auto">
<li>Remember everything</li>
</ol>
<ul dir="auto">
<li>This tool is intended to aid in research, the purpose is experimentation and exploration. I developed it because far too often I try a lot of things and then I forget what parameters lead me down a promising path in the first place. All choices you make in the process are recorded in metadata files along with the output of the process.</li>
</ul>
<ol start="3" dir="auto">
<li>It&#39;s all about the indices</li>
</ol>
<ul dir="auto">
<li>We consider an input dataset the source of truth, a list of rows that can be indexed into. So all downstream operations, whether its embeddings, pointing to nearest neighbors or assigning data points to clusters, all use indices into the input dataset.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-command-line-scripts-detailed-description" aria-hidden="true" tabindex="-1" href="#command-line-scripts-detailed-description"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Command Line Scripts: Detailed description</h2>
<p dir="auto">If you want to use the CLI instead of the web UI you can use the following scripts.</p>
<p dir="auto">The scripts should be run in order once you have an <code>input.csv</code> file in your folder. Alternatively the Setup page in the web UI will run these scripts via API calls to the server for you.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-0-ingest" aria-hidden="true" tabindex="-1" href="#0-ingest"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>0. ingest</h3>
<p dir="auto">This script turns the <code>input.csv</code> into <code>input.parquet</code> and sets up the directories and <code>meta.json</code> which run the app.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ls-ingest &lt;dataset_name&gt;
ls-ingest database-curated"><pre><span><span>#</span> ls-ingest &lt;dataset_name&gt;</span>
ls-ingest database-curated</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-1-embed" aria-hidden="true" tabindex="-1" href="#1-embed"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>1. embed</h3>
<p dir="auto">Take the text from the input and embed it. Default is to use <code>BAAI/bge-small-en-v1.5</code> locally via HuggingFace transformers. API services are supported as well, see <a href="https://github.com/enjalot/latent-scope/blob/main/latentscope/models/embedding_models.json">latentscope/models/embedding_models.json</a> for model ids.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# you can get a list of models available with:
ls-list-models
# ls-embed &lt;dataset_name&gt; &lt;text_column&gt; &lt;model_id&gt;
ls-embed dadabase joke transformers-intfloat___e5-small-v2"><pre><span><span>#</span> you can get a list of models available with:</span>
ls-list-models
<span><span>#</span> ls-embed &lt;dataset_name&gt; &lt;text_column&gt; &lt;model_id&gt;</span>
ls-embed dadabase joke transformers-intfloat___e5-small-v2</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-2-umap" aria-hidden="true" tabindex="-1" href="#2-umap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>2. umap</h3>
<p dir="auto">Map the embeddings from high-dimensional space to 2D with UMAP. Will generate a thumbnail of the scatterplot.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ls-umap &lt;dataset_name&gt; &lt;embedding_id&gt; &lt;neighbors&gt; &lt;min_dist&gt;
ls-umap dadabase embedding-001 50 0.1"><pre><span><span>#</span> ls-umap &lt;dataset_name&gt; &lt;embedding_id&gt; &lt;neighbors&gt; &lt;min_dist&gt;</span>
ls-umap dadabase embedding-001 50 0.1</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-3-cluster" aria-hidden="true" tabindex="-1" href="#3-cluster"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>3. cluster</h3>
<p dir="auto">Cluster the UMAP points using HDBSCAN. This will label each point with a cluster label</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ls-cluster &lt;dataset_name&gt; &lt;umap_id&gt; &lt;samples&gt; &lt;min-samples&gt;
ls-cluster dadabase umap-001 5 3"><pre><span><span>#</span> ls-cluster &lt;dataset_name&gt; &lt;umap_id&gt; &lt;samples&gt; &lt;min-samples&gt;</span>
ls-cluster dadabase umap-001 5 3</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-4-label" aria-hidden="true" tabindex="-1" href="#4-label"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>4. label</h3>
<p dir="auto">We support auto-labeling clusters by summarizing them with an LLM. Supported models and APIs are listed in <a href="https://github.com/enjalot/latent-scope/blob/main/latentscope/models/chat_models.json">latentscope/models/chat_models.json</a>.
You can pass context that will be injected into the system prompt for your dataset.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ls-label &lt;dataset_id&gt; &lt;cluster_id&gt; &lt;chat_model_id&gt; &lt;context&gt;
ls-label dadabase &#34;joke&#34; cluster-001 openai-gpt-3.5-turbo &#34;&#34;"><pre><span><span>#</span> ls-label &lt;dataset_id&gt; &lt;cluster_id&gt; &lt;chat_model_id&gt; &lt;context&gt;</span>
ls-label dadabase <span><span>&#34;</span>joke<span>&#34;</span></span> cluster-001 openai-gpt-3.5-turbo <span><span>&#34;</span><span>&#34;</span></span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-5-scope" aria-hidden="true" tabindex="-1" href="#5-scope"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>5. scope</h3>
<p dir="auto">The scope command ties together each step of the process to create an explorable configuration. You can have several scopes to view different choices, for example using different embeddings or even different parameters for UMAP and clustering. Switching between scopes in the UI is instant.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ls-scope  &lt;dataset_id&gt; &lt;embedding_id&gt; &lt;umap_id&gt; &lt;cluster_id&gt; &lt;cluster_labels_id&gt; &lt;label&gt; &lt;description&gt;
ls-scope datavis-misunderstood cluster-001-labels-001 &#34;E5 demo&#34; &#34;E5 embeddings summarized by GPT3.5-Turbo&#34;"><pre><span><span>#</span> ls-scope  &lt;dataset_id&gt; &lt;embedding_id&gt; &lt;umap_id&gt; &lt;cluster_id&gt; &lt;cluster_labels_id&gt; &lt;label&gt; &lt;description&gt;</span>
ls-scope datavis-misunderstood cluster-001-labels-001 <span><span>&#34;</span>E5 demo<span>&#34;</span></span> <span><span>&#34;</span>E5 embeddings summarized by GPT3.5-Turbo<span>&#34;</span></span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-6-serve" aria-hidden="true" tabindex="-1" href="#6-serve"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>6. serve</h3>
<p dir="auto">To start the web UI we run a small server. This also enables nearest neighbor similarity search and interactively querying subsets of the input data while exploring the scopes.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ls-serve ~/latent-scope-data"><pre>ls-serve <span>~</span>/latent-scope-data</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-dataset-directory-structure" aria-hidden="true" tabindex="-1" href="#dataset-directory-structure"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Dataset directory structure</h2>
<p dir="auto">Each dataset will have its own directory in data/ created when you ingest your CSV. All subsequent steps of setting up a dataset write their data and metadata to this directory.
There are no databases in this tool, just flat files that are easy to copy and edit.</p>
<pre>├── data/
|   ├── dataset1/
|   |   ├── input.parquet                           # from ingest.py, the dataset
|   |   ├── meta.json                               # from ingest.py, metadata for dataset, #rows, columns, text_column
|   |   ├── embeddings/
|   |   |   ├── embedding-001.h5                    # from embed.py, embedding vectors
|   |   |   ├── embedding-001.json                  # from embed.py, parameters used to embed
|   |   |   ├── embedding-002...                   
|   |   ├── umaps/
|   |   |   ├── umap-001.parquet                    # from umap.py, x,y coordinates
|   |   |   ├── umap-001.json                       # from umap.py, params used
|   |   |   ├── umap-001.png                        # from umap.py, thumbnail of plot
|   |   |   ├── umap-002....                        
|   |   ├── clusters/
|   |   |   ├── clusters-001.parquet                # from cluster.py, cluster indices
|   |   |   ├── clusters-001-labels-default.parquet # from cluster.py, default labels
|   |   |   ├── clusters-001-labels-001.parquet     # from label_clusters.py, LLM generated labels
|   |   |   ├── clusters-001.json                   # from cluster.py, params used
|   |   |   ├── clusters-001.png                    # from cluster.py, thumbnail of plot
|   |   |   ├── clusters-002...                     
|   |   ├── scopes/
|   |   |   ├── scopes-001.json                     # from scope.py, combination of embed, umap, clusters and label choice
|   |   |   ├── scopes-...                      
|   |   ├── tags/
|   |   |   ├── ❤️.indices                           # tagged by UI, powered by tags.py
|   |   |   ├── ...                                 # can have arbitrary named tags
|   |   ├── jobs/
|   |   |   ├──  8980️-12345...json                  # created when job is run via web UI
</pre>
</article></div></div>
  </body>
</html>
