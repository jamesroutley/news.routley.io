<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pierre-couy.dev/tinkering/2023/03/turning-rpi-into-external-monitor-driver.html">Original</a>
    <h1>Using a Raspberry Pi to add a second HDMI port to a laptop</h1>
    
    <div id="readability-page-1" class="page"><div>
            <nav>
    
        <a href="https://pierre-couy.dev/">
            Home</a>
    
        <a href="https://pierre-couy.dev/about.html">
            About</a>
    
    
        
        
        <a href="https://pierre-couy.dev/category/tinkering/">
            Tinkering</a>
    
</nav>

            
            <div><p>
    11 Mar 2023 
    
        in
            Tinkering
    
    .
    
        Tags :
            
                <a href="https://pierre-couy.dev/tag/raspberry-pi/">raspberry-pi</a>
                ,
            
                <a href="https://pierre-couy.dev/tag/ffmpeg/">ffmpeg</a>
                ,
            
                <a href="https://pierre-couy.dev/tag/tutorial/">tutorial</a>
                ,
            
                <a href="https://pierre-couy.dev/tag/linux/">linux</a>
                
            
    
</p></div>

<p>Recently, I purchased a new laptop. I was really focused on spending the least amount of money and had not noticed that the laptop I chose was missing an essential feature : it did not have Display Port over USB C. Not being able to use my second external monitor on this new laptop felt like a huge downgrade from my previous one (which was able to output to both its HDMI and VGA ports simultaneously).</p>

<p>This is the story of how I managed to overcome this limitation by rolling my own virtual screen streaming solution using a Raspberry Pi. I tried to write it in a way you can follow along if you want to reproduce it. If you are just looking to get it up and running as quick as possible, you can check out <a href="https://github.com/pcouy/rpi-eth-display">the GitHub repository containing configuration files and installation scripts</a> (Work In Progress)</p>

<h2 id="existing-solutions-and-limitations-of-old-raspberry-pi-models">Existing solutions and limitations of old Raspberry Pi models</h2>

<p>I quickly hooked a Raspberry Pi to the external monitor and tried to find a turnkey solution that would allow me to stream a virtual screen to the Pi via an Ethernet cable. I looked into using VNC, Steam Remote Play, and some dedicated VNC wrappers I found on GitHub.</p>

<p>Since I was not willing to spend more money on my setup, I used a Raspberry Pi 3 which was sitting unused in one of my drawers. This meant I could not benefit from hardware accelerated h264 decoding, which happened to be a significant limitation for using modern low-latency video streaming solutions. I had to compromise between picture quality, latency and framerate, and could never reach a balance I felt satisfied with : the slow LAN port and CPU could not handle my requirements.</p>

<p>I also did not like the fact that most of these solutions depended on running a full desktop session on the Pi, which I wanted to avoid in order to save its thin resources.</p>

<h2 id="goals">Goals</h2>

<p>Since I intended to use this daily, and I could not see myself using anything I had tried, I decided to go for my own solution. I had a clear goal in mind : after setting it up, it should feel as much as using a regular external monitor as possible ; while still being able to run on outdated hardware.</p>

<p>My main requirements were the following :</p>

<ul>
  <li>The latency should not be noticeable when scrolling or moving the mouse</li>
  <li>The picture quality should be high enough to read small text</li>
  <li>Since I planned to mainly use it for static text content, I decided to go easy on myself by setting a low target of 10 FPS.</li>
  <li>If the receiving end of the stream ever gets behind, it should catch-up to live as quick as possible</li>
  <li>Use <a href="https://en.wikipedia.org/wiki/Direct_Rendering_Manager">Direct Rendering Manager</a> to display the stream on the Pi instead of depending on a X server.</li>
  <li>I looked into remote-play tools and VNC because they seemed like easy to use low-latency solutions. However, I was not interested with streaming inputs back from the Pi to the laptop.</li>
</ul>

<p>As I was using a Raspberry Pi 3, I had to consider its limitations :</p>

<ul>
  <li>Due to slow CPU, use a low-overhead protocol and fast to decode encoding</li>
  <li>Due to slow network, use a low-bitrate encoding</li>
  <li>No hardware accelerated h264 decoding</li>
</ul>

<p>Since I was already going to roll my own solution, I also listed some non essential features I would enjoy having, including :</p>

<ul>
  <li>Having a DHCP server on the Raspberry Pi so that I would not have to bother myself with IP settings</li>
  <li>Automatically running the necessary software on the Pi at boot so I never have to hook a keyboard or SSH into it for regular use</li>
  <li>Having the laptop automatically start streaming to the Pi when I enable a given virtual monitor with <code>xrandr</code> (or one of its GUI wrapper such as <code>arandr</code>)</li>
  <li>Automatically turning the pi-controlled monitor on and off as if it were a regular monitor hooked to a regular HDMI port</li>
</ul>

<h2 id="making-it-happen">Making it happen</h2>

<p>I knew the hardest part was going to fine-tune the video pipeline between the laptop and the Pi. I wanted to tackle this first and only spend time on other features when I was sure it was worth it.</p>

<p>I chose to encode and send the stream using <a href="https://ffmpeg.org/"><code>ffmpeg</code></a> on my laptop (which is known to be the Swiss-army knife of audio and video manipulation). It takes care of screen-grabbing, video encoding, encapsulation and networking and provides fine-grained controls over all steps. Its numerous options can often feel overwhelming, but digging the docs have never let me down.</p>

<p>For the receiving end, I considered several <code>ffmpeg</code>-compatible video players with Direct Rendering Manager support, including <code>mpv</code>, <code>vlc</code>, and <code>ffplay</code> (more on that topic later).</p>

<h3 id="raspberry-pi-initial-setup">Raspberry Pi initial setup</h3>

<p>I started with a fresh Raspberry Pi OS install, which I flashed on my SD card using the usual commands :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span>lsblk <span>-f</span> <span># Identify SD card block device</span>
<span>pierre@laptop:~ $</span><span> </span><span>sudo dd </span><span>if</span><span>=</span>2022-09-22-raspios-bullseye-arm64-lite.img <span>of</span><span>=</span>/dev/sd[SD card letter]</code></pre></figure>

<p>I booted the Pi a first time with the screen and a keyboard attached. This lets Raspberry Pi OS resize the partition to fit the SD card. After connecting the Pi to my home WiFi and enabling SSH using <a href="https://www.raspberrypi.com/documentation/computers/configuration.html"><code>raspi-config</code></a>, I unplugged the keyboard from the Pi and SSH’ed into it.</p>

<p>I installed the required software to quickly start experimenting with the stream settings :</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span><span>sudo </span>apt-get update <span>&amp;&amp;</span> <span>sudo </span>apt-get <span>install </span>mpv ffmpeg</code></pre></figure>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span><span>sudo </span>apt-get update <span>&amp;&amp;</span> <span>sudo </span>apt-get <span>install </span>ffmpeg</code></pre></figure>

<p>While waiting for the players to install, I found an Ethernet cable to use between the Pi and the laptop. To my surprise, both computers seemed to be able to talk to each other without me doing anything, so I started tinkering with <code>ffmpeg</code> parameters. I don’t remember the details, but the connection ended up not being stable enough. It was necessary to install and configure a DHCP server on the Raspberry Pi in order to comfortably experiment.</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span><span>sudo </span>apt-get <span>install </span>udhcpd
<span>pi@raspberrypi:~ $</span><span> </span>sudoedit /etc/udhcpd.conf</code></pre></figure>

<p>This will install <a href="https://manpages.ubuntu.com/manpages/bionic/man5/udhcpd.conf.5.html"><code>udhcpd</code></a> and open its configuration file with root privileges using the editor set in your <code>EDITOR</code> shell variable (<code>nano</code> by default on Raspberry Pi OS). I used the following configuration file :</p>

<figure><pre><code data-lang="conf"><span># Only one lease for the Pi itself, and one for the laptop
</span><span>start</span> <span>10</span>.<span>0</span>.<span>0</span>.<span>0</span>
<span>end</span> <span>10</span>.<span>0</span>.<span>0</span>.<span>1</span>

<span># udhcpd will use eth0
</span><span>interface</span> <span>eth0</span>

<span># Various options
</span><span>option</span> <span>subnet</span> <span>255</span>.<span>255</span>.<span>255</span>.<span>0</span>
<span>option</span> <span>domain</span> <span>hdmi</span>
<span>option</span> <span>lease</span>  <span>60</span>  <span># One minute lease
</span>
<span># The Pi itself will always be 10.0.0.0
</span><span>static_lease</span> [<span>PI</span> <span>MAC</span> <span>ADDRESS</span>] <span>10</span>.<span>0</span>.<span>0</span>.<span>0</span></code></pre></figure>

<p>You will need to replace <code>[PI MAC ADDRESS]</code> with the actual MAC address of your hardware, which you can find by running <code>ip a</code> on the Pi (<code>link/ether</code> field).</p>

<figure><pre><code data-lang="console"><span>pi@rapsberrypi:~ $</span><span> </span><span>sudo </span>systemctl <span>enable </span>udhcpd
<span>pi@rapsberrypi:~ $</span><span> </span><span>sudo </span>systemctl restart udhcpd</code></pre></figure>

<p>The first command above will launch the DHCP server on boot, and the second one will launch it immediately. Rebooting the Pi may help both computers pick up on their new network configurations. From now on, the Raspberry Pi will be reachable from the laptop using <code>10.0.0.0</code> as long as the Ethernet cable is plugged to both. The laptop will use the IP <code>10.0.0.1</code>.</p>

<h3 id="starting-an-unoptimized-stream">Starting an unoptimized stream</h3>

<p>With this initial setup done, I was able to quickly iterate over commands for sending and receiving the stream. This was not a straightforward process and while I did not keep records of every attempt, I’ll do my best to tell the interesting discoveries I made along the way. I will also detail every option in the commands presented below.</p>

<p>On the Raspberry Pi, the goal was to launch a media player that would listen on the network waiting for the laptop to send it a stream, and display it using DRM with the lowest possible latency. I first tried using <a href="https://mpv.io/"><code>mpv</code></a> because of its support for GPU decoding.</p>

<p>Since both ends of the stream were connected over a single wire with no realistic opportunity for interception and I wanted to save resources on the Pi, encryption was not necessary. My requirements for lowest possible latency led my to try streaming over plain UDP. Long story short, my experiments with UDP did not go so well : one skipped packet and the whole screen would turn to garbage (or worse, the player would crash). I then switched to TCP, which proved to offer low-enough latency while not suffering from the same issue.</p>

<p>Let’s start with the most basic command that does that, without bothering with optimization for now :</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span>mpv <span>--hwdec</span><span>=</span>drm <span>&#34;tcp://10.0.0.0:1234?listen&#34;</span></code></pre></figure>

<p>This command makes <code>mpv</code> listen on interface <code>10.0.0.0</code>, TCP port <code>1234</code> and will display the received stream using DRM.</p>

<p>On the sending side, I started with a simple command to test the stream :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span>ffmpeg <span>-video_size</span> 1920x1080 <span>-framerate</span> 5 <span>-f</span> x11grab <span>-i</span> :0.0+0x0 <span>-f</span> mpegts tcp://10.0.0.0:1234</code></pre></figure>

<p>From <code>man ffmpeg</code>, the syntax is :</p>

<figure><pre><code data-lang="console"><span>ffmpeg [global_options] {[input_file_options] -i input_url} ... {[output_file_options] output_url}</span></code></pre></figure>

<p>Let’s detail the arguments used here :</p>

<ul>
  <li><code>-video_size 1920x1080</code> indicates the size of the region to grab.</li>
  <li><code>-framerate 5</code> only grabs 5 frames per second. This is below our requirement but this allows somewhat smooth testing of the setup before optimization.</li>
  <li><a href="https://ffmpeg.org/ffmpeg-devices.html#x11grab"><code>-f x11grab</code></a> : used as an input file option, <code>-f</code> specifies the input device. <code>x11grab</code> is used for screen grabbing.</li>
  <li><code>-i :0.0+0x0</code> : <code>-i</code> is usually used for specifying input file. When used with the X11 video input device, specifies where to grab from in the syntax : <code>[hostname]:display_number.screen_number[+x_offset,y_offset]</code></li>
  <li><a href="https://ffmpeg.org/ffmpeg-formats.html#mpegts"><code>-f mpegts</code></a> : used as an output file option, <code>-f</code> specifies the output container (also called file format or muxer). <code>mpegts</code> designates MPEG-2 transport stream.</li>
  <li><code>tcp://10.0.0.0:1234</code> is the URL to send the stream to (the <code>mpv</code> listener running on the Pi)</li>
</ul>

<p>This did not meet any of my performance and quality requirements, but provided me with a starting point I could optimize from.</p>

<h3 id="optimizing-the-receiving-end-of-the-stream">Optimizing the receiving end of the stream</h3>

<p>I then tried two optimization strategies on the receiving side, which involved a lot of googling and a bunch of not-so-well documented <code>mpv</code> options :</p>

<ul>
  <li>Speeding up decoding using hardware acceleration</li>
  <li>Jumping to the latest available frame when decoding fell behind</li>
</ul>

<p>I came up with the following <code>mpv</code> command (which I will not detail) before trying another player :</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span>mpv <span>-vo</span><span>=</span>gpu <span>--gpu-context</span><span>=</span>drm <span>--input-cursor</span><span>=</span>no <span>--input-vo-keyboard</span><span>=</span>no <span>--input-default-bindings</span><span>=</span>no <span>--hwdec</span><span>=</span>drm <span>--untimed</span> <span>--no-cache</span> <span>--profile</span><span>=</span>low-latency <span>--opengl-glfinish</span><span>=</span><span>yes</span> <span>--opengl-swapinterval</span><span>=</span>0 <span>--gpu-hwdec-interop</span><span>=</span>drmprime-drm <span>--drm-draw-plane</span><span>=</span>overlay <span>--drm-drmprime-video-plane</span><span>=</span>primary <span>--framedrop</span><span>=</span>no <span>--speed</span><span>=</span>1.01 <span>--video-latency-hacks</span><span>=</span><span>yes</span> <span>--opengl-glfinish</span><span>=</span><span>yes</span> <span>--opengl-swapinterval</span><span>=</span>0 tcp://10.0.0.0:1234<span>\?</span>listen</code></pre></figure>

<p>While this achieved the best latency I could reach using <code>mpv</code> and the basic <code>ffmpeg</code> command above, I felt this was too complicated. Some other resources I found online were using <a href="https://ffmpeg.org/ffplay.html"><code>ffplay</code></a> on the receiving end so I gave it a try. This proved to be a much simpler path, and I achieved comparable results using the following command :</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span>ffplay <span>-autoexit</span> <span>-flags</span> low_delay <span>-framedrop</span> <span>-strict</span> experimental <span>-vf</span> <span>setpts</span><span>=</span>0 <span>-tcp_nodelay</span> 1 <span>&#34;tcp://10.0.0.0:1234</span><span>\?</span><span>listen&#34;</span></code></pre></figure>

<p>Most of these optimizations came from <a href="https://stackoverflow.com/questions/16658873/how-to-minimize-the-delay-in-a-live-streaming-with-ffmpeg">this StackOverflow post about minimizing delay in a live stream</a>. Let’s detail the meaning of the options I used :</p>

<ul>
  <li><code>-autoexit</code> makes <code>ffplay</code> exit when the stream ends</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Codec-Options"><code>-flags low_delay</code></a> seemed like an obvious choice, even if the documentation is not clear about what it does</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Advanced-options"><code>-framedrop</code></a> “Drop video frames if video is out of sync”</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Codec-Options"><code>-strict experimental</code></a> enables “unfinished/work in progress/not well tested” stuff. This proved to be useful. Note : the documentation mentions this option not being suitable for decoding untrusted input. You should probably remove it if you plan on plugging untrusted computers on your Raspberry Pi’s LAN port.</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#setpts_002c-asetpts"><code>-vf setpts=0</code></a> : <code>-vf</code> is used to specify video filters. The <code>setpts</code> filter changes the <em>Presentation TimeStamp</em> of video frames. <code>setpts=0</code> is used to make all frames display as soon as possible</li>
  <li><code>-tcp_nodelay 1</code> enables the <a href="https://www.extrahop.com/company/blog/2016/tcp-nodelay-nagle-quickack-best-practices/">TCP nodelay flag</a>. I’m not sure this one really had any impact, but it made sense to include it and did not hurt performances.</li>
</ul>

<p>The stream sent by the basic <code>ffmpeg</code> command gets displayed on the Pi monitor with a delay of approximately 1 second using <code>ffplay</code>. This is too high, and the quality is too low for small text, but we are very close to the final command I’m still running on the Pi.</p>

<p>Let’s make sure the OS prioritizes the <code>ffplay</code> process using the <code>nice</code> and <code>ionice</code> commands :</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span><span>sudo nice</span> <span>-n</span> <span>-20</span> ionice <span>-c</span> 1 <span>-n</span> 0 ffplay <span>-autoexit</span> <span>-flags</span> low_delay <span>-framedrop</span> <span>-strict</span> experimental <span>-vf</span> <span>setpts</span><span>=</span>0 <span>-tcp_nodelay</span> 1 <span>&#34;tcp://10.0.0.0:1234</span><span>\?</span><span>listen&#34;</span></code></pre></figure>

<h3 id="supervising-ffplay">Supervising <code>ffplay</code></h3>

<p>Since the player automatically detects, decodes and demuxes the input codec and muxer, I could experiment with the sending side without changing the command run on the Pi. However, I still had to switch between terminals in order to manually restart <code>ffplay</code> between each try. This pushed me to take care of a non-essential feature before going on.</p>

<p>I used <a href="http://supervisord.org/"><code>supervisor</code></a> to manage the media player process. The choice was motivated by its ease of use over creating <code>systemd</code> services.</p>

<figure><pre><code data-lang="console"><span>pi@raspberrypi:~ $</span><span> </span><span>sudo </span>apt-get <span>install </span>supervisor
<span>pi@raspberrypi:~ $</span><span> </span>sudoedit /etc/supervisor/conf.d/pimonitor.conf</code></pre></figure>

<p>This will install <code>supervisor</code> and open a configuration file for editing. I used the following content :</p>

<figure><pre><code data-lang="conf">[<span>program</span>:<span>ffplay</span>]
<span>command</span>=<span>nice</span> -<span>n</span> -<span>20</span> <span>ionice</span> -<span>c</span> <span>1</span> -<span>n</span> <span>0</span> <span>ffplay</span> -<span>autoexit</span> -<span>flags</span> <span>low_delay</span> -<span>framedrop</span> -<span>strict</span> <span>experimental</span> -<span>vf</span> <span>setpts</span>=<span>0</span> -<span>tcp_nodelay</span> <span>1</span> <span>&#34;tcp://10.0.0.0:1234\?listen&#34;</span>
<span>autorestart</span>=<span>true</span>
<span>stdout_logfile</span>=/<span>dev</span>/<span>null</span>
<span>stderr_logfile</span>=/<span>dev</span>/<span>null</span></code></pre></figure>

<p>The <code>autorestart</code> option makes a new instance of <code>ffplay</code> listen and wait for a new stream when the previous one exits. I used <code>/dev/null</code> for logfiles to prevent <code>ffplay</code>’s verbose output from filling my small SD card with log files.</p>

<p>After starting the <code>supervisor</code> daemon with <code>sudo systemctl enable supervisor</code> and <code>sudo systemctl restart supervisor</code>, I could try <code>ffmpeg</code> option combinations much quicker.</p>

<h3 id="fine-tuning-the-encoder-process">Fine-tuning the encoder process</h3>

<p>The first thing I did was increase the framerate to 30 FPS, and I was really surprised to find out this helped a lot with latency. The encoder would still occasionally fall behind, which caused latency spikes, but the with that simple change it suddenly started to feel like I was on the right track.</p>

<p>I then tried switching from the default <code>mpeg2video</code> to the more modern <code>mpeg4</code> which did not lead to any improvement in itself, but provided more options. Switching the muxer from <code>mpegts</code> to <code>nut</code> led to more noticeable improvements regarding delay. While quality was still too low, it started to feel responsive enough to meet the latency requirement.</p>

<p>I then managed to increase the quality to my standards by using encoder options to target a higher bit-rate (<code>-b:v 40M -maxrate 50M -bufsize 200M</code>). However, the Raspberry Pi became overloaded and started to drop a couple of frames a few times per seconds. This led to an unpleasant experience, with the mouse movements and scrolling not feeling smooth. What surprised me the most was seeing frames being dropped even when displaying a still screen.</p>

<h4 id="hunting-down-the-framedrops">Hunting down the framedrops</h4>

<p>At this point, I was back to square one, trying to find the balance between picture quality and smoothness. One key difference, however, was that this time I was working with tools I was somewhat familiar with, and provided lots of options. After trying a few things that did not work, I noticed a few things :</p>

<ul>
  <li><code>ffmpeg</code> was sending a stream with a bitrate of several Mbit/s for a still screen.</li>
  <li>Framedrops from <code>ffplay</code> seemed to happen at a very stable rate.</li>
  <li>The Raspberry Pi did not seem to be limited by its CPU.</li>
</ul>

<p>This hinted to me that the problem came from the network, so I launched a network capture using <code>tcpdump</code> :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span><span>sudo </span>tcpdump <span>-i</span> eth0 <span>-c</span> 2000 <span>-w</span> diag_remote_screen.pcapng <span>&#34;port 1234&#34;</span>
<span>pierre@laptop:~ $</span><span> </span>tcpdump <span>-r</span> diag_remote_screen.pcapng | <span>awk</span> <span>&#39;{ print $1 &#34; &#34; $8 &#34; &#34; $9 &#34; &#34; $NF }&#39;</span> | less</code></pre></figure>

<p>This captures 2000 packets of the stream between <code>ffmpeg</code> running on the laptop and <code>ffplay</code> running on the Pi. The second command is used to examine the captured packets, but you can also open the <code>.pcapng</code> file with Wireshark or other similar tools.</p>

<p>The command above shows :</p>

<ul>
  <li>The time at which the packet was captured</li>
  <li>The TCP sequence number for packets from the laptop to the Pi and their acknowledgments</li>
  <li>The size of packets</li>
</ul>

<p>Here is a sample of its output :</p>

<figure><pre><code data-lang="console"><span>14:13:36.879965 seq 79239:81556, 2317
14:13:36.881709 ack 81556, 0
14:13:36.916838 seq 81556:83849, 2293
14:13:36.918185 ack 83849, 0
14:13:36.943326 seq 83849:85014, 1165
14:13:36.944438 ack 85014, 0
14:13:36.981337 seq 85014:87613, 2599
14:13:36.982724 ack 87613, 0
14:13:37.014469 seq 87613:88769, 1156
14:13:37.015752 ack 88769, 0
14:13:37.054639 seq 88769:90701, 1932
14:13:37.055851 ack 90701, 0
14:13:37.077741 seq 90701:91858, 1157
14:13:37.079045 ack 91858, 0
14:13:37.121258 seq 91858:107786, 15928
14:13:37.121301 seq 107786:123714, 15928
14:13:37.121324 seq 123714:124626, 912
14:13:37.121360 seq 124626:140554, 15928
14:13:37.121374 seq 140554:156482, 15928
14:13:37.121386 seq 156482:172410, 15928
14:13:37.121391 seq 172410:188338, 15928
14:13:37.121403 seq 188338:204266, 15928
14:13:37.121410 seq 204266:220194, 15928
14:13:37.121421 seq 220194:236122, 15928
14:13:37.121426 seq 236122:252050, 15928
14:13:37.121438 seq 252050:267978, 15928
14:13:37.122535 seq 267978:283906, 15928
14:13:37.122567 ack 94754, 0
14:13:37.122567 ack 97650, 0
14:13:37.122567 ack 100546, 0
14:13:37.122585 seq 283906:299834, 15928
14:13:37.123237 ack 103442, 0
14:13:37.123237 ack 106338, 0
14:13:37.123238 ack 109234, 0
14:13:37.123255 seq 299834:315762, 15928
14:13:37.123891 seq 315762:331690, 15928
14:13:37.123916 seq 331690:347618, 15928
14:13:37.123926 ack 112130, 0
    [LOTS OF SUCCESSIVE ACKs]
14:13:37.135636 ack 254946, 0
14:13:37.136070 seq 347618:363546, 15928
14:13:37.136273 ack 257842, 0
14:13:37.136273 ack 260738, 0
14:13:37.136273 ack 263634, 0
14:13:37.136989 ack 266530, 0
14:13:37.136989 ack 269426, 0
14:13:37.136989 ack 272322, 0
    [REPEAT 25x THE ABOVE PATTERN OF A 15928 BYTES TCP PACKET FOLLOWED BY A FEW ACKs]
14:13:37.168585 seq 745818:761746, 15928
14:13:37.169275 ack 645906, 0
14:13:37.169275 ack 648802, 0
14:13:37.169275 ack 651698, 0
14:13:37.169857 seq 761746:769413, 7667
14:13:37.170274 ack 654594, 0
    [LOTS OF SUCCESSIVE ACKs]
14:13:37.179345 ack 769413, 0
14:13:37.184011 seq 769413:770863, 1450
14:13:37.185333 ack 770863, 0
14:13:37.214388 seq 770863:772194, 1331
14:13:37.215822 ack 772194, 0
14:13:37.241472 seq 772194:774010, 1816
14:13:37.243176 ack 774010, 0</span></code></pre></figure>

<p>At first, we see the laptop sends a packet that weights a couple kB approximately every 0.033s, which matches our framerate of 30fps. The Pi sends the acknowledgments for each of these packets before the next one comes in. At <code>14:13:37.121258</code>, <code>ffmpeg</code> starts sending a lot of 16kB packets to the Pi and the acknowledgment numbers start falling behind. When the Pi gets too far behind, <code>ffmpeg</code> waits for ACKs to catch-up a little before sending more data (TCP sequence numbers <code>283906-769413</code>). This burst of data from the laptop stops at <code>14:13:37.169857</code> (TCP seq num <code>769413</code>) and the Pi TCP stack finally catches up at <code>14:13:37.179345</code> (TCP ack <code>769413</code>). This is <code>0.58s</code> (almost 2 frames) after the laptop began sending this data. This whole thing happened precisely every 12 frames and explained the details I noticed earlier about the framedrops.</p>

<p>The MPEG codec compresses videos by only saving a few frames in full, which are called keyframes. All other frames are derived from the previous frame which is associated with a description of the differences between consecutive frames. Data bursts occur every-time <code>ffmpeg</code> sends a keyframe, which is set by default to happen every 12 frame (~ 3 times/sec).</p>

<p>Increasing the “group of picture” <a href="https://ffmpeg.org/ffmpeg-codecs.html#Codec-Options">codec option</a> from 12 to 100 (~ once every 3 seconds) had the expected effect : framedrops were only happening once every 3 seconds, which I could live with.</p>

<p>At this point I had the following command :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span>ffmpeg <span>-video_size</span> 1920x1080 <span>-framerate</span> 30 <span>\</span>
<span>    -f x11grab -i :0.0+0x0 \
    -b:v 40M -maxrate 50M -bufsize 200M \
    -vcodec mpeg4 -g 100 -f nut \
    &#34;tcp://10.0.0.0:1234&#34;</span></code></pre></figure>

<p>Even though I was satisfied with what I managed to get, I kept tinkering with options. At one point, it became difficult to tell what actually improved the experience and what could be attributed to some kind of placebo effect. Anyway, here is the final command I came up with :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span>ffmpeg <span>-video_size</span> 1920x1080 <span>-r</span> 30 <span>-framerate</span> 30 <span>-f</span> x11grab <span>-i</span> :0.0+0x0 <span>\</span>
<span>    -b:v 40M -maxrate 50M -bufsize 200M \
    -field_order tt -fflags nobuffer -threads 1 \
    -vcodec mpeg4 -g 100 -r 30 -bf 0 -mbd bits -flags +aic+mv4+low_delay \
    -thread_type slice -slices 1 -level 32 -strict experimental -f_strict experimental \
    -syncpoints none -f nut &#34;tcp://10.0.0.0:1234&#34;</span></code></pre></figure>

<h3 id="extending-the-laptop-display">Extending the laptop display</h3>

<p>For this task, my goal was to configure the X server on my laptop so that it could output to a virtual monitor I could then screen-grab and stream to the Raspberry Pi.
To accomplish this, I closely followed what <a href="https://github.com/dianariyanto/virtual-display-linux"><code>virtual-display-linux</code></a> does and I copied the <a href="https://github.com/dianariyanto/virtual-display-linux/blob/master/20-intel.conf">provided configuration file for intel GPU</a>. After rebooting, I could indeed see two monitors called <code>VIRTUAL1</code> and <code>VIRTUAL2</code> in my <code>xrandr</code> output.</p>

<p>Using the accepted answer from <a href="https://unix.stackexchange.com/questions/227876/how-to-set-custom-resolution-using-xrandr-when-the-resolution-is-not-available-i">this StackOverflow thread</a> I created the mode for my external monitor resolution and associated it with the first virtual display :</p>

<figure><pre><code data-lang="console"><span>pierre@laptop:~ $</span><span> </span>gtf 1920 1200 30 <span># gtf {W} {H} {FPS}</span>
<span>#</span><span> </span>Use the Modeline from the output of the above <span>command </span><span>in </span>the <span>command </span>below
<span>pierre@laptop:~ $</span><span> </span>xrandr <span>--newmode</span> <span>&#34;1920x1200_30.00&#34;</span>  89.67  1920 1992 2184 2448  1200 1201 1204 1221  <span>-HSync</span> +Vsync
<span>pierre@laptop:~ $</span><span> </span>xrandr <span>--addmode</span> VIRTUAL1 <span>&#34;1920x1200_30.00&#34;</span></code></pre></figure>

<p>Note that I used a resolution of 1920x1200 because this is the resolution of the monitor I’m using. If you are following along, you will need to change this to fit your actual screen resolution.</p>

<p>After enabling the virtual monitor using <code>arandr</code> (a graphical frontend for <code>xrandr</code>), I modified the <code>-video_size</code> and <code>-i</code> options in my <code>ffmpeg</code> command to grab the virtual display. This worked as intended and it effectively extended my laptop’s display to the Pi-driven monitor.</p>

<h3 id="wrapping-xrandr">Wrapping <code>xrandr</code></h3>

<p>At this point, my solution was meeting all my primary requirements. I was able to set everything up so it really felt like using a regular monitor. However, I still had to run a bunch of commands by hand on the laptop. How nice would it be to enable the virtual display just like a regular one, and have the <code>ffmpeg</code> command run automatically with the right options ?</p>

<p>The solution I came up with feels a bit hacky : I wrote a wrapper script for <code>xrandr</code>.</p>

<figure><pre><code data-lang="bash"><span>#!/bin/bash</span>

<span># Enable job control</span>
<span>set</span> <span>-m</span>

<span># Extract arguments between `--output VIRTUAL1` and the next occurrence of `--output`</span>
<span>V_ARGS</span><span>=</span><span>$(</span><span>echo</span> <span>&#34;</span><span>$@</span><span>&#34;</span> | <span>grep</span> <span>&#34;VIRTUAL1&#34;</span> | <span>sed</span> <span>-e</span> <span>&#39;s/.*--output VIRTUAL1 //&#39;</span> <span>-e</span> <span>&#39;s/ \?--output.*//&#39;</span><span>)</span>

<span># Run the real xrandr</span>
<span># (using full path YOU MAY NEED TO UPDATE THIS DEPENDING ON YOUR DISTRO)</span>
/usr/bin/xrandr <span>&#34;</span><span>$@</span><span>&#34;</span>

<span># If there were no args related to VIRTUAL1, exit with the same exit code as `xrandr`</span>
<span>EXITCODE</span><span>=</span><span>$?</span>
<span>if</span> <span>[</span> <span>$(</span><span>echo</span> <span>$V_ARGS</span> | <span>wc</span> <span>-w</span><span>)</span> <span>-eq</span> 0 <span>]</span><span>;</span> <span>then
    </span><span>exit</span> <span>$EXITCODE</span>
<span>fi</span>

<span># Kill the previous ffmpeg process if it exists</span>
<span>kill</span> <span>$(</span><span>cat</span> /tmp/remote_screen_ffmpeg.pid<span>)</span>
<span>KILLEDFFMPEG</span><span>=</span><span>$?</span>
<span>rm</span> /tmp/remote_screen_ffmpeg.pid

<span># If the arguments for the display contain `--off`</span>
<span>if</span> <span>[</span> <span>$(</span><span>echo</span> <span>$V_ARGS</span> | <span>grep</span> <span>-e</span> <span>&#34;--off&#34;</span> | <span>wc</span> <span>-l</span><span>)</span> <span>-ge</span> 1 <span>]</span><span>;</span> <span>then
    </span><span>echo</span> <span>&#34;Screen off&#34;</span> <span>&gt;&gt;</span> ~/testxrandr <span># For debugging</span>
<span>else</span>
    <span># Extract the arguments for the display we&#39;re interested in</span>
    <span>MODE</span><span>=</span><span>$(</span><span>echo</span> <span>$V_ARGS</span> | <span>sed</span> <span>-e</span> <span>&#39;s/.*--mode \([^ ]*\).*/\1/&#39;</span><span>)</span>
    <span>POS</span><span>=</span><span>$(</span><span>echo</span> <span>$V_ARGS</span> | <span>sed</span> <span>-e</span> <span>&#39;s/.*--pos \([^ ]*\).*/\1/&#39;</span><span>)</span>
    <span>ROTATE</span><span>=</span><span>$(</span><span>echo</span> <span>$V_ARGS</span> | <span>sed</span> <span>-e</span> <span>&#39;s/.*--rotate \([^ ]*\).*/\1/&#39;</span><span>)</span>

    <span># If the display is rotated, invert width and height in $MODE</span>
    <span>if</span> <span>[[</span> <span>$ROTATE</span> <span>==</span> <span>&#34;left&#34;</span> <span>]]</span> <span>||</span> <span>[[</span> <span>$ROTATE</span> <span>==</span> <span>&#34;right&#34;</span> <span>]]</span><span>;</span> <span>then
        </span><span>MODE</span><span>=</span><span>$(</span><span>echo</span> <span>$MODE</span> | <span>sed</span> <span>-e</span> <span>&#39;s/\([0-9]*\)x\([0-9]*\)/\2x\1/&#39;</span><span>)</span>
    <span>fi</span>

    <span># $VFARG will be used later in an ffmpeg option</span>
    <span>case</span> <span>$ROTATE</span> <span>in
        </span>normal<span>)</span>
            <span>VFARG</span><span>=</span><span>&#34;null&#34;</span>
            <span>;;</span>
        left<span>)</span>
            <span>VFARG</span><span>=</span><span>&#34;transpose=2&#34;</span>
            <span>;;</span>
        right<span>)</span>
            <span>VFARG</span><span>=</span><span>&#34;transpose=1&#34;</span>
            <span>;;</span>
        inverted<span>)</span>
            <span>VFARG</span><span>=</span><span>&#34;transpose=2,transpose=2&#34;</span>
            <span>;;</span>
        <span>*</span><span>)</span>
            <span>VFARG</span><span>=</span><span>&#34;null&#34;</span>
            <span>;;</span>
    <span>esac</span>

    <span># If there was a previously running ffmpeg process which we killed,</span>
    <span># wait 5 seconds for the supervisor daemon on the Pi to restart ffplay</span>
    <span>if</span> <span>[</span> <span>$KILLEDFFMPEG</span> <span>]</span><span>;</span> <span>then
        </span><span>sleep </span>5
    <span>fi</span>

    <span># ffmpeg command, the magic happens here</span>
    taskset <span>-c</span> 0 ffmpeg <span>-nostdin</span> <span>\</span>
        <span>-video_size</span> <span>$MODE</span> <span>-r</span> 30 <span>-framerate</span> 30 <span>-f</span> x11grab <span>-i</span> :0.0+<span>$POS</span> <span>\</span>
        <span>-b</span>:v 40M <span>-maxrate</span> 50M <span>-minrate</span> 1K <span>-bufsize</span> 200M <span>\</span>
        <span>-field_order</span> tt <span>-fflags</span> nobuffer <span>-threads</span> 1 <span>\</span>
        <span>-vcodec</span> mpeg4 <span>-g</span> 100 <span>-r</span> 30 <span>-bf</span> 0 <span>\</span>
        <span>-mbd</span> bits <span>-me_method</span> full <span>-flags</span> +aic+mv4+low_delay <span>-me_method</span> full <span>\</span>
        <span>-thread_type</span> slice <span>-slices</span> 1 <span>-level</span> 32 <span>\</span>
        <span>-strict</span> experimental <span>-f_strict</span> experimental <span>-syncpoints</span> none <span>\</span>
        <span>-vf</span> <span>&#34;</span><span>$VFARG</span><span>&#34;</span> <span>-f</span> nut <span>-tcp_nodelay</span> 1 <span>\</span>
        <span>&#34;tcp://10.0.0.0:1234?tcp_nodelay=1&#34;</span> <span>&gt;</span>/dev/null 2&gt;&amp;1 &amp;

    <span># Save the ffmpeg pid to a file which we&#39;ll read on next invocation</span>
    <span>FFMPEGPID</span><span>=</span><span>$!</span>
    <span>disown</span> <span>$FFMPEGPID</span>
    <span>echo</span> <span>$FFMPEGPID</span> <span>&gt;</span> /tmp/remote_screen_ffmpeg.pid
<span>fi</span>

<span># Return the same exit code as xrandr did</span>
<span>exit</span> <span>$EXITCODE</span></code></pre></figure>

<p>You can recognize the <code>ffmpeg</code> command from earlier. There are however a few different things :</p>

<ul>
  <li>The <code>-video_size</code> and <code>-i</code> options are determined from the <code>xrandr</code> invocation</li>
  <li>Depending on the screen orientation, we use a <a href="https://ffmpeg.org/ffmpeg-filters.html#transpose-1">video filter</a> to rotate the stream</li>
  <li><code>ffmpeg</code> is invoked through <a href="https://manpages.ubuntu.com/manpages/trusty/fr/man1/taskset.1.html"><code>taskset</code></a></li>
</ul>

<p>I saved this script as <code>~/.local/bin/xrandr</code>. For this to work, you need to have your <code>~/.local/bin</code> directory in your path, with a higher priority than system-wide directories. This is achieved by adding the following line in your <code>~/.bashrc</code> (or whatever rc file your shell uses) :</p>

<figure><pre><code data-lang="bash"><span>export </span><span>PATH</span><span>=</span><span>&#34;</span><span>$HOME</span><span>/.local/bin:</span><span>$PATH</span><span>&#34;</span></code></pre></figure>

<p>This wrapper script is run every time I run a <code>xrandr</code> command, including from GUI frontends such as <code>arandr</code>. It manages the <code>ffmpeg</code> process and starts the stream whenever the <code>VIRTUAL1</code> display is enabled. It even manages screen orientation, which was essential to me since I actually use this monitor in portrait orientation.</p>

<h3 id="managing-power">Managing power</h3>

<p>After writing the wrapper script, I was really happy with the result. I even got the pleasant surprise of not having to handle resuming the stream after the laptop wakes up from sleep. Since <code>ffmpeg</code> was not exiting on sleep, <code>ffplay</code> silently waited for the laptop to start sending data again. There was one thing bothering me though : I still had to manually power the monitor on and off when leaving my desk.</p>

<p>I googled for how to turn the HDMI port of the Raspberry Pi on and off, and quickly found out about the <a href="https://elinux.org/RPI_vcgencmd_usage"><code>vcgencmd</code></a> command and its <code>display_power</code> subcommand. Unfortunately, every command I tried seemed to have no effect on the Raspberry Pi 3. It took me a few days to <a href="https://forum.magicmirror.builders/topic/16865/mmm-remotecontrol-or-vcgencmd-issue">find a fix</a> : by editing the <code>/boot/config.txt</code> to replace <code>dtoverlay=vc4-kms-v3d</code> with <code>dtoverlay=vc4-fkms-v3d</code> and rebooting the Pi, it worked. It seems like the <code>kms</code> driver has a bug on the Raspberry Pi 3. Fortunately, switching VideoCore drivers did not impact the stream decoding performance. With that issue fixed, I was able to turn the screen on and off from an SSH session.</p>

<p>In order to run the <code>vcgencmd</code> commands at the right time, I once again went the hacky way and came up with a short script (featuring a dirty infinite loop) :</p>

<figure><pre><code data-lang="bash"><span>#!/bin/bash</span>

<span>while </span><span>true</span><span>;</span> <span>do
	if</span> <span>[</span> <span>$(</span><span>sudo timeout </span>2 tcpdump <span>-i</span> eth0 <span>&#34;port 1234&#34;</span> | <span>wc</span> <span>-l</span><span>)</span> <span>-gt</span> 1 <span>]</span><span>;</span> <span>then
		</span>vcgencmd display_power 1 2
	<span>else
		</span>vcgencmd display_power 0 2
	<span>fi
done</span></code></pre></figure>

<p>The loop does the following :</p>

<ul>
  <li>Run <code>tcpdump</code> for two seconds and count the number of packets received on port 1234 during this time</li>
  <li>If there was at least one packet received during the last 2 seconds, turn the display on</li>
  <li>If no packets were received during the last 2 seconds, turn the display off</li>
  <li>Repeat</li>
</ul>

<p>I saved the script on the Pi as <code>/home/pi/check_screen_input.sh</code> and edited the <code>supervisor</code> configuration file :</p>

<figure><pre><code data-lang="conf">[<span>program</span>:<span>power_mgmt</span>]
<span>command</span>=/<span>home</span>/<span>pi</span>/<span>check_screen_input</span>.<span>sh</span>
<span>autorestart</span>=<span>true</span></code></pre></figure>

<p>I then restarted the <code>supervisor</code> daemon, which had the effect of stopping the stream. The monitor went back to the Pi tty and after a short moment, turned off. I then disabled and re-enabled the <code>VIRTUAL1</code> display on my laptop, and the magic happened : the monitor woke up from sleep and extended the laptop’s display.</p>

<h2 id="improvements-and-last-thoughts">Improvements and last thoughts</h2>

<p>I finally reached a solution I could use in my day-to-day life, with only small quirks I don’t mind dealing with.</p>

<p>I still have to manually create the new mode and add it to the virtual display after every reboot. It would be really nice to have the Pi detect the resolution of the monitor and use it to automatically configure the virtual display on the laptop. However, since I’m of the kind who rarely reboots their computers and I already spent quite some time on this project, I moved on from it without taking care of this part.</p>

<p>The main defect is that I sometimes get visible encoding/decoding glitches that fix themselves on the next keyframe. I don’t know what causes them. If you have leads on this, please open an issue in the GitHub repository.</p>

<p>I made a <a href="https://github.com/pcouy/rpi-eth-display">GitHub repository that features all needed configuration files and scripts, as well as untested installation scripts</a>. The part that runs on the Raspberry Pi seems like a good opportunity to learn how to make a <code>.deb</code> package, so I may look into it in the future. If there is interest around this project, I may get motivated to make the process more streamlined and beginner-friendly.</p>

<p>Overall, I am really satisfied with what I managed to come up with. While using it, I even noticed I was able to watch videos without the audio-video delay being noticeable. With this solution available, and considering the money it saved me, I may knowingly purchase a laptop that lacks a second video output when I need to replace this one.</p>


        </div></div>
  </body>
</html>
