<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://accent-strength.boldvoice.com/">Original</a>
    <h1>Accents in latent spaces: How AI hears accent strength in English</h1>
    
    <div id="readability-page-1" class="page"><div>
        

        <section id="intro">
          <p>
            We work with accents a lot at
            <a href="https://boldvoice.com" target="_blank" rel="noopener">BoldVoice</a>, the AI-powered accent coaching app for non-native English
            speakers. Accents are subtle patterns in speech—vowel shape, timing,
            pitch, and more. Usually, you need a linguist to make sense of these
            qualities. However, our goal at BoldVoice is to get machines to
            understand accents, and machines don’t think like linguists. So, we
            ask: how does a machine learning model understand an accent, and
            specifically, how strong it is?
          </p>
          <p>
            To begin this journey, we first introduce the “accent fingerprint,”
            an embedding that is generated by inferencing an English speech
            recording through BoldVoice’s large-scale accented speech model.
          </p>
          <figure>
            <pre><code>torch.Size([1, 768, 12])</code></pre>
            <figcaption>The accent fingerprint embedding dimensions</figcaption>
          </figure>
          <p>
            In this post we’ll show where the accent fingerprint lives in a
            latent space, how distances and directions in that space correspond
            to accent similarity and language background, and how we use it to
            coach our product management intern Victor, a non-native English
            speaker, toward the American English accent of our expert accent
            coach Eliza.
          </p>

          <h3>The Original Recordings</h3>
          <p>First off, here&#39;s how Victor sounds when speaking English:</p>
          <figure>
            <audio controls="" src="victor-original.wav"></audio>
            <figcaption>Victor (original recording)</figcaption>
          </figure>
          <p>
            Now have a listen to Eliza reading the same passage. Eliza is
            demonstrating our “target” American accent.
          </p>
          <figure>
            <audio controls="" src="eliza-original.wav"></audio>
            <figcaption>Eliza&#39;s recording</figcaption>
          </figure>
          <p>
            Compared to Eliza, who is an American English native speaker, Victor
            has a noticeably strong Chinese accent when speaking English.
          </p>
        </section>

        <section id="latent-space">
          <h3>The Latent Space</h3>
          <p>
            So that we can make sense of how the machine learning model
            understands both of these recordings, we now populate a latent space
            with 1,000 speech recordings sourced from our internal data
            representing varied levels of accent. Feel free to inspect the 2D
            visualization of the latent space<sup>1</sup> and hover over the
            points to see details about each recording.
          </p>

          <p>
            The full dimensional latent space contains information about speaker
            identity, accent, intelligibility, emotion, and other
            characteristics. This visualization has been pruned to show only the
            information relevant to &#34;accent strength&#34;, that is &#34;how strong is
            the speaker&#39;s accent relative to native speakers of English?&#34;
          </p>
          <p>
            More specifically, we apply PLS regression to identify the latent
            space directions which correlate most with human accent strength
            ratings, and for the purpose of this visualization only, we apply 2D
            UMAP dimensionality reduction. The x-axis represents the first
            hidden dimension of accent strength, while the y-axis represents the
            second hidden dimension.<sup>2</sup>
          </p>

          <p>
            The below pseudocode shows how the dimensions of the latent space
            are selected:
          </p>
          <figure>
            <pre><code>accent_strength_directions = PLSRegression.fit(train_accent_fingerprints, train_accent_strength_ratings)
accent_strength_features = test_accent_fingerprints[accent_strength_directions]
visualization_features = UMAP(n_components=2).fit_transform(accent_strength_features)</code></pre>
          </figure>

          
          
        </section>

        <section id="victor-original">
          <h3>Plotting Accents</h3>
          <p>
            Now, let’s visualize the accent fingerprints of Victor’s and Eliza’s
            recordings in this latent space. You can see a purple diamond in the
            bottom left representing Eliza’s recording and a yellow diamond
            towards the top right representing Victor’s recording.
          </p>

          <p>
            From what we can see, the more towards the lower left of the plot a
            recording is, the more ”native sounding” and “less strong” its
            speaker’s accent is. Accordingly, we labeled the points as Native,
            Near Native, Advanced, Intermediate, and Beginner based on their
            distance from Eliza’s position in the latent space.
          </p>

          <p>
            Another finding we immediately see is that the latent space is not
            biased towards different native languages, as we don’t see any
            clustering based on the speaker’s native language, and a fairly
            uniform distribution of native languages across all proficiency
            levels.
          </p>

          <p>
            Now, let’s look at some creative ways that we can use our in-house
            suite of speech models and tools to help Victor get closer to
            Eliza’s accent.
          </p>
        </section>

        <section id="victor-cleaned">
          <h3>Cleaning the Background Noise</h3>
          <p>
            The first thing that jumps out is that Eliza’s recording is much
            cleaner than Victor’s. Perhaps it will be easier for him to focus on
            just the accent differences if we can get rid of the background
            noise in his recording?
          </p>
          <figure>
            <audio controls="" src="victor-cleaned.wav"></audio>
            <figcaption>Victor (cleaned recording)</figcaption>
          </figure>

          <p>
            Surprise! This didn’t change Victor&#39;s position in the latent space
            much, the cleaned recording lands very close to Victor&#39;s original at
            the top right of the latent space. This is a good sanity check that
            our latent space is working correctly—the recording quality and
            level background noise are not relevant to accent strength.
          </p>
        </section>

        <section id="victor-converted">
          <h3>Converting the Accent</h3>
          <p>
            Next, perhaps Victor finds it difficult to mimic Eliza’s accent
            because the register of his voice is so much lower than hers. So
            we’re going to use BoldVoice’s in-house accent conversion model to
            hear what Victor sounds like with Eliza&#39;s accent. (Yes, we can
            really do that—we&#39;ll share more about this in a future post.)
          </p>
          <figure>
            <audio controls="" src="victor-cleaned.wav"></audio>
            <figcaption>Victor&#39;s original recording</figcaption>
          </figure>
          <figure>
            <audio controls="" src="victor-converted.wav"></audio>
            <figcaption>Victor (converted recording)</figcaption>
          </figure>
          <p>
            As you can see, the position of Victor with Eliza’s accent is right
            next to Eliza’s original position in the latent space. Phonetically
            speaking, there are still some differences in vowel shapes,
            emphasis, pitch, and timing, but even without expert knowledge,
            Victor will have a much easier time mimicking Eliza’s accent now
            that it’s in his own voice.
          </p>
        </section>

        <section id="victor-after">
          <h3>Practicing the Accent</h3>
          <p>
            We left Victor with this audio of his voice with Eliza&#39;s accent for
            about 10 minutes to give him time to practice mimicking it. Here’s
            what Victor sounds like after that practice:
          </p>
          <figure>
            <audio controls="" src="victor-after.wav"></audio>
            <figcaption>Victor (after practice recording)</figcaption>
          </figure>
          <figure>
            <audio controls="" src="eliza-original.wav"></audio>
            <figcaption>Compare to Eliza&#39;s original recording</figcaption>
          </figure>
          <p>
            Not bad—Victor matched her timing, intonation and stress pretty
            well, but some of the vowel shapes still aren’t quite the same.
            Let’s see how far he is from Eliza in the latent space now.
          </p>
          <p>
            That’s quite an improvement! Victor’s new position in the latent
            space is right on the border of Intermediate and Advanced.
          </p>
          <p>
            If Victor wanted to move beyond this point, the sound-by-sound
            phonetic analysis available in the BoldVoice app would allow him to
            understand the patterns in pronunciation and stress that contribute
            to Eliza’s accent and teach him how to apply them in his own speech.
          </p>
        </section>

        <section id="conclusion">
          <h3>What did we learn?</h3>
          <ul>
            <li>
              This machine learning model can clearly distinguish the strength
              of a speaker’s accent.
            </li>
            <li>
              The model’s assessment of accent strength appears independent of
              the speaker&#39;s native language background.
            </li>
            <li>
              The accent strength of a speaker is something that can be changed
              with practice.
            </li>
            <li>
              Voice conversion technology can map a target accent onto a
              different voice, providing a useful tool for practice.
            </li>
            <li>
              Changes to the acoustic environment, such as denoising, don’t
              result in a large change in measured accent strength.
            </li>
          </ul>

          <h3>Applications and Next Steps</h3>
          <p>
            The accent strength metric derived from this model has several
            promising applications.
          </p>
          <ol>
            <li>
              It offers a quantitative way to track an English learner’s accent
              journey over multiple recordings by measuring their distance from
              a target accent profile in the latent space.
            </li>
            <li>
              This same quantitative approach can be applied to rigorously
              evaluate automatic speech recognition (ASR) systems for
              performance variations across different accent strengths.
            </li>
            <li>
              It can similarly monitor text-to-speech (TTS) systems for unwanted
              changes in accent, often referred to as “accent drift.”
            </li>
          </ol>

          <h3>Stay tuned for more!</h3>
          <p>
            Do you have any questions or comments? Or a suggestion for what you
            would like for us to cover in the future? Please reach out to us at
            <a href="https://accent-strength.boldvoice.com/cdn-cgi/l/email-protection#88ede6efe1e6ededfae1e6efc8eae7e4ecfee7e1ebeda6ebe7e5"><span data-cfemail="c2a7aca5abaca7a7b0abaca582a0adaea6b4adaba1a7eca1adaf">[email protected]</span></a>!
          </p>
          <p>
            In our next post, we&#39;ll demonstrate how to explore accent
            fingerprints (embeddings) directly without engineering them for any
            particular task, and go on a tour of the world’s accents in English.
          </p>
        </section>
      </div></div>
  </body>
</html>
