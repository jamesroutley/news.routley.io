<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://commoncog.com/letter-to-a-young-person-worrying-about-ai/">Original</a>
    <h1>Letter to a Young Person Worrying About AI</h1>
    
    <img src="https://commoncog.com/content/images/2025/10/letter_young_person_worrying_ai-1.jpg" alt="Letter to a Young Person Worrying About AI"><p><em>This was written as a </em><a href="https://forum.commoncog.com/t/will-llms-that-hallucinate-less-make-young-knowledge-workers-obsolete/2976/5?u=cedric&amp;ref=commoncog.com"><em>post</em></a><em> in the private Commoncog members forum, as a response to a young person worried about AI making young knowledge workers obsolete.</em></p><p><em>The meta point of this response is that it is possible to <strong>act without prediction</strong> &#x2014; something that might not be obvious if you have never attempted to achieve outcomes in a </em><a href="https://commoncog.com/learning-from-waldrop-complexity/"><em>complex adaptive system</em></a><em>. But the truth is that most good businesspeople do NOT attempt to predict the future; instead, they design their lives and their organisations for &#x2018;fast adaptation under uncertainty&#x2019;. This is an idea that we&#x2019;ve </em><a href="https://commoncog.com/the-limits-of-superforecasting/"><em>covered</em></a><em> </em><a href="https://commoncog.com/much-ado-about-the-ooda-loop/"><em>before</em></a><em> on Commoncog. This letter provides a concrete example of what that looks like, at least for our current AI moment.</em></p><p><em>Another implication is that you may ignore any essay that attempts to predict the future. And you may do so with peace of mind. Read on to see why.</em></p><p>I&#x2019;ve been thinking about your question for a few days now, and I think I finally have a coherent response. In this past we&#x2019;ve discussed how <a href="https://forum.commoncog.com/t/cognitive-systems-engineering-as-a-worthwhile-field-to-steal-ideas-from-for-ai/2677/11?u=cedric&amp;ref=commoncog.com">difficult</a> it is to predict anything about the effects of AI adoption. I&#x2019;m not sure if I&#x2019;ve said this explicitly here, but I&#x2019;ve said elsewhere that the lesson I took away from the unpredictability of the Covid years is that prediction is hard and that humans are not smart enough; I shouldn&#x2019;t bother with it.</p><p>Of course that is easy to say, but hard to do. A more compelling way to put this is that &#x201C;you should learn to act without the need for narrow, accurate prediction&#x201D;. Which is why I feel more comfortable about the uncertainty of the current AI boom.</p><p>When I was preparing for this reply, a part of me thought about addressing your concerns directly. You linked to a <a href="https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf?ref=commoncog.com">research paper by OpenAI on why LLMs hallucinate</a>, with the implication that perhaps they would be able to cut down on such hallucinations. I sent the paper to an AI researcher friend and he laughed at it. (Technical argument: no matter what you do, you will never be able to solve aleatoric uncertainty in natural language). But I don&#x2019;t think attacking the paper is a good idea. In a way, the &#x2018;LLMs that hallucinate less&#x2019; result isn&#x2019;t the real thing you&#x2019;re asking. Say I get a bunch of AI researchers to debunk this and you are convinced. Tomorrow there may be yet another result, about a different AI capability, that implies &#x201C;everyone will lose their jobs and starve&#x201D; and you will extrapolate from that result the way you are extrapolating from this result.</p><p>No, the real problem is this:</p><ol><li>You are afraid you cannot get a job because AI.</li><li>You believe that in order to prevent (1), you must be able to predict the future accurately, never mind that the smartest people of every generation have atrociously bad track records of making predictions. <ol><li><em>(Maybe you think this time is different, and folks today are smarter. Maybe you think you just need to try harder and you will do better than prior generations.)</em></li></ol></li><li>So you spend a lot of cycles trying to predict and model changes in the world better.</li></ol><p>In truth, embedded within your worldview is a particular model of technological change. It goes something like this:</p><ul><li>A new technology arrives, and it changes society in breakneck time.</li><li>If you do not act before it changes society, you will be too late.</li><li>Because of the speed of change, it is not possible to watch what&#x2019;s happening <em>right now</em> and then act in response to it; you <em>must</em> predict accurately, <em>before it happens</em>, so that you don&#x2019;t get caught out by the change.</li></ul><p>Here is an alternative approach.</p><ol><li>You should read <em>actual</em> historical examples of technological change resulting in career displacement. Aim for at least 10. Find some that are breakneck fast, and some that take longer. Have a bias towards books, with oral histories or actual interviews with the workers being displaced by the new technology. It is ok to skim and jump to specific chapters about such displacement in those books, so you can finish this research project quicker. Examine across industries. (ChatGPT can help you, but I&#x2019;ll also give some suggestions later). Right now the model of technological change in your head is made up; <strong>it is not calibrated against real world examples of technological change</strong>.</li><li>Here is what you will find. (Again, my telling you this does NOT remove the need to go and do this research for yourself &#x2014; you can only <a href="https://commoncog.com/calibration-case-method/">calibrate properly</a> if you fill your head with the stories and experiences of others. Otherwise you will find that your brain will discount what I am telling you.) First, in the vast, vast majority of cases, it takes a <strong>long time for technological change to destroy jobs</strong>. Second, most of the folks making the most noise in a technological bubble either i) do not read history, ii) need to make it seem like their technology is world changing and the change is closer than anyone can ever imagine (because otherwise investors would not be willing to hand over their cash) &#x2026; or iii) blindly believe the folks who are talking their book and doing (ii) because &#x2014; haha &#x2014; they themselves do not read history and believe that the folks closest to a new technology are best-equipped to predict the future.</li><li>Once you are properly calibrated, you will have a better sense of how long these changes will take. I suspect that in your head, you currently think it will happen in a matter of &#x2026; months? Or perhaps one to two years? Whichever way it is, you&#x2019;ll think that this will happen fast enough that you will be caught wrong-footed.<ol><li>Or you are finding it difficult to get a job right now, and you think AI might be to blame or it might make things worse. This is a slightly different topic &#x2014; I currently believe that a) it is not AI, and b) you should not make predictions! But also c) there are so many other, more important factors that determine if YOU &#x2014; a single person in a specific job market &#x2014; will get a job that it is not productive to talk about it here. We may talk about that separately if you&#x2019;d like &#x2014; start a forum thread if that&#x2019;s something you want to do.</li></ol></li><li>Now: i) technological change takes longer than expected to destroy jobs, and ii) it is difficult to make predictions, especially about the future. If you are convinced by these two points, then it is actually a more prudent strategy to <em>wait, watch, and then act in response to real world, observable changes instead of speculation.</em> (Aka &#x201C;good businesspeople do not predict well, instead they do <a href="https://commoncog.com/what-uncertainty-feels-like/">fast adaptation</a> <a href="https://commoncog.com/much-ado-about-the-ooda-loop/">under uncertainty</a>&#x201D;). This is partly why I created the <a href="https://forum.commoncog.com/t/ai-field-reports/2487?ref=commoncog.com">AI Field Reports</a> topic.</li></ol><p>How do you verify for yourself that technological obsolescence is slower than everyone makes it out to be?</p><ul><li>You can ask ChatGPT for a list of books with detailed stories of worker obsolescence. For instance, <em>The Box</em> talks about how the invention of the shipping container changed the world, but it also contains bits about how the container destroyed the dockworker areas in major port cities like San Francisco and New York (because containers are easier to load and unload and do not require hundreds of dockhands). You should look for stories like this, and pay special attention to the years in the narrative, keeping track of how long it takes for the change to work its way through until it impacts the dockyard worker. As you are reading, put yourself in the worker&#x2019;s shoes, and keep asking &#x201C;In X year, would I have known? Is the impending obsolescence clear by then? Should I have acted? If I had not acted, how long more before it would become too late?&#x201D;</li><li>Read <a href="https://reactionwheel.net/2024/10/the-illusion-of-acceleration.html?ref=commoncog.com">The Illusion of Acceleration</a>. This is a summary of Everett Roger&#x2019;s <em>The Diffusion of Innovations</em>, which is apparently the classic text on the topic.</li><li>The single book that you want to get to, though, is <em>The Shock of the Old</em>, by David Edgerton. I want to say a bit more about this.</li></ul><p><em>The Shock of the Old</em> contains a <em>lot</em> of shocking factoids, like how:</p><ul><li>There were more horses deployed in World War II than in any other war in history. These horses were deployed <em>alongside tanks</em>, and outnumbered the total number of horses deployed during Napoleon&#x2019;s campaign and during the time of the Mongol hordes.</li><li>Peak horse in Finland&#x2019;s lumber industry was in <em>1950</em>.</li><li>More than a <em>decade</em> after the invention of the automobile, railroad companies owned 3x to 5x more horses than motorised vehicles.</li><li>New steam-powered ships were built as late as the 1920s &#x2014; even though gas powered motors were getting adopted en masse!</li><li>The rickshaw spread across Asia in the 60s and 70s, the same decade of the Space Race in the US. <em>Think about what that means: there were new rickshaw manufacturers who were expanding during the same time that man landed on the moon.</em></li><li>During the PC boom of the 80s through to the 90s, people were predicting the end of books. They predicted the end of books during the Internet bubble (90s) and again during the mobile revolution (2010s). We still buy paper books today; the main threat seems to be the death of reading.</li></ul><p>And so on so forth.</p><p>Why are these facts surprising to us?</p><p>Edgerton is a technology historian. He points out that whenever we go to a museum or watch a documentary, what we see is a history of <em>inventions</em>, not a history of <em>use</em>. So we all have this fake mental model of technological obsolescence in our heads: a new technology gets invented, and then we think everyone adopts it and the old tech dies a rapid death.</p><p>But Edgerton points out this is the exception, not the norm! And why this is the case is actually common sense. Technology is never used in a vacuum. It always exists in a sociotechnical system. That is, there are many years of maintenance know-how, training systems, regulations, unions or other organisations, existing processes, repair and maintenance supply chains all built up around the old technology. In order to change to a new technology, you also have to switch over all the other things around that technology. And that takes time.</p><p>And even in the fastest cases, it can take a few years. Meaning that there&#x2019;s plenty of time for you to <em>observe the change in the real world, and then switch based on your observations</em>.</p><p>Ignore the speculation, and ignore the predictions. Most of them are going to be wrong. Just look at what is happening <em>right now</em> &#x2014; you have plenty of time to adapt.</p>
  </body>
</html>
