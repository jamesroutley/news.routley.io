<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/rnn-lstm-gru-and-saliency-map/">Original</a>
    <h1>RNN, LSTM, GRU, and Saliency Map</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>Beneath a weathered cloak, three crafty goblins stand stacked, masquerading as an ancient wizard. Each goblin, akin to the layers of a Recurrent Neural Network. Every action built upon the input of others, warping the delicate weave of mana. Though seamless from the outside, this clever orchestration of individual parts works in mischievous harmony, each decision a product of collective cunning.</em></p>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/three-goblins.png" title="three-goblins" data-thumbnail="three-goblins.png" data-sub-html="&lt;h2&gt;Three goblins masquerading as a wizard&lt;/h2&gt;&lt;p&gt;three-goblins&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="three-goblins.png" data-srcset="three-goblins.png, three-goblins.png 1.5x, three-goblins.png 2x" data-sizes="auto" alt="three-goblins.png"/>
    </a><figcaption>Three goblins masquerading as a wizard</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Look through the archives for ancient magic, and implement the different flavors of recurrent neural networks whose power once reigned supreme and may rise anew to claim their throne.</p>
<h2 id="why-rnns">Why RNNs?</h2>
<p>RNNs arise from the need to handle sequences with variable lengths. By calling the RNN cell sequentially on each of its elements and passing along a compressed representation of the previous state.</p>
<h2 id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h2>
<p>RNNs are the most basic flavor, and give their name to the family of models. We start with a <code>memory</code> initialized to zeros, compute a simple function and pass it around.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>RNN</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>d_hidden</span> <span>=</span> <span>d_hidden</span>
</span></span><span><span>        <span>self</span><span>.</span><span>i2h</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span><span>,</span> <span>d_hidden</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>h2h</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>xs</span><span>,</span> <span>memory</span><span>=</span><span>None</span><span>,</span> <span>return_memory</span><span>=</span><span>False</span><span>):</span>
</span></span><span><span>        <span>batch</span><span>,</span> <span>d_context</span><span>,</span> <span>d_in</span> <span>=</span> <span>xs</span><span>.</span><span>shape</span>
</span></span><span><span>        <span>outs</span> <span>=</span> <span>[]</span>
</span></span><span><span>        <span>if</span> <span>memory</span> <span>is</span> <span>None</span><span>:</span> <span>memory</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>d_context</span><span>):</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>xs</span><span>[:,</span> <span>i</span><span>]</span>
</span></span><span><span>            <span>memory</span> <span>=</span> <span>F</span><span>.</span><span>tanh</span><span>(</span><span>self</span><span>.</span><span>i2h</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>self</span><span>.</span><span>h2h</span><span>(</span><span>memory</span><span>))</span>
</span></span><span><span>            <span>outs</span><span>.</span><span>append</span><span>(</span><span>memory</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>outs</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span></code></pre></div><h2 id="long-short-term-memory-lstm">Long short-term memory (LSTM)</h2>
<p>LSTMs try to address the shortcomings of RNNs by adding some kind of residual / skip connection to help the gradients flow between stages. We still have to handle the input, the short-term memory <code>h_prev</code>, but also a long-term memory <code>c_prev</code>.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>LSTMCell</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_f</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># forget gate</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_i</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># input gate</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_c</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># cell state update</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_o</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># output gate</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>,</span> <span>h_prev</span><span>,</span> <span>c_prev</span><span>):</span>
</span></span><span><span>        <span>x</span> <span>=</span> <span>t</span><span>.</span><span>cat</span><span>((</span><span>x</span><span>,</span> <span>h_prev</span><span>),</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span><span><span>        <span># handle long-term memory `c`</span>
</span></span><span><span>        <span>f_gate</span> <span>=</span> <span>t</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>W_f</span><span>(</span><span>x</span><span>))</span>
</span></span><span><span>        <span>i_gate</span> <span>=</span> <span>t</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>W_i</span><span>(</span><span>x</span><span>))</span>
</span></span><span><span>        <span>c_update</span> <span>=</span> <span>t</span><span>.</span><span>tanh</span><span>(</span><span>self</span><span>.</span><span>W_c</span><span>(</span><span>x</span><span>))</span>
</span></span><span><span>        <span>c_prev</span> <span>=</span> <span>f_gate</span> <span>*</span> <span>c_prev</span> <span>+</span> <span>i_gate</span> <span>*</span> <span>c_update</span>
</span></span><span><span>        <span># handle short-term memory `h`</span>
</span></span><span><span>        <span>o_gate</span> <span>=</span> <span>t</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>W_o</span><span>(</span><span>x</span><span>))</span>
</span></span><span><span>        <span>h_prev</span> <span>=</span> <span>o_gate</span> <span>*</span> <span>t</span><span>.</span><span>tanh</span><span>(</span><span>c_prev</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>h_prev</span><span>,</span> <span>c_prev</span>
</span></span></code></pre></div><p>We orchestrate the LSTMCell in the same way as for RNN.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>LSTM</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>d_hidden</span> <span>=</span> <span>d_hidden</span>
</span></span><span><span>        <span>self</span><span>.</span><span>lstm_cell</span> <span>=</span> <span>LSTMCell</span><span>(</span><span>d_in</span><span>,</span> <span>d_hidden</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>xs</span><span>,</span> <span>h_prev</span><span>=</span><span>None</span><span>,</span> <span>c_prev</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>        <span>batch</span><span>,</span> <span>d_context</span><span>,</span> <span>d_in</span> <span>=</span> <span>xs</span><span>.</span><span>shape</span>
</span></span><span><span>        <span>hs</span><span>,</span> <span>cs</span> <span>=</span> <span>[],</span> <span>[]</span>
</span></span><span><span>        <span>if</span> <span>h_prev</span> <span>is</span> <span>None</span><span>:</span> <span>h_prev</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>if</span> <span>c_prev</span> <span>is</span> <span>None</span><span>:</span> <span>c_prev</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>d_context</span><span>):</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>xs</span><span>[:,</span> <span>i</span><span>]</span>
</span></span><span><span>            <span>h_prev</span><span>,</span> <span>c_prev</span> <span>=</span> <span>self</span><span>.</span><span>lstm_cell</span><span>(</span><span>x</span><span>,</span> <span>h_prev</span><span>,</span> <span>c_prev</span><span>)</span>
</span></span><span><span>            <span>hs</span><span>.</span><span>append</span><span>(</span><span>h_prev</span><span>)</span>
</span></span><span><span>            <span>cs</span><span>.</span><span>append</span><span>(</span><span>c_prev</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>hs</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>),</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>cs</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span></code></pre></div><h2 id="gated-recurrent-unit-gru">Gated Recurrent Unit (GRU)</h2>
<p>GRUs are a simplification of LSTMs while retaining most of the performance.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>GRUCell</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_r</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># reset gate</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_z</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># update gate</span>
</span></span><span><span>        <span>self</span><span>.</span><span>W_h</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_in</span> <span>+</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span>  <span># hidden state update</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>,</span> <span>h_prev</span><span>):</span>
</span></span><span><span>        <span>cat</span> <span>=</span> <span>t</span><span>.</span><span>cat</span><span>((</span><span>x</span><span>,</span> <span>h_prev</span><span>),</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span><span><span>        <span>r_gate</span> <span>=</span> <span>t</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>W_r</span><span>(</span><span>cat</span><span>))</span>
</span></span><span><span>        <span>z_gate</span> <span>=</span> <span>t</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>W_z</span><span>(</span><span>cat</span><span>))</span>
</span></span><span><span>        <span>h_candidate</span> <span>=</span> <span>t</span><span>.</span><span>tanh</span><span>(</span><span>self</span><span>.</span><span>W_h</span><span>(</span><span>t</span><span>.</span><span>cat</span><span>((</span><span>x</span><span>,</span> <span>r_gate</span> <span>*</span> <span>h_prev</span><span>),</span> <span>dim</span><span>=</span><span>1</span><span>)))</span>
</span></span><span><span>        <span>h_prev</span> <span>=</span> <span>(</span><span>1</span> <span>-</span> <span>z_gate</span><span>)</span> <span>*</span> <span>h_prev</span> <span>+</span> <span>z_gate</span> <span>*</span> <span>h_candidate</span>
</span></span><span><span>        <span>return</span> <span>h_prev</span>
</span></span></code></pre></div><p>The driving code remains the same.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>GRU</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>d_hidden</span> <span>=</span> <span>d_hidden</span>
</span></span><span><span>        <span>self</span><span>.</span><span>gru_cell</span> <span>=</span> <span>GRUCell</span><span>(</span><span>d_in</span><span>,</span> <span>d_hidden</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>xs</span><span>,</span> <span>h_prev</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>        <span>batch</span><span>,</span> <span>d_context</span><span>,</span> <span>d_in</span> <span>=</span> <span>xs</span><span>.</span><span>shape</span>
</span></span><span><span>        <span>outs</span> <span>=</span> <span>[]</span>
</span></span><span><span>        <span>if</span> <span>h_prev</span> <span>is</span> <span>None</span><span>:</span> <span>h_prev</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>d_context</span><span>):</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>xs</span><span>[:,</span> <span>i</span><span>]</span>
</span></span><span><span>            <span>h_prev</span> <span>=</span> <span>self</span><span>.</span><span>gru_cell</span><span>(</span><span>x</span><span>,</span> <span>h_prev</span><span>)</span>
</span></span><span><span>            <span>outs</span><span>.</span><span>append</span><span>(</span><span>h_prev</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>outs</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span></code></pre></div><h2 id="bonus-stacked-lstm">Bonus: Stacked LSTM</h2>
<p>Now all of the above can be stacked. To put the <em>deep</em> in deep learning. The Cell remains unchanged. Adding more depth to the network will, in principle, let us learn more complex functions.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>StackedLSTM</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_in</span><span>,</span> <span>d_hidden</span><span>,</span> <span>d_layers</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>d_hidden</span> <span>=</span> <span>d_hidden</span>
</span></span><span><span>        <span>self</span><span>.</span><span>d_layers</span> <span>=</span> <span>d_layers</span>
</span></span><span><span>        <span>self</span><span>.</span><span>lstm_cells</span> <span>=</span> <span>nn</span><span>.</span><span>ModuleList</span><span>([</span><span>LSTMCell</span><span>(</span><span>d_in</span> <span>if</span> <span>l</span> <span>==</span> <span>0</span> <span>else</span> <span>d_hidden</span><span>,</span> <span>d_hidden</span><span>)</span> <span>for</span> <span>l</span> <span>in</span> <span>range</span><span>(</span><span>d_layers</span><span>)])</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>xs</span><span>,</span> <span>h_prev</span><span>=</span><span>None</span><span>,</span> <span>c_prev</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>        <span>batch</span><span>,</span> <span>d_context</span><span>,</span> <span>d_in</span> <span>=</span> <span>xs</span><span>.</span><span>shape</span>
</span></span><span><span>        <span>outs</span> <span>=</span> <span>[]</span>
</span></span><span><span>        <span>if</span> <span>h_prev</span> <span>is</span> <span>None</span><span>:</span> <span>h_prev</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>self</span><span>.</span><span>d_layers</span><span>,</span> <span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>if</span> <span>c_prev</span> <span>is</span> <span>None</span><span>:</span> <span>c_prev</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>self</span><span>.</span><span>d_layers</span><span>,</span> <span>batch</span><span>,</span> <span>self</span><span>.</span><span>d_hidden</span><span>,</span> <span>device</span><span>=</span><span>xs</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>d_context</span><span>):</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>xs</span><span>[:,</span> <span>i</span><span>]</span>
</span></span><span><span>            <span>h_next</span><span>,</span> <span>c_next</span> <span>=</span> <span>[],</span> <span>[]</span>
</span></span><span><span>            <span>for</span> <span>lstm_cell</span><span>,</span> <span>h</span><span>,</span> <span>c</span> <span>in</span> <span>zip</span><span>(</span><span>self</span><span>.</span><span>lstm_cells</span><span>,</span> <span>h_prev</span><span>,</span> <span>c_prev</span><span>):</span>
</span></span><span><span>                <span>h</span><span>,</span> <span>c</span> <span>=</span> <span>lstm_cell</span><span>(</span><span>x</span><span>,</span> <span>h</span><span>,</span> <span>c</span><span>)</span>
</span></span><span><span>                <span>h_next</span><span>.</span><span>append</span><span>(</span><span>h</span><span>)</span>
</span></span><span><span>                <span>c_next</span><span>.</span><span>append</span><span>(</span><span>c</span><span>)</span>
</span></span><span><span>                <span>x</span> <span>=</span> <span>h</span>
</span></span><span><span>            <span>outs</span><span>.</span><span>append</span><span>(</span><span>h</span><span>)</span>
</span></span><span><span>            <span>h_prev</span> <span>=</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>h_next</span><span>)</span>
</span></span><span><span>            <span>c_prev</span> <span>=</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>c_next</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>t</span><span>.</span><span>stack</span><span>(</span><span>outs</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>),</span> <span>h_prev</span><span>,</span> <span>c_prev</span>
</span></span></code></pre></div><h2 id="next-token-prediction-learn-alices-adventures-in-wonderland">Next Token Prediction: Learn Alice’s Adventures in Wonderland</h2>
<p>Let’s train a character level next token predictor on a classic.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>AliceStackedLSTM</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>d_vocab</span><span>,</span> <span>d_hidden</span><span>,</span> <span>d_layers</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>embed</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>d_vocab</span><span>,</span> <span>d_hidden</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>stacked_lstm</span> <span>=</span> <span>StackedLSTM</span><span>(</span><span>d_hidden</span><span>,</span> <span>d_hidden</span><span>,</span> <span>d_layers</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>unembed</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_hidden</span><span>,</span> <span>d_vocab</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>unembed</span><span>.</span><span>weight</span> <span>=</span> <span>self</span><span>.</span><span>embed</span><span>.</span><span>weight</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>xs</span><span>):</span>
</span></span><span><span>        <span>xs</span> <span>=</span> <span>self</span><span>.</span><span>embed</span><span>(</span><span>xs</span><span>)</span>
</span></span><span><span>        <span>out</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>self</span><span>.</span><span>stacked_lstm</span><span>(</span><span>xs</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>self</span><span>.</span><span>unembed</span><span>(</span><span>out</span><span>)</span>
</span></span></code></pre></div><p>Train for a bunch of epochs.</p>
<p><img src="https://blog.apnic.net/svg/loading.min.svg" data-src="loss.png" data-srcset="loss.png, loss.png 1.5x, loss.png 2x" data-sizes="auto" alt="loss.png" title="loss"/></p>
<table>
<thead>
<tr>
<th>Epoch</th>
<th>Sample</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>AMz-((uuqshpggpgppzzSg(zp(gqq(zh((-((ggzq(pz(qgzzS(uh</td>
</tr>
<tr>
<td>100</td>
<td>A) asel tho the therad in h the as t icl ooud shand the as tha s</td>
</tr>
<tr>
<td>400</td>
<td>Alien the the calked a that of the heres all should sayt, and to seen it</td>
</tr>
<tr>
<td>3000</td>
<td>As after her playing again and made all the roof. (she was surprised</td>
</tr>
<tr>
<td>10000</td>
<td>Alice, and they sawn Alice of the sky-boxed the Queen</td>
</tr>
</tbody>
</table>
<h3 id="how-does-the-model-choose-the-next-token">How does the model choose the next token</h3>
<p>I made a small widget inspired by the Anthropic papers to look at how the model chooses the next token.</p>
<p>When hovering, we can see:</p>
<ul>
<li>the activations of the last layer</li>
<li>the top 5 predicted tokens</li>
<li>the influence of preceding tokens, positive in red, negative in blue</li>
</ul>
<p>(PS: It looks cuter in light-mode)</p>


<p>I can’t say that the results are very intuitive to me. Looking at the second word, <code>l</code>, <code>o</code>, and <code>o</code> all encourage <code>k</code>, which goes nicely with my idea, but <code>e</code> doesn’t get much support even though it’s a 99% favorite to get picked.</p>
<h2 id="image-classification-and-saliency-map">Image Classification and Saliency Map</h2>
<p>RNNs can also be used for classification. First, we tokenize the images; it could be by row, column, in a spiral pattern…</p>
<p>For the demo, I’ll use tiles.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>reshape_tile</span><span>(</span><span>xs</span><span>,</span> <span>tile</span><span>=</span><span>7</span><span>):</span>
</span></span><span><span>    <span>batch</span><span>,</span> <span>c</span><span>,</span> <span>h</span><span>,</span> <span>w</span> <span>=</span> <span>xs</span><span>.</span><span>shape</span>
</span></span><span><span>    <span>assert</span> <span>h</span> <span>%</span> <span>tile</span> <span>==</span> <span>0</span>
</span></span><span><span>    <span>assert</span> <span>w</span> <span>%</span> <span>tile</span> <span>==</span> <span>0</span>
</span></span><span><span>    <span>assert</span> <span>c</span> <span>==</span> <span>1</span>
</span></span><span><span>    <span>xs</span> <span>=</span> <span>xs</span><span>.</span><span>view</span><span>(</span><span>batch</span><span>,</span> <span>h</span> <span>//</span> <span>tile</span><span>,</span> <span>tile</span><span>,</span> <span>w</span> <span>//</span> <span>tile</span><span>,</span> <span>tile</span><span>)</span>
</span></span><span><span>    <span>xs</span> <span>=</span> <span>xs</span><span>.</span><span>permute</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>3</span><span>,</span> <span>2</span><span>,</span> <span>4</span><span>)</span>
</span></span><span><span>    <span>xs</span> <span>=</span> <span>xs</span><span>.</span><span>contiguous</span><span>()</span><span>.</span><span>view</span><span>(</span><span>batch</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>tile</span> <span>*</span> <span>tile</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>xs</span>
</span></span></code></pre></div><p><img src="https://blog.apnic.net/svg/loading.min.svg" data-src="tiling.gif" data-srcset="tiling.gif, tiling.gif 1.5x, tiling.gif 2x" data-sizes="auto" alt="tiling.gif" title="tiling"/></p>
<h3 id="compare-different-models-accuracy-and-saliency-map">Compare Different Models: Accuracy and Saliency Map</h3>
<p>Training for a few epochs just to get an idea of how capable the models are. The code for all the models is available on <a href="https://github.com/peluche/RNN-LSTM-GRU/blob/master/rnn-lstm-gru.ipynb" target="_blank" rel="noopener noreffer ">github</a>.</p>
<p>For each model we’ll compute the accuracy on the test set.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>@t.no_grad</span><span>()</span>
</span></span><span><span><span>def</span> <span>accuracy</span><span>(</span><span>model</span><span>,</span> <span>dataloader</span><span>=</span><span>testloader</span><span>,</span> <span>reshape</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>    <span>model</span><span>.</span><span>eval</span><span>()</span>
</span></span><span><span>    <span>assert</span> <span>reshape</span> <span>is</span> <span>not</span> <span>None</span>
</span></span><span><span>    <span>correct</span><span>,</span> <span>total</span> <span>=</span> <span>0</span><span>,</span> <span>0</span>
</span></span><span><span>    <span>for</span> <span>xs</span><span>,</span> <span>ys</span> <span>in</span> <span>dataloader</span><span>:</span>
</span></span><span><span>        <span>xs</span> <span>=</span> <span>reshape</span><span>(</span><span>xs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>))</span>
</span></span><span><span>        <span>out</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>)</span>
</span></span><span><span>        <span>correct</span> <span>+=</span> <span>(</span><span>out</span><span>.</span><span>argmax</span><span>(</span><span>-</span><span>1</span><span>)</span> <span>==</span> <span>ys</span><span>.</span><span>to</span><span>(</span><span>device</span><span>))</span><span>.</span><span>sum</span><span>()</span>
</span></span><span><span>        <span>total</span> <span>+=</span> <span>len</span><span>(</span><span>xs</span><span>)</span>
</span></span><span><span>    <span>model</span><span>.</span><span>train</span><span>()</span>
</span></span><span><span>    <span>return</span> <span>correct</span> <span>/</span> <span>total</span>
</span></span></code></pre></div><p>As well as a saliency map.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>saliency</span><span>(</span><span>model</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>,</span> <span>accumulate</span><span>=</span><span>1</span><span>,</span> <span>noise</span><span>=</span><span>None</span><span>,</span> <span>reshape</span><span>=</span><span>reshape_default</span><span>):</span>
</span></span><span><span>    <span>model</span><span>.</span><span>eval</span><span>()</span>
</span></span><span><span>    <span>x</span><span>,</span> <span>y</span> <span>=</span> <span>x</span><span>.</span><span>to</span><span>(</span><span>device</span><span>),</span> <span>y</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>x</span><span>.</span><span>requires_grad</span> <span>=</span> <span>True</span>
</span></span><span><span>    <span>x</span><span>.</span><span>grad</span> <span>=</span> <span>None</span>
</span></span><span><span>    <span>xs</span> <span>=</span> <span>reshape</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>    <span>out</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>)</span>
</span></span><span><span>    <span>loss</span> <span>=</span> <span>-</span><span>out</span><span>[</span><span>0</span><span>,</span> <span>y</span><span>]</span>
</span></span><span><span>    <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>    <span>return</span> <span>x</span><span>.</span><span>grad</span>
</span></span></code></pre></div><h4 id="mnist">MNIST</h4>
<p>All the models’ performances are fairly similar.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLP</td>
<td>0.961</td>
</tr>
<tr>
<td>CNN</td>
<td>0.988</td>
</tr>
<tr>
<td>RNN by rows</td>
<td>0.964</td>
</tr>
<tr>
<td>GRU by rows</td>
<td>0.982</td>
</tr>
<tr>
<td>LSTM by rows</td>
<td>0.987</td>
</tr>
<tr>
<td>LSTM by tiles</td>
<td>0.966</td>
</tr>
</tbody>
</table>
<p>What is interesting is how different the saliency maps look across architectures.</p>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/mnist-1.png" title="mnist-1" data-thumbnail="mnist-1.png" data-sub-html="&lt;h2&gt; &lt;/h2&gt;&lt;p&gt;mnist-1&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="mnist-1.png" data-srcset="mnist-1.png, mnist-1.png 1.5x, mnist-1.png 2x" data-sizes="auto" alt="mnist-1.png"/>
    </a><figcaption> </figcaption>
    </figure>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/mnist-2.png" title="mnist-2" data-thumbnail="mnist-2.png" data-sub-html="&lt;h2&gt; &lt;/h2&gt;&lt;p&gt;mnist-2&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="mnist-2.png" data-srcset="mnist-2.png, mnist-2.png 1.5x, mnist-2.png 2x" data-sizes="auto" alt="mnist-2.png"/>
    </a><figcaption> </figcaption>
    </figure>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/mnist-9.png" title="mnist-9" data-thumbnail="mnist-9.png" data-sub-html="&lt;h2&gt; &lt;/h2&gt;&lt;p&gt;mnist-9&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="mnist-9.png" data-srcset="mnist-9.png, mnist-9.png 1.5x, mnist-9.png 2x" data-sizes="auto" alt="mnist-9.png"/>
    </a><figcaption> </figcaption>
    </figure>
<p>Based on the images, I would have assumed the CNN would significantly outperform everything else, but the GRU and LSTM by rows have similar accuracies.</p>
<h4 id="fashion-mnist">Fashion MNIST</h4>
<p>Once again, the accuracies are pretty similar.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLP</td>
<td>0.883</td>
</tr>
<tr>
<td>CNN</td>
<td>0.881</td>
</tr>
<tr>
<td>RNN by rows</td>
<td>0.850</td>
</tr>
<tr>
<td>GRU by rows</td>
<td>0.881</td>
</tr>
<tr>
<td>LSTM by rows</td>
<td>0.869</td>
</tr>
<tr>
<td>LSTM by tiles</td>
<td>0.857</td>
</tr>
</tbody>
</table>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/fmnist-shirt.png" title="fmnist-shirt" data-thumbnail="fmnist-shirt.png" data-sub-html="&lt;h2&gt; &lt;/h2&gt;&lt;p&gt;fmnist-shirt&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="fmnist-shirt.png" data-srcset="fmnist-shirt.png, fmnist-shirt.png 1.5x, fmnist-shirt.png 2x" data-sizes="auto" alt="fmnist-shirt.png"/>
    </a><figcaption> </figcaption>
    </figure>
<figure><a href="https://blog.apnic.net/2024/06/18/off-path-tcp-hijacking-in-nat-enabled-wi-fi-networks/fmnist-shoe.png" title="fmnist-shoe" data-thumbnail="fmnist-shoe.png" data-sub-html="&lt;h2&gt; &lt;/h2&gt;&lt;p&gt;fmnist-shoe&lt;/p&gt;">
        <img src="https://blog.apnic.net/svg/loading.min.svg" data-src="fmnist-shoe.png" data-srcset="fmnist-shoe.png, fmnist-shoe.png 1.5x, fmnist-shoe.png 2x" data-sizes="auto" alt="fmnist-shoe.png"/>
    </a><figcaption> </figcaption>
    </figure>
<p>This time, I would have put my money on the MLP.</p>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/RNN-LSTM-GRU/blob/master/rnn-lstm-gru.ipynb" target="_blank" rel="noopener noreffer ">https://github.com/peluche/RNN-LSTM-GRU/blob/master/rnn-lstm-gru.ipynb</a></p>
<h2 id="sources">Sources</h2>
<p>For nice visualizations of the different RNNs architectures: <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener noreffer ">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
</div></div>
  </body>
</html>
