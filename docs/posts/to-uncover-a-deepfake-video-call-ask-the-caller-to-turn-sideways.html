<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/">Original</a>
    <h1>To Uncover a Deepfake Video Call, Ask the Caller to Turn Sideways</h1>
    
    <div id="readability-page-1" class="page"><div data-id="230321ec" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>There is an interesting vulnerability in video deepfakes that, to date, has been generally overlooked by the security research community, perhaps because ‘live’, real-time deepfakes in video calls have not been a major cause for concern until very recently.</p><p>For a number of reasons, which we’ll examine in this article, deepfakes are not usually very good at recreating profile views:</p><p>The above examples are taken* from a session with tech exponent and commenter <a href="https://www.youtube.com/playlist?list=PLR2tU9z819XsueWxXiOBUM5aOj-u9Gm6V">Bob Doyle</a>, who agreed to run some tests with us, using <a href="https://github.com/iperov/DeepFaceLive">DeepFaceLive</a> to change his appearance to that of a series of popular celebrities.</p><p>DeepFaceLive is a live-streaming version of the popular <a href="https://github.com/iperov/DeepFaceLab">DeepFaceLab</a> software, and is capable of creating alternate video identities in real-time.</p><p>For these tests, Bob used a mix of models downloaded from deepfake communities, as well as some community-trained models that come bundled with the DeepFaceLive application.</p><p>From more or less face-on viewpoints, most of the celebrity recreations are quite effective, and some are very convincing even at fairly acute angles – until the facial angle hits a full 90°.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-scaled.jpg" sizes="(max-width: 2560px) 100vw, 2560px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-scaled.jpg 2560w, https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-300x162.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-1024x552.jpg 1024w, https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-768x414.jpg 768w, https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-1536x828.jpg 1536w, https://metaphysic.ai/wp-content/uploads/2022/08/Examples-Of-DeepFaceLive-Failures-2048x1104.jpg 2048w" alt="Examples from the DeepFaceLive session, showing authentic-looking faces – except in profile view. Thanks to Bob Doyle, the &#39;host&#39; for these personalities." width="2560" height="1380"/><figcaption>Examples from the DeepFaceLive session, showing authentic-looking faces – except in profile view. Thanks to Bob Doyle, the ‘host’ for these personalities.</figcaption></figure><p>It’s evident also that Bob’s real profile lineaments entirely survive the deepfake process for all these models, none of which have been trained with enough good-quality profile data to be capable of either transforming the distinct boundaries of the face, or performing the <a href="https://www.nvidia.com/research/inpainting/index.html">inpainting</a> necessary to simulate ‘revealed background’ (i.e. when the ‘host’s’ profile extends further than that of the ‘guest’ identity, and more of the background needs to be ‘invented’ – see image below).</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/Keanu_Bob.jpg" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/Keanu_Bob.jpg 500w, https://metaphysic.ai/wp-content/uploads/2022/08/Keanu_Bob-274x300.jpg 274w" alt="Any shortfall between the facial profile of the target identity and that of the host will have to be &#39;invented&#39; by the deepfake model, through inpainting. This kind of capability is only likely to develop in the model if it has been trained on abundant profile views, to a very high number of iterations (usually over a million, which may take 6-10 days, depending on resolution and settings)." width="500" height="548"/><figcaption>Any shortfall between the facial profile of the target identity and that of the host will have to be ‘invented’ by the deepfake model, through inpainting. This kind of capability is only likely to develop in the model if it has been trained on abundant profile views, to a very high number of iterations (usually over a million, which may take 6-10 days, depending on resolution and settings).</figcaption></figure><p>Why does recreation fail so steeply when a deepfaked subject goes into sharp 90° profile? Is this a possible way to detect whether or not the person you’re talking to in a videoconference is real or deepfaked? And what, if anything, can deepfakers themselves do to ‘fix’ it?</p><h2>Lateral Limitations</h2><p>The standard software (<a href="https://github.com/1adrianb/face-alignment">Facial Alignment Network</a>) that estimates facial poses in images, in deepfakes packages, does not work reliably at acute angles. In fact, most 2D-based facial alignments algorithms assign only 50-60% of the number of landmarks from a front-on face view to a profile view.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/Multi-view-Hourglass-Model.jpg" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/Multi-view-Hourglass-Model.jpg 1000w, https://metaphysic.ai/wp-content/uploads/2022/08/Multi-view-Hourglass-Model-300x215.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/Multi-view-Hourglass-Model-768x550.jpg 768w" alt="From the 2015 paper &#39;Joint Multi-view Face Alignment in the Wild&#39;, which showcases the Multi-view Hourglass facial alignment model. Frontal alignments contain 68 landmarks, while profile alignments have only 39. Source: https://arxiv.org/pdf/1708.06023.pdf" width="1000" height="716"/><figcaption>From the 2015 paper ‘Joint Multi-view Face Alignment in the Wild’, which showcases the Multi-view Hourglass facial alignment model. Frontal alignments contain 68 landmarks, while profile alignments have only 39. Source: https://arxiv.org/pdf/1708.06023.pdf</figcaption></figure><p>Typical 2D alignment packages consider a profile view to be 50% hidden, which hinders recognition, as well as accurate training and subsequent face synthesis.</p><p>Frequently the generated profile landmarks will ‘leap out’ to any possible group of pixels that may represent a ‘missing eye’ or other facial detail that’s obscured in a profile view:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/All_The_Presidents_Men_FAN_Align-1.gif" alt="All_The_Presidents_Men_FAN_Align" width="800" height="370"/></p><p>In the above example, we see some typical profile extraction issues in a clip from <i>All The President’s Men</i> (1976), in spite of the fact that there are no distracting background patterns (such as wallpaper or patterned curtains) to ‘fool’ FAN Align into believing that they might constitute part of a face (which is a common problem).</p><p>For this reason, in spite of manual intervention and various clean-up processes that can be used, sheer profile shots are likely to be less temporally consistent than most frames in extracted videos, as well as in the training of deepfake models based on those extracted images, and in the final reconstruction, where a new identity is finally superimposed on a ‘target’.</p><h2>The ‘Profile Data’ Desert Outside Hollywood</h2><p>Cognizant of this weak spot in deepfakes, most viral deepfakers tend to avoid using clips that require well-trained, accurate and temporally consistent profile views.</p><p>Some, however, have made a special effort. YouTube deepfaker DesiFakes <a href="https://www.youtube.com/watch?v=S1MBVXkQbWU&amp;lc=UgxCMZu_f3Q_ESJeRbV4AaABAg.9Y9BWy3758E9Y9RZAh2jW4">told us</a> that he achieved an extraordinary profile view of Jerry Seinfeld inserted into a tense scene from <i>Pulp Fiction</i> (1994) through extensive post-processing, and that the above-average side-view of Seinfeld is aided also by a close resemblance between the comedian and original actor Alexis Arquette:</p><p><iframe title="Jerry Seinfeld in Pulp Fiction [DeepFake]" width="800" height="450" data-src="https://www.youtube.com/embed/S1MBVXkQbWU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>For such heroic (and untypical) profile efforts, we need to consider the high availability of data for notable Hollywood TV and movie actors. By itself, the TV show <i>Seinfeld</i> represents 66 hours of available footage, the majority featuring Jerry Seinfeld, with abundant profile footage on display due to the frequent multi-person conversations.</p><p>Matt Damon’s current <a href="https://www.imdb.com/name/nm0000354/#actorMovie">movie output</a> alone, likewise, has a rough combined runtime of 144 hours, most of it available in high-definition.</p><p>By contrast, how many profile shots do you have of yourself?</p><p>Unless you’ve been arrested at some point, it’s likely that you don’t have even <i>one</i> such image, either on social media or in an offline collection.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/Jane-Fonda-arrest-picture-1024x599.jpg" sizes="(max-width: 800px) 100vw, 800px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/Jane-Fonda-arrest-picture-1024x599.jpg 1024w, https://metaphysic.ai/wp-content/uploads/2022/08/Jane-Fonda-arrest-picture-300x176.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/Jane-Fonda-arrest-picture-768x449.jpg 768w, https://metaphysic.ai/wp-content/uploads/2022/08/Jane-Fonda-arrest-picture.jpg 1200w" alt="Jane Fonda in profile, aged 32, courtesy of the Cleveland police department, who arrested her in November of 1970 on (contested) charges of drug smuggling. Note that even this right-hand image is not a pure profile view, but at best an 80-85° stance (Fonda herself has long since embraced the iconic status of this image). Source: https://clevelandmemory.contentdm.oclc.org/digital/collection/general/id/8076/rec/2" width="800" height="468"/><figcaption>Jane Fonda in profile, aged 32, courtesy of the Cleveland police department, who arrested her in November of 1970 on (contested) charges of drug smuggling. Note that even this right-hand image is not a pure profile view, but at best an 80-85° stance (Fonda herself has <a href="https://archive.ph/2PiAW">long since embraced</a> the iconic status of this image). Source: https://clevelandmemory.contentdm.oclc.org/digital/collection/general/id/8076/rec/2</figcaption></figure><p>Besides clinicians, VFX artists, forensics experts and police authorities, nobody wants profile shots. Photographers will fight a crowd to escape them; picture editors can’t sell them (or can’t sell them as well as a ‘real’ photo); and they are in general charmless and prosaic representations of us that many of us literally would barely even recognize as ourselves.</p><p>Ioana Grecu, Content Manager for the stock image domain Dreamstime, comments to us on the slim demand for the side-on view:</p><p><i>‘Most customers of stock sites will look for images that connect with their end subject. My guess is that a profile shot will do this job in only very few and specific cases and mostly only in instances where a concept image is needed.’</i></p><p>And continues:</p><p><i>‘[The] profile shot is one of the least flattering ones and the one where not much can be expressed either by the model or the camera angle. While a photographer can use light to express emotion, such an image would likely not be fit for your expressed purpose…The main reason photographers don’t take these shots is because there are so many more angles that have more to offer in a traditional photo shoot.’</i></p><h2>Using Profile Requests for Deepfake Detection in Video Calls</h2><p>That paucity of available data makes it difficult to obtain a range of profile images on <i>non</i>-celebrities that’s diverse and extensive enough to train a deepfake model to reproduce profile views convincingly.</p><p>Consequently, this weakness in deepfakes offers a potential way of uncovering ‘simulated’ correspondents in live video calls, recently <a href="https://www.techspot.com/news/95119-fbi-warns-more-criminals-using-deepfakes-remote-job.html">classified as an emergent risk</a> by the FBI: if you suspect that the person you’re talking to might be a ‘deepfake clone’, you could ask them to turn sideways for more than a second or two, and see if you’re still convinced by their appearance.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/sly-sideways.gif" alt="sly-sideways" width="600" height="492"/></p><p>Arguably, this approach could be extended to automated systems that ask the user to adopt various poses in order to authenticate their entry into banking and other security-critical systems.</p><p>In May of this year, AI-based security company Sensity released a <a href="https://www.theverge.com/2022/5/18/23092964/deepfake-attack-facial-recognition-liveness-test-banks-sensity-report">report</a>, and a <a href="https://www.youtube.com/shorts/rLmxdIHpZtU">supporting video</a>, demonstrating a DeepFaceLive-style system that apparently succeeds in fooling a liveness detector by superimposing a deepfaked identity onto a potential attacker in real-time.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/deepfake-sensity.jpg" sizes="(max-width: 900px) 100vw, 900px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/deepfake-sensity.jpg 900w, https://metaphysic.ai/wp-content/uploads/2022/08/deepfake-sensity-300x234.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/deepfake-sensity-768x599.jpg 768w" alt="A snapshot of a part of a Sensity video demonstrating a deepfake-driven attack on a liveness detector. Source: https://www.theverge.com/2022/5/18/23092964/deepfake-attack-facial-recognition-liveness-test-banks-sensity-report" width="900" height="702"/><figcaption>A snapshot of a part of a Sensity video demonstrating a deepfake-driven attack on a liveness detector. Source: https://www.theverge.com/2022/5/18/23092964/deepfake-attack-facial-recognition-liveness-test-banks-sensity-report</figcaption></figure><p>However, none of the accompanying videos show the subject in acute profile. We asked Sensity’s CEO and Chief Scientist Giorgio Patrini if the experiments and tests included the subject making 90° turns from camera as part of the deception technique, and he confirmed<sup>†</sup> that they did not.</p><p>We also asked him if he considers that there is any possible merit in soliciting profile views as an anti-deepfake measure during videoconferencing calls. Patrini responded:</p><p><i>‘Lateral views of people faces, when used as a form of identity verification, may indeed provide some additional protection against deepfakes. As pointed out, the lack of widely available profile view data make the training of deepfake detector very challenging. </i></p><p><i>‘Additionally, I’d argue that most state of the art deepfake software simply fails if applied for faceswapping or re-enacting faces fully rotated on their side. This is because deepfake software needs to accurately detect faces and their landmarks on the target video; profile views make this more difficult as the detector has to work with only half of the facial key points. </i></p><p><i>‘Indeed, one tip for performing deepfake detection “by eye” today is to check whether one can spot face artefacts or flickering while a person is turning completely to their side — where it’s more likely that a face landmarks detector would have failed.’</i></p><p>Further, we asked deepfake expert <a href="https://www.buffalo.edu/news/experts/siwei-lyu-faculty-expert-deepfakes-computer-vision.html?par_list_0_start=0">Dr. Siwei Lyu</a>, Professor of Computer Science and Engineering at the University at Buffalo School of Engineering and Applied Sciences,  if this ‘lateral’ approach potentially has any value in deepfake detection in a live video scenario. He agreed that it does:</p><p><i>‘The profile is a big problem for current deepfake technologies. The FAN network works extremely well for frontal faces, but not very well for side-on faces.</i></p><p><i>‘The lack of available data is certainly an obstacle. Another aspect is that these algorithms do have a fundamental limitation: the alignment mechanism works well if you cover only part of your face, and is quite robust in those circumstances – but when you turn around, more than half the landmarks are missing. </i></p><p><i>‘Probably the best an algorithm can do is to roughly estimate the profile, particularly if the person is enacting various expressions, or taking requests from the other correspondent in a video call, or from an automated liveness detection system. </i></p><p><i>‘In a case like that, profile estimation is going to be kind of a ‘guess’, even if you were to have some depth information from some of the more recent sensors in smartphones.’</i></p><p>However, Dr. Lyu believes that the emerging new generation of 3D landmark location systems could improve on FAN’s performance (though FAN itself can also enact 3D landmarks, and is used by DeepFaceLab in this way for ‘full head’ pose capture), but notes that this would not solve the problem of the lack of profile data for ‘non-famous’ people who deepfake attackers might want to train into models for deceptive purposes in a videoconference scenario.</p><p>In the absence of high-quality profile images as source training input, Dr. Lyu does not feel that novel-view synthesis systems such as <a href="https://metaphysic.ai/nerf-successor-deepfakes/">NeRF</a>, Generative Adversarial Networks (GANs) and Signed Distance Fields (<a href="https://arxiv.org/pdf/1912.07109.pdf">SDF</a>) are likely to be able to provide the necessary level of inference and detail in order to accurately imitate a person’s profile views – at least, to a level that could stand up to the reasonably high-resolution capabilities of modern smartphone cameras and laptop webcams, which represent the likeliest environments for a deepfake attack.</p><p><i>‘The problem is that you would have to make up information on the basis of inadequate, estimated data. Perhaps you could use a GAN model and get something similar, but the data would not be likely to stand up to cross-checking on a user who has already been legitimately en</i><i>rolled into a liveness detection system, for instance.’</i></p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/3DDFA-V2.jpg" sizes="(max-width: 1078px) 100vw, 1078px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/3DDFA-V2.jpg 1078w, https://metaphysic.ai/wp-content/uploads/2022/08/3DDFA-V2-300x92.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/3DDFA-V2-1024x313.jpg 1024w, https://metaphysic.ai/wp-content/uploads/2022/08/3DDFA-V2-768x234.jpg 768w" alt="A new generation of facial alignment models are using parametric CGI templates to help estimate facial poses more accurately, including profile poses. However, there is no evidence that these more sophisticated models will be integrated into popular deepfakes packages, nor could such systems solve the remaining issues around profile quality by themselves. This example is from Version 2 of the 3DDFA package, a collaboration between various Chinese universities. Source: https://arxiv.org/pdf/2009.09960.pdf" width="1078" height="329"/><figcaption>A new generation of facial alignment models are using parametric CGI templates to help estimate facial poses more accurately, including profile poses. However, there is no evidence that these more sophisticated models will be integrated into popular deepfakes packages, nor could such systems solve the remaining issues around profile quality by themselves. This example is from Version 2 of the 3DDFA package, a collaboration between various Chinese universities. Source: https://arxiv.org/pdf/2009.09960.pdf</figcaption></figure><h2>Could Profile Data Be Synthesized?</h2><p>Facial profile synthesis is an unusual pursuit in computer vision, not least because demand is slim. Nonetheless, there is an ongoing strand of research that concentrates on profiles.</p><p>This year the University of Taipei released a research <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf">paper</a> called <i>Dual-Generator Face Reenactment</i>, the accompanying material of which provides a few rare samples of entirely 90° deviations generated from less oblique material, notably in the below example, which also includes actor Adam Driver:</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/dual-generator-face-reenactment.jpg" sizes="(max-width: 810px) 100vw, 810px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/dual-generator-face-reenactment.jpg 810w, https://metaphysic.ai/wp-content/uploads/2022/08/dual-generator-face-reenactment-300x247.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/dual-generator-face-reenactment-768x632.jpg 768w" alt="Profile faces (far right) synthesized from more frontal source input material. Source: https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf" width="810" height="667"/><figcaption>Profile faces (far right) synthesized from more frontal source input material. Source: https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf</figcaption></figure><p>The majority of the paper’s accompanying examples stop short of this extreme angle, at around the 80° mark also found in the Sensity material from May.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/dual_image_generator-1.gif" alt="A little short of 90 degrees, pose variations created by Dual Generator Face Reenactment. Source: https://github.com/AvLab-CV/Dual_Generator_Face_Reenactment/blob/main/result.gif" width="512" height="512"/><figcaption>A little short of 90 degrees, pose variations created by Dual Generator Face Reenactment. Source: https://github.com/AvLab-CV/Dual_Generator_Face_Reenactment/blob/main/result.gif</figcaption></figure><p>It’s just a few degrees, but it seems to make all the difference, and getting there reliably and with authenticity would be no minor milestone for a live deepfake streaming system, or the models that power it:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/cruise-80-and-90-degrees.jpg" sizes="(max-width: 694px) 100vw, 694px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/cruise-80-and-90-degrees.jpg 694w, https://metaphysic.ai/wp-content/uploads/2022/08/cruise-80-and-90-degrees-300x170.jpg 300w" alt="cruise-80-and-90-degrees.jpg" width="694" height="394"/></p><p>Deepfakers have been experimenting with the use of CGI-human simulations as training data practically since the technology emerged in 2017. Currently that interest has switched to applying deepfakes to Unreal Engine <a href="https://www.unrealengine.com/en-US/metahuman">MetaHuman</a> simulations – a ‘CGI replacement’ scenario where a real person controls a completely simulated person who is being deepfaked in real time:</p><p><iframe title="Metahuman Unreal Engine Live Link Face with ScarJo" width="800" height="450" data-src="https://www.youtube.com/embed/jZMFe4oN4FQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>The converse case is where a hyper-realistic CGI head is created for the purpose of <a href="https://www.unite.ai/disentanglement-is-the-next-deepfake-revolution/">providing ‘missing’ angles</a> (such as profile views) in a training dataset for a deepfake model.</p><p>However, deepfakes have been capable, almost from the start, of producing more realistic and convincing images than CGI can, because they’re based on real data rather than artistic interpretation. Therefore, not only is this a backward approach to the challenge, but it would require a level of industry-standard artistry even to ‘fail well’.</p><p>The 2005 <a href="https://link.springer.com/book/10.1007/978-0-85729-932-1"><i>Handbook of Face Recognition</i></a> includes some interesting material regarding profile recognition and synthesis, and features a use-case of a security system that only has profile access to a target, who is driving a car, and can only be seen in profile. To this end, the system seeks to extrapolate profile views from other views at a prior stage.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/handbook-of-face-recognition.jpg" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/handbook-of-face-recognition.jpg 700w, https://metaphysic.ai/wp-content/uploads/2022/08/handbook-of-face-recognition-300x177.jpg 300w" alt="From the Handbook of Face Recognition, the basic principles of estimating profile geometry based on a very different point of view. Source: http://what-when-how.com/face-recognition/face-recognition-using-3d-images-face-recognition-techniques-part-1/" width="700" height="413"/><figcaption>From the Handbook of Face Recognition, the basic principles of estimating profile geometry based on a very different point of view. Source: http://what-when-how.com/face-recognition/face-recognition-using-3d-images-face-recognition-techniques-part-1/</figcaption></figure><p>The image above illustrates the central idea of novel viewpoint synthesis (including the generation of profile views) – that alternate-viewpoint estimation can potentially infer a model accurately enough to resolve well from any angle.</p><p>Short of volunteering to be 3D-bodyscanned by a visual effects house (in which case, one could expect that the data would be highly controlled), this can be achieved by using depth-map information on frontal views, LIDAR information, or simply, as in the case of NeRF (see below), visual geometry estimation.</p><p>There are a number of frameworks offering such conversion processes, such as the Heges iOS app, which supports LIDAR as of iOS 14.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/Heges_3D.gif" alt="Profile views obtained from the Heges app. Source: https://hege.sh/" width="622" height="410"/><figcaption>Profile views obtained from the Heges app. Source: https://hege.sh/</figcaption></figure><p>Facial inference of this type, though not always powered by LIDAR, is now trivial technology: in 2017, Apple <a href="https://www.washingtonpost.com/news/the-switch/wp/2017/11/30/apple-is-sharing-your-face-with-apps-thats-a-new-privacy-worry/">hit the headlines</a> when it was revealed that scans from the iPhone X’s front sensors, which can obtain 30,000 points from an iPhone user’s face, was apparently being made available to app developers.</p><p>Neural Radiance Fields (NeRF) can, in theory, extrapolate any number of facial angles from just a handful of pictures, which could be used to train an autoencoder model (presuming that NeRF-related technologies do not advance beyond autoencoders in the next few years).</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/NVIDIA_Instant_NeRF_examples-2.gif" alt="NVIDIA&#39;s InstantNeRF extrapolates an impressive range of facial views from just four images, but resolution, expression accuracy and mobility remain major challenges to high-resolution inference. Source: https://www.youtube.com/watch?v=DJ2hcC1orc4" width="800" height="320"/><figcaption>NVIDIA’s InstantNeRF extrapolates an impressive range of facial views from just four images, but resolution, expression accuracy and mobility remain major challenges to high-resolution inference. Source: https://www.youtube.com/watch?v=DJ2hcC1orc4</figcaption></figure><p>However, as we noted in our <a href="https://metaphysic.ai/nerf-successor-deepfakes/">June feature on NeRF</a>, at the moment, issues around resolution, facial mobility and temporal stability hinder NeRF from producing the rich data needed to train an autoencoder model that can handle profile images well. Additionally, really accurate NeRF profile inferences are likely to need original, genuine profile data that includes a range of expressions; if that’s available, you won’t need NeRF anyway.</p><p>In fact, the hallmarks of inferred profiles using <i>any</i> existing technology are a) rigid faces, b) inadequate resolution and c) poor fidelity of expression and facial pose. To effectively simulate a wide range of profile data at a suitably high resolution, inferred data is not adequate – at least not at the current state of the art.</p><p>Nor is it possible, as it so often is in computer vision research, to simply bolt on an existing Python library or open source dataset and benefit from ‘upstream efforts’. <i>No-one</i> has that profile-centric data, and no-one has <i>ever</i> had that data; and, unless you’re quite famous, no-one has access to your particular side-views, because your profile view doesn’t interest anyone (usually not even you). At least, not yet.</p><h2>Edge Cases</h2><p>There are possible exceptions to this ‘security-by-obscurity’ safeguard, even for potential deepfake victims that are not famous. For instance, we mentioned earlier that the social set-up of <i>Seinfeld</i> (i.e., frequent group conversations) tends to put its star into profile more often than leading actors in a typical headlining role.</p><p>Likewise, one social media video of this type (perhaps an interview scenario), at a reasonably high resolution and featuring a sustained profile view, could provide a deepfaker with enough material to generate the data needed to exhaustively train lateral viewpoints to a high standard.</p><p>Even so, a single video is unlikely to provide every possible facial expression necessary. It would be trivial for a liveness detection system to request the person at the other end of a potential deepfake authentication session to enact certain expressions and poses that it has on record, such as mouth aperture, tightly-shut eyes, and particularly smiling (which affects the topography of the face <a href="https://eprints.whiterose.ac.uk/132466/1/Smiles_in_face_matching_Mileva_Burton_2018.pdf">in unpredictable ways</a> that are difficult to estimate from a limited viewpoint), and expect that the subject could reproduce expressions that the deepfake model cannot.</p><p>Including ‘rare’ facial poses and dispositions in facial enrolment is <a href="https://www.imore.com/how-train-face-id-recognize-differnt-expressions">already part</a> of facial ID culture. Adding the ‘obscurity’ of these facial changes to already rare facial profile data could further help liveness systems to distinguish real from fake face-based login attempts.</p><h2>Profile-Based Recognition Systems</h2><p>In 2017, researchers from the Netherlands developed a face-based security system <a href="https://ris.utwente.nl/ws/files/71635819/automaticfacerecognition.pdf">that keys on profiles</a>.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/video-based-side-view-face-images.jpg" sizes="(max-width: 950px) 100vw, 950px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/video-based-side-view-face-images.jpg 950w, https://metaphysic.ai/wp-content/uploads/2022/08/video-based-side-view-face-images-300x180.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/video-based-side-view-face-images-768x460.jpg 768w" alt="he Dutch system keys on profile recognition, and has to account for obstruction of ears, and the various other challenges that make profile data acquisition normally so difficult. Source: https://ris.utwente.nl/ws/files/71635819/automaticfacerecognition.pdf" width="950" height="569"/><figcaption>The Dutch system keys on profile recognition, and <a href="https://subs.emis.de/LNI/Proceedings/Proceedings212/337.pdf">has to account</a> for obstruction of ears, and the various other challenges that make profile data acquisition normally so difficult. Source: https://ris.utwente.nl/ws/files/71635819/automaticfacerecognition.pdf</figcaption></figure><p>Though the work does not aid potential deepfake attackers, it does offer a rare example of a curated database that concentrates on pure profile views, and addresses the challenge of the limited number of landmarks that are available in a side-view, and represents an unusual foray into the facial profile as a potential enrolment tool.</p><p>In the late 2010s, the University of Houston also offered some <a href="https://cgi.di.uoa.gr/~graphics/Downloads/papers/conferences/s38.pdf">seminal work</a> on a profile-based facial recognition system, which acquires an estimated 3D model of a user at enrolment time, and uses this as a reference for estimated profile comparisons of subjects that are acquired from the side whilst driving.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/facial-profile-system-Houston.jpg" sizes="(max-width: 797px) 100vw, 797px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/facial-profile-system-Houston.jpg 797w, https://metaphysic.ai/wp-content/uploads/2022/08/facial-profile-system-Houston-300x174.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/facial-profile-system-Houston-768x444.jpg 768w" alt="Illustrations from the Houston paper. Top left, the data capture equipment; top right, select fitted 3D face models which will eventually yield profile view data; bottom left, the base 3D template, the raw data, and the fitted facial capture; bottom right, different poses that fit within the latitude of a &#39;profile&#39; definition. The method retains an active patent. Source: https://cgi.di.uoa.gr/~graphics/Downloads/papers/conferences/s38.pdf" width="797" height="461"/><figcaption>Illustrations from the Houston paper. Top left, the data capture equipment; top right, select fitted 3D face models which will eventually yield profile view data; bottom left, the base 3D template, the raw data, and the fitted facial capture; bottom right, different poses that fit within the latitude of a ‘profile’ definition. The method retains an <a href="https://patentimages.storage.googleapis.com/0f/0b/75/71c2ffc71a9121/US20090310828A1.pdf">active patent</a>. Source: https://cgi.di.uoa.gr/~graphics/Downloads/papers/conferences/s38.pdf</figcaption></figure><h2>Mattes Matter</h2><p>There are other possible requests one can make to a potential deepfake video caller that can be helpful in determining their authenticity, though none of them are quite as data-starved or (for the moment) impervious to improvement as profile examination.</p><p>Live deepfake video shares a common problem with augmented reality – the need to <a href="https://github.com/ad8454/Hand-Detection-AR">superimpose real hand images</a> and other kinds of real obstruction onto a non-real image. In the visual effects world, these superimpositions are known as ‘mattes’, <i>rotoscoping</i>, or ‘background removal’.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/druzil-tech-and-games.jpg" sizes="(max-width: 798px) 100vw, 798px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/druzil-tech-and-games.jpg 798w, https://metaphysic.ai/wp-content/uploads/2022/08/druzil-tech-and-games-300x132.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/druzil-tech-and-games-768x338.jpg 768w" alt="YouTube deepfaker Druuzil Tech and Games stumbles across some digital disruption while impersonating Scarlett Johansson and Patrick Stewart. Sources: https://youtu.be/C4kU4emoowk?t=501 and https://youtu.be/kjEWX67jS6U?t=102" width="798" height="351"/><figcaption>YouTube deepfaker Druuzil Tech and Games stumbles across some digital disruption while impersonating Scarlett Johansson and Patrick Stewart. Sources: https://youtu.be/C4kU4emoowk?t=501 and https://youtu.be/kjEWX67jS6U?t=102</figcaption></figure><p>In rendered-out deepfake videos (i.e. viral videos on YouTube and TikTok, that cannot be altered), the deepfaker is able to elaborately rotoscope away any facial obstructions – such as hands or fingers – that proved too complex for the automated matting process of <a href="https://www.youtube.com/watch?v=kOIMXt8KK8M">XSeg</a> (DeepFaceLab/<a href="https://github.com/MachineEditor/MachineVideoEditor">Machine Video Editor</a>) or trained <a href="https://github.com/zllrunning/face-parsing.PyTorch">BiseNet</a> weights (FaceSwap).</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/machine_video_editor.gif" alt="Masking out obstructions in Machine Video Editor (MVE), an extended platform that primarily supports the DeepFaceLab workflow. Source: https://www.youtube.com/watch?v=EpWmdGfvXR0" width="600" height="338"/><figcaption>Masking out obstructions in Machine Video Editor (MVE), an extended platform that primarily supports the DeepFaceLab workflow. Source: https://www.youtube.com/watch?v=EpWmdGfvXR0</figcaption></figure><p>On the other hand, a ‘live’ deepfake model needs the capacity to perform matting at will, and on request, to an acceptably convincing level. This may involve including many images that deliberately feature facial obstructions (including artificially-generated obstructions) in the training dataset, so that the model is at least a little better prepared to handle sudden facial intrusions and obfuscations.</p><p>However, no matter how well it’s trained, asking a video caller to wave their hands in front of their face creates a critical situation for the model, which is likely to demonstrate poor latency and quality of superimposition over the deepfaked face:</p><p>Such matte glitches are currently a useful indicator of a potential deepfake video caller, but they’re potentially a more solvable problem than the absence of authentic profile data, and not likely to endure as a reliable ‘tell’ in the long term.</p><h2>Conclusion</h2><p>In recent weeks, the FBI’s warning about potential live deepfake fraud has been <a href="https://www.fox23.com/news/bbb-warns-about-scammers-using-deepfakes/6L73KYL45BHLLIK4VCXUJHHERU/">reiterated by the Better Business Bureau</a>, and it seems that what was once an improbable attack vector is set to grow, and to continue to <a href="https://fortune.com/2022/06/27/fake-kyiv-klitschko-giffey-ludwig-martinez-almeida-karacsony-colau-deepfake-ai/">capture</a> <a href="https://www.tomsguide.com/news/forget-lying-on-your-resume-now-people-are-using-deepfakes-for-video-interviews">headlines</a>.</p><p>The research community has been <a href="https://arxiv.org/pdf/2204.12067.pdf">deeply engaged</a> in the development of deepfake detection technologies since the inception of the phenomenon, but are, to an extent, hindered by the fact that they cannot interact with the material that they’re investigating.</p><p>Nonetheless, there are a growing number of solutions emerging that could be applied as a security layer in video calls, including <a href="https://farid.berkeley.edu/downloads/publications/cvpr22a.pdf">measuring monitor illumination</a>; evaluating <a href="https://arxiv.org/pdf/2207.06612.pdf">inconsistency in facial regions</a>; using the recognized parameters of known deepfake models <a href="https://arxiv.org/pdf/2106.07873.pdf">as a security signature</a>; cataloguing and detecting <a href="http://ceur-ws.org/Vol-3084/paper2.pdf">consistent artefacts in deepfake video</a>; embedding facets <a href="https://arxiv.org/pdf/2204.03083.pdf">of a known and trusted video</a> into a detection system; and comparing potential deepfaked video content <a href="https://arxiv.org/pdf/2204.03083.pdf">against known biometric traits</a>, among many other approaches.</p><p>In live video conversations, there are additional possible ways to ask video correspondents to help authenticate themselves, such as by turning to hard profile, and checking if facial obstructions are poorly matted. Algorithmic security systems can add to this the possibility of <a href="https://farid.berkeley.edu/downloads/publications/cvpr21a.pdf">ear recognition</a>, and the plethora of new approaches to deepfake detection, many of which are likely to be as effective on ‘live’ content as they are on rendered video.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/biden-ear-recognition.jpg" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/biden-ear-recognition.jpg 1000w, https://metaphysic.ai/wp-content/uploads/2022/08/biden-ear-recognition-300x85.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/biden-ear-recognition-768x218.jpg 768w" alt="From the university of Berkeley, one recent suggestion for an additional deepfake recognition vector is based on ear recognition. Source: https://farid.berkeley.edu/downloads/publications/cvpr21a.pdf" width="1000" height="284"/><figcaption>From the university of Berkeley, one recent suggestion for an additional deepfake recognition vector is based on ear recognition. Source: https://farid.berkeley.edu/downloads/publications/cvpr21a.pdf</figcaption></figure><p>The real threat of such attacks could be that <a href="https://arxiv.org/pdf/2202.10673.pdf">we are not expecting them</a>, and are likely to actually <i>aid</i> deepfake attackers by dismissing artefacts and glitches that might have raised our state of alert if we were more aware of how fallible video and audio content is becoming.</p><figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://metaphysic.ai/wp-content/uploads/2022/08/flv_system.jpg" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://metaphysic.ai/wp-content/uploads/2022/08/flv_system.jpg 1000w, https://metaphysic.ai/wp-content/uploads/2022/08/flv_system-300x189.jpg 300w, https://metaphysic.ai/wp-content/uploads/2022/08/flv_system-768x485.jpg 768w" alt="Schematic of the workflow of a recent system designed to defeat Facial Liveness Verification (FLV) through the injection of deepfakes into a live video scenario, created as a security research tool by researchers in the US and China. Source: https://arxiv.org/pdf/2202.10673.pdf" width="1000" height="631"/><figcaption>Schematic of the workflow of a recent system designed to defeat Facial Liveness Verification (FLV) through the injection of deepfakes into a live video scenario, created as a security research tool by researchers in the US and China. Source: https://arxiv.org/pdf/2202.10673.pdf</figcaption></figure><p>Perhaps in the future, video content of any kind will be relegated to the same status as the ‘<a href="https://www.history.com/news/paul-revere-engraving-boston-massacre">on-the-spot’ engravings</a> that adorned newspapers and books prior to the advent of reproducible photography, and viewed as potentially <i>representative</i> of the truth, rather than as an authentic token of truth in itself.</p><p><i>* My great thanks to Bob Doyle for running these tests with me. The video showing profile failures is a local capture taken at Bob’s end by OBS Studio, and is therefore not affected by encoding errors that might occur with Zoom and other videoconferencing software. Bob’s DeepFaceLive implementation was running on a NVIDIA 2070S graphics card with 8GB of VRAM.</i></p><p><sup>†</sup> <i>In an email dated July 3rd 2022.</i></p></div></div></div>
  </body>
</html>
