<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://30fps.net/pages/palette-lighting-tricks-n64/">Original</a>
    <h1>Palette lighting tricks on the Nintendo 64</h1>
    
    <div id="readability-page-1" class="page"><div id="text">

<p><em>This article is a continuation to <a href="https://bsky.app/profile/pekkavaa.bsky.social/post/3lnnwax4vxk2v">my Bluesky thread</a> from April.</em></p>
<!-- ![](castello_screenshot.jpg) -->
<p>We made a Nintendo 64 demo for <a href="https://2025.revision-party.net/">Revision 2025</a>!</p>
<center>
<iframe width="100%" src="https://www.youtube.com/embed/v3wYV6gxJII" title="Real-time tech demo Castello (N64)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</center>
<p>It has baked lighting with normal mapping and real-time specular shading, ahem, well sort of.
More on that later.
The beautiful song was made by <a href="https://bsky.app/profile/did:plc:svoizwy5mp6q4ol6j2pu74we">noby</a> with guitar performed by Moloko (<a href="https://soundcloud.com/sou_andrade">https://soundcloud.com/sou_andrade</a>).</p>
<p>Below I have some notes on the directional ambient and normal mapping techniques I developed.
They are both pretty simple in the end but I haven‚Äôt seen them used elsewhere.</p>
<h2 id="but-wait-normal-mapping-on-the-n64">But wait, normal mapping on the N64?</h2>
<p>I knew normal mapping on the N64 was possible due to earlier experiments by fellow homebrew developers WadeTyhon and <a href="https://www.youtube.com/@SpookyIluha">Spooky Iluha</a>. I had also done <a href="https://www.youtube.com/watch?v=UOHdDllyqOU">some emboss bump mapping hacks</a> myself.</p>
<p>The approach explained in this article is not new: <strong>the renderer computes lighting directly to textures at runtime</strong>.
It‚Äôs great because no specialized hardware support is needed and you can run arbitrary shading code on the CPU.
Too bad it‚Äôs so slow‚Ä¶</p>
<!-- The Nintendo 64 supports no shaders but it has a bunch of registers you can program for different combinations of textures and interpolated vertex colors. This kind of graphics hardware is known as a "register combiner" and it's also how early GeForce chips worked. -->
<h2 id="shading-a-palette-instead">Shading a palette instead</h2>
<p>So the idea is to do texture-space shading on the CPU.
But what if it‚Äôs a palette texture we‚Äôre shading?
Those are very common on the N64 anyway.
In that case it‚Äôs enough to update <em>only the palette</em> and the texture will respond as if we computed lighting for each texel.
Instant savings!</p>
<!-- In this case it's optimized by fitting a 256-color palette to the normal map, and then computing lighting only for each entry in the palette for speed. -->
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/palettes_example.jpg" alt="A demonstration of ‚Äúpalette-space‚Äù shading. When the palettes update, the full textures update too. When mapped to an object, it looks like the shading changed."/>
<figcaption aria-hidden="true">A demonstration of ‚Äúpalette-space‚Äù shading. When the palettes update, the full textures update too. When mapped to an object, it looks like the shading changed.</figcaption>
</figure>
<p>The original palette is replaced with a shaded palette and the palette texture is applied as a regular texture to an object.
With just a diffuse ‚Äúdot(N,L)‚Äù lighting the results look pretty good:
<!-- The shading model is basically `color=basecolor*dot(normal, light)`, but since this is on the CPU side, you could use any formula. --></p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/potatorock.png" alt="Another view of the above potato-shaped rock mesh."/>
<figcaption aria-hidden="true">Another view of the above potato-shaped rock mesh.</figcaption>
</figure>
<!-- The result looks pretty convincing if you don't see any UV map seams. -->
<p>In the above example I also did shading in linear space by undoing the gamma correction of the color texture :) In the final demo it wasn‚Äôt possible because I split the ambient and direct light terms to be combined by N64‚Äôs RDP unit in hardware.</p>
<h3 id="object-space-normal-mapping">Object-space normal mapping</h3>
<p>Usually normal mapping is done in tangent space.
This is way you can use repeating textures and the fine normals can modulate smoothly varying vertex normals.
A tangent-space normal map of a single color represents a smooth surface.</p>
<p>An object-space normal is simpler but more constrained.
Now the normal map‚Äôs texels don‚Äôt represent deviations from the vertex normals but absolute surface normals instead.
The runtime math becomes simpler ‚Äì just read a color from a texture ‚Äì but all surface points now need a unique texel, like in lightmaps.</p>
<!-- ![An early object-space normal mapping experiment in Blender. I reduced the color count of a baked normal map in an image editor and reapplied it back on the object. The results validated that the approach might work.](2025-01-21-object-space-normal-map-compression-comparison.jpg) -->
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/baseline_vs_32_palette_objectspace_normalmap.png" alt="An early experiment to validate the approach on a high-res normal map. Left: The original object-space normal map. Right: Compressed to a 32-color palette."/>
<figcaption aria-hidden="true">An early experiment to validate the approach on a high-res normal map.</figcaption>
</figure>

<p>The objects have both a diffuse texture (basecolor * ao) and a normal map.
Both textures actually share the same palette indices that I generated with scikit-learn‚Äôs <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">K-means clustering</a>.
The images were interpreted as a single six-channel image for that to work.
<!-- It took a lot of tweaking to persuade k-means to behave and weight both textures fairly. --></p>
<p>Below is an example how the compression looks with a tangent-space normal map.</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/compression_diagram.png" alt="A roof tile texture compression example. An RGB diffuse texture and a normal map are both compressed to a 16-color palette image in a way that palette indices are shared. Therefore the actual image data has to be stored just once at 4 bits per pixel."/>
<figcaption aria-hidden="true">A roof tile texture compression example. An RGB diffuse texture and a normal map are both compressed to a 16-color palette image in a way that palette indices are shared. Therefore the actual image data has to be stored just once at 4 bits per pixel.</figcaption>
</figure>
<!-- The objects still need a varying surface color, even though they are shaded with a normal map. -->
<!-- I achieved this by combining a diffuse map and an object-space normal map to a single six-channel image, and fit a palette to *that*. -->
<!-- I had to tweak the colors-vs-normals weights for each texture though. -->
<p>At shading time, which can happen on load or on each frame, each palette color is processed in a for loop.
A single index is used to fetch a normal and a surface diffuse color.
The CPU-side shader code then produces a new RGB color for that index.
The result of the loop is a new palette but with shading applied.</p>
<p>Unfortunately this approach only really works with directional lights.
It‚Äôs also difficult to represent any kind of shadows with just the palette alone.
That‚Äôs why I started looking into how baked lighting could fit in the to the equation.</p>
<h2 id="baked-directional-ambient-and-sun-light">Baked directional ambient and sun light</h2>
<p>I wanted the demo to have a building with realistic lighting.
Perhaps it was a bit too ambitiousüòÖ
After a lot of deliberation, I put ambient and direct sun lighting in vertex color RGB and alpha channels, respectively.
The ambient term is further split into a directional intensity (a greyscale environment map) and color (vertex RGB with a saturation boost).
The sun is a directional light whose visibility is transmitted in vertex alpha.</p>
<p>The shading formula is therefore this:</p>
<pre><code>ambient = vertex_rgb      * grey_irradiance_map(N) 
direct  = vertex_alpha    * sun_color * dot(N, sun_dir)
color   = diffuse_texture * (ambient + direct)</code></pre>
<!-- Ambient color is stored in `vertex_rgb` and sun visibility in `vertex_alpha`. -->
<p>Here‚Äôs how the different terms look:</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/lighting_comparison.jpg" alt="Lighting decomposition."/>
<figcaption aria-hidden="true">Lighting decomposition.</figcaption>
</figure>
<p>Note how the messy ‚ÄúSun visibility‚Äù vertex colors get neatly masked out by the sun (N.L) computation in the bottom right corner.
In the end the ambient and direct terms are summed to get the shaded result below.</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/shaded.jpg" alt="Shaded result."/>
<figcaption aria-hidden="true">Shaded result.</figcaption>
</figure>
<p>The thing about directional ambient is that even the baked lighting is rough, the details in the textures still make it look pretty high end.
Consider this scene that has just a colored blurred environment map and per-vertex ambient occlusion:</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/ibl.png" alt="Image-based ambient lighting. In this image only an ambient sky light is enabled. Also shows the palettes used (top left corner)."/>
<figcaption aria-hidden="true">Image-based ambient lighting. In this image only an ambient sky light is enabled. Also shows the palettes used (top left corner).</figcaption>
</figure>
<p>It really pops!
I love image-based lighting.</p>
<p>For the blurred environment maps, I used an equirectangular projection for simplicity.
Polyhaven‚Äôs HDRIs already use the projection.
Since I precomputed the shading at load time, the complex sampling math wasn‚Äôt an issue.</p>
<!-- Consider these messy vertex colors:

![Direct light intensity only.](pillars_vertex_alpha.png)

When these vertex colors are modulated by the surface texture, the shaded normal map, and a directional ambient term, the shading looks pretty convincing:

![Combined ambient and direct light.](pillars_shaded.png)

Here's using a colored environment and per-vertex ambient occlusion: -->
<!-- Conceptually, on each texture texel the renderer samples the irradiance map with the surface normal, multiplies the resulting sky color with the surface color. In this case the texture is then modulated by per-vertex ambient occlusion but in the final demo I also had other bounce light in the vertex color RGB channels. -->
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/hdri_plot.png" alt="Visualization of an 64x32 environment map (right) before it gets blurred to an irradiance map. The dot sphere on the left shows the image pixels mapped to unit sphere directions."/>
<figcaption aria-hidden="true">Visualization of an 64x32 environment map (right) before it gets blurred to an irradiance map. The dot sphere on the left shows the image pixels mapped to unit sphere directions.</figcaption>
</figure>
<!-- Both ambient and direct light respect normal maps. Ambient uses image-based lighting and the direct light is just a single directional light. Environment lighting is provided by a greyscale irradiance map (think of a blurred cubemap) and is later modulated by vertex colors. -->
<!-- ![The original 3D reconstruction geometry was way too dense.](zumaglia_wireframe2.png)

![A cleaned-up model. I used Instant Meshes for this step. It's really good!](zumaglia_mesh2.png)

The castle model in the demo is based on [a 3D reconstruction by Sketchfab user andxet](https://sketchfab.com/3d-models/zumaglias-castle-bi-italy-8ef740a8ca31498c9e8f73b1c27a3298).
I retopo'd and textured it myself. I'm still very slow working in Blender so the model was left in a pretty rough state in the end.
[Instant Meshes](https://github.com/wjakob/instant-meshes) was a great help in this process. -->
<h2 id="shading-a-larger-model-with-repeating-textures">Shading a larger model with repeating textures</h2>
<p>I designed the original shading algorithm for single objects and only tested it with the <code>potato_rock.obj</code> you saw in the beginning.
For the demo, the castle mesh‚Äôs repeating textures posed a problem.
As a workaround, I split the large mesh into submeshes that each conceptually share the same object-space normal map.</p>
<p>The task was done primarily by yours truly manually in Blender, by grouping geometry by material and surface direction.
The computer did its part by calculating a world-to-model matrix based on polygon normals for each group.
That is a pretty much an approximate tangent space.
So I couldn‚Äôt escape them in the end!</p>
<p>Each of these groups shares a palette so as a whole their lighting will be correct only in the average sense.</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/cube_tangents.png" alt="Tangent-space basis vector visualization for a simple cube. In the final model many polygons that point roughly in the same direction have to share the same tangent space."/>
<figcaption aria-hidden="true">Tangent-space basis vector visualization for a simple cube. In the final model many polygons that point roughly in the same direction have to share the same tangent space.</figcaption>
</figure>
<p>The tangent spaces are <em>not</em> interpolated at runtime, which shows up as faceted lighting.
This is perhaps the biggest downside of this technique.</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/lighting_facet.png" alt="Lighting isn‚Äôt interpolated smoothly on this arch because the tangent spaces are constant over polygons, unlike in proper tangent-space normal mapping."/>
<figcaption aria-hidden="true">Lighting isn‚Äôt interpolated smoothly on this arch because the tangent spaces are constant over polygons, unlike in proper tangent-space normal mapping.</figcaption>
</figure>
<!-- The skydome consists of a 32x64 texture that repeats horizontally and a cut sphere with some vertex coloring. I think it looked alright in the end, even though it is blurry.

![The skydome model.](skydome.jpg)

Regarding bloom, it's done on the CPU and composited back as a white quad with an alpha texture. A bit slow and buggy thoughüôÇ

![The sky dome with some bloom.](skydomebloom.jpg)

Finally, the white "egg" was supposed to be just a test model that I replace with something else. Well, that didn't happen!

![How the ending of the demo could have been.](cat_statue.jpg)

It's a perfect sphere but due to projection precision issues (!) it got stretched. Later I wanted to put a cat sit on top of it but sadly couldn't make it look right on time.üòø -->
<h2 id="specular-shading">Specular shading</h2>
<!-- Unfortunately many surface points now share a single shaded color. -->
<p>Since many surface points now share the same shaded color, computing point light or specular shading correctly is not possible.
The ‚Äúpalette-space‚Äù approach only really works for diffuse directional lights because the shading formulas don‚Äôt need a ‚Äúto camera‚Äù vector <span><em>V</em></span>, which depends on the position of the shaded surface point.
Yet still I tried to hack it for the speculars :)</p>
<p>If we approximate the object to be shaded as a sphere, then the point <em>p</em> being shaded is simply <code>p=radius*normal</code>.
We must also accept that the result will look faceted since many surface points share the same palette index.</p>
<figure>
<img src="https://30fps.net/pages/palette-lighting-tricks-n64/lion.jpg" alt="Fresnel shading. The sculpt was approximated as a stretched sphere in lighting calculations."/>
<figcaption aria-hidden="true">Fresnel shading. The sculpt was approximated as a stretched sphere in lighting calculations.</figcaption>
</figure>
<p>In the demo, the specular highlights looked a bit funny but still they seemed to fool most people. I count this as a success.</p>
<h2 id="is-this-the-future">Is this the future?</h2>
<p>In the demo I tried to hide the main limitations of the technique: shading discontinuities, only greyscale textures supported (!), no point lights.
So it really only works with elaborate preprocessing.
I‚Äôd love to see the shading discontinuity issue solved somehow (Spooky Iluha‚Äôs techniques don‚Äôt have it) without losing support for both ambient and direct lighting.
I don‚Äôt know if it‚Äôs possible but that‚Äôs what makes this hobby so fun :)</p>
<p>A <a href="https://files.scene.org/view/parties/2025/revision25/wild/castello.zip">PAL-compatible N64 ROM</a> is available but note that it crashes a lot.</p>
<hr/>
<p><em>I‚Äôm also thinking of writing a book. <a href="https://30fps.net/book">Sign up here</a> if you‚Äôre interested.</em></p>



</div></div>
  </body>
</html>
