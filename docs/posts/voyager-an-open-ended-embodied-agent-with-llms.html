<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://voyager.minedojo.org/">Original</a>
    <h1>Voyager: An Open-Ended Embodied Agent with LLMs</h1>
    
    <div id="readability-page-1" class="page">
        <section>
            <div>
                <div>
                    <div>
                        <div>
                            
                            

                            <p>
                                <span><sup>2</sup>Caltech, </span>
                                <span><sup>3</sup>UT Austin, </span>
                                <span><sup>4</sup>Stanford, </span>
                                <span><sup>5</sup>ASU</span>
                            </p>

                            <p><span><sup>*</sup>Equal Contribution</span>
                                <span><sup>â€ </sup>Equal Advising </span>
                            </p>

                            
                        </div>
                    </div>
                </div>
            </div>
        </section>

        
        <section>
            
        </section>

        <section>
            <div>
                <!-- Abstract. -->
                <div>
                    <div>
                        <h2>Abstract</h2>
                        <p>
                                We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.
                                Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new
                                iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the
                                need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent&#39;s abilities rapidly and alleviates catastrophic
                                forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer
                                distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other
                                techniques struggle to generalize.
                            </p>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <div>
                                <p><img src="https://voyager.minedojo.org/assets/images/exploration_performance.png" alt=""/></p></div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!--Introduction-->
        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <h2><span>Introduction</span></h2>
                            <p><span>
                                    Building generally capable embodied agents that continuously explore, plan, and develop new skills in open-ended worlds is a grand challenge for the AI community. Classical approaches employ reinforcement
                                    learning (RL) and imitation learning that operate on primitive actions, which could be challenging for systematic exploration, interpretability, and generalization. Recent advances in large language model
                                    (LLM) based agents harness the world knowledge encapsulated in pre-trained LLMs to generate consistent action plans or executable policies. They are applied to embodied tasks like games and robotics, as
                                    well as NLP tasks without embodiment. However, these agents are not lifelong learners that can progressively acquire, update, accumulate, and transfer knowledge over extended time spans.
                                    </span>
                            </p>
                            <br/>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!--Method-->
        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <h2><span>Voyager Components</span></h2>
                            <p><span>
                                    We introduce Voyager, the first <i>LLM-powered embodied lifelong learning agent</i> to drive exploration, master a wide range of skills, and make new discoveries continually without human intervention in
                                    Minecraft. Voyager is made possible through three key modules: 1) an <b>automatic curriculum</b> that maximizes exploration; 2) a <b>skill library</b> for storing and retrieving complex behaviors; and 3)
                                    a new <b>iterative prompting mechanism</b> that generates executable code for embodied control. We opt to use code as the action space instead of low-level motor commands because programs can naturally
                                    represent temporally extended and compositional actions, which are essential for many long-horizon tasks in Minecraft. Voyager interacts with a blackbox LLM (GPT-4) through prompting and in-context
                                    learning. Our approach bypasses the need for model parameter access and explicit gradient-based training or finetuning.
                                </span>
                            </p>
                            </div>
                    </div>
                </div>
            </div>
        </section>

        <!--Experiments-->
        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <h2><span>Experiments</span></h2>
                            <p>
                                    We systematically evaluate Voyager and baselines on their exploration performance, tech tree mastery, map coverage, and zero-shot generalization capability to novel tasks in a new world.
                                </p>
                            </div>
                    </div>
                </div>
            </div>
        </section>

        <!--Conclusion-->
        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <h2><span>Conclusion</span></h2>
                            <p>
                                    In this work, we introduce Voyager, the first LLM-powered embodied lifelong learning agent, which leverages GPT-4 to explore the world continuously, develop increasingly sophisticated skills, and make new
                                    discoveries consistently without human intervention. Voyager exhibits superior performance in discovering novel items, unlocking the Minecraft tech tree, traversing diverse terrains, and applying its
                                    learned skill library to unseen tasks in a newly instantiated world. Voyager serves as a starting point to develop powerful generalist agents without tuning the model parameters.
                                </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <div>
                <div>
                    <div>
                        <div>
                            <h2><span>Team</span></h2>

                            <div>
                                <p><a href="https://www.guanzhi.me/" target="_blank">
                                        <span><img src="https://voyager.minedojo.org/assets/images/avatars/guanzhi.jpg" alt=""/></span>
                                    </a>
                                    <span>Guanzhi Wang</span>
                                </p>

                                <p><a href="https://xieleo5.github.io/" target="_blank">
                                        <span><img src="https://voyager.minedojo.org/assets/images/avatars/leo.jpeg" alt=""/></span>
                                    </a>
                                    <span>Yuqi Xie</span>
                                </p>

                                <p><a href="https://yunfanj.com/" target="_blank">
                                        <span><img src="https://voyager.minedojo.org/assets/images/avatars/yunfan.jpg" alt=""/></span>
                                    </a>
                                    <span>Yunfan Jiang<sup>*</sup></span>
                                </p>

                                <p><a href="https://ai.stanford.edu/~amandlek/" target="_blank">
                                        <span><img src="https://voyager.minedojo.org/assets/images/avatars/ajay.jpeg" alt=""/></span>
                                    </a>
                                    <span>Ajay Mandlekar<sup>*</sup></span>
                                </p>
                            </div>
                            </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="BibTeX">
            <div>
                <h2>BibTeX</h2>
                <pre><code>@article{wang2023voyager,
  title   = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author  = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: Arxiv-2305.16291},
}</code></pre>
            </div>
        </section>

        
    

</div>
  </body>
</html>
