<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.shaped.ai/blog/the-secret-sauce-of-tik-toks-recommendations">Original</a>
    <h1>The secret sauce of TikTok’s recommendations</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><div><div><p>Why is TikTok&#39;s feed so addicting? The secret lies in their recommendation engine, it’s precisely what made TikTok one of the largest social media platforms. Seemingly the feed can read your mind and keep you in the app for longer. Recently TikTok decided to let everyone in on a secret and released its model <strong>Monolith</strong> in a paper titled: <a href="https://arxiv.org/pdf/2209.07663.pdf">&#34;Monolith: Real-Time Recommendation System With Collisionless Embedding Table&#34;</a>.</p><p>Online recommendation systems are algorithms that are used to make personalized suggestions to users based on their interests and preferences. These systems are commonly used by online retailers and media companies to recommend products or content to their users. In this post, we’ll dive into the inner workings of TikTok’s awesome recommendation system and learn what makes it one of the best in the field!</p><p>Building scalable, real-time recommendation systems is vital for many businesses to build great experiences within their products or websites. However, current deep-learning frameworks (TensorFlow or PyTorch) don’t work well for real-time production scenarios. This is because:</p><ul role="list"><li>Updating models based on static parameters and dense computations is unsuitable for good performance in recommendations, which rely on dynamic and sparse features.</li><li>Common approaches are designed with a batch-training stage and serving stage (during user interaction with the product) wholly separated, preventing the model from interacting with customer feedback in real-time.</li></ul><p>TikTok’s team explains their solution in 3 steps:</p><ol role="list"><li>They crafted a <strong>collisionless embedding table</strong> while further optimizing it by adding expirable embeddings and frequency filtering to reduce its memory consumption, making it efficient and suitable for deployment to users;</li><li>They provided a <strong>production-ready online training architecture</strong> with high fault-tolerance</li><li>They experimentally proved that <strong>system reliability could be traded-off for real-time learning</strong></li></ol><p>Sounds intimidating? Not to worry, we will go through every single component and break it down, by the end of this article you will confidently understand why you can lose hours upon hours in the app. Ready? Here we go.</p><p>Researchers at TikTok made the observation that for recommendation systems <strong>the data is mostly categorical and sparse</strong>. This means that if we were to embed the data using an ML approach like word embeddings we would not be able to do so with the number of unique features that data for recommendation provides, in comparison the language models can get away with it due to limited vocabulary size. Using practical experience from the recommendation systems of YouTube and Instagram the <a href="https://en.wikipedia.org/wiki/Feature_hashing">hashing trick</a> was decided to be an optimal approach for a large-scale recommendation system. Let’s dive into the specifics of the one used in Monolith.</p><h3>But what about a HashMap?</h3><p>A <strong>hash map</strong> is a data structure that allows very fast mapping via a special <strong>hash function</strong> of some piece of data to a value.</p><p>Hash maps are fast and are used by large platforms to efficiently encode the data, so how does Monolith make it better? Hash maps suffer from an inherent tradeoff that comes with an original design of this data structure called a <strong>collision</strong>.</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef413f7039effe1b9e3e05_Hash%20Map%20illustration.png" loading="lazy" alt=""/></p><figcaption><a href="https://commons.wikimedia.org/wiki/File:Hash_table_5_0_1_1_1_1_1_LL.svg#/media/File:Hash_table_5_0_1_1_1_1_1_LL.svg">Hash map illustration</a></figcaption></figure><p>‍</p><p>A <strong>collision</strong> occurs when two or more pieces of data are mapped to the same output value by a hash function. This can cause problems when using hash functions to index data, as multiple pieces of data will be mapped to the same location.  TikTok’s team developed a <strong>cuckoo hashmap</strong> to address this.</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef419ca31e980f96a29aee_Cuckoo%20HashMap.png" loading="lazy" alt=""/></p></figure><p>In a cuckoo hash map, just as in a standard hash map each piece of data is assigned a unique key, and the key is hashed to determine its location in the array. If the location is already occupied by another piece of data, the existing data is &#34;kicked out&#34; (similar to a real-life cuckoo behavior of cuckoo in relation to eggs in the nest) and has to find a new location in the array, using a second hash function. This process continues until all the data has been successfully inserted into the array, or until a maximum number of iterations is reached. An example is illustrated above. Here two hash tables $T_0$ and $T_1$used to store the hashed data. A value $A$ is hashed and inserted in $T_0$, but as $B$  already occupies this place it is then evicted and an attempt is made to insert it in $T_1$, this process will repeat until all values are inserted or the rehashing happens to avoid cyclic insertions. This process allows for the avoidance of collisions and it has a significant effect on the performance of the production model.</p><p>To complete their embedding system design researchers added a few bells and whistles to further optimize the process, in particular, to cut the memory requirement that hashing would require:</p><ul role="list"><li>A probabilistic filter to filter IDs in the hashmap.  Since an important observation is that in data from TikTok IDs are long-tail distributed, where popular IDs may occur millions of times while the unpopular ones appear no more than ten times, there is a reasonable assumption to be made that they will not affect the final model quality and therefore can be cleared.</li><li>An ID existence timer that controls the erasure of old and stale IDs. This could possibly be due to a user that is no longer active, or a short video that is out-of-date. Storing embeddings for these IDs could not help the model in any way so it is sensible to clear the memory.</li></ul><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef41c2add38b76ada01e54_Effect%20of%20embedding%20collision.png" loading="lazy" alt=""/></p></figure><p>Now as we learned how the data is represented inside the model we need to understand how it is trained and updated. The overall diagram of the Monolith online training architecture can be found below:</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef41ebf17174a73121ddca_Monolith%20Online%20Training%20Architecture.png" loading="lazy" alt=""/></p></figure><p>It looks complicated but actually, it all revolves around a very simple process that is the basis for the larger architecture and that drives the core of the overall training architecture.</p><p>TensorFlow&#39;s distributed <strong>Worker-ParameterServer</strong> (or simply <strong>PS</strong>) model is a way of training machine learning models in a distributed fashion, where multiple machines (or processes on a single machine) work together to train the model, illustrated below:</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef421635dd42fdcb21371c_Worker-PS%20Architecture.png" loading="lazy" alt=""/></p></figure><p>In this model, there are two types of processes: <strong>workers</strong> and <strong>parameter servers.</strong> The workers are responsible for performing the computations required to train the model, such as calculating gradients or updating model parameters. The parameter servers are responsible for storing the current state of the model, such as the model weights or biases.</p><p>The training is divided between <strong>batch training</strong> and <strong>online training</strong> stages:</p><ul role="list"><li><strong>Batch training stage</strong>. This stage works as follows: in each training step, a training worker reads one mini-batch of training examples from the storage, requests parameters from PS, computes a forward and a backward pass, and finally pushes updated parameters to the training PS. Batch training is useful for training historical data when there is a need to modify model architecture and retrain the model;</li><li><strong>Online training stage</strong>. After a model is deployed to online serving, the training does not stop but enters the online training stage. Instead of reading mini-batch examples from the storage, a training worker consumes real-time data on-the-fly and updates the training PS. The training PS periodically synchronizes its parameters to the serving PS, which will takeeffect on the user side immediately.</li></ul><h3>Streaming engine</h3><p>To make sure that Monolith can seamlessly switch between batch training and online training it was built with a streaming engine component:</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef4237b6792e246a7dd1f5_Streaming%20Engine.png" loading="lazy" alt=""/></p></figure><p>In order to gather real-time user feedback for further training the research team used <a href="https://www.semanticscholar.org/paper/Kafka-%3A-a-Distributed-Messaging-System-for-Log-Kreps/ea97f112c165e4da1062c30812a41afca4dab628">Kafka queues</a>, one queue logs the user actions (click’s, likes etc.) another one is for features coming from a model server. Then two are joined by using <a href="https://www.semanticscholar.org/paper/Apache-Flink%E2%84%A2%3A-Stream-and-Batch-Processing-in-a-Carbone-Katsifodimos/ab18dc8b12ab8db6c939ec671bc1f74d6655f465">Apache Flink joiner</a>, this data packed is transformed into the training data that is then is read by another Kafka queue, those training examples are used for both batch training and online training:</p><ul role="list"><li>During batch training, data from the Kafka queue is dumped to <strong>Hadoop Distributed File Storage (HDFS)</strong>,  after a certain amount of training data is accumulated it is then sent to the training worker</li><li>For online training the process is simpler: the data is just read directly from the Kafka queue</li></ul><p>After the training operation is performed a PS collects parameters and according to a selected synchronization schedule updates the serving PS which in turn updates the model on the user side.</p><h3>Online Joiner</h3><p>The joiner process is actually a bit more complicated and we should note a few things about it:</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef4259abe86943ac75d52a_Online%20Joiner.png" loading="lazy" alt=""/></p></figure><p><strong>In-memory cache</strong> and <strong>KV(Key-Value)-store</strong>, are two components that help stabilize the latency between user actions and features coming from the server, this is due to the fact that they both arrive irrespective of each other’s arrival time, so caching is required to correctly pair them up. But what if the user takes a long time to complete an action? Then caching would not be such a great idea, hence some values are stored on the disk to be paired up again. When a user action log arrives, it first looks up the in-memory cache and then looks up the key-value storage in case of a missing cache.</p><p>Note also one last step which is <strong>Negative Sampling</strong>. As there are <strong>positive</strong> and <strong>negative</strong> examples during training. In a recommendation system, positive examples are items that a user likes or has shown interest in, while negative examples are items that the user does not like or has not shown interest in. But their amount can be imbalanced therefore it is important to correct this bias in the dataset.</p><p>And that’s it! You’ve learned about all of the components in Monolith. Now for one last section where researchers prove the effectiveness of online learning on the fly.</p><p>Here the team also compared the performance of the model at different sync time intervals to verify the performance:</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/6217ffc5d2a3bb848ea33545/63ef42810e8af938054d1550_Real-time%20learning.png" loading="lazy" alt=""/></p></figure><p>As we can see above online training is essential for better performance of a recommender system with dynamic feedback.</p><p>‍</p></div></div></div></div></div></div>
  </body>
</html>
