<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Jul/10/grok-4/">Original</a>
    <h1>Grok 4</h1>
    
    <div id="readability-page-1" class="page"><div>



<p><strong><a href="https://docs.x.ai/docs/models/grok-4-0709">Grok 4</a></strong>. Released last night, Grok 4 is now available via both API and a paid subscription for end-users.</p>
<p>Key characteristics: image and text input, text output. 256,000 context length (twice that of Grok 3). It&#39;s a reasoning model where you can&#39;t see the reasoning tokens or turn off reasoning mode.</p>
<p>xAI released results showing Grok 4 beating other models on most of the significant benchmarks. I haven&#39;t been able to find their own written version of these (the launch was a <a href="https://x.com/xai/status/1943158495588815072">livestream video</a>) but here&#39;s <a href="https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/">a TechCrunch report</a> that includes those scores. It&#39;s not clear to me if these benchmark results are for Grok 4 or Grok 4 Heavy.</p>
<p>I ran <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">my own benchmark</a> using Grok 4 <a href="https://openrouter.ai/x-ai/grok-4">via OpenRouter</a> (since I have API keys there already). </p>
<pre><code>llm -m openrouter/x-ai/grok-4 &#34;Generate an SVG of a pelican riding a bicycle&#34; \
  -o max_tokens 10000
</code></pre>
<p><img alt="Description below." src="https://static.simonwillison.net/static/2025/grok4-pelican.png"/></p>
<p>I then asked Grok to describe the image it had just created:</p>
<pre><code>llm -m openrouter/x-ai/grok-4 -o max_tokens 10000 \
  -a https://static.simonwillison.net/static/2025/grok4-pelican.png \
  &#39;describe this image&#39;
</code></pre>
<p>Here&#39;s <a href="https://gist.github.com/simonw/ec9aee006997b6ae7f2bba07da738279#response">the result</a>. It described it as a &#34;cute, bird-like creature (resembling a duck, chick, or stylized bird)&#34;.</p>
<p>The most interesting independent analysis I&#39;ve seen so far is <a href="https://twitter.com/ArtificialAnlys/status/1943166841150644622">this one from Artificial Analysis</a>:</p>
<blockquote>
<p>We have run our full suite of benchmarks and Grok 4 achieves an Artificial Analysis Intelligence Index of 73, ahead of OpenAI o3 at 70, Google Gemini 2.5 Pro at 70, Anthropic Claude 4 Opus at 64 and DeepSeek R1 0528 at 68.</p>
</blockquote>
<p>The timing of the release is somewhat unfortunate, given that Grok 3 made headlines <a href="https://www.theguardian.com/technology/2025/jul/09/grok-ai-praised-hitler-antisemitism-x-ntwnfb">just this week</a> after a <a href="https://github.com/xai-org/grok-prompts/commit/535aa67a6221ce4928761335a38dea8e678d8501#diff-dec87f526b85f35cb546db6b1dd39d588011503a94f1aad86d023615a0e9e85aR6">clumsy system prompt update</a> - persumably another attempt to make Grok &#34;less woke&#34; - caused it to start firing off antisemitic tropes and referring to itself as MechaHitler.</p>
<p>My best guess is that these lines in the prompt were the root of the problem:</p>
<blockquote>
<p><code>- If the query requires analysis of current events, subjective claims, or statistics, conduct a deep analysis finding diverse sources representing all parties. Assume subjective viewpoints sourced from the media are biased. No need to repeat this to the user.</code></p>
</blockquote>
<p>If xAI expect developers to start building applications on top of Grok they need to do a lot better than this. Absurd self-inflicted mistakes like this do not build developer trust!</p>
<p>As it stands, Grok 4 isn&#39;t even accompanied by a model card.</p>
<p><em><strong>Update:</strong> Ian Bicking <a href="https://bsky.app/profile/ianbicking.org/post/3ltn3r7g4xc2i">makes an astute point</a>:</em></p>
<blockquote>
<p><em>It feels very credulous to ascribe what happened to a system prompt update. Other models can&#39;t be pushed into racism, Nazism, and ideating rape with a system prompt tweak.</em></p>
</blockquote>
<p><em>Even if that system prompt change was responsible for unlocking this behavior, the fact that it was able to speaks to a much looser approach to model safety by xAI compared to other providers.</em></p>
<p>Grok 4 is competitively priced. It&#39;s $3/million for input tokens and $15/million for output tokens - the same price as Claude Sonnet 4. Once you go above 128,000 input tokens the price doubles to $6/$30 (Gemini 2.5 Pro has a similar price increase for longer inputs). I&#39;ve added these prices to <a href="https://www.llm-prices.com/">llm-prices.com</a>.</p>
<p>Consumers can access Grok 4 via a new $30/month or $300/year &#34;SuperGrok&#34; plan - or a $300/month or $3,000/year &#34;SuperGrok Heavy&#34; plan providing access to Grok 4 Heavy.</p>
<p><img alt="Screenshot of subscription pricing page showing two plans: SuperGrok at $30.00/month (marked as Popular) with Grok 4 and Grok 3 increased access, features including Everything in Basic, Context Memory 128,000 Tokens, and Voice with vision; SuperGrok Heavy at $300.00/month with Grok 4 Heavy exclusive preview, Grok 4 and Grok 3 increased access, features including Everything in SuperGrok, Early access to new features, and Dedicated Support. Toggle at top shows &#34;Pay yearly save 16%&#34; and &#34;Pay monthly&#34; options with Pay monthly selected." src="https://static.simonwillison.net/static/2025/supergrok-pricing.jpg"/></p>




</div></div>
  </body>
</html>
