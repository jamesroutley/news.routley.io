<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/AntonioTepsich/Convolutional-KANs">Original</a>
    <h1>Convolutional-KANs</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div dir="auto"><h3 tabindex="-1" dir="auto">Introducing Convolutional KAN Networks!</h3><a id="user-content-introducing-convolutional-kan-networks" aria-label="Permalink: Introducing Convolutional KAN Networks!" href="#introducing-convolutional-kan-networks"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This project extends the idea of the innovative architecture of Kolmogorov-Arnold Networks (KAN) to the Convolutional Layers, changing the classic linear transformation of the convolution to learnable non linear activations in each pixel.</p>

<p dir="auto">This repository was made by:</p>
<ul dir="auto">
<li>Alexander Bodner | <a href="mailto:abodner@udesa.edu.ar">abodner@udesa.edu.ar</a> | <a href="https://twitter.com/AlexBodner_" rel="nofollow">Twitter</a> | <a href="https://www.linkedin.com/in/alexanderbodner/" rel="nofollow">LinkedIn</a></li>
<li>Antonio Tepsich | <a href="mailto:atepsich@udesa.edu.ar">atepsich@udesa.edu.ar</a> | <a href="https://twitter.com/antotepsich" rel="nofollow">Twitter</a> | <a href="https://www.linkedin.com/in/antonio-tepsich/" rel="nofollow">LinkedIn</a></li>
<li>Jack Spolski | <a href="mailto:jspolski@udesa.edu.ar">jspolski@udesa.edu.ar</a> | <a href="https://www.linkedin.com/in/jack-spolski-9882a3196/" rel="nofollow">LinkedIn</a></li>
<li>Santiago Pourteau | <a href="mailto:spourteau@udesa.edu.ar">spourteau@udesa.edu.ar</a> | <a href="https://twitter.com/SantiPourteau" rel="nofollow">Twitter</a> | <a href="https://www.linkedin.com/in/santiago-pourteau-1bba8619a/" rel="nofollow">LinkedIn</a></li>
</ul>

<p dir="auto">This repository uses an efficient implementation of KAN which is available <a href="https://github.com/Blealtan/efficient-kan">here</a>.
The original implementation of KAN is available <a href="https://github.com/KindXiaoming/pykan">here</a>.
The original paper of the KAN is available <a href="https://arxiv.org/pdf/2404.19756" rel="nofollow">here</a>.</p>

<p dir="auto">KANs are promising alternatives of Multi-Layer Perceptrons (MLPs). KANs have strong mathematical foundations just like MLPs: MLPs are based on the universal approximation theorem, while KANs are based on Kolmogorov-Arnold representation theorem. KANs and MLPs are dual: KANs have activation functions on edges, while MLPs have activation functions on nodes. KAN seems to be more parameter efficient than MLPs, but each KAN Layer has more parameters than a MLP layer.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/23551623/326219527-695adc2d-0d0b-4e4b-bcff-db2c8070f841.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU3MjE0NTEsIm5iZiI6MTcxNTcyMTE1MSwicGF0aCI6Ii8yMzU1MTYyMy8zMjYyMTk1MjctNjk1YWRjMmQtMGQwYi00ZTRiLWJjZmYtZGIyYzgwNzBmODQxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE0VDIxMTIzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQwYmQ0NGI5MTFmZDhjNzE3YzNlYjMwMTAzNWQ0ZTFmYTU2Y2VhN2YwNTEwMWU2NDIxMzc3ZmE3YmNiODEyMWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.yNOvA5QpENlOLOuL3Lz2igHUewTTI172narW7VkqJGU"><img width="1163" alt="mlp_kan_compare" src="https://private-user-images.githubusercontent.com/23551623/326219527-695adc2d-0d0b-4e4b-bcff-db2c8070f841.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU3MjE0NTEsIm5iZiI6MTcxNTcyMTE1MSwicGF0aCI6Ii8yMzU1MTYyMy8zMjYyMTk1MjctNjk1YWRjMmQtMGQwYi00ZTRiLWJjZmYtZGIyYzgwNzBmODQxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE0VDIxMTIzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQwYmQ0NGI5MTFmZDhjNzE3YzNlYjMwMTAzNWQ0ZTFmYTU2Y2VhN2YwNTEwMWU2NDIxMzc3ZmE3YmNiODEyMWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.yNOvA5QpENlOLOuL3Lz2igHUewTTI172narW7VkqJGU"/></a>
<p dir="auto">For more information about this novel architecture please visit:</p>
<ul dir="auto">
<li>The official Pytorch implementation of the architecture: <a href="https://github.com/KindXiaoming/pykan">https://github.com/KindXiaoming/pykan</a></li>
<li>The research paper: <a href="https://arxiv.org/abs/2404.19756" rel="nofollow">https://arxiv.org/abs/2404.19756</a></li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">What is a KAN Convolution?</h3><a id="user-content-what-is-a-kan-convolution" aria-label="Permalink: What is a KAN Convolution?" href="#what-is-a-kan-convolution"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">KAN Convoluions are very similar to convolutions, but instead of applying the dot product between the kernel and the corresponding pixels in the image, we apply a <strong>Learnable Non Linear activation function</strong> to each element, and then add them up. The kernel of the KAN Convolution is equivalent to a KAN Linear Layer of 4 inputs and 1 output neuron. For each input i, we apply a ϕ_i learnable function, and the resulting pixel of that convolution step is the sum of ϕ_i(x_i). This can be visualized in the following figure.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/AntonioTepsich/Convolutional-KANs/blob/master/images/Convs.png"><img src="https://github.com/AntonioTepsich/Convolutional-KANs/raw/master/images/Convs.png" alt="image"/></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Parameters in a KAN Convolution</h3><a id="user-content-parameters-in-a-kan-convolution" aria-label="Permalink: Parameters in a KAN Convolution" href="#parameters-in-a-kan-convolution"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Suppose that we have a KxK kernel. In this case, for each element of this matrix we have a ϕ, which its parameter count is: gridsize + 1. For implementation issues, eficcient kan defines:</p>
<p dir="auto">This gives more expresability to the activation function b. So the parameter count for a linear layer is gridsize + 2. So in total we have K²(gridsize + 2) parameters for KAN Convolution, vs only K² for a common convolution. Consider that gridsize is tipically (in our experiments) between k and k², but k tends to be a small value, between 2 and 16.</p>

<p dir="auto">The different architectures we have tested are:</p>
<ul dir="auto">
<li>KAN Convolutional Layers connected to Kan Linear Layers (KKAN)</li>
<li>Kan Convolutional Layers connected to a MLP (CKAN)</li>
<li>CKAN with Batch Normalization between convolutions (CKAN_BN)</li>
<li>ConvNet (Classic Convolutions connected to a MLP) (ConvNet)</li>
<li>Simple MLPs</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/AntonioTepsich/Convolutional-KANs/blob/master/images/experiment_28x28.png"><img src="https://github.com/AntonioTepsich/Convolutional-KANs/raw/master/images/experiment_28x28.png" alt="image"/></a></p>
<p dir="auto">Have a look at <code>experiment_28x28.ipynb</code>.</p>

<p dir="auto">The implementation of KAN Convolutions is a promising idea, although it is still in its early stages. We have conducted some preliminary experiments to evaluate the performance of KAN Convolutions. The reason we say preliminary is because we wanted to publish this idea as soon as possible, so that the community can start working on it.</p>
<p dir="auto"><strong>Here we have some results:</strong></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Test Accuracy</th>
<th>Test Precision</th>
<th>Test Recall</th>
<th>Test F1 Score</th>
<th>Number of Parameters</th>
<th>Convolutional Layers</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 Layer MLP</td>
<td>0.922</td>
<td>0.922</td>
<td>0.921</td>
<td>0.921</td>
<td>7850</td>
<td>-</td>
</tr>
<tr>
<td>ConvNet (Small)</td>
<td>0.976</td>
<td>0.976</td>
<td>0.976</td>
<td>0.976</td>
<td>2740</td>
<td>[5,1] k=[3,3]</td>
</tr>
<tr>
<td>ConvNet (Medium)</td>
<td>0.991</td>
<td>0.991</td>
<td>0.991</td>
<td>0.991</td>
<td>157 030</td>
<td>[5,5] k=[3,3]</td>
</tr>
<tr>
<td>ConvNet (Big)</td>
<td><strong>0.995</strong></td>
<td>0.995</td>
<td>0.995</td>
<td>0.995</td>
<td>887 530</td>
<td>[32,1,2,1] k=[5,5,3,3]</td>
</tr>
<tr>
<td>KANConv &amp; MLP</td>
<td>0.985</td>
<td>0.985</td>
<td>0.984</td>
<td>0.984</td>
<td>163 726</td>
<td>KanConvs[5,5] k =[3,3]</td>
</tr>
<tr>
<td>Simple Conv &amp; KAN</td>
<td>0.980</td>
<td>0.980</td>
<td>0.980</td>
<td>0.980</td>
<td>37 030</td>
<td>[5,1] k=[3,3]</td>
</tr>
<tr>
<td>KKAN</td>
<td>0.987</td>
<td>0.987</td>
<td>0.987</td>
<td>0.987</td>
<td>94 650</td>
<td>KanConvs[5,5] k =[3,3]</td>
</tr>
</tbody>
</table>
<p dir="auto"><em>The lists in Convolutional Layers cotain en each element the number of convolutions and then the corresponding kernel size.</em></p>
<p dir="auto">Based on a 28x28 MNIST dataset, we can observe that the KANConv &amp; MLP model achieves acceptable accuracy compared to the ConvNet (Big). However, the difference is that the number of parameters required by the KANConv &amp; MLP is seven times less than those needed by the standard ConvNet. Also the KKAN achieved 0.04 less Accuracy than ConvNet Medium, with almst half the parameter count (94k vs 157k), which shows the potential of the architecture. Experiments on more datasets need to be conducted to take certain conclussions on this</p>
<p dir="auto">We are aware that there are many hyperparameters to tune, and many experiments to conduct. In the coming days and weeks we will be thoroughly tuning the hyperparameters of our model and the models we use to compare. We have tried some variations in the hyperparameters and architectures, but it was heuristically and not done with any precise method.
We also recognize that we have not used large or more complex datasets because of computational power and time reasons and we are working on that.</p>

<p dir="auto">At the moment we aren&#39;t seeing a significant improvement in the performance of the KAN Convolutional Networks compared to the traditional Convolutional Networks. We believe that this is due to the fact that we are using simple datasets and small models since the strength of our architecture lies in its requirement for significantly fewer parameters compared to the best architecture we have tried (ConvNet Big, which is an unfair comparison because of its size). The comparison between 2 equal convolutional and KAN convolutional layers with the same MLP connected at the end showed a small win to the classic approach, getting 0.06 better accuracy, while the KAN convolutions and a KAN Linear Layer with almost half the parameter count got 0.04 less Accuracy. We are confident that as we increase the complexity of the models and the datasets we will see a significant improvement in the performance of the KAN Convolutional Networks. But also the parameter count of our models will grow faster with higher dimentional inputs.</p>

<ul dir="auto">
<li>Experiments on more complex datasets.</li>
<li>Hiperparameter Tuning with Random Search.</li>
<li>Experiments with more architectures.</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com/AntonioTepsich/ckan.git
cd ckan
pip install -r requirements.txt"><pre>git clone git@github.com/AntonioTepsich/ckan.git
<span>cd</span> ckan
pip install -r requirements.txt</pre></div>

<p dir="auto">Just copy the file <code>kan_convolutional</code> to your project and import it.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from kan_convolutional.KANConv import KAN_Convolutional_Layer"><pre><span>from</span> <span>kan_convolutional</span>.<span>KANConv</span> <span>import</span> <span>KAN_Convolutional_Layer</span></pre></div>

<p dir="auto">Construct a KANConv for MNIST</p>
<div dir="auto" data-snippet-clipboard-copy-content="import torch
from torch import nn
import torch.nn.functional as F

from kan_convolutional.KANConv import KAN_Convolutional_Layer

class KANC_MLP(nn.Module):
    def __init__(self,device: str = &#39;cpu&#39;):
        super().__init__()
        self.conv1 = KAN_Convolutional_Layer(
            n_convs = 5,
            kernel_size= (3,3),
            device = device
        )

        self.conv2 = KAN_Convolutional_Layer(
            n_convs = 5,
            kernel_size = (3,3),
            device = device
        )

        self.pool1 = nn.MaxPool2d(
            kernel_size=(2, 2)
        )
        
        self.flat = nn.Flatten() 
        
        self.linear1 = nn.Linear(625, 256)
        self.linear2 = nn.Linear(256, 10)


    def forward(self, x):
        x = self.conv1(x)

        x = self.pool1(x)

        x = self.conv2(x)
        x = self.pool1(x)
        x = self.flat(x)
        x = self.linear1(x)
        x = self.linear2(x)
        x = F.log_softmax(x, dim=1)
        return x"><pre><span>import</span> <span>torch</span>
<span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>import</span> <span>torch</span>.<span>nn</span>.<span>functional</span> <span>as</span> <span>F</span>

<span>from</span> <span>kan_convolutional</span>.<span>KANConv</span> <span>import</span> <span>KAN_Convolutional_Layer</span>

<span>class</span> <span>KANC_MLP</span>(<span>nn</span>.<span>Module</span>):
    <span>def</span> <span>__init__</span>(<span>self</span>,<span>device</span>: <span>str</span> <span>=</span> <span>&#39;cpu&#39;</span>):
        <span>super</span>().<span>__init__</span>()
        <span>self</span>.<span>conv1</span> <span>=</span> <span>KAN_Convolutional_Layer</span>(
            <span>n_convs</span> <span>=</span> <span>5</span>,
            <span>kernel_size</span><span>=</span> (<span>3</span>,<span>3</span>),
            <span>device</span> <span>=</span> <span>device</span>
        )

        <span>self</span>.<span>conv2</span> <span>=</span> <span>KAN_Convolutional_Layer</span>(
            <span>n_convs</span> <span>=</span> <span>5</span>,
            <span>kernel_size</span> <span>=</span> (<span>3</span>,<span>3</span>),
            <span>device</span> <span>=</span> <span>device</span>
        )

        <span>self</span>.<span>pool1</span> <span>=</span> <span>nn</span>.<span>MaxPool2d</span>(
            <span>kernel_size</span><span>=</span>(<span>2</span>, <span>2</span>)
        )
        
        <span>self</span>.<span>flat</span> <span>=</span> <span>nn</span>.<span>Flatten</span>() 
        
        <span>self</span>.<span>linear1</span> <span>=</span> <span>nn</span>.<span>Linear</span>(<span>625</span>, <span>256</span>)
        <span>self</span>.<span>linear2</span> <span>=</span> <span>nn</span>.<span>Linear</span>(<span>256</span>, <span>10</span>)


    <span>def</span> <span>forward</span>(<span>self</span>, <span>x</span>):
        <span>x</span> <span>=</span> <span>self</span>.<span>conv1</span>(<span>x</span>)

        <span>x</span> <span>=</span> <span>self</span>.<span>pool1</span>(<span>x</span>)

        <span>x</span> <span>=</span> <span>self</span>.<span>conv2</span>(<span>x</span>)
        <span>x</span> <span>=</span> <span>self</span>.<span>pool1</span>(<span>x</span>)
        <span>x</span> <span>=</span> <span>self</span>.<span>flat</span>(<span>x</span>)
        <span>x</span> <span>=</span> <span>self</span>.<span>linear1</span>(<span>x</span>)
        <span>x</span> <span>=</span> <span>self</span>.<span>linear2</span>(<span>x</span>)
        <span>x</span> <span>=</span> <span>F</span>.<span>log_softmax</span>(<span>x</span>, <span>dim</span><span>=</span><span>1</span>)
        <span>return</span> <span>x</span></pre></div>

<p dir="auto">We invite the community to join us in advancing this project. There are numerous ways to contribute. You are welcome to contribute by submitting pull requests or opening issues to share ideas and suggest enhancements. Together, we can unlock the full possibilities of KAN and push the boundaries of Computer Vision ❤️.</p>
</article></div></div>
  </body>
</html>
