<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.randombits.host/monitoring-self-hosted-services/">Original</a>
    <h1>Show HN: Homelab Monitoring Setup with Grafana</h1>
    
    <div id="readability-page-1" class="page"><section>
				<p>I have been self-hosting for almost <s>two</s> three years now, and one thing I have never quite figured out is how to monitor all the applications I host. At this stage, there are approximately <em>forty</em> running Docker containers so I really should have some means of monitoring what&#39;s going on on them and the general health of the server they are running on. Professionally, I have used <a href="https://www.splunk.com/?ref=blog.randombits.host">Splunk</a> and <a href="https://www.sumologic.com/?ref=blog.randombits.host">Sumo Logic</a> for monitoring services, but the open source solution I would prefer to use for this is <a href="https://grafana.com/?ref=blog.randombits.host">Grafana</a>. I have already set up Grafana to get logs from the <a href="https://via.randombits.host/?ref=blog.randombits.host">Via</a> app, and it seems to be a very widely used tool industry-wide, so it would be nice to not be completely in the dark on it! In particular, I will be using <a href="https://grafana.com/oss/loki/?ref=blog.randombits.host">Loki</a>, <a href="https://grafana.com/oss/prometheus/?ref=blog.randombits.host">Prometheus</a>, <a href="https://grafana.com/docs/loki/latest/clients/promtail/?ref=blog.randombits.host">Promtail</a>, <a href="https://github.com/prometheus/node_exporter?ref=blog.randombits.host">Node-Exporter</a>, and <a href="https://github.com/google/cadvisor?ref=blog.randombits.host">cAdvisor</a>. As I have basically no experience with any of these tools, I will summarize my research on them for you, and document how they interact with each other in my setup. After that, I will describe which data I wish to collect and for what purpose, before finally showing the dashboards/alerts I have made. Let&#39;s go!</p><h3 id="grafana"> Grafana</h3><p>   Lets start with the main one - what is Grafana? Grafana is at its core a web-based data visualization platform. It acts as a front end to many time-series databases, and uses plugins to consume data from different sources and support custom dashboard visualizations.  It also has a simple graphical tool to help you craft queries on the data. The best place to try the Grafana platform out is at <a href="https://play.grafana.org/?ref=blog.randombits.host">play.grafana.org</a>.</p><h3 id="prometheus"> Prometheus</h3><p>   Prometheus is a time-series database which operates on a <code>pull</code> model. You configure exporters which will have metrics requested from them by Prometheus on a regular schedule. There is a suite of <a href="https://prometheus.io/docs/introduction/overview/?ref=blog.randombits.host#components">components</a> it can make use of, but one core feature we will be using is <a href="https://prometheus.io/docs/prometheus/latest/querying/examples/?ref=blog.randombits.host">PromQL</a> - the Prometheus Query Language. We will use this through Grafana to aggregate metrics collected by Prometheus. One thing that is important to note is that Prometheus is designed to work with numeric information only. This means it cannot be used to search through textual logs like you might do in Splunk or Sumo Logic.</p><h3 id="loki"> Loki</h3><p>   Being restricted to just working with metrics is quite a limitation, so we will also be using <a href="https://grafana.com/oss/loki/?ref=blog.randombits.host">Loki</a>. Loki encompasses a set of tools/services, but my working model of it doesn&#39;t extend much further than Prometheus for log lines. It accepts data in any format, and similar to Prometheus, it allows you to build metrics and alerts based on them.</p><h3 id="promtail"> Promtail</h3><p>   <a href="https://grafana.com/docs/loki/latest/clients/promtail/?ref=blog.randombits.host">Promtail</a> is responsible for delivering log lines from log files to Loki. It is the roughly equivalent component in the Loki stack as Node-Exporter is in the Prometheus stack. This is confusing as <em>Prom</em>tail looks like it should be part of the <em>Prom</em>etheus stack, but alas naming of open source tooling is never great!</p><p>   Promtail will be used to collect log lines from containers of my own services, or of services being debugged.</p><h3 id="node-exporter"> Node-Exporter</h3><p>   <a href="https://grafana.com/oss/prometheus/exporters/node-exporter/?ref=blog.randombits.host">Node Exporter</a> monitors and exports hardware and kernel level metrics to Prometheus. It is highly configurable with a <a href="https://github.com/prometheus/node_exporter?ref=blog.randombits.host#collectors">long list</a> of metrics it can collect if you desire. Despite the warnings, we will be running <code>node-exporter</code> from a Docker container for now. This is just for ease of encapsulation until I can move my personal home server to using NixOS or similar.</p><p>   This will provide the host-level metrics we need, such as CPU usage, RAM usage, free space, etc.</p><h3 id="cadvisor"> cAdvisor</h3><p>   From the <a href="https://github.com/google/cadvisor?ref=blog.randombits.host">cAdvisor Github page</a>:</p><blockquote>[cAdvisor] is a running daemon that collects, aggregates, processes, and exports information about running containers.</blockquote><p>   <a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md?ref=blog.randombits.host">These metrics</a> can be exposed for Prometheus, and will provide the per-container resource usage metrics we need.</p><h2 id="stack">Stack</h2><p>   So now we have all the components explained, it&#39;s worthwhile visualizing the stack we will have. One crucial thing to remember is that while this seems like a large number of services, each one is very small and modular, so it won&#39;t be consuming a huge amount of resources.</p><figure><img src="https://blog.randombits.host/content/images/2023/03/grafana.png" alt="" loading="lazy" width="711" height="321" srcset="https://blog.randombits.host/content/images/size/w600/2023/03/grafana.png 600w, https://blog.randombits.host/content/images/2023/03/grafana.png 711w"/></figure><h2 id="the-data">The Data</h2><p>   Now we know the <em>how</em> of observability, we need to get to the <em>what</em>. Honestly, I spent a long time putting this off, probably because this was the largest gap in my knowledge! However, I think an iterative approach works best here anyways - both in iteratively building up to &#34;complete&#34; observability/insight, and iteratively building up my knowledge of the Grafana stack.</p><!--kg-card-begin: markdown--><ul>
<li>Host
<ul>
<li>Metrics
<ul>
<li>CPU Usage</li>
<li>RAM Usage</li>
<li>Storage Usage %</li>
<li>Load (1 min, 5 min, 15 min seems standard)</li>
<li>Network Throughput (Input/Output volume)</li>
</ul>
</li>
<li>Logs
<ul>
<li>syslog</li>
<li>auth.log</li>
</ul>
</li>
</ul>
</li>
<li>Per-Service
<ul>
<li>Metrics
<ul>
<li>CPU Usage %</li>
<li>RAM Usage</li>
<li>Storage Usage %</li>
<li>Network Throughput</li>
</ul>
</li>
<li>Logs
<ul>
<li>For specific containers</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><h2 id="the-implementation">The Implementation</h2><p>   Now we know <em>what</em> we&#39;re observing, and <em>how</em> we&#39;re going to ingest it, we just need to do it! </p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/RZGV9Z5Gvgs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Completing the plan"></iframe><figcaption>I wish I could have found the author&#39;s site to link to and not Youtube...</figcaption></figure><p>   Since we painstakingly mapped out the different component services, we can tell instantly that we need <code>cAdvisor</code> for the per-service metrics, <code>NodeExporter</code> for the host metrics, and <code>loki</code> for all the log lines. Lets start with the metrics.</p><pre><code>scrape_configs:
  - job_name: &#34;cadvisor&#34;
    scrape_interval: 15s
    static_configs:
      - targets: [&#34;cadvisor:8080&#34;]
  - job_name: &#34;node_exporter&#34;
    scrape_interval: 15s
    static_configs:
      - targets: [&#34;node-exporter:9100&#34;]</code></pre><p>   Then Loki needs to be configured for <code>syslog</code> and <code>auth.log</code>. This was achieved by a simple promtail config and mapping <code>/var/log:/var/log/host_logs</code> in docker-compose:</p><pre><code>scrape_configs:
- job_name: hostlogs_job
  static_configs:
  - targets:
      - localhost
    labels:
      job: hostlogs
      __path__: /var/hostlogs/*log
- job_name: docker_container_logs
  docker_sd_configs:
  - host: unix:///var/run/docker.sock
    refresh_interval: 5s
  relabel_configs:
    - source_labels: [&#39;__meta_docker_container_name&#39;]
      regex: &#39;/(.*)&#39;
      target_label: &#39;container&#39;
</code></pre><h2 id="alerting">Alerting</h2><p> Finally we have the full stack set up. Last remaining thing to get a semi-professional (emphasis on the semi!) is to get some alerting going. For alerting, I&#39;m going to use <a href="https://github.com/binwiederhier/ntfy?ref=blog.randombits.host">ntfy</a> and a small Grafana integration I found called <a href="https://github.com/kittyandrew/grafana-to-ntfy?ref=blog.randombits.host">grafana-to-ntfy</a>. This took a little more work than expected, but eventually I got it all working. Firstly, I set up a personal <code>ntfy</code> instance, then added the <code>grafana-ntfy</code> container to my docker-compose along with a simple env file as explained in the README. I then integrated it with Grafana alerting. One of the key things to note here is that I just used plain <code>http</code> for communication with the <code>grafana-ntfy</code> container as I couldn&#39;t get it set up with SSL! I kept getting invalid cert errors with reference to a cert only valid for Traefik. Also not fully documented, but the <code>BAUTH</code> variables need to be passed too although they should be made optional. May submit a PR for that... Follow the README to do a test notification</p><p>Set up a query to make sure notifications are coming through and then just get on with standard alarming!</p><h2 id="conclusion">Conclusion</h2><p> So, as you&#39;ve probably realized, I <em>really</em> lost steam towards the end of this post. I have been working on this post/stack setup for about three months and it has been frustrating me to no end and stopping me from writing things I would prefer to write about, and follow my current tech interests. I try to balance doing things I feel I <em>should</em> do with things that I have a strong (but usually fleeting) motivation to do as these rarely overlap. This time however, even though I can see the huge benefit of having a well set up monitoring stack for my home server and how all aspects of this will improve my quality of life when debugging/doing basic admin, the balance has just tipped to being more stressful than beneficial to me.</p><p> I will update my stack in the future, and hopefully write a more concise post on setting up a home server monitoring stack, but for now, this is all you get!</p>
			</section></div>
  </body>
</html>
