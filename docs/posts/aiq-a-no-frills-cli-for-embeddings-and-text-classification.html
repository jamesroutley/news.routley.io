<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/taylorai/aiq">Original</a>
    <h1>Show HN: AIQ â€“ A no-frills CLI for embeddings and text classification</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/taylorai/aiq/blob/main/aiq.gif"><img src="https://github.com/taylorai/aiq/raw/main/aiq.gif" alt="gif of aiq in the terminal" data-animated-image=""/></a></p>
<p dir="auto"><code>aiq</code> is a no-frills CLI for embeddings and text classification, inspired by the power of <code>jq</code>. It does 4 things:</p>
<ul dir="auto">
<li><code>aiq label</code>: Use LLM APIs to label a stream of texts</li>
<li><code>aiq embed</code>: Compute embeddings on a stream of texts</li>
<li><code>aiq train</code>: Train a text classifier (linear model) on a stream of embedded texts with labels</li>
<li><code>aiq classify</code>: Classify a stream of unlabeled text embeddings</li>
</ul>
<p dir="auto">These commands can operate on text and JSONL files, but they can also <strong>read from stdin.</strong> This means that you can chain them together: for example, you can use a single command to stream a text file in to be labeled, pipe the labeled data through an embedding model, and finally pipe the embedded, labeled training data through classifier training. (See the Quickstart to learn how!)</p>

<p dir="auto">To use, install with pip. This will install dependencies, and the aiq command-line interface.</p>

<p dir="auto">To use <code>aiq label</code>, you&#39;ll also need an OpenAI key. The other commands can be used on their own with no API key, as they run locally on your computer. Set the key as an environment variable:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"><pre><span>export</span> OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</pre></div>
<p dir="auto">For this quickstart, we include an example dataset and labels file (<code>recipes.txt</code> and <code>label_options.yaml</code>) to try in the <code>examples</code> folder. After downloading these files, you can run the following command to train a model to classify recipe names into breakfast, lunch/dinner, dessert, etc.</p>
<div dir="auto" data-snippet-clipboard-copy-content="aiq label --file recipes.txt --label-options-file label_options.yaml | aiq embed | aiq train --model_path model.joblib --n-classes 10"><pre>aiq label --file recipes.txt --label-options-file label_options.yaml <span>|</span> aiq embed <span>|</span> aiq train --model_path model.joblib --n-classes 10</pre></div>
<p dir="auto">This uses an LLM to label the text in <code>unlabeled.txt</code>, with the label options from <code>label_options.yaml</code>. The text fields are embedded using an embedding model (runs locally on CPU). Finally, a passive-aggressive classifier is trained using the labels and embeddings. The resulting model will be saved to <code>model.joblib</code>.</p>
<p dir="auto">You can then use <code>aiq classify</code> to run the model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &#39;{&#34;text&#34;: &#34;Maple-bacon and blueberry muffins&#34;}&#39; | aiq embed | aiq classify --model_path model.joblib"><pre><span>echo</span> <span><span>&#39;</span>{&#34;text&#34;: &#34;Maple-bacon and blueberry muffins&#34;}<span>&#39;</span></span> <span>|</span> aiq embed <span>|</span> aiq classify --model_path model.joblib</pre></div>
<p dir="auto">...which outputs the classified text:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{&#34;text&#34;: &#34;Maple-bacon and blueberry muffins&#34;, &#34;label&#34;: &#34;breakfast&#34;}"><pre>{<span>&#34;text&#34;</span>: <span><span>&#34;</span>Maple-bacon and blueberry muffins<span>&#34;</span></span>, <span>&#34;label&#34;</span>: <span><span>&#34;</span>breakfast<span>&#34;</span></span>}</pre></div>
<p dir="auto">You&#39;ll also get a warning about loading the model, which is a reminder that it&#39;s not safe to load <code>aiq</code> models from untrusted sources. You can disable this warning by setting the <code>--no-warn</code> flag for <code>aiq classify</code>.</p>


<p dir="auto">The <code>aiq label</code> command can read text or JSON from a file or from <code>stdin</code>. If you just want to label data and save the result, you can pipe the output directly to a file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="aiq label --file recipes.txt --label-options-file label_options.yaml &gt; labeled.jsonl"><pre>aiq label --file recipes.txt --label-options-file label_options.yaml <span>&gt;</span> labeled.jsonl</pre></div>

<p dir="auto">Embed the <code>text</code> field in <code>data.jsonl</code> and write the embeddings to <code>embeddings.jsonl</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat data.jsonl | aiq embed --input_field text --progress &gt; embeddings.jsonl"><pre>cat data.jsonl <span>|</span> aiq embed --input_field text --progress <span>&gt;</span> embeddings.jsonl</pre></div>
<p dir="auto">The <code>--progress</code> flag will show a running count of how many texts have been embedded. It should not be enabled if you&#39;re piping the output to another process, as the status indicators can interfere with each other.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Use labeled data to train a classifier</h3><a id="user-content-use-labeled-data-to-train-a-classifier" aria-label="Permalink: Use labeled data to train a classifier" href="#use-labeled-data-to-train-a-classifier"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Train a classifier with input in the <code>text</code> field and labels in the <code>label</code> field of <code>train_data.jsonl</code> and save it to <code>classifier.model</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat train_data.jsonl |
aiq embed --input_field text |
aiq train --label_field label --n_classes 2 --model_path classifier.model"><pre>cat train_data.jsonl <span>|</span>
aiq embed --input_field text <span>|</span>
aiq train --label_field label --n_classes 2 --model_path classifier.model</pre></div>
<p dir="auto">Note that &#34;text&#34; and &#34;label&#34; are the default fields for the text and label, so these flags can be omitted.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Inference with a classifier</h3><a id="user-content-inference-with-a-classifier" aria-label="Permalink: Inference with a classifier" href="#inference-with-a-classifier"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Use the classifier to classify unlabeled data in <code>unlabeled_data.txt</code> and write the predictions to <code>predictions.jsonl</code>. By default, <code>aiq embed</code> expects JSON, so we have to set the <code>input-type</code> to be &#34;text&#34;.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat unlabeled_data.txt | aiq embed --input-type text |
aiq classify --model-path classifier.model --label-field prediction &gt; predictions.jsonl"><pre>cat unlabeled_data.txt <span>|</span> aiq embed --input-type text <span>|</span>
aiq classify --model-path classifier.model --label-field prediction <span>&gt;</span> predictions.jsonl</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Save intermediate outputs</h3><a id="user-content-save-intermediate-outputs" aria-label="Permalink: Save intermediate outputs" href="#save-intermediate-outputs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Since <code>aiq</code> commands use <code>stdin</code>/<code>stdout</code> to communicate with each other, it&#39;s easy to combine them with other command-line utilities. For instance, if you don&#39;t just want the final output, you can use <code>tee</code> to sink intermediate outputs to a file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat unlabeled_data.txt | aiq embed --input-type text | tee embeddings.jsonl |
aiq classify --model-path classifier.model --label-field prediction &gt; predictions.jsonl"><pre>cat unlabeled_data.txt <span>|</span> aiq embed --input-type text <span>|</span> tee embeddings.jsonl <span>|</span>
aiq classify --model-path classifier.model --label-field prediction <span>&gt;</span> predictions.jsonl</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Chaining with <code>curl</code> and <code>jq</code></h3><a id="user-content-chaining-with-curl-and-jq" aria-label="Permalink: Chaining with curl and jq" href="#chaining-with-curl-and-jq"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can also combine <code>aiq</code> with <code>curl</code> and <code>jq</code> since it natively reads JSON from <code>stdin</code>. This allows you to, for example, fetch some remote JSON, and then compute embeddings on it. Here, we&#39;re grabbing 10 randomly-generated beers and computing the text embedding on their names:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl &#39;https://random-data-api.com/api/v2/beers?size=10&#39; |
jq -c &#39;.[]&#39; |
aiq embed --input_field name &gt; embeddings.jsonl"><pre>curl <span><span>&#39;</span>https://random-data-api.com/api/v2/beers?size=10<span>&#39;</span></span> <span>|</span>
jq -c <span><span>&#39;</span>.[]<span>&#39;</span></span> <span>|</span>
aiq embed --input_field name <span>&gt;</span> embeddings.jsonl</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Train a classifier on a remote dataset</h3><a id="user-content-train-a-classifier-on-a-remote-dataset" aria-label="Permalink: Train a classifier on a remote dataset" href="#train-a-classifier-on-a-remote-dataset"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Or, train a classifier to identify topics on some LLM fine-tuning data. We&#39;ll use <code>jq</code> to concatenate the &#34;input&#34; and &#34;output&#34; fields into one &#34;text&#34; field, then pass it to <code>aiq</code> to embed and train:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl https://gist.githubusercontent.com/andersonbcdefg/a4c8483bd7ffd349e685a6c04660c179/raw/ff7c18b8530982312dafe5db750177fb3e8be186/topics.jsonl |
jq  -c &#39;{text: (.input + &#34; &#34; + .output), topic: .topic}&#39; |
aiq embed |
aiq train --label_field topic --n_classes 8 --model_path topics.model"><pre>curl https://gist.githubusercontent.com/andersonbcdefg/a4c8483bd7ffd349e685a6c04660c179/raw/ff7c18b8530982312dafe5db750177fb3e8be186/topics.jsonl <span>|</span>
jq  -c <span><span>&#39;</span>{text: (.input + &#34; &#34; + .output), topic: .topic}<span>&#39;</span></span> <span>|</span>
aiq embed <span>|</span>
aiq train --label_field topic --n_classes 8 --model_path topics.model</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Command-line inference with the trained model</h3><a id="user-content-command-line-inference-with-the-trained-model" aria-label="Permalink: Command-line inference with the trained model" href="#command-line-inference-with-the-trained-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can then infer topics on some new data:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &#39;{&#34;input&#34;: &#34;What is the capital of Italy?&#34;, &#34;output&#34;: &#34;The capital of Italy is Rome.&#34;}&#39; |
jq -c &#39;{text: (.input + &#34; &#34; + .output)}&#39; |
aiq embed |
aiq classify --model_path topics.model"><pre><span>echo</span> <span><span>&#39;</span>{&#34;input&#34;: &#34;What is the capital of Italy?&#34;, &#34;output&#34;: &#34;The capital of Italy is Rome.&#34;}<span>&#39;</span></span> <span>|</span>
jq -c <span><span>&#39;</span>{text: (.input + &#34; &#34; + .output)}<span>&#39;</span></span> <span>|</span>
aiq embed <span>|</span>
aiq classify --model_path topics.model</pre></div>
<p dir="auto">And we get the output:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    &#34;text&#34;: &#34;What is the capital of Italy? The capital of Italy is Rome.&#34;,
    &#34;label&#34;: &#34;world_knowledge&#34;
}"><pre>{
    <span>&#34;text&#34;</span>: <span><span>&#34;</span>What is the capital of Italy? The capital of Italy is Rome.<span>&#34;</span></span>,
    <span>&#34;label&#34;</span>: <span><span>&#34;</span>world_knowledge<span>&#34;</span></span>
}</pre></div>

<p dir="auto">Here&#39;s an exhaustive list of arguments for each <code>aiq</code> command. Note that for these CLI arguments, hyphens and underscores are interchangeable.</p>

<p dir="auto">Label text inputs with an LLM. Supports raw text, or JSON objects.</p>
<p dir="auto">Flags:</p>
<ul dir="auto">
<li><code>--input_type</code>: Whether the input stream is raw texts (&#34;text&#34;), or JSON (&#34;json&#34;). If raw texts, then <code>--input_field</code> will be ignored.</li>
<li><code>--input_field</code>: If reading JSON, specifies the field to use as the input for labeling. The default value is &#34;text&#34;.</li>
<li><code>--label_options</code>: You can use this to directly provide inline label options. For instance: <code>--label_options &#39;{&#34;pos&#34;: &#34;positive sentiment&#34;, &#34;neg&#34;: &#34;negative sentiment&#34;}&#39;</code>. This is null by default; it&#39;s recommended to use <code>--label_options_file</code> to keep the command simpler.</li>
<li><code>--label_options_file</code>: CSV, JSON, JSONL, or YAML with labels and (optionally) their definitions/descriptions. The column with the labels should be called <code>label</code>, and the column with the definitions/descriptions should be called <code>description</code>. For YAML/JSON, you may also provide a file where the labels are the keys, and the descriptions are the values.</li>
<li><code>--output_field</code>, <code>-o</code>: The field to put the LLM label in. Defaults to &#34;label&#34;.</li>
<li><code>--model</code>: Name of the LLM to use for labeling. This is passed directly to the OpenAI client, so it supports any OpenAI chat model. You can also use any OpenAI-compatible API by setting the <code>api_base_url</code> (see below).</li>
<li><code>--file</code>, <code>-f</code>: If provided, reads from a file (can be text or JSON). Otherwise, reads from <code>stdin</code>, so it has to be chained.</li>
<li><code>--max_concurrency</code>: How many LLM completions can be running at once. You can increase this depending on your rate limits; it&#39;s 10 by default.</li>
<li><code>--api_key</code>: You can use this flag to pass your OpenAI (or OpenAI-compatible provider) API key, but it&#39;s recommended to use an environment variable instead.</li>
<li><code>--api_base_url</code>: You can use this flag (or the OPENAI_BASE_URL environment variable) to pass a different API URL from the default &#34;<a href="https://api.openai.com/v1" rel="nofollow">https://api.openai.com/v1</a>&#34;. This allows you to use other OpenAI-compatible LLM providers like TogetherAI, self-hosted vLLM or Ollama, etc.</li>
<li><code>--skip_errors</code>: Default False. If true, data points where an error happens will just be skipped and won&#39;t be put in the output stream. The benefit is that your process won&#39;t stop if an error occurs; the downside is your output may be missing some data from the input.</li>
<li><code>--progress</code>, <code>p</code>: Whether to show progress indicator for labeling. Do not enable this if you&#39;re piping the output to another <code>aiq</code> command; the status indicators interfere.</li>
</ul>

<p dir="auto">Compute embeddings for a text field in a stream of texts or JSON objects.</p>
<p dir="auto">Flags:</p>
<ul dir="auto">
<li><code>--input_type</code>: Whether the input is a stream of texts (&#34;text&#34;), or JSON objects (&#34;json&#34;). By default, it&#39;s &#34;json&#34;, which makes it compatible with the output of <code>aiq label</code>.</li>
<li><code>--input_field</code>: If <code>input_type</code> is &#34;json&#34;, the field to embed. Ignored for text input.</li>
<li><code>--output_field</code>, <code>-o</code>: The field in the JSON objects to write the embeddings to. Defaults to <code>embedding</code>.</li>
<li><code>--model_name</code>, <code>-m</code>: The name of the embedding model to use. Uses <code>snowflake-xs</code> by default, supports all models in the <a href="https://github.com/taylorai/onnx_embedding_models"><code>onnx_embedding_models</code></a> package.</li>
<li><code>--skip_errors</code>, <code>-s</code>: If true, skip over any errors that occur while embedding--inputs that cause errors will just not appear in the output. Otherwise, raise an exception. Defaults to <code>false</code>.</li>
<li><code>--progress</code>, <code>-p</code>: If true, will show progress in the console. Defaults to <code>false</code>, as the progress from embeddings can interfere with other progress bars and <code>embed</code> is designed to be chained.</li>
<li><code>--file</code>, <code>-f</code>: If provided, will read from the file instead of stdin. Supports <code>.jsonl</code> and <code>.txt</code>.</li>
</ul>

<p dir="auto">Train a text classifier on a stream of JSON objects with embeddings. Uses the PassiveAggressiveClassifier from <code>scikit-learn</code> for incremental learning, which means that the entire dataset never needs to be materialized in memory.</p>
<p dir="auto">Flags:</p>
<ul dir="auto">
<li><code>--model_path</code>, <code>-m</code>: The path to save the model to.</li>
<li><code>--n_classes</code>, <code>-n</code>: The number of classes to train on. The trainer will automatically identify the label names during training. However, will throw an error if more unique labels than <code>n_classes</code> are encountered.</li>
<li><code>--label_field</code>, <code>-l</code>: The field in the JSON objects to use as the label. This should be a string field, and it defaults to &#34;label&#34;, the default output of <code>aiq label</code>.</li>
<li><code>--input_field</code>, <code>-i</code>: The field in the JSON objects (which should be the embedding, a list of floats) to use as the input. Defaults to &#34;embedding&#34;, the default output field of <code>aiq embed</code>.</li>
<li><code>--batch_size</code>, <code>-b</code>: The batch size to use for training. Defaults to 32.</li>
<li><code>--test_size</code>, <code>-t</code>: The proportion of the data to use for estimating out-of-sample accuracy. Defaults to 0.1.</li>
</ul>

<p dir="auto">Classify a stream of JSON objects using their embeddings. Uses the model from <code>aiq train</code>.</p>
<p dir="auto">Flags:</p>
<ul dir="auto">
<li><code>--model_path</code>, <code>-m</code>: The path to load the model from.</li>
<li><code>--label_field</code>, <code>-l</code>: The field name for the predicted label in the output JSON. Can be different than the label field used for training.</li>
<li><code>--input_field</code>, <code>-i</code>: The field in the JSON objects (which should be the embedding, a list of floats) to use as the input. Defaults to &#34;embedding&#34;, which is the default output field of <code>embed</code>.</li>
<li><code>--remove_input</code>, <code>-r</code>: If this flag is set, remove the input (i.e. embedding) field from the output JSON. Embeddings can get really large and take up a lot of space, and you might not need it in the final result. Enabled by default.</li>
<li><code>--skip_errors</code>, <code>-s</code>: If true, skip over any errors that occur while embedding--inputs that cause errors will just not appear in the output. Otherwise, raise an exception. Defaults to <code>false</code>.</li>
<li><code>--no-warn</code>: If set, do not show the error about loading models from untrusted sources.</li>
</ul>

<p dir="auto">This tool is written in Python, and it works fine as a Python library. You can import the <code>label</code>, <code>embed</code>, <code>train</code>, and <code>classify</code> functions from <code>aiq</code> and use them directly.</p>
</article></div></div>
  </body>
</html>
