<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/ossrs/ffmpeg-webrtc/pull/1">Original</a>
    <h1>WebRTC support being added to FFmpeg</h1>
    
    <div id="readability-page-1" class="page"><div>
        <div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto"><a href="https://datatracker.ietf.org/doc/draft-ietf-wish-whip/" rel="nofollow">WHIP</a> stands for the WebRTC-HTTP ingestion protocol, which is a sub-second streaming protocol designed by encoders and publishers. It is widely supported by various tools and media servers, allowing it to interact with other WebRTC clients, ingest streams to media servers, and is compatible with all modern browsers.</p>
<p dir="auto">Unfortunately, most WHIP implementations are highly complex and require modern C++11 or C++14, or RUST. This complexity makes it impossible to integrate with FFmpeg, which requires C.</p>
<p dir="auto">However, if FFmpeg were to incorporate WHIP support, it could be a game-changer for both FFmpeg and the WebRTC ecosystem, particularly for certain IoT or small devices that are too small to run modern languages but can run FFmpeg.</p>
<p dir="auto">To meet FFmpeg&#39;s requirements, this PR contains just C code. And we have rewritten the WHIP and WebRTC protocol stack using only around 2k lines of C code.</p>
<blockquote>
<p dir="auto">Note: We&#39;ve included Janus, Pion, Millicast, and SRS as examples of WHIP servers you can use. However, there are many other options available, such as Galene, Deadsfu, and more. For more information, please see the <a href="https://github.com/IETF-Hackathon/ietf112-project-presentations/blob/main/ietf112-hackathon-whip.pdf">ietf112-hackathon-whip.pdf</a>.</p>
</blockquote>

<h2 dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto">Please select a WHIP server to work with FFmpeg.</p>
<ul dir="auto">
<li><a href="#usage-ffmpeg-janus">Usage: FFmpeg + Janus</a></li>
<li><a href="#usage-ffmpeg-pion">Usage: FFmpeg + Pion</a></li>
<li><a href="#usage-ffmpeg-srs">Usage: FFmpeg + SRS</a></li>
</ul>
<p dir="auto">If you encounter any issues or get stuck, please leave us a message on <a href="https://discord.gg/yZ4BnPmHAd" rel="nofollow">Discord</a>.</p>

<h2 dir="auto"><a href="#usage-ffmpeg-janus">Usage: FFmpeg + Janus</a></h2>
<p dir="auto">We referred to <a href="https://www.meetecho.com/blog/whip-janus-part-ii/" rel="nofollow">WISH, WHIP and Janus: Part II</a> to make it possible to use FFmpeg for publishing a stream to Janus via WHIP. We have also created a demo docker image <a href="https://github.com/winlinvip/janus-docker#whip">janus-docker</a> for quick testing.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/winlinvip/janus-docker.git
cd janus-docker"><pre>git clone https://github.com/winlinvip/janus-docker.git
<span>cd</span> janus-docker</pre></div>
<p dir="auto">Initially, run the demo Docker that includes Janus server using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd ~/git/janus-docker

ip=&#34;192.168.3.85&#34; &amp;&amp; sed -i &#39;&#39; &#34;s/nat_1_1_mapping.*/nat_1_1_mapping=\&#34;$ip\&#34;/g&#34; janus.jcfg

docker run --rm -it -p 8081:8080 -p 8188:8188 -p 8443:8443 -p 20000-20010:20000-20010/udp \
    -v $(pwd)/janus.jcfg:/usr/local/etc/janus/janus.jcfg \
    -v $(pwd)/janus.plugin.videoroom.jcfg:/usr/local/etc/janus/janus.plugin.videoroom.jcfg \
    -v $(pwd)/janus.transport.http.jcfg:/usr/local/etc/janus/janus.transport.http.jcfg \
    -v $(pwd)/janus.transport.websockets.jcfg:/usr/local/etc/janus/janus.transport.websockets.jcfg \
    -v $(pwd)/videoroomtest.js:/usr/local/share/janus/demos/videoroomtest.js \
    ossrs/janus:v1.0.11"><pre><span>cd</span> <span>~</span>/git/janus-docker

ip=<span><span>&#34;</span>192.168.3.85<span>&#34;</span></span> <span>&amp;&amp;</span> sed -i <span><span>&#39;</span><span>&#39;</span></span> <span><span>&#34;</span>s/nat_1_1_mapping.*/nat_1_1_mapping=<span>\&#34;</span><span>$ip</span><span>\&#34;</span>/g<span>&#34;</span></span> janus.jcfg

docker run --rm -it -p 8081:8080 -p 8188:8188 -p 8443:8443 -p 20000-20010:20000-20010/udp \
    -v <span><span>$(</span>pwd<span>)</span></span>/janus.jcfg:/usr/local/etc/janus/janus.jcfg \
    -v <span><span>$(</span>pwd<span>)</span></span>/janus.plugin.videoroom.jcfg:/usr/local/etc/janus/janus.plugin.videoroom.jcfg \
    -v <span><span>$(</span>pwd<span>)</span></span>/janus.transport.http.jcfg:/usr/local/etc/janus/janus.transport.http.jcfg \
    -v <span><span>$(</span>pwd<span>)</span></span>/janus.transport.websockets.jcfg:/usr/local/etc/janus/janus.transport.websockets.jcfg \
    -v <span><span>$(</span>pwd<span>)</span></span>/videoroomtest.js:/usr/local/share/janus/demos/videoroomtest.js \
    ossrs/janus:v1.0.11</pre></div>
<blockquote>
<p dir="auto">Note: Kindly modify the IP address to your own IP address. You can use <code>ifconfig</code> or <code>ipconfig</code> to determine it.</p>
</blockquote>
<p dir="auto">After that, access the URL <a href="http://localhost:8081/videoroomtest.html?room=2345" rel="nofollow">http://localhost:8081/videoroomtest.html?room=2345</a> in your browser to join the Janus room.</p>
<p dir="auto">Next, download and run the <a href="https://github.com/meetecho/simple-whip-server">Simple WHIP Server</a> for Janus using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/meetecho/simple-whip-server.git
cd simple-whip-server
npm install
npm run build
npm run start"><pre>git clone https://github.com/meetecho/simple-whip-server.git
<span>cd</span> simple-whip-server
npm install
npm run build
npm run start</pre></div>
<p dir="auto">Generate a WHIP handler using curl, which will  enable ffmpeg to join the same Janus room through WHIP:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -H &#39;Content-Type: application/json&#39; -d &#39;{&#34;id&#34;: &#34;abc123&#34;, &#34;room&#34;: 2345}&#39; \
    http://localhost:7080/whip/create"><pre>curl -H <span><span>&#39;</span>Content-Type: application/json<span>&#39;</span></span> -d <span><span>&#39;</span>{&#34;id&#34;: &#34;abc123&#34;, &#34;room&#34;: 2345}<span>&#39;</span></span> \
    http://localhost:7080/whip/create</pre></div>
<p dir="auto">To download the code and build FFmpeg, you can use the following command.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd ~/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10"><pre><span>cd</span> <span>~</span>/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10</pre></div>
<blockquote>
<p dir="auto">Note: To enable DTLS handshake, OpenSSL is mandatory. Please install OpenSSL, for instance, <code>brew install openssl</code>, and then configure the environment by running export <code>PKG_CONFIG_PATH=&#34;/usr/local/opt/openssl@3/lib/pkgconfig&#34;</code>.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: For demonstration purposes, you can install libx264 by running <code>brew install x264</code> and libopus by running <code>brew install opus</code>.</p>
</blockquote>
<p dir="auto">Although WebRTC has the capability to support x264 main and high profiles without B frames, it is advisable to use the baseline profile for better compatibility. If your stream doesn&#39;t have these codecs, you can transcode it using FFmpeg.</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/git/FFmpeg/ffmpeg_g -re -i ~/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc &#39;http://localhost:7080/whip/endpoint/abc123&#39;

# Or you can also capture your screen, and measure the end-to-end latency.
~/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i &#34;2:0&#34; \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc &#39;http://localhost:7080/whip/endpoint/abc123&#39;"><pre><span>~</span>/git/FFmpeg/ffmpeg_g -re -i <span>~</span>/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc <span><span>&#39;</span>http://localhost:7080/whip/endpoint/abc123<span>&#39;</span></span>

<span><span>#</span> Or you can also capture your screen, and measure the end-to-end latency.</span>
<span>~</span>/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i <span><span>&#34;</span>2:0<span>&#34;</span></span> \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc <span><span>&#39;</span>http://localhost:7080/whip/endpoint/abc123<span>&#39;</span></span></pre></div>
<p dir="auto">After publishing the stream to the Janus room, you will be able to view it on the previously opened webpage. The image below shows that the latency is around 480ms.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/2777660/238165501-303a6f22-0f0c-4c64-81b2-22ebbc5211e4.png"><img width="480" alt="image" src="https://user-images.githubusercontent.com/2777660/238165501-303a6f22-0f0c-4c64-81b2-22ebbc5211e4.png"/></a></p><blockquote>
<p dir="auto">Note: Initially, the latency was about 150ms, but it later increased to approximately 480ms. We have reported this issue at <a href="https://github.com/meetecho/janus-gateway/issues/3222" data-hovercard-type="issue" data-hovercard-url="/meetecho/janus-gateway/issues/3222/hovercard">here</a>.</p>
</blockquote>

<h2 dir="auto"><a href="#usage-ffmpeg-pion">Usage: FFmpeg + Pion</a></h2>
<p dir="auto">To download the code and build FFmpeg, you can use the following command.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd ~/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10"><pre><span>cd</span> <span>~</span>/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10</pre></div>
<blockquote>
<p dir="auto">Note: To enable DTLS handshake, OpenSSL is mandatory. Please install OpenSSL, for instance, <code>brew install openssl</code>, and then configure the environment by running export <code>PKG_CONFIG_PATH=&#34;/usr/local/opt/openssl@3/lib/pkgconfig&#34;</code>.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: For demonstration purposes, you can install libx264 by running <code>brew install x264</code> and libopus by running <code>brew install opus</code>.</p>
</blockquote>
<p dir="auto">Although WebRTC has the capability to support x264 main and high profiles without B frames, it is advisable to use the baseline profile for better compatibility. If your stream doesn&#39;t have these codecs, you can transcode it using FFmpeg.</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/git/FFmpeg/ffmpeg_g -re -i ~/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization &#34;seanTest&#34; &#34;https://b.siobud.com/api/whip&#34;

# Or you can also capture your screen, and measure the end-to-end latency.
~/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i &#34;2:0&#34; \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization &#34;seanTest&#34; &#34;https://b.siobud.com/api/whip&#34;"><pre><span>~</span>/git/FFmpeg/ffmpeg_g -re -i <span>~</span>/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization <span><span>&#34;</span>seanTest<span>&#34;</span></span> <span><span>&#34;</span>https://b.siobud.com/api/whip<span>&#34;</span></span>

<span><span>#</span> Or you can also capture your screen, and measure the end-to-end latency.</span>
<span>~</span>/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i <span><span>&#34;</span>2:0<span>&#34;</span></span> \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization <span><span>&#34;</span>seanTest<span>&#34;</span></span> <span><span>&#34;</span>https://b.siobud.com/api/whip<span>&#34;</span></span></pre></div>
<p dir="auto">After publishing stream to pion, you can play the WebRTC stream in web browser such as Chrome</p>
<ul dir="auto">
<li>WebRTC: <a href="https://b.siobud.com/seanTest" rel="nofollow">https://b.siobud.com/seanTest</a></li>
</ul>

<h2 dir="auto"><a href="#usage-ffmpeg-milicast">Usage: FFmpeg + Millicast</a></h2>
<p dir="auto">On the way.</p>

<h2 dir="auto"><a href="#usage-ffmpeg-srs">Usage: FFmpeg + SRS</a></h2>
<p dir="auto">To enable FFmpeg to publish a stream, SRS can be used as the WHIP server. It is recommended to use docker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ip=&#34;192.168.3.85&#34; 
docker run --rm -it -p 1935:1935 -p 1985:1985 -p 8080:8080 \
    --env CANDIDATE=$ip -p 8000:8000/udp \
    ossrs/srs:5 ./objs/srs -c conf/rtc2rtmp.conf"><pre>ip=<span><span>&#34;</span>192.168.3.85<span>&#34;</span></span> 
docker run --rm -it -p 1935:1935 -p 1985:1985 -p 8080:8080 \
    --env CANDIDATE=<span>$ip</span> -p 8000:8000/udp \
    ossrs/srs:5 ./objs/srs -c conf/rtc2rtmp.conf</pre></div>
<p dir="auto">Alternatively, you can build SRS from its source code.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd ~/git
git clone -b develop https://github.com/ossrs/srs.git
cd srs/trunk
./configure
make -j10

# After building SRS, you may run it using a configuration file.
cd ~/git/srs/trunk
./objs/srs -c conf/rtc2rtmp.conf"><pre><span>cd</span> <span>~</span>/git
git clone -b develop https://github.com/ossrs/srs.git
<span>cd</span> srs/trunk
./configure
make -j10

<span><span>#</span> After building SRS, you may run it using a configuration file.</span>
<span>cd</span> <span>~</span>/git/srs/trunk
./objs/srs -c conf/rtc2rtmp.conf</pre></div>
<blockquote>
<p dir="auto">Note: Please upgrade to SRS version 5.0.153 or higher, or 6.0.43 or higher.</p>
</blockquote>
<p dir="auto">To download the code and build FFmpeg, you can use the following command.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd ~/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10"><pre><span>cd</span> <span>~</span>/git 
git clone -b feature/rtc-muxer https://github.com/winlinvip/ffmpeg-webrtc.git
./configure --enable-muxer=rtc --enable-openssl --enable-version3 \
    --enable-libx264 --enable-gpl --enable-libopus
make -j10</pre></div>
<blockquote>
<p dir="auto">Note: To enable DTLS handshake, OpenSSL is mandatory. Please install OpenSSL, for instance, <code>brew install openssl</code>, and then configure the environment by running export <code>PKG_CONFIG_PATH=&#34;/usr/local/opt/openssl@3/lib/pkgconfig&#34;</code>.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: For demonstration purposes, you can install libx264 by running <code>brew install x264</code> and libopus by running <code>brew install opus</code>.</p>
</blockquote>
<p dir="auto">Although WebRTC has the capability to support x264 main and high profiles without B frames, it is advisable to use the baseline profile for better compatibility. If your stream doesn&#39;t have these codecs, you can transcode it using FFmpeg.</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/git/FFmpeg/ffmpeg_g -re -i ~/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc &#34;http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream&#34;

# Or you can also capture your screen, and measure the end-to-end latency.
~/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i &#34;2:0&#34; \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc &#34;http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream&#34;"><pre><span>~</span>/git/FFmpeg/ffmpeg_g -re -i <span>~</span>/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc <span><span>&#34;</span>http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream<span>&#34;</span></span>

<span><span>#</span> Or you can also capture your screen, and measure the end-to-end latency.</span>
<span>~</span>/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i <span><span>&#34;</span>2:0<span>&#34;</span></span> \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc <span><span>&#34;</span>http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream<span>&#34;</span></span></pre></div>
<p dir="auto">After publishing stream to SRS, you can play the WHIP stream in web browser such as Chrome, using srs-player.</p>
<ul dir="auto">
<li>WHEP: <a href="http://localhost:8080/players/whep.html" rel="nofollow">http://localhost:1985/rtc/v1/whip-play/?app=live&amp;stream=livestream</a></li>
</ul>
<p dir="auto">The image below shows that the latency is around 150ms.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/2777660/237846317-6f077d7a-3265-45be-9233-0c621da0c800.png"><img width="480" alt="image" src="https://user-images.githubusercontent.com/2777660/237846317-6f077d7a-3265-45be-9233-0c621da0c800.png"/></a></p><p dir="auto">The RTMP, HTTP-FLV, or HTTP-TS stream remuxed by SRS can be played using ffplay, VLC, or srs-player.</p>

<h2 dir="auto"><a href="#known-issues">Known Issues</a></h2>
<p dir="auto">The current version has some known issues that we plan to fix in the future. You are welcome to help us fix them by sending a pull request.</p>
<p dir="auto">The current known issues include:</p>
<ul dir="auto">
<li>Long First Screen Wait Time: Respond to the PLI request for quick decoding and rendering; otherwise, it takes a GOP&#39;s duration to display the first decoded image. A RTC encoder ought to have the capability to refresh the IDR frame when a new player joins or there is packet loss, as requested by the player through a PLI. When working within the ffmpeg framework, it&#39;s not possible to control the encoder in muxer. This means we cannot force an encoder to generate an IDR frame right away. One possible solution could be to cache the IDR frame or a GOP of frames in the RTC muxer and send it to the server upon receiving a PLI request. The player can then handle any latency issues that may arise.</li>
<li>Multiple Slices Issue: If the <code>-tune zerolatency</code> option is enabled and <code>threads&gt;1</code>, FFmpeg will encode the frame in multiple slices. This process can cause stuttering in Chrome&#39;s decoding, with only the IDR being able to be decoded. Both the IDR and P frames may be encoded to multiple slices and sent by multiple RTP packets with the same timestamp. RTC players, such as Chrome, may have issues decoding frames that have been encoded using multiple slices. As a result, Chrome may only decode some of the slices of the IDR frame and drop the P frames. If this issue occurs, it may appear as if the video player is stuttering and the decoded framerate will be equivalent to the GOP size.</li>
<li>In addition to OpenSSL, support for other cryptographic libraries such as GnuTLS, mbedtls, etc., is needed. To achieve this, a dtls.c file should be extracted, similar to tls.c, for better utilization.</li>
<li>Presently, only the client role is supported for DTLS, while the server role remains unsupported. Although not mandatory, the DTLS client is commonly used in ffmpeg as a WebRTC client.</li>
<li>Compatibility is limited to OpenSSL 1.1.1b or newer versions. To prevent build failures, it may be necessary to ensure compatibility with older versions.</li>
<li>Features such as congestion control, NACK, and FEC are not yet implemented. While NACK is essential, FEC remains optional.</li>
<li>Currently, only the first candidate (UDP and host type) is utilized. A mechanism to determine the fastest candidate, select the best one, or switch during publishing is needed.</li>
<li>When remuxing WebRTC to RTMP or HTTP-FLV, stuttering can occur every N seconds, which may be the same as the GOP size. Note that this bug occurs during screen streaming,  but there is no issues when converting a file to WHIP streaming.</li>
<li>While capturing the screen using FFmpeg, the h.264 profile may be negative (e.g. -99), in which case we set the profile to 0x42 (baseline). However, in such a situation, it may be necessary to parse from SPS/PPS.</li>
</ul>
<p dir="auto">Below are the issues that have already been fixed:</p>
<ul dir="auto">
<li>Need to improve the end-to-end latency to 150ms from 800ms. Fixed by <a data-hovercard-type="user" data-hovercard-url="/users/T-bagwell/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/T-bagwell">@T-bagwell</a> <a data-hovercard-type="user" data-hovercard-url="/users/mypopydev/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/mypopydev">@mypopydev</a> <a data-hovercard-type="user" data-hovercard-url="/users/winlinvip/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/winlinvip">@winlinvip</a></li>
<li>For SRS to convert RTC to RTMP using time information, it is essential to send an RTCP SR report. Fixed by <a data-hovercard-type="user" data-hovercard-url="/users/duiniuluantanqin/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/duiniuluantanqin">@duiniuluantanqin</a></li>
<li>Only send binding requests to the server and cannot receive binding requests from the server. Fixed by <a data-hovercard-type="user" data-hovercard-url="/users/cloudwebrtc/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cloudwebrtc">@cloudwebrtc</a>. In addition, he assists in enabling ICE use-candidate for Janus or Pion to finalize the ICE handshake.</li>
<li>WHIP currently supports only HTTP, with HTTPS yet to be implemented. However, incorporating HTTPS should be straightforward, as ffmpeg already contains the necessary code. Note: The ffmpeg HTTP library has the functionality to support both the HTTP and HTTPS protocols.</li>
<li>Support baseline/main/high profile without B frames. Even though WebRTC has the capability to support x264 main and high profiles without B frames, it is advisable to use the baseline profile for better compatibility. See <a data-hovercard-type="commit" data-hovercard-url="https://github.com/ossrs/ffmpeg-webrtc/commit/bd9f7d1a0478ed8d300ec8b71b7908e847410e5a/hovercard" href="https://github.com/ossrs/ffmpeg-webrtc/commit/bd9f7d1a0478ed8d300ec8b71b7908e847410e5a"><tt>bd9f7d1</tt></a> <a data-hovercard-type="user" data-hovercard-url="/users/duiniuluantanqin/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/duiniuluantanqin">@duiniuluantanqin</a></li>
<li>During the DTLS handshake, when FFmpeg receives a ServerHello from the server, it generates a ClientHello for retransmission with a Certificate. This causes the server to retransmit the ServerHello, which still works but is not efficient. We should try to eliminate the unnecessary retransmission of the ClientHello. See <a data-hovercard-type="commit" data-hovercard-url="https://github.com/ossrs/ffmpeg-webrtc/commit/3b3b17a6f06cb15198d32c2e424544e5ef4e8651/hovercard" href="https://github.com/ossrs/ffmpeg-webrtc/commit/3b3b17a6f06cb15198d32c2e424544e5ef4e8651"><tt>3b3b17a</tt></a> <a data-hovercard-type="user" data-hovercard-url="/users/winlinvip/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/winlinvip">@winlinvip</a></li>
</ul>

<h2 dir="auto"><a href="#latency">Latency</a></h2>
<p dir="auto">To test the end-to-end latency of a WIHP stream published using FFmpeg, you can capture your desktop using FFmpeg, open a <a href="https://www.timeanddate.com/stopwatch/" rel="nofollow">stopwatch</a> or <a href="https://m.wannianli.tianqi.com/jisuanqi/miaobiao" rel="nofollow">miaobiao</a> in the browser, and compare the <a href="http://localhost:8080/players/whep.html" rel="nofollow">player</a> with the original stopwatch.</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i &#34;2:0&#34; \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc &#39;http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream&#39;"><pre><span>~</span>/git/FFmpeg/ffmpeg_g -f avfoundation -framerate 25 -pixel_format yuyv422 -i <span><span>&#34;</span>2:0<span>&#34;</span></span> \
    -vcodec libx264 -pix_fmt yuv420p -profile:v baseline -preset:v ultrafast \
    -b:v 800k -s 1024x576 -r 25 -g 50 -tune zerolatency -threads 1 -bf 0 \
    -acodec libopus -ar 48000 -ac 2 \
    -f rtc <span><span>&#39;</span>http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream<span>&#39;</span></span></pre></div>
<blockquote>
<p dir="auto">Note: The parameter <code>-i &#34;2:0&#34;</code> is formatted as a video:audio device ID. Please use the <code>~/git/FFmpeg/ffmpeg_g -f avfoundation -list_devices true -i &#34;&#34;</code> command to list device ID and information.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: It is recommended to keep the threads=1 setting to prevent the occurrence of the <code>Multiple Slices Issue</code>. Please refer to <a href="#known-issues">Known Issues</a> for more information.</p>
</blockquote>
<p dir="auto">The test results are incredible! The image below shows that the latency is around 150ms.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/2777660/237846317-6f077d7a-3265-45be-9233-0c621da0c800.png"><img width="480" alt="image" src="https://user-images.githubusercontent.com/2777660/237846317-6f077d7a-3265-45be-9233-0c621da0c800.png"/></a></p>
<h2 dir="auto"><a href="#openssl">OpenSSL</a></h2>
<p dir="auto">Below is a list of OpenSSL versions that are supported.</p>
<ul dir="auto">
<li><a href="https://github.com/openssl/openssl/releases/tag/OpenSSL_1_0_1k">OpenSSL 1.0.1k</a> and newer. Note that OpenSSL 1.0.1j does not work, please refer to <a href="https://github.com/openssl/openssl/issues/346" data-hovercard-type="issue" data-hovercard-url="/openssl/openssl/issues/346/hovercard">this link</a>.</li>
<li><a href="https://github.com/openssl/openssl/releases/tag/OpenSSL_1_0_2">OpenSSL 1.0.2</a> and newer.</li>
<li><a href="https://github.com/openssl/openssl/releases/tag/OpenSSL_1_1_0h">OpenSSL 1.1.0h</a> and newer. Note that the compilation of OpenSSL 1.1.0g failed, but the API should work if you can fix the compilation bug.</li>
<li><a href="https://github.com/openssl/openssl/releases/tag/openssl-3.0.0">OpenSSl 3.0.0</a> and newer.</li>
<li><a href="https://github.com/openssl/openssl/releases/tag/openssl-3.1.0">OpenSSl 3.1.0</a> and newer.</li>
</ul>
<p dir="auto">In short, OpenSSL <code>1.0.1k</code> and newer versions should work. However, <a href="https://github.com/openssl/openssl/releases/tag/OpenSSL_1_1_0h">OpenSSL 1.1.0h</a> is highly recommended.</p>
<p dir="auto">Execute the command below to compile OpenSSL.</p>
<div dir="auto" data-snippet-clipboard-copy-content="./config &amp;&amp; make &amp;&amp; make install_sw"><pre>./config <span>&amp;&amp;</span> make <span>&amp;&amp;</span> make install_sw</pre></div>
<blockquote>
<p dir="auto">Note: For macOS, please use command <code>./Configure darwin64-x86_64-cc</code> instead.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: You can specify the target directory by <code>--prefix=$HOME/.release/openssl</code> and set the <code>PKG_CONFIG_PATH=&#34;$HOME/.release/openssl/lib/pkgconfig&#34;</code> for FFmpeg.</p>
</blockquote>
<blockquote>
<p dir="auto">Note: For OpenSSL <code>1.0</code>, if <code>OpenSSL not found</code> even after confirming that the <code>PKG_CONFIG_PATH</code> is correctly set, then use <code>--extra-libs=&#34;-ldl&#34;</code> while configuring FFmpeg.</p>
</blockquote>

<h2 dir="auto"><a href="#authorization">Authorization</a></h2>
<p dir="auto">Set option <code>-authorization token</code> to use the authorization of WHIP, please refer to the <a href="https://www.ietf.org/archive/id/draft-ietf-wish-whip-08.html#name-authentication-and-authoriz" rel="nofollow">Authentication and authorization</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/git/FFmpeg/ffmpeg_g -re -i ~/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization &#34;mF_9.B5f-4.1JqM&#34; \
    &#34;http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream&#34;"><pre><span>~</span>/git/FFmpeg/ffmpeg_g -re -i <span>~</span>/git/srs/trunk/doc/source.flv \
    -vcodec libx264 -profile:v baseline -r 25 -g 50 -acodec libopus -ar 48000 -ac 2 \
    -f rtc -authorization <span><span>&#34;</span>mF_9.B5f-4.1JqM<span>&#34;</span></span> \
    <span><span>&#34;</span>http://localhost:1985/rtc/v1/whip/?app=live&amp;stream=livestream<span>&#34;</span></span></pre></div>
<blockquote>
<p dir="auto">Note: The token is <code>mF_9.B5f-4.1JqM</code>, and the HTTP header is set to <code>Authorization: Bearer mF_9.B5f-4.1JqM</code>.</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/2777660/241973872-852a4f50-313f-450b-b5b2-3624e55bb984.png"><img src="https://user-images.githubusercontent.com/2777660/241973872-852a4f50-313f-450b-b5b2-3624e55bb984.png" alt=""/></a></p>

<h2 dir="auto"><a href="#authors">Authors</a></h2>
<p dir="auto">This patch has been created and is maintained by the developers below.</p>
<ul dir="auto">
<li>Steven Liu <a href="mailto:liuqi05@kuaishou.com">liuqi05@kuaishou.com</a></li>
<li>winlin <a href="mailto:winlinvip@gmail.com">winlinvip@gmail.com</a></li>
<li>yangrtc <a href="mailto:yangrtc@aliyun.com">yangrtc@aliyun.com</a></li>
<li>cloudwebrtc <a href="mailto:duanweiwei1982@gmail.com">duanweiwei1982@gmail.com</a></li>
<li>Haibo Chen <a href="mailto:495810242@qq.com">495810242@qq.com</a></li>
</ul>

<h2 dir="auto"><a href="#links">Links</a></h2>
<p dir="auto">WHIP: <a href="https://datatracker.ietf.org/doc/draft-ietf-wish-whip/" rel="nofollow">https://datatracker.ietf.org/doc/draft-ietf-wish-whip/</a></p>
    </div>
  </task-lists>
  
</div>

      </div></div>
  </body>
</html>
