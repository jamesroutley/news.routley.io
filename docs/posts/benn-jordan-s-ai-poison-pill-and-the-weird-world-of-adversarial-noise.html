<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cdm.link/benn-jordan-ai-poison-pill/">Original</a>
    <h1>Benn Jordan&#39;s AI poison pill and the weird world of adversarial noise</h1>
    
    <div id="readability-page-1" class="page"><div>
    	  
<p>Benn Jordan’s latest video proposes a way to fight back when generative AI music services rip off music for their data sets. It’s not ready for prime time yet, but it does offer a window into the wild, wonderful world of adversarial noise poisoning attacks.</p>



<p>Now, if you run in circles like mine, you’ve already gotten, “Hey, have you seen this new Benn Jordan video?” already, and I suspect gotten as far as watching it, but here you go:</p>



<figure><p>
<iframe title="The Art Of Poison-Pilling Music Files" width="500" height="281" src="https://www.youtube.com/embed/xMYm2d9bmEA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Benn’s approaches should have some real legs. There are two reasons to be optimistic. One, this family of techniques works on audio, so it covers the so-called “<a href="https://en.wikipedia.org/wiki/Analog_hole">analog loophole</a>“: it functions <em>anywhere</em> sound is heard. Two, there’s a potential to use <em>different</em> methods, thus obfuscating the results. You can also validate the results, meaning these could be updated if services react.</p>



<p>It’s funny; when I spoke to Roland’s Paul McCabe about that company’s AI initiatives, I suggested a speculative design where you could press a button and block a performance from being trained. Benn actually went directly to the data science researchers to find out how that could be done – even in a live instrumental performance.</p>



<p>Of course, you count as a CDM reader if your favorite music in the entire video is the targeted pressure wave attack at 22:00. </p>



<p>The big gotcha – spoiler alert – is that this requires high-end GPUs and a massive amount of electricity and time to pull off. Computation doesn’t magically consume less power on its own, either – least of all with semiconductor trade wars looming. But now that the idea is out there, the challenge would be devising a more efficient method; this at least works as a proof of concept.</p>



<p>In short, I’m for it. And I do expect a fear of training will stop some people from sending music to streaming services. It’s not hard to envision, as Benn does, a world where distributors license this technology to give producers added peace of mind. Remember in the early 2000s when we worried about protecting music from human fans? Now we’re protecting it from generative AI.</p>



<p>It’s worth watching the video, though, because the whole world of adversarial noise gets fascinating – and is a way to imagine hacking increasing AI and surveillance. So this is all about more than just the Poisonify concept (though that’s already essential).</p>



<h3>Into the data science</h3>



<p>Here’s more on the harmony cloaking tools developed at University of Tennessee Knoxville:</p>



<p><a href="https://eu.knoxnews.com/story/news/education/2024/12/10/harmonycloak-university-of-tennessee-stops-ai-from-using-copyrighted-music/76338974007/">You can’t hear it, but University of Tennessee tool ‘cloaks’ songs to protect music from AI</a> [<em>Knoxville News</em>]</p>



<p>The site/paper also has a survey:</p>



<p><a href="https://mosis.eecs.utk.edu/harmonycloak.html">HarmonyCloak: Making Music Unlearnable for Generative AI</a></p>



<p>The instrument classification attack, as far as I know, is novel. </p>



<p>Even if it didn’t find its market in digital distribution and DSPs, as Benn notes in the video, the AI detection algorithm research Benn did also remains compelling:</p>



<p><a href="https://musictech.com/news/music/benn-jordan-detect-ai-music/">Benn Jordan has made an algorithm that can detect if music has been made by AI or not</a></p>



<p>You’ll find a lot on adversarial noise, in different contexts – because that can be a method of training neural network classifiers and a way of attacking those systems. (There’s “friendly” and “unfriendly,” basically – even though I know that conflicts with what the word “adversarial” normally means. Think of it as “I’m challenging you to a game of chess to teach you something” versus “I’m challenging you to a game of chess to <em>mind control you</em>.” Sort of.)</p>



<p>And this stuff is moving <em>fast</em>. Here’s Los Alamos National Laboratory, the folks who have never been associated with anything other than friendly uses of science and technology:</p>



<p><a href="https://www.lanl.gov/media/news/0305-ai-adversarial-attacks">New AI defense method shields models from adversarial attacks</a></p>



<p>Or some 2022 proceedings of the International Conference of Neural Information Processing Systems:</p>



<p><a href="https://dl.acm.org/doi/10.5555/3600270.3601138">Friendly noise against adversarial noise: a powerful defense against data poisoning attacks</a></p>



<p>2020 and IBM Watson: [PDF]</p>



<p><a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Agarwal_Noise_Is_Inside_Me_Generating_Adversarial_Perturbations_With_Noise_Derived_CVPRW_2020_paper.pdf">Noise is Inside Me! Generating Adversarial Perturbations with Noise Derived from Natural Filters</a></p>



<p>Targeted pressure wave attacks as discussed in the video are being deployed against machines, but they’re also known for use in sonic weapons against humans. That’s likely what was causing serious neurological symptoms in pulsed microwave energy in Cuba, the <a href="https://www.nbcnews.com/news/all/havana-syndrome-likely-caused-microwave-energy-government-study-finds-n1250094">so-called “Havana Syndrome”</a> – <a href="https://www.nationaldefensemagazine.org/articles/2018/9/6/exclusive-doctors-reveal-details-of-neuroweapon-attacks-in-havana">sound as a neuro-weapon</a>.</p>



<p>But as for using sound against machines, here you go:</p>



<p><a href="https://hal.science/hal-03878176/file/Adversarial_attacks_by_random_noises.pdf">Neural Adversarial Attacks with Random Noises</a></p>



<p>And the same broader category of mechanisms that can be used to attack can be used in training:</p>



<p><a href="https://arxiv.org/abs/2109.09901">Modeling Adversarial Noise for Adversarial Training</a></p>



<p><a href="https://arxiv.org/abs/2212.05337">Targeted Adversarial Attacks on Deep Reinforcement Learning Policies via Model Checking</a></p>



<p>An actual data scientist might have some better ideas; I just play one on TV.</p>



<p>Anyway, yes, my idea of fun is making music, I really don’t find genAI music to be fun, but I do also enjoy imagining generating unheard musics by rewiring machine listening to categorize things incorrectly. </p>



<p>And, I mean, obviously we need to do some kind of music compilation of (audible) adversarial noise attacks, though I guess we should be careful how we distribute it. I think I’m only interested in a malfunctioning Alexa, so this might convince me to try to buy someone’s older model just to mess with it. I … also liked the screwed-up musical results better.</p>



<p>If that meandering discourse put you to sleep, here, let me wake you up again with rage.</p>



<p>Here’s the clip that inspired the image at top; it’s a quote from Suno.ai founder Mikey Shulman:</p>







<p>Oh, sorry, that is the text as spoken with an AI-generated version of Anakin Skywalker’s voice. (I was just <a href="https://youtu.be/miVu_LOC0G0?si=-3B196q8P5-PExT5">inspired by this conversation</a>; the sentence construction seemed similar.) Here is the original clip in context, in which he also says people don’t like running (again, maybe suggesting a Darth Vader sort of solution):</p>



<blockquote data-media-max-width="560"><p lang="en" dir="ltr">“It’s not really enjoyable to make music now… it takes a lot of time, it takes a lot of practice, you have to get really good at an instrument or really good at a piece of production software. I think the majority of people don’t enjoy the majority of time they spend making… <a href="https://t.co/zkv73Bhmi9">pic.twitter.com/zkv73Bhmi9</a></p>— Mike Patti (@mpatti) <a href="https://twitter.com/mpatti/status/1878147029764911131?ref_src=twsrc%5Etfw">January 11, 2025</a></blockquote> 

        
    	  
    	  <div><p>Tags: <a href="https://cdm.link/tag/adversarial-noise/" rel="tag">adversarial noise</a>, <a href="https://cdm.link/tag/ai/" rel="tag">AI</a>, <a href="https://cdm.link/tag/ai-weapons/" rel="tag">AI weapons</a>, <a href="https://cdm.link/tag/artists/" rel="tag">artists</a>, <a href="https://cdm.link/tag/benn-jordan/" rel="tag">Benn Jordan</a>, <a href="https://cdm.link/tag/business/" rel="tag">business</a>, <a href="https://cdm.link/tag/darth-vader/" rel="tag">Darth Vader</a>, <a href="https://cdm.link/tag/data-science/" rel="tag">data science</a>, <a href="https://cdm.link/tag/data-sets/" rel="tag">data sets</a>, <a href="https://cdm.link/tag/genai/" rel="tag">genAI</a>, <a href="https://cdm.link/tag/generative-ai/" rel="tag">generative AI</a>, <a href="https://cdm.link/tag/hacks/" rel="tag">hacks</a>, <a href="https://cdm.link/tag/machine-learning-2/" rel="tag">machine learning</a>, <a href="https://cdm.link/tag/opinion/" rel="tag">opinion</a>, <a href="https://cdm.link/tag/poison-pills/" rel="tag">poison pills</a>, <a href="https://cdm.link/tag/streaming/" rel="tag">streaming</a>, <a href="https://cdm.link/tag/the-flashbulb/" rel="tag">The Flashbulb</a></p></div>
    	  
    		      		
    						
				
				
				        
                          
                  	</div></div>
  </body>
</html>
