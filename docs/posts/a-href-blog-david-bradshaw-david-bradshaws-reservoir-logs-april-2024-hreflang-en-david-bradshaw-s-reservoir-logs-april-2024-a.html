<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.wildlondon.org.uk/blog/david-bradshaw/david-bradshaws-reservoir-logs-april-2024">Original</a>
    <h1>&lt;a href=&#34;/blog/david-bradshaw/david-bradshaws-reservoir-logs-april-2024&#34; hreflang=&#34;en&#34;&gt;David Bradshaw&#39;s Reservoir Logs - April 2024&lt;/a&gt;</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://www.wildlondon.org.uk/metaskills/experts/blob/main/docs/images/logo.png"><img src="https://www.wildlondon.org.uk/metaskills/experts/raw/main/docs/images/logo.png" alt="Experts.js"/></a></p>
<p dir="auto">Experts.js is the easiest way to create and deploy <a href="https://platform.openai.com/docs/assistants/how-it-works" rel="nofollow">OpenAI&#39;s Assistants</a> and link them together as Tools to create a Panel of Experts system with expanded memory and attention to detail.</p>

<p dir="auto">The new Assistants API from OpenAI sets a new industry standard, significantly advancing beyond the widely adopted Chat Completions API. It represents a major leap in the usability of AI agents and the way engineers interact with LLMs. Paired with the cutting-edge <a href="https://openai.com/index/hello-gpt-4o/" rel="nofollow">GPT-4o</a> model, Assistants can now reference attached files &amp; images as knowledge sources within a managed context window called a <a href="#threads">Thread</a>. Unlike <a href="https://openai.com/index/introducing-gpts/" rel="nofollow">Custom GPTs</a>, Assistants support instructions up to 256,000 characters, integrate with 128 tools, and utilize the innovative <a href="https://platform.openai.com/docs/assistants/tools/file-search/vector-stores" rel="nofollow">Vector Store</a> API for efficient file search on up to 10,000 files per assistant.</p>
<p dir="auto">Experts.js aims to simplify the usage of this new API by removing the complexity of managing <a href="https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps" rel="nofollow">Run</a> objects and allowing Assistants to be linked together as Tools.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const thread = Thread.create();
const assistant = await MyAssistant.create();
const output = await assistant.ask(&#34;Say hello.&#34;, thread.id);
console.log(output) // Hello"><pre><span>const</span> <span>thread</span> <span>=</span> <span>Thread</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>assistant</span> <span>=</span> <span>await</span> <span>MyAssistant</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>output</span> <span>=</span> <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>&#34;Say hello.&#34;</span><span>,</span> <span>thread</span><span>.</span><span>id</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>output</span><span>)</span> <span>// Hello</span></pre></div>
<p dir="auto">More importantly, Experts.js introduces Assistants as <a href="#tools">Tools</a>, enabling the creation of <a href="https://twitter.com/AndrewYNg/status/1790769732146307308" rel="nofollow">Multi AI Agent Systems</a>. Each Tool is an LLM-backed Assistant that can take on specialized roles or fulfill complex tasks on behalf of their parent <a href="#assistants">Assistant</a> or Tool. Allowing for complex orchestration workflows or choreographing a series of tightly knit tasks. Shown here is an example of a company assistant with a product catalog tool which itself has a LLM backed tool to create OpenSearch queries.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://www.wildlondon.org.uk/metaskills/experts/blob/main/docs/images/panel-of-experts-company-apparel-after.webp"><img src="https://www.wildlondon.org.uk/metaskills/experts/raw/main/docs/images/panel-of-experts-company-apparel-after.webp" alt="Multi AI Agent Systems with OpenAI Assistants API"/></a></p>

<p dir="auto">Install via npm. Usage is very simple, there are only three objects to import.</p>

<div dir="auto" data-snippet-clipboard-copy-content="import { Assistant, Tool, Thread } from &#34;experts&#34;;"><pre><span>import</span> <span>{</span> <span>Assistant</span><span>,</span> <span>Tool</span><span>,</span> <span>Thread</span> <span>}</span> <span>from</span> <span>&#34;experts&#34;</span><span>;</span></pre></div>
<ul dir="auto">
<li><a href="#assistants">Assistants</a> - The main object that represents an AI agent.</li>
<li><a href="#tools">Tools</a> - An Assistant that can be used by other Assistants.</li>
<li><a href="#threads">Threads</a> - A managed context window for your agents.</li>
</ul>

<p dir="auto">The constructor of our <a href="https://platform.openai.com/docs/assistants/how-it-works/creating-assistants" rel="nofollow">Assistant</a> facade object requires a name, description, and instructions. The third argument is a set of options which directly maps to all the request body options outlined in the <a href="https://platform.openai.com/docs/api-reference/assistants/createAssistant" rel="nofollow">create assistant</a> documentation. All examples in Experts.js are written in ES6 classes for simplicity. The default model is <code>gpt-4o</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyAssistant extends Assistant {
  constructor() {
    const name = &#34;My Assistant&#34;;
    const description = &#34;...&#34;;
    const instructions = &#34;...&#34;
    super(name, description, instructions, {
      model: &#34;gpt-4-turbo&#34;,
      tools: [{ type: &#34;file_search&#34; }],
      temperature: 0.1,
      tool_resources: {
        file_search: {
          vector_store_ids: [process.env.VECTOR_STORE_ID],
        },
      },
    });
  }
}

const assistant = await MyAssistant.create();"><pre><span>class</span> <span>MyAssistant</span> <span>extends</span> <span>Assistant</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>name</span> <span>=</span> <span>&#34;My Assistant&#34;</span><span>;</span>
    <span>const</span> <span>description</span> <span>=</span> <span>&#34;...&#34;</span><span>;</span>
    <span>const</span> <span>instructions</span> <span>=</span> <span>&#34;...&#34;</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>,</span> <span>{</span>
      <span>model</span>: <span>&#34;gpt-4-turbo&#34;</span><span>,</span>
      <span>tools</span>: <span>[</span><span>{</span> <span>type</span>: <span>&#34;file_search&#34;</span> <span>}</span><span>]</span><span>,</span>
      <span>temperature</span>: <span>0.1</span><span>,</span>
      <span>tool_resources</span>: <span>{</span>
        <span>file_search</span>: <span>{</span>
          <span>vector_store_ids</span>: <span>[</span><span>process</span><span>.</span><span>env</span><span>.</span><span>VECTOR_STORE_ID</span><span>]</span><span>,</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>const</span> <span>assistant</span> <span>=</span> <span>await</span> <span>MyAssistant</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The Experts.js async <code>create()</code> function will:</p>
<ul dir="auto">
<li>Find or create your assistant by name.</li>
<li>Updates the assistants configurations to latest. <a href="https://github.com/metaskills/experts/issues/2" data-hovercard-type="issue" data-hovercard-url="/metaskills/experts/issues/2/hovercard">(pending)</a></li>
</ul>

<p dir="auto">The <code>ask()</code> function is a simple interface to ask or instruct your assistant(s). It requires a message and a thread identifier. More on <a href="#threads">Threads</a> below. The message can be a string or native OpenAI message object. This is where Experts.js really shines. You never have to manage <a href="https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps" rel="nofollow">Run</a> objects or their <a href="https://platform.openai.com/docs/assistants/how-it-works/run-steps" rel="nofollow">Run Steps</a> directly.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const output = await assistant.ask(&#34;...&#34;, threadID)
const output = await assistant.ask({ role: &#34;user&#34;, content: &#34;...&#34; }, threadID);"><pre><span>const</span> <span>output</span> <span>=</span> <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>&#34;...&#34;</span><span>,</span> <span>threadID</span><span>)</span>
<span>const</span> <span>output</span> <span>=</span> <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>{</span> <span>role</span>: <span>&#34;user&#34;</span><span>,</span> <span>content</span>: <span>&#34;...&#34;</span> <span>}</span><span>,</span> <span>threadID</span><span>)</span><span>;</span></pre></div>

<p dir="auto">Normal OpenAI <a href="https://platform.openai.com/docs/assistants/tools/function-calling" rel="nofollow">tools and function calling</a> are supported via our constructors options object via <code>tools</code> and <code>tool_resources</code>. Experts.js also supports adding <a href="#assistants">Assistants</a> as Tools. More information on using Assistants as <a href="#tools">Tools</a> can be found in the next section. Use the <code>addAssistantTool</code> function to add an Assistant as a Tool.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MainAssistant extends Assistant {
  constructor() {
    const name = &#34;Company Assistant;
    const description = &#34;...&#34;;
    const instructions = &#34;...&#34;;
    super(name, description, instructions);
    this.addAssistantTool(ProductsTools);
  }
}"><pre><span>class</span> <span>MainAssistant</span> <span>extends</span> <span>Assistant</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>name</span> <span>=</span> <span>&#34;Company Assistant;</span>
<span>    const description = &#34;</span><span>.</span><span>.</span><span>.</span>&#34;<span>;</span>
    <span>const</span> <span>instructions</span> <span>=</span> <span>&#34;...&#34;</span><span>;</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>addAssistantTool</span><span>(</span><span>ProductsTools</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>

<p dir="auto">By default all Experts.js leverages the <a href="https://platform.openai.com/docs/api-reference/assistants-streaming/events" rel="nofollow">Assistants Streaming Events</a>. These allow your applications to receive text, image, and tool outputs via OpenAI&#39;s server-send events. We lever the <a href="https://github.com/openai/openai-node/blob/master/helpers.md">openai-node</a> stream helpers and surface these and more so you can be in control of all events in your agentic applications.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const assistant = await MainAssistant.create();
assistant.on(&#34;textDelta&#34;, (delta, _snapshot) =&gt; {
  process.stdout.write(delta.value)
});"><pre><span>const</span> <span>assistant</span> <span>=</span> <span>await</span> <span>MainAssistant</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>assistant</span><span>.</span><span>on</span><span>(</span><span>&#34;textDelta&#34;</span><span>,</span> <span>(</span><span>delta</span><span>,</span> <span>_snapshot</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>process</span><span>.</span><span>stdout</span><span>.</span><span>write</span><span>(</span><span>delta</span><span>.</span><span>value</span><span>)</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">All openai-node <a href="https://github.com/openai/openai-node/blob/master/helpers.md">streaming events</a> are supported via our Assistant&#39;s <code>on()</code> function. The available event names are: <code>event</code>, <code>textDelta</code>, <code>textDone</code>, <code>imageFileDone</code>, <code>toolCallDelta</code>, <code>runStepDone</code>, <code>toolCallDone</code>, and <code>end</code></p>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Important</p><p dir="auto">OpenAI&#39;s server-send events are not async/await friendly.</p>
</div>
<p dir="auto">If your listeners need to perform work in an async fashion, such as redirecting tool outputs, consider using our extensions to these events. They are called in this order after the Run has been completed. The available async event names are: <code>textDoneAsync</code>, <code>imageFileDoneAsync</code>, <code>runStepDoneAsync</code>, <code>toolCallDoneAsync</code>, and <code>endAsync</code>.</p>

<p dir="auto">If you want to lazily standup additional resources when an assistant&#39;s <code>create()</code> function is called, implement the <code>beforeInit()</code> function in your class. This is an async method that will be called before the assistant is created.</p>
<div dir="auto" data-snippet-clipboard-copy-content="async beforeInit() {
  await this.#createFileSearch();
}"><pre><span>async</span> <span>beforeInit</span><span>(</span><span>)</span> <span>{</span>
  <span>await</span> <span>this</span><span>.</span>#<span>createFileSearch</span><span>(</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">All Assistant events receive an extra Experts&#39;js metadata argument. An object that contains the Run&#39;s <code>stream</code>. This allows you to use the <a href="https://github.com/openai/openai-node/blob/master/helpers.md#assistant-methods">openai-node&#39;s helper functions</a> such as <code>currentEvent</code>, <code>finalMessages</code>, etc.</p>
<div dir="auto" data-snippet-clipboard-copy-content="assistant.on(&#34;endAsync&#34;, async (metadata) =&gt; {
  await metadata.stream.finalMessages();
});"><pre><span>assistant</span><span>.</span><span>on</span><span>(</span><span>&#34;endAsync&#34;</span><span>,</span> <span>async</span> <span>(</span><span>metadata</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>await</span> <span>metadata</span><span>.</span><span>stream</span><span>.</span><span>finalMessages</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>

<p dir="auto">Using an <a href="#assistants">Assistant</a> as a Tool is central focal point of the Experts.js framework. Tools are a subclass of Assistant and encapsulate the interface for their parent objects. In this way Experts.js tools are reusable components in your agentic architecture. Our examples illustrate a basic message passing pattern, for brevity. You should leverage all of OpenAI&#39;s <a href="https://platform.openai.com/docs/assistants/tools/function-calling" rel="nofollow">tool and function calling</a> features to their fullest.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class EchoTool extends Tool {
  constructor() {
    const name = &#34;Echo Tool&#34;;
    const description = &#34;Echo&#34;;
    const instructions = &#34;Echo the same text back to the user&#34;;
    super(name, description, instructions, {
      parentsTools: [
        {
          type: &#34;function&#34;,
          function: {
            name: EchoTool.toolName,
            description: description,
            parameters: {
              type: &#34;object&#34;,
              properties: { message: { type: &#34;string&#34; } },
              required: [&#34;message&#34;],
            },
          },
        },
      ],
    });
  }
}"><pre><span>class</span> <span>EchoTool</span> <span>extends</span> <span>Tool</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>name</span> <span>=</span> <span>&#34;Echo Tool&#34;</span><span>;</span>
    <span>const</span> <span>description</span> <span>=</span> <span>&#34;Echo&#34;</span><span>;</span>
    <span>const</span> <span>instructions</span> <span>=</span> <span>&#34;Echo the same text back to the user&#34;</span><span>;</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>,</span> <span>{</span>
      <span>parentsTools</span>: <span>[</span>
        <span>{</span>
          <span>type</span>: <span>&#34;function&#34;</span><span>,</span>
          <span>function</span>: <span>{</span>
            <span>name</span>: <span>EchoTool</span><span>.</span><span>toolName</span><span>,</span>
            <span>description</span>: <span>description</span><span>,</span>
            <span>parameters</span>: <span>{</span>
              <span>type</span>: <span>&#34;object&#34;</span><span>,</span>
              <span>properties</span>: <span>{</span> <span>message</span>: <span>{</span> <span>type</span>: <span>&#34;string&#34;</span> <span>}</span> <span>}</span><span>,</span>
              <span>required</span>: <span>[</span><span>&#34;message&#34;</span><span>]</span><span>,</span>
            <span>}</span><span>,</span>
          <span>}</span><span>,</span>
        <span>}</span><span>,</span>
      <span>]</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M4.47.22A.749.749 0 0 1 5 0h6c.199 0 .389.079.53.22l4.25 4.25c.141.14.22.331.22.53v6a.749.749 0 0 1-.22.53l-4.25 4.25A.749.749 0 0 1 11 16H5a.749.749 0 0 1-.53-.22L.22 11.53A.749.749 0 0 1 0 11V5c0-.199.079-.389.22-.53Zm.84 1.28L1.5 5.31v5.38l3.81 3.81h5.38l3.81-3.81V5.31L10.69 1.5ZM8 4a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 4Zm0 8a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Caution</p><p dir="auto">It is critical that your tool&#39;s function name use the <code>toolName</code> getter. Experts.js converts this to a snake_case string and uses the name to find the the right tool and call it.</p>
</div>
<p dir="auto">As such, Tool class names are important and help OpenAI&#39;s models decide which tool to call. So pick a good name for your tool class. For example, <code>ProductsOpenSearchTool</code> will be <code>products_open_search</code> and clearly helps the model infer along with the tool&#39;s description what role it performs.</p>
<p dir="auto">Tools are added to your <a href="#assistants">Assistant</a> via the <code>addAssistantTool</code> function. This function will add the tool to the assistant&#39;s tools array and update the assistant&#39;s configuration.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MainAssistant extends Assistant {
  constructor() {
    const name = &#34;Company Assistant;
    const description = &#34;...&#34;;
    const instructions = &#34;...&#34;;
    super(name, description, instructions);
    this.addAssistantTool(EchoTool);
  }
}"><pre><span>class</span> <span>MainAssistant</span> <span>extends</span> <span>Assistant</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>name</span> <span>=</span> <span>&#34;Company Assistant;</span>
<span>    const description = &#34;</span><span>.</span><span>.</span><span>.</span>&#34;<span>;</span>
    <span>const</span> <span>instructions</span> <span>=</span> <span>&#34;...&#34;</span><span>;</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>addAssistantTool</span><span>(</span><span>EchoTool</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto">Your Tool assistant response will automatically be submitted as the output for the parent Assistant or Tool.</p>

<p dir="auto">By default Tools are backed by an LLM <code>model</code> and perform all the same lifecycles events, runs, etc as Assistants. However, you can create a Tool that does not use any of the core Assistant&#39;s features by setting the <code>llm</code> option to <code>false</code>. When doing so, you must implement the <code>ask()</code> function in your Tool. The return value will be submitted as the tool&#39;s output.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class AnswerTwoTool extends Tool {
  constructor() {
    // ...
    super(name, description, instructions, {
      llm: false,
      parentsTools: [...],
    });
  }
  async ask(message) {
    return ...;
  }
}"><pre><span>class</span> <span>AnswerTwoTool</span> <span>extends</span> <span>Tool</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>// ...</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>,</span> <span>{</span>
      <span>llm</span>: <span>false</span><span>,</span>
      <span>parentsTools</span>: <span>[</span>...<span>]</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
  <span>async</span> <span>ask</span><span>(</span><span>message</span><span>)</span> <span>{</span>
    <span>return</span> ...<span>;</span>
  <span>}</span>
<span>}</span></pre></div>

<p dir="auto">In complex workflows, a LLM backed Tool can be used to convert human or other LLM instructions into executable code and the result of that code (not the LLM output) would need to be submitted for your Tool&#39;s parent&#39;s outputs. For example, the <code>ProductsOpenSearchTool</code> could convert messages into OpenSearch queries, execute them, and return the results. Sub classes can implement the <code>answered()</code> function to control the output. In this case, the <code>output</code> would be an OpenSearch query and the tools outputs now contain the results of that LLM-generated query.</p>
<div dir="auto" data-snippet-clipboard-copy-content="async answered(output) {
  const args = JSON.parse(output);
  return await this.opensearchQuery(args);
}"><pre><span>async</span> <span>answered</span><span>(</span><span>output</span><span>)</span><span></span> <span>{</span>
  <span>const</span> <span>args</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>output</span><span>)</span><span>;</span>
  <span>return</span> <span>await</span> <span>this</span><span>.</span><span>opensearchQuery</span><span>(</span><span>args</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Alternatively, LLM backed Tools could opt to redirect their own tool outputs back to their parent Assistant or Tool. Thus ignoring the LLM output. This also allows for all of a Tools tool outputs to be submitted as the parent&#39;s output. More on why this is important in the <a href="#product-catalog">product catalog</a> example below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class ProductsTool extends Tool {
  constructor() {
    // ...
    super(name, description, instructions, {
      temperature: 0.1,
      tools: [{ type: &#34;code_interpreter&#34; }],
      outputs: &#34;tools&#34;,
      parentsTools: [...],
    });
    this.addAssistantTool(ProductsOpenSearchTool);
    this.on(&#34;imageFileDoneAsync&#34;, this.imageFileDoneAsync.bind(this));
  }
}"><pre><span>class</span> <span>ProductsTool</span> <span>extends</span> <span>Tool</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>// ...</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>,</span> <span>{</span>
      <span>temperature</span>: <span>0.1</span><span>,</span>
      <span>tools</span>: <span>[</span><span>{</span> <span>type</span>: <span>&#34;code_interpreter&#34;</span> <span>}</span><span>]</span><span>,</span>
      <span>outputs</span>: <span>&#34;tools&#34;</span><span>,</span>
      <span>parentsTools</span>: <span>[</span>...<span>]</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>addAssistantTool</span><span>(</span><span>ProductsOpenSearchTool</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>on</span><span>(</span><span>&#34;imageFileDoneAsync&#34;</span><span>,</span> <span>this</span><span>.</span><span>imageFileDoneAsync</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>

<p dir="auto">OpenAI&#39;s Assistants API introduces a new resource called <a href="https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages" rel="nofollow">Threads</a> which messages &amp; files are stored within. Essentially, threads are a managed context window (memory) for your agents. Creating a new thread with Experts.js is as easy as:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const thread = Thread.create();
console.log(thread.id) // thread_abc123"><pre><span>const</span> <span>thread</span> <span>=</span> <span>Thread</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>thread</span><span>.</span><span>id</span><span>)</span> <span>// thread_abc123</span></pre></div>
<p dir="auto">You can also create a thread with messages, files, or tool resources to start a conversation. We support OpenAI&#39;s thread create request body outlined in their <a href="https://platform.openai.com/docs/api-reference/threads" rel="nofollow">Threads API</a> reference.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const thread = await Thread.create({
  messages: [
    { role: &#34;user&#34;, content: &#34;My name is Ken&#34; },
    { role: &#34;user&#34;, content: &#34;Oh, my last name is Collins&#34; },
  ],
});
const output = await assistant.ask(&#34;What is my full name?&#34;, thread.id);
console.log(output) // Ken Collins"><pre><span>const</span> <span>thread</span> <span>=</span> <span>await</span> <span>Thread</span><span>.</span><span>create</span><span>(</span><span>{</span>
  <span>messages</span>: <span>[</span>
    <span>{</span> <span>role</span>: <span>&#34;user&#34;</span><span>,</span> <span>content</span>: <span>&#34;My name is Ken&#34;</span> <span>}</span><span>,</span>
    <span>{</span> <span>role</span>: <span>&#34;user&#34;</span><span>,</span> <span>content</span>: <span>&#34;Oh, my last name is Collins&#34;</span> <span>}</span><span>,</span>
  <span>]</span><span>,</span>
<span>}</span><span>)</span><span>;</span>
<span>const</span> <span>output</span> <span>=</span> <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>&#34;What is my full name?&#34;</span><span>,</span> <span>thread</span><span>.</span><span>id</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>output</span><span>)</span> <span>// Ken Collins</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Thread Management &amp; Locks</h3><a id="user-content-thread-management--locks" aria-label="Permalink: Thread Management &amp; Locks" href="#thread-management--locks"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">By default, each <a href="#tools">Tool</a> in Experts.js has its own thread &amp; context. This avoids a potential <a href="https://platform.openai.com/docs/assistants/how-it-works/thread-locks" rel="nofollow">thread locking</a> issue which happens if a <a href="#tools">Tool</a> were to share an <a href="#assistants">Assistant&#39;s</a> thread still waiting for tool outputs to be submitted. The following diagram illustrates how Experts.js manages threads on your behalf to avoid this problem:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://www.wildlondon.org.uk/metaskills/experts/blob/main/docs/images/panel-of-experts-thread-management.webp"><img src="https://www.wildlondon.org.uk/metaskills/experts/raw/main/docs/images/panel-of-experts-thread-management.webp" alt="Panel of Experts Thread Management"/></a></p>
<p dir="auto">All questions to your experts require a thread ID. For chat applications, the ID would be stored on the client. Such as a URL path parameter. With Expert.js, no other client-side IDs are needed. As each <a href="#assistants">Assistant</a> calls an LLM backed <a href="#tools">Tool</a>, it will find or create a thread for that tool as needed. Experts.js stores this parent -&gt; child thread relationship for you using OpenAI&#39;s <a href="https://platform.openai.com/docs/api-reference/threads/modifyThread" rel="nofollow">thread metadata</a>.</p>

<p dir="auto">To see code examples of these and more in action, please take a look at our <a href="https://github.com/metaskills/experts/tree/main/test/uat">test suite</a>.</p>

<p dir="auto">In the <a href="#overview">Overview</a> section we showed a three-tiered agent system that can answer the following types of questions. The examples uses most, if not all, the features of the Experts.js framework.</p>
<ul dir="auto">
<li>What is the total amount of products available?</li>
<li>Show me a bar chart image with totals of all top level categories.</li>
<li>Find men&#39;s accessories for a sophisticated comic book enthusiast.</li>
</ul>

<p dir="auto">Basic example using the <code>textDelta</code> event to stream responses from an Express route.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import express from &#34;express&#34;;
import { MainAssistant } from &#34;../experts/main.js&#34;;

const assistant = await MainAssistant.create();

messagesRouter.post(&#34;&#34;, async (req, res, next) =&gt; {
  res.setHeader(&#34;Content-Type&#34;, &#34;text/plain&#34;);
  res.setHeader(&#34;Transfer-Encoding&#34;, &#34;chunked&#34;);
  assistant.on(&#34;textDelta&#34;, (delta, _snapshot) =&gt; {
    res.write(delta.value);
  });
  await assistant.ask(req.body.message.content, req.body.threadID);
  res.end();
});"><pre><span>import</span> <span>express</span> <span>from</span> <span>&#34;express&#34;</span><span>;</span>
<span>import</span> <span>{</span> <span>MainAssistant</span> <span>}</span> <span>from</span> <span>&#34;../experts/main.js&#34;</span><span>;</span>

<span>const</span> <span>assistant</span> <span>=</span> <span>await</span> <span>MainAssistant</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>

<span>messagesRouter</span><span>.</span><span>post</span><span>(</span><span>&#34;&#34;</span><span>,</span> <span>async</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>res</span><span>.</span><span>setHeader</span><span>(</span><span>&#34;Content-Type&#34;</span><span>,</span> <span>&#34;text/plain&#34;</span><span>)</span><span>;</span>
  <span>res</span><span>.</span><span>setHeader</span><span>(</span><span>&#34;Transfer-Encoding&#34;</span><span>,</span> <span>&#34;chunked&#34;</span><span>)</span><span>;</span>
  <span>assistant</span><span>.</span><span>on</span><span>(</span><span>&#34;textDelta&#34;</span><span>,</span> <span>(</span><span>delta</span><span>,</span> <span>_snapshot</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>res</span><span>.</span><span>write</span><span>(</span><span>delta</span><span>.</span><span>value</span><span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>
  <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>req</span><span>.</span><span>body</span><span>.</span><span>message</span><span>.</span><span>content</span><span>,</span> <span>req</span><span>.</span><span>body</span><span>.</span><span>threadID</span><span>)</span><span>;</span>
  <span>res</span><span>.</span><span>end</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>

<p dir="auto">The Assistant&#39;s API supports messages with images using either the <code>image_url</code> or <code>image_file</code> content types. Since our <code>ask()</code> function supports strings or native OpenAI message objects.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const output = await assistant.ask(
  { 
    role: &#34;user&#34;, 
    content: [
      { type: &#34;text&#34;, text: &#34;Tell me about this image.&#34; },
      { type: &#34;image_file&#34;, image_file: { file_id: file.id detail: &#34;high&#34; } },
    ],
  },
  threadID
);"><pre><span>const</span> <span>output</span> <span>=</span> <span>await</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span>
  <span>{</span> 
    <span>role</span>: <span>&#34;user&#34;</span><span>,</span> 
    <span>content</span>: <span>[</span>
      <span>{</span> <span>type</span>: <span>&#34;text&#34;</span><span>,</span> <span>text</span>: <span>&#34;Tell me about this image.&#34;</span> <span>}</span><span>,</span>
      <span>{</span> <span>type</span>: <span>&#34;image_file&#34;</span><span>,</span> <span>image_file</span>: <span>{</span> <span>file_id</span>: <span>file</span><span>.</span><span>id</span> <span>detail</span>: <span>&#34;high&#34;</span> <span>}</span> <span>}</span><span>,</span>
    <span>]</span><span>,</span>
  <span>}</span><span>,</span>
  <span>threadID</span>
<span>)</span><span>;</span></pre></div>

<p dir="auto">Using a <a href="https://platform.openai.com/docs/assistants/tools/file-search/vector-stores" rel="nofollow">Vector Store</a> for file search is easy using OpenAI&#39;s interface via our third configuration option. You could alternatively create your vector store on-demand using our <code>beforeInit()</code> function described in <a href="#advanced-features">Advanced Features</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
class VectorSearchAssistant extends Assistant {
  constructor() {
    const name = &#34;Vector Search Assistant&#34;;
    const description = &#34;...&#34;;
    const instructions = &#34;...&#34;
    super(name, description, instructions, {
      tools: [{ type: &#34;file_search&#34; }],
      temperature: 0.1,
      tool_resources: {
        file_search: {
          vector_store_ids: [process.env.VECTOR_STORE_ID],
        },
      },
    });
  }
}"><pre><span>class</span> <span>VectorSearchAssistant</span> <span>extends</span> <span>Assistant</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>name</span> <span>=</span> <span>&#34;Vector Search Assistant&#34;</span><span>;</span>
    <span>const</span> <span>description</span> <span>=</span> <span>&#34;...&#34;</span><span>;</span>
    <span>const</span> <span>instructions</span> <span>=</span> <span>&#34;...&#34;</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>,</span> <span>{</span>
      <span>tools</span>: <span>[</span><span>{</span> <span>type</span>: <span>&#34;file_search&#34;</span> <span>}</span><span>]</span><span>,</span>
      <span>temperature</span>: <span>0.1</span><span>,</span>
      <span>tool_resources</span>: <span>{</span>
        <span>file_search</span>: <span>{</span>
          <span>vector_store_ids</span>: <span>[</span><span>process</span><span>.</span><span>env</span><span>.</span><span>VECTOR_STORE_ID</span><span>]</span><span>,</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>

<p dir="auto">Using the <a href="#streaming--events">Streaming &amp; Events</a> feature to report token usage allows you to have per-assistant metrics.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyAssistant extends Assistant {
  constructor() {
    // ...
    super(name, description, instructions);
    this.on(&#34;runStepDone&#34;, this.#reportUsage.bind(this));
  }

  #reportUsage(runStep) {
    if (!runStep?.usage?.total_tokens) return;
    const iT = runStep.usage.prompt_tokens;
    const oT = runStep.usage.completion_tokens;
    const tT = runStep.usage.total_tokens;
    console.log({ InTokens: iT, OutTokens: oT, TotalTokens: tT });
  }
}"><pre><span>class</span> <span>MyAssistant</span> <span>extends</span> <span>Assistant</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>// ...</span>
    <span>super</span><span>(</span><span>name</span><span>,</span> <span>description</span><span>,</span> <span>instructions</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>on</span><span>(</span><span>&#34;runStepDone&#34;</span><span>,</span> <span>this</span><span>.</span>#<span>reportUsage</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  #<span>reportUsage</span><span>(</span><span>runStep</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>runStep</span><span>?.</span><span>usage</span><span>?.</span><span>total_tokens</span><span>)</span> <span>return</span><span>;</span>
    <span>const</span> <span>iT</span> <span>=</span> <span>runStep</span><span>.</span><span>usage</span><span>.</span><span>prompt_tokens</span><span>;</span>
    <span>const</span> <span>oT</span> <span>=</span> <span>runStep</span><span>.</span><span>usage</span><span>.</span><span>completion_tokens</span><span>;</span>
    <span>const</span> <span>tT</span> <span>=</span> <span>runStep</span><span>.</span><span>usage</span><span>.</span><span>total_tokens</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>{</span> <span>InTokens</span>: <span>iT</span><span>,</span> <span>OutTokens</span>: <span>oT</span><span>,</span> <span>TotalTokens</span>: <span>tT</span> <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>

<p dir="auto">This project leverages <a href="https://containers.dev/" rel="nofollow">Dev Containers</a> meaning you can open it in any supporting IDE to get started right away. This includes using <a href="https://www.youtube.com/watch?v=b1RavPr_878" rel="nofollow">VS Code with Dev Containers</a> which is the recommended approach.</p>
<p dir="auto">Once opened in your development container, create a <code>.env.development.local</code> file with your OpenAI API key and <a href="https://postimages.org" rel="nofollow">postimage.org</a> API key:</p>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY=sk-...
POST_IMAGES_API_KEY=..."><pre><code>OPENAI_API_KEY=sk-...
POST_IMAGES_API_KEY=...
</code></pre></div>
<p dir="auto">Now you can run the following commands:</p>


<div dir="auto" data-snippet-clipboard-copy-content="const thread = Thread.create();
const assistant = await MyAssistant.create();
const output = assistant.ask(&#34;Hi, how are you?&#34;, thread.id);"><pre><span>const</span> <span>thread</span> <span>=</span> <span>Thread</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>assistant</span> <span>=</span> <span>await</span> <span>MyAssistant</span><span>.</span><span>create</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>output</span> <span>=</span> <span>assistant</span><span>.</span><span>ask</span><span>(</span><span>&#34;Hi, how are you?&#34;</span><span>,</span> <span>thread</span><span>.</span><span>id</span><span>)</span><span>;</span></pre></div>
</article></div></div>
  </body>
</html>
