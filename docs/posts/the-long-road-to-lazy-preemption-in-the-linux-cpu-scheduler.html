<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/">Original</a>
    <h1>The long road to lazy preemption in the Linux CPU scheduler</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>
The kernel&#39;s CPU scheduler currently offers several preemption modes that
implement a range of tradeoffs between system throughput and response time.
Back in September 2023, a <a href="https://lwn.net/Articles/944686/">discussion
on scheduling</a> led to the concept of &#34;lazy preemption&#34;, which could
simplify scheduling in the kernel while providing better results.  Things
went quiet for a while, but lazy preemption has returned in the form of <a href="https://lwn.net/ml/all/20241007074609.447006177@infradead.org">this patch series</a>
from Peter Zijlstra.  While the concept appears to work well, there is
still a fair amount of work to be done.
</p><h4>Some review</h4>
<p>
Current kernels have four different modes that regulate when one task can
be preempted in favor of another.  <tt>PREEMPT_NONE</tt>, the simplest
mode, only allows preemption to happen when the running task has exhausted
its time slice.  <tt>PREEMPT_VOLUNTARY</tt> adds a large number of points
within the kernel where preemption can happen if needed.
<tt>PREEMPT_FULL</tt> allows preemption at almost any point except places
in the kernel that prevent it, such as when a spinlock is held.  Finally,
<tt>PREEMPT_RT</tt> prioritizes preemption over most other things, even
making most spinlock-holding code preemptible.
</p><p>
A higher level of preemption enables the system to respond more quickly to
events; whether an event is the movement of a mouse or an &#34;imminent
meltdown&#34; signal from a nuclear reactor, faster response tends to be more
gratifying.  But a higher level of preemption can hurt the overall
throughput of the system; workloads with a lot of long-running,
CPU-intensive tasks tend to benefit from being disturbed as little as
possible.  More frequent preemption can also lead to higher lock
contention.  That is why the different modes exist; the optimal preemption
mode will vary for different workloads.
</p><blockquote>
<b>Nobody covers the Linux kernel like LWN</b>; be in the know with
<a href="https://lwn.net/Promo/Kernel-2/claim">a one-month trial subscription</a>, no credit card needed.
</blockquote>
<p>
Most distributions ship kernels built with the <tt>PREEMPT_DYNAMIC</tt>
pseudo-mode, which allows any of the first three modes to be selected at
boot time, with <tt>PREEMPT_VOLUNTARY</tt> being the default.  On systems
with debugfs mounted, the current mode can be read from
<tt>/sys/kernel/debug/sched/preempt</tt>.
</p><p>
<tt>PREEMPT_NONE</tt> and <tt>PREEMPT_VOLUNTARY</tt> do not allow the
arbitrary preemption of code running in the kernel; there are times when
that can lead to excessive latency even in systems where minimal latency is
not prioritized.  This problem is the result of places in the kernel where
a large amount of work can be done; if that work is allowed to run
unchecked, it can disrupt the scheduling of the system as a whole.  To get
around this problem, long-running loops have been sprinkled with calls to
<tt>cond_resched()</tt>, each of which is an additional voluntary
preemption point that is active even in the <tt>PREEMPT_NONE</tt> mode.
There are hundreds of these calls in the kernel.
</p><p>
There are some problems with this approach.  <tt>cond_resched()</tt> is a
form of heuristic that only works in the places where a developer has
thought to put it.  Some calls are surely unnecessary, while there will be
other places in the kernel that could benefit from <tt>cond_resched()</tt>
calls, but do not have them.  The use of <tt>cond_resched()</tt>, at its
core, takes a decision that should be confined to the scheduling code and
spreads it throughout the kernel.  It is, in short, a bit of a hack that
mostly works, but which could be done better.
</p><h4>Doing better</h4>
<p>
The tracking of whether a given task can be preempted at any moment is a
complicated affair that must take into account several variables; see <a href="https://lwn.net/Articles/945422/">this article</a> and <a href="https://lwn.net/Articles/831678/">this article</a> for details.  One of those
variables is a simple flag, <tt>TIF_NEED_RESCHED</tt>, that indicates the
presence of a higher-priority task that is waiting for access to the CPU.
Events such as waking a high-priority task can cause that flag to be set in
whatever task is currently running.  In the absence of this flag, there is
no need for the kernel to consider preempting the current task.
</p><p>
There are various points where the kernel can notice that flag and cause
the currently running task to be preempted.  The scheduler&#39;s timer tick is
one example; any time a task returns to user space from a system call is
another.  The completion of an interrupt handler is yet another, but that
check, which can cause preemption to happen any time that interrupts are
enabled, is only enabled in <tt>PREEMPT_FULL</tt> kernels.  A call to
<tt>cond_resched()</tt> will also check that flag and, if it is set, call
into the scheduler to yield the CPU to the other task.
</p><p>
The lazy-preemption patches are simple at their core; they add another
flag, <tt>TIF_NEED_RESCHED_LAZY</tt>, that indicates a need for
rescheduling at some point, but not necessarily right away.  In the lazy
preemption mode (<tt>PREEMPT_LAZY</tt>), most events will set the new flag
rather than <tt>TIF_NEED_RESCHED</tt>.  At points like the return to user
space from the kernel, either flag will lead to a call into the scheduler.
At the voluntary preemption points and in the return-from interrupt path,
though, only <tt>TIF_NEED_RESCHED</tt> is checked.
</p><p>
The result of this change is that, in lazy-preemption mode, most events in
the kernel will not cause the current task to be preempted.  That task
<i>should</i> be preempted eventually, though.  To make that happen, the
kernel&#39;s timer-tick handler will check whether
<tt>TIF_NEED_RESCHED_LAZY</tt> is set; if so, <tt>TIF_NEED_RESCHED</tt>
will also be set, possibly causing the running task to be preempted.  Tasks
will generally end up running for something close to their full time slice
unless they give up the CPU voluntarily, which should lead to good
throughput. 
</p><p>
With these changes, the lazy-preemption mode can, like
<tt>PREEMPT_FULL</tt>, run with kernel preemption enabled at (almost) all
times.  Preemption <i>can</i> happen any time that the preemption counter
says that it should.  That allows long-running kernel code to be preempted
whenever other conditions do not prevent it.  It also allows preemption to
happen quickly in those cases where it is truly needed.  For example, 
should a realtime task become runnable, as the result of
handling an interrupt, for example, the <tt>TIF_NEED_RESCHED</tt> flag will
be set, leading to an almost immediate preemption.  There will be no need
to wait for the timer tick in such cases.
</p><p>
Preemption will <i>not</i> happen, though, if only
<tt>TIF_NEED_RESCHED_LAZY</tt> is set, which will be the case much of the
time. So a <tt>PREEMPT_LAZY</tt> kernel will be far less likely to preempt
a running task than a <tt>PREEMPT_FULL</tt> kernel.
</p><h4>Removing <tt>cond_resched()</tt> â€” eventually</h4>
<p>
The end goal of this work is to have a scheduler with only two non-realtime
modes: <tt>PREEMPT_LAZY</tt> and <tt>PREEMPT_FULL</tt>.  The lazy mode will
occupy a place between <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt>, replacing both of them.  It will, however, not
need the voluntary preemption points that were added for the two modes it
replaces.  Since preemption can now happen almost anywhere, there is no
longer a need to enable it in specific spots.
</p><p>
For now, though, the <tt>cond_resched()</tt> calls remain; if nothing else,
they are required for as long as the <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt> modes exist.  Those calls also help to ensure
that problems are not introduced while lazy preemption is being stabilized.
</p><p>
In the current patch set, <tt>cond_resched()</tt> only checks
<tt>TIF_NEED_RESCHED</tt>, meaning that preemption will be deferred in many
situations where it will happen immediately from <tt>cond_resched()</tt> in
<tt>PREEMPT_VOLUNTARY</tt> or <tt>PREEMPT_NONE</tt> mode.
Steve Rostedt <a href="https://lwn.net/ml/all/20241009100133.2569e2a7@gandalf.local.home">questioned</a>
this change, asking whether <tt>cond_resched()</tt> should retain its older
meaning, at least for the <tt>PREEMPT_VOLUNTARY</tt> case.  Even though
<tt>PREEMPT_VOLUNTARY</tt> is slated for eventual removal, he thought,
keeping the older behavior could help to ease the transition.
</p><p>
Thomas Gleixner
<a href="https://lwn.net/ml/all/87h69lqbk0.ffs@tglx">answered</a> that only checking
<tt>TIF_NEED_RESCHED</tt> is the correct choice, since it will help in the
process of removing the <tt>cond_resched()</tt> calls entirely:
</p><blockquote>
	That forces us to look at all of them and figure out whether they
	need to be extended to include the lazy bit or not. Those which do
	not need it can be eliminated when LAZY is in effect because that
	will preempt on the next possible preemption point once the
	non-lazy bit is set in the tick.
</blockquote>
<p>
He added that he expects &#34;<q>less than 5%</q>&#34; of the
<tt>cond_resched()</tt> calls need to check <tt>TIF_NEED_RESCHED_LAZY</tt>
and, thus, will need to remain even after the transition to
<tt>PREEMPT_LAZY</tt> is complete.
</p><p>
Before then, though, there are hundreds of <tt>cond_resched()</tt> calls
that need to be checked and, for most of them at least, removed.  Many
other details have to be dealt with as well; <a href="https://lwn.net/ml/all/20241009165411.3426937-1-ankur.a.arora@oracle.com">this patch
set</a> from Ankur Arora addresses a few of them.  There is
also, of course, the need for extensive performance testing; Mike Galbraith
has made <a href="https://lwn.net/ml/all/579b7ea34ef6e2f7c955abdfc0929fe1af36faef.camel@gmx.de">an
early start</a> on that work, showing that throughput with lazy preemption
falls just short of that with <tt>PREEMPT_VOLUNTARY</tt>.
</p><p>
It all adds up to a lot to be done still, but the end result
of the lazy-preemption work should be a kernel that is a bit smaller and
simpler while delivering predictable latencies without the need to
sprinkle scheduler-related calls throughout the code.  That seems like a
better solution, but getting there is going to take some time.<br clear="all"/></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Preemption">Preemption</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            </tbody></table></div></div>
  </body>
</html>
