<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/hatchet-dev/hatchet">Original</a>
    <h1>Show HN: Hatchet ‚Äì Open-source distributed task queue</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto">Hatchet replaces difficult to manage legacy queues or pub/sub systems so you can design durable workloads that recover from failure and solve for problems like <strong>concurrency</strong>, <strong>fairness</strong>, and <strong>rate limiting</strong>. Instead of managing your own task queue or pub/sub system, you can use Hatchet to distribute your functions between a set of workers with minimal configuration or infrastructure:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25448214/307867265-c3defa1e-d9d9-4419-94e5-b4ea4a748f8d.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDk5MjUzNTksIm5iZiI6MTcwOTkyNTA1OSwicGF0aCI6Ii8yNTQ0ODIxNC8zMDc4NjcyNjUtYzNkZWZhMWUtZDlkOS00NDE5LTk0ZTUtYjRlYTRhNzQ4ZjhkLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMDglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzA4VDE5MTA1OVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEwNjg4YmY5MTZlNTEyMzBlYTQwNjlhMGRiMGZkMTQxZmVjYTUwNDAyNjRkYzgxZTE3M2Y2YjE3MzM2YzM1NWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.rC8qXoaj_KiekVhl5WzSZ-ghMwIykjhGPct74ly2W8M"><img width="500" height="500" src="https://private-user-images.githubusercontent.com/25448214/307867265-c3defa1e-d9d9-4419-94e5-b4ea4a748f8d.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDk5MjUzNTksIm5iZiI6MTcwOTkyNTA1OSwicGF0aCI6Ii8yNTQ0ODIxNC8zMDc4NjcyNjUtYzNkZWZhMWUtZDlkOS00NDE5LTk0ZTUtYjRlYTRhNzQ4ZjhkLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMDglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzA4VDE5MTA1OVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEwNjg4YmY5MTZlNTEyMzBlYTQwNjlhMGRiMGZkMTQxZmVjYTUwNDAyNjRkYzgxZTE3M2Y2YjE3MzM2YzM1NWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.rC8qXoaj_KiekVhl5WzSZ-ghMwIykjhGPct74ly2W8M" data-animated-image=""/></a>
</p>
<p dir="auto"><strong>What Makes Hatchet Great?</strong></p>
<ul dir="auto">
<li>
<p dir="auto">‚ö°Ô∏è <strong>Ultra-low Latency and High Throughput Scheduling:</strong> Hatchet is built on a low-latency queue (<code>25ms</code> average start), perfectly balancing real-time interaction capabilities with the reliability required for mission-critical tasks.</p>
</li>
<li>
<p dir="auto">‚òÆÔ∏è <strong>Concurrency, Fairness, and Rate Limiting:</strong> Implement FIFO, LIFO, Round Robin, and Priority Queues with Hatchet‚Äôs built-in strategies, designed to circumvent common scaling pitfalls with minimal configuration. <a href="https://docs.hatchet.run" rel="nofollow">Read Docs ‚Üí</a></p>
</li>
<li>
<p dir="auto">üî•üßØ <strong>Resilience by Design:</strong> With customizable retry policies and integrated error handling, Hatchet ensures your operations recover swiftly from transient failures. You can break large jobs down into small tasks so you can finish a run without rerunning work. <a href="https://docs.hatchet.run" rel="nofollow">Read Docs ‚Üí</a></p>
</li>
</ul>
<p dir="auto"><strong>Enhanced Visibility and Control:</strong></p>
<ul dir="auto">
<li><strong>Observability.</strong> All of your runs are fully searchable, allowing you to quickly identify issues. We track latency, error rates, or custom metrics in your run.</li>
<li><strong>(Practical) Durable Execution.</strong> Replay events and manually pick up execution from specific steps in your workflow.</li>
<li><strong>Cron.</strong> Set recurring schedules for functions runs to execute.</li>
<li><strong>One-Time Scheduling.</strong> Schedule a function run to execute at a specific time and date in the future.</li>
<li><strong>Spike Protection.</strong> Smooth out spikes in traffic and only execute what your system can handle.</li>
<li><strong>Incremental Streaming.</strong> Subscribe to updates as your functions progress in the background worker.</li>
</ul>
<p dir="auto"><strong>Example Use Cases:</strong></p>
<ul dir="auto">
<li><strong>Fairness for Generative AI:</strong> Don&#39;t let busy users overwhelm your system. Hatchet lets you distribute requests to your workers fairly with configurable policies.</li>
<li><strong>Batch Processing for Document Indexing:</strong> Hatchet can handle large-scale batch processing of documents, images, and other data and resume mid-job on failure.</li>
<li><strong>Workflow Orchestration for Multi-Modal Systems:</strong> Hatchet can handle orchestrating multi-modal inputs and outputs, with full DAG-style execution.</li>
<li><strong>Correctness for Event-Based Processing:</strong> Respond to external events or internal events within your system and replay events automatically.</li>
</ul>

<p dir="auto">Hatchet supports your technology stack with open-source SDKs for Python, Typescript, and Go. To get started, see the Hatchet documentation <a href="https://docs.hatchet.run/home/quickstart" rel="nofollow">here</a>, or check out our quickstart repos:</p>
<ul dir="auto">
<li><a href="https://github.com/hatchet-dev/hatchet-go-quickstart">Go SDK Quickstart</a></li>
<li><a href="https://github.com/hatchet-dev/hatchet-python-quickstart">Python SDK Quickstart</a></li>
<li><a href="https://github.com/hatchet-dev/hatchet-typescript-quickstart">Typescript SDK Quickstart</a></li>
</ul>

<p dir="auto">Hatchet comes with a native Go SDK. The following SDKs are also available:</p>
<ul dir="auto">
<li><a href="https://github.com/hatchet-dev/hatchet-typescript">Typescript SDK</a></li>
</ul>
<p dir="auto">If you encounter any issues with the SDKs, please submit an issue in the respective repository.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Is there a managed cloud version of Hatchet?</h4><a id="user-content-is-there-a-managed-cloud-version-of-hatchet" aria-label="Permalink: Is there a managed cloud version of Hatchet?" href="#is-there-a-managed-cloud-version-of-hatchet"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Yes, we are offering a have a cloud version to select companies while in beta who are helping to build and shape the product. Please <a href="mailto:contact@hatchet.run">reach out</a> or <a href="https://hatchet.run/request-access" rel="nofollow">request access</a> for more information.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Is there a self-hosted version of Hatchet?</h4><a id="user-content-is-there-a-self-hosted-version-of-hatchet" aria-label="Permalink: Is there a self-hosted version of Hatchet?" href="#is-there-a-self-hosted-version-of-hatchet"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Yes, instructions for self-hosting our open source docker containers can be found in our <a href="https://docs.hatchet.run/self-hosting/docker-compose" rel="nofollow">documentation</a>. Please <a href="mailto:contact@hatchet.run">reach out</a> if you&#39;re interested in support.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">How does this compare to alternatives (Celery, BullMQ)?</h2><a id="user-content-how-does-this-compare-to-alternatives-celery-bullmq" aria-label="Permalink: How does this compare to alternatives (Celery, BullMQ)?" href="#how-does-this-compare-to-alternatives-celery-bullmq"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Why build another managed queue? We wanted to build something with the benefits of full transactional enqueueing - particularly for dependent, DAG-style execution - and felt strongly that Postgres solves for 99.9% of queueing use-cases better than most alternatives (Celery uses Redis or RabbitMQ as a broker, BullMQ uses Redis). Since the introduction of <code>SKIP LOCKED</code> and the milestones of recent PG releases (like active-active replication), it&#39;s becoming more feasible to horizontally scale Postgres across multiple regions and vertically scale to 10k TPS or more. Many queues (like BullMQ) are built on Redis and data loss can occur when suffering OOM if you&#39;re not careful, and using PG helps avoid an entire class of problems.</p>
<p dir="auto">We also wanted something that was significantly easier to use and debug for application developers. A lot of times the burden of building task observability falls on the infra/platform team (for example, asking the infra team to build a Grafana view for their tasks based on exported prom metrics). We&#39;re building this type of observability directly into Hatchet.</p>

<p dir="auto">Please submit any bugs that you encounter via Github issues. However, please reach out on <a href="https://discord.gg/ZMeUafwH89" rel="nofollow">Discord</a> before submitting a feature request - as the project is very early, we&#39;d like to build a solid foundation before adding more complex features.</p>

<p dir="auto">See the contributing docs <a href="https://docs.hatchet.run/contributing" rel="nofollow">here</a>, and please let us know what you&#39;re interesting in working on in the #contributing channel on <a href="https://discord.gg/ZMeUafwH89" rel="nofollow">Discord</a>. This will help us shape the direction of the project and will make collaboration much easier!</p>
</article></div></div>
  </body>
</html>
