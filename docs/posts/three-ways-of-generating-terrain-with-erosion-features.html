<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/dandrino/terrain-erosion-3-ways">Original</a>
    <h1>Three Ways of Generating Terrain with Erosion Features</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<h2 dir="auto"><a id="user-content-background" aria-hidden="true" href="#background"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Background</h2>
<p dir="auto">Terrain generation has long been a popular topic in the procedural generation community, with applications in video games and movies. Some games use procedural terrain to generate novel environments on the fly for the player to explore. Others use procedural terrain as a tool for artists to use when crafting a believable world.</p>
<p dir="auto">The most common way of representing array is a 2D grid of height values. This type of terrain doesn&#39;t allow for overhangs and caves, but at large scales those features are not very apparent. The most popular terrain generation algorithms focus on adding together different layers of <a href="http://libnoise.sourceforge.net/coherentnoise/index.html" rel="nofollow">coherent noise</a>, which can be thought of as smoothed random noise. Several popular choices for coherent noise are:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Perlin_noise" rel="nofollow"><strong>Perlin noise</strong></a> - A form of <a href="https://en.wikipedia.org/wiki/Gradient_noise" rel="nofollow">gradient noise</a> on a rectangular lattice.</li>
<li><a href="https://en.wikipedia.org/wiki/Simplex_noise" rel="nofollow"><strong>Simplex noise</strong></a> - Like Perlin noise, but on a simplex lattice.</li>
<li><a href="https://en.wikipedia.org/wiki/Value_noise" rel="nofollow"><strong>Value noise</strong></a> - Basically just white noise that&#39;s been upscaled and interpolated.</li>
</ul>
<p dir="auto">If you take several layers of coherent noise, each at different levels of detail and with different amplitudes, you get a rough pattern frequently (and mostly inaccurately) called <a href="https://en.wikipedia.org/wiki/Brownian_surface" rel="nofollow"><strong>fBm</strong></a> (fractional Brownian motion). <a href="https://www.redblobgames.com/maps/terrain-from-noise/" rel="nofollow">This page</a> provides a good overview for how this process works.</p>
<p dir="auto">In addition, there are other methods of generating fBm more directly, including:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Diamond-square_algorithm" rel="nofollow"><strong>Diamond-square</strong></a> - A fast, but artifact-prone divide-and-conquer approach.</li>
<li><strong>Power-law noise</strong> - Created by filtering white noise in the frequency domain with a power-law function.</li>
</ul>
<p dir="auto">What you get from regular fBm terrain is something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/fbm_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/fbm_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/fbm_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/fbm_hillshaded.png" width="40%"/></a>
  </p>
<p dir="auto">This gives reasonable looking terrain at a quick glance. It generates distinguishable mountains and valleys, and has a general roughness one expects from rocky terrain.</p>
<p dir="auto">However, it is also fairly boring. The fractal nature of fBm means everything more or less looks the same. Once you&#39;ve seen one patch of land, you&#39;ve basically seen it all.</p>
<p dir="auto">One method of adding a more organic look to terrain is to perform <a href="http://www.iquilezles.org/www/articles/warp/warp.htm" rel="nofollow">domain warping</a>, which is where you take regular fBm noise but offset each point by another fBm noise map. What you get is terrain that looks warped and twisted, somewhat resembling terrain that has been deformed by tectonic movement. The game No Man&#39;s Sky uses domain warping for its custom noise function called <a href="https://youtu.be/SePDzis8HqY?t=1547" rel="nofollow">uber noise</a>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/domain_warping_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/domain_warping_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/domain_warping_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/domain_warping_hillshaded.png" width="40%"/></a>
  </p>
<p dir="auto">Another way of spicing up fBm is to modify each coherent noise layer before adding them together. For instance, if you take the absolute value of each coherent noise layer, and invert the final result you can get a mountain ridge effect:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/ridge_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/ridge_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/ridge_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/ridge_hillshaded.png" width="40%"/></a>
  </p>
<p dir="auto">These all look iteratively more convincing. However, if you look at actual elevation maps, you will notice that these look nothing like real life terrain:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/real1_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/real1_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/real1_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/real1_hillshaded.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/real2_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/real2_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/real2_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/real2_hillshaded.png" width="40%"/></a>
</p>

<p dir="auto">The fractal shapes you see in real life terrain are driven by <strong>erosion</strong>: the set of processes that describe terrain displacement over time. There are several types of erosion, but the one that most significantly causes those fractal shapes you see is <strong>hydraulic erosion</strong>, which is basically the process of terrain displacement via water. As water flows across terrain, it takes sediment with it and deposits it downhill. This has the effect of carving out mountains and creating smooth valleys. The fractal pattern emerges from smaller streams merging into larger streams and rivers as they flow downhill.</p>
<p dir="auto">Unfortunately, more involved techniques are required to generate terrain with convincing erosion patterns. The following three sections will go over three distinct methods of generating eroded terrain. Each method has their pros and cons, so take that into consideration if you want to include them in your terrain project.</p>
<h2 dir="auto"><a id="user-content-simulation" aria-hidden="true" href="#simulation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simulation</h2>
<p dir="auto">If real life erosion is driven by physical processes, couldn&#39;t we just simulate those processes to generate terrain with erosion? Then answer is, yes! The mechanics of hydraulic erosion, in particular, are well known and are fairly easily to simulate.</p>
<p dir="auto">The basic idea of hydraulic erosion is that water dissolves terrain into sediment, which is then transported downhill and deposited. Programmatically, this means tracking the following quantities:</p>
<ul dir="auto">
<li><strong>Terrain height</strong> - The rock layer that we&#39;re interested in.</li>
<li><strong>Water level</strong> - How much water is at each grid point.</li>
<li><strong>Sediment level</strong> - The amount of sediment suspended in water.</li>
</ul>
<p dir="auto">When simulating, we make small changes to these quantities repeatedly until the erosion features emerge in our terrain.</p>
<p dir="auto">To start off, we initiate the water and sediment levels to zero. The initial terrain height is seeded to some prior height map, frequently just regular fBm.</p>
<p dir="auto">Each simulation iteration involves the following steps:</p>
<ol dir="auto">
<li><strong>Increment the water level</strong> (as in via precipitation). For this I used a simple uniform random distribution, although some approaches use individual water &#34;droplets&#34;.</li>
<li><strong>Compute the terrain gradient.</strong> This is used to determine where water and sediment will flow, as well as the velocity of water at each point.</li>
<li><strong>Determine the sediment capacity</strong> for each point. This is affected by the terrain slope, water velocity, and water volume.</li>
<li><strong>Erode or deposit sediment</strong>. If the sediment level is above the capacity, then sediment is deposited to terrain. Otherwise, terrain is eroded into sediment.</li>
<li><strong>Displace water and sediment downhill.</strong></li>
<li><strong>Evaporate</strong> some fraction of the water away.</li>
</ol>
<p dir="auto">Apply this process for long enough and you may get something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/simulation_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/simulation_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/simulation_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/simulation_hillshaded.png" width="40%"/></a>
  </p>
<p dir="auto">The results are fairly convincing. The tendril-like shape of ridges and cuts you see in real-life terrain are readily apparent. What also jumps out are the large, flat valleys that are the result of sediment deposition over time. If this simulation were left to continue indefinitely, eventually all mountains would be eroded into these flat sedimentary valleys.</p>
<p dir="auto">Because of results like you see above, this method of generating terrain can be seen in professional terrain-authoring tools. The code for the terrain above is largely a vectorized implementation of the code found on <a href="http://ranmantaru.com/blog/2011/10/08/water-erosion-on-heightmap-terrain/" rel="nofollow">this page</a>. For a more theoretical approach, check out this <a href="https://hal.inria.fr/inria-00402079/document" rel="nofollow">paper</a>.</p>
<h3 dir="auto"><a id="user-content-pros" aria-hidden="true" href="#pros"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pros</h3>
<ul dir="auto">
<li>Lot of real-life terrain features simply emerge from running these rules, including stream downcutting, smooth valleys, and differential erosion.</li>
<li>Instead of using global parameter values, different regions can be parameterized differently to develop distinct terrain features (e.g. deserts can evolve differently than forests).</li>
<li>Fairly easy to parallelize given how straightforward vectorization is.</li>
</ul>
<h3 dir="auto"><a id="user-content-cons" aria-hidden="true" href="#cons"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cons</h3>
<ul dir="auto">
<li>Parameter hell. There are around 10 constants that need to be set, in addition to other factors like the precipitation pattern and the initial terrain shape. Small changes to any of these can produce completely different results, so it can be difficult to find the ideal combination of parameters that produces good results.</li>
<li>Fairly inefficient. Given an NxN grid, in order for changes on one side of the map to affect the opposite size you need O(N) iterations, which puts the overall runtime at O(N<sup>3</sup>). This means that doubling the grid dimension can result in 8x execution time. This performance cost further exacerbates the cost of parameter tweaking.</li>
<li>Difficult to utilize to produce novel terrain. The results of simulation all look like reasonable approximations of real life terrain, however extending this to new types of terrain requires an understanding of the physical processes that would give way to that terrain, which can be prohibitively difficult.</li>
</ul>
<h2 dir="auto"><a id="user-content-machine-learning" aria-hidden="true" href="#machine-learning"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning</h2>
<p dir="auto">Machine learning is frequently uses as a panacea for all sorts of problems, and terrain generation is no exception. Machine learning can be effective so long as you have lots of compute power and a large, diverse dataset. Fortunately, compute power is easy to acquire, and lots of terrain elevation data is readily available to download.</p>
<p dir="auto">The most suitable machine learning approach is to use a <strong>Generative Adversarial Network (GAN)</strong>. GANs are able to produce fairly convincing novel instances of a distribution described by training data. It works via two neural networks: one that produces new instances of the distribution (called the &#34;generator&#34;), and another whose job is to determine whether a provided terrain sample is real (i.e. from the training set), or fake (i.e. via the generator). For some more technical background, check out <a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" rel="nofollow">these Stanford lectures</a>.</p>
<p dir="auto">Creating the right network and tuning all the different hyperparameters can be difficult and requires a lot of expertise to get right. Instead of creating the network from scratch, I will be building off of the work done for <em>Progressive Growing of GANs for Improved Quality, Stability, and Variation</em> by Karras, et al. (<a href="https://arxiv.org/pdf/1710.10196.pdf" rel="nofollow">paper</a>, <a href="https://github.com/tkarras/progressive_growing_of_gans">code</a>). The basic approach of this paper is to train the network on lower resolution versions of the training samples while adding new layers for progressively higher resolutions. This makes the network converge quicker for high resolution images than it would if training from full resolution images to begin with.</p>
<h3 dir="auto"><a id="user-content-training" aria-hidden="true" href="#training"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Training</h3>
<p dir="auto">Like with almost all machine learning projects, most effort is spent in data gathering, cleaning, validation, and training.</p>
<p dir="auto">The first step is to get real life terrain height data. For this demonstration, I used the <a href="https://lta.cr.usgs.gov/NED" rel="nofollow">National Elevation Dataset (NED)</a> by the USGS. The dataset I used consists of ~1000 1x1 degree height maps with resolutions of 3600x3600 (i.e. pixel size of 1 arcsecond<sup>2</sup>).</p>
<p dir="auto">From these height maps I will take 512x512 samples for use in training. In the source height arrays, each pixel is a square arcsecond, which means that each sample as-is will appear horizontally stretched, since a square arcsecond is spatially narrower than it is tall. After compensating for this, I also apply several heuristics to filter out what are likely sample unsuitable for training:</p>
<ul dir="auto">
<li>Only accept samples who minimum and maximum elevation span a certain threshold. This approach prefers samples that are more &#34;mountainous&#34;, and will therefore produce more noticeable erosion effects.</li>
<li>Ignore samples if a certain percentage of grid points are within a certain margin of the sample&#39;s minimum elevation. This filters out samples that are largely flat, or ones that consist mostly of water.</li>
<li>Ignore samples whose <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" rel="nofollow">Shannon entropy</a> is below a certain threshold. This helps filter out samples that have been corrupted (perhaps due to different libraries used to encode and decode the height data).</li>
</ul>
<p dir="auto">In addition, if we assume that terrain features do not have a directional preference, we can rotate each sample by 90° increments as well as flipping it to increase the dataset size by 8x. In the end, this nets us around 180,000 training samples.</p>
<p dir="auto">These training samples are then used to train the GAN. Even using progressively grown GANs, this will still take quite a while to complete (expect around a week even with a beefy Nvidia Tesla GPU).</p>
<p dir="auto"><a href="https://drive.google.com/file/d/1zdlgpkQu2zqWKJr23di73-lc3hJBAfqW/view?usp=sharing" rel="nofollow">Here</a> is a timelapse video several terrain samples throughout the training process.</p>
<h3 dir="auto"><a id="user-content-results" aria-hidden="true" href="#results"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Results</h3>
<p dir="auto">Once the network is trained, all we need to do is feed it a new random latent vector into the generator to create new terrain samples:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/ml_generated_1_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/ml_generated_1_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/ml_generated_1_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/ml_generated_1_hillshaded.png" width="40%"/></a>
  </p><p dir="auto"><em>ML-generated terrain.</em></p>

<h3 dir="auto"><a id="user-content-pros-1" aria-hidden="true" href="#pros-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pros</h3>
<ul dir="auto">
<li>Generated terrain is basically indistinguishable from real-world elevation data. It captures not just erosion effects, but many other natural phenomena that shape terrain in nature.</li>
<li>Generation is fairly efficient. Once you have a trained network, creating new terrain samples is fairly fast.</li>
</ul>
<h3 dir="auto"><a id="user-content-cons-1" aria-hidden="true" href="#cons-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cons</h3>
<ul dir="auto">
<li>Training is <em>very</em> expensive (both in time and money). Lot of effort is required to acquire, clean, validate, and finally train the network. It took about 8 days to train the network used in the above examples.</li>
<li>Very little control over the final product. The quality of generated terrain is basically driven by the training samples. Not only do you need a large number of training samples to generate good terrain, you also need good heuristics to make sure that each training sample is suitable. Because training takes so long, it isn&#39;t really practical to iterate on these heuristics to generate good results.</li>
<li>Difficult to scale to higher resolutions. GANs are generally good a low resolution images. It gets much more expensive, both in terms of compute and memory costs, to scale up to higher resolution height maps.</li>
</ul>
<h2 dir="auto"><a id="user-content-river-networks" aria-hidden="true" href="#river-networks"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>River Networks</h2>
<p dir="auto">In most procedural erosion techniques, terrain is carved out first and river placement happens afterward. An alternative method is to work backward: first generate where rivers and streams will be located, and from there determine how the terrain would be shaped to match the rivers. This eases the burden of creating river-friendly terrain by simply defining where the rivers are up front and working the terrain around them.</p>
<h3 dir="auto"><a id="user-content-creating-the-river-network" aria-hidden="true" href="#creating-the-river-network"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Creating the River Network</h3>
<p dir="auto">Every stream eventually terminates somewhere, most frequently the ocean (they occasionally drain into inland bodies of water, but we will be ignoring those; these drainage basins are called <a href="https://en.wikipedia.org/wiki/Endorheic_basin" rel="nofollow">endorheic basins</a>). Given that we need some ocean to drain into, this terrain will be generated as an island,</p>
<p dir="auto">First we start off with what regions will be land or water. Using some simple fBm filtering, we get something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/land_mask.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/land_mask.png" width="40%"/></a>
  </p>
<p dir="auto">The next step is to define the nodes on which the river network will be generated. A straightforward approach is to assign a node to each (x, y) coordinate of the image, however this has a tendency to create horizontal and vertical artifacts in the final product. Instead will we create out nodes by sampling some random points across the grid using <a href="https://www.jasondavies.com/poisson-disc/" rel="nofollow">Poisson disc sampling</a>. After that we use <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation" rel="nofollow">Delaunay triangulation</a> to connect the nodes.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/poisson_disc_sampling.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/poisson_disc_sampling.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/delaunay_triangulation.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/delaunay_triangulation.png" width="40%"/></a>
  </p>
<p dir="auto">Next, we generate the generic shape the terrain will have (which will later be &#34;carved out&#34; via erosion). Because endorheic basins are being avoided in this demo, this terrain is generated such that each point has a downhill path to the ocean (i.e. no landlocked valleys). Here is an example of such a shape:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/initial_shape.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/initial_shape.png" width="40%"/></a>
  </p>
<p dir="auto">The next step is to generate the river network. The general approach is to generate rivers starting from the mouth (i.e. where they terminate in the ocean) and growing the graph upstream one edge at a time until no more valid edges are left. A valid edge is one that:</p>
<ul dir="auto">
<li>Moves uphill. Since we are growing the river graphs upstream, the end effect is only downhill-flowing rivers.</li>
<li>Does not reconnect with an existing river graph. This results in rivers that only merge as they flow downhill, but never split.</li>
</ul>
<p dir="auto">Furthermore, we also prioritize which edge to add by how much it aligns with the previous edge in the graph. Without this, rivers will twist and turn in ways that don&#39;t appear natural. Furthermore, amount of &#34;directional inertia&#34; for each edge can be configured to get more twisty or straight rivers.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/river_network_low_inertia.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/river_network_low_inertia.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/river_network_high_inertia.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/river_network_high_inertia.png" width="40%"/></a>
  </p>
<p dir="auto">After this, the water volume for each node in the river graph is calculated. This is basically done by giving each node a base water volume and adding the sum of all upstream nodes&#39; volumes.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/river_network_with_volume.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/river_network_with_volume.png" width="40%"/></a>
  </p>
<h3 dir="auto"><a id="user-content-generating-the-terrain" aria-hidden="true" href="#generating-the-terrain"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Generating the Terrain</h3>
<p dir="auto">The next step is to generate the terrain height to match the river network. Each node of the river network graph will be assigned a height that will then be rendered via triangulation to get the final  height map as a 2D grid.</p>
<p dir="auto">The graph traversal move uphill, starting from the water level. Each time an edge is traversed, the height of the next node will be proportional to the height difference in the initial terrain height generated earlier, scaled inversely by the volume of water along that edge. Furthermore, we will cap the height delta between any two nodes to give a thermal-erosion-like effect.</p>
<p dir="auto">Traversing only the river network edges will produce discontinuities in the generated height, since no two distinct river &#34;trees&#34; can communicate with each other. When traversing, we will have to also allow traversing edges that span different river trees. For these edges, we simply assume the edge&#39;s water volume to be zero.</p>
<p dir="auto">In the end, you get something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/river_network_grayscale.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/river_network_grayscale.png" width="40%"/></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/dandrino/terrain-erosion-3-ways/blob/master/images/river_network_hillshaded.png"><img src="https://github.com/dandrino/terrain-erosion-3-ways/raw/master/images/river_network_hillshaded.png" width="40%"/></a>
  </p>
<p dir="auto">If you&#39;re interested in an approach that blends river networks and simulation, check out <a href="https://hal.inria.fr/hal-01262376/document" rel="nofollow">this paper</a>.</p>
<h3 dir="auto"><a id="user-content-pros-2" aria-hidden="true" href="#pros-2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pros</h3>
<ul dir="auto">
<li>Creates very convincing erosion-like ridges and cuts. The shape of the river network can easily be seen in the generated height map.</li>
<li>Easy to add rivers if desired given the already-generated river network.</li>
<li>Fairly efficient. Given an NxN height map, this algorithm takes O(N<sup>2</sup>log N) time.</li>
</ul>
<h3 dir="auto"><a id="user-content-cons-2" aria-hidden="true" href="#cons-2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cons</h3>
<ul dir="auto">
<li>This algorithm is good at carving out mountains, but needs work to generate other erosion effects like sediment deposition and differential erosion.</li>
<li>Some of the algorithms used in this approach are a bit more difficult to parallelize (e.g. best first search).</li>
</ul>
<h2 dir="auto"><a id="user-content-running-the-code" aria-hidden="true" href="#running-the-code"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Running the Code</h2>
<p dir="auto">All the examples were generated with Python 3.6.0 using Numpy. I&#39;ve gotten this code to work on OSX and Linux, but I haven&#39;t tried with Windows.</p>
<p dir="auto">Most of the height maps above are generated by running a single python script, with the exception of machine learning which is a bit more involved (described farther down).</p>
<p dir="auto">Here is a breakdown of all the simple terrain-generating scripts. All outputs are 512x512 grids.</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Output</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>plain_old_fbm.py</code></td>
<td><code>fbm.npy</code></td>
<td>Regular fBm</td>
</tr>
<tr>
<td><code>domain_warping.py</code></td>
<td><code>domain_warping.npy</code></td>
<td>fBm with domain warping</td>
</tr>
<tr>
<td><code>ridge_noise.py</code></td>
<td><code>ridge.npy</code></td>
<td>The noise with ridge-like effects seen above.</td>
</tr>
<tr>
<td><code>simulation.py</code></td>
<td><code>simulation.npy</code></td>
<td>Eroded terrain via simulation.</td>
</tr>
<tr>
<td><code>river_network.py</code></td>
<td><code>river_network.npz</code></td>
<td>Eroded terrain using river networks. The NPZ file also contains the height map</td>
</tr>
</tbody>
</table>
<p dir="auto">To generate the images used in this demo, use the <code>make_grayscale_image.py</code> and <code>make_hillshaded_image.py</code> scripts. Example: <code>python3 make_hillshaded_image.py input.npy output.png</code></p>
<h3 dir="auto"><a id="user-content-machine-learning-1" aria-hidden="true" href="#machine-learning-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning</h3>
<p dir="auto">The machine learning examples are all heavily dependent on the <a href="https://github.com/tkarras/progressive_growing_of_gans">Progressive Growing of GANs</a> project, so make sure to clone that repository. That project uses Tensorflow, and requires that you run on a machine with a GPU. If you have a GPU but Tensorflow doesn&#39;t see it, you probably have driver issues.</p>
<h4 dir="auto"><a id="user-content-creating-the-training-data" aria-hidden="true" href="#creating-the-training-data"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Creating the Training Data</h4>
<p dir="auto">If you wish to train a custom network, you can use whatever source of data you want. For the above examples, I used the USGS.</p>
<p dir="auto">The first step is to get the list of URLs pointing to the elevation data:</p>
<ol dir="auto">
<li>Go to the USGS <a href="https://viewer.nationalmap.gov/basic/" rel="nofollow">download application</a></li>
<li>Select the area from which you want to get elevation data.</li>
<li>On the left under <strong>Data</strong>, select <strong>Elevation Product (3DEP)</strong>, then <strong>1 arc-second DEM</strong>. You can choose other resolutions, but I found 1 arcsecond to be adequate.</li>
<li>Under <strong>File Format</strong>, make sure to select <strong>IMG</strong>.</li>
<li>Click on the <strong>Find Products</strong> button.</li>
<li>Click <strong>Save as CSV</strong>. If you wish to use your own download manager, also click <strong>Save as Text</strong>.</li>
</ol>
<p dir="auto">The next step is to download the actual elevation data. You can either use the <code>python3 download_ned_zips.py &lt;downloaded CSV file&gt;</code> which will download the files in the <code>zip_files/</code> directory. The USGS site gives this <a href="https://viewer.nationalmap.gov/uget-instructions/" rel="nofollow">guide</a> to downloading the files via uGet.</p>
<p dir="auto">The next step is to convert the elevation data from IMG files in a ZIP archive to Numpy array files. You can do this by calling <code>python3 extract_height_arrays.py &lt;downloaded CSV file&gt;</code>. This will write the Numpy arrays to the <code>array_files/</code> directory.</p>
<p dir="auto">After this, run <code>python3 generate_training_images.py</code>, which will go through each array in the <code>array_files/</code> directory, and create 512x512 training sample images from it (written to the <code>training_samples/</code> directory). This script performs the validation and filtering described above. It also takes a long time to run, so brew a pot of coffee before you kick it off.</p>
<p dir="auto">The next steps will require that you cloned the <code>progressive_growing_of_gans</code> project. First, you need to generate the training data in the <code>tfrecords</code> format. This can be done by calling:</p>
<p dir="auto"><code>progressive_growing_of_gans/: python3 dataset_tool.py /path/to/erosion_3_ways datasets/terrain</code></p>
<p dir="auto">I chose <code>terrain</code> as the output directory, but you can use whatever you want (just make sure it&#39;s in the <code>datasets/</code> directory.</p>
<p dir="auto">Almost there! The next step is to edit <code>config.py</code> and add the following line to the dataset section:</p>
<p dir="auto"><code>desc += &#39;-terrain&#39;; dataset = EasyDict(tfrecord_dir=&#39;terrain&#39;)</code></p>
<p dir="auto">Make sure to uncomment/delete the &#34;celebahq&#34; line.</p>
<p dir="auto">Now, you can finally run <code>python3 train.py</code>. Even with a good graphics card, this will take days to run. For further training customizations, check out <a href="https://github.com/tkarras/progressive_growing_of_gans#preparing-datasets-for-training">this section</a>.</p>
<p dir="auto">When you&#39;re done, the <code>results/</code> directory will contain all sorts of training outputs, including progress images, Tensorboard logs, and (most importantly) the PKL files containing the network weights.</p>
<h4 dir="auto"><a id="user-content-generating-terrain-samples" aria-hidden="true" href="#generating-terrain-samples"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Generating Terrain Samples</h4>
<p dir="auto">To generate samples, run the following script:</p>
<p dir="auto"><code>python3 generate_ml_output.py path/to/progressive_growing_of_gans network_weights.pkl 10</code></p>
<p dir="auto">The arguments are:</p>
<ol dir="auto">
<li>The path to the cloned <code>progressive_growing_of_gans</code> repository.</li>
<li>The network weights file (the one used for this demo can be found <a href="https://drive.google.com/file/d/1czHFcF2ZG_lki7TAQyYCoqtsVcJmdCUN/view?usp=sharing" rel="nofollow">here</a>).</li>
<li>The number of terrain samples to generate (optional, defaults to 20)</li>
</ol>
<p dir="auto">The outputs are written to the <code>ml_outputs</code> directory.</p>
</article>
        </div></div>
  </body>
</html>
