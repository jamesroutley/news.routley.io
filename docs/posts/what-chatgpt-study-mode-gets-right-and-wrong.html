<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.moderndescartes.com/essays/study_mode">Original</a>
    <h1>What ChatGPT Study Mode gets right and wrong</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2025-07-29</p>
<p> Tagged: <a href="https://drawafish.com/essays/tags/cartesian_tutor">cartesian_tutor</a>, <a href="https://drawafish.com/essays/tags/llms">llms</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr/>

<h2 id="introduction">Introduction</h2>
<p>Today, OpenAI released <a href="https://openai.com/index/chatgpt-study-mode/">Study Mode</a>, a
new ChatGPT features that offers step by step guidance instead of quick
answers.</p>
<p>I’ve been working on a <a href="https://www.moderndescartes.com/essays/tags/cartesian_tutor/">startup
in the AI tutoring space</a> for the last few months, and Study Mode
looks a lot like an <a href="https://drawafish.com/essays/5_16_2025/">early prototype</a> I
built. Having dogfooded this product for a month or two, here’s what I
find Study Mode to be good/bad for.</p>
<h2 id="the-socratic-method-has-advantages">The Socratic method has
advantages</h2>
<p>At its core, Study Mode is build around the idea of Socratic
back-and-forth, relying on the LLM’s knowledge of “core curriculum” to
help guide the student in the right direction. This has a number of
benefits:</p>
<ul>
<li>The student is actively engaged, rather than passively reading the
ChatGPT answer.</li>
<li>The student gets a chance to demonstrate the flaws in their
thinking, which ChatGPT can pounce upon and correct.</li>
<li>The students’ unknown unknowns are typically within the LLM’s world
knowledge. The Socratic method is a great way to suss out these unknown
unknowns.</li>
</ul>
<h2 id="the-student-runs-the-lesson">The student runs the lesson</h2>
<p>The fundamental problem I found with the Socratic method is that the
student is still in the driver’s seat. This can be good, if the student
is epistemically curious enough to systematically explore their blind
spots. However, I have had sessions with my own tutor where I latch onto
what I <em>think</em> is a key idea, and the LLM will enthusiastically
encourage me and build upon my “insight”. Later on, I realize that this
insight is 1. not actually that central of an idea and 2. led me to
completely miss the actual lesson. Overall, the vibe is one of a tutor
that didn’t prep for the session and is just winging it.</p>
<h3 id="problem-solving">Problem solving</h3>
<p>One flavor of this issue is when when the LLM doesn’t always solve
the problem correctly - especially when its context is being
contaminated with potentially incorrect attempts from the student. On
more difficult problems, the LLM will eagerly encourage mistakes and end
up hopelessly confused along with the student. Here, it is useful to
asynchronously solve the problem with a much more powerful model,
summarize the key points of the solution, identify potential alternate
solutions, and then system prompt the LLM to constrain the students’
progress to these guardrails, offering hints as needed.</p>
<h3 id="lesson-planning">Lesson planning</h3>
<p>Another place this goes awry is with lesson planning. I figured that
one solution to this might be analogous to the coding agent technique of
“plan, then execute”, where you first sketch out the lesson to be
learned, and then learn it. However, this runs into the fundamental
problem where you need to have expertise and taste in order to decide
whether the lesson sketch is any good.</p>
<p>Here, a temptation might be to fall back upon the known syllabi of
various classes - whether it’s courses downloaded from MIT OCW, or
course outlines for the AP tests. This sort of works, but suffers from
the problem that the writers of K-12 curricula are often people with
PhDs in education - people who have never practiced in the field they
are now setting teaching standards for. You end up with pablum like this
example taken from the Common Core State Standards for Mathematics:</p>
<blockquote>
<p>Students grasp the concept of a function as a rule that assigns to
each input exactly one output. They understand that functions describe
situations where one quantity determines another. They can translate
among representations and partial representations of functions (noting
that tabular and graphical representations may be partial
representations), and they describe how aspects of the function are
reflected in the different representations.</p>
</blockquote>
<p>Putting this into the system prompt of an LLM will cause the LLM to
start talking like this. You do <strong>not</strong> want to learn from
a teacher that talks like this, I promise you.</p>
<p>Using the syllabus of a college course works better, because
professors are overall more knowledgable and get direct feedback on the
quality of their own curriculum. I think some version of Study Mode will
make it into college campuses via Learning Management System products,
with professors given a relatively simple interface where they can dump
their curriculum/lesson notes/problem sets.</p>
<h2 id="learning-to-what-end">Learning, to what end?</h2>
<p>I think Study Mode will drive incremental signups of ChatGPT Plus,
and possibly help in enterprise sales to schools. I don’t see it being a
killer app, though. Study Mode falls prey to a misconception common to
highly educated people (including myself!): that people want to learn
for the sake of learning.</p>
<p>Education is an <a href="https://drawafish.com/essays/7_28_2025/#thoughts-on-the-fragmented-state-of-education">umbrella
term</a>, much in the way cancer is an umbrella diagnosis. Very few
students learn for the sake of learning. Most students are instead
seeking a diploma/certification/license/degree/test score (call this the
“terminal goal”), for which they will begrudgingly learn something so
they can pass an exam. To build a product that people will pay for, you
have to help them meet their terminal goal, rather than selling them on
the idea of learning better/faster. Solving that terminal goal often
involves integrating, e.g. spaced-repetition flashcards, paced learning
plans, good problem solving sequences, etc.., and need software support
(not just raw LLMs).</p>
<p>The educational products market will remain fragmented because the
set of terminal goals that people have is fragmented. There will likely
be an LLM-powered app that captures the MCAT prep market, another that
captures the remedial math market, another that captures the contest
math market, and so on.</p>
<p>I think the beauty of Study Mode is that it ~75% works for just about
anything you throw at it. ChatGPT was already a strong baseline that I
found hard to beat, and Study Mode will be an even stronger one. Generic
GPT wrapper education products will need to narrow in on their target
audience and terminal goal if they want to survive.</p>


    </div>
</div></div>
  </body>
</html>
