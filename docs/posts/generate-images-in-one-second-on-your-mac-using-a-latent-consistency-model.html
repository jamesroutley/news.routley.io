<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://replicate.com/blog/run-latent-consistency-model-on-mac">Original</a>
    <h1>Generate images in one second on your Mac using a latent consistency model</h1>
    
    <div id="readability-page-1" class="page"><div>
    
    

<article>
  <hgroup>
    

    <p>
      Posted
      <time datetime="2023-10-25">
        October 25, 2023
      </time>
      by
      

      
      <a href="https://replicate.com/fofr">@fofr</a>

      
    </p>
  </hgroup>

  <div>
    <p>Latent consistency models (LCMs) are based on Stable Diffusion, but they can generate images much faster, needing only 4 to 8 steps for a good image (compared to 25 to 50 steps). By running an LCM on your M1 or M2 Mac you can generate 512x512 images at a rate of one per second.</p>
<p><a href="https://arxiv.org/abs/2310.04378">Simian Luo et al</a> released the first Stable Diffusion distilled model. It’s distilled from the Dreamshaper fine-tune by incorporating classifier-free guidance into the model’s input. Only one model has been distilled so far, but more will be released. Stable Diffusion 2.1 and SDXL are being worked on by the paper authors.</p>
<p>You can run the first <a href="https://replicate.com/luosiallen/latent-consistency-model">latent consistency model in the cloud on Replicate</a>, but it’s also possible to run it locally. As well as generating predictions, you can hack on it, modify it, and build new things.</p>
<p>We’ve written this guide to help you get started.</p>
<video autoplay="" controls="" loop="" src="/static/blog/run-latent-consistency-model-on-mac/output.mp4"></video>

<h2 id="prerequisites">Prerequisites</h2>
<p>You’ll need:</p>
<ul>
<li>a Mac with an M1 or M2 chip</li>
<li>16GB RAM or more</li>
<li>macOS 12.3 or higher</li>
<li>Python 3.10 or above</li>
</ul>
<p>We’ve found that an M1 Max or M2 with 32GB RAM can generate images in 1 second. An M1 Pro with 16GB RAM can generate images in 2 to 4 seconds. Please <a href="https://github.com/replicate/latent-consistency-model">share your benchmarks with us on our Github repository</a>.</p>
<h2 id="set-up-python">Set up Python</h2>
<p>You need Python 3.10 or above. Run <code>python -V</code> to see what Python version you have installed:</p>
<pre><code>$ python3 -V
Python 3.10.6
</code></pre>
<p>If it’s 3.10 or above, like here, you’re good to go! Skip on over to the next step.</p>
<p>Otherwise, you’ll need to install Python 3.10. The easiest way to do that is with Homebrew. First, <a href="https://brew.sh/">install Homebrew</a> if you haven’t already.</p>
<p>Then, install the latest version of Python:</p>
<pre><code>brew update
brew install python
</code></pre>
<p>Now if you run <code>python3 -V</code> you should have 3.10 or above. You might need to reopen your console to make it work.</p>
<h2 id="clone-the-repository-and-install-the-dependencies">Clone the repository and install the dependencies</h2>
<p>Run this to <a href="https://github.com/replicate/latent-consistency-model">clone the LCM script from Github</a>:</p>
<pre><code>git clone https://github.com/replicate/latent-consistency-model.git
cd latent-consistency-model
</code></pre>
<p>Then, set up a virtualenv to install the dependencies:</p>
<pre><code>python3 -m pip install virtualenv
python3 -m virtualenv venv
</code></pre>
<p>Activate the virtualenv:</p>
<pre><code>source venv/bin/activate
</code></pre>
<p>(You’ll need to run this command again any time you want to run the script.)</p>
<p>Then, install the dependencies:</p>
<pre><code>pip install -r requirements.txt
</code></pre>
<h2 id="run-it">Run it!</h2>
<p>Now, you can run your latent consistency model. The script will automatically download the <a href="https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7"><code>SimianLuo/LCM_Dreamshaper_v7</code></a> (3.44 GB) and <a href="https://huggingface.co/CompVis/stable-diffusion-safety-checker">safety checker</a> (1.22 GB) models from HuggingFace.</p>
<pre><code>python main.py \
  &#34;a beautiful apple floating in outer space, like a planet&#34; \
  --steps 4 --width 512 --height 512
</code></pre>
<p>You’ll see an output like this:</p>
<pre><code>Output image saved to: output/out-20231026-144506.png
Using seed: 48404
100%|███████████████████████████| 4/4 [00:00&lt;00:00,  5.54it/s]
</code></pre>
<p>We’ve also added a <code>--continous</code> flag, so you can keep on generating image after image until your harddrive is full. Generations after the first one will run a bit faster too.</p>
<pre><code>python main.py \
  &#34;a beautiful apple floating in outer space, like a planet&#34; \
  --steps 4 --width 512 --height 512 --continuous
</code></pre>
<p>That’s it!</p>
<p><img alt="Latent consistency model generation of a beautiful apple floating in outer space, like a planet" src="https://replicate.com/static/blog/run-latent-consistency-model-on-mac/output.webp"/></p>
<h2 id="next-steps">Next steps</h2>
<ul>
<li>If you’re struggling to get this set up, or you aren’t getting fast speeds, <a href="https://discord.gg/replicate">ask in our Discord for some help</a>. Or take a look at <a href="https://github.com/replicate/latent-consistency-model">our Github repository</a>.</li>
<li>You can <a href="https://replicate.com/docs/guides/push-a-model">push custom models to Replicate</a> if you want to host your creations.</li>
<li><a href="https://replicate.com/fofr/latent-consistency-model">Try out a latent consistency model with img2img support</a> on Replicate</li>
<li><a href="https://x.com/replicate">Follow @replicate on X</a>.</li>
</ul>
<p>Happy hacking!</p>
  </div>

  
</article>


    
  </div></div>
  </body>
</html>
