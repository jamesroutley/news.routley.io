<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theverge.com/meta/694685/meta-ai-camera-roll">Original</a>
    <h1>Facebook is starting to feed its AI with private, unpublished photos</h1>
    
    <div id="readability-page-1" class="page"><div id="zephr-anchor"><p>For years, Meta trained its AI programs using the billions of public images uploaded by users onto Facebook and Instagram’s servers. Now, it’s also hoping to access the billions of images that users <em>haven’t </em>uploaded to those servers. Meta tells <em>The Verge</em> that it’s not <em>currently</em> training its AI models on those photos, but it would not answer our questions about whether it might do so in future, or what rights it will hold over your camera roll images.</p><p><a href="https://techcrunch.com/2025/06/27/facebook-is-asking-to-use-meta-ai-on-photos-in-your-camera-roll-you-havent-yet-shared/">On Friday, <em>TechCrunch</em> reported</a> that Facebook users trying to post something on the Story feature have encountered pop-up messages asking if they’d like to opt into “cloud processing”, which would allow Facebook to “select media from your camera roll and upload it to our cloud on a regular basis”, to generate “ideas like collages, recaps, AI restyling or themes like birthdays or graduations.” </p><p>By allowing this feature, the message continues, users are agreeing to Meta AI terms, which allows their AI to analyze “media and facial features” of those unpublished photos, as well as the date said photos were taken, and the presence of other people or objects in them. You further grant Meta the right to “retain and use” that personal information.</p><p><a href="https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data">Meta recently acknowledged</a> that it scraped the data from all the content that’s been published on Facebook and Instagram since 2007 to train its generative AI models. Though the company stated that it’s only used public posts uploaded from adult users over the age of 18, it has long been vague about exactly what “public” entails, as well as what counted as an “adult user” in 2007. </p><p>Meta tells <em>The Verge</em> that, for now, it’s not training on your unpublished photos with this new feature. “[<em>The Verge</em>’s headline] implies we are currently training our AI models with these photos, which we aren’t. This test doesn’t use people’s photos to improve or train our AI models,” Meta public affairs manager Ryan Daniels tells <em>The Verge</em>.</p><p>Meta’s public stance is that the feature is “very early,” innocuous and entirely opt-in: “We’re exploring ways to make content sharing easier for people on Facebook by testing suggestions of ready-to-share and curated content from a person’s camera roll. These suggestions are opt-in only and only shown to you – unless you decide to share them – and can be turned off at any time. Camera roll media may be used to improve these suggestions, but are not used to improve AI models in this test,” reads a statement from Meta comms manager Maria Cubeta.</p><p>On its face, that might sound not altogether different from Google Photos, which similarly might suggest AI tweaks to your images after you opt into Google Gemini. But unlike Google, <a href="https://support.google.com/photos/answer/15344015?visit_id=638682604172372293-2305795082&amp;p=photos-gemini-privacy&amp;rd=1">which explicitly states</a> that it does <em>not </em>train generative AI models with personal data gleaned from Google Photos, Meta’s current AI usage terms, which have been in place since June 23, 2024, do not provide any clarity as to whether unpublished photos accessed through “cloud processing” are exempt from being used as training data — and Meta would not clear that up for us going forward.</p><p>And while Daniels and Cubeta tell <em>The Verge</em> that opting in only gives Meta permission to retrieve 30 days worth of your unpublished camera roll at a time, it appears that Meta is retaining some data longer than that. “Camera roll suggestions based on themes, such as pets, weddings and graduations, may include media that is older than 30 days,” Meta writes.</p><p>Thankfully, Facebook users do have an option to turn off camera roll cloud processing in their settings, which, once activated, will also start removing unpublished photos from the cloud after 30 days.</p><p>The feature suggests a new incursion into our previously private data, one that bypasses the point of friction known as <em>conscientiously deciding to post a photo for public consumption. </em> And according to Reddit posts found by <em>TechCrunch</em>, Meta’s already offering AI restyling suggestions on previously-uploaded photos, even if users hadn’t been aware of the feature: <a href="https://www.reddit.com/r/assholedesign/comments/1lkz8t9/facebook_is_now_inputting_your_photos_into_meta/">one user reported </a>that Facebook had Studio Ghiblified her wedding photos without her knowledge.</p><p><em><strong>Correction, June 27th: </strong>An earlier version of this story implied Meta was already training AI on these photos, but Meta now states that the current test does not yet do so. Also added statement and additional details from Meta</em>.</p></div></div>
  </body>
</html>
