<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theverge.com/meta/694685/meta-ai-camera-roll">Original</a>
    <h1>Facebook is starting to feed its AI with private, unpublished photos</h1>
    
    <div id="readability-page-1" class="page"><div id="zephr-anchor"><p>For years, Meta’s trained its AI programs using the billions of public images uploaded by users onto Facebook and Instagram’s servers. But apparently, Meta has decided to try training its AI on the billions of images that users <em>haven’t </em>uploaded to those servers.</p><p><a href="https://techcrunch.com/2025/06/27/facebook-is-asking-to-use-meta-ai-on-photos-in-your-camera-roll-you-havent-yet-shared/">On Friday, <em>TechCrunch</em> reported</a> that Facebook users trying to post something on the Story feature have encountered pop-up messages asking if they’d like to opt into “cloud processing”, which would allow Facebook to “select media from your camera roll and upload it to our cloud on a regular basis”, to generate “ideas like collages, recaps, AI restyling or themes like birthdays or graduations.” </p><p>By allowing this feature, the message continues, users are agreeing to Meta AI terms, which allows their AI to analyze “media and facial features” of those unpublished photos, as well as the date said photos were taken, and the presence of other people or objects in them. You further grant Meta the right to “retain and use” that personal information.</p><p><a href="https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data">Meta recently acknowledged</a> that it’s scraped the data from all the content that’s been published on Facebook and Instagram since 2007 to train its generative AI models. Though the company stated that it’s only used public posts uploaded from adult users over the age of 18, it has long been vague about exactly what “public” entails, as well as what counted as an “adult user” in 2007. </p><p>Unlike Google, <a href="https://support.google.com/photos/answer/15344015?visit_id=638682604172372293-2305795082&amp;p=photos-gemini-privacy&amp;rd=1">which explicitly states</a> that it does not train generative AI models with personal data gleaned from Google Photos, Meta’s current AI usage terms, which have been in place since June 23, 2024, do not provide any clarity as to whether unpublished photos accessed through “cloud processing” are exempt from being used as training data. Meta did not return <em>TechCrunch</em>’s request for comment; <em>The Verge</em> has reached out for comment as well.</p><p>Thankfully, Facebook users do have an option to turn off camera roll cloud processing in their settings, which, once activated, will also start removing unpublished photos from the cloud after 30 days. But the workaround, disguised as a feature, suggest a new incursion into our private data, one that bypasses the point of friction known as <em>conscientiously deciding to post a photo for public consumption. </em> And according to Reddit posts found by <em>TechCrunch</em>, Meta’s already offering AI restyling suggestions on previously-uploaded photos, even if users hadn’t been aware of the feature: <a href="https://www.reddit.com/r/assholedesign/comments/1lkz8t9/facebook_is_now_inputting_your_photos_into_meta/">one user reported </a>that Facebook had Studio Ghiblified her wedding photos without her knowledge.</p></div></div>
  </body>
</html>
