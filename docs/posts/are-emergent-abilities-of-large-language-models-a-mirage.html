<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2304.15004">Original</a>
    <h1>Are emergent abilities of large language models a mirage?</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2304.15004">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Recent work claims that large language models display emergent abilities,
abilities not present in smaller-scale models that are present in larger-scale
models. What makes emergent abilities intriguing is two-fold: their sharpness,
transitioning seemingly instantaneously from not present to present, and their
unpredictability, appearing at seemingly unforeseeable model scales. Here, we
present an alternative explanation for emergent abilities: that for a
particular task and model family, when analyzing fixed model outputs, one can
choose a metric which leads to the inference of an emergent ability or another
metric which does not. Thus, our alternative suggests that existing claims of
emergent abilities are creations of the researcher&#39;s analyses, not fundamental
changes in model behavior on specific tasks with scale. We present our
explanation in a simple mathematical model, then test it in three complementary
ways: we (1) make, test and confirm three predictions on the effect of metric
choice using the InstructGPT/GPT-3 family on tasks with claimed emergent
abilities, (2) make, test and confirm two predictions about metric choices in a
meta-analysis of emergent abilities on BIG-Bench; and (3) show how similar
metric decisions suggest apparent emergent abilities on vision tasks in diverse
deep network architectures (convolutional, autoencoder, transformers). In all
three analyses, we find strong supporting evidence that emergent abilities may
not be a fundamental property of scaling AI models.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Rylan Schaeffer [<a href="https://arxiv.org/show-email/a812a71a/2304.15004">view email</a>]
      </p></div></div>
  </body>
</html>
