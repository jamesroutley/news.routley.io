<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.githubstatus.com?todayis=2026-02-02">Original</a>
    <h1>GitHub experience various partial-outages/degradations</h1>
    
    <div id="readability-page-1" class="page"><div>
      

    <div>
        <div>
            <div>
              
              <div>
                  <div>
                    <p><strong>Update</strong> - <span>Our upstream provider has applied a mitigation to address queuing and job failures on hosted runners.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>We continue to investigate failures impacting GitHub Actions hosted-runner jobs.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>Copilot is experiencing degraded performance. We are continuing to investigate.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>We continue to investigate failures impacting GitHub Actions hosted-runner jobs.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>The team continues to investigate issues causing GitHub Actions jobs on hosted runners to remain queued for extended periods, with a percentage of jobs failing. We will continue to provide updates as we make progress toward mitigation.<br/></span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>Pages is experiencing degraded performance. We are continuing to investigate.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>The team continues to investigate issues causing GitHub Actions jobs on hosted runners to remain queued for extended periods, with a percentage of jobs failing. We will continue to provide updates as we make progress toward mitigation.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>Actions is experiencing degraded availability. We are continuing to investigate.</span></p></div>
                  <div>
                    <p><strong>Update</strong> - <span>GitHub Actions hosted runners are experiencing high wait times across all labels. Self-hosted runners are not impacted.</span></p></div>
                  <div>
                    <p><strong>Investigating</strong> - <span>We are investigating reports of degraded performance for Actions</span></p></div>
              </div>
            </div>
            
  



            <div>
              
              <div>
                  <div>
                    <p><strong>Update</strong> - <span>Users may see errors creating or resuming codespaces. We are investigating and will provide further updates as we have them.</span></p></div>
                  <div>
                    <p><strong>Investigating</strong> - <span>We are investigating reports of degraded availability for Codespaces</span></p></div>
              </div>
            </div>
            
  



        </div>


        <div>
          <h2>
            <a id="about-this-site" href="#about-this-site">About This Site</a>
          </h2>
          <p>
            Check GitHub Enterprise Cloud status by region:
</p>
        </div>

        <div>
    <div>
          <div>
            
<p><span>
      Git Operations
   </span>

    

  <span title="">

    Operational

  </span>

  

</p>

          </div>
          
          <div>
            
<p><span>
      Visit www.githubstatus.com for more information
   </span>


  <span title="">

    Operational

  </span>

  

</p>

          </div>
          
          
          <div>
            
<p><span>
      Pull Requests
   </span>

    

  <span title="">

    Operational

  </span>

  

</p>

          </div>
          
          
          
          
          
    </div>
    <div>
  <p><span></span>
    Operational
  </p>
  <p><span></span>
    Degraded Performance
  </p>
  <p><span></span>
    Partial Outage
  </p>
  
  <p><span></span>
    Major Outage
  </p>
  <p><span></span>
    Maintenance
  </p>
</div>

  </div>






      <div>
        <h2 id="past-incidents">Past Incidents</h2>
          
  <div>
    <p>Feb <var data-var="date"> 2</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Dependabot is currently experiencing an issue that may cause scheduled update jobs to fail when creating pull requests.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We’ve observed a low rate (~0.01%) of 5xx errors for HTTP-based fetches and clones. We’re currently routing traffic away from the affected location and are seeing recovery.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Git Operations is experiencing degraded performance. We are continuing to investigate.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Feb <var data-var="date"> 1</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">31</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">30</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Customers may experience misreported Copilot Coding Agent tasks in the GitHub UI. Although the underlying actions are completing as requested, surfaces like Agent Sessions on the GitHub website, or Agent Hub in VS Code, will show that an agent is still working on a task, even if that work has completed. </span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Actions</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">29</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">28</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On Jan 28, 2026, between 14:56 UTC and 15:44 UTC, GitHub Actions experienced degraded performance. During this time, workflows experienced an average delay of 49 seconds, and 4.7% of workflow runs failed to start within 5 minutes. The root cause was an atypical load pattern that overwhelmed system capacity and caused resource contention.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Actions workflow run starts are delayed. We are actively investigating to find a mitigation.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Actions</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">27</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">26</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On Jan 26, 2026, from approximately 14:03 UTC to 23:42 UTC, GitHub Actions experienced job failures on some Windows standard hosted runners. This was caused by a configuration difference in a new Windows runner type that caused the expected D: drive to be missing. About 2.5% of all Windows standard runners jobs were impacted. Re-run of failed workflows had a high chance of succeeding given the limited rollout of the change.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>At 23:45 UTC we applied a mitigation to take remaining impacted capacity offline and are seeing improvement. We will update again once we&#39;ve confirmed the issue is resolved.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Our investigation into GitHub Actions 4 Core Windows runner failures in public repositories is ongoing.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We&#39;re continuing to investigate failures in GitHub Actions 4 Core Windows runners in public repositories. </span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Rollback has been completed, but we are still seeing failures on about 11% of GitHub Actions runs on 4 Core Windows runners in public repositories.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Mitigation for failing GitHub Actions jobs on 4-Core Windows runners is still being mitigated. You should start to see more runs succeeding.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We&#39;ve applied a mitigation to unblock running Actions. A regression occurred for Windows runners in public repositories which caused Actions workflows to fail. A mitigation is in place and customers should expect to see resolution soon.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">25</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>Between January 24, 2026,19:56 UTC and January 25, 2026, 2:50 UTC repository creation and clone were degraded. On average, the error rate was 25% and peaked at 55% of requests for repository creation. This was due to increased latency on the repositories database impacting a read-after-write problem during repo creation. We mitigated the incident by stopping an operation that was generating load on the database to increase throughput. </span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>The issue has been resolved. We will continue to monitor to ensure stability.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Repo creation failure rate increased above 50%. We have mitigated the problem and are monitoring for recovery.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">24</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">23</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Jan <var data-var="date">22</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On January 22, 2026, our authentication service experienced an issue between 14:00 UTC and 14:50 UTC, resulting in downstream disruptions for users.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We have identified an issue in one of our services and have mitigated it. Services have recovered and we have a mitigation but we are working on a longer term solution.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Issues is operating normally.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>Issues is experiencing degraded performance. We are continuing to investigate.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">21</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On January 21, between 17:50 and 20:53 UTC, around 350 enterprises and organizations experienced slower load times or timeouts when viewing Copilot policy pages. The issue was traced to performance degradation under load due to an issue in upstream database caching capability within our billing infrastructure, which increased query latency to retrieve billing and policy information from approximately 300ms to up to 1.5s.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We are rolling out a fix to reduce latency and timeouts on policy pages and are continuing to monitor impact.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We are continuing to investigate latency and timeout issues affecting Copilot policy pages.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We are investigating timeouts for customers visiting the Copilot policy pages for organizations and enterprises.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of impacted performance for some GitHub services.</span></p></div>
  </div>

</div>

          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On Jan 21st, 2025, between 11:15 UTC and 13:00 UTC the Copilot service was degraded for Grok Code Fast 1 model. On average, more than 90% of the requests to this model failed due to an issue with an upstream provider. No other models were impacted.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We are experiencing degraded availability for the Grok Code Fast 1 model in Copilot Chat, VS Code and other Copilot products. This is due to an issue with an upstream model provider. We are working with them to resolve the issue.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Copilot</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">20</var>, <var data-var="year">2026</var></p>
          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On January 20, 2026, between 19:08 UTC and 20:18 UTC, manually dispatched GitHub Actions workflows saw delayed job starts. GitHub products built on Actions such as Dependabot, Pages builds, and Copilot coding agent experienced similar delays. All jobs successfully completed despite the delays. At peak impact, approximately 23% of workflow runs were affected, with an average delay of 11 minutes.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>We are investigating delays in manually dispatched Actions workflows as well as other GitHub products which run on Actions. We have identified a fix and are working on mitigating the delays.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Actions</span></p></div>
  </div>

</div>

          <div>
  

  <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <div>
        <p><strong>Resolved</strong> -
      	<span>On January 20, 2026, between 14:39 UTC and 16:03 UTC, actions-runner-controller users experienced a 1% failure rate for API requests managing GitHub Actions runner scale sets. This caused delays in runner creation, resulting in delayed job starts for workflows targeting those runners. The root cause was a service to service circuit breaker that incorrectly tripped for all users when a single user hit rate limits for runner registration. The issue was mitigated by bypassing the circuit breaker, and users saw immediate and full service recovery following the fix.</span></p></div>
      <div>
        <p><strong>Update</strong> -
      	<span>GitHub Actions customers that use actions-runner-controller are experiencing errors from our APIs that informs auto-scaling. We are investigating the issue and working on mitigating the impact.</span></p></div>
      <div>
        <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Actions</span></p></div>
  </div>

</div>

  </div>

          
  <div>
    <p>Jan <var data-var="date">19</var>, <var data-var="year">2026</var></p>
        <p>No incidents reported.</p>
  </div>

      </div>


      
    </div>

      


  </div></div>
  </body>
</html>
