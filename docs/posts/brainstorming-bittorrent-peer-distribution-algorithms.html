<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://moerner.com/posts/brainstorming-peer-distribution-algorithms/">Original</a>
    <h1>Brainstorming BitTorrent Peer Distribution Algorithms</h1>
    
    <div id="readability-page-1" class="page"><div>
      

<article>
  <header>
    

    
    <p><time>Dec 12, 2024</time>
      
      
      
      
    </p>
    
  </header>

  <section><p>Recently, I’ve been working on <a href="https://github.com/dmoerner/etracker">etracker</a>, an experimental BitTorrent tracker designed to incentivize healthy client behavior. If you already know about the Bittorrent protocol or about my project, feel free to skip ahead to the actual <a href="#brainstorming">brainstorming</a>.</p>

<p>BitTorrent is a P2P file transfer protocol, which can use centralized trackers to distribute peer lists to clients, who in turn connect to each other. A collection of clients announcing a particular content infohash is a swarm, which consists of some clients “seeding” content they already have, and other “leeching” content they do not yet have. A tracker must keep track of many clients, each in one or more swarms.</p>
<p>A standard challenge in the BitTorrent world is free-riding: Users who only
leech content, but do not seed. The protocol does not build in an incentive to
seed, so users may leech content and then leave the swarm. This behavior can
put additional upload bandwidth requirements on users who do choose to seed,
and can reduce the longevity of swarms as only a proper subset of the clients
with the content actually offer to seed it to others.</p>
<p>One approach to the free-riding problem, developed by private communities, is
to put out-of-protocol restrictions on clients to force them to seed.
BitTorrent metadata is distributed in the form of <code>.torrent</code> files. A front-end
can restrict access to <code>.torrent</code> files only to users who have demonstrated
that they have uploaded a certain amount of content or seeded torrents for a
certain amount of time. This kind of approach requires significant overhead and
coordination, including a separate database to track user contributions over
time, rules for when new <code>.torrent</code> files can be downloaded, including
authorization that ties clients to a persisting user identity, and moderation
to prevent cheating.</p>
<p>In <code>etracker</code>, I pursue a different approach. The tracker’s primary job is to
distribute peers to clients. The unofficial <a href="https://wiki.theory.org/BitTorrentSpecification#Tracker_Response">extension to the BitTorrent
spec</a>
states:</p>
<blockquote>
<p>As mentioned above, the list of peers is length 50 by default. If there are
fewer peers in the torrent, then the list will be smaller. Otherwise, the
tracker randomly selects peers to include in the response. <em>The tracker may
choose to implement a more intelligent mechanism for peer selection when
responding to a request. For instance, reporting seeds to other seeders could
be avoided.</em></p>
</blockquote>
<p>One of the goals of <code>etracker</code> is to explore alternative peer distribution
algorithms which are designed to incentivize long-term and fast seeding,
without relying on restrictions on <code>.torrent</code> file downloads or requiring that
users authorize with a central service to gain access to content.</p>
<p>(Another goal of <code>etracker</code> is to experiment with tracker-level cheater
detection. Cheating becomes an issue with any system that tries to
algorithmically solve the free-riding problem. I hope to discuss cheating in
later posts.)</p>

<p>The informal idea behind <code>etracker</code> is to reward good peers with more good
peers. Formalizing this informal idea requires figuring out what a good seeder
is, figuring out what a good peer is, and figuring out how to scale the
rewards. At this point I’m just going to be publicly brainstorming, building up
in steps towards the algorithm I’m currently targeting.</p>
<h2 id="first-algorithm-number-of-announces--number-of-peers">First Algorithm: Number of announces = Number of peers</h2>
<p>The simplest algorithm counts how many non-stale announces a client has (i.e.,
the number of torrents they have announcing in their client), and returns a
number of peers equal to that number, up to the maximum that the client
requests. A <a href="https://github.com/dmoerner/etracker/commit/ac658a8e9c63ceb442615a089c42b108357f473a">sample
implementation</a>
of this simple algorithm is available on GitHub.</p>
<p>However, it has a number of problems:</p>
<ol>
<li>A linear algorithm with an intercept of zero is probably not what we want.
It’s too punishing to new peers in few or no existing swarms.</li>
<li>Large-scale leechers can still get all the peers they request, because they
are making announces for each torrent they are trying to leech. Although
leechers should get peers, we should do more to incentivize seeding as well.</li>
<li>No sense of peer quality beyond number of peers returned. <code>etracker</code> bends the spec by giving many leechers
fewer peers than they request. If leechers are only given poor quality peers
and are not given as many as they request, they will be incentivized to use
another tracker, rather than to seed more. Poor quality peers might be slow
peers, or there might be other kinds of poor quality peer.</li>
</ol>
<p>From now on, I’m going to assume that Problem #1 can be solved independently.
It’s just a matter of exploring some mathematical functions to normalize the
curve of peers we distribute.</p>
<h2 id="second-algorithm-number-of-seeds--normalized-number-of-peers">Second Algorithm: Number of seeds = Normalized number of peers</h2>
<p>The next evolution of the algorithm defines a good peer as a good seeder. We
can detect seeders in the swarm by tracking announces with the <code>left</code> key set
to zero. This solves Problem 2 of the first algorithm, since we only reward
seeders, and not leechers. However, some problems remain and other problems
arise.</p>
<p>Problems:</p>
<ol>
<li>Disadvantages partial seeders: A partial seeder is a client which snatches
part of a torrent, not all of it. For example, the <a href="https://archive.org">Internet
Archive</a> hosts large torrents of historical documents,
and a user may wish to only snatch some subset of the data. These seeders
keep announcing with a non-zero <code>left</code> key, even though they never leech
more of the torrent.</li>
<li>No sense of peer quality beyond the number of peers received.</li>
</ol>
<h2 id="third-algorithm-number-of-seeds-and-amount-of-upload--normalized-number-of-peers">Third Algorithm: Number of seeds and Amount of upload = Normalized number of peers</h2>
<p>Each client announce includes statistics on how much the client has upload
and downloaded on a particular torrent. The tracker can keep track of this, and
this points to a third evolution in the algorithm. Define as a good peer as a
good seeder, or as a leecher who announces upload on torrents which they have not yet completed. This will capture at least two additional cases beyond the second algorithm: First, it rewards leechers who are simultaneously seeding to others. Even if the leecher leaves the swarm soon, the fact that they have seeded as well before leaving is a sign of swarm health. Second, it rewards partial seeders who report upload to other peers.</p>
<p>This algorithm is not a complete solution to the issue of disadvantaging
partial seeders: It will only count partial seeders who are also uploading to
other leechers. This will not count partial seeders on unpopular content, who
do not seed to anyone else. However, I think this is a reasonable compromise.
If content is unpopular, we should incentivize people to seed it all for better
retention. (Conversely, if a partial seeder reports no upload because they are
a partial seeder of a very well-seeded torrent, there is no reason to
particularly incentivize this kind of partial seeding either.)</p>
<p>Problems:</p>
<ol>
<li>No sense of peer quality beyond the number of peers received.</li>
</ol>
<h2 id="fourth-algorithm-number-of-seeds-and-amount-of-upload--scaled-peers-by-tier">Fourth Algorithm: Number of seeds and Amount of upload = Scaled peers by tier</h2>
<p>The fourth and final algorithm finally tries to tackle the problem of returning good peers. The basic idea is that just as we can use upload and download
amounts to measure if a particular client is a good enough contributor to be
“deserving” of peers, we can also judge the other peers in the same way.</p>
<p>I imagine dividing the set of peers into tiers. Seeding peers with quick upload are in
a high tier, and are preferentially distributed to high tier peers which are
leeching new content.</p>
<p>This involves a number of complications in implementation. As you can tell, I’m
still working through exactly what this might look like:</p>
<ul>
<li>Seeding amount versus seeding speed: Clients seeding large number of torrents
may have a limit on the number of connections they can make. Although we want
to distribute peers in such a way as to take advantage of large bandwidth
uploaders, we cannot punish them by trying to make them use too many
connections. Ideally, we may want to reserve the upload bandwidth of large
seeders for the most unpopular torrents they are sharing.</li>
<li>Uncertainty in estimating peer quality: Peers do not directly report their
client limits or their bandwidth limits to us. This can only be unreliably
inferred from their announce statistics.</li>
<li>Handling multiple requests for peers from leeching clients: On slower
connections or with large files, a leecher may make several announces before
completing. It may make sense to give them better peers in later announces to
help them finish snatching a torrent. If we do not adequately reward clients
with completed content, they won’t use this kind of tracker to begin with.</li>
<li>Technical issues: Efficiently calculating and updating peer tiers may be
expensive, and require additional tables or caching.</li>
<li>Cheating: Once the algorithm becomes sufficiently sensitive to reported
announce statistics, it also increases the incentive for clients to cheat.
This is a large topic which I’ll approach in later development.</li>
</ul>
<p>How is the fourth evolution of the algorithm different from the out-of-protocol
solution I mentioned earlier in this post? Those solutions are all-or-nothing:
Authorization for each user is used to prevent any bad contributors from using
the tracker at all. <code>etracker</code> is designed to be more generous: All the content
is still available to anyone, but it just may be slower to snatch if you are
not a good seeder or active uploader. This is designed to incentivize such
behavior by rewarding it with faster download speeds. This is implemented
without any specific mechanism for client authorization, and the broader
requirements for state are limited, since clients are identified by PeerID,
which reset on every client restart.</p>
</section>

  
  

  
  
  
  
  <nav>
    
    
    <a href="https://moerner.com/posts/postgresql-parameter-placeholders/"><span>Where can you use a PostgreSQL parameter placeholder?</span><span>→</span></a>
    
  </nav>
  
  

  
  

  
  

  


  
</article>


    </div></div>
  </body>
</html>
