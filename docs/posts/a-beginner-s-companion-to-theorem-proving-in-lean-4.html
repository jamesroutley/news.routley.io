<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://emallson.net/blog/a-beginners-companion-to-theorem-proving-in-lean/">Original</a>
    <h1>A Beginner&#39;s Companion to Theorem Proving in Lean 4</h1>
    
    <div id="readability-page-1" class="page"><article id="a-beginners-companion-to-theorem-proving-in-lean">
      <header>
        
        <p>
          <em id="written-by">Written by J. David Smith</em>
          </p>
      </header>
      <p>This year, one of my hobby projects has been implementing some basic properties
and conversions between <a href="https://en.wikipedia.org/wiki/Matroid">Matroids</a> in
<a href="https://lean-lang.org/">Lean</a>.</p>
<p>My primary resource for doing this has been <a href="https://lean-lang.org/theorem_proving_in_lean4/title_page.html"><em>Theorem Proving in Lean
4</em></a> (TPiL),
which is an incredibly detailed walk through using Lean as a proof assistant.
While useful, it has...gaps—as does the main Lean documentation. A lot
of this gap appears to be <a href="https://leanprover-community.github.io/archive/">filled by the Zulip
chat</a>.</p>
<p>The title of this post is a bit of a double entendre: I am still a relative
beginner, writing what I intend as a companion to TPiL; and this is is intended
for beginners to Lean, covering that I wish I had known as a beginner myself.</p>
<p>A final caveat emptor: I haven&#39;t really hung out in Zulip and don&#39;t have a good
grasp on good code organization and style in Lean. These may not be best
practices, but they helped me.</p>
<hr/>
<p>This is organized in small sections covering individual things that I learned
the hard way while working on my hobby project.</p>
<details>
<summary><p>Running Snippets</p></summary>
<p>You can run the code snippets below in Lean or on the <a href="https://live.lean-lang.org/">Lean website</a> if you paste this prelude at the top:</p>
<pre data-lang="lean"><code data-lang="lean"><span>import</span><span> Mathlib.Data.Finset.Basic
</span><span>import</span><span> Mathlib.Data.Finset.Card
</span></code></pre>
</details>
<h2 id="theorem-location-with-rw-simp-apply-and-exact"><a href="#theorem-location-with-rw-simp-apply-and-exact" aria-label="Anchor link for: theorem-location-with-rw-simp-apply-and-exact">Theorem Location with <code>rw?</code>, <code>simp?</code>, <code>apply?</code> and <code>exact?</code></a></h2>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T : Finset α) : S ⊆ T -&gt; T ⊆ S -&gt; T = S := </span><span>by 
</span><span>  exact?
</span></code></pre>
<p>One of the biggest pain points early in my Lean experience was <em>finding</em>
theorems to use. The
<a href="https://leanprover-community.github.io/mathlib4_docs/foundational_types.html"><code>mathlib</code></a>
documentation is great, but lacking <a href="https://hoogle.haskell.org/">hoogle</a>-style
search.</p>
<p>EDIT: Apparently not! <code>LeahNeukirchen</code> points out on
<a href="https://lobste.rs/s/hwjv0f/beginner_s_companion_theorem_proving#c_7rypt5">lobste.rs</a>
two different hoogle-like search engines that I missed:</p>
<ul>
<li><a href="https://www.moogle.ai/">moogle.ai</a></li>
<li><a href="https://loogle.lean-lang.org">loogle</a></li>
</ul>
<p>The <code>rw?</code>, <code>simp?</code>, <code>apply?</code> and <code>exact?</code> tactics give you specialized
hoogle-like access within the Lean environment, finding candidate theorems that
satisfy a specific goal and listing them in the editor UI. You can pick one of
the solutions via code actions if using the LSP.</p>
<p>By default, all target the current goal, but <code>rw?</code> and <code>simp?</code> can have <code>at</code> forms:</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T : Finset α) : S ⊆ T -&gt; T ⊆ S -&gt; T = S := </span><span>by 
</span><span>  intro S_subs T_subs
</span><span>  rw? </span><span>at</span><span> S_subs
</span></code></pre>
<h2 id="goal-patterns-for-rw-apply-and-exact"><a href="#goal-patterns-for-rw-apply-and-exact" aria-label="Anchor link for: goal-patterns-for-rw-apply-and-exact">Goal Patterns for <code>rw</code>, <code>apply</code> and <code>exact</code></a></h2>
<p>TPiL explains what each of these tactics do in technical terms, but it took
time for me to grok what each do in practice.</p>
<p>It is important to understand that these tactics are all fundamentally
performing <em>pattern rewriting</em>. The patterns for each are:</p>
<h3 id="rw"><a href="#rw" aria-label="Anchor link for: rw"><code>rw</code></a></h3>
<p><strong>Input Goal:</strong> <code>a</code></p>
<p><code>rw</code> is the most direct of the 3. It applies a theorem or assumption that looks
like <code>a = b</code> or <code>a &lt;-&gt; b</code> to a goal that looks like <code>a</code>, substituting it with
<code>b</code>.</p>
<p><code>rw</code>, unlike <code>apply</code> and <code>exact</code>, can be applied to non-goals to transform
them. This is very useful to massage theorems from different sources into
alignment to prove your goal.</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T X : Finset α) : S = X -&gt; X = T -&gt; S = T := </span><span>by
</span><span>  intro S_eq X_eq
</span><span>  rw [S_eq, &lt;-X_eq]
</span></code></pre>
<h3 id="exact"><a href="#exact" aria-label="Anchor link for: exact"><code>exact</code></a></h3>
<p><strong>Input Goal:</strong> <code>a</code></p>
<p><code>exact</code> takes an assumption, along with any needed parameters, and uses it to
resolve the current goal. It is simplistic, but effective.</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T : Finset α) : S ⊆ T -&gt; T ⊆ S -&gt; S = T := </span><span>by
</span><span>  intro S_subs T_subs
</span><span>  </span><span>/- Finset.Subset.antisymm looks like: S ⊆ T -&gt; T ⊆ S -&gt; S = T -/
</span><span>  </span><span>/- the S_subs and T_subs parameters leave us with S = T, which matches the goal. -/
</span><span>  exact Finset.Subset.antisymm S_subs T_subs
</span></code></pre>
<h3 id="apply"><a href="#apply" aria-label="Anchor link for: apply"><code>apply</code></a></h3>
<p><strong>Input Goal:</strong> <code>b</code></p>
<p><code>apply</code> transforms your goal into a different goal using an implication. If a
proof of <code>a</code> exists in the current scope, it is applied (in which case you
basically get <code>exact</code>). Otherwise, you get a new goal <code>a</code>.</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T : Finset α) : S ⊆ T ∧ T ⊆ S := </span><span>by
</span><span>  </span><span>/- Finset.Subset.antisymm_iff.mp looks like S = T -&gt; S ⊆ T ∧ T ⊆ S -/
</span><span>  apply Finset.Subset.antisymm_iff.mp
</span><span>  </span><span>/- new goal: S = T -/
</span></code></pre>
<p>Importantly (so importantly I&#39;ll bring it up again later): an <code>a ↔ b</code> or <code>a = b</code> assumption can be converted to <code>a → b</code> (with <code>.mp</code>) or <code>b → a</code> (with
<code>.mpr</code>).</p>
<h2 id="introducing-new-sub-goals-with-have-and-if-else"><a href="#introducing-new-sub-goals-with-have-and-if-else" aria-label="Anchor link for: introducing-new-sub-goals-with-have-and-if-else">Introducing New Sub-Goals with <code>have</code> and <code>if</code>/<code>else</code></a></h2>
<p>TPiL mentions sub-goals at several points and does briefly discuss <code>have</code>, but
I feel this area was glossed over. Adding sub-goals toward your larger goal is
an extremely helpful method of making larger proofs tractable.</p>
<p>The first (and seemingly most common) way to introduce sub-goals is by way of
<code>have</code>, which generally has two purposes. First: you can introduce smaller
goals that are easier to prove—sometimes even possible for Lean to prove
automatically.</p>
<pre data-lang="lean"><code data-lang="lean"><span>/- While lean cannot auto-solve the outer statement, it can trivially solve the both steps with `exact?` -/
</span><span>example</span><span> [DecidableEq α] (S : Finset α) (e1 e2 : α) : e2 ∈ S → insert e2 (insert e1 S) = (insert e1 S) := </span><span>by
</span><span>  intro e2_mem
</span><span>  </span><span>have</span><span> : e2 ∈ (insert e1 S) := </span><span>by</span><span> exact? 
</span><span>  exact? 
</span></code></pre>
<p>Second: you can use it to instantiate other theorems for re-use:</p>
<pre data-lang="lean"><code data-lang="lean"><span>/- (not runnable) -/
</span><span>have</span><span> T_card := ind_rank_eq_largest_ind_subset_card ind (insert e2 S) T T_subs T_ind T_max
</span></code></pre>
<p>In contrast, <code>if</code> / <code>else</code> is generally useful in cases where you need to
introduce a goal that relies on the <a href="https://lean-lang.org/theorem_proving_in_lean4/axioms_and_computation.html?highlight=propext#the-law-of-the-excluded-middle">law of the excluded
middle</a>.</p>
<pre data-lang="lean"><code data-lang="lean"><span>/- there is a theorem in Mathlib for this, but we use `have` to create smaller goals to bypass it -/
</span><span>example</span><span> [DecidableEq α] (S : Finset α) (e : α) : (insert e S).card ≤ S.card + </span><span>1</span><span> := </span><span>by
</span><span>  </span><span>if</span><span> h : e ∈ S </span><span>then
</span><span>    </span><span>have</span><span> : insert e S = S := Finset.insert_eq_self.mpr h
</span><span>    rw [</span><span>this</span><span>]
</span><span>    exact Nat.le_add_right (Finset.card S) </span><span>1
</span><span>  </span><span>else
</span><span>    </span><span>have</span><span> : S.card + </span><span>1</span><span> = (insert e S).card := (Finset.card_insert_of_not_mem h).symm
</span><span>    rw [</span><span>this</span><span>]
</span></code></pre>
<p>Note that this, along with helpful theorems like <code>not_not</code> rely on classical
logic and as such are not strictly constructive (as far as my knowledge
indicates), but <code>if</code>/<code>else</code> in particular is such a useful means of organizing
my thoughts in the implementation of a proof that I opted to use it quite
heavily.</p>
<p>EDIT: It appears that Lean will only allow non-constructive uses of <code>if</code> /
<code>else</code> if you have used <code>open Classical</code> in the module. <a href="https://lobste.rs/s/hwjv0f/beginner_s_companion_theorem_proving#c_jc4wbc">More
info</a></p>
<h2 id="refine-and-case"><a href="#refine-and-case" aria-label="Anchor link for: refine-and-case"><code>refine</code> and <code>case</code></a></h2>
<p>TLiP discusses handling cases with dots and <code>cases _ with</code> and <code>match _ with</code>,
but it wasn&#39;t clear to me how to handle the (labelled) sub-goals generated
other tools (like <code>apply Iff.intro</code>).</p>
<p>You can use <code>case &lt;label&gt; =&gt; &lt;proof&gt;</code> to handle a specific named proof.</p>
<p>This couples well with <code>refine</code>, which is like <code>exact</code> but generates sub-goals for (named or anonymous) placeholders:</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S T : Finset α) : S ⊆ T -&gt; T ⊆ S -&gt; S = T := </span><span>by
</span><span>  intros
</span><span>  refine Finset.Subset.antisymm ?left ?right
</span><span>  case left =&gt; assumption
</span><span>  case right =&gt; assumption
</span></code></pre>
<h2 id="transforming-assumptions-via-dot-notation"><a href="#transforming-assumptions-via-dot-notation" aria-label="Anchor link for: transforming-assumptions-via-dot-notation">Transforming Assumptions via dot-notation</a></h2>
<p>As noted above, you can transform inferential rules with dot accessors: </p>
<ul>
<li><code>this.mp</code> and <code>this.mpr</code> give you <a href="https://en.wikipedia.org/wiki/Modus_ponens"><em>modus ponens</em></a> (and an order-swapped one for iff/eq terms)</li>
<li><code>this.mt</code> gives you <a href="https://en.wikipedia.org/wiki/Modus_tollens"><em>modus tollens</em></a></li>
</ul>
<p>Beyond this, many operators expose helpful utilities. Using <code>a &gt; b</code> as an example:</p>
<ul>
<li><code>le</code> produces <code>b &lt; a</code></li>
<li><code>not_le</code> produces <code>¬ a &lt;= b</code></li>
<li><code>asymm</code> produces <code>¬ a &lt; b</code></li>
<li><code>trans_le</code> produces <code>a &lt;= c -&gt; b &lt; c</code></li>
</ul>
<p>and many more. These are super handy for cases where (for example) you&#39;ve got
your hands on a proof of <code>a &gt; b</code> and need to prove <code>¬ a &lt;= b</code>, which happens
often with contraposition.</p>
<h2 id="absurd-contrapose-contradiction"><a href="#absurd-contrapose-contradiction" aria-label="Anchor link for: absurd-contrapose-contradiction"><code>absurd</code>, <code>contrapose</code>, <code>contradiction</code></a></h2>
<p>These tactics are all negation-related. Much like <code>rw</code> / <code>apply</code> / <code>exact</code>,
they do different yet similar things.</p>
<h3 id="absurd-h"><a href="#absurd-h" aria-label="Anchor link for: absurd-h"><code>absurd h</code></a></h3>
<p><strong>Input State:</strong> an assumption <code>h</code>, for which you can prove <code>¬ h</code> from other assumptions</p>
<p>This is useful in cases where you have constructed a contradiction in your
assumptions for a proof by contradiction, but the contradiction is not obvious
to Lean.</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (a b : ℕ) : a &gt; b -&gt; b &gt; a -&gt; True := </span><span>by
</span><span>  intro left right
</span><span>  absurd right
</span><span>  exact left.asymm
</span></code></pre>
<h3 id="contradiction"><a href="#contradiction" aria-label="Anchor link for: contradiction"><code>contradiction</code></a></h3>
<p><strong>Input State:</strong> a pair of assumptions <code>h</code> and <code>h&#39;</code> which <em>blatantly</em> contradict</p>
<p><code>contradiction</code> cuts out the extra steps of <code>absurd</code> in cases where the
contradiction is obvious to Lean. Typically, this means that you have
hypothesis <code>h : a</code> and <code>h&#39; : ¬ a</code>.</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (a b : ℕ) : a &gt; b -&gt; ¬ a &gt; b -&gt; True := </span><span>by
</span><span>  intros
</span><span>  contradiction
</span></code></pre>
<h3 id="contrapose-h"><a href="#contrapose-h" aria-label="Anchor link for: contrapose-h"><code>contrapose h</code></a></h3>
<p><strong>Input State:</strong> an assumption <code>h</code></p>
<p>Unlike <code>absurd</code> / <code>contradiction</code>, this is <em>actually</em> doing something
different: applying
<a href="https://en.wikipedia.org/wiki/Contraposition">contraposition</a>. I&#39;m including
it mostly because the tactic wasn&#39;t mentioned in TLiP and I often find that
<code>contrapose</code> is useful to simplify goals that involve negation in combination with <code>rw [not_not]</code>.</p>
<pre data-lang="lean"><code data-lang="lean"><span>/- a theorem for this exists in Mathlib, but again we&#39;re ignoring it -/
</span><span>example</span><span> (S : Finset α) : ¬ S.card = </span><span>0</span><span> -&gt; S ≠ ∅ := </span><span>by
</span><span>  intro neq_zero
</span><span>  contrapose neq_zero
</span><span>  rw [not_ne_iff] </span><span>at</span><span> neq_zero
</span><span>  rw [not_not, neq_zero]
</span><span>  rfl
</span></code></pre>
<h2 id="and-or-destructuring-and-pattern-matching"><a href="#and-or-destructuring-and-pattern-matching" aria-label="Anchor link for: and-or-destructuring-and-pattern-matching"><code>And</code>, <code>Or</code>, Destructuring and Pattern Matching</a></h2>
<p>In a conventional language with algebraic data types, there are broadly two groups of types:</p>
<h3 id="product-types"><a href="#product-types" aria-label="Anchor link for: product-types">Product Types</a></h3>
<p>In a language like Rust, these are <code>struct</code>s or tuples:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Foo </span><span>{
</span><span>  </span><span>a</span><span>: </span><span>usize</span><span>;
</span><span>  b: </span><span>usize</span><span>;
</span><span>}
</span><span>
</span><span>struct </span><span>Bar</span><span>(</span><span>usize</span><span>, </span><span>usize</span><span>);
</span></code></pre>
<p>The <code>And</code> type in Lean, while usually written <code>A ∧ B</code>, is actually a structure that looks something like:</p>
<pre data-lang="lean"><code data-lang="lean"><span>structure </span><span>And where
</span><span>  </span><span>left </span><span>: α
</span><span>  right : β
</span></code></pre>
<p>Since this is a structure, that means you can destructure it in an assumption:</p>
<pre data-lang="lean"><code data-lang="lean"><span>have</span><span> : a ∧ b := </span><span>sorry</span><span>
</span><span>have</span><span> 〈 a, b 〉 := </span><span>this
</span></code></pre>
<p>You can deal with it in a goal in two ways:</p>
<ul>
<li>Instantiating the structure: <code>exact 〈 a, b 〉</code> (closes the goal)</li>
<li>Converting to sub-goals: <code>apply And.intro</code> (creates new goals for proving the left and right sides)</li>
</ul>
<h3 id="sum-types"><a href="#sum-types" aria-label="Anchor link for: sum-types">Sum Types</a></h3>
<p>In a language like Rust, these are <code>enum</code>s:</p>
<pre data-lang="rust"><code data-lang="rust"><span>enum </span><span>Foo </span><span>{
</span><span>  A(</span><span>usize</span><span>),
</span><span>  B(</span><span>usize</span><span>)
</span><span>}
</span></code></pre>
<p>The <code>Or</code> type in Lean is a sum type. While written <code>A ∨ B</code>, it would actually look something like this:</p>
<pre data-lang="lean"><code data-lang="lean"><span>inductive </span><span>Or where
</span><span>| inl : α
</span><span>| inr : β
</span></code></pre>
<p>As a sum type, you deal with it by <em>pattern matching</em> in assumptions:</p>
<pre data-lang="lean"><code data-lang="lean"><span>have</span><span> : a ∨ b := </span><span>sorry</span><span>
</span><span>cases </span><span>this with
</span><span>| inl a =&gt; </span><span>sorry</span><span>
</span><span>| inr b =&gt; </span><span>sorry</span><span>
</span></code></pre>
<p>However, in goals you generally do one of two things:</p>
<ul>
<li>Instantiate one side of the structure: <code>exact Or.inr b</code> (which closes the goal). This pairs well with <code>have</code> to create a sub-goal for one side of the <code>Or</code>.</li>
<li>Convert to an implication: for example <code>rw [or_iff_not_imp_left]</code> (which convers <code>a ∨ b</code> to <code>¬ a -&gt; b</code>, and given a <code>¬a</code> assumption changes the goal to <code>b</code>)</li>
</ul>
<h2 id="existentials"><a href="#existentials" aria-label="Anchor link for: existentials">Existentials</a></h2>
<p>The single thing that gave me the most trouble in my hobby project was the
proving of theorems involving <em>existential quantifiers.</em> It is important to
understand the constructive elements of Lean to fully understand the design of
existentials, and I think that TPiL does a pretty good job of explaining that.
However, that explanation doesn&#39;t really tell you how to prove existentials in
more complicated settings.</p>
<p>First off: existentials have the type <code>Exist α β</code>. This is a product type, much
like <code>And</code>, and can be destructured in a similar way:</p>
<pre data-lang="lean"><code data-lang="lean"><span>have</span><span> : ∃ x : N, x &lt; </span><span>4</span><span> := </span><span>sorry</span><span>
</span><span>have</span><span> 〈x, x_lt〉 := </span><span>this </span><span>/- note that `x` is actually an N that exists satisfying x_lt! -/
</span></code></pre>
<p>This also means that your options for <em>proving</em> an existential are much like an
<code>And</code>. Principally: construct it with <code>exact 〈x, h〉</code>, <code>x</code> is some value that
satisfies <code>h</code>.</p>
<p>The question then: for complex types, how do you get an <code>x</code>? The answer: get it
from a method. <code>bex</code> seems like the common name for it. For example, to obtain
an element of a finite set <code>S</code>:</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> (S : Finset α) : S ≠ ∅ -&gt; ∃ x : α, x ∈ S := </span><span>by
</span><span>  intro h
</span><span>  </span><span>/- before getting an element from S, we have to construct the Nonempty type -/
</span><span>  </span><span>have</span><span> : S.Nonempty := Finset.nonempty_of_ne_empty h
</span><span>  exact this.bex
</span></code></pre>
<p>Once you&#39;re used to this, it starts becoming fairly natural. Retrieving
elements from collections generally requires proving that they are nonempty
(otherwise there may be no element to retrieve!), but that this was a totally
separate type (<code>Finset.Nonempty</code> in my case) was opaque and difficult for me to
discover.</p>
<h2 id="let-vs-have"><a href="#let-vs-have" aria-label="Anchor link for: let-vs-have"><code>let</code> vs <code>have</code></a></h2>
<p>Above, I discussed <code>have</code> as a means of introducing sub-goals to solve.
Alongside it exists a syntactically-similar tool: <code>let</code>. Specifically:</p>
<pre data-lang="lean"><code data-lang="lean"><span>have</span><span> &lt;name&gt; : &lt;assumption&gt; := &lt;proof of assumption&gt;
</span></code></pre>
<p>may be restated as:</p>
<pre data-lang="lean"><code data-lang="lean"><span>have</span><span> &lt;name&gt; : &lt;type&gt; := &lt;construction&gt;
</span></code></pre>
<p>which is then (almost!) equivalent to:</p>
<pre data-lang="lean"><code data-lang="lean"><span>let</span><span> &lt;name&gt; : &lt;type&gt; := &lt;construction&gt;
</span></code></pre>
<p>There is one key difference: <code>let</code> definitions are <em>transparent</em>, while <code>have</code>
definitions are <em>opaque</em>. In other words: if you want the rewriter to be able
to operate on the construction of a term, use <code>let</code>. Otherwise, <code>have</code>.</p>
<p>To see the difference, consider this example:</p>
<pre data-lang="lean"><code data-lang="lean"><span>example</span><span> [DecidableEq α] (a b : Finset α) (e : α) : ¬ e ∈ a -&gt; insert e a = b -&gt; b.card = a.card + </span><span>1</span><span> := </span><span>by
</span><span>  intro mem h
</span><span>  </span><span>let</span><span> x := insert e a
</span><span>  </span><span>have</span><span> : x.card = a.card + </span><span>1</span><span> := </span><span>by
</span><span>    rw [Finset.card_insert_of_not_mem mem]
</span><span>  rw [← </span><span>this</span><span>, ← h]
</span></code></pre>
<p>If <code>let x</code> is replaced by <code>have x</code>, then the inner sub-goal is no longer
provable—the definition of <code>x</code> has become opaque.</p>
<p>There is one other difference: which fields are optional. <code>have</code> requires
<em>only</em> the <code>construction</code> / <code>proof</code> field, while <code>let</code> requires at least the
<code>name</code> and <code>construction</code> fields (the type may be inferred).</p>
<h2 id="use-small-theorems"><a href="#use-small-theorems" aria-label="Anchor link for: use-small-theorems">Use Small Theorems</a></h2>
<p>My final note—and the only one on code organization—is to use small
theorems. If you example much of mathlib, you will find small proofs: a handful
of lines, at most. This is obviously helpful when you are familiar with the
library internals, but opaque as a reader on how exactly the proof is
constructed.</p>
<p>Don&#39;t let that discourage you from focusing on small proofs, though! There are
two <em>strong</em> reasons beyond vague &#34;code architecture&#34; considerations for this:</p>
<ol>
<li>Small proofs can often be constructed automatically by Lean through
<code>exact?</code>, <code>rw?</code> or <code>simp?</code> (if not more advanced tools like
<a href="https://github.com/JLimperg/aesop"><code>aesop</code></a>), which means less work for
you.</li>
<li>The theorem lookup tactics start to perform noticeable worse with large
proof states, which makes the interactive experience worse.</li>
</ol>
<p>This is not <em>too</em> much of a problem—my proof of submodularity of Matroid
rank functions derived from independence predicates is around 100 lines long
and remained at least <em>usable</em>—but certainly an element of UX that
coincides with good practice: small theorems, like small functions, are
generally easier to work with and this aligns with the practical performance of
Lean&#39;s interactive systems.</p>

<p>Overall, working through these proofs in Lean was a very instructive experience
for me. Being a relative beginner to proof assistants in general (having only
light experience toying with Emacs&#39; <a href="https://proofgeneral.github.io/">Proof
General</a> + <a href="https://coq.inria.fr/">Coq</a> during
grad school), the quality of the LSP and other tools were huge boons. I wish
this had existed while I was working on theory stuff more actively, as it did
help me find issues with on-paper proofs that I&#39;d done which held hidden
assumptions.</p>
<p>That said: it definitely was not a replacement for working on paper for me. The
degree to which Lean encourages small transformations caused me to miss the
forest for the trees in a very direct way. It is useful in verification of
theory, but not a replacement for sitting down with pen, paper, and tea and
working through a proof.</p>
<p>Hopefully these notes will be useful for others looking to use Lean as a proof
assistant (and, perhaps, people who are less committed to constructive theory
and are more than willing to embrace practical niceties like <code>if</code>/<code>else</code> and
<code>not_not</code>).</p>

    </article></div>
  </body>
</html>
