<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://railsatscale.com/2025-09-08-how-ruby-executes-jit-code-the-hidden-mechanics-behind-the-magic/">Original</a>
    <h1>How Ruby executes JIT code</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Ever since YJIT’s introduction, I’ve felt simultaneously close to and distant from Ruby’s JIT compiler. I know how to enable it in my Ruby programs. I know it makes my Ruby programs run faster by compiling some of them into machine code. But my understanding around YJIT, or JIT compilers in Ruby in general, seems to end here.</p>

<p>A few months ago, my colleague <a href="https://bernsteinbear.com/">Max Bernstein</a> wrote <a href="https://railsatscale.com/2025-05-14-merge-zjit/">ZJIT has been merged into Ruby</a> to explain how ZJIT compiles Ruby’s bytecode to HIR, LIR, and then to native code.
It sheds some light on how JIT compilers can compile our program, which is why I started to <a href="https://github.com/ruby/ruby/pulls?q=is%3Apr+author%3Ast0012+ZJIT+">contribute to ZJIT in July</a>.
But I still had many questions unanswered before digging into the source code and asking the JIT experts around me (<a href="https://bernsteinbear.com/">Max</a>, <a href="https://github.com/k0kubun">Kokubun</a>, and <a href="https://alanwu.space/">Alan</a>).</p>

<p>So I want to use this post to answer some questions/mental gaps you might also have about JIT compilers for Ruby:</p>

<ol>
  <li><strong>Where does JIT-compiled code actually live?</strong></li>
  <li><strong>How does Ruby actually execute JIT code?</strong></li>
  <li><strong>How does Ruby decide what to compile?</strong></li>
  <li><strong>Why does JIT-compiled code fall back to the interpreter?</strong></li>
</ol>

<p>While we use ZJIT (Ruby’s experimental next-generation JIT) as our reference, these concepts apply equally to YJIT as well.</p>

<h2 id="where-jit-compiled-code-actually-lives">Where JIT-Compiled Code Actually Lives</h2>

<h3 id="ruby-iseqs-and-yarv-bytecode">Ruby ISEQs and YARV Bytecode</h3>

<p>When Ruby loads your code, it compiles each method into an Instruction Sequence (ISEQ) - a data structure containing <a href="https://en.wikipedia.org/wiki/YARV">YARV</a> (CRuby virtual machine) bytecode instructions.</p>

<p>(If you’re not familiar with YARV instructions or want to learn more, <a href="https://kddnewton.com/">Kevin Newton</a> wrote a <a href="https://kddnewton.com/2022/11/30/advent-of-yarv-part-0.html">great blog series</a> to introduce them)</p>

<p>Let’s start with a simple example:</p>

<div><div><pre><code><span>def</span> <span>foo</span>
  <span>bar</span>
<span>end</span>

<span>def</span> <span>bar</span>
  <span>42</span>
<span>end</span>
</code></pre></div></div>

<p>Running <code>ruby --dump=insn example.rb</code> shows us the bytecode:</p>

<div><div><pre><code>== disasm: #&lt;ISeq:foo@example.rb:1 (1,0)-(3,3)&gt;
0000 putself                                                          (   2)[LiCa]
0001 opt_send_without_block                 &lt;calldata!mid:bar, argc:0, FCALL|VCALL|ARGS_SIMPLE&gt;
0003 leave                                  [Re]

== disasm: #&lt;ISeq:bar@example.rb:5 (5,0)-(7,3)&gt;
0000 putobject                              42                        (   6)[LiCa]
0002 leave                                  [Re]
</code></pre></div></div>

<h3 id="jit-compiled-code-lives-on-iseq-too">JIT-Compiled Code Lives on ISEQ Too</h3>

<p>I assumed JIT-compiled code would replace bytecode—after all, native code is faster. But Ruby keeps both, for good reason.</p>

<p>Here’s what an ISEQ looks like initially:</p>

<div><div><pre><code>ISEQ (foo method)
├── body
│   ├── bytecode: [putself, opt_send_without_block, leave]
│   ├── jit_entry: NULL  // No JIT code yet
│   ├── jit_entry_calls: 0  // Call counter
</code></pre></div></div>

<p>After the method is called repeatedly and gets JIT-compiled:</p>

<div><div><pre><code>ISEQ (foo method)
├── body
│   ├── bytecode: [putself, opt_send_without_block, leave]  // Still here!
│   ├── jit_entry: 0x7f8b2c001000  // Pointer to native machine code
│   ├── jit_entry_calls: 35  // Reached compilation threshold
</code></pre></div></div>

<p>The <code>jit_entry</code> field is the gateway to native code. When it’s NULL, Ruby interprets bytecode. When it points to compiled code, Ruby can jump directly to machine instructions.
But the bytecode never goes away - Ruby needs it for de-optimization, which we will explore a bit later.</p>

<h2 id="the-execution-switch-from-bytecode-to-native-code">The Execution Switch: From Bytecode to Native Code</h2>

<p>This is easier than I expected. Since each ISEQ points to its JIT compiled code when it’s available, Ruby simply
checks the <code>jit_entry</code> field on every ISEQ it’s going to execute:</p>

<p><img src="https://railsatscale.com/2025-09-08-how-ruby-executes-jit-code-the-hidden-mechanics-behind-the-magic/jit-compiled-execution.svg" alt="JIT-compiled code execution"/></p>

<p>When there’s no JIT code (<code>jit_entry</code> is NULL), it continues interpreting. Otherwise, it runs the compiled native code.</p>

<h2 id="how-ruby-decides-what-to-compile">How Ruby Decides What to Compile</h2>

<p>Ruby doesn’t compile methods randomly or all at once. Instead, methods earn compilation through repeated use. In ZJIT, this happens in two phases:</p>

<div><div><pre><code><span>if</span> <span>(</span><span>body</span><span>-&gt;</span><span>jit_entry</span> <span>==</span> <span>NULL</span> <span>&amp;&amp;</span> <span>rb_zjit_enabled_p</span><span>)</span> <span>{</span>
    <span>body</span><span>-&gt;</span><span>jit_entry_calls</span><span>++</span><span>;</span>

    <span>// Phase 1: Profile the method</span>
    <span>if</span> <span>(</span><span>body</span><span>-&gt;</span><span>jit_entry_calls</span> <span>==</span> <span>rb_zjit_profile_threshold</span><span>)</span> <span>{</span>
        <span>rb_zjit_profile_enable</span><span>(</span><span>iseq</span><span>);</span>
    <span>}</span>

    <span>// Phase 2: Compile to native code</span>
    <span>if</span> <span>(</span><span>body</span><span>-&gt;</span><span>jit_entry_calls</span> <span>==</span> <span>rb_zjit_call_threshold</span><span>)</span> <span>{</span>
        <span>rb_zjit_compile_iseq</span><span>(</span><span>iseq</span><span>,</span> <span>false</span><span>);</span>
        <span>// After this, jit_entry points to machine code</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of now, ZJIT’s default profile threshold is <code>25</code> and compile threshold is <code>30</code> (both may change in the future). So a method’s lifecycle may look like this:</p>

<div><div><pre><code>Calls:     0 ─────────── 25 ────────── 30 ─────────────────►
           │              │             │
Mode:      └─ Interpret ──┴── Profile ──┴─ Native Code (JIT compiled)
</code></pre></div></div>

<p>This is why we need to “warm up” the program before we get the peak performance with JIT.</p>

<h3 id="when-jit-code-gives-up-understanding-de-optimization">When JIT Code Gives Up: Understanding De-optimization</h3>

<p>JIT code makes assumptions to run fast. When those assumptions break, Ruby must “de-optimize” - return control to the interpreter. It’s a safety mechanism that ensures your code always produces correct results.</p>

<p>Consider this method:</p>



<p>which would generate these instructions:</p>

<pre><code>== disasm: #&lt;ISeq:add@test.rb:1 (1,0)-(3,3)&gt;
0000 getlocal_WC_0                          a@0                       (   2)[LiCa]
0002 getlocal_WC_0                          b@1
0004 opt_plus                               &lt;calldata!mid:+, argc:1, ARGS_SIMPLE&gt;[CcCr]
0006 leave                                                            (   3)[Re]
</code></pre>

<p>Because Ruby doesn’t know what <code>opt_plus</code> would be called with beforehand, the underlying C function <code>vm_opt_plus</code> needs to handle various classes (like String, Array, Float, Integer, etc.) that can respond to <code>+</code>.</p>

<p>But, if profiling shows <code>add</code> is always called with integers (Fixnums), JIT compilers can generate optimized code that <em>only</em> handles integer addition. But it includes “guards” to check this assumption:</p>

<p><img src="https://railsatscale.com/2025-09-08-how-ruby-executes-jit-code-the-hidden-mechanics-behind-the-magic/jit-deopt.svg" alt="JIT type guard"/></p>

<p>When the assumption is broken, like when <code>add(1.5, 2)</code> is called:</p>

<ol>
  <li>The guard check fails</li>
  <li>JIT code jumps to a “side exit”</li>
  <li>The side exit restores interpreter state (stack, instruction pointer..etc.)</li>
  <li>Control returns to the interpreter</li>
  <li>The interpreter executes <code>opt_plus</code> and calls the <code>vm_opt_plus</code> function</li>
</ol>

<p>Other triggers for falling back include:</p>

<ul>
  <li><strong>TracePoint activation</strong> - TracePoint needs bytecode execution for properly emitting events (more details below)</li>
  <li><strong>Redefined core methods</strong> - Someone changed what <code>+</code> means on Integer</li>
  <li><strong>Ractor usage</strong> - Multi-ractor changes some YARV instruction’s behaviour. So the compiled code could perform differently than the interpreter in that situation</li>
</ul>

<p>These assumption checks, or patch points as we call them in ZJIT, make sure your program performs correctly when any of the assumptions change.</p>

<h2 id="answering-some-additional-questions">Answering Some Additional Questions</h2>

<p><strong>Why does enabling TracePoint slow everything down?</strong></p>

<p>(<a href="https://docs.ruby-lang.org/en/master/TracePoint.html">TracePoint</a> is a Ruby class that can be used to register callbacks on specific Ruby execution events. It’s commonly used in debugging/development tools.)</p>

<p>Most of TracePoint’s events are triggered by corresponding YARV bytecode. When TracePoint is activated, instructions in ISEQs will be replaced with their <code>trace_*</code> counterpart. Like <code>opt_plus</code> will be replaced with <code>trace_opt_plus</code>.</p>

<p>If Ruby only executes the compiled machine code, then those events wouldn’t be triggered correctly. Therefore, when ZJIT and YJIT compilers detect TracePoint’s activation, they immediately throw away the optimized code to force Ruby to interpret YARV instructions instead.</p>

<p><strong>Why doesn’t Ruby just compile everything?</strong></p>

<p>Many methods are called rarely. Compiling them would waste memory and compilation time for no performance benefit. Also, compiling methods without profiling would mean that JIT compilers either make wrong assumptions that get invalidated pretty quickly, or don’t make specific enough assumptions that miss further optimization opportunities.</p>

<h2 id="final-notes">Final Notes</h2>

<p>I hope this post helped you understand JIT compilers, a now essential part of Ruby, a little bit more.</p>

<p>If you want to learn more about Ruby’s new JIT compiler: ZJIT, I highly recommend giving <a href="https://railsatscale.com/2025-05-14-merge-zjit/">ZJIT has been merged into Ruby</a> a read.
And if you want to learn more about Ruby’s YARV instructions, <a href="https://kddnewton.com/">Kevin Newton</a>’s <a href="https://kddnewton.com/2022/11/30/advent-of-yarv-part-0.html">Advent of YARV series</a> is the best resource.</p>


  </div>
</article>

      </div>
    </div></div>
  </body>
</html>
