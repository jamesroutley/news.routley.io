<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gist.github.com/rxliuli/be31cbded41ef7eac6ae0da9070c8ef8">Original</a>
    <h1>Journey to Optimize Cloudflare D1 Database Queries</h1>
    
    <div id="readability-page-1" class="page"><div>
  <div id="file-journey-to-optimize-cloudflare-d1-database-queries-md">
      
      <div id="file-journey-to-optimize-cloudflare-d1-database-queries-md-readme" tabindex="0" role="region" aria-label="journey-to-optimize-cloudflare-d1-database-queries.md content, created by rxliuli on 04:47PM on April 03.">
    <article itemprop="text">

<p dir="auto">Recently, I&#39;ve been working on server-side projects using Cloudflare Workers with D1 database. During this process, I encountered several database-related challenges. Since databases are quite unfamiliar territory for frontend developers, I decided to document my experiences.</p>
<p dir="auto">The image below shows the request records for the past 30 days, revealing dramatic fluctuations in database queries.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d2869ffc66f3fb140137f5df00a20424c6790bb93506588ebffae978e3d0a9b6/68747470733a2f2f626c6f672e72786c69756c692e636f6d2f7265736f75726365732f33313933616166326332623934373964616366333465333930326166356165652e6a7067"><img src="https://camo.githubusercontent.com/d2869ffc66f3fb140137f5df00a20424c6790bb93506588ebffae978e3d0a9b6/68747470733a2f2f626c6f672e72786c69756c692e636f6d2f7265736f75726365732f33313933616166326332623934373964616366333465333930326166356165652e6a7067" alt="Database query fluctuations over 30 days" data-canonical-src="https://blog.rxliuli.com/resources/3193aaf2c2b9479dacf34e3902af5aee.jpg"/></a></p>

<p dir="auto">Solving problems begins with identifying them. Here are several methods that helped me spot issues:</p>
<ol dir="auto">
<li>Monitoring the D1 dashboard to detect anomalies in database operations</li>
<li>Examining query statements and row read/write counts, with special attention to queries with high counts or rows read/written</li>
<li>Using <code>c.env.DB.prepare(&#39;&lt;sql&gt;&#39;).run()).meta</code> to check the returned metadata, which reveals how many rows were actually read/written for each query</li>
</ol>

<p dir="auto">It&#39;s important to understand that while Workers and D1 are both Cloudflare services, using them together doesn&#39;t make D1 faster. For example, a simple query like this has an average response time exceeding 200ms:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>select</span><span>(</span><span>)</span><span>.</span><span>from</span><span>(</span><span>user</span><span>)</span><span>.</span><span>limit</span><span>(</span><span>1</span><span>)</span></pre></div>
<p dir="auto">When an endpoint includes multiple database operations, it&#39;s best to use D1 batch operations, especially for write operations which are even slower than queries due to lack of read-only replicas. For instance, instead of:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>{</span>...<span>}</span><span>)</span>
<span>await</span> <span>db</span><span>.</span><span>insert</span><span>(</span><span>tweet</span><span>)</span><span>.</span><span>values</span><span>(</span><span>{</span>...<span>}</span><span>)</span></pre></div>
<p dir="auto">Use batch operations:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>batch</span><span>(</span><span>[</span>
  <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>{</span>...<span>}</span><span>)</span><span>,</span>
  <span>db</span><span>.</span><span>insert</span><span>(</span><span>tweet</span><span>)</span><span>.</span><span>values</span><span>(</span><span>{</span>...<span>}</span><span>)</span>
<span>]</span><span>)</span></pre></div>
<p dir="auto">This approach requires only a single REST request to D1 to complete multiple database write operations.</p>
<blockquote>
<p dir="auto">Note 1: Prisma doesn&#39;t support D1 batch operations, which led me to switch to Drizzle.
Note 2: Be cautious when using batch for multiple queries, particularly when tables have columns with identical names.</p>
</blockquote>
<div dir="auto"><h2 dir="auto">Excluding IDs from Update Operations</h2><a id="user-content-excluding-ids-from-update-operations" aria-label="Permalink: Excluding IDs from Update Operations" href="#excluding-ids-from-update-operations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">When updating records, it&#39;s important to exclude the ID field (even if it remains unchanged). Consider this code:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>update</span><span>(</span><span>user</span><span>)</span><span>.</span><span>set</span><span>(</span><span>userParam</span><span>)</span><span>.</span><span>where</span><span>(</span><span>eq</span><span>(</span><span>user</span><span>.</span><span>id</span><span>,</span> <span>userParam</span><span>.</span><span>id</span><span>)</span><span>)</span></pre></div>
<p dir="auto">The actual SQL executed:</p>
<div dir="auto"><pre><span>update</span> <span><span>&#34;</span>User<span>&#34;</span></span> <span>set</span> <span><span>&#34;</span>id<span>&#34;</span></span> <span>=</span> ?, <span><span>&#34;</span>screenName<span>&#34;</span></span> <span>=</span> ?, <span><span>&#34;</span>updatedAt<span>&#34;</span></span> <span>=</span> ? <span>where</span> <span><span>&#34;</span>User<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span> <span>=</span> ?</pre></div>
<p dir="auto">If this ID is referenced by foreign keys in other tables, it can lead to a massive number of row reads. For example, if a &#34;tweet&#34; table has a userId field referencing this ID and contains 1,000 records, updating the user with the ID included will cause 2,005 rows to be read instead of just 1.</p>
<p dir="auto">The solution is to explicitly exclude the ID field from updates:</p>
<div dir="auto"><pre><span>const</span> <span>r</span> <span>=</span> <span>await</span> <span>db</span>
  <span>.</span><span>update</span><span>(</span><span>user</span><span>)</span>
  <span>.</span><span>set</span><span>(</span><span>omit</span><span>(</span><span>userParam</span><span>,</span> <span>[</span><span>&#39;id&#39;</span><span>]</span><span>)</span><span>)</span>
  <span>.</span><span>where</span><span>(</span><span>eq</span><span>(</span><span>user</span><span>.</span><span>id</span><span>,</span> <span>userParam</span><span>.</span><span>id</span><span>)</span><span>)</span></pre></div>
<p dir="auto">This properly limits rows read to 1, regardless of how many related records exist.</p>
<div dir="auto"><h2 dir="auto">Avoiding Full Table Scans for Count Queries</h2><a id="user-content-avoiding-full-table-scans-for-count-queries" aria-label="Permalink: Avoiding Full Table Scans for Count Queries" href="#avoiding-full-table-scans-for-count-queries"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">I noticed an SQL statement ranking high in rows read on the D1 dashboard:</p>
<div dir="auto"><pre><span>SELECT</span> <span>count</span>(id) <span>as</span> num_rows <span>FROM</span> <span><span>&#34;</span>User<span>&#34;</span></span>;</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c1d15bdd5ad84cfbbd28941f24c13cf4e60feda054ff910a6c1aab7e83c0e0a9/68747470733a2f2f626c6f672e72786c69756c692e636f6d2f7265736f75726365732f35306264313233373364373334616532383563303131656230373665383038642e6a7067"><img src="https://camo.githubusercontent.com/c1d15bdd5ad84cfbbd28941f24c13cf4e60feda054ff910a6c1aab7e83c0e0a9/68747470733a2f2f626c6f672e72786c69756c692e636f6d2f7265736f75726365732f35306264313233373364373334616532383563303131656230373665383038642e6a7067" alt="demo" data-canonical-src="https://blog.rxliuli.com/resources/50bd12373d734ae285c011eb076e808d.jpg"/></a></p>
<p dir="auto">This led to a significant increase in rows read, so I implemented cursor-based pagination instead of offset-based pagination, and never provided total counts, since counting records scans all rows even with indexed IDs. This is a known issue with D1.</p>
<div dir="auto"><h2 dir="auto">Avoiding Multi-table Left Joins</h2><a id="user-content-avoiding-multi-table-left-joins" aria-label="Permalink: Avoiding Multi-table Left Joins" href="#avoiding-multi-table-left-joins"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">I discovered that a specific SQL query was causing hundreds of thousands of row reads:</p>
<div dir="auto"><pre><span>SELECT</span> <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span>,
       <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>updatedat<span>&#34;</span></span>,
       <span><span>&#34;</span>modlistsubscription<span>&#34;</span></span>.<span><span>&#34;</span>action<span>&#34;</span></span>,
       Json_group_array(DISTINCT <span><span>&#34;</span>modlistuser<span>&#34;</span></span>.<span><span>&#34;</span>twitteruserid<span>&#34;</span></span>),
       Json_group_array(DISTINCT <span><span>&#34;</span>modlistrule<span>&#34;</span></span>.<span><span>&#34;</span>rule<span>&#34;</span></span>)
<span>FROM</span>   <span><span>&#34;</span>modlist<span>&#34;</span></span>
       <span>LEFT JOIN</span> <span><span>&#34;</span>modlistsubscription<span>&#34;</span></span>
              <span>ON</span> <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span> <span>=</span> <span><span>&#34;</span>modlistsubscription<span>&#34;</span></span>.<span><span>&#34;</span>modlistid<span>&#34;</span></span>
       <span>LEFT JOIN</span> <span><span>&#34;</span>modlistuser<span>&#34;</span></span>
              <span>ON</span> <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span> <span>=</span> <span><span>&#34;</span>modlistuser<span>&#34;</span></span>.<span><span>&#34;</span>modlistid<span>&#34;</span></span>
       <span>LEFT JOIN</span> <span><span>&#34;</span>modlistrule<span>&#34;</span></span>
              <span>ON</span> <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span> <span>=</span> <span><span>&#34;</span>modlistrule<span>&#34;</span></span>.<span><span>&#34;</span>modlistid<span>&#34;</span></span>
<span>WHERE</span>  <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span> <span>IN</span> ( ?, ? )
GROUP  BY <span><span>&#34;</span>modlist<span>&#34;</span></span>.<span><span>&#34;</span>id<span>&#34;</span></span>,
          <span><span>&#34;</span>modlistsubscription<span>&#34;</span></span>.<span><span>&#34;</span>action<span>&#34;</span></span>;</pre></div>
<p dir="auto">This query joined four tables, potentially causing a &#34;Cartesian product explosion.&#34; If both modListUser and modListRule tables contain 100 records each, a simple join could yield 10,000 results, which is not the expected behavior.</p>
<p dir="auto">The solution was to split queries and handle grouping and transformation in the application logic:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>batch</span><span>(</span><span>[</span>
  <span>db</span>
    <span>.</span><span>select</span><span>(</span><span>{</span>
      <span>modListId</span>: <span>modListUser</span><span>.</span><span>modListId</span><span>,</span>
      <span>twitterUserId</span>: <span>modListUser</span><span>.</span><span>twitterUserId</span><span>,</span>
    <span>}</span><span>)</span>
    <span>.</span><span>from</span><span>(</span><span>modListUser</span><span>)</span>
    <span>.</span><span>where</span><span>(</span><span>eq</span><span>(</span><span>modListUser</span><span>.</span><span>modListId</span><span>,</span> <span>&#39;modlist-1&#39;</span><span>)</span><span>)</span><span>,</span>
  <span>db</span>
    <span>.</span><span>select</span><span>(</span><span>{</span>
      <span>modListId</span>: <span>modListRule</span><span>.</span><span>modListId</span><span>,</span>
      <span>rule</span>: <span>modListRule</span><span>.</span><span>rule</span><span>,</span>
    <span>}</span><span>)</span>
    <span>.</span><span>from</span><span>(</span><span>modListRule</span><span>)</span>
    <span>.</span><span>where</span><span>(</span><span>eq</span><span>(</span><span>modListRule</span><span>.</span><span>modListId</span><span>,</span> <span>&#39;modlist-1&#39;</span><span>)</span><span>)</span><span>,</span>
<span>]</span><span>)</span> <span>// 200 rows read instead of 10,101</span></pre></div>
<div dir="auto"><h2 dir="auto">Optimizing Multi-Record Inserts</h2><a id="user-content-optimizing-multi-record-inserts" aria-label="Permalink: Optimizing Multi-Record Inserts" href="#optimizing-multi-record-inserts"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For bulk inserts, instead of using:</p>
<div dir="auto"><pre><span>await</span> <span>Promise</span><span>.</span><span>all</span><span>(</span><span>users</span><span>.</span><span>map</span><span>(</span><span>(</span><span>it</span><span>)</span> <span>=&gt;</span> <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>it</span><span>)</span><span>)</span> <span>as</span> <span>any</span><span>)</span></pre></div>
<p dir="auto">Or even:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>batch</span><span>(</span><span>users</span><span>.</span><span>map</span><span>(</span><span>(</span><span>it</span><span>)</span> <span>=&gt;</span> <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>it</span><span>)</span><span>)</span> <span>as</span> <span>any</span><span>)</span></pre></div>
<p dir="auto">I found it more efficient to insert multiple records in a single statement:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>users</span><span>)</span></pre></div>
<p dir="auto">However, SQLite and D1 limit the number of bound parameters to 100 per query. With 10 columns, we can insert at most 10 rows per SQL statement. For larger batches, we need to chunk the data:</p>
<div dir="auto"><pre><span>await</span> <span>db</span><span>.</span><span>batch</span><span>(</span>
  <span>safeChunkInsertValues</span><span>(</span><span>user</span><span>,</span> <span>users</span><span>)</span><span>.</span><span>map</span><span>(</span><span>(</span><span>it</span><span>)</span> <span>=&gt;</span>
    <span>db</span><span>.</span><span>insert</span><span>(</span><span>user</span><span>)</span><span>.</span><span>values</span><span>(</span><span>it</span><span>)</span><span>,</span>
  <span>)</span> <span>as</span> <span>any</span><span>,</span>
<span>)</span></pre></div>
<p dir="auto">Testing this approach with 5,000 records showed a performance improvement from 78ms to 14ms, making this optimization worthwhile.</p>

<p dir="auto">Server-side issues differ significantly from client-side problems. While client-side errors only affect users, server-side errors can directly impact monthly bills and may take time to manifest. Therefore, caution and thorough unit testing are essential.</p>
<p dir="auto">When addressing database query issues, I found it helpful to follow this process: discover, investigate, attempt to solve, monitor, try again if needed, continue monitoring, and then finalize. The first solution attempt may not succeed—it might even make things worse—but continuous monitoring is crucial for timely detection and resolution of issues.</p>
</article>
  </div>

  </div>
</div></div>
  </body>
</html>
