<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://portswigger.net/research/smashing-the-state-machine">Original</a>
    <h1>Smashing the state machine: the true potential of web race conditions</h1>
    
    <div id="readability-page-1" class="page"><div>
    
    
    
<div>
    <p><img alt="James Kettle" src="https://ntietz.com/content/images/profiles/callout_james_kettle_112px.png"/></p>
</div>
    <ul>
        <li>
            <p><span></span><strong>Published: </strong>09 August 2023 at 18:00 UTC</p>
        </li>
        <li>
            <p><strong>Updated: </strong>18 September 2023 at 14:17 UTC</p>
        </li>
        <li>
        </li>
    </ul>
    <p><img src="https://ntietz.com/cms/images/f3/d4/607f-article-state-machine_article.png"/><br/></p><p>For too long, web race condition attacks have focused on a tiny handful of scenarios. Their true potential has been masked thanks to tricky workflows, missing tooling, and simple network jitter hiding all but the most trivial, obvious examples.
</p><p>
In this paper, I&#39;ll introduce new classes of race condition that go far beyond the limit-overrun exploits you&#39;re probably already familiar with. With these I&#39;ll exploit both multiple high-profile websites and Devise, a popular authentication framework for Rails.
</p><p>
I&#39;ll also introduce the single-packet attack; a jitter-dodging strategy that can squeeze 30 requests sent from Melbourne to Dublin into a sub-1ms execution window. This paper is accompanied by a full complement of free online labs, so you&#39;ll be able to try out your new skill set immediately.</p><p>This research paper accompanies a presentation at <a href="https://www.blackhat.com/us-23/briefings/schedule/index.html#smashing-the-state-machine-the-true-potential-of-web-race-conditions-31712" target="_blank">Black Hat USA</a>, <a href="https://defcon.org/html/defcon-31/dc-31-schedule.html#:~:text=Smashing%20the%20state%20machine%3A%20the%20true%20potential%20of%20web%20race%20conditions" target="_blank">DEF CON</a> &amp; <a href="https://nullcon.net/goa-2023/speaker-smashing-the-state-machine-the-true-potential-of-web-race-conditions" target="_blank">Nullcon</a>:</p><p><iframe src="https://www.youtube.com/embed/tKJzsaB1ZvI?origin=https://portswigger.net&amp;rel=0"></iframe></p><p>It is also available in a <a href="https://portswigger.net/kb/papers/rifmwla/racewhitepaper.pdf" target="_blank">print/download-friendly PDF</a> format.</p>
<h3>Outline</h3>
<h3 id="introduction">Background</h3><h4 id="fundamentals">Race condition fundamentals</h4><p>
    To begin, let&#39;s recap race condition fundamentals. I&#39;ll keep this brief - if you&#39;d prefer an in-depth introduction, check out our new <a target="_blank" href="https://portswigger.net/web-security/race-conditions">Web Security Academy topic</a>.
</p><p>Most websites handle concurrent requests using multiple threads, all reading and writing from a single, shared database. Application code is rarely crafted with concurrency risks in mind and as a result, <a href="https://ntietz.com/web-security/race-conditions">race conditions</a> plague the web. Exploits are typically limit-overrun attacks - they use synchronized requests to overcome some kind of limit, for example:</p><ul>    <li>Redeeming a gift card multiple times</li>    <li><a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-limit-overrun">Repeatedly applying a single discount code</a></li>    <li>Rating a product multiple times</li>    <li>Withdrawing or transferring cash in excess of your account balance</li>    <li><a target="_blank" href="https://portswigger.net/research/cracking-recaptcha-turbo-intruder-style">Reusing a single CAPTCHA solution</a></li>    <li><a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-bypassing-rate-limits">Bypassing an anti-bruteforce rate-limit</a></li></ul><p>The underlying cause of these is also similar - they all exploit the time-gap between the security check and the protected action. For example, two threads may simultaneously query a database and confirm that the <span>TOP10</span> discount code hasn&#39;t been applied to the cart, then both attempt to apply the discount, resulting in it being applied twice.
    You&#39;ll often find these referred to as &#39;time of check, time of use&#39; (TOCTOU) flaws for this reason.
</p><p>Please note that race-conditions are not limited to a specific web-app architecture. It&#39;s easiest to reason about a multi-threaded single-database application, but more complex setups typically end up with state stored in even more places, and ORMs just hide the dangers under layers of abstraction. Single-threaded systems like NodeJS are slightly less exposed, but can still end up vulnerable.</p>
<h4 id="beyond-limit-overrun">Beyond limit-overrun exploits</h4><p>I used to think race conditions were a well-understood problem. I had discovered and exploited plenty, implemented the &#39;last-byte sync&#39; technique in Turbo Intruder, and used that to exploit various targets <a target="_blank" href="https://portswigger.net/research/cracking-recaptcha-turbo-intruder-style">including Google reCAPTCHA</a>. Over time, Turbo Intruder has become the de-facto tool for hunting web race conditions.
</p><p>However, there was one thing I didn&#39;t understand. A <a target="_blank" href="https://www.josipfranjkovic.com/blog/race-conditions-on-web">blog post from 2016</a> by Josip Franjković detailed four vulnerabilities, and while three of them made perfect sense to me, one didn&#39;t. In the post, Josip explained how he <span>&#34;somehow succeeded to confirm a random email address&#34;</span> by accident, and neither he nor Facebook&#39;s security team were able to identify the cause until two months later. The bug? Changing your Facebook email address to two different addresses simultaneously could trigger an email containing two distinct confirmation codes, one for each address: </p><p><code>/confirmemail.php?e=user@gmail.com&amp;c=13475&amp;code=84751</code></p><p>
I had never seen a finding like this before, and it confounded every attempt to visualize what might be happening server-side. One thing was for sure - this wasn&#39;t a limit-overrun.
</p><p>
Seven years later, I decided to try and figure out what happened.
</p>


<h4 id="true-potential">The true potential of web race conditions</h4><p>The true potential of race conditions can be summed up in a single sentence. Every pentester knows that multi-step sequences are a hotbed for vulnerabilities, but <span>with race conditions, everything is multi-step</span>.</p><p>
To illustrate this, let&#39;s plot the state machine for a serious vulnerability that I discovered by accident a while back. When a user logged in, they were presented with a &#39;role selection&#39; page containing a range of buttons that would assign a role, and redirect to a specific application. The request flow looked something like:</p><table>
    <tbody>
    <tr><td>POST /login</td><td>302 Found</td></tr>
    <tr><td>GET /role</td><td>200 Found</td></tr>
    <tr><td>POST /role</td><td>302 Found</td></tr>
    <tr><td>GET /application </td><td>200 OK</td></tr>
    </tbody>
</table>
<p>In my head, the state machine for the user&#39;s role looked like this:</p><p><img src="https://ntietz.com/cms/images/53/8c/286a-article-blackhat_diagrams-01.png"/><br/></p><p>I attempted to elevate privileges by forcibly browsing directly from the role selection page to an application without selecting a role, but this didn&#39;t work and so I concluded that it was secure.
</p><p>However, this state machine had a mistake. I had incorrectly assumed that the <span>GET /role</span> request didn&#39;t change the application state. In actual fact, the application was initialising every session with administrator privileges, then overwriting them as soon as the browser fetched the role selection page. Here&#39;s an accurate state machine:
</p><p><img src="https://ntietz.com/cms/images/a2/67/43dd-article-blackhat_diagrams-02.png"/><br/></p><p>By refusing to follow the redirect to /role and skipping straight to an application, anyone could gain super-admin privileges.
</p><p>I only discovered this through extreme luck, and it took me hours of retrospective log digging to figure out the cause. This vulnerability pattern is frankly a weird one, but we can learn something valuable from the near-miss. </p>
<p>My primary mistake was the assumption that the GET request wouldn&#39;t change the application state. However, there&#39;s a second assumption that&#39;s even more common - that &#34;requests are atomic&#34;. If we ditch this assumption too, we realize this pattern could occur <span>in the span of a single login request</span>:</p><p><img src="https://ntietz.com/cms/images/2d/23/4445-article-blackhat_diagrams-03.png"/><br/></p>
<p>This scenario captures the essence of &#39;with race conditions, everything is multi-step&#39;. Every HTTP request may transition an application through multiple fleeting, hidden states, which I&#39;ll refer to as &#39;sub-states&#39;. If you time it right, you can abuse these sub-states for unintended transitions, break business logic, and achieve high-impact exploits. Let&#39;s get started.
</p>

<h3 id="single-packet-attack">Single-packet attack</h3>
<p>A sub-state is a short-lived state that an application transitions through while processing a single request, and exits before the request completes. Sub-states are only occupied for a brief time window - often around 1ms (0.001s). I&#39;ll refer to this time window as the &#39;race window&#39;.</p><p>To discover a sub-state, you need an initial HTTP request to trigger a transition through the sub-state, and a second request that interacts with the same resource during the race window. For example, to discover the vulnerability mentioned earlier you would send a request to log in, and a second request that attempted to access the admin panel. Vulnerabilities with small race windows have historically been extremely difficult to discover thanks to network jitter. Jitter erratically delays the arrival of TCP packets, making it tricky to get multiple requests to arrive close together, even when using techniques like last-byte sync:
</p><p><img src="https://ntietz.com/cms/images/f9/1e/4365-article-blackhat_diagrams-07.png"/><br/></p><p>In search of a solution, I&#39;ve developed the &#39;single-packet attack&#39;. Using this technique, you can make 20-30 requests arrive at the server simultaneously - regardless of network jitter:</p><p><img src="https://ntietz.com/cms/images/b6/d6/9239-article-blackhat_diagrams-08.png"/><br/></p><p>I implemented the single-packet attack in the open-source Burp Suite extension <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder">Turbo Intruder</a>. To benchmark it, I repeatedly sent a batch of 20 requests 17,000km from Melbourne to Dublin, and measured the gap between the start-of-execution timestamp of the first and last request in each batch. I&#39;ve published the benchmark scripts in <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/">the examples folder</a> so you can try them for yourself if you like.
</p>
<table>
    <tbody>
    <tr><th>Technique</th><th>Median spread</th><th>Standard deviation</th></tr>
    <tr><td>Last-byte sync</td><td>4ms</td><td>3ms</td></tr>
    <tr><td>Single-packet attack</td><td>1ms</td><td>0.3ms</td></tr>
    </tbody>
</table>
<p>By these measures, the single-packet attack is 4 to 10 times more effective. When replicating one real-world vulnerability, the single-packet attack was successful after around 30 seconds, and last-byte sync took over two hours.</p>
<p>One great side effect of this is that we&#39;ve been able to launch a Web Security Academy topic containing labs with realistic race windows, without alienating users who live far away from our servers or have high-jitter connections. You can try the single-packet attack out for yourself by tackling our <a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-limit-overrun">limit-overrun lab</a> with the <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/race-single-packet-attack.py">single-packet-attack.py</a> Turbo Intruder template. The race-window on this lab ended up so small that exploitation is near-impossible using multiple packets. It&#39;s also available in Repeater via the new &#39;Send group in parallel&#39; option in Burp Suite.
</p>
<p>Let&#39;s take a look under the hood.</p>
<h4 id="under-the-hood">Developing the single-packet attack</h4>
<p>The single-packet attack was inspired by the 2020 USENIX presentation <a target="_blank" href="https://www.usenix.org/conference/usenixsecurity20/presentation/van-goethem">Timeless Timing Attacks</a>. In that presentation, they place two entire HTTP/2 requests into a single TCP packet, then look at the response order to compare the server-side processing time of the two requests:</p><p><img src="https://ntietz.com/cms/images/05/e7/9c53-article-blackhat_diagrams-13.png"/></p><p>This is a novel possibility with HTTP/2 because it allows HTTP requests to be sent over a single connection
    concurrently, whereas in HTTP/1.1 they have to be sequential.</p>
<p>The use of a single TCP packet completely eliminates the effect of network jitter, so this clearly has potential for
    race condition attacks too. However, two requests isn&#39;t enough for a reliable race attack thanks to server-side
    jitter - variations in the application&#39;s request-processing time caused by uncontrollable variables like CPU
    contention.</p>
<p>I spotted an opportunity to adapt a trick from the HTTP/1.1 &#39;last-byte sync&#39; technique. Since servers only process a request once they regard it as complete, maybe by withholding a tiny
    fragment from each request we could pre-send the bulk of the data, then &#39;complete&#39; 20-30 requests with a single TCP
    packet:</p>
<p><img src="https://ntietz.com/cms/images/af/9a/d56c-article-blackhat_diagrams-14.png"/><br/></p>
<p>After a few weeks of experimenting, I&#39;d built an implementation that worked on all tested HTTP/2 servers.</p>
<h4 id="rolling-your-own">Rolling your own implementation
</h4><p>This concept is honestly pretty obvious, and after implementing it I discovered someone else had the same idea <a target="_blank" href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/47110/master_Papli_Kaspar_2020.pdf">back in 2020</a>, but nobody noticed at the time and their algorithm &amp; implementation didn&#39;t receive the polish, testing and integration essential to prove its true value. The reason I&#39;m so excited about the single-packet attack is that it&#39;s powerful, universal, and trivial. Even after spending months refining it to work on all major webservers the algorithm is still so simple it fits on a single page, and so easy to implement that I expect it to end up in all major web testing tools.</p><p>The primary reason it&#39;s so easy to implement is that thanks to some creative abuse of <a target="_blank" href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle&#39;s algorithm</a>, it doesn&#39;t require a custom TCP or TLS stack. You can just pick an HTTP/2 library to hook into (trust me, coding your own is not much fun), and apply the following steps:</p><p>First, pre-send the bulk of each request:</p><ul><li>If the request has no body, send all the headers, but don&#39;t set the END_STREAM flag. Withhold an empty data frame with END_STREAM set.</li><li>If the request has a body, send the headers and all the body data except the final byte.
    Withhold a data frame containing the final byte.</li></ul><p>You might be tempted to send the full body and rely on not sending END_STREAM, but this will break on certain HTTP/2 server implementations that use the content-length header to decide when a message is complete, as opposed to waiting for END_STREAM.</p><p>Next, prepare to send the final frames:</p><ul><li>Wait for 100ms to ensure the initial frames have been sent.</li>    <li>Ensure TCP_NODELAY is disabled - it&#39;s crucial that Nagle&#39;s algorithm batches the final frames.</li>    <li>Send a ping packet to warm the local connection. If you don&#39;t do this, the OS network stack will place the first final-frame in a separate packet.
</li></ul><p>Finally, send the withheld frames. You should be able to verify that they landed in a single packet using Wireshark.</p><p>This approach worked on all dynamic endpoints on all tested servers. It doesn&#39;t work for static files on certain servers but as static files aren&#39;t relevant to race condition attacks, I haven&#39;t attempted to find a workaround for this. In Turbo Intruder, the static-file quirk results in a negative timestamp as the response is received before the request is completed. This behavior can be used as a way of testing if a file is static or not.</p><p>If you&#39;re not sure which HTTP/2 stack to build on, I think Golang&#39;s might be a good choice - I&#39;ve seen that successfully extended for advanced HTTP/2 attacks in the past. If you&#39;d like to see a reference implementation in Kotlin, feel free to use Turbo Intruder. The relevant code can be found in <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/src/SpikeEngine.kt">SpikeEngine</a> and <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/src/SpikeConnection.kt">SpikeConnection</a>.</p><h4>Adapting to the target architecture</h4><p>It&#39;s worth noting that many applications sit behind a front-end server, and these may decide to forward some requests over existing connections to the back-end, and to create fresh connections for others.
</p><p>As a result, it&#39;s important not to attribute inconsistent request timing to application behavior such as locking mechanisms that only allow a single thread to access a resource at once. Also, front-end request routing is often done on a per-connection basis, so you may be able to smooth request timing by performing server-side connection warming - sending a few inconsequential requests down your connection before performing the attack. You can try this technique out for yourself on our <a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-multi-endpoint">multi-endpoint lab</a>.</p>
<h3 id="methodology">Methodology</h3><p>Now that we&#39;ve established &#39;everything is multi-step&#39;, and developed a technique to allow accurate request synchronization and make race conditions reliable, it&#39;s time to start hunting vulnerabilities. Classic limit-overrun vulnerabilities can be discovered using a trivial methodology: identify a limit, and try to overrun it. Discovering exploitable sub-states for more advanced attacks is not quite so simple.</p><p>Over months of testing, I&#39;ve developed the following black-box methodology to help. I recommend using this approach even if you have source-code access; in my experience it&#39;s extremely challenging to identify race conditions through pure code analysis.</p><p><img src="https://ntietz.com/cms/images/2f/d3/9618-article-blackhat_diagrams-06.png"/><br/></p>
<h4 id="predict">Predict potential collisions</h4><p>Prediction is about efficiency. Since everything is multi-step, ideally we&#39;d test every possible combination of endpoints on the entire website. This is impractical - instead, we need to predict where vulnerabilities are likely to occur. One tempting approach is to simply try and find replicas of the vulnerabilities described in this paper later on - this is nice and easy, but you&#39;ll miss out on exciting, undiscovered variants.</p><p>To start, identify objects with security controls that you&#39;d like to bypass. This will typically include users and
    sessions, plus some business-specific concepts like orders.</p><p>For each object, we then need to identify all the endpoints that either write to it, or read data from it and then use that data for something important. For example, users might be stored in a
    database table that is modified by registration, profile-edits, password reset initiation, and password reset
    completion. Also, a website&#39;s login functionality might read critical data from the users table when creating sessions.</p>
<p>A race condition vulnerability requires a &#39;collision&#39; - two concurrent operations on a shared resource. We can use
three key questions to rule out endpoints that are unlikely to cause collisions. For each object and the
associated endpoints, ask:
</p>
<h5>1) How is the state stored?</h5>
<p>Data that&#39;s stored in a persistent server-side data structure is ideal for exploitation. Some endpoints
    store their state entirely client-side, such as password resets that work by emailing a JWT - these can be safely
    skipped.</p>
<p>Applications will often store some state in the user session. These are often somewhat protected against sub-states -
    more on that later.</p>
<h5>2) Are we editing or appending?</h5><p>Operations that edit existing data (such as changing an account&#39;s primary email address) have ample collision potential, whereas actions that simply append to existing data (such as adding an additional email address) are unlikely to be vulnerable to anything other than limit-overrun attacks.
</p>
<h5>3) What&#39;s the operation keyed on?</h5>
<p>Most endpoints operate on a specific record, which is looked up using a &#39;key&#39;, such as a username, password reset
token, or filename. For a successful attack, we need two operations that use the same key. For example, picture two
plausible password reset implementations:
</p><p><img src="https://ntietz.com/cms/images/2e/8d/494e-article-collision.png"/><br/></p><p>In the first implementation, the user&#39;s password reset token is stored in the <span>users</span> table in the database, and the supplied <span>userid</span> acts as the key. If an attacker uses two requests to trigger a reset for two different userids at the same time, two different database records will be altered so there&#39;s no potential for a collision. By identifying the key, you&#39;ve identified that this attack is probably not worth attempting. </p>
<p>In the second implementation, the state is stored in the user&#39;s session, and the token-storage operation is keyed on the user&#39;s sessionid. If an attacker uses two requests to trigger a reset for two different emails at the same time, both threads will attempt to alter the same session&#39;s <span>token</span> and <span>userid</span> attributes, and the session may end up containing one user&#39;s <span>userid</span>, and a <span>token</span> that was sent to the other user.</p>


<h4 id="probe">Probe for clues</h4><p>Now that we&#39;ve selected some high-value endpoints, it&#39;s time to probe for clues - hints that hidden sub-states exist. We don&#39;t need to cause a meaningful exploit yet - our objective at this point is simply to evoke a clue. As such, you&#39;ll want to send a large number of requests to maximize the chance of visible side-effects, and mitigate server-side jitter. Think of this as a chaos-based strategy - if we see something interesting, we&#39;ll figure out what actually happened later.</p>
<p>Prepare your blend of requests, targeting endpoints and parameters to trigger all relevant code paths. Where possible, use multiple requests to trigger each code path multiple times, with different input values.</p>
<p>Next, benchmark how the endpoints behave under normal conditions by sending your request-blend with a few seconds between each request.</p>
<p>Finally, use the single-packet attack (or last-byte sync if HTTP/2 isn&#39;t supported) to issue all the requests at once. You can do this in Turbo Intruder using the single-packet-attack template, or in Repeater using the &#39;Send group in parallel&#39; option.</p><p>Analyze the results and look for clues in the form of any deviation from the benchmarked behavior. This could be a change in one or more responses, or a second-order effect like different email contents or a visible change in your session. Clues can be subtle and counterintuitive so if you skip the benchmark step, you&#39;ll miss vulnerabilities.
</p><p>Pretty much anything can be a clue, but pay close attention to the request processing time. If it&#39;s shorter than you&#39;d expect, this can indicate that data is being passed to a separate thread, greatly increasing the chances of a vulnerability. If it&#39;s longer than you expect, that could indicate resource limits - or that the application is using locking to avoid concurrency issues. Note that PHP locks on the sessionid by default, so you need to use a separate session for every request in your batch or they&#39;ll get processed sequentially.
</p><h4 id="prove">Prove the concept</h4><p>If you spot a clue, the final step is to prove the concept and turn it into a viable attack. The exact steps here will depend on the attack you&#39;re attempting, but there are a few general pointers that may be useful:</p>
<p>When you send a batch of requests, you may find that an early request pair triggers a vulnerable end-state, but later requests overwrite/invalidate it and the final state is unexploitable. In this scenario, you&#39;ll want to eliminate all unnecessary requests - two should be sufficient for exploiting most vulnerabilities. </p>
<p>Dropping to two requests will make the attack more timing-sensitive, so you may need to retry the attack multiple times or automate it. On a couple of targets I ended up writing a Turbo Intruder script to repeatedly trigger emails, retrieve them from Burp Collaborator, and extract and visit the links within. You can find an example in the <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/email-link-extraction.py">email-extraction template</a>.</p>
<p>Finally, don&#39;t forget to escalate! Think of each race condition as a structural weakness, rather than an isolated vulnerability. Advanced race conditions can cause unusual and unique primitives, so the path to maximum impact isn&#39;t always obvious. For example, in one case I ended up with different endpoints on a single website disagreeing about what my email address was. During this research I personally missed out on ~$5k due to overlooking one exploit avenue until after the vulnerability was patched.
</p>
<h3 id="case-studies">Case studies</h3><p>Let&#39;s take a look at the methodology and tooling in action, with some real-life case studies. These vulnerabilities are focused on email-related functionality, as my primary objective was to understand the mysterious Facebook exploit.</p><p>First, a disclaimer. During research, I usually accrue a large number of case studies affecting high-profile companies by using automation to test tens of thousands of sites. Race conditions aren&#39;t suitable for this scale of automation, so every example that follows is brought to you by hours of mostly manual testing. On the bright side, this means I&#39;ve tested only a tiny proportion of websites with bug bounty programs, and left a lot of money on the table for everyone else.</p>
<h4 id="object-masking">Object masking via limit-overrun</h4><p>We&#39;ll start with an object masking vulnerability in Gitlab. Gitlab lets you invite users to administer projects via their email address. I decided to try a probe with six identical requests:</p>
<p><code>POST /api/…/invitations HTTP/2
...
{&#34;email&#34;:&#34;x@psres.net&#34;}</code></p><p>To build a baseline, I sent these requests sequentially with a small delay between each. This resulted in the response <span>{&#34;status&#34;:&#34;success&#34;}</span> six times, and one invitation email.</p>
<p>Next, I sent the requests simultaneously, using the single-packet attack. This resulted in one response containing <span>{&#34;status&#34;:&#34;success&#34;}</span>, five responses saying <span>{&#34;message&#34;:&#34;The member&#39;s email address has already been taken&#34;}</span>, and two emails.</p>
<p>Receiving two emails from six requests is a clear clue that I&#39;ve hit a sub-state, and further testing is warranted. The difference in the responses is also a clue. Note that if I hadn&#39;t benchmarked Gitlab&#39;s baseline behavior, I wouldn&#39;t have regarded the five &#34;The member&#39;s email address has already been taken&#34; responses as suspicious. Finally, there was also a second-order clue: after an attack, any attempt to edit the resulting invitation triggered an error.</p>
<p>After some more digging, I was able to arrive at a low-severity exploit. The page that lists active invitations only displays one invitation for a given email address. Using the race condition, I was able to create a dummy low-privilege invitation which gets replaced by an admin-level invitation if it&#39;s revoked.</p>
<p>The impact here wasn&#39;t great, but it hinted at deeper problems to come.</p>




<h4 id="multi-endpoint">Multi-endpoint collisions</h4>
<p>Classic multi-step exploits can provide inspiration for race condition attacks. While testing an online shop a while ago, I discovered that I could start a purchase flow, pay for my order, and then add an extra item to my basket before I loaded the order confirmation page - effectively getting the extra item for free. We later made a <a target="_blank" href="https://portswigger.net/web-security/logic-flaws/examples/lab-logic-flaws-insufficient-workflow-validation">replica of this vulnerability</a> for training purposes.</p>
<p>There&#39;s a <a target="_blank" href="https://soroush.secproject.com/downloadable/common-security-issues-in-financially-orientated-web-applications.pdf">documented</a> race condition variation of this attack that can occur when the payment and order confirmation are performed by a single request.</p><p><img src="https://ntietz.com/cms/images/df/1e/1b65-article-basket.png"/></p><p>On Gitlab, emails are important. The ability to &#39;verify&#39; an email address you don&#39;t own would let you gain administrator access to other projects by hijacking pending invitations. Furthermore, since Gitlab acts as an <a href="https://ntietz.com/web-security/oauth/openid">OpenID</a> IDP, it could also be abused to hijack accounts on third-party websites that naively trust Gitlab&#39;s email verification.</p>
<p>The basket attack might not sound relevant to exploiting Gitlab, but I realized that when visualized, Gitlab&#39;s email verification flow looks awfully similar:</p>
<p><img src="https://ntietz.com/cms/images/31/9a/abcf-article-blackhat_diagrams-05.png"/><br/></p><p>Perhaps by verifying an email address and changing it at the same time, I could trick Gitlab into incorrectly marking the wrong address as verified?<br/></p><p>When I attempted this attack, I noticed that the confirmation operation was executing before the email-change every time. This suggested that the email-change endpoint was doing more processing than the email-confirmation endpoint before it hit the vulnerable sub-state, so sending the two requests in sync was missing the race window:</p><p><img src="https://ntietz.com/cms/images/bb/ea/3162-article-multiendpoint.png"/></p><p>Delaying the confirmation request by 90ms fixed the issue, and achieved a 50/50 spread between the email-change landing first, and the email-confirmation landing first.</p>
<p>Note that adding a client-side delay means you can&#39;t use the single-packet attack, so on high-jitter targets it won&#39;t work reliably regardless of what delay you set:</p><p><img src="https://ntietz.com/cms/images/8e/3d/2eb6-article-client-sidedelay.png"/></p><p>If you encounter this problem, you may be able to solve it by abusing a common security feature. Webservers often have &#39;leaky bucket&#39; rate-limits which delay processing of requests if they&#39;re sent too quickly. You can abuse this by sending a large number of dummy requests to trigger the rate-limit and cause a server-side delay, making the single-packet attack viable even when delayed execution is required:</p><p><img src="https://ntietz.com/cms/images/68/3c/1592-article-delay.png"/></p><p>Back on Gitlab, lining the race window up revealed two clues - the email confirmation request intermittently triggered a 500 Internal Server Error, and sometimes the confirmation token was sent to the wrong address! Unfortunately, the misdirected code was only valid for confirming the already-confirmed address, making it useless.</p>
<p>Still, thanks to the misdirected code we know there&#39;s at least one sub-state hidden inside Gitlab&#39;s email-change endpoint. Maybe we just need a different angle to exploit this?</p>

<h4 id="single-endpoint">Single-endpoint collisions</h4><p>Race conditions thrive on complexity - they get progressively more likely the more data gets saved, written, read, altered, and handed off between classes, threads, and processes. When an endpoint is sufficiently complex, you don&#39;t even need any other endpoints to cause an exploitable collision. </p>
<p>On Gitlab, I noticed that when I tried to change my email address, the response time was 220ms - faster than I&#39;d expect for an operation that sends an email. This hinted that the email might be sent by a different thread - exactly the kind of complexity we need.</p>
<p>I decided to probe Gitlab by changing my account&#39;s email address to two different addresses at the same time:</p>
<p><span>
<code>POST /-/profile HTTP/2</code></span></p><p>This revealed a massive clue:</p><p><code>To: <span>test2</span>@psres.net
Subject: Confirmation instructions

           <span>test1</span>@psres.net

Click the link below to confirm your email address.

        <span>Confirm your email address</span></code></p><p>The address the message was sent to didn&#39;t always match the address in the body. Crucially, the confirmation token in the misrouted email was often valid. By submitting two requests, containing my own email address and albinowaxed@gitlab.com, I was able to obtain the latter as a validated address. You can still <a target="_blank" href="https://gitlab.com/albinowax1">view it on my profile</a>.</p><p>More importantly, this unlocked the invitation-hijacking and OpenID attacks mentioned earlier.
</p><p>I&#39;ve recorded a video demonstrating the full discovery process on a remote Gitlab installation:</p><p><iframe src="https://www.youtube.com/embed/Y0NVIVucQNE?origin=https://portswigger.net&amp;rel=0" allowfullscreen="allowfullscreen"></iframe></p></div></div>
  </body>
</html>
