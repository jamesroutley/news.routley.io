<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gitlab.com/gnachman/iterm2/-/issues/11470#note_1917647951">Original</a>
    <h1>iTerm2 removes AI feature from core, creates separate plugin</h1>
    
    <div id="readability-page-1" class="page">




<header data-testid="navbar">
<a href="#content-body">Skip to content</a>

</header>

<div>


<div>


<div>
<main id="content-body" itemscope="" itemtype="http://schema.org/SoftwareSourceCode">








<div>
<div>
<div data-header-actions-data="{&#34;can_create_issue&#34;:&#34;true&#34;,&#34;can_create_incident&#34;:&#34;false&#34;,&#34;can_destroy_issue&#34;:&#34;false&#34;,&#34;can_reopen_issue&#34;:&#34;false&#34;,&#34;can_report_spam&#34;:&#34;&#34;,&#34;can_update_issue&#34;:&#34;false&#34;,&#34;is_issue_author&#34;:&#34;false&#34;,&#34;issue_path&#34;:&#34;/gnachman/iterm2/-/issues/11470&#34;,&#34;new_issue_path&#34;:&#34;/gnachman/iterm2/-/issues/new?add_related_issue=11470&#34;,&#34;project_path&#34;:&#34;gnachman/iterm2&#34;,&#34;report_abuse_path&#34;:&#34;/-/abuse_reports/add_category&#34;,&#34;reported_user_id&#34;:2387536,&#34;reported_from_url&#34;:&#34;https://gitlab.com/gnachman/iterm2/-/issues/11470&#34;,&#34;submit_as_spam_path&#34;:&#34;/gnachman/iterm2/-/issues/11470/mark_as_spam&#34;,&#34;issuable_email_address&#34;:null,&#34;can_promote_to_epic&#34;:&#34;false&#34;}" data-initial="{&#34;endpoint&#34;:&#34;/gnachman/iterm2/-/issues/11470&#34;,&#34;updateEndpoint&#34;:&#34;/gnachman/iterm2/-/issues/11470.json&#34;,&#34;canUpdate&#34;:false,&#34;canDestroy&#34;:false,&#34;issuableRef&#34;:&#34;#11470&#34;,&#34;imported&#34;:false,&#34;markdownPreviewPath&#34;:&#34;/gnachman/iterm2/preview_markdown?target_id=11470\u0026target_type=Issue&#34;,&#34;markdownDocsPath&#34;:&#34;/help/user/markdown&#34;,&#34;lockVersion&#34;:0,&#34;issuableTemplateNamesPath&#34;:&#34;/gnachman/iterm2/description_templates/names/issue&#34;,&#34;initialTitleHtml&#34;:&#34;Provide a build without ChatGPT integration&#34;,&#34;initialTitleText&#34;:&#34;Provide a build without ChatGPT integration&#34;,&#34;initialDescriptionHtml&#34;:&#34;\u003ch1 data-sourcepos=\&#34;1:1-1:17\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003ca href=\&#34;#feature-request\&#34; aria-hidden=\&#34;true\&#34; class=\&#34;anchor\&#34; id=\&#34;user-content-feature-request\&#34;\u003e\u003c/a\u003eFeature Request\u003c/h1\u003e\u0026#x000A;\u003ch2 data-sourcepos=\&#34;3:1-3:10\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003ca href=\&#34;#summary\&#34; aria-hidden=\&#34;true\&#34; class=\&#34;anchor\&#34; id=\&#34;user-content-summary\&#34;\u003e\u003c/a\u003eSummary\u003c/h2\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;5:1-5:118\&#34; dir=\&#34;auto\&#34;\u003eI just found this is the \u003ca data-sourcepos=\&#34;5:26-5:100\&#34; href=\&#34;https://iterm2.com/downloads/stable/iTerm2-3_5_0.changelog\&#34; rel=\&#34;nofollow noreferrer noopener\&#34; target=\&#34;_blank\&#34;\u003erelease notes\u003c/a\u003e for iTerm2 3.5.0:\u003c/p\u003e\u0026#x000A;\u003cdiv class=\&#34;gl-relative markdown-code-block js-markdown-code\&#34;\u003e\u0026#x000A;\u003cpre data-sourcepos=\&#34;7:1-12:3\&#34; class=\&#34;code highlight js-syntax-highlight language-plaintext\&#34; v-pre=\&#34;true\&#34;\u003e\u003ccode\u003e\u003cspan id=\&#34;LC1\&#34; class=\&#34;line\&#34; lang=\&#34;plaintext\&#34;\u003e- Using OpenAI&#39;s ChatGPT API, iTerm2 can now write\u003c/span\u003e\u0026#x000A;\u003cspan id=\&#34;LC2\&#34; class=\&#34;line\&#34; lang=\&#34;plaintext\&#34;\u003e  commands for you, interpret the output of\u003c/span\u003e\u0026#x000A;\u003cspan id=\&#34;LC3\&#34; class=\&#34;line\&#34; lang=\&#34;plaintext\&#34;\u003e  commands, and guide you towards a goal. See the\u003c/span\u003e\u0026#x000A;\u003cspan id=\&#34;LC4\&#34; class=\&#34;line\&#34; lang=\&#34;plaintext\&#34;\u003e  AI section below for details.\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u0026#x000A;\u003ccopy-code\u003e\u003c/copy-code\u003e\u0026#x000A;\u003c/div\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;14:1-14:81\&#34; dir=\&#34;auto\&#34;\u003eSadly, this makes iTerm2 completely untenable for me. Do I have to spell out why?\u003c/p\u003e\u0026#x000A;\u003cul data-sourcepos=\&#34;16:1-18:0\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;16:1-16:89\&#34;\u003eThere is a risk that everything I type is being sent to someone else&#39;s server somewhere\u003c/li\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;17:1-18:0\&#34;\u003eThere is a risk that some LLM-generated random spew is \u003cem data-sourcepos=\&#34;17:58-17:78\&#34;\u003etyped into my shell\u003c/em\u003e and \u003cem data-sourcepos=\&#34;17:84-17:93\&#34;\u003eexecuted\u003c/em\u003e ?! (possibly as root)\u003c/li\u003e\u0026#x000A;\u003c/ul\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;19:1-19:142\&#34; dir=\&#34;auto\&#34;\u003eI don&#39;t care if there&#39;s a buried flag that enables or disables this behaviour. I want a binary that doesn&#39;t have this capability in it at all.\u003c/p\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;21:1-21:275\&#34; dir=\&#34;auto\&#34;\u003eI haven&#39;t donated to iTerm2, but I would \u003cem data-sourcepos=\&#34;21:42-21:46\&#34;\u003epay\u003c/em\u003e for a version which \u003cem data-sourcepos=\&#34;21:68-21:76\&#34;\u003edoesn&#39;t\u003c/em\u003e have any remote communication capability in it (no OpenAI, no remote syntax highlighting or remote autocomplete or web search or mail reader). If I want remote communication, I&#39;ll use ssh thank you.\u003c/p\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;23:1-23:284\&#34; dir=\&#34;auto\&#34;\u003eAside: recent Apple CPUs do have a \&#34;neural engine\&#34;, but I&#39;m also not interested in downloading a multi-gigabyte LLM and running it locally. As far as I&#39;m concerned, the job of a terminal program is to take what I type and submit it to the system, and to print what the system returns.\u003c/p\u003e\u0026#x000A;\u003ch2 data-sourcepos=\&#34;25:1-25:15\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003ca href=\&#34;#alternatives\&#34; aria-hidden=\&#34;true\&#34; class=\&#34;anchor\&#34; id=\&#34;user-content-alternatives\&#34;\u003e\u003c/a\u003eAlternatives\u003c/h2\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;27:1-27:192\&#34; dir=\&#34;auto\&#34;\u003eI have now disabled \&#34;Check for updates automatically\&#34; in iTerm2 Settings (General \u0026gt; Services) so that I don&#39;t get 3.5.0, but it&#39;s obviously not sustainable long-term to stay on 3.4.23 forever.\u003c/p\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;29:1-29:50\&#34; dir=\&#34;auto\&#34;\u003eI will possibly have to go back to Apple Terminal.\u003c/p\u003e\u0026#x000A;\u003ch2 data-sourcepos=\&#34;31:1-31:11\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003ca href=\&#34;#concerns\&#34; aria-hidden=\&#34;true\&#34; class=\&#34;anchor\&#34; id=\&#34;user-content-concerns\&#34;\u003e\u003c/a\u003eConcerns\u003c/h2\u003e\u0026#x000A;\u003cul data-sourcepos=\&#34;33:1-38:0\&#34; dir=\&#34;auto\&#34;\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;33:1-33:19\&#34;\u003ePrivacy - obvious\u003c/li\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;34:1-34:18\&#34;\u003eComplexity - yes\u003c/li\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;35:1-38:0\&#34;\u003eIs this an instance of a more general problem? - yes\u0026#x000A;\u003col data-sourcepos=\&#34;36:5-38:0\&#34;\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;36:5-36:44\&#34;\u003etoo much LLM integration in the world\u003c/li\u003e\u0026#x000A;\u003cli data-sourcepos=\&#34;37:5-38:0\&#34;\u003etoo much creeping featurism in software in general\u003c/li\u003e\u0026#x000A;\u003c/ol\u003e\u0026#x000A;\u003c/li\u003e\u0026#x000A;\u003c/ul\u003e\u0026#x000A;\u003cp data-sourcepos=\&#34;39:1-39:62\&#34; dir=\&#34;auto\&#34;\u003eThis message was composed using my brain. No LLM was involved.\u003c/p\u003e\u0026#x000A;\u003chr data-sourcepos=\&#34;41:1-41:3\&#34;\u003e&#34;,&#34;initialDescriptionText&#34;:&#34;# Feature Request\n\n## Summary\n\nI just found this is the [release notes](https://iterm2.com/downloads/stable/iTerm2-3_5_0.changelog) for iTerm2 3.5.0:\n\n```\n- Using OpenAI&#39;s ChatGPT API, iTerm2 can now write\n  commands for you, interpret the output of\n  commands, and guide you towards a goal. See the\n  AI section below for details.\n```\n\nSadly, this makes iTerm2 completely untenable for me. Do I have to spell out why?\n\n* There is a risk that everything I type is being sent to someone else&#39;s server somewhere\n* There is a risk that some LLM-generated random spew is *typed into my shell* and *executed* ?! (possibly as root)\n\nI don&#39;t care if there&#39;s a buried flag that enables or disables this behaviour. I want a binary that doesn&#39;t have this capability in it at all.\n\nI haven&#39;t donated to iTerm2, but I would *pay* for a version which *doesn&#39;t* have any remote communication capability in it (no OpenAI, no remote syntax highlighting or remote autocomplete or web search or mail reader). If I want remote communication, I&#39;ll use ssh thank you.\n\nAside: recent Apple CPUs do have a \&#34;neural engine\&#34;, but I&#39;m also not interested in downloading a multi-gigabyte LLM and running it locally. As far as I&#39;m concerned, the job of a terminal program is to take what I type and submit it to the system, and to print what the system returns.\n\n## Alternatives\n\nI have now disabled \&#34;Check for updates automatically\&#34; in iTerm2 Settings (General \u003e Services) so that I don&#39;t get 3.5.0, but it&#39;s obviously not sustainable long-term to stay on 3.4.23 forever.\n\nI will possibly have to go back to Apple Terminal.\n\n## Concerns\n\n* Privacy - obvious\n* Complexity - yes\n* Is this an instance of a more general problem? - yes\n    1. too much LLM integration in the world\n    2. too much creeping featurism in software in general\n\nThis message was composed using my brain. No LLM was involved.\n\n---&#34;,&#34;initialTaskCompletionStatus&#34;:{&#34;count&#34;:0,&#34;completed_count&#34;:0},&#34;canCreateIncident&#34;:false,&#34;fullPath&#34;:&#34;gnachman/iterm2&#34;,&#34;iid&#34;:11470,&#34;issuableId&#34;:146826039,&#34;issueType&#34;:&#34;issue&#34;,&#34;isHidden&#34;:false,&#34;zoomMeetingUrl&#34;:null,&#34;authorId&#34;:2387536,&#34;authorName&#34;:&#34;Brian Candler&#34;,&#34;authorUsername&#34;:&#34;candlerb&#34;,&#34;authorWebUrl&#34;:&#34;/candlerb&#34;,&#34;createdAt&#34;:&#34;2024-05-21T07:51:55+00:00&#34;,&#34;isFirstContribution&#34;:false,&#34;serviceDeskReplyTo&#34;:null,&#34;registerPath&#34;:&#34;/users/sign_up?redirect_to_referer=yes&#34;,&#34;signInPath&#34;:&#34;/users/sign_in?redirect_to_referer=yes&#34;,&#34;publishedIncidentUrl&#34;:null,&#34;slaFeatureAvailable&#34;:&#34;false&#34;,&#34;uploadMetricsFeatureAvailable&#34;:&#34;false&#34;,&#34;projectId&#34;:252461,&#34;projectPath&#34;:&#34;iterm2&#34;,&#34;projectNamespace&#34;:&#34;gnachman&#34;,&#34;canAdmin&#34;:false,&#34;hasIssueWeightsFeature&#34;:true,&#34;hasIterationsFeature&#34;:true,&#34;canAdminRelation&#34;:false}" id="js-issuable-app">

<div>
<div>
<h2 data-sourcepos="3:1-3:10" dir="auto">
<a href="#summary" aria-hidden="true" id="user-content-summary"></a>Summary</h2>
<p data-sourcepos="5:1-5:118" dir="auto">I just found this is the <a data-sourcepos="5:26-5:100" href="https://iterm2.com/downloads/stable/iTerm2-3_5_0.changelog" rel="nofollow noreferrer noopener" target="_blank">release notes</a> for iTerm2 3.5.0:</p>
<div>
<pre data-sourcepos="7:1-12:3" v-pre="true"><code><span id="LC1" lang="plaintext">- Using OpenAI&#39;s ChatGPT API, iTerm2 can now write</span>
<span id="LC2" lang="plaintext">  commands for you, interpret the output of</span>
<span id="LC3" lang="plaintext">  commands, and guide you towards a goal. See the</span>
<span id="LC4" lang="plaintext">  AI section below for details.</span></code></pre>
<copy-code></copy-code>
</div>
<p data-sourcepos="14:1-14:81" dir="auto">Sadly, this makes iTerm2 completely untenable for me. Do I have to spell out why?</p>
<ul data-sourcepos="16:1-18:0" dir="auto">
<li data-sourcepos="16:1-16:89">There is a risk that everything I type is being sent to someone else&#39;s server somewhere</li>
<li data-sourcepos="17:1-18:0">There is a risk that some LLM-generated random spew is <em data-sourcepos="17:58-17:78">typed into my shell</em> and <em data-sourcepos="17:84-17:93">executed</em> ?! (possibly as root)</li>
</ul>
<p data-sourcepos="19:1-19:142" dir="auto">I don&#39;t care if there&#39;s a buried flag that enables or disables this behaviour. I want a binary that doesn&#39;t have this capability in it at all.</p>
<p data-sourcepos="21:1-21:275" dir="auto">I haven&#39;t donated to iTerm2, but I would <em data-sourcepos="21:42-21:46">pay</em> for a version which <em data-sourcepos="21:68-21:76">doesn&#39;t</em> have any remote communication capability in it (no OpenAI, no remote syntax highlighting or remote autocomplete or web search or mail reader). If I want remote communication, I&#39;ll use ssh thank you.</p>
<p data-sourcepos="23:1-23:284" dir="auto">Aside: recent Apple CPUs do have a &#34;neural engine&#34;, but I&#39;m also not interested in downloading a multi-gigabyte LLM and running it locally. As far as I&#39;m concerned, the job of a terminal program is to take what I type and submit it to the system, and to print what the system returns.</p>
<h2 data-sourcepos="25:1-25:15" dir="auto">
<a href="#alternatives" aria-hidden="true" id="user-content-alternatives"></a>Alternatives</h2>
<p data-sourcepos="27:1-27:192" dir="auto">I have now disabled &#34;Check for updates automatically&#34; in iTerm2 Settings (General &gt; Services) so that I don&#39;t get 3.5.0, but it&#39;s obviously not sustainable long-term to stay on 3.4.23 forever.</p>
<p data-sourcepos="29:1-29:50" dir="auto">I will possibly have to go back to Apple Terminal.</p>
<h2 data-sourcepos="31:1-31:11" dir="auto">
<a href="#concerns" aria-hidden="true" id="user-content-concerns"></a>Concerns</h2>
<ul data-sourcepos="33:1-38:0" dir="auto">
<li data-sourcepos="33:1-33:19">Privacy - obvious</li>
<li data-sourcepos="34:1-34:18">Complexity - yes</li>
<li data-sourcepos="35:1-38:0">Is this an instance of a more general problem? - yes
<ol data-sourcepos="36:5-38:0">
<li data-sourcepos="36:5-36:44">too much LLM integration in the world</li>
<li data-sourcepos="37:5-38:0">too much creeping featurism in software in general</li>
</ol>
</li>
</ul>
<p data-sourcepos="39:1-39:62" dir="auto">This message was composed using my brain. No LLM was involved.</p>
<hr data-sourcepos="41:1-41:3"/></div>
</div>

</div>

</div>


</div>




</main>
</div>


</div>
</div>








</div>
  </body>
</html>
