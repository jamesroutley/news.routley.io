<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://registerspill.thorstenball.com/p/from-1s-to-4ms">Original</a>
    <h1>Zed Editor: All Occurrences Search from 1s to 4ms</h1>
    
    <div id="readability-page-1" class="page"><div><div><article><div class=""><div><div dir="auto"><p><span>When Zed was open-sourced, someone on HackerNews </span><a href="https://news.ycombinator.com/item?id=39122280" rel="">commented</a><span> that Sublime Text is faster when searching for all occurrences of the current word in a buffer. Zed takes 1s and Sublime something around 200ms.</span></p><p><span>Searching all occurrences means: you position your cursor over a word, you hit </span><code>cmd-shift-l</code><span> and all occurrences of that word in the current buffer are selected and you get a cursor at each occurrence, ready to play some multi-cursor rock’n’roll.</span></p><p>Here, watch this:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif" width="800" height="647" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:647,&#34;width&#34;:800,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:2065942,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/gif&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9a8002f-5366-4ffc-9ff4-f2acb2f371b3_800x647.gif 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a></figure></div><p>So, Sublime does this in 200ms and Zed takes 1s? Huh.</p><p><a href="https://twitter.com/as__cii" rel="">Antonio</a><span>, one of Zed’s co-founders, immediately and confidently said “we can make this faster.” My not-yet-too-familiar-with-the-codebase mind silently asked “can we?” before we dove in. Little did my mind know.</span></p><p><span>We looked at </span><a href="https://github.com/zed-industries/zed/blob/8cc7a023906a283b91b84bd790106500497779aa/crates/editor/src/editor.rs#L6065-L6087" rel="">the code in question</a><span>. Here it is, in its original, takes-1s form:</span></p><pre><code><code> pub fn select_all_matches(
     &amp;mut self,
     action: &amp;SelectAllMatches,
     cx: &amp;mut ViewContext&lt;Self&gt;
 ) -&gt; Result&lt;()&gt; {
        self.push_to_selection_history();
        let display_map = self.display_map.update(cx, |map, cx| map.snapshot(cx));

        loop {
            self.select_next_match_internal(&amp;display_map, action.replace_newest, cx)?;

            if self.select_next_state.as_ref().map(|selection_state| selection_state.done).unwrap_or(true)
            {
                break;
            }
        }

        Ok(())
    }</code></code></pre><p><span>Ignore the details. What’s important is that keyword right in the middle: </span><code>loop</code><span>. The code is probably what many people would naturally do to implement a </span><code>select_all_matches</code><span> method: use the </span><code>select_next_match</code><span> in a loop until there’s no more matches to select. Voilà, all matches selected.</span></p><p><span>When looking at it with Antonio, I knew this code as well as you do right now, but he knew what’s going on under the hood. His idea: optimize it by inlining what </span><code>select_next_match_internal</code><span> does and then do it in batches.</span></p><p>It’s similar to how you’d optimize an N+1 query in a web application. Instead of doing something like this in your request path:</p><pre><code><code>loop {
  user = loadNextUser()
  if user == null {
    break
  }
  profilePicture = loadUserProfilePicture(user)
  blogPosts = loadLastFiveBlogPosts(user)

  render_template(&#34;user_profile&#34;, user)
}</code></code></pre><p>you would do this:</p><pre><code><code>users = loadAllUsers()
pictures = loadUserProfilePicturesForUsers(users)
blogPosts = loadLastFiveBlogPostsForUsers(users)
for user in users {
  render_template(&#34;user_profile&#34;, user)
}</code></code></pre><p>Or something like that. You get the idea.</p><p><span>And that’s what we did with that piece of code from above. I’m going to show you what </span><a href="https://github.com/zed-industries/zed/pull/6700" rel="">we ended up with</a><span>, but before you look at the code, keep in mind the following: don’t worry about the details! Just read the code like you’d read instructions for a new toothbrush: confident you don’t need know the line-by-line, but curious nonetheless (because, hey, maybe you’ve done it wrong all your life):</span></p><pre><code><code>pub fn select_all_matches(
    &amp;mut self,
    _action: &amp;SelectAllMatches,
    cx: &amp;mut ViewContext&lt;Self&gt;,
) -&gt; Result&lt;()&gt; {
    self.push_to_selection_history();
    let display_map = self.display_map.update(cx, |map, cx| map.snapshot(cx));

    self.select_next_match_internal(&amp;display_map, false, None, cx)?;
    let Some(select_next_state) = self.select_next_state.as_mut() else {
        return Ok(());
    };
    if select_next_state.done {
        return Ok(());
    }

    let mut new_selections = self.selections.all::&lt;usize&gt;(cx);

    let buffer = &amp;display_map.buffer_snapshot;
    let query_matches = select_next_state
        .query
        .stream_find_iter(buffer.bytes_in_range(0..buffer.len()));

    for query_match in query_matches {
        let query_match = query_match.unwrap(); // can only fail due to I/O
        let offset_range = query_match.start()..query_match.end();
        let display_range = offset_range.start.to_display_point(&amp;display_map)
            ..offset_range.end.to_display_point(&amp;display_map);

        if !select_next_state.wordwise
            || (!movement::is_inside_word(&amp;display_map, display_range.start)
                &amp;&amp; !movement::is_inside_word(&amp;display_map, display_range.end))
            {
                self.selections.change_with(cx, |selections| {
                    new_selections.push(Selection {
                        id: selections.new_selection_id(),
                        start: offset_range.start,
                        end: offset_range.end,
                        reversed: false,
                        goal: SelectionGoal::None,
                    });
                });
            }
    }

    new_selections.sort_by_key(|selection| selection.start);
    let mut ix = 0;
    while ix + 1 &lt; new_selections.len() {
        let current_selection = &amp;new_selections[ix];
        let next_selection = &amp;new_selections[ix + 1];
        if current_selection.range().overlaps(&amp;next_selection.range()) {
            if current_selection.id &lt; next_selection.id {
                new_selections.remove(ix + 1);
            } else {
                new_selections.remove(ix);
            }
        } else {
            ix += 1;
        }
    }

    select_next_state.done = true;
    self.unfold_ranges(
        new_selections.iter().map(|selection| selection.range()),
        false, false, cx,
    );
    self.change_selections(Some(Autoscroll::fit()), cx, |selections| {
        selections.select(new_selections)
    });

    Ok(())
}</code></code></pre><p>70 lines of code on an empty stomach without syntax highlighting — I’m sorry. But even if you’ve never seen code that’s similar to this bit here, I’m pretty sure you understood what’s happening:</p><ol><li><p>Check whether we even have a next selection, return if not.</p></li><li><p><span>Get all current selections in the buffer (</span><code>let mut new_selections = …</code><span>)</span></p></li><li><p><span>Find all matches in the current buffer (</span><code>select_next_state.query.stream_find_iter</code><span>)</span></p></li><li><p><span>For each match: add it to </span><code>new_selections</code><span>, modulo some word-boundary checks.</span></p></li><li><p>Sort the selections and remove overlapping ones.</p></li><li><p>Unfold code that contains selections.</p></li><li><p><span>Change the selections in the editor to the ones we just constructed (</span><code>self.change_selections</code><span>), which causes them to be rendered.</span></p></li></ol><p><span>Except for that </span><code>while</code><span>-loop in the middle that does some wicked </span><code>plus-1</code><span>-ing (that I surely would’ve messed up but Antonio didn’t) — it’s pretty high-level, right?</span></p><p>It doesn’t even look optimized. There’s none of the scars that optimized code usually wears: no secondary data structures to save another loop, no falling-down to raw pointers carnage, no SIMD, no fancy data structures introduced. None of that.</p><p>Here’s the thing, though. Here’s why I’m showing you this and why I’ve thought about this code for the last three weeks.</p><p><span>When we ran the optimized code for the first time the runtime went from 1s </span><em>down to 4ms</em><span>. 4 milliseconds!</span></p><p><span>I couldn’t believe it. 4ms! With code that’s still this high-level! With the </span><code>unfold_ranges</code><span> call, with finding all the matches, with checking word boundaries, with extending and sorting and possibly dropping and rendering selections — 4ms!</span></p><p><span>If you’re reading this and shrugging it off with “so what, 4ms is an eternity for computers” then yes, you’re right, 4ms </span><em>is</em><span> an eternity for computers, yes, I agree, </span><em>but</em><span> based on that reaction I bet that you didn’t grew up like I did as a programmer. See, I grew up building websites, web applications, backends, that kind of stuff and in that world basically </span><em>nothing</em><span> takes 4ms. If it takes me 10ms to ping the closest data center in Frankfurt, how can I deliver something to you over the wire in less than that?</span></p><p>So there I was, staring at the 4ms and wondering: is this what the Rust enthusiasts mean when they say zero-cost abstractions? Yes, we’ve all heard that claim before (and yes: maybe too many times) and I’ve also written Rust for years now, so the idea that Rust is fast wasn’t new to me.</p><p><span>But seeing high-level code like this find </span><a href="https://github.com/zed-industries/zed/issues/6440" rel="">2351 occurrences of </a><code>&lt;span</code><a href="https://github.com/zed-industries/zed/issues/6440" rel=""> in a 5184 lines XML file that contains the collected poetry of Edgar Allan Poe</a><span> </span><em>in 4ms</em><span>?</span></p><p>I don’t know, man. I think it might have changed me.</p></div></div></div></article></div></div></div>
  </body>
</html>
