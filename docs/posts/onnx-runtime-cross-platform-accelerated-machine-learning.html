<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://onnxruntime.ai/">Original</a>
    <h1>ONNX runtime: Cross-platform accelerated machine learning</h1>
    
    <div id="readability-page-1" class="page"><div>
										<div id="v-pills-tabContent">
											<div id="v-pills-python" role="tabpanel" aria-labelledby="v-pills-python-tab">
												<pre><code>import onnxruntime as ort

# Load the model and create InferenceSession
model_path = &#34;path/to/your/onnx/model&#34;
session = ort.InferenceSession(model_path)

# Load and preprocess the input image inputTensor
...

# Run inference
outputs = session.run(None, {&#34;input&#34;: inputTensor})
print(outputs)</code>
<a href="https://onnxruntime.ai/docs/get-started/with-python"><i></i> Learn more</a>
											</pre>
											</div>
											<div id="v-pills-java" role="tabpanel" aria-labelledby="v-pills-java-tab">
												<pre><code>import ai.onnxruntime.*;

// Load the model and create InferenceSession
String modelPath = &#34;path/to/your/onnx/model&#34;;
OrtEnvironment env = OrtEnvironment.getEnvironment();
OrtSession session = env.createSession(modelPath);

// Load and preprocess the input image inputTensor
...

// Run inference
OrtSession.Result outputs = session.run(inputTensor);
System.out.println(outputs.get(0).getTensor().getFloatBuffer().get(0));</code>
<a href="https://onnxruntime.ai/docs/get-started/with-java"><i></i> Learn more</a>
											</pre>
											</div>
											<div id="v-pills-javascript" role="tabpanel" aria-labelledby="v-pills-javascript-tab">
												<pre><code>import * as ort from &#34;onnxruntime-web&#34;;

// Load the model and create InferenceSession
const modelPath = &#34;path/to/your/onnx/model&#34;;
const session = await ort.InferenceSession.create(modelPath);

// Load and preprocess the input image to inputTensor
...

// Run inference
const outputs = await session.run({ input: inputTensor });
console.log(outputs);</code>
<a href="https://onnxruntime.ai/docs/get-started/with-javascript"><i></i> Learn more</a>
											</pre>
											</div>
											<div id="v-pills-cpp" role="tabpanel" aria-labelledby="v-pills-cpp-tab">
												<pre><code>#include &#34;onnxruntime_cxx_api.h&#34;

// Load the model and create InferenceSession
Ort::Env env;
std::string model_path = &#34;path/to/your/onnx/model&#34;;
Ort::Session session(env, model_path, Ort::SessionOptions{ nullptr });

// Load and preprocess the input image to 
// inputTensor, inputNames, and outputNames
...

// Run inference
std::vector<ort::value> outputTensors =
 session.Run(Ort::RunOptions{nullptr}, 
 			inputNames.data(), 
			&amp;inputTensor, 
			inputNames.size(), 
			outputNames.data(), 
			outputNames.size());

const float* outputDataPtr = outputTensors[0].GetTensorMutableData<float>();
std::cout &lt;&lt; outputDataPtr[0] &lt;&lt; std::endl;</float></ort::value></code>
<a href="https://onnxruntime.ai/docs/get-started/with-cpp"><i></i> Learn more</a>
											</pre>
											</div>
											<div id="v-pills-cs" role="tabpanel" aria-labelledby="v-pills-cs-tab">
												<pre><code>using Microsoft.ML.OnnxRuntime;

// Load the model and create InferenceSession
string model_path = &#34;path/to/your/onnx/model&#34;;
var session = new InferenceSession(model_path);

// Load and preprocess the input image to inputTensor
...

// Run inference
var outputs = session.Run(inputTensor).ToList();
Console.WriteLine(outputs[0].AsTensor<float>()[0]);</float></code>
<a href="https://onnxruntime.ai/docs/get-started/with-csharp"><i></i> Learn more</a>
											</pre>
											</div>
										</div>
									</div></div>
  </body>
</html>
