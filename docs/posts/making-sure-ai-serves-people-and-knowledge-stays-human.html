<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://diff.wikimedia.org/2025/09/30/making-sure-ai-serves-people-and-knowledge-stays-human-wikimedia-foundation-publishes-a-human-rights-impact-assessment-on-the-interaction-of-ai-and-machine-learning-with-wikimedia-projects/">Original</a>
    <h1>Making sure AI serves people and knowledge stays human</h1>
    
    <div id="readability-page-1" class="page"><article id="post-174601">
	<div>
		<!-- .entry-header -->

		
			<!-- .post-thumbnail -->

		
		<div>
			


<p>At the Wikimedia Foundation, <a href="https://diff.wikimedia.org/2021/12/09/what-the-wikimedia-foundations-new-human-rights-policy-means-for-our-movement/">we believe</a> that access to knowledge is a human right. Our mission is to ensure everyone, everywhere can access and share reliable information freely and openly on Wikipedia and other Wikimedia projects. Access to free and open knowledge, supported by the fundamental right to freedom of expression, empowers people to exercise many other rights enshrined in the <a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">Universal Declaration of Human Rights</a>, including the rights to education, artistic expression, economic advancement, and political participation. Today, we are sharing <a href="https://meta.wikimedia.org/wiki/Wikimedia_Foundation_Artificial_Intelligence_and_Machine_Learning_Human_Rights_Impact_Assessment">a human rights impact assessment (HRIA) on artificial intelligence (AI) and machine learning (ML)</a> that was carried out in 2024 to help the Foundation and Wikimedia volunteer communities better understand how these technologies may affect the exercise of human rights in our ecosystem.</p>



<ul>
<li>What, if any, role should AI play in terms of the knowledge shared on Wikimedia projects?</li>



<li>Given the widespread use of generative AI on the internet, how can we protect and strengthen the accuracy and integrity of knowledge on the Wikimedia projects? </li>



<li>How can ML and AI tools help strengthen, not replace, what humans do best: creating, cultivating, and sharing free knowledge?</li>



<li>How can LLMs and AI tools be used to translate content into new languages, while preserving reliability and cultural nuance and context?</li>



<li>How should the volunteer communities’ policies evolve to account for such uses of these new technologies?</li>
</ul>



<h2><strong><strong><strong>About the AI/ML Human Rights Impact Assessment (HRIA)</strong></strong></strong></h2>



<p>This HRIA is the latest outcome of the Foundation’s ongoing efforts to meet our <a href="https://foundation.wikimedia.org/wiki/Policy:Wikimedia_Human_Rights_Policy">commitment</a> to protect and uphold the human rights of all those who interact with Wikimedia projects. The Foundation commissioned it to identify and analyze the impacts, opportunities, and risks emanating from the use of AI and ML technologies in the Wikimedia ecosystem. The report was written and compiled by <a href="https://taraazresearch.org/">Taraaz Research</a>, a specialized research and advocacy organization working at the intersection of technology and human rights. In developing the report, Taraaz consulted Foundation staff, individual volunteers, volunteer affiliates, civil society organizations, and external subject matter experts, though the report does not represent the views or shared consensus of any of these groups. Instead, the report offers suggestions for further inquiry, policy, and technology investment based on the state of the Wikimedia projects and technology from October 2023 to August 2024 when the research was conducted. Furthermore, the findings in the report represent potential areas of risk and opportunity. The report does not identify any actual observed risks, harms, opportunities, or benefits that have resulted from the use of ML or AI technologies on Wikimedia projects.</p>



<h2><strong><strong><strong>What are the findings of this report?</strong></strong></strong></h2>



<p>This report considered risks emanating from three different categories of issues relating to AI/ML on Wikimedia projects: tools developed in-house by Foundation staff to support the work of volunteer editors; Generative AI (GenAI) and its potential for marginal human rights risks in the Wikimedia context; and content on Wikimedia projects that may be used for external machine learning (ML) development.</p>



<h2><strong><strong><strong>What does this HRIA report mean for the Wikimedia projects and volunteer communities?</strong></strong></strong></h2>



<p>Since we <a href="https://diff.wikimedia.org/2022/07/12/what-does-the-wikimedia-foundations-human-rights-impact-assessment-mean-for-the-wikimedia-movement/">published</a> our first HRIA in July 2022, the Foundation has been clear that implementing many of these reports’ recommendations requires the buy-in and collaboration of the global volunteer communities. It will take time to discuss this HRIA’s findings and recommendations with the volunteer communities in order to decide how best to work together on their implementation, but our actions will be more effective for having done so.</p>



<h2><strong><strong><strong>How can Wikimedians learn more and give feedback?</strong></strong></strong></h2>



<p>We want to hear from you! What questions do you have? What are your thoughts on the risks and recommendations discussed in the report? What is your community already doing, or what would you like to do, to responsibly harness the benefits of AI and ML on Wikimedia projects?</p>



<ul>
<li><a href="https://wikimedia.zoom.us/webinar/register/WN_9qwyMXETTwugi0R9uhqvEw">21 November (12:00 UTC): Global Advocacy Community Conversation Hour</a></li>



<li><a href="https://wikimedia.zoom.us/webinar/register/WN_vmFR3DM4QqqMF6I6fhLHxA">21 November (17:00 UTC): Global Advocacy Community Conversation Hour </a></li>
</ul>
				<div id="translate-post">
					<p><img src="https://diff.wikimedia.org/wp-content/themes/interconnection/assets/images/translate-post.jpg" alt=""/>
					</p>

					<div>
						<h2>Can you help us translate this article?</h2>

						<p>In order for this article to reach as many people as possible we would like your help. Can you translate this article to get the message out?</p>

													<p><a href="https://diff.wikimedia.org/wp-login.php?redirect_to=%2F2025%2F09%2F30%2Fmaking-sure-ai-serves-people-and-knowledge-stays-human-wikimedia-foundation-publishes-a-human-rights-impact-assessment-on-the-interaction-of-ai-and-machine-learning-with-wikimedia-projects%2F%23translate-post">Start translation</a>
												</p></div>
				</div>
				
		</div><!-- .entry-content -->
	</div>

	<!-- .entry-footer -->

</article></div>
  </body>
</html>
