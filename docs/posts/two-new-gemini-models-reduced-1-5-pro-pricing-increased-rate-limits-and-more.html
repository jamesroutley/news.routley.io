<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/">Original</a>
    <h1>Two new Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more</h1>
    
    <div id="readability-page-1" class="page"><div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Logan+Kilpatrick">Logan Kilpatrick</a>
            
              <span>Senior Product Manager</span>
            
            
              <span>Gemini API and Google AI Studio</span>
            
          </p>
        
          
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <p data-block-key="hf05d">Today, we’re releasing two updated production-ready Gemini models: <b><i>Gemini-1.5-Pro-002</i></b> and <b><i>Gemini-1.5-Flash-002</i></b> along with:</p><ul><li data-block-key="36s1">&gt;50% reduced price on 1.5 Pro (both input and output for prompts &lt;128K)</li><li data-block-key="1uea">2x higher rate limits on 1.5 Flash and ~3x higher on 1.5 Pro</li><li data-block-key="o65m">2x faster output and 3x lower latency</li><li data-block-key="12oqm">Updated default filter settings</li></ul><p data-block-key="694mg">These new models build on our latest experimental model releases and include meaningful improvements to the Gemini 1.5 models released at Google I/O in May. Developers can access our latest models for free via <a href="https://aistudio.google.com/app/prompts/new_chat?model=gemini-1.5-pro-002">Google AI Studio</a> and the <a href="https://ai.google.dev/gemini-api/docs/models/gemini">Gemini API</a>. For larger organizations and Google Cloud customers, the models are also available on <a href="https://cloud.google.com/vertex-ai">Vertex AI</a>.</p><h3 data-block-key="7ehg"><b></b></h3><p data-block-key="6afk8">The Gemini 1.5 series are models that are designed for general performance across a wide range of text, code, and multimodal tasks. For example, Gemini models can be used to synthesize information from 1000 page PDFs, answer questions about repos containing more than 10 thousand lines of code, take in hour long videos and create useful content from them, and more.</p><p data-block-key="5f8nb">With the latest updates, 1.5 Pro and Flash are now better, faster, and more cost-efficient to build with in production. We see a ~7% increase in MMLU-Pro, a more challenging version of the popular MMLU benchmark. On MATH and HiddenMath (an internal holdout set of competition math problems) benchmarks, both models have made a considerable ~20% improvement. For vision and code use cases, both models also perform better (ranging from ~2-7%) across evals measuring visual understanding and Python code generation.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_jBYRI1Z.original.png" alt="A table showcasing benchmark data, demonstrating improved performance for the latest Gemini models, Gemini 1.5 Pro and Gemini 1.5 Flash. The table highlights advancements in various capabilities including reasoning, code, and math"/>
        
        
    </p>
</div>
  <div>
    <p data-block-key="hf05d">We also improved the overall helpfulness of model responses, while continuing to uphold our content safety policies and standards. This means less punting/fewer refusals and more helpful responses across many topics.</p><p data-block-key="2peu8">Both models now have a more concise style in response to developer feedback which is intended to make these models easier to use and reduce costs. For use cases like summarization, question answering, and extraction, the default output length of the updated models is ~5-20% shorter than previous models. For chat-based products where users might prefer longer responses by default, you can read our <a href="https://ai.google.dev/gemini-api/docs/prompting-strategies#define-the-format-of-the-response">prompting strategies guide</a> to learn more about how to make the models more verbose and conversational.</p><p data-block-key="be8d5">For more details on migrating to the latest versions of Gemini 1.5 Pro and 1.5 Flash, check out the <a href="https://ai.google.dev/gemini-api/docs/models/gemini">Gemini API models page</a>.</p><h3 data-block-key="5c9ku"><b></b></h3><p data-block-key="1hich">We continue to be blown away with the creative and useful applications of Gemini 1.5 Pro’s 2 million token <a href="https://ai.google.dev/gemini-api/docs/long-context">long context window</a> and multimodal capabilities. From video understanding to <a href="https://ai.google.dev/gemini-api/docs/document-processing">processing 1000 page PDFs</a>, there are so many new use cases still to be built. Today we are announcing a 64% price reduction on input tokens, a 52% price reduction on output tokens, and a 64% price reduction on incremental cached tokens for our strongest 1.5 series model, Gemini 1.5 Pro, <a href="https://ai.google.dev/pricing">effective October 1st, 2024</a>, on prompts less than 128K tokens. Coupled with <a href="https://ai.google.dev/gemini-api/docs/caching">context caching</a>, this continues to drive the cost of building with Gemini down.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_HKWM8vn.original.png" alt="A pricing table for the Gemini 1.5 Flash model, outlining the cost per one million tokens for input and output"/>
        
        
    </p>
</div>
  <div>
    <h3 data-block-key="hf05d"><b>Increased rate limits</b></h3><p data-block-key="5lvio">To make it even easier for developers to build with Gemini, we are increasing the paid tier rate limits for 1.5 Flash to 2,000 RPM and increasing 1.5 Pro to 1,000 RPM, up from 1,000 and 360, respectively. In the coming weeks, we expect to continue to increase the <a href="https://ai.google.dev/pricing">Gemini API rate limits</a> so developers can build more with Gemini.</p><h3 data-block-key="20apm"><b></b></h3><p data-block-key="5l45o">Along with core improvements to our latest models, over the last few weeks we have driven down the latency with 1.5 Flash and significantly increased the output tokens per second, enabling new use cases with our most powerful models.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_HthRi7g.original.png" alt="Side-by-side graphs charting the latency of Google&#39;s Gemini model over time, showing improvements."/>
        
        
    </p>
</div>
  <div>
    <h3 data-block-key="hf05d"><b>Updated filter settings</b></h3><p data-block-key="68n0j">Since the first launch of Gemini in December of 2023, <a href="https://ai.google.dev/gemini-api/docs/safety-guidance">building a safe</a> and reliable model has been a key focus. With the latest versions of Gemini (-002 models), we’ve made improvements to the model&#39;s ability to follow user instructions while balancing safety. We will continue to offer a suite of <a href="https://ai.google.dev/gemini-api/docs/safety-settings">safety filters</a> that developers may apply to Google’s models. For the models released today, the filters will not be applied by default so that developers can determine the configuration best suited for their use case.</p><h3 data-block-key="cncp4"><b></b></h3><p data-block-key="epr5n">We are releasing a further improved version of the Gemini 1.5 model we announced in August called “Gemini-1.5-Flash-8B-Exp-0924.” This improved version includes significant performance increases across both text and multimodal use cases. It is available now via Google AI Studio and the Gemini API.</p><p data-block-key="4md6d">The overwhelmingly positive feedback developers have shared about 1.5 Flash-8B has been incredible to see, and we will continue to shape our experimental to production release pipeline based on developer feedback.</p>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div></div>
  </body>
</html>
