<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mistral.ai/news/magistral">Original</a>
    <h1>Magistral — the first reasoning model by Mistral AI</h1>
    
    <div id="readability-page-1" class="page"><div><div><p dir="ltr text-lg">Announcing Magistral — the first reasoning model by Mistral AI — excelling in domain-specific, transparent, and multilingual reasoning.</p>
<p dir="ltr">The best human thinking isn’t linear — it weaves through logic, insight, uncertainty, and discovery. Reasoning language models have enabled us to augment and delegate complex thinking and deep understanding to AI, improving our ability to work through problems requiring precise, step-by-step deliberation and analysis.</p>
<p dir="ltr">But this space is still nascent. Lack of specialized depth needed for domain-specific problems, limited transparency, and inconsistent reasoning in the desired language — are just some of the known limitations of early thinking models.</p>
<p dir="ltr">Today, we’re excited to announce our latest contribution to AI research with Magistral — our first reasoning model. Released in both open and enterprise versions, Magistral is designed to think things through — in ways familiar to us — while bringing expertise across professional domains, transparent reasoning that you can follow and verify, along with deep multilingual flexibility.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/99xd7kHx80U?si=GPEvDJxf68FFEM9T" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">A one-shot physics simulation showcasing gravity, friction and collisions with Magistral Medium in Preview.</p>
<h2 dir="ltr">Highlights.</h2>
<p><img src="https://cms.mistral.ai/assets/d73ee721-ea92-46f5-af77-79674fdb4163.png?width=1600&amp;height=635" alt="Plot Magistral"/></p>
<p dir="ltr">Magistral is a dual-release model focused on real-world reasoning and feedback-driven improvement.</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">We’re releasing the model in two variants: Magistral Small — a 24B parameter open-source version and Magistral Medium — a more powerful, enterprise version.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Magistral Medium scored 73.6% on AIME2024, and 90% with majority voting @64. Magistral Small scored 70.7% and 83.3% respectively.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Reason natively — Magistral’s chain-of-thought works across global languages and alphabets.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Suited for a wide range of enterprise use cases — from structured calculations and programmatic logic to decision trees and rule-based systems.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">With the new Think mode and Flash Answers in Le Chat, you can get responses at 10x the speed compared to most competitors.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">The release is supported by our <a href="https://mistral.ai/static/research/magistral.pdf" target="_blank" rel="noopener">latest paper</a> covering comprehensive evaluations of Magistral, our training infrastructure, reinforcement learning algorithm, and novel observations for training reasoning models. </p>
</li>
</ul>
<p dir="ltr">As we’ve open-sourced Magistral Small, we welcome the community to examine, modify and build upon its architecture and reasoning processes to further accelerate the emergence of thinking language models. Our earlier open models have already been leveraged by the community for exciting projects like <a href="https://www.futurehouse.org/research-announcements/ether0-a-scientific-reasoning-model-for-chemistry">ether0</a> and <a href="https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview">DeepHermes 3</a>.</p>
<h3 dir="ltr">Purpose-built for transparent reasoning.</h3>
<p dir="ltr">Magistral is fine-tuned for multi-step logic, improving interpretability and providing a traceable thought process in the user’s language, unlike general-purpose models.</p>
<p dir="ltr">We aim to iterate the model quickly starting with this release. Expect the models to constantly improve.</p>
<h3 dir="ltr">Multilingual dexterity.</h3>
<p dir="ltr">The model excels in maintaining high-fidelity reasoning across numerous languages. Magistral is especially well-suited to reason in languages including English, French, Spanish, German, Italian, Arabic, Russian, and Simplified Chinese.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/0NC-wM3hbgs?si=D-LEpAKUekkbGeyn" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Prompt and response in Arabic with Magistral Medium in Preview in Le Chat.</p>
<h3 dir="ltr">10x faster reasoning with Le Chat.</h3>
<p dir="ltr">With Flash Answers in Le Chat, Magistral Medium achieves up to 10x faster token throughput than most competitors. This enables real-time reasoning and user feedback, at scale.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/_ImwDFqgblY?si=SAmY7mFwzKjGgKTT" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Speed comparison of Magistral Medium in Preview in Le Chat against ChatGPT.</p>
<h2 dir="ltr">Versatility in application.</h2>
<p dir="ltr">Magistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical.</p>
<h3 dir="ltr">Business strategy and operations.</h3>
<p dir="ltr">Building on our flagship <a href="https://mistral.ai/models">models</a>, Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making — whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints.</p>
<h3 dir="ltr">Regulated industries and sectors.</h3>
<p dir="ltr">Legal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI.</p>
<h3 dir="ltr">Systems, software, and data engineering.</h3>
<p dir="ltr">Magistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API.</p>
<h3 dir="ltr">Content and communication.</h3>
<p dir="ltr">Our early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or — if needed — delightfully eccentric copy.</p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">Magistral Small is an open-weight model, and is available for self-deployment under the Apache 2.0 license. You can download it from:  </p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Hugging Face: <a href="https://huggingface.co/mistralai/Magistral-Small-2506">https://huggingface.co/mistralai/Magistral-Small-2506</a></p>
</li>
</ul>
<p dir="ltr">You can try out a preview version of Magistral Medium in <a href="http://chat.mistral.ai">Le Chat</a> or via API on <a href="http://console.mistral.ai">La Plateforme</a>. </p>
<p dir="ltr">Magistral Medium is also available on Amazon SageMaker, and soon on IBM WatsonX, Azure AI and Google Cloud Marketplace.</p>
<p dir="ltr"><strong id="docs-internal-guid-dcd44481-7fff-e65a-9fdf-b6a154ef6740"></strong>For enterprise and custom solutions, including on-premises deployments, <a href="https://mistral.ai/contact">contact our sales team</a>.</p>
<div>
<h2 dir="ltr">BTW, we’re hiring!</h2>
<p dir="ltr">Magistral represents a significant contribution by Mistral AI to the open source community, with input from seasoned experts and interns. And we’re keen to grow our family to further shape future AI innovation.</p>
<p dir="ltr">If you’re interested in joining us on our mission to democratize artificial intelligenceI, we welcome your applications to <a href="https://mistral.ai/careers">join our team</a>! </p>
</div></div></div></div>
  </body>
</html>
