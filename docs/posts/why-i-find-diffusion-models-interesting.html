<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rnikhil.com/2025/03/06/diffusion-models-eval">Original</a>
    <h1>Why I find diffusion models interesting?</h1>
    
    <div id="readability-page-1" class="page"><section><p>I stumbled across <a href="https://x.com/InceptionAILabs/status/1894847919624462794">this</a> tweet a week or so back where this company called Inception Labs released a Diffusion LLM (dLLM). Instead of being autoregressive and predicting tokens left to right, here you start all at once and then gradually come up with sensible words simultaneously (start/finish/middle etc. all at once). Something which worked historically for image and video models is now outperforming similar-sized LLMs in code generation.</p><ul><li>The company also claims 5-10x improvement across speed and efficiency</li></ul><p><img src="https://rnikhil.com/assets/files/inceptionlabs.png"/></p><h3 id="why-are-they-interesting-to-me">Why are they interesting to me?</h3><p>After spending the better part of the last 2 years reading, writing, and working in LLM evaluation, I see some obvious first-hand benefits for this paradigm:</p><p><strong>Traditional LLMs hallucinate.</strong> It’s like they are confidently spitballing text while actually making up facts on the go. This is why they start sentences super confidently sometimes only to suggest something stupid in the end. dLLMs can generate certain important portions first, validate it, and then continue the rest of the generation.</p><ul><li>Ex: A CX chatbot would first generate the policy version number, validate it before advising a customer about a potentially hallucinated policy.</li></ul><p><strong>Agents might get better.</strong> Multi-step agentic workflows may not get stuck in loops using dLLMs. Planning, reasoning, and self-correction are a crucial part of agent flows, and we might currently be <a href="https://x.com/ylecun/status/1702027572077326505">bottlenecked</a> due to the LLM architecture. dLLMs could solve for this by ensuring that the entire plan top to bottom stays coherent. It’s like seeing ahead in the future for a little bit (based on whatever context you have) and then ensuring you don’t get stuck.</p><p>Here is a look at a more recent <a href="https://arxiv.org/abs/2502.09992">model</a> responding to the prompt “Explain Game theory” to me. You can notice the last part of the sentences are generated before the middle. It’s quite fun to run some queries and see which words get generated first.</p><p><img src="https://rnikhil.com/assets/files/hfgif.gif"/></p><p>You can try it yourself here on <a href="https://huggingface.co/spaces/multimodalart/LLaDA">HF</a>.</p><span><time datetime="2025-03-06T00:00:00+00:00">March 6, 2025</time> · <a href="https://rnikhil.com/tag/Diffusion">Diffusion</a>, <a href="https://rnikhil.com/tag/evals">evals</a>, <a href="https://rnikhil.com/tag/dLLMs">dLLMs</a>, <a href="https://rnikhil.com/tag/agents">agents</a>, <a href="https://rnikhil.com/tag/hallucination">hallucination</a></span></section></div>
  </body>
</html>
