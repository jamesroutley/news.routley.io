<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama">Original</a>
    <h1>Open source implementation for LLaMA-based ChatGPT</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">Meta has recently released LLaMA, a collection of foundational large language models ranging from 7 to 65 billion parameters.
LLaMA is creating a lot of excitement because it is smaller than GPT-3 but has better performance. For example, LLaMA&#39;s 13B architecture outperforms GPT-3 despite being 10 times smaller. This new collection of fundamental models opens the door to faster inference performance and chatGPT-like real-time assistants, while being cost-effective and running on a single GPU.</p>
<p dir="auto">However, LLaMA was not fine-tuned for instruction task with a Reinforcement Learning from Human Feedback (RLHF) training process.</p>
<p dir="auto">The good news is that we introduce <code>ChatLLaMA</code>, the first open source implementation of LLaMA based on RLHF:</p>
<ul dir="auto">
<li>A complete open source implementation that enables you to build a ChatGPT-style service based on pre-trained LLaMA models.</li>
<li>Compared to the original ChatGPT, the training process and single-GPU inference are much faster and cheaper by taking advantage of the smaller size of LLaMA architectures.</li>
<li>ChatLLaMA has built-in support for DeepSpeed ZERO to speedup the fine-tuning process.</li>
<li>The library also supports all LLaMA model architectures (7B, 13B, 33B, 65B), so that you can fine-tune the model according to your preferences for training time and inference performance.</li>
</ul>
<p dir="auto">If you like the project, please show your support by <a href="https://github.com/nebuly-ai/nebullvm/stargazers">leaving a star <g-emoji alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png">⭐</g-emoji></a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/83510798/221439813-5972d029-dae5-4561-ab3d-5a55fa5cde09.png"><img width="1032" alt="Screen Shot 2023-02-26 at 10 56 13 PM" src="https://user-images.githubusercontent.com/83510798/221439813-5972d029-dae5-4561-ab3d-5a55fa5cde09.png"/></a></p>
<p dir="auto">Image from <a href="https://openai.com/blog/chatgpt" rel="nofollow">OpenAI’s blog</a>.</p>

<blockquote>
<p dir="auto"><g-emoji alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> Please note this code represents the algorithmic implementation for RLHF training process of LLaMA and does not contain the model weights. To access the model weights, you need to apply to Meta&#39;s <a href="https://forms.gle/jk851eBVbX1m5TAv5" rel="nofollow">form</a>.</p>
</blockquote>
<p dir="auto">ChatLLaMA allows you to easily train LLaMA-based architectures in a similar way to ChatGPT, using RLHF.
For example, below is the code to start the training in the case of ChatLLaMA 7B.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from chatllama.rlhf.trainer import RLTrainer
from chatllama.rlhf.config import Config

path = &#34;path_to_config_file.yaml&#34;
config = Config(path=path)
trainer = RLTrainer(config.trainer)
trainer.distillate()
trainer.train()
trainer.training_stats.plot()"><pre><span>from</span> <span>chatllama</span>.<span>rlhf</span>.<span>trainer</span> <span>import</span> <span>RLTrainer</span>
<span>from</span> <span>chatllama</span>.<span>rlhf</span>.<span>config</span> <span>import</span> <span>Config</span>

<span>path</span> <span>=</span> <span>&#34;path_to_config_file.yaml&#34;</span>
<span>config</span> <span>=</span> <span>Config</span>(<span>path</span><span>=</span><span>path</span>)
<span>trainer</span> <span>=</span> <span>RLTrainer</span>(<span>config</span>.<span>trainer</span>)
<span>trainer</span>.<span>distillate</span>()
<span>trainer</span>.<span>train</span>()
<span>trainer</span>.<span>training_stats</span>.<span>plot</span>()</pre></div>
<p dir="auto">Note that you should provide Meta&#39;s original weights and your custom dataset before starting the fine-tuning process. Alternatively, you can generate your own dataset using LangChain&#39;s agents.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python generate_dataset.py"><pre><span>python</span> <span>generate_dataset</span>.<span>py</span></pre></div>

<p dir="auto">We have open-sourced the complete code to replicate the ChatLLaMA implementation, opening up the possibility for each user to fine-tune their own personalized ChatLLaMA assistants. The library is in its very early stages. It can be further extended with the following additions:</p>
<ul dir="auto">
<li>Checkpoints with fine-tuned weights</li>
<li>Optimization techniques for faster inference</li>
<li>Support for packaging the model into an efficient deployment framework</li>
</ul>
<p dir="auto">All developers are invited to join Nebuly&#39;s efforts toward more efficient and open ChatGPT-like assistants.</p>
<p dir="auto">You can participate in the following ways:</p>
<ol dir="auto">
<li>Submit an issue or PR on GitHub</li>
<li>Join our <a href="https://discord.gg/77d5kGSa8e" rel="nofollow">Discord group</a> to chat</li>
</ol>
</article>
          </div></div>
  </body>
</html>
