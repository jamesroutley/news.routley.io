<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.lortex.org/articles/value-speculation-ocaml/">Original</a>
    <h1>Implementing Value Speculation in OCaml</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p>CPUs are very good at doing things in parallel, even in a single core context.
Indeed, speculative execution of code and instruction reordering helps the CPU
ensure that the pipeline is always full. However, data dependencies in the
sequence of instructions might cause the CPU to have to wait for data, be it
from the L1 cache or the much slower RAM storage. Francesco Mazzoli shows in their blog post, <a href="https://mazzo.li/posts/value-speculation.html">Beating the L1 cache with value speculation</a> ,
that optimizing the critical path will in some conditions yield huge performance
improvements.</p>
<p>This article demonstrates that this optimisation can be implemented in the
OCaml programming language. Knowing how OCaml values are represented in memory is useful, here is a chapter of Real World OCaml on that matter: <a href="https://dev.realworldocaml.org/runtime-memory-layout.html">Memory Representation of Values</a>.</p>
<h2 id="fast-list-iterations-using-one-simple-trick"><a href="#fast-list-iterations-using-one-simple-trick">#<!-- --> </a>Fast list iterations using one simple trick™</h2>
<p>Let&#39;s start by instantiating a linked list of 10000 random numbers.</p>
<pre><p><span>let</span><span> l </span><span>=</span><span> List</span><span>.</span><span>init </span><span>10000</span><span> </span><span>(</span><span>fun</span><span> </span><span>_</span><span> </span><span>-&gt;</span><span> Random</span><span>.</span><span>int </span><span>1024</span><span>)</span><span></span></p></pre>
<p>Now, let&#39;s sum the numbers 100k times and see how long that takes. To obtain these statistics, <code>perf stat</code> was used with the default settings on programs compiled with OCaml 5.0.</p>
<pre><p><span>let</span><span> </span><span>rec</span><span> sum </span><span>(</span><span>accumulator</span><span>:</span><span> int</span><span>)</span><span> </span><span>(</span><span>cell</span><span>:</span><span> int list</span><span>)</span><span> </span><span>=</span><span></span></p><p><span>  </span><span>match</span><span> cell </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> head</span><span>::</span><span>tail </span><span>-&gt;</span><span> sum </span><span>(</span><span>accumulator </span><span>+</span><span> head</span><span>)</span><span> tail</span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>]</span><span> </span><span>-&gt;</span><span> accumulator</span></p><p><span></span><span>for</span><span> </span><span>_</span><span> </span><span>=</span><span> </span><span>1</span><span> </span><span>to</span><span> </span><span>100000</span><span> </span><span>do</span><span></span></p><p><span>  ignore </span><span>(</span><span>sum </span><span>0</span><span> l</span><span>)</span><span></span></p><p><span></span><span>done</span><span></span></p></pre>
<pre><p><span> Performance counter stats for &#39;./a.out sum&#39;:</span></p><p><span>          1 368,91 msec task-clock:u                     #    0,999 CPUs utilized</span></p><p><span>     4 835 597 233      cycles:u                         #    3,532 GHz</span></p><p><span>     9 005 641 989      instructions:u                   #    1,86  insn per cycle</span></p><p><span>     3 001 229 709      branches:u                       #    2,192 G/sec</span></p><p><span>           195 819      branch-misses:u                  #    0,01% of all branches</span></p></pre>
<p>Conveniently, we&#39;re doing one billion additions (10000 list items, repeated 100k times). So each iteration is taking:</p>
<ul>
<li>1.36 nanoseconds</li>
<li>4.8 cycles</li>
<li>9 instructions</li>
<li>3 branches</li>
</ul>
<p>We can already see that the CPU is cramming multiple instructions per cycle.
Using the <a href="https://godbolt.org/">compiler explorer</a>, the following assembly is obtained:</p>
<pre><p><span>camlExample__sum_268:</span><span></span></p><p><span>        subq    </span><span>$8</span><span>, </span><span>%</span><span>rsp</span><span></span></p><p><span></span><span>.L101:</span><span></span></p><p><span>        cmpq    (</span><span>%</span><span>r14</span><span>), </span><span>%</span><span>r15</span><span>         # check if GC is waiting for us</span></p><p><span>        jbe     .L102                # branch #</span><span>1</span><span></span></p><p><span></span><span>.L103:</span><span></span></p><p><span>        testb   </span><span>$1</span><span>, </span><span>%</span><span>bl</span><span>              # check if at end of list</span></p><p><span>        je      .L100                # branch #</span><span>2</span><span></span></p><p><span>        addq    </span><span>$8</span><span>, </span><span>%</span><span>rsp</span><span></span></p><p><span>        ret</span></p><p><span></span><span>.L100:</span><span></span></p><p><span>        movq    </span><span>8</span><span>(</span><span>%</span><span>rbx</span><span>), </span><span>%</span><span>rdi</span><span>        # load tail element of list</span></p><p><span>        movq    (</span><span>%</span><span>rbx</span><span>), </span><span>%</span><span>rbx</span><span>         # load head element of list</span></p><p><span>        leaq    </span><span>-</span><span>1</span><span>(</span><span>%</span><span>rbx</span><span>,</span><span>%</span><span>rax</span><span>), </span><span>%</span><span>rax</span><span>  # add it to accumulator</span></p><p><span>        movq    </span><span>%</span><span>rdi</span><span>, </span><span>%</span><span>rbx</span><span>           # move tail element for next iteration</span></p><p><span>        jmp     .L101</span></p><p><span></span><span>.L102:</span><span></span></p><p><span>        call    caml_call_gc@PLT</span></p><p><span></span><span>.L104:</span><span></span></p><p><span>        jmp     .L103</span></p></pre>
<p>I&#39;ve tried to think like a CPU in order to explain the numbers according to the perf results, but as so many pieces are involved I assumed it would be hard for everything to be correct. Instead, we&#39;ll try to get a good <em>intuition</em> by thinking in terms of <em>data dependency</em>. Basically, the assumption is that things that do not depend on each other can be ran in parallel. The second assumption is that thanks to the <em>branch predictor</em>, branch instructions are supposed to have zero cost and they don&#39;t introduce data dependencies. Instead, the CPU predicts whether the program will go through the branch and continue execution. In case of misprediction, the CPU will roll back computations for us.</p>
<p>So here is the data dependency chart for this program, showing how two iterations are expected to be ran, with the critical path in red:</p>
<p><span><span>
      <a href="https://www.lortex.org/static/0ee27ac4c33fd4dc2224c18363d91a17/d07ca/sum_chart.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="data chart" title="" src="https://www.lortex.org/static/0ee27ac4c33fd4dc2224c18363d91a17/c1b63/sum_chart.png" srcset="/static/0ee27ac4c33fd4dc2224c18363d91a17/5a46d/sum_chart.png 300w,
/static/0ee27ac4c33fd4dc2224c18363d91a17/0a47e/sum_chart.png 600w,
/static/0ee27ac4c33fd4dc2224c18363d91a17/c1b63/sum_chart.png 1200w,
/static/0ee27ac4c33fd4dc2224c18363d91a17/d61c2/sum_chart.png 1800w,
/static/0ee27ac4c33fd4dc2224c18363d91a17/97a96/sum_chart.png 2400w,
/static/0ee27ac4c33fd4dc2224c18363d91a17/d07ca/sum_chart.png 2523w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy" decoding="async"/>
  </a>
    </span></span></p><p>Even if the tail pointer is loaded from cache, we still have to pay a 4 cycles cost to fetch from the L1 cache.</p>
<p>The <strong>Check GC</strong> part of the loop is independent from the rest, and is useful in a multicore context as every domain of the program has to synchronize when performing garbage collection.</p>
<h2 id="value-speculation"><a href="#value-speculation">#<!-- --> </a>Value speculation</h2>
<p>It&#39;s time to open the rune book and perform some dark magic. We know that we
won&#39;t get past that 4 cycles per iteration bottleneck unless there is a way to
bypass the pointer chasing. To do that, we&#39;re going to do what was done in
the value speculation article, but in pure OCaml.</p>
<!-- -->
<p>The principle is the same: <code>cell</code> is converted to a &#34;pointer&#34; using the forbidden <a href="https://www.lortex.org/static/obj_magic-2d96f4d86cc70e5d70af0612885a2620.jpg"><code>Obj.magic</code></a> function. Using the value of the <code>previous</code> list
cell pointer, we can compute <code>delta</code>, the number of bytes between the two last cells.
This is used to estimate where will be the next cell. If the prediction is correct,
the memory load of the next cell address is effectively bypassed, and the CPU can
directly start working on the next iteration. If not, the branch predictor rolls back the
computation.<!-- --> </p>
<pre><p><span>let</span><span> current </span><span>:</span><span> int </span><span>=</span><span> Obj</span><span>.</span><span>magic cell </span><span>in</span><span>                   </span><span></span></p><p><span></span><span>let</span><span> delta </span><span>:</span><span> int </span><span>=</span><span> current </span><span>-</span><span> previous                    </span><span></span></p><p><span></span><span>let</span><span> prediction </span><span>:</span><span> int list </span><span>=</span><span> Obj</span><span>.</span><span>magic </span><span>(</span><span>current </span><span>+</span><span> delta</span><span>)</span><span> </span><span> </span></p></pre>
<p><span><span>
      <a href="https://www.lortex.org/static/b6a2941fbaf286b58431c35c774b74a5/d3f96/seum_delta_1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="illustration of the delta computing mechanism " title="" src="https://www.lortex.org/static/b6a2941fbaf286b58431c35c774b74a5/d3f96/seum_delta_1.png" srcset="/static/b6a2941fbaf286b58431c35c774b74a5/5a46d/seum_delta_1.png 300w,
/static/b6a2941fbaf286b58431c35c774b74a5/0a47e/seum_delta_1.png 600w,
/static/b6a2941fbaf286b58431c35c774b74a5/d3f96/seum_delta_1.png 1093w" sizes="(max-width: 1093px) 100vw, 1093px" loading="lazy" decoding="async"/>
  </a>
    </span></span></p><p>Here is the full program. Note that the delta calculation was inlined for performance reasons.</p>
<p>(<code>current + delta = current + (current - previous) = 2 * current - previous</code>)</p>
<pre><p><span>let</span><span> </span><span>rec</span><span> seum </span><span>(</span><span>previous </span><span>:</span><span> int</span><span>)</span><span> </span><span>(</span><span>accu </span><span>:</span><span> int</span><span>)</span><span> </span><span>(</span><span>cell </span><span>:</span><span> int list</span><span>)</span><span> </span><span>=</span><span></span></p><p><span>  </span><span>match</span><span> cell </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>]</span><span> </span><span>-&gt;</span><span> accu</span></p><p><span>  </span><span>|</span><span> head</span><span>::</span><span>tail </span><span>-&gt;</span><span></span></p><p><span>    </span><span>let</span><span> current </span><span>:</span><span> int </span><span>=</span><span> Obj</span><span>.</span><span>magic cell </span><span>in</span><span></span></p><p><span>    </span><span>let</span><span> prediction </span><span>:</span><span> int list </span><span>=</span><span> </span><span></span></p><p><span>      Obj</span><span>.</span><span>magic </span><span>(</span><span>2</span><span> </span><span>*</span><span> current </span><span>-</span><span> previous</span><span>)</span><span></span></p><p><span>    </span><span>in</span><span></span></p><p><span>    seum</span></p><p><span>      current</span></p><p><span>      </span><span>(</span><span>accu </span><span>+</span><span> head</span><span>)</span><span></span></p><p><span>      </span><span>(</span><span>if</span><span> prediction </span><span>==</span><span> tail </span><span>then</span><span> prediction </span><span>else</span><span> tail</span><span>)</span><span> </span><span></span></p></pre>
<p>The program is executed with the same input and...</p>
<pre><p><span> Performance counter stats for &#39;./a.out seum&#39;:</span></p><p><span>            944,67 msec task-clock:u                     #    1,000 CPUs utilized</span></p><p><span>     3 422 107 884      cycles:u                         #    3,623 GHz</span></p><p><span>    16 006 647 403      instructions:u                   #    4,68  insn per cycle</span></p><p><span>     5 001 230 197      branches:u                       #    5,294 G/sec</span></p><p><span>           225 781      branch-misses:u                  #    0,00% of all branches</span></p></pre>
<p>Per iteration:</p>
<ul>
<li>0.94 nanoseconds</li>
<li>3.4 cycles</li>
<li>16 instructions</li>
<li>5 branches</li>
</ul>
<p>We got past the bottleneck ! What we&#39;re effectively doing is transforming the list iteration into an array iteration. And this works, because there are situations where OCaml lists are allocated in a linear fashion, making the cell addresses predictible. Note in particular the huge number of instructions per cycle.</p>
<p>If you are not convinced, here is an updated dependency diagram for this program.</p>
<p><span><span>
      <a href="https://www.lortex.org/static/0e7c68e5183233304bf79def6aa2b5e5/37d90/seum_chart.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="seum chart" title="" src="https://www.lortex.org/static/0e7c68e5183233304bf79def6aa2b5e5/c1b63/seum_chart.png" srcset="/static/0e7c68e5183233304bf79def6aa2b5e5/5a46d/seum_chart.png 300w,
/static/0e7c68e5183233304bf79def6aa2b5e5/0a47e/seum_chart.png 600w,
/static/0e7c68e5183233304bf79def6aa2b5e5/c1b63/seum_chart.png 1200w,
/static/0e7c68e5183233304bf79def6aa2b5e5/d61c2/seum_chart.png 1800w,
/static/0e7c68e5183233304bf79def6aa2b5e5/97a96/seum_chart.png 2400w,
/static/0e7c68e5183233304bf79def6aa2b5e5/37d90/seum_chart.png 3003w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy" decoding="async"/>
  </a>
    </span></span></p><p>By moving the tail pointer load outside of the critical path, the CPU is able to do more things at once. The following chart shows how one can expect the CPU to execute instructions for three iterations in parallel.</p>
<p><span><span>
      <a href="https://www.lortex.org/static/33d0488feef08b4620b60d3776e40b59/344cf/seum_chart_tiled.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="seum chart tiled" title="" src="https://www.lortex.org/static/33d0488feef08b4620b60d3776e40b59/c1b63/seum_chart_tiled.png" srcset="/static/33d0488feef08b4620b60d3776e40b59/5a46d/seum_chart_tiled.png 300w,
/static/33d0488feef08b4620b60d3776e40b59/0a47e/seum_chart_tiled.png 600w,
/static/33d0488feef08b4620b60d3776e40b59/c1b63/seum_chart_tiled.png 1200w,
/static/33d0488feef08b4620b60d3776e40b59/d61c2/seum_chart_tiled.png 1800w,
/static/33d0488feef08b4620b60d3776e40b59/97a96/seum_chart_tiled.png 2400w,
/static/33d0488feef08b4620b60d3776e40b59/344cf/seum_chart_tiled.png 2643w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy" decoding="async"/>
  </a>
    </span></span></p><h3 id="the-crux-of-the-hack"><a href="#the-crux-of-the-hack">#<!-- --> </a>The crux of the hack</h3>
<p>The astute reader will wonder how is it possible to use <code>Obj.magic</code> to transmute the <code>int list</code> to an <code>int</code>. Indeed these OCaml types have different representations.</p>
<ul>
<li>An <code>int list</code> is a pointer to an OCaml block allocated on the heap. Due to alignment, it always end with a zero bit.</li>
<li>An <code>int</code> is a primitive OCaml value, the value <code>n</code> being represented as the <em>tagged integer</em> <code>2 * n + 1</code>.</li>
</ul>
<p>This means that usual operations on <code>int</code> values won&#39;t work on raw pointers.
For example, the addition is implemented as <code>Int.add a b = a + b - 1</code>. The consequence is that adding two raw numbers together using the OCaml addition will subtract one from the result to account for the expected tags.</p>
<p>For subtraction, it is similar: <code>Int.sub a b = a - b + 1</code>.</p>
<p>The magic happens when we&#39;re combining an addition and a subtraction, so that the whole operation is correct on both pointers and integers:</p>
<pre><p><span>Int</span><span>.</span><span>add current </span><span>(</span><span>Int</span><span>.</span><span>sub current previous</span><span>)</span><span> </span></p><p><span>  </span><span>=</span><span> current </span><span>+</span><span> </span><span>(</span><span>current </span><span>-</span><span> previous </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>-</span><span> </span><span>1</span><span></span></p><p><span>  </span><span>=</span><span> current </span><span>+</span><span> </span><span>(</span><span>current </span><span>-</span><span> previous</span><span>)</span><span></span></p></pre>
<details><summary>Here is the full annotated assembly for the curious</summary><pre><p><span>camlExample__seum_268:</span><span></span></p><p><span>        subq    </span><span>$8</span><span>, </span><span>%</span><span>rsp</span><span></span></p><p><span></span><span>.L103:</span><span></span></p><p><span>        movq    </span><span>%</span><span>rax</span><span>, </span><span>%</span><span>rsi</span><span></span></p><p><span>        movq    </span><span>%</span><span>rdi</span><span>, </span><span>%</span><span>rax</span><span></span></p><p><span>        cmpq    (</span><span>%</span><span>r14</span><span>), </span><span>%</span><span>r15</span><span>           # check if GC is waiting for us</span></p><p><span>        jbe     .L104                  # branch #</span><span>1</span><span></span></p><p><span></span><span>.L105:</span><span></span></p><p><span>        testb   </span><span>$1</span><span>, </span><span>%</span><span>al</span><span>                # check if at end of list</span></p><p><span>        je      .L102                  # branch #</span><span>2</span><span></span></p><p><span>        movq    </span><span>%</span><span>rbx</span><span>, </span><span>%</span><span>rax</span><span></span></p><p><span>        addq    </span><span>$8</span><span>, </span><span>%</span><span>rsp</span><span></span></p><p><span>        ret</span></p><p><span></span><span>.L102:</span><span></span></p><p><span>        movq    </span><span>8</span><span>(</span><span>%</span><span>rax</span><span>), </span><span>%</span><span>rdx</span><span>          # load tail element of list cell </span></p><p><span>        movq    </span><span>%</span><span>rax</span><span>, </span><span>%</span><span>rdi</span><span>             # move cell pointer to </span><span>%</span><span>rdi</span><span></span></p><p><span>        salq    </span><span>$1</span><span>, </span><span>%</span><span>rdi</span><span>               # multiply pointer by two</span></p><p><span>        subq    </span><span>%</span><span>rsi</span><span>, </span><span>%</span><span>rdi</span><span>             # subtract previous cell pointer to obtain the prediction</span></p><p><span>        cmpq    </span><span>%</span><span>rdx</span><span>, </span><span>%</span><span>rdi</span><span>             # compare tail element with prediction</span></p><p><span>        jne     .L101</span></p><p><span>        jmp     .L100</span></p><p><span></span><span>.L101:</span><span></span></p><p><span>        movq    </span><span>%</span><span>rdx</span><span>, </span><span>%</span><span>rdi</span><span>             # prediction is incorrect, move the tail element in </span><span>%</span><span>rdi</span><span></span></p><p><span></span><span>.L100:</span><span></span></p><p><span>        movq    (</span><span>%</span><span>rax</span><span>), </span><span>%</span><span>rsi</span><span>           # load head element of list cell</span></p><p><span>        leaq    </span><span>-</span><span>1</span><span>(</span><span>%</span><span>rbx</span><span>,</span><span>%</span><span>rsi</span><span>), </span><span>%</span><span>rbx</span><span>    # add to accumulator</span></p><p><span>        jmp     .L103                  # loop</span></p><p><span></span><span>.L104:</span><span></span></p><p><span>        call    caml_call_gc@PLT</span></p><p><span></span><span>.L106:</span><span></span></p><p><span>        jmp     .L105</span></p></pre></details>
<h3 id="optimized"><a href="#optimized">#<!-- --> </a>Optimized</h3>
<p>I was not satisfied by this mere 45% improvement. What if the loop was unrolled, so that the CPU has more freedom to move instructions around ?</p>
<pre><p><span>let</span><span> </span><span>rec</span><span> seum_unroll </span><span>(</span><span>previous </span><span>:</span><span> int</span><span>)</span><span> </span><span>(</span><span>accu </span><span>:</span><span> int</span><span>)</span><span> </span><span>(</span><span>cell </span><span>:</span><span> int list</span><span>)</span><span> </span><span>=</span><span></span></p><p><span>  </span><span>match</span><span> cell </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>]</span><span> </span><span>-&gt;</span><span> accu</span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span>  accu </span><span>+</span><span> a</span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>a</span><span>;</span><span> b</span><span>]</span><span> </span><span>-&gt;</span><span> accu </span><span>+</span><span> a </span><span>+</span><span> b</span></p><p><span>  </span><span>|</span><span> </span><span>[</span><span>a</span><span>;</span><span> b</span><span>;</span><span> c</span><span>]</span><span> </span><span>-&gt;</span><span> accu </span><span>+</span><span> a </span><span>+</span><span> b </span><span>+</span><span> c</span></p><p><span>  </span><span>|</span><span> a</span><span>::</span><span>b</span><span>::</span><span>c</span><span>::</span><span>d</span><span>::</span><span>tail </span><span>-&gt;</span><span></span></p><p><span>      </span><span>let</span><span> current </span><span>=</span><span> Obj</span><span>.</span><span>magic cell </span><span>in</span><span></span></p><p><span>      </span><span>let</span><span> prediction </span><span>:</span><span> int list </span><span>=</span><span></span></p><p><span>        Obj</span><span>.</span><span>magic </span><span>(</span><span>2</span><span> </span><span>*</span><span> current </span><span>-</span><span> previous</span><span>)</span><span></span></p><p><span>      </span><span>in</span><span></span></p><p><span>      seum_unroll</span></p><p><span>        current</span></p><p><span>        </span><span>(</span><span>accu </span><span>+</span><span> a </span><span>+</span><span> b </span><span>+</span><span> c </span><span>+</span><span> d</span><span>)</span><span></span></p><p><span>        </span><span>(</span><span>if</span><span> prediction </span><span>==</span><span> tail </span><span>then</span><span> prediction </span><span>else</span><span> tail</span><span>)</span><span></span></p></pre>
<p>The idea is to iterate on the list by chunks of 4 items. There is still the same amount of work to do, but the value prediction trick is performed once every 4 element.</p>
<pre><p><span> Performance counter stats for &#39;./a.out seum_unroll&#39;:</span></p><p><span>            715,58 msec task-clock:u                     #    0,999 CPUs utilized</span></p><p><span>     2 410 830 333      cycles:u                         #    3,369 GHz</span></p><p><span>     7 756 543 257      instructions:u                   #    3,22  insn per cycle</span></p><p><span>     2 001 229 820      branches:u                       #    2,797 G/sec</span></p><p><span>           112 956      branch-misses:u                  #    0,01% of all branches</span></p></pre>
<p>Per iteration:</p>
<ul>
<li>0.72 nanoseconds</li>
<li>2.4 cycles</li>
<li>7.7 instructions</li>
<li>2 branches</li>
</ul>

<p>According the original article, we&#39;re now faster than the naive C implementation, but 2x slower than the hand-optimized one. This is all very synthetic but I found it quite interesting that OCaml is able to benefit from the same hacks as C. Of course this won&#39;t be useful in a lot of situations, but maybe one will gain some insights on how modern CPU are able to make programs go fast.</p>
<hr/>
<p>If you like this article I&#39;d be glad to have your feedback.
Public discussion on <a href="https://twitter.com/TheLortex/status/1654563811569836032">Twitter</a></p></div></div></div></div>
  </body>
</html>
