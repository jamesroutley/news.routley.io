<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dubroy.com/blog/two-little-interpreters">Original</a>
    <h1>Two little interpreters</h1>
    
    <div id="readability-page-1" class="page"><div id="content">
		<div>
			
			<p><small>March 26, 2024
            </small></p><p>Late last year, I read a few blog posts that said something like “everyone knows that bytecode interpreters are faster than tree-walking interpreters”. And then I saw the paper <a href="https://stefan-marr.de/downloads/oopsla23-larose-et-al-ast-vs-bytecode-interpreters-in-the-age-of-meta-compilation.pdf">AST vs. Bytecode: Interpreters in the Age of
Meta-Compilation”</a> when Stefan Marr <a href="https://twitter.com/smarr/status/1691036663764430848">shared a draft on Twitter</a>.</p>
<p>I realized that although I’d written a number of tree-walking interpreters, I’d never actually built a bytecode interpreter before. So, I thought it would be a fun exercise to build two small interpreters in the same language and compare the performance.</p>
<p>The result is <a href="https://github.com/pdubroy/pegboard">Pegboard: Two little interpreters</a>. It’s around 600 lines of TypeScript code: ~180 for the tree-walking interpreter, ~370 for the bytecode interpreter, and a bit of shared code.</p>
<p>I won’t bury the lede: the bytecode interpreter is not faster! In fact, the tree-walking interpreter is about 2–3x faster on my benchmarks. Read on for more details.</p>
<h2>The language: parsing expression grammars</h2>
<p>Maybe surprising: the “language” I chose to implement isn’t a general-purpose purpose programming language. Instead, I wrote interpreters for <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing expression grammars</a>, aka PEGs. The language of PEGs is almost like simple a programming language — but one whose expressions implicitly operate on some hidden data structures.</p>
<p>It even has something like function calls: rule applications. For example, in the grammar snippet below<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, there are two rules defined: <code>hexDigit</code> and <code>hexIntegerLiteral</code>.</p>
<pre><code>  hexDigit = &#34;0&#34;..&#34;9&#34; | &#34;a&#34;..&#34;f&#34; | &#34;A&#34;..&#34;F&#34;

  hexIntegerLiteral = &#34;0x&#34; hexDigit+
                    | &#34;0X&#34; hexDigit+</code></pre>


<p>The <code>hexDigit</code> rule is defined on line 1, and used (or <em>applied</em>) on lines 3 and 4, in the body of <code>hexIntegeralLiteral</code>.</p>
<p>Rule applications can be arbitrarily deep, and — like function calls — mutually recursive. So an interpreter for PEGs needs to maintain a rule application stack, which is very much like a call stack.</p>
<p>One more detail: for simplicity, I’m not using a custom syntax (like the one above) to specify the grammars. Instead, I use <a href="https://en.wikipedia.org/wiki/Parser_combinator">parser combinators</a>. So the rules above are actually defined like this:</p>
<pre><code>{
  // ...
  hexDigit: choice(range(&#34;0&#34;, &#34;9&#34;), range(&#34;a&#34;, &#34;f&#34;), range(&#34;A&#34;, &#34;F&#34;)),
  hexIntegerLiteral: choice(
    seq(_(&#34;0x&#34;), seq(app(&#34;hexDigit&#34;), rep(app(&#34;hexDigit&#34;)))),
    seq(_(&#34;0X&#34;), seq(app(&#34;hexDigit&#34;), rep(app(&#34;hexDigit&#34;)))),
  ),
  // ...
};</code></pre>


<h2>Wait, what?</h2>
<p>Okay, I realize this could all be kind of confusing, since we don’t usually talk about interpreting grammars. Here’s another explanation:</p>
<ol>
<li>You can think of a parsing expression grammar as a program, in a very limited programming language, that describes a parser.</li>
<li>You could compile that program to another language. Tools that do this are known as <em>parser generators</em>.</li>
<li>You can also interpret that program. That involves matching the grammar against a particular input string.</li>
<li>Compilers and interpreters typically convert a program from a source language to an abstract syntax tree (AST). With parser combinators, you skip that step and construct the AST directly.</li>
</ol>
<h2>Performance</h2>
<p>To measure the performance of my two interpreters, I ported the <a href="https://ohmjs.org/editor/#0a9a649c3c630fd0a470ba6cb75393fe">ES5 grammar from Ohm</a> to the parser combinator style. This allowed me to use some real-world examples: using each interpreter to parse the source code for jQuery, React, and Underscore.</p>
<p>My bytecode interpreter turned out to be slower!</p>
<p>As you can see, the tree-walking interpreter (or, “AST interp” here) is a bit more than 2x faster on V8, and more than 3x faster on JSC. Though I wouldn’t suggest drawing any big conclusions from these numbers.</p>
<p>If you’re interested, you can check out <a href="https://github.com/pdubroy/pegboard/blob/main/scripts/bench.ts">the benchmark source on GitHub</a>.</p>
<h3>Node (V8)</h3>
<pre><code>cpu: Apple M1
runtime: node v21.2.0 (arm64-darwin)

summary for jquery
  AST interp
   2.86x faster than bytecode interp (switch)

summary for react
  AST interp
   2.24x faster than bytecode interp (switch)

summary for underscore
  AST interp
   2.04x faster than bytecode interp (switch)</code></pre>


<h3>Bun (JSC)</h3>
<pre><code>cpu: Apple M1
runtime: bun 1.0.26 (arm64-darwin)

summary for jquery
  AST interp
   3.69x faster than bytecode interp (switch)

summary for react
  AST interp
   3.2x faster than bytecode interp (switch)

summary for underscore
  AST interp
   3.17x faster than bytecode interp (switch)</code></pre>




<p>Again, I wouldn’t suggest drawing any big conclusions from this experiment. My main motivation was to get some experience building a traditional, switch-style bytecode interpreter. The fact that it turned out to be so much slower was an interesting surprise!</p>
<p>Some caveats:</p>
<ul>
<li>There’s a big difference between interpreting a PEG, and interpreting a real programming language. And even though it’s a good real-world use case, the “program” here (the ES5 grammar) is less than 500 lines of code.</li>
<li>I didn’t spend much time trying to optimize the performance of either interpreter. I did use <a href="https://github.com/microsoft/deoptexplorer-vscode">Deopt Explorer</a> to fix some obvious performance problems, but didn’t go much deeper than that. It would be interesting to dig into <em>why</em> the bytecode interpreter is slower — but that’s a project for another day.</li>
</ul>
<p>You can find the <a href="https://github.com/pdubroy/pegboard/">full source of both interpreters on GitHub</a>. If you have any suggestions for improvements, or notice anything major that I’ve missed, please let me know!</p>
<p><small><em>Thanks to David Albert for pairing with me to finish up the bytecode interpreter, and to Kevin Lynagh for proofreading this post.</em></small></p>

		</div>	</div></div>
  </body>
</html>
