<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stack.convex.dev/the-magic-of-embeddings">Original</a>
    <h1>The Magic of Embeddings</h1>
    
    <div id="readability-page-1" class="page"><article><header><img alt="Profile image" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F077753b63476b77fb111ba06d1bb538517033a54-3500x3500.jpg%3Fw%3D40%26h%3D40%26fit%3Dcrop%26crop%3Dfocalpoint&amp;w=48&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F077753b63476b77fb111ba06d1bb538517033a54-3500x3500.jpg%3Fw%3D40%26h%3D40%26fit%3Dcrop%26crop%3Dfocalpoint&amp;w=96&amp;q=75 2x" src="https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F077753b63476b77fb111ba06d1bb538517033a54-3500x3500.jpg%3Fw%3D40%26h%3D40%26fit%3Dcrop%26crop%3Dfocalpoint&amp;w=96&amp;q=75"/></header><p><img alt="Embeddings turn text into an array of numbers" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw, (min-width: 1024px) 60vw, (min-width: 1280) 780px" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=384&amp;q=75 384w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=3840&amp;q=75 3840w" src="https://stack.convex.dev/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fts10onj4%2Fproduction%2F4e40aa260c25ec7bdde41bd26f4a2a07f41d138a-1200x628.png&amp;w=3840&amp;q=75"/></p><p>How similar are the strings “I care about strong ACID guarantees” and “I like transactional databases”? While there’s a number of ways we could compare these strings—syntactically or grammatically for instance—one powerful thing AI models give us is the ability to compare these semantically, using something called <em>embeddings</em>. Given a model, such as OpenAI’s <code>text-embedding-ada-002</code>, I can tell you that the aforementioned two strings have a similarity of 0.784, and are more similar than “I care about strong ACID guarantees” and “I like MongoDB” 😛. With embeddings, we can do a whole suite of powerful things:<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup></p>
<ul>
<li><strong>Search</strong> (where results are ranked by relevance to a query string)</li>
<li><strong>Clustering</strong> (where text strings are grouped by similarity)</li>
<li><strong>Recommendations</strong> (where items with related text strings are recommended)</li>
<li><strong>Anomaly detection</strong> (where outliers with little relatedness are identified)</li>
<li><strong>Diversity measurement</strong> (where similarity distributions are analyzed)</li>
<li><strong>Classification</strong> (where text strings are classified by their most similar label)</li>
</ul>
<p>This article will look at working with raw OpenAI embeddings.</p>
<h2 id="what-is-an-embedding">What is an embedding?<a href="#what-is-an-embedding"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h2>
<p>An embedding is ultimately a list of numbers that describe a piece of text, for a given model. In the case of OpenAI’s model, it’s always a 1,536-element-long array of numbers. Furthermore, for OpenAI, the numbers are all between -1 and 1, and if you treat the array as a vector in 1,536-dimensional space, it has a magnitude of 1 (i.e. it’s “normalized to length 1” in linear algebra lingo).</p>
<p>On a conceptual level, you can think of each number in the array as capturing some aspect of the text. Two arrays are considered similar to the degree that they have similar values in each element in the array. You don’t have to know what any of the individual values correspond to—that’s both the beauty and the mystery of embeddings—you just need to compare the resulting arrays. We’ll look at how to compute this similarity below.</p>
<p>Depending on what model you use, you can get wildly different arrays, so it only makes sense to compare arrays that come from the same model. It also means that different models may disagree about what is similar. You could imagine one model being more sensitive to whether the string rhymes. You could fine-tune a model for your specific use case, but I’d recommend starting with a general-purpose one to start, for similar reasons as to why to generally pick Chat GPT over fine-tuned text generation models.</p>
<p>It’s beyond the scope of this post, but it’s also worth mentioning that we’re just looking at text embeddings here, but there are also models to turn images and audio into embeddings, with similar implications.</p>
<h2 id="how-do-i-get-an-embedding">How do I get an embedding?<a href="#how-do-i-get-an-embedding"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h2>
<p>There are a few models to turn text into an embedding. To use a hosted model behind an API, I’d recommend <a href="https://platform.openai.com/docs/guides/embeddings">OpenAI</a>, and that’s what we’ll be using in this article. For open-source options, you can check out <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2#all-minilm-l6-v2">all-MiniLM-L6-v2</a> or <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">all-mpnet-base-v2</a>.</p>
<p>Assuming you have an <a href="https://platform.openai.com/account/api-keys">API key</a> in your <a href="https://docs.convex.dev/production/hosting/environment-variables">environment variables</a>, you can get an embedding via a simple <code>fetch</code>:</p>
<div><div><pre><code><span>export</span><span> </span><span>async</span><span> </span><span>function</span><span> </span><span>fetchEmbedding</span><span>(</span><span>text</span><span>:</span><span> string</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>const</span><span> result </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>&#34;https://api.openai.com/v1/embeddings&#34;</span><span>,</span><span> </span><span>{</span><span>
</span><span>    </span><span>method</span><span>:</span><span> </span><span>&#34;POST&#34;</span><span>,</span><span>
</span><span>    </span><span>headers</span><span>:</span><span> </span><span>{</span><span>
</span><span>      </span><span>&#34;Content-Type&#34;</span><span>:</span><span> </span><span>&#34;application/json&#34;</span><span>,</span><span>
</span><span>      </span><span>Authorization</span><span>:</span><span> </span><span>&#34;Bearer &#34;</span><span> </span><span>+</span><span> process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span><span>
</span><span>    </span><span>}</span><span>,</span><span>
</span><span>    </span><span>body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>
</span><span>      </span><span>model</span><span>:</span><span> </span><span>&#34;text-embedding-ada-002&#34;</span><span>,</span><span>
</span><span>      </span><span>input</span><span>:</span><span> </span><span>[</span><span>text</span><span>]</span><span>,</span><span>
</span><span>    </span><span>}</span><span>)</span><span>,</span><span>
</span><span>  </span><span>}</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> jsonresults </span><span>=</span><span> </span><span>await</span><span> result</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span>
</span><span>  </span><span>return</span><span> jsonresults</span><span>.</span><span>data</span><span>[</span><span>0</span><span>]</span><span>.</span><span>embedding</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div></div>
<details><summary>For efficiency, I’d recommend fetching multiple embeddings at once in a batch.</summary><div><div><pre><code><span>export</span><span> </span><span>async</span><span> </span><span>function</span><span> </span><span>fetchEmbeddingBatch</span><span>(</span><span>text</span><span>:</span><span> string</span><span>[</span><span>]</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>const</span><span> result </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>&#34;https://api.openai.com/v1/embeddings&#34;</span><span>,</span><span> </span><span>{</span><span>
</span><span>    </span><span>method</span><span>:</span><span> </span><span>&#34;POST&#34;</span><span>,</span><span>
</span><span>    </span><span>headers</span><span>:</span><span> </span><span>{</span><span>
</span><span>      </span><span>&#34;Content-Type&#34;</span><span>:</span><span> </span><span>&#34;application/json&#34;</span><span>,</span><span>
</span><span>      </span><span>Authorization</span><span>:</span><span> </span><span>&#34;Bearer &#34;</span><span> </span><span>+</span><span> process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span><span>
</span><span>    </span><span>}</span><span>,</span><span>
</span>
<span>    </span><span>body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>
</span><span>      </span><span>model</span><span>:</span><span> </span><span>&#34;text-embedding-ada-002&#34;</span><span>,</span><span>
</span><span>      </span><span>input</span><span>:</span><span> </span><span>[</span><span>text</span><span>]</span><span>,</span><span>
</span><span>    </span><span>}</span><span>)</span><span>,</span><span>
</span><span>  </span><span>}</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> jsonresults </span><span>=</span><span> </span><span>await</span><span> result</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> allembeddings </span><span>=</span><span> jsonresults</span><span>.</span><span>data</span><span> </span><span>as</span><span> </span><span>{</span><span>
</span><span>    </span><span>embedding</span><span>:</span><span> number</span><span>[</span><span>]</span><span>;</span><span>
</span><span>    </span><span>index</span><span>:</span><span> number</span><span>;</span><span>
</span><span>  </span><span>}</span><span>[</span><span>]</span><span>;</span><span>
</span><span>  allembeddings</span><span>.</span><span>sort</span><span>(</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>=&gt;</span><span> b</span><span>.</span><span>index</span><span> </span><span>-</span><span> a</span><span>.</span><span>index</span><span>)</span><span>;</span><span>
</span><span>  </span><span>return</span><span> allembeddings</span><span>.</span><span>map</span><span>(</span><span>(</span><span>{</span><span> embedding </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> embedding</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div></div></details>
<h2 id="where-should-i-store-it">Where should I store it?<a href="#where-should-i-store-it"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h2>
<p>Once you have an embedding vector, you’ll likely want to do one of two things with it:</p>
<ol>
<li>Use it to search for similar strings (i.e. search for similar embeddings).</li>
<li>Store it to be searched against in the future.</li>
</ol>
<p>If you plan to store thousands of vectors, I’d recommend using a dedicated vector database like <a href="https://www.pinecone.io/">Pinecone</a>. This allows you to quickly find nearby vectors for a given input, without having to compare against every vector every time. Stay tuned for a future post on using Pinecone alongside Convex.</p>
<p>If you don’t have many vectors, however, you can just store them directly in a normal database. In my case, if I want to suggest <a href="https://stack.convex.dev">Stack</a> posts similar to a given post or search, I only need to compare against fewer than 100 vectors, so I can just fetch them all and compare them in a matter of milliseconds using the <span>Convex</span> database.</p>
<h3 id="how-should-i-store-an-embedding">How should I store an embedding?<a href="#how-should-i-store-an-embedding"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h3>
<p>If you’re storing your embeddings in Pinecone, stay tuned for a dedicated post on it, but the short answer is you configure a Pinecone “Index” and store some metadata along with the vector, so when you get results from Pinecone you can easily re-associate them with your application data. For instance, you can store the document ID for a row that you want to associate with the vector.</p>
<p>If you’re storing the embedding in Convex, I’d advise storing it as a binary blob rather than a javascript array of numbers. Convex advises to <a href="https://docs.convex.dev/database/types">not store arrays longer than 1024 elements</a>. We can achieve this by converting it into a Float32Array pretty easily in JavaScript:</p>
<div><div><pre><code><span>const</span><span> numberList </span><span>=</span><span> </span><span>await</span><span> </span><span>fetchEmbedding</span><span>(</span><span>inputText</span><span>)</span><span>;</span><span> </span><span>// number[]</span><span>
</span><span></span><span>const</span><span> floatArray </span><span>=</span><span> </span><span>Float32Array</span><span>.</span><span>from</span><span>(</span><span>numberList</span><span>)</span><span>;</span><span> </span><span>// Float32Array</span><span>
</span><span></span><span>const</span><span> floatBytes </span><span>=</span><span> floatArray</span><span>.</span><span>buffer</span><span>;</span><span> </span><span>// ArrayBuffer</span><span>
</span><span></span><span>// Save floatBytes to the DB</span><span>
</span><span></span><span>// Later, after you read the bytes back out:</span><span>
</span><span></span><span>const</span><span> arrayAgain </span><span>=</span><span> </span><span>new</span><span> </span><span>Float32Array</span><span>(</span><span>bytesFromDB</span><span>)</span><span>;</span><span> </span><span>// Float32Array</span><span>
</span></code></pre></div></div>
<p>You can represent the embedding as a field in a table <a href="https://docs.convex.dev/database/schemas">in your schema</a>:</p>
<div><div><pre><code><span>vectors</span><span>:</span><span> </span><span>defineTable</span><span>(</span><span>{</span><span>
</span><span>  </span><span>float32Buffer</span><span>:</span><span> v</span><span>.</span><span>bytes</span><span>(</span><span>)</span><span>,</span><span>
</span><span>  </span><span>textId</span><span>:</span><span> v</span><span>.</span><span>id</span><span>(</span><span>&#34;texts&#34;</span><span>)</span><span>,</span><span>
</span><span></span><span>}</span><span>)</span><span>,</span><span>
</span></code></pre></div></div>
<p>In this case, I store the vector alongside an ID of a document in the “texts” table.</p>
<h2 id="how-to-compare-embeddings-in-javascript">How to compare embeddings in JavaScript<a href="#how-to-compare-embeddings-in-javascript"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h2>
<p>If you’re looking to compare two embeddings from OpenAI without using a vector database, it’s very simple. There’s <a href="https://www.pinecone.io/learn/roughly-explained/distance-between-vectors/">a few ways of comparing vectors</a>, including Euclidean distance, dot product, and cosine similarity. Thankfully, because OpenAI normalizes all the vectors to be length 1, they will all give the same rankings! With a simple <a href="https://www.notion.so/Product-f8d495cd1e29469289011becf658f547?pvs=21">dot product</a> you can get a similarity score ranging from -1 (totally unrelated) to 1 (incredibly similar). There are optimized libraries to do it, but for my purposes, this simple function suffices:</p>
<div><div><pre><code><span>/**
</span><span> * Compares two vectors by doing a dot product.
</span><span> *
</span><span> * Assuming both vectors are normalized to length 1, it will be in [-1, 1].
</span><span> * @returns [-1, 1] based on similarity. (1 is the same, -1 is the opposite)
</span><span> */</span><span>
</span><span></span><span>export</span><span> </span><span>function</span><span> </span><span>compare</span><span>(</span><span>vectorA</span><span>:</span><span> </span><span>Float32Array</span><span>,</span><span> </span><span>vectorB</span><span>:</span><span> </span><span>Float32Array</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>return</span><span> vectorA</span><span>.</span><span>reduce</span><span>(</span><span>(</span><span>sum</span><span>,</span><span> val</span><span>,</span><span> idx</span><span>)</span><span> </span><span>=&gt;</span><span> sum </span><span>+</span><span> val </span><span>*</span><span> vectorB</span><span>[</span><span>idx</span><span>]</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div></div>
<h4 id="example">Example<a href="#example"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h4>
<p>In this example, let’s make a function (a Convex <a href="https://docs.convex.dev/functions/query-functions">query</a> in this case) that returns all of the vectors and their similarity scores in order based on some query vector, assuming a table of <code>vectors</code> as we defined above, and the <code>compare</code> function we just defined.</p>
<div><div><pre><code><span>export</span><span> </span><span>const</span><span> compareTo </span><span>=</span><span> </span><span>query</span><span>(</span><span>async</span><span> </span><span>(</span><span>{</span><span> db </span><span>}</span><span>,</span><span> </span><span>{</span><span> vectorId </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>  </span><span>const</span><span> target </span><span>=</span><span> </span><span>await</span><span> db</span><span>.</span><span>get</span><span>(</span><span>vectorId</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> targetArray </span><span>=</span><span> </span><span>new</span><span> </span><span>Float32Array</span><span>(</span><span>target</span><span>.</span><span>float32Buffer</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> vectors </span><span>=</span><span> </span><span>await</span><span> db</span><span>.</span><span>query</span><span>(</span><span>&#34;vectors&#34;</span><span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span><span>
</span><span>  </span><span>const</span><span> scores </span><span>=</span><span> </span><span>await</span><span> </span><span>Promise</span><span>.</span><span>all</span><span>(</span><span>
</span>    vectors
<span>      </span><span>.</span><span>filter</span><span>(</span><span>(</span><span>vector</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>vector</span><span>.</span><span>_id</span><span>.</span><span>equals</span><span>(</span><span>vectorId</span><span>)</span><span>)</span><span>
</span><span>      </span><span>.</span><span>map</span><span>(</span><span>async</span><span> </span><span>(</span><span>vector</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>        </span><span>const</span><span> score </span><span>=</span><span> </span><span>compare</span><span>(</span><span>
</span><span>          targetArray</span><span>,</span><span>
</span><span>          </span><span>new</span><span> </span><span>Float32Array</span><span>(</span><span>vector</span><span>.</span><span>float32Buffer</span><span>)</span><span>
</span><span>        </span><span>)</span><span>;</span><span>
</span><span>        </span><span>return</span><span> </span><span>{</span><span> score</span><span>,</span><span> </span><span>textId</span><span>:</span><span> vector</span><span>.</span><span>textId</span><span>,</span><span> </span><span>vectorId</span><span>:</span><span> vector</span><span>.</span><span>_id</span><span> </span><span>}</span><span>;</span><span>
</span><span>      </span><span>}</span><span>)</span><span>
</span><span>  </span><span>)</span><span>;</span><span>
</span><span>  </span><span>return</span><span> scores</span><span>.</span><span>sort</span><span>(</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>=&gt;</span><span> b</span><span>.</span><span>score</span><span> </span><span>-</span><span> a</span><span>.</span><span>score</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>)</span><span>;</span><span>
</span></code></pre></div></div>
<h2 id="summary">Summary<a href="#summary"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 00-6.364-6.364l-4.5 4.5a4.5 4.5 0 001.242 7.244"></path></svg></a></h2>
<p>In this post, we looked at embeddings, why they’re useful, and how we can store and use them in Convex. I’ll be making more posts on working with embeddings, including chunking long input into multiple embeddings and using Pinecone alongside Convex soon. Let us know in <a href="https://convex.dev/community">our Discord</a> what you think!</p>
<section><div><p>Build in minutes, scale forever.</p><p>Convex is the backend application platform with everything you need to build your project. Cloud functions, a database, file storage, scheduling, search, and realtime updates fit together seamlessly.</p><p>Get started</p></div><svg width="122" height="66" viewBox="0 0 122 66" aria-hidden="true"><path d="M121.763 26.7781C121.56 1.67502 66.0853 -5.21351 34.7548 6.43616C12.7114 14.6384 -4.66772 31.3594 2.02414 48.4254C8.71599 65.4915 28.8127 68.8682 53.3887 61.8161C77.9565 54.7666 121.902 43.5832 121.763 26.7781V26.7781Z" fill="currentColor"></path></svg><svg width="122" height="66" viewBox="0 0 122 66" aria-hidden="true"><path d="M121.763 26.7781C121.56 1.67502 66.0853 -5.21351 34.7548 6.43616C12.7114 14.6384 -4.66772 31.3594 2.02414 48.4254C8.71599 65.4915 28.8127 68.8682 53.3887 61.8161C77.9565 54.7666 121.902 43.5832 121.763 26.7781V26.7781Z" fill="currentColor"></path></svg></section></article></div>
  </body>
</html>
