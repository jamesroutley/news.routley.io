<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.jetpress.org/volume1/moravec.htm">Original</a>
    <h1>When will computer hardware match the human brain? (1998)</h1>
    
    <div id="readability-page-1" class="page"><div>
	<div>

<hr/>


			<p><i>Journal of Evolution and Technology</i>. 1998. 
			Vol. 1 - <a href="https://www.jetpress.org/volume1/moravec.pdf">
			<img src="https://www.jetpress.org/images/PDF.gif" width="10" height="10"/> PDF 
			Version</a></p>

<blockquote>
    <blockquote>
        <blockquote>
            <blockquote>
                <dl>
                    <p><center>
                    <dt><SPAN size="2"><em>(Received Dec. 1997)</em></SPAN></dt>
                    </center></p>
                </dl>
            </blockquote>
        </blockquote>
    </blockquote>
</blockquote>

<dl>
    <p><center>
    <dt><SPAN size="4">Hans Moravec</SPAN></dt>
    </center></p>
</dl>
			<blockquote>
    <p><b><em><SPAN size="4">ABSTRACT</SPAN></em></b></p>
    <p><SPAN size="2">This paper describes how the performance of AI machines
    tends to improve at the same pace that AI researchers get
    access to faster hardware. The processing power and memory
    capacity necessary to match general intellectual performance
    of the human brain are estimated. Based on extrapolation of
    past trends and on examination of technologies under
    development, it is predicted that the required hardware will
    be available in cheap machines in the 2020s.</SPAN></p>
</blockquote>



<h3>Brains, Eyes and Machines</h3>

<dl>
    <dt><SPAN size="2">Computers have far to go to match human strengths, and
        our estimates will depend on analogy and extrapolation.
        Fortunately, these are grounded in the first bit of the
        journey, now behind us. Thirty years of computer vision
        reveals that 1 MIPS can extract simple features from
        real-time imagery--tracking a white line or a white spot
        on a mottled background. 10 MIPS can follow complex
        gray-scale patches--as smart bombs, cruise missiles and
        early self-driving vans attest. 100 MIPS can follow
        moderately unpredictable features like roads--as recent
        long NAVLAB trips demonstrate. 1,000 MIPS will be
        adequate for coarse-grained three-dimensional spatial
        awareness--illustrated by several mid-resolution
        stereoscopic vision programs, including my own. 10,000
        MIPS can find three-dimensional objects in
        clutter--suggested by several &#34;bin-picking&#34; and
        high-resolution stereo-vision demonstrations, which
        accomplish the task in an hour or so at 10 MIPS. The data
        fades there--research careers are too short, and computer
        memories too small, for significantly more elaborate
        experiments.</SPAN>
        </dt>
</dl>

<h3>Extrapolation</h3>

<p><SPAN size="2">By our estimate, today&#39;s very biggest supercomputers are
within a factor of a hundred of having the power to mimic a human
mind. Their successors a decade hence will be more than powerful
enough. Yet, it is unlikely that machines costing tens of
millions of dollars will be wasted doing what any human can do,
when they could instead be solving urgent physical and
mathematical problems nothing else can touch. Machines with
human-like performance will make economic sense only when they
cost less than humans, say when their &#34;brains&#34; cost
about $1,000. When will that day arrive?</SPAN>
</p>





<h3>False Start</h3>

<p><SPAN size="2">It may seem rash to expect fully intelligent machines in a few
decades, when the computers have barely matched insect mentality
in a half-century of development. Indeed, for that reason, many
long-time artificial intelligence researchers scoff at the
suggestion, and offer a few centuries as a more believable
period. But there are very good reasons why things will go much
faster in the next fifty years than they have in the last fifty.</SPAN>
</p>

<h3>The Game&#39;s Afoot</h3>

<p><SPAN size="2">A summerlike air already pervades the few applications of
artificial intelligence that retained access to the largest
computers. Some of these, like pattern analysis for satellite
images and other kinds of spying, and in seismic oil exploration,
are closely held secrets. Another, though, basks in the
limelight. The best chess-playing computers are so interesting
they generate millions of dollars of free advertising for the
winners, and consequently have enticed a series of computer
companies to donate time on their best machines and other
resources to the cause. Since 1960 IBM, Control Data, AT&amp;T,
Cray, Intel and now again IBM have been sponsors of computer
chess. The &#34;knights&#34; in the AI power graph show the
effect of this largesse, relative to mainstream AI research. The
top chess programs have competed in tournaments powered by
supercomputers, or specialized machines whose chess power is
comparable. In 1958 IBM had both the first checker program, by
Arthur Samuel, and the first full chess program, by Alex
Bernstein. They ran on an IBM 704, the biggest and last
vacuum-tube computer. The Bernstein program played atrociously,
but Samuel&#39;s program, which automatically learned its board
scoring parameters, was able to beat Connecticut checkers
champion Robert Nealey. Since 1994, Chinook, a program written by
Jonathan Schaeffer of the University of Alberta, has consistently
bested the world&#39;s human checker champion. But checkers isn&#39;t
very glamorous, and this portent received little notice.</SPAN>
</p>

<h3>The Great Flood</h3>

<p><SPAN size="2">Computers are universal machines, their potential extends
uniformly over a boundless expanse of tasks. Human potentials, on
the other hand, are strong in areas long important for survival,
but weak in things far removed. Imagine a &#34;landscape of
human competence,&#34; having lowlands with labels like
&#34;arithmetic&#34; and &#34;rote memorization&#34;,
foothills like &#34;theorem proving&#34; and &#34;chess
playing,&#34; and high mountain peaks labeled
&#34;locomotion,&#34; &#34;hand-eye coordination&#34; and
&#34;social interaction.&#34; We all live in the solid
mountaintops, but it takes great effort to reach the rest of the
terrain, and only a few of us work each patch.</SPAN></p>



<p><b><em><SPAN size="4">REFERENCES</SPAN></em></b></p>

<p><SPAN size="2">Goldhaber-Gordon, D. J. et al. (1997) &#34;Overview of
Nanoelectronic Devices&#34;, <em>Proceedings of the IEEE</em>,
April 1997.</SPAN></p>

<p><SPAN size="2">Moravec, H. (1998) <em>Robot, Being: mere machine to
transcendent mind. </em>(forthcoming) Oxford University Press.</SPAN></p>

<p><strong><SPAN size="4"><a href="https://www.jetpress.org/volume1/commentary.htm">Peer Commentaries </a></SPAN>
</strong></p>

<hr/>

			</div>
</div></div>
  </body>
</html>
