<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://furiosa.ai/blog/introducing-rngd-server-efficient-ai-inference-at-data-center-scale">Original</a>
    <h1>Furiosa: 3.5x efficiency over H100s</h1>
    
    <div id="readability-page-1" class="page"><p data-reveal="">
            We are excited to introduce FuriosaAI’s NXT RNGD Server—our first branded, turnkey solution for AI inference.
        </p><div>
      



<div data-blocks="" data-spacing-bottom="false">
			
						
						
									
			
			
			
			
			

													
			
			
						

									

			
	<div>
		<div data-reveal="">
			

		
		
	
	<p dir="ltr">Built around our RNGD accelerators, NXT RNGD Server is an optimized system that delivers high performance on today’s most important AI workloads while fitting seamlessly into existing data center environments.  </p>
<p dir="ltr">With NXT RNGD Server, enterprises can move from experimentation to deployment faster than ever. The system ships with the Furiosa SDK and Furiosa LLM runtime preinstalled, so applications can serve immediately upon installation. We optimized the platform over standard PCIe interconnects, eliminating the need for proprietary fabrics or exotic infrastructure.<br/></p>
		</div>
	</div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
      
  
  <div>
    <div data-reveal="">
              
					
	
				
	
			
		
		
		
				
	
	
		
							
	<figure data-image="">
		<p><img width="750" height="391" alt="3 5xmore" data-src="https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=391&amp;q=85&amp;transformer=imgix&amp;w=750" data-sizes="auto" data-srcset="https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=391&amp;q=85&amp;transformer=imgix&amp;w=750 750w, https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=522&amp;q=85&amp;transformer=imgix&amp;w=1000 1000w, https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=652&amp;q=85&amp;transformer=imgix&amp;w=1250 1250w, https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=782&amp;q=85&amp;transformer=imgix&amp;w=1500 1500w, https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=913&amp;q=85&amp;transformer=imgix&amp;w=1750 1750w, https://furiosa-ai.imgix.net/3.5xmore_2025-09-25-000900_uxrt.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1043&amp;q=85&amp;transformer=imgix&amp;w=2000 2000w"/>
							
					</p>
			</figure>
          </div>
  </div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
	<div>
		<div data-reveal="">
			

		
		
	
	<p dir="ltr">Designed for compatibility, NXT RNGD Server runs at just 3 kW per system, allowing organizations to scale AI within the power and cooling limits of most modern facilities. This makes NXT RNGD Server a practical and cost-effective system to build out AI factories inside the data centers enterprises already operate.</p>
<h2 dir="ltr"><span>Technical Specifications</span></h2>
<ul><li dir="ltr"><p dir="ltr"><strong>Compute</strong>: Up to 8 × RNGD accelerators (4 petaFLOPS FP8 per server) with dual AMD EPYC processors. Supports BF16, FP8, INT8, and INT4</p></li><li dir="ltr"><p dir="ltr"><strong>Memory</strong>: 384 GB HBM3 (12 TB/s bandwidth) plus 1 TB DDR5 system memory</p></li><li dir="ltr"><p dir="ltr"><strong>Storage</strong>: 2 × 960 GB NVMe M.2 (OS), 2 × 3.84 TB NVMe U.2 (internal)</p></li><li dir="ltr"><p dir="ltr"><strong>Networking</strong>: 1G management NIC plus 2 × 25G data NICs</p></li><li dir="ltr"><p dir="ltr"><strong>Power &amp; Cooling</strong>: 3 kW system power, redundant 2,000 W Titanium PSUs, air-cooled</p></li><li dir="ltr"><p dir="ltr"><strong>Security &amp; Management</strong>: Secure Boot, TPM, BMC attestation, dual management paths (PCIe + I2C)</p></li><li dir="ltr"><p dir="ltr"><strong>Software</strong>: Preinstalled Furiosa SDK and Furiosa LLM runtime with native Kubernetes and Helm integration</p></li></ul>
<h2 dir="ltr">Real-world benefits and proven performance      </h2>
<p dir="ltr">NXT RNGD Server’s superior power efficiency significantly lowers businesses’ TCO. Enterprise customers can run advanced AI efficiently at scale within current infrastructure and power limitations – using on-prem servers or cloud data centers. This is crucial for leveraging existing infrastructure, since more than <a href="https://www.upsite.com/blog/data-center-cooling-trends-for-2025/" target="_blank" rel="noreferrer noopener">80% of data centers today are air-cooled</a> and operate at <a href="https://www.upsite.com/blog/data-center-trends-rack-density-rises-while-pue-and-outage-frequency-remain-flat/" target="_blank" rel="noreferrer noopener">8 kW per rack or less</a>. <br/></p>
		</div>
	</div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
      
        
  <div>
    <div data-reveal="">
              
					
	
				
	
			
		
		
		
				
	
	
		
							
	<figure data-image="">
		<p><img width="750" height="500" alt="A7 C04997" data-src="https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=500&amp;q=85&amp;transformer=imgix&amp;w=750" data-sizes="auto" data-srcset="https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=500&amp;q=85&amp;transformer=imgix&amp;w=750 750w, https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=85&amp;transformer=imgix&amp;w=1000 1000w, https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=833&amp;q=85&amp;transformer=imgix&amp;w=1250 1250w, https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1000&amp;q=85&amp;transformer=imgix&amp;w=1500 1500w, https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1167&amp;q=85&amp;transformer=imgix&amp;w=1750 1750w, https://furiosa-ai.imgix.net/A7C04997.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=85&amp;transformer=imgix&amp;w=2000 2000w"/>
							
					</p>
					<figcaption>
				
  
  <p>
    <span>FuriosaAI CTO Hanjoon Kim talks with guests at OpenAI&#39;s Seoul launch event.</span>
  </p>
			</figcaption>
			</figure>
          </div>
  </div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
	<div>
		<div data-reveal="">
			

		
		
	
	<p dir="ltr">For businesses with sensitive workloads, regulatory compliance requirements, or enhanced privacy and security needs, NXT RNGD Server offers complete control over enterprise data, with model weights running entirely on local infrastructure.</p>
<p dir="ltr">Global enterprises have validated NXT RNGD Server’s performance. In July, <a href="https://furiosa.ai/blog/lg-ai-research-taps-furiosaai-to-achieve-2-25x-better-llm-inference-in-production-vs-gpus" target="_blank" rel="noreferrer noopener">LG AI Research announced that it has adopted RNGD</a> for inference computing with its EXAONE models. Running LG’s EXAONE 3.5 32B model on a single server with four RNGD cards and a batch size of one, LG AI Research achieved 60 tokens/second with a 4K context window and 50 tokens/second with a 32K context window.</p>
<p dir="ltr">We are now working with LG AI Research to supply NXT RNGD servers to enterprises using EXAONE across key sectors, including electronics, finance, telecommunications, and biotechnology.<br/></p>
		</div>
	</div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
      
        
  <div>
    <div data-reveal="">
              
					
	
				
	
			
		
		
		
				
	
	
		
							
	<figure data-image="">
		<p><img width="750" height="750" alt="RNGD Server Specs" data-src="https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=750&amp;q=85&amp;transformer=imgix&amp;w=750" data-sizes="auto" data-srcset="https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=750&amp;q=85&amp;transformer=imgix&amp;w=750 750w, https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1000&amp;q=85&amp;transformer=imgix&amp;w=1000 1000w, https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1250&amp;q=85&amp;transformer=imgix&amp;w=1250 1250w, https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1500&amp;q=85&amp;transformer=imgix&amp;w=1500 1500w, https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1750&amp;q=85&amp;transformer=imgix&amp;w=1750 1750w, https://furiosa-ai.imgix.net/RNGD-Server-Specs.png?auto=format&amp;crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=85&amp;transformer=imgix&amp;w=2000 2000w"/>
							
					</p>
			</figure>
          </div>
  </div>

		
						
						
									
			
			
			
			
										

						
			
			
						

																

			
	<div>
		<div data-reveal="">
			

		
		
	
	<h2 dir="ltr">Making rapid deployment of advanced AI available to everyone</h2>
<p dir="ltr">With global data center demand at 60 GW in 2024 and <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/ai-power-expanding-data-center-capacity-to-meet-growing-demand" target="_blank" rel="noreferrer noopener">expected to triple</a> by the end of the decade, the industry faces a once-in-a-generation transformation. More than 80 percent of facilities today are air-cooled and operate at 8 kW per rack or less, making them poorly suited for GPU-based systems that require liquid cooling and 10 kW+ per server.</p>
<p dir="ltr">NXT RNGD Server provides a practical path forward. It allows organizations to deploy advanced AI within their existing facilities, without prohibitive energy costs or disruptive retrofits. Engineered as a plug-and-play system, NXT RNGD combines AI-optimized silicon with Furiosa LLM, a vLLM-compatible serving framework featuring built-in OpenAI API support, enabling organizations to deploy and scale AI workloads from day one. </p>
<p dir="ltr">By combining silicon and system design, NXT RNGD Server makes efficient, enterprise-ready, and future-proof AI infrastructure a reality.</p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">We are taking inquiries and orders for January 2026.</p>
<p>Download the datasheet <a href="https://furiosa.ai/download/FuriosaAI-nxt-rngd-server-datasheet" target="_blank" rel="noreferrer noopener">here</a> and sign up for RNGD updates <a href="https://furiosa.ai/signup" target="_blank" rel="noreferrer noopener">here</a>.</p>
		</div>
	</div>

			</div>
    </div></div>
  </body>
</html>
