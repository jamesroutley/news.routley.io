<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://postgres.ai/blog/20220525-common-db-schema-change-mistakes">Original</a>
    <h1>Common DB schema change mistakes in Postgres</h1>
    
    <div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p><img loading="eager" src="https://postgres.ai/assets/thumbnails/20220525-common-db-schema-change-mistakes2.jpg" alt="Stepping on a &#39;rake db:migrate&#39;" width="825px" height="380px"/></p><p><small>&#39;rake db:migrate&#39; – a command known to any Ruby developer. But how many times did we step on the same rake?</small></p><p>In his article <a href="https://hakibenita.com/postgresql-unknown-features" target="_blank" rel="noopener noreferrer">&#34;Lesser Known PostgreSQL Features&#34;</a>, <a href="https://twitter.com/be_haki" target="_blank" rel="noopener noreferrer">@be_haki</a> describes 18 Postgres features many people don&#39;t know. I enjoyed that article, and it inspired me to write about &#34;anti-features&#34; – things that everyone should avoid when working in probably the riskiest field of application development – so-called &#34;schema migrations&#34;.</p><p>This is one of my favorite topics in the field of relational databases. We all remember how MongoDB entered the stage with two clear messages: &#34;web-scale&#34; (let&#39;s have sharding out-of-the-box) and &#34;schemaless&#34; (let&#39;s avoid designing schemas and allow full flexibility). In my opinion, both buzzwords are an oversimplification, but if you have experience in reviewing and deploying schema changes in relational databases, you probably understand the level of difficulty, risks, and pain of scaling the process of making schema changes. My personal score: 1000+ migrations designed/reviewed/deployed during 17+ years of using Postgres in my own companies and when consulting others such as GitLab, Chewy, Miro. Here I&#39;m going to share what I&#39;ve learned, describing some mistakes I&#39;ve made or observed – so probably next time you&#39;ll avoid them.</p><p>Moreover, a strong desire to help people avoid such mistakes led me to invent the <a href="https://github.com/postgres-ai/database-lab-engine" target="_blank" rel="noopener noreferrer">Database Lab Engine</a> – a technology for thin cloning of databases, essential for development and testing. With it, you can clone a 10 TiB database in 10 seconds, test schema changes, and understand the risks before deployment. Most cases discussed in this article can be easily detected by such testing, and it can be done automatically in CI/CD pipelines.</p><p>As usual, I&#39;ll be focusing on OLTP use cases (mobile and web apps), for which query execution that exceeds 1 second is normally considered too slow. Some cases discussed here are hard to notice in small databases with low activity. But I&#39;m pretty confident that you&#39;ll encounter most of them when your database grows to ~10 TiB in size and its load reaches ~10<sup>5</sup>–10<sup>6</sup> transactions per second (of course, some cases will be seen – unless deliberately prevented. – much, much earlier).</p><p>I advise you to read GitLab&#39;s great documentation – their <a href="https://docs.gitlab.com/ee/development/migration_style_guide.html" target="_blank" rel="noopener noreferrer">Migration Style Guide</a> is full of wisdom written by those who have experience in deploying numerous Postgres schema changes in a fully automated fashion to a huge number of instances, including GitLab.com itself.</p><p>I also encourage everyone to watch <a href="https://www.pgcon.org/2022/" target="_blank" rel="noopener noreferrer">PGCon-2022</a> – one of the key Postgres conferences; this time, it&#39;s happening online again. On Thursday, May 26, I&#39;ll give two talks, and one of them is called <a href="https://www.pgcon.org/events/pgcon_2022/schedule/session/268-common-db-schema-change-mistakes/" target="_blank" rel="noopener noreferrer">&#34;Common DB schema change mistakes&#34;</a>, you find the slide deck <a href="https://docs.google.com/presentation/d/1j8I-vimymMXj4iK7klhiveH7BYCGLNeu8GLhWr-OAyY/edit?usp=sharing" target="_blank" rel="noopener noreferrer">here</a>. If you missed it, no worries – <a href="https://twitter.com/DLangille" target="_blank" rel="noopener noreferrer">@DLangille</a>, who has organized the conference since 2006 (thank you, Dan!), promises to publish talk videos in a few weeks.</p><h2 id="table-of-contents">Table of Contents<a href="#table-of-contents" aria-label="Direct link to Table of Contents" title="Direct link to Table of Contents">​</a></h2><ul><li><a href="#terminology">Terminology</a></li><li><a href="#three-categories-of-db-migration-mistakes">Three categories of DB migration mistakes</a></li><li><a href="#case-1-schema-mismatch">Case 1. Schema mismatch</a></li><li><a href="#case-2-misuse-of-if-not-exists">Case 2. Misuse of IF [NOT] EXISTS</a></li><li><a href="#case-3-hitting-statement_timeout">Case 3. Hitting <code>statement_timeout</code></a></li><li><a href="#case-4-unlimited-massive-change">Case 4. Unlimited massive change</a></li><li><a href="#case-5-acquire-an-exclusive-lock--wait-in-transaction">Case 5. Acquire an exclusive lock + wait in transaction</a></li><li><a href="#case-6-a-transaction-with-ddl--massive-dml">Case 6. A transaction with DDL + massive DML</a></li><li><a href="#case-7-waiting-to-acquire-an-exclusive-lock-for-long--blocking-others">Case 7. Waiting to acquire an exclusive lock for long ⇒ blocking others)</a></li><li><a href="#case-8-careless-creation-of-an-fk">Case 8. Careless creation of an FK</a></li><li><a href="#case-9-careless-removal-of-an-fk">Case 9. Careless removal of an FK</a></li><li><a href="#case-10-careless-addition-of-a-check-constraint">Case 10. Careless addition of a <code>CHECK</code> constraint</a></li><li><a href="#case-11-careless-addition-of-not-null">Case 11. Careless addition of <code>NOT NULL</code></a></li><li><a href="#case-12-careless-change-of-columns-data-type">Case 12. Careless change of column&#39;s data type</a></li><li><a href="#case-13-careless-create-index">Case 13. Careless <code>CREATE INDEX</code></a></li><li><a href="#case-14-careless-drop-index">Case 14. Careless <code>DROP INDEX</code></a></li><li><a href="#case-15-renaming-objects">Case 15. Renaming objects</a></li><li><a href="#case-16-add-a-column-with-default">Case 16. Add a column with <code>DEFAULT</code></a></li><li><a href="#case-17-leftovers-of-create-index-concurrently">Case 17. Leftovers of <code>CREATE INDEX CONCURRENTLY</code></a></li><li><a href="#case-18-4-byte-integer-primary-keys-for-large-tables">Case 18. 4-byte integer primary keys for large tables</a></li><li><a href="#recommendations">Recommendations</a></li></ul><h2 id="terminology">Terminology<a href="#terminology" aria-label="Direct link to Terminology" title="Direct link to Terminology">​</a></h2><p>The term &#34;DB migration&#34; may be confusing; it&#39;s often used to describe the task of switching from one database system to another, moving the database, and minimizing possible negative effects (such as long downtime).</p><p>In this article, I&#39;m going to talk about the second meaning of the term – DB schema changes having the following properties:</p><ul><li>&#34;incremental&#34;: changes are performed in steps;</li><li>&#34;reversible&#34;: it is possible to &#34;undo&#34; any change, returning to the original state of the schema (and data; which, in some cases, may be difficult or impossible);</li><li>&#34;versionable&#34;: some version control system is used (such as Git).</li></ul><p>I prefer using the adjusted term, &#34;DB schema migration&#34;. However, we need to remember that many schema changes imply data changes – for example, changing a column data type from integer to text requires a full table rewrite, which is a non-trivial task in heavily-loaded large databases.</p><p>Application DBA – a database engineer responsible for tasks such as DB schema design, development and deployment of changes, query performance optimization, and so on, while &#34;Infrastructure DBA&#34; is responsible for database provisioning, replication, backups, global configuration. The term &#34;Application DBA&#34; was explained by <a href="https://twitter.com/be_haki" target="_blank" rel="noopener noreferrer">@be_haki</a> in <a href="https://hakibenita.medium.com/some-sql-tricks-of-an-application-dba-3145001d999f" target="_blank" rel="noopener noreferrer">&#34;Some SQL Tricks of an Application DBA&#34;</a>.</p><p>Finally, the usual suspects in our small terminology list:</p><ul><li>DML – database manipulation language (<code>SELECT</code> / <code>INSERT</code> / <code>UPDATE</code> / <code>DELETE</code>, etc.)</li><li>DDL – data definition language (<code>CREATE …</code>, <code>ALTER …</code>, <code>DROP …</code>)</li></ul><h2 id="three-categories-of-db-migration-mistakes">Three categories of DB migration mistakes<a href="#three-categories-of-db-migration-mistakes" aria-label="Direct link to Three categories of DB migration mistakes" title="Direct link to Three categories of DB migration mistakes">​</a></h2><p>I distinguish three big categories of DB schema migration mistakes:</p><ol><li>Concurrency-related mistakes. This is the largest category, usually determining a significant part of an application DBA&#39;s experience. Some examples (skipping details; we&#39;ll talk about them soon):<ul><li>Failure to acquire a lock</li><li>Updating too many rows at once</li><li>Acquired an exclusive lock and left transaction open for long</li></ul></li><li>Mistakes related to the correctness of steps – logical issues. Examples:<ul><li>Unexpected schema deviations</li><li>Schema/app code mismatch</li><li>Unexpected data</li></ul></li><li>Miscellaneous – mistakes related to the implementation of some specific database feature or the configuration of a particular database, e.g.:<ul><li>Reaching statement_timeout</li><li>Use of 4-byte integer primary keys in tables that can grow</li><li>Ignoring VACUUM behavior and bloat risks</li></ul></li></ol><h2 id="case-1-schema-mismatch">Case 1. Schema mismatch<a href="#case-1-schema-mismatch" aria-label="Direct link to Case 1. Schema mismatch" title="Direct link to Case 1. Schema mismatch">​</a></h2><p>Let&#39;s start with an elementary example. Assume we need to deploy the following DDL:</p><p>It worked well when we developed and tested it. But later, it failed during testing in some test/QA or staging environment, or – in the worst case – during deployment attempt on production:</p><div><div><pre tabindex="0"><code><span><span>ERROR:  relation &#34;t1&#34; already exists</span><br/></span></code></pre></div></div><p>Reasons for this problem may vary. For example, the table could be created by breaking the workflow (for example, manually). To fix it, we should investigate how the table was created and why the process wasn&#39;t followed, and then we need to find a way to establish a good workflow to avoid such cases.</p><p>Unfortunately, people often choose another way to &#34;fix&#34; it – leading us to the second case.</p><h2 id="case-2-misuse-of-if-not-exists">Case 2. Misuse of <code>IF [NOT] EXISTS</code><a href="#case-2-misuse-of-if-not-exists" aria-label="Direct link to case-2-misuse-of-if-not-exists" title="Direct link to case-2-misuse-of-if-not-exists">​</a></h2><p>Observing schema mismatch errors such as those above may lead to the &#34;give up&#34; kind of fix: instead of finding the error&#39;s root cause, engineers often choose to patch their code blindly. For the example above it can be the following:</p><div><div><pre tabindex="0"><code><span><span>create</span><span> </span><span>table</span><span> </span><span>if</span><span> </span><span>not</span><span> </span><span>exists</span><span> t1</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p>If this code is used not for benchmarking or testing scripts but to define some application schema, this approach is usually a bad idea. It masks the problem with logic, adding some risks of anomalies. An obvious example of such an anomaly: an existing table that has a different structure than table we were going to create. In my example, I used an &#34;empty&#34; set of columns (in reality, there are always some columns – Postgres creates hidden, system columns such as <code>xmin</code>, <code>xmax</code> and <code>ctid</code>, you can read about them in Postgres docs, <a href="https://www.postgresql.org/docs/current/ddl-system-columns.html" target="_blank" rel="noopener noreferrer">&#34;5.5. System Columns&#34;</a>, so each row always have a few columns; try: <code>insert into t1 select; select ctid, xmin, xmax from t1;</code>).</p><p>I observe this approach quite often, probably in every other engineering team I work with. A detailed analysis of this problem is given in <a href="https://postgres.ai/blog/20211103-three-cases-against-if-not-exists-and-if-exists-in-postgresql-ddl" target="_blank" rel="noopener noreferrer">&#34;Three Cases Against IF NOT EXISTS / IF EXISTS in Postgres DDL&#34;</a>.</p><p>If you&#39;re using a DB schema migration tool such as Sqitch, Liquibase, Flyway, or one embedded in your framework (Ruby on Rails, Django, Yii, and others have it), you probably test the migration stems in CI/CD pipelines. If you start testing the chain DO-UNDO-DO (apply the change, revert it, and re-apply again), it can help with detecting some undesired use of <code>IF [NOT] EXISTS</code>. Of course, keeping schemas in all environments up-to-date and respecting all observed errors, not ignoring them, and not choosing &#34;workaround&#34; paths such as <code>IF [NOT] EXISTS</code>, can be considered good engineering practices.</p><h2 id="case-3-hitting-statement_timeout">Case 3. Hitting <code>statement_timeout</code><a href="#case-3-hitting-statement_timeout" aria-label="Direct link to case-3-hitting-statement_timeout" title="Direct link to case-3-hitting-statement_timeout">​</a></h2><p>This one is pretty common if testing environments don&#39;t have large tables and testing procedures are not mature:</p><div><div><pre tabindex="0"><code><span><span>ERROR: canceling statement due to statement timeout</span><br/></span></code></pre></div></div><p>Even if both production and non-production environments use identical <code>statement_timeout</code> settings, the smaller tables are, the faster queries are executed. This can easily lead to a situation when a timeout is reached only on production.</p><p>I strongly recommend testing <em>all</em> changes on large volumes of data so such problems will be observed much earlier in dev-test-deploy pipelines. The most powerful approach here is using thin clones of full-size databases as early in the pipelines as possible – preferably right during development. Check out our <a href="https://github.com/postgres-ai/database-lab-engine" target="_blank" rel="noopener noreferrer">Database Lab Engine</a> and let us know if you have questions (for example, on Twitter: <a href="https://twitter.com/Database_Lab" target="_blank" rel="noopener noreferrer">@Database_Lab</a>).</p><h2 id="case-4-unlimited-massive-change">Case 4. Unlimited massive change<a href="#case-4-unlimited-massive-change" aria-label="Direct link to Case 4. Unlimited massive change" title="Direct link to Case 4. Unlimited massive change">​</a></h2><p>An <code>UPDATE</code> or <code>DELETE</code> targeting too many rows is a bad idea, as everyone knows. But why?</p><p>Some example:</p><div><div><pre tabindex="0"><code><span><span>test=# explain (buffers, analyze) update t1</span><br/></span><span><span>       set val = replace(val, &#39;0159&#39;, &#39;OiSg&#39;);</span><br/></span><span><span></span><br/></span><span><span></span><br/></span><span><span>                                               QUERY PLAN</span><br/></span><span><span>--------------------------------------------------------------------------------------------------------</span><br/></span><span><span> Update on t1  (cost=0.00..189165.00 rows=10000000 width=42) (actual time=76024.507..76024.508 rows=0 loops=1)</span><br/></span><span><span>   Buffers: shared hit=60154265 read=91606 dirtied=183191 written=198198</span><br/></span><span><span>   -&gt;  Seq Scan on t1  (cost=0.00..189165.00 rows=10000000 width=42) (actual time=0.367..2227.103 rows=10000000 loops=1)</span><br/></span><span><span>         Buffers: shared read=64165 written=37703</span><br/></span><span><span> Planning:</span><br/></span><span><span>   Buffers: shared hit=17 read=1 dirtied=1</span><br/></span><span><span> Planning Time: 0.497 ms</span><br/></span><span><span> Execution Time: 76024.546 ms</span><br/></span><span><span>(8 rows)</span><br/></span><span><span></span><br/></span><span><span>Time: 76030.399 ms (01:16.030)</span><br/></span></code></pre></div></div><p>Potential problems that may disturb production:</p><ul><li>Modifying too many rows in a transaction (here, we have a single-query transaction) means that those rows will be locked for modifications until our transaction finishes. This can affect other transactions, potentially worsening the user experience. For example, if some user tries to modify one of the locked rows, their modification attempt may take very long.</li><li>If the checkpointer is not well-tuned (for example, the <code>max_wal_size</code> value is left default, <code>1GB</code>), checkpoints may occur very often during such a massive operation. With <code>full_page_writes</code> being <code>on</code> (default), this leads to excessive generation of WAL data.</li><li>Moreover, if the disk system is not powerful enough, the IO generated by the checkpointer may saturate the write capabilities of the disks, leading to general performance degradation.</li><li>If our massive operation is based on some index and data modifications happen in pages in random order, re-visiting a single page multiple times, with untuned checkpointer and frequent checkpoints, one buffer may pass multiple dirty-clean cycles, meaning that we have redundant write operations.</li><li>Finally, we may have two types of VACUUM/bloat issues here. First, if we&#39;re changing a lot of tuples in a single transaction with UPDATE or DELETE, a lot of dead tuples are produced. Even if autovacuum cleans them up soon, there are high chances that such a mass of dead tuples will be directly converted to bloat, leading to extra disk consumption and potential performance degradation. Second, during the long transaction, the autovacuum cannot clean up dead tuples in <em>any</em> table that became dead during our transaction – until this transaction stops.</li></ul><p>What to do?</p><ul><li>Consider splitting the work into batches, each one being a separate transaction. If you&#39;re working in the OLTP context (mobile or web apps), the batch size should be determined so the expected processing of <em>any</em> batch won&#39;t exceed 1 second. To understand why I recommend 1 second as a soft threshold for batch processing, read the article <a href="https://postgres.ai/blog/20210909-what-is-a-slow-sql-query" target="_blank" rel="noopener noreferrer">&#34;What is a slow SQL query?&#34;</a></li><li>Take care of VACUUMing – tune autovacuum and/or consider using explicit <code>VACUUM</code> calls after some number of batches processed.</li><li>Finally, as an extra protection measure, tune the checkpointer so that even if a massive change happens, our database&#39;s negative effect is not so acute. I recommend reading <a href="https://www.2ndquadrant.com/en/blog/basics-of-tuning-checkpoints/" target="_blank" rel="noopener noreferrer">&#34;Basics of Tuning Checkpoints&#34;</a> by Tomáš Vondra.</li></ul><h2 id="case-5-acquire-an-exclusive-lock--wait-in-transaction">Case 5. Acquire an exclusive lock + wait in transaction<a href="#case-5-acquire-an-exclusive-lock--wait-in-transaction" aria-label="Direct link to Case 5. Acquire an exclusive lock + wait in transaction" title="Direct link to Case 5. Acquire an exclusive lock + wait in transaction">​</a></h2><p><img loading="lazy" src="https://postgres.ai/assets/blog/20220523-holding-lock-for-long-2.png" alt="Concurrency issues – holding an acquired lock for long"/></p><p>In the previous case, we touched on the problem of holding exclusive locks for long. These can be locked rows (implicitly via <code>UPDATE</code> or <code>DELETE</code> or explicitly via <code>SELECT .. FOR UPDATE</code>) or database objects (example: successful <code>ALTER TABLE</code> inside a transaction block locks the table and holds the lock until the end of the transaction). If you need to learn more about locks in Postgres, read the article <a href="https://www.citusdata.com/blog/2018/02/15/when-postgresql-blocks/" target="_blank" rel="noopener noreferrer">&#34;PostgreSQL rocks, except when it blocks: Understanding locks&#34;</a> by Marco Slot.</p><p>An abstract example of the general issue with locking:</p><div><div><pre tabindex="0"><code><span><span>begin</span><span>;</span><span></span><br/></span><span><span></span><span>alter</span><span> </span><span>table</span><span> t1 </span><span>add</span><span> </span><span>column</span><span> c123 int8</span><span>;</span><span></span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>commit</span><span>;</span><br/></span></code></pre></div></div><p>The reason for sitting inside a transaction after lock acquisition may vary. However, sometimes it is nothing – a simple waiting with an open transaction and acquired lock. This is the most annoying reason that can quickly lead to various performance or even partial downtime: an exclusive lock to a table blocks even SELECTs to this table.</p><div><p><span><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</p><p>Remember: any lock acquired in a transaction is held until the very end of this transaction. It is released only when the transaction finishes, with either COMMIT or ROLLBACK.</p></div><p>Every time we acquire an exclusive lock, we should think about finishing the transaction as soon as possible.</p><h2 id="case-6-a-transaction-with-ddl--massive-dml">Case 6. A transaction with DDL + massive DML<a href="#case-6-a-transaction-with-ddl--massive-dml" aria-label="Direct link to Case 6. A transaction with DDL + massive DML" title="Direct link to Case 6. A transaction with DDL + massive DML">​</a></h2><p>This one is a subcase of the previous case. I describe it separately because it can be considered a common anti-pattern that is quite easy to encounter when developing DB migrations. Here is it in pseudocode:</p><div><div><pre tabindex="0"><code><span><span>begin</span><span>;</span><span></span><br/></span><span><span></span><span>alter</span><span> </span><span>table</span><span> t1 </span><span>add</span><span> </span><span>column</span><span> c123 int8</span><span>;</span><span></span><br/></span><span><span>copy </span><span>.</span><span>.</span><span>.</span><span> </span><span></span><br/></span><span><span></span><span>commit</span><span>;</span><br/></span></code></pre></div></div><p>If the DML step takes significant time, as we already discussed, the locks acquired on the previous step (DDL) will be held long too. This can lead to performance degradation or partial downtime.</p><p>Basic rules to follow:</p><ul><li>DML never should go after DDL unless they both deal with some freshly created table</li><li>It is usually wise to split DDL and DML activities into separate transactions / migration steps</li><li>Finally, remember that massive changes should go in batches? Each batch is a separate transaction – so if you follow this rule and have used large data volumes when testing changes in CI/CD pipelines, you should never encounter this case</li></ul><h2 id="case-7-waiting-to-acquire-an-exclusive-lock-for-long--blocking-others">Case 7. Waiting to acquire an exclusive lock for long ⇒ blocking others<a href="#case-7-waiting-to-acquire-an-exclusive-lock-for-long--blocking-others" aria-label="Direct link to Case 7. Waiting to acquire an exclusive lock for long ⇒ blocking others" title="Direct link to Case 7. Waiting to acquire an exclusive lock for long ⇒ blocking others">​</a></h2><p>This problem might happen with most ALTER commands deployed in a careless fashion – but for small, not heavily loaded databases, the chances are quite small, so the problem may remain unnoticed for a long time, until someday it hits in an ugly way, triggering the questions like &#34;How dare could we live with this?&#34; (I passed thru this process with a few teams, it was always quite embarrassing.)</p><p>We&#39;ve discussed what happens when an exclusive lock is acquired and then it&#39;s being held for too long. But what if we cannot acquire it?</p><p>This event may happen, and in heavily-loaded large databases, it&#39;s pretty common. For example, this may happen because the autovacuum is processing the table we&#39;re trying to modify, and it doesn&#39;t yield – normally, it does, but not when running in the transaction ID wraparound prevention mode. This mode is considered by Postgres as a severe state that must be handled ASAP, so regular logic of autovacuum interrupting its work to allow DDL to succeed won&#39;t work here. In this case, usually, it&#39;s better to just wait.</p><p>But that&#39;s not the worst part of this case. What&#39;s really bad is the fact that while we&#39;re waiting to acquire a lock, if our timeout settings (<code>statement_timeout</code> and <code>lock_timeout</code>) are set to 0 (default) or quite large (&gt;&gt; 1s), we&#39;re going to block <em>all</em> queries to this table, even SELECTs. I talk about this particular problem in the article <a href="https://postgres.ai/blog/20210923-zero-downtime-postgres-schema-migrations-lock-timeout-and-retries" target="_blank" rel="noopener noreferrer">&#34;Zero-downtime Postgres schema migrations need this: lock_timeout and retries&#34;</a>.</p><p>What to do here? For all (!) DB migrations, except those that create brand new DB objects or use <code>CREATE/DROP INDEX CONCURRENTLY</code> (discussed below), you should have retry logic with low <code>lock_timeout</code>, <a href="https://postgres.ai/blog/20210923-zero-downtime-postgres-schema-migrations-lock-timeout-and-retries#graceful-schema-changes-lock_timeout-and-retries" target="_blank" rel="noopener noreferrer">as I describe in my article</a>. This is a fundamental mechanism that everyone needs to have – I think at some point, either Postgres or popular DB schema migration tools will implement it so the world of application DBA will become better.</p><h2 id="case-8-careless-creation-of-an-fk">Case 8. Careless creation of an FK<a href="#case-8-careless-creation-of-an-fk" aria-label="Direct link to Case 8. Careless creation of an FK" title="Direct link to Case 8. Careless creation of an FK">​</a></h2><p>In <a href="#case-5-acquire-an-exclusive-lock--wait-in-transaction">Case 5</a>, we&#39;ve discussed a transaction consisting of a successful DDL acquiring an exclusive lock and some actions (or lack of them) in the same transaction. But sometimes, a single-statement transaction – a DDL – can combine a lock acquisition and some work that increases the duration of the operation, leading to similar effects. That work can be either reading or data modification; the longer it lasts, the longer the operation will be, and the more risks of blocking other sessions we have.</p><p>We&#39;ll discuss several cases with such a nature – a DDL operation whose duration is prolonged because of the need to read or modify some data. These cases are quite similar, but I want to recognize them individually because there are nuances for each one of them.</p><p>The first case in this series is the creation of a foreign key on two existing tables which are large and busy:</p><div><div><pre tabindex="0"><code><span><span>alter</span><span> </span><span>table</span><span> orders </span><span>add</span><span> </span><span>constraint</span><span> fk_orders_customers </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>customer_id</span><span>)</span><span> </span><span>references</span><span> customers </span><span>(</span><span>id</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p>Here we can have two issues we&#39;ve already discussed:</p><ol><li>The metadata for two tables needs to be adjusted, so we need two locks – and if one is acquired but the second one is not, and we&#39;re waiting for it, we&#39;re going to experience blocking issues (for both tables!)</li><li>When an FK is introduced, Postgres needs to check the presence of this value in the referenced table for each value used in the referencing table. It may take a while – and during this time, locks are going to be held.</li></ol><p>To avoid these issues:</p><ul><li>Use a two-step approach: first, define the FK with the <code>not valid</code> option, then, in a separate transaction, run <code>alter table … validate constraint …;</code></li><li>When the first ALTER, don&#39;t forget about the retry logic that we discussed above. Note that two table-level exclusive locks are needed.</li></ul><h2 id="case-9-careless-removal-of-an-fk">Case 9. Careless removal of an FK<a href="#case-9-careless-removal-of-an-fk" aria-label="Direct link to Case 9. Careless removal of an FK" title="Direct link to Case 9. Careless removal of an FK">​</a></h2><p>When an FK needs to be dropped, similar considerations have to be applied as in the previous case, except that no data checks are needed. So, when dropping an FK, we need to acquire two table-level exclusive locks, and the retry logic with low <code>lock_timeout</code> can save us from the risks of blocking issues.</p><h2 id="case-10-careless-addition-of-a-check-constraint">Case 10. Careless addition of a <code>CHECK</code> constraint<a href="#case-10-careless-addition-of-a-check-constraint" aria-label="Direct link to case-10-careless-addition-of-a-check-constraint" title="Direct link to case-10-careless-addition-of-a-check-constraint">​</a></h2><p>CHECK constraints are a powerful and really useful mechanism. I like them a lot because they can help us define a strict data model where major checks are done on the database side, so we have a reliable guarantee of high data quality.</p><p>The problem with adding <code>CHECK</code> constraints is very similar to adding foreign key constraints – but it&#39;s simpler because we need to deal with only one table (you cannot reference another table in a <code>CHECK</code> constraint, unfortunately). When we add such a constraint on a large table, a full table scan needs to be performed to ensure that there is no violation of the constraint. This takes time, during which we have a partial downtime – no queries to the table are possible. (Remember the DDL + massive data change case? Here we have a subcase of that.)</p><p>Fortunately, CHECKs support the same approach as we saw for FKs: first, we define this constraint by adding the <code>not valid</code> option. Next, in a separate transaction, we perform validation: <code>alter table … validate constraint …;</code>.</p><p>Dropping such constraints doesn&#39;t imply any risks (although, we still shouldn&#39;t forget about retry logic with low <code>lock_timeout</code> when running the <code>ALTER</code> command).</p><h2 id="case-11-careless-addition-of-not-null">Case 11. Careless addition of <code>NOT NULL</code><a href="#case-11-careless-addition-of-not-null" aria-label="Direct link to case-11-careless-addition-of-not-null" title="Direct link to case-11-careless-addition-of-not-null">​</a></h2><p>This is one of my favorite cases. It is very interesting and often overlooked because, on small and mid-size tables, its negative effect can be left unnoticed. But on a table with, say, one billion rows, this case can lead to partial downtime.</p><p>When we need to forbid NULLs in a column <code>col1</code>, there are two popular ways:</p><ol><li>Use a <code>CHECK</code> constraint with the expression: <code>alter table ... add constraint ... (col1 is not null)</code></li><li>Use a &#34;regular&#34; <code>NOT NULL</code> constraint: <code>alter table ... alter column c1 set not null</code></li></ol><p>The problem with the latter is that, unlike for <code>CHECK</code> constraints, the definition of regular NOT NULL cannot be performed in an &#34;online fashion&#34;, in two steps, as we saw for FKs and CHECKs.</p><p>Let&#39;s always use CHECKs then, one could say. Agreed – the approaches are semantically identical. However, there is one important case, when only regular <code>NOT NULL</code> can be applicable – it&#39;s when we define (or redefine) a primary key on an existing table with lots of data. There we must have a <code>NOT NULL</code> on all columns that are used in the primary key definition – or we&#39;ll get a sudden full-table scan to install the <code>NOT NULL</code> constraint implicitly.</p><p>What to do about this? It depends on the Postgres version:</p><ul><li>Before Postgres 11, there were no &#34;official&#34; ways to avoid partial downtime. The only way was to ensure that no values violate the constraint and edit system catalogs explicitly, which, of course, is not recommended.</li><li>Since Postgres 11, if <code>NOT NULL</code> has to be installed on a new column (quite often a case when we talk about a PK definition), we can use a nice trick:<ul><li>first, add a column with <code>not null default -1</code> (considering that column is of <code>int8</code> type; here we benefit from a great optimization introduced in Postgres 11 – fast creation of column with a default value; our <code>NOT NULL</code> is automagically introduced and enforced because all existing rows get <code>-1</code> in the new column, so there are no NULL values present)</li><li>then backfill all existing rows with values</li><li>and in the end, drop the <code>DEFAULT</code> – the <code>NOT NULL</code> constraint will remain in its place</li></ul></li><li>Finally, in Postgres 12, another great optimization made it possible to introduce a regular, traditional <code>NOT NULL</code> on any column in a fully &#34;online&#34; fashion. What has to be done: first, create a <code>CHECK</code> constraint with <code>(... is not null)</code> expression. Next, define a regular <code>NOT NULL</code> constraint – due to new optimization, the mandatory scan will be skipped because now Postgres understand that there are no NULLs present, thanks to the <code>CHECK</code> constraint. In the end, the CHECK constraint can be dropped because it becomes redundant to our regular NOT NULL one.</li></ul><h2 id="case-12-careless-change-of-columns-data-type">Case 12. Careless change of column&#39;s data type<a href="#case-12-careless-change-of-columns-data-type" aria-label="Direct link to Case 12. Careless change of column&#39;s data type" title="Direct link to Case 12. Careless change of column&#39;s data type">​</a></h2><p>One cannot simply change the data type of a column not thinking about blocking issues. In most cases, you risk getting a full table rewrite when you issue a simple <code>alter table t1 alter column c2 type int8;</code>.</p><p>What to do with it? Create a new column, define a trigger to mirror values from the old one, backfill (in batches, controlling dead tuples and bloat), and then switch your app to use the new column, dropping the old one when fully switched.</p><h2 id="case-13-careless-create-index">Case 13. Careless <code>CREATE INDEX</code><a href="#case-13-careless-create-index" aria-label="Direct link to case-13-careless-create-index" title="Direct link to case-13-careless-create-index">​</a></h2><p>This is a widely known fact – you shouldn&#39;t use <code>CREATE INDEX</code> in OLTP context unless it&#39;s an index on a brand new table that nobody is using yet.</p><p>Everyone should use <code>CREATE INDEX CONCURRENTLY</code>. Although, there are caveats to remember:</p><ul><li>it&#39;s roughly two times slower than regular <code>CREATE INDEX</code></li><li>it cannot be used in transaction blocks</li><li>if it fails (chances are not 0 if you&#39;re building a unique index), an invalid index is left defined for the table, so:<ul><li>deployment system has to be prepared to retry index creation</li><li>after failures, cleanup is needed</li></ul></li></ul><h2 id="case-14-careless-drop-index">Case 14. Careless <code>DROP INDEX</code><a href="#case-14-careless-drop-index" aria-label="Direct link to case-14-careless-drop-index" title="Direct link to case-14-careless-drop-index">​</a></h2><p>Unlike <code>CREATE INDEX</code>, the only issue with <code>DROP INDEX</code> is that it can lead to lock acquisition issues (see <a href="#case-7-waiting-to-acquire-an-exclusive-lock-for-long--blocking-others">Case 7</a>). While for ALTER, there is nothing that can be used to the issues associated with a long-waiting or failing lock acquisition, for <code>DROP INDEX</code> Postgres has <code>DROP INDEX CONCURRENTLY</code>. This looks imbalanced but probably can be explained by the fact that index recreation is what may be needed much more often than <code>ALTER</code> (plus, <code>REINDEX CONCURRENTLY</code> was added in Postgres 12).</p><h2 id="case-15-renaming-objects">Case 15. Renaming objects<a href="#case-15-renaming-objects" aria-label="Direct link to Case 15. Renaming objects" title="Direct link to Case 15. Renaming objects">​</a></h2><p>Renaming a table or a column may become a non-trivial task in a large database receiving lots of SQL traffic.</p><p>The renaming doesn&#39;t look like a hard task – until we look at how the application code works with the database and how changes are deployed on both ends. PostgreSQL DDL supports transactions. (Well, except <code>CREATE INDEX CONCURRENTLY</code>. And the fact that we need batches. And avoid long-lasting exclusive locks. And all the other bells and whistles we already discussed...) Ideally, the deployment of application code – on all nodes that we have, and it might be hundreds or thousands – should happen inside the same transaction, so when renaming is committed, all application nodes have a new version of code already.</p><p>Of course, it&#39;s impossible. So when renaming something, we need to find a way to avoid inconsistencies between application code and DB schema – otherwise, users will be getting errors for a significant period of time.</p><p>One approach can be: to deploy application changes first, adjusting the code to understand both old and new (not yet deployed) schema versions. Then deploy DB changes. Finally, deploy another application code change (cleanup).</p><p>Another approach is more data change intensive, but it may be easier to use for developers once properly automated. It is similar to what was already described in <a href="#case-12-careless-change-of-columns-data-type">Case 12</a> (changing column&#39;s data type):</p><ul><li>Create a new column (with a new name)</li><li>Define a trigger to mirror values from the old one</li><li>Backfill (in batches, controlling dead tuples and bloat)</li><li>Switch your app to use the new column</li><li>Drop the old one when fully switched</li></ul><h2 id="case-16-add-a-column-with-default">Case 16. Add a column with <code>DEFAULT</code><a href="#case-16-add-a-column-with-default" aria-label="Direct link to case-16-add-a-column-with-default" title="Direct link to case-16-add-a-column-with-default">​</a></h2><p>As was already mentioned, before Postgres 11, adding a column with default was a non-trivial and data change intensive task (by default implying a full table rewrite). If you missed that feature somehow, read about it, for example, in <a href="https://brandur.org/postgres-default" target="_blank" rel="noopener noreferrer">&#34;A Missing Link in Postgres 11: Fast Column Creation with Defaults&#34;</a> by <a href="https://twitter.com/brandur" target="_blank" rel="noopener noreferrer">@brandur</a>.</p><p>This is a perfect example of how a long-time painful type of change can be fully automated, so the development and deployment of a DB schema change become simple and risk-free.</p><h2 id="case-17-leftovers-of-create-index-concurrently">Case 17. Leftovers of <code>CREATE INDEX CONCURRENTLY</code><a href="#case-17-leftovers-of-create-index-concurrently" aria-label="Direct link to case-17-leftovers-of-create-index-concurrently" title="Direct link to case-17-leftovers-of-create-index-concurrently">​</a></h2><p>As we already discussed in <a href="#case-13-careless-create-index">Case 13</a>, a failed <code>CREATE INDEX CONCURRENTLY</code> leaves an invalid index behind. If migration scripts don&#39;t expect that, fully automated retries are going to be blocked, so manual intervention would be required. To make retries fully automated, before running <code>CREATE INDEX CONCURRENTLY</code>, we should check if <code>pg_indexes</code>:</p><div><div><pre tabindex="0"><code><span><span>test=# select indexrelid, indexrelid::regclass as indexname, indisvalid</span><br/></span><span><span>from pg_index</span><br/></span><span><span>where not indisvalid and indexrelid::regclass::text = &#39;mytable_title_idx&#39;;</span><br/></span><span><span></span><br/></span><span><span> indexrelid |     indexname     | indisvalid</span><br/></span><span><span>------------+-------------------+------------</span><br/></span><span><span>      26401 | mytable_title_idx | f</span><br/></span><span><span>(1 row)</span><br/></span></code></pre></div></div><p>A complication here could be if the framework you&#39;re using encourages the creation of indexes with unpredictable names – it is usually better to take control over names, making cleanup implementation straightforward.</p><h2 id="case-18-4-byte-integer-primary-keys-for-large-tables">Case 18. 4-byte integer primary keys for large tables<a href="#case-18-4-byte-integer-primary-keys-for-large-tables" aria-label="Direct link to Case 18. 4-byte integer primary keys for large tables" title="Direct link to Case 18. 4-byte integer primary keys for large tables">​</a></h2><p>This is a big topic that is worth a separate article. In most cases, it doesn&#39;t make sense to use <code>int4</code> PKs when defining a new table – and the good news here is that most popular frameworks such as Rails, Django have already switched to using <code>int8</code>. I personally recommend using <code>int8</code> always, even if you don&#39;t expect your table to grow right now – things may change if the project is successful.</p><p>To those who still tend to use <code>int4</code> in surrogate PKs, I have a question. Consider a table with 1 billion rows, with two columns – an integer and a timestamp. Will you see the difference in size between the two versions of the table, <code>(id int4, ts timestamptz)</code> and <code>(id int8, ts timestamptz)</code>. The answer may be surprising to you (in this case, read about <a href="https://stackoverflow.com/questions/2966524/calculating-and-saving-space-in-postgresql/7431468#7431468" target="_blank" rel="noopener noreferrer">&#34;Column Tetris&#34;</a>).</p><h2 id="recommendations">Recommendations<a href="#recommendations" aria-label="Direct link to Recommendations" title="Direct link to Recommendations">​</a></h2><p>In addition to the recommendations provided for each specific case, here are general ones, without specific order:</p><ul><li>Test, test, test. Use realistic data volumes during testing. As already mentioned, <a href="https://github.com/postgres-ai/database-lab-engine" target="_blank" rel="noopener noreferrer">Database Lab Engine (DLE)</a> can be very useful for it.</li><li>When testing, pay attention to how long exclusive locks are held. Check out DLE&#39;s component called <a href="https://postgres.ai/docs/db-migration-checker" target="_blank" rel="noopener noreferrer">&#34;DB Migration Checker&#34;</a>, it can help you automate this kind of testing in CI/CD pipelines.</li><li>For extended lock analysis, use the snipped from my <a href="https://postgres.ai/blog/20211018-postgresql-lock-trees" target="_blank" rel="noopener noreferrer">blog post about lock tree analysis</a>.</li><li>Build better automation for deployment. There are many good examples of great automation, libraries of helpers that allow avoiding downtime and performance issues during (and after) DB migration deployment. GitLab&#39;s <a href="https://gitlab.com/gitlab-org/gitlab-foss/blob/master/lib/gitlab/database/migration_helpers.rb" target="_blank" rel="noopener noreferrer"><code>migration_helpers.rb</code></a> is a great example of such a set of helpers.</li><li>Learn from others and share your knowledge! If you have another idea of what can be mentioned in the list above, send me an email (<code><a href="https://postgres.ai/cdn-cgi/l/email-protection" data-cfemail="bbd5d2d0fbcbd4c8cfdcc9dec895dad2">[email protected]</a></code>) or reach me on Twitter: <a href="https://twitter.com/samokhvalov" target="_blank" rel="noopener noreferrer">@samokhvalov</a>; I&#39;ll be happy to discuss it.</li></ul><div id="author"><p><img src="https://postgres.ai/assets/author/nik.jpg" alt="Nikolay Samokhvalov"/></p><div><h6>Nikolay Samokhvalov</h6><p>CEO &amp; Founder of<!-- --> <a href="https://postgres.ai/">Postgres.ai</a></p><nav><a href="https://twitter.com/samokhvalov" aria-label="Twitter" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 0C4.0302 0 0 4.0302 0 9C0 13.9698 4.0302 18 9 18C13.9698 18 18 13.9698 18 9C18 4.0302 13.9698 0 9 0ZM13.1093 7.01724C13.1133 7.10582 13.1152 7.19481 13.1152 7.28421C13.1152 10.0139 11.0374 13.1616 7.23766 13.1618C6.07104 13.1618 4.98546 12.8198 4.07126 12.2338C4.23289 12.2529 4.39742 12.2624 4.564 12.2624C5.53189 12.2624 6.42261 11.9323 7.12971 11.3781C6.2254 11.3614 5.46295 10.7641 5.19983 9.94331C5.32576 9.96748 5.45526 9.98067 5.58806 9.98067C5.77661 9.98067 5.95926 9.95526 6.13284 9.90788C5.18761 9.71864 4.47556 8.88327 4.47556 7.88297C4.47556 7.87363 4.47556 7.86525 4.47583 7.8566C4.7542 8.01137 5.07253 8.10448 5.41145 8.11491C4.85678 7.74481 4.49217 7.11214 4.49217 6.39542C4.49217 6.01694 4.59448 5.66235 4.77191 5.35707C5.79062 6.60704 7.31305 7.42909 9.02994 7.51547C8.99451 7.36414 8.97624 7.20648 8.97624 7.04443C8.97624 5.90405 9.90143 4.97887 11.0422 4.97887C11.6364 4.97887 12.1731 5.23004 12.5501 5.63159C13.0207 5.53876 13.4626 5.36682 13.8619 5.1302C13.7074 5.61237 13.38 6.01694 12.9534 6.27278C13.3713 6.22279 13.7696 6.11197 14.1397 5.94745C13.8632 6.36177 13.5126 6.72569 13.1093 7.01724Z" fill="currentColor"></path></svg></a><a href="https://gitlab.com/NikolayS" aria-label="Gitlab" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.81657 14.2023C8.81752 14.2032 8.81847 14.204 8.81945 14.2048C8.82084 14.2059 8.8223 14.207 8.82377 14.208L8.82605 14.2096L8.82472 14.2085C8.81676 14.2024 8.80915 14.1959 8.80191 14.189L8.80074 14.188L8.79986 14.1872C8.80324 14.1906 8.80678 14.1938 8.81038 14.1969C8.81221 14.1986 8.81408 14.2002 8.81597 14.2018L8.81657 14.2023Z" fill="currentColor"></path><path d="M9.14091 14.1983L9.14247 14.1969C9.14601 14.1938 9.14949 14.1907 9.15283 14.1874L9.1517 14.1884L9.15078 14.1891C9.14361 14.1961 9.13584 14.2027 9.12788 14.2087L9.12677 14.2097C9.12787 14.2088 9.12899 14.2081 9.13009 14.2073C9.13119 14.2065 9.13227 14.2057 9.13331 14.2048C9.13426 14.204 9.13518 14.2032 9.13616 14.2024L9.13682 14.2018C9.13821 14.2006 9.13955 14.1995 9.14091 14.1983Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M9 18C13.9706 18 18 13.9706 18 9C18 4.02944 13.9706 0 9 0C4.02944 0 0 4.02944 0 9C0 13.9706 4.02944 18 9 18ZM13.7284 8.12794L14.2985 9.88984C14.3845 10.1559 14.2911 10.4449 14.0661 10.6092L9.12475 14.2115C9.12402 14.212 9.12317 14.2123 9.12244 14.2129L9.12194 14.2132L9.12001 14.2144C9.1124 14.2197 9.1045 14.2245 9.09635 14.229C9.09518 14.2296 9.09411 14.2305 9.09294 14.2311L9.09083 14.2323L9.08918 14.233L9.08798 14.2335C9.08703 14.2339 9.08599 14.2342 9.08501 14.2347C9.0829 14.2357 9.08074 14.2366 9.07857 14.2375C9.07664 14.2383 9.0747 14.239 9.07279 14.2398C9.0712 14.2405 9.06964 14.2412 9.06808 14.2419C9.06531 14.2431 9.06255 14.2443 9.05968 14.2453L9.05914 14.2455L9.05712 14.2464L9.05619 14.2467C9.05561 14.247 9.05503 14.2472 9.05444 14.2474L9.05336 14.2476C9.05274 14.2478 9.05211 14.2479 9.05149 14.2481C9.05093 14.2482 9.05037 14.2483 9.04982 14.2485L9.04859 14.2488C9.04269 14.2505 9.03662 14.2518 9.03059 14.2532C9.02935 14.2534 9.02814 14.2538 9.02692 14.2541C9.02572 14.2544 9.02452 14.2547 9.02329 14.255L9.01997 14.2558C9.01927 14.2559 9.01859 14.2561 9.01791 14.2562C9.0173 14.2564 9.01668 14.2565 9.01605 14.2566C9.01501 14.2568 9.01391 14.2567 9.01287 14.2569L9.01217 14.2569C9.00643 14.2577 9.00055 14.2584 8.99464 14.2589C8.98851 14.2594 8.98233 14.2597 8.97619 14.2597C8.96416 14.2597 8.95218 14.2586 8.94053 14.2569L8.93999 14.2569C8.93923 14.2567 8.93845 14.2567 8.93768 14.2567C8.9374 14.2567 8.93711 14.2566 8.93683 14.2566C8.9361 14.2565 8.93538 14.2563 8.93467 14.2562C8.9341 14.256 8.93352 14.2559 8.93294 14.2558C8.93212 14.2557 8.93061 14.2552 8.93061 14.2552L8.92957 14.255C8.92842 14.2547 8.9273 14.2545 8.92619 14.2542C8.92494 14.2538 8.92369 14.2535 8.92242 14.2532C8.91969 14.2526 8.91694 14.252 8.91421 14.2514C8.91083 14.2506 8.90748 14.2497 8.9042 14.2487L8.90287 14.2484C8.90236 14.2483 8.90182 14.2482 8.90129 14.248C8.90067 14.2479 8.90005 14.2478 8.89946 14.2476L8.89842 14.2473C8.89784 14.2472 8.89728 14.2469 8.89671 14.2467L8.8958 14.2464L8.89374 14.2455L8.89321 14.2453C8.88897 14.2438 8.88496 14.2418 8.88082 14.2401L8.87737 14.2387C8.87407 14.2374 8.87077 14.2361 8.86759 14.2346C8.86667 14.2341 8.86566 14.2338 8.86474 14.2334L8.86358 14.2329L8.86196 14.2322L8.85988 14.2311C8.85928 14.2307 8.85872 14.2304 8.85815 14.23C8.85764 14.2297 8.85713 14.2293 8.8566 14.229C8.84838 14.2246 8.84033 14.2196 8.83268 14.2143L8.83183 14.2137L8.83082 14.2131L8.83041 14.2129C8.82968 14.2123 8.82886 14.212 8.82814 14.2115L3.88752 10.6093C3.66236 10.445 3.56895 10.1559 3.65503 9.88991L4.22732 8.12753L4.22748 8.12709L5.35612 4.63381C5.4187 4.44755 5.58937 4.32469 5.78222 4.32469H5.78459C5.98044 4.3257 6.14612 4.44692 6.20664 4.63346L7.2829 7.95242H10.6725L11.7468 4.63365C11.8074 4.44692 11.9731 4.3257 12.1689 4.32469C12.3642 4.32313 12.5346 4.44676 12.5965 4.63096L13.7282 8.12744L13.7284 8.12794ZM8.83082 14.2131C8.83166 14.2137 8.83249 14.2143 8.83333 14.215C8.83445 14.2158 8.83557 14.2166 8.83672 14.2174C8.8352 14.2164 8.83372 14.2153 8.83223 14.2142L8.83082 14.2131Z" fill="currentColor"></path></svg></a><a href="https://github.com/NikolayS" aria-label="Github" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 0C4.0275 0 0 4.13211 0 9.22838C0 13.3065 2.5785 16.7648 6.15375 17.9841C6.60375 18.0709 6.76875 17.7853 6.76875 17.5403C6.76875 17.3212 6.76125 16.7405 6.7575 15.9712C4.254 16.5277 3.726 14.7332 3.726 14.7332C3.3165 13.6681 2.72475 13.3832 2.72475 13.3832C1.9095 12.8111 2.78775 12.8229 2.78775 12.8229C3.6915 12.887 4.16625 13.7737 4.16625 13.7737C4.96875 15.1847 6.273 14.777 6.7875 14.5414C6.8685 13.9443 7.10025 13.5381 7.3575 13.3073C5.35875 13.0764 3.258 12.2829 3.258 8.74709C3.258 7.73988 3.60675 6.91659 4.18425 6.27095C4.083 6.03774 3.77925 5.0994 4.263 3.82846C4.263 3.82846 5.01675 3.58116 6.738 4.77462C7.458 4.56958 8.223 4.46785 8.988 4.46315C9.753 4.46785 10.518 4.56958 11.238 4.77462C12.948 3.58116 13.7017 3.82846 13.7017 3.82846C14.1855 5.0994 13.8817 6.03774 13.7917 6.27095C14.3655 6.91659 14.7142 7.73988 14.7142 8.74709C14.7142 12.2923 12.6105 13.0725 10.608 13.2995C10.923 13.5765 11.2155 14.1423 11.2155 15.0071C11.2155 16.242 11.2043 17.2344 11.2043 17.5341C11.2043 17.7759 11.3617 18.0647 11.823 17.9723C15.4238 16.7609 18 13.3002 18 9.22838C18 4.13211 13.9702 0 9 0V0Z" fill="currentColor"></path></svg></a><a href="https://www.linkedin.com/in/samokhvalov" aria-label="Linkedin" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 0C4.0302 0 0 4.0302 0 9C0 13.9698 4.0302 18 9 18C13.9698 18 18 13.9698 18 9C18 4.0302 13.9698 0 9 0ZM6.3847 13.6055H4.19279V7.01106H6.3847V13.6055ZM5.28882 6.1106H5.27454C4.539 6.1106 4.06329 5.60426 4.06329 4.97145C4.06329 4.32436 4.55356 3.83203 5.30338 3.83203C6.05319 3.83203 6.51462 4.32436 6.5289 4.97145C6.5289 5.60426 6.05319 6.1106 5.28882 6.1106ZM14.2883 13.6055H12.0966V10.0776C12.0966 9.19102 11.7793 8.58636 10.9862 8.58636C10.3807 8.58636 10.0201 8.99423 9.8616 9.38795C9.80365 9.52885 9.78951 9.72578 9.78951 9.92285V13.6055H7.59773C7.59773 13.6055 7.62643 7.62973 7.59773 7.01106H9.78951V7.94476C10.0808 7.49542 10.6019 6.85629 11.7648 6.85629C13.2069 6.85629 14.2883 7.79878 14.2883 9.82425V13.6055Z" fill="currentColor"></path></svg></a></nav><p>Working on tools to balance Dev with Ops in DevOps</p></div></div><div><p><img src="https://postgres.ai/assets/db-lab-logo.svg" alt="Database Lab" width="224px" height="170px"/></p><div><h6>Database Lab by Postgres.ai</h6><p>An open-source experimentation platform for PostgreSQL databases. Instantly create full-size clones of your production database and use them to test your database migrations, optimize SQL, or deploy full-size staging apps.</p><nav><a href="https://postgres.ai/products/how-it-works">How it works<!-- --> <svg viewBox="0 0 15 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.6571 6.16873L7.83291 0.344521C7.37355 -0.11484 6.62854 -0.11484 6.16917 0.344521C5.70981 0.803883 5.70981 1.5489 6.16917 2.00826L11.161 7.00001L6.16917 11.9917C5.70981 12.4511 5.70981 13.1961 6.16917 13.6555C6.62854 14.1148 7.37355 14.1148 7.83291 13.6555L13.6571 7.8313C14.1165 7.37308 14.1165 6.62809 13.6571 6.16873ZM6.65418 5.81604L2.03028 0.942636C1.56565 0.453556 0.813091 0.453556 0.348467 0.942636C-0.116156 1.43172 -0.116156 2.22511 0.348467 2.71479L4.13178 6.70212L0.348467 10.6895C-0.116156 11.1786 -0.116156 11.9725 0.348467 12.4616C0.813091 12.9507 1.56565 12.9507 2.03028 12.4616L6.65418 7.5882C7.1188 7.09912 7.1188 6.30572 6.65418 5.81604Z" fill="currentColor"></path></svg></a><a href="https://postgres.ai/docs">Read documentation<!-- --> <svg viewBox="0 0 15 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.6571 6.16873L7.83291 0.344521C7.37355 -0.11484 6.62854 -0.11484 6.16917 0.344521C5.70981 0.803883 5.70981 1.5489 6.16917 2.00826L11.161 7.00001L6.16917 11.9917C5.70981 12.4511 5.70981 13.1961 6.16917 13.6555C6.62854 14.1148 7.37355 14.1148 7.83291 13.6555L13.6571 7.8313C14.1165 7.37308 14.1165 6.62809 13.6571 6.16873ZM6.65418 5.81604L2.03028 0.942636C1.56565 0.453556 0.813091 0.453556 0.348467 0.942636C-0.116156 1.43172 -0.116156 2.22511 0.348467 2.71479L4.13178 6.70212L0.348467 10.6895C-0.116156 11.1786 -0.116156 11.9725 0.348467 12.4616C0.813091 12.9507 1.56565 12.9507 2.03028 12.4616L6.65418 7.5882C7.1188 7.09912 7.1188 6.30572 6.65418 5.81604Z" fill="currentColor"></path></svg></a></nav></div></div></div></div>
  </body>
</html>
