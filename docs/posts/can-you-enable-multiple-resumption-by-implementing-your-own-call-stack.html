<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://interjectedfuture.com/can-you-enable-multiple-resumption-by-implementing-your-own-call-stack/">Original</a>
    <h1>Can you enable multiple resumption by implementing your own call stack?</h1>
    
    <div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://interjectedfuture.com/tag/ai-chat/">OpenAI Deep Research Chats</a>
            

            <div>
                <p><a href="https://news.ycombinator.com/author/wil/">
                                <img src="https://www.gravatar.com/avatar/915aac3dfde2fb502ce415d77643a72d?s=250&amp;r=x&amp;d=mp" alt="Wil Chung"/>
                            </a>
                </p>
                <div>
                    
                    <p><time datetime="2025-02-21">21 Feb 2025</time>
                            <span><span>‚Äî</span> 20 min read</span>
                    </p>
                </div>
            </div>

                <figure>
        <img srcset="/content/images/size/w320/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg 320w,
                    /content/images/size/w600/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg 600w,
                    /content/images/size/w960/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg 960w,
                    /content/images/size/w1200/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg 1200w,
                    /content/images/size/w2000/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://news.ycombinator.com/content/images/size/w1200/2025/02/DALL-E-2025-02-17-07.58.08---A-digital-illustration-in-a-cute-yet-intricate-style-with-Art-Nouveau-sensibilities.-The-image-represents-the-concept-of-multiple-resumption-and-custo.jpeg" alt="Can you enable multiple resumption by implementing your own call stack?"/>
    </figure>

        </header>

        <section>
            <div><p>‚ùì</p><p>This is a Deep Research report with GPT o3-mini</p></div><div><p>üí≠</p><div><p>&lt;goal&gt; If I wanted to build and design an algebraic effect system in a language that didn&#39;t support delimited continuations (like python), but I wanted multi-resumption, I wouldn&#39;t be able to use generators. So how would I go about implementing such a system? &lt;/goal&gt;</p></div></div><p>You have a strong foundation on this topic, and I appreciate the depth of your inquiry! Before diving into the explanations and design, I&#39;d like to clarify a few things:</p><p>Regarding monads and free monads:</p><ul><li>Are you specifically looking for how monads simulate control flow in terms of a stack-like behavior, or are you more interested in their use in modeling side effects?</li><li>When you mention free monads, do you want an explanation of how they enable effect handling, or do you also want insights into their performance implications compared to algebraic effects?</li></ul><p>For React:</p><ul><li>Are you looking for a comparison between React&#39;s rendering process and algebraic effects, or do you specifically want to understand how React‚Äôs reconciliation algorithm relates to control flow?</li></ul><p>For the algebraic effect system design:</p><ul><li>Should the design be optimized for practical use in Python, or would you prefer a more general theoretical construction that could be implemented in multiple languages?</li><li>Would you like concrete examples of how such a system could be applied, e.g., for structured concurrency, dependency injection, or other real-world scenarios?</li></ul><p>Answering these will help me tailor my response to exactly what you&#39;re aiming for.</p><div><p>üí≠</p><div><p>1. - I&#39;m looking for an explanation that connects how monad does control flow to call stack behavior. Like if monads are controlling control flow, how does each part of what a monad does have an analogy to call stack operations? </p></div></div><p>Got it! I&#39;ll break this down into three main areas:</p><ol><li><strong>Monads and Call Stack Analogy</strong> ‚Äì I&#39;ll explain how monads control flow in a way that mirrors a call stack, including how sequencing operations work in a stack-like manner.</li><li><strong>Free Monads and Effect Systems</strong> ‚Äì I&#39;ll connect how free monads structure computation in a way similar to delimited continuations, making explicit the connection between algebraic effects and call stack management.</li><li><strong>React&#39;s Reconciliation and Control Flow</strong> ‚Äì I&#39;ll analyze React&#39;s reconciliation algorithm and draw explicit parallels to control flow and stack behavior, including any connections to delimited continuations.</li></ol><p>Then, I&#39;ll design an algebraic effect system for Python that supports multiple resumptions, avoiding generators. I&#39;ll also contrast this with a more general theoretical model.</p><p>I&#39;ll let you know when I have the full breakdown ready!</p><hr/><h2 id="monads-simulate-control-flow">Monads Simulate Control Flow</h2><p>Monads in functional programming let us <strong>embed control flow</strong> (like sequencing, branching, looping) into a single composable abstraction‚Äã</p><p><a href="https://www.unison-lang.org/docs/fundamentals/abilities/for-monadically-inclined/?ref=interjectedfuture.com#:~:text=The%20actual%20superpower%20of%20monads,and%20use%20functions%20over%20values" rel="noopener">unison-lang.org</a>. Each step in a monadic computation represents a stage of execution, much like each function call in an imperative program‚Äôs call stack. By chaining operations in a monad, we can dictate <em>what happens first, next, and so on</em> even in a pure functional setting. For example, Haskell‚Äôs <code>IO</code> or <code>Maybe</code> monads let you sequence actions or short-circuit on failure, respectively, mimicking imperative control structures (do this, then that, or stop if something fails). In this way, <strong>each monadic operation acts like a call in a traditional call stack</strong> ‚Äì it has an input (the context from previous operations) and produces an output (passed to the next operation), enforcing an execution order.</p><h2 id="bind-as-stack-frame-transitions"><code>bind</code> (&gt;&gt;=) as Stack Frame Transitions</h2><p>The monadic bind operation <code>&gt;&gt;=</code> is the glue that links these steps. <strong>Bind takes the result of one computation and ‚Äúcalls‚Äù the next computation with that result</strong>, akin to popping one stack frame‚Äôs return value and pushing it into the next function call‚Äôs stack frame. In an imperative call stack, when function <code>A</code> returns <code>x</code>, the runtime passes <code>x</code> back to the caller (say function <code>B</code>), which then continues. Similarly, <code>m &gt;&gt;= f</code> runs monadic action <code>m</code>, then feeds its result into function <code>f</code> to produce the next action. This <strong>‚Äúthreading‚Äù of results</strong> is analogous to the way a stack threads return values between calls. All the monadic calls are <em>chained together</em>, each waiting for the previous to finish and hand off its output‚Äã</p><p><a href="https://williamyaoh.com/posts/2022-05-02-the-cont-monad.html?ref=interjectedfuture.com#:~:text=The%20definition%20looks,the%20way%20monadic%20binds%20work" rel="noopener">williamyaoh.com</a>.</p><p><strong>Monadic composition replaces explicit stack manipulation.</strong> Instead of the programmer manually managing function returns, jumps, or stack frames, the monad‚Äôs <code>bind</code> handles it. For instance, in a series of monadic operations <code>m1 &gt;&gt;= \\x -&gt; m2 &gt;&gt;= \\y -&gt; m3</code>, the monad ensures <code>m1</code> runs fully before <code>m2</code>, and so on, much like the call stack ensures function calls execute in sequence. We don‚Äôt need to push or pop frames explicitly ‚Äì the monad abstracts that. A concrete example is the <code>Maybe</code> monad‚Äôs bind: if one step returns <code>Nothing</code>, it <em>short-circuits</em> the chain (analogous to unwinding the call stack on an error) and skips remaining steps‚Äã</p><p><a href="https://stackoverflow.com/questions/20170703/monads-for-control-flow-sequence-selection-and-iteration?ref=interjectedfuture.com#:~:text=instance%20Monad%20Maybe%20where%20return,f%20%3D%20Nothing" rel="noopener">stackoverflow.com</a>. In summary, <strong><code>&gt;&gt;=</code> behaves like the transition between stack frames</strong> ‚Äì ensuring the next computation is invoked with the prior result ‚Äì and monadic do-notation gives us structured control flow without manually handling the program counter or stack.</p><h2 id="free-monads-as-a-call-stack-of-effects">Free Monads as a Call Stack of Effects</h2><p>Free monads allow us to <strong>represent effectful computations as data</strong> ‚Äì essentially building an <em>explicit call stack (or tree) of operations</em> that can be interpreted later. A free monad is a data structure (often an AST of instructions) where each node captures an operation to perform and holds the continuation (the rest of the computation)‚Äã</p><p><a href="https://calwoo.github.io/posts/2020-02-09-effects.html?ref=interjectedfuture.com#:~:text=As%20above%2C%20free%20monads%20allow,free%20monad%20is%20given%20by" rel="noopener">calwoo.github.io</a>. This is very much like capturing the state of a call stack: each suspended operation node contains what to do next, akin to a stack frame holding the return address and local state. By constructing a program as a free monad, we <strong>separate the description of the computation from its execution</strong>‚Äã<a href="https://calwoo.github.io/posts/2020-02-09-effects.html?ref=interjectedfuture.com#:~:text=An%20algebra%20for%20a%20monad,its%20interpretation%20in%20reified%20values" rel="noopener">calwoo.github.io</a>. The sequence of <code>Impure</code> nodes in a free monad represents nested effectful calls, and interpreting this structure is like unwinding a call stack, handling each operation in order.</p><p>In an <strong>algebraic effects system</strong>, the free monad serves as a <em>bookkeeping device for effects</em>: you accumulate operations (e.g., ‚ÄúLog this message‚Äù, ‚ÄúGet state‚Äù, etc.) in the monadic structure. The <em>shape</em> of this structure mirrors the control flow of the program (each nested operation corresponding to a deeper call). At runtime, an interpreter or handler will process this structure, much like a CPU would pop stack frames ‚Äì handling one operation and then moving to the continuation. Thus, free monads give us a <strong>first-class representation of the call stack for effectful computations</strong>, which we can manipulate or inspect before executing. This makes things like debugging or optimizing effects easier, at the cost of building an explicit structure.</p><h2 id="free-monads-vs-delimited-continuations-for-effects">Free Monads vs. Delimited Continuations for Effects</h2><p>Both free monads and <em>delimited continuations</em> enable <strong>user-defined effect handling</strong>, but they do so differently. A delimited continuation captures <em>the rest of the computation</em> at a certain point (up to a delimiter) as a first-class object, which an effect handler can invoke (resume) one or multiple times. Free monads achieve a similar outcome by <em>building the rest of the computation into the data structure</em> explicitly. In other words, using a free monad, when an effect (operation) is encountered, it doesn‚Äôt execute immediately ‚Äì it becomes an <code>Impure</code> node holding a callback (continuation) for what to do after the effect. This is conceptually similar to what happens with a delimited continuation: the program at an effect yield point is paused, waiting for the handler to give a result and continue.</p><p>The key difference is <strong>how the continuation is managed</strong>: free monads manage it <em>denotationally</em> (as data to be interpreted), whereas delimited continuations manage it <em>operationally</em> (by the runtime capturing the stack). With free monads, we write our program as a pure data structure and then hand it to a handler (interpreter) that pattern-matches on each operation and decides how to handle it. With algebraic effect handlers (which often use delimited continuations under the hood), the running program hits an effect and the language runtime packages up the current continuation and gives it to the handler. In practice, both approaches can express the same kinds of effects, but effect handlers (with real continuations) are more flexible in that the handler can <strong>resume at the original call site</strong> directly‚Äã</p><p><a href="https://www.reddit.com/r/functionalprogramming/comments/19f8s6b/what_is_the_actual_difference_from_monads_effect/?ref=interjectedfuture.com#:~:text=the%20operational%20difference" rel="noopener">reddit.com</a> (and even multiple times), rather than having to thread through a monadic structure.</p><p>There is also a difference in <em>ergonomics and performance</em>: Free monads are a library approach to effects ‚Äì you work within a monad and possibly compose multiple effects via monad transformers or similar. This can get verbose and is known to be less efficient (due to layers of wrapping and interpretation). By contrast, a language with algebraic effect handlers treats effects as a native concept: <strong>handlers use mechanisms like delimited continuations for efficiency</strong>, avoiding the overhead of building large intermediate ASTs‚Äã</p><p><a href="https://www.reddit.com/r/ProgrammingLanguages/comments/vq86w1/efficient_compilation_of_algebraic_effect/?ref=interjectedfuture.com#:~:text=Free%20Monads%20are%20a%20,to%20work%20in%20a%20monad" rel="noopener">reddit.com</a>. In summary, free monads and effect handlers both allow defining custom effects (that feel like extending the language), but free monads do so by <strong>reifying the call stack as a pure structure</strong> to interpret, whereas effect systems do so by <strong>capturing and manipulating the actual call stack (continuation) at runtime</strong>.</p><h2 id="operational-vs-denotational-perspective">Operational vs. Denotational Perspective</h2><p>The distinction between these approaches can be seen as <em>operational vs. denotational</em>. <strong>Denotationally</strong>, a free monad + interpreter gives a clear, mathematical semantics: you define what each operation <em>means</em> by interpreting the AST (much like giving meaning to a program in a structured way). Each effect operation in the free monad is like a symbol, and the handler is a function mapping that symbol (plus a continuation) to a result ‚Äì essentially an algebra for the monad‚Äã</p><p><a href="https://calwoo.github.io/posts/2020-02-09-effects.html?ref=interjectedfuture.com#:~:text=An%20algebra%20for%20a%20monad,its%20interpretation%20in%20reified%20values" rel="noopener">calwoo.github.io</a>. <strong>Operationally</strong>, algebraic effect handlers perform a similar mapping, but on the fly: when an effect is invoked, the runtime <em>operationally</em> transfers control to the handler along with a live continuation that represents ‚Äúthe rest of the program‚Äù. The handler then decides what to do (produce a result, resume the continuation, resume it multiple times, etc.).</p><p>Despite these differences, there is a strong connection: <strong>many monads correspond to algebraic effects</strong>. In fact, a handler for an algebraic effect can be seen as providing a <em>model</em> (an algebra) for the free monad of that effect. For example, the <em>State monad</em> is one way to represent stateful computations (with a fixed single resumption), whereas an <em>algebraic state effect</em> handler can accomplish the same operationally. The free monad of the state effect contains all the ‚Äúget‚Äù and ‚Äúput‚Äù operations (like a log of actions), and a handler gives them meaning by specifying how to fetch or update real state. The two approaches should agree on final outcomes even if their execution strategy differs. In essence, free monads provide a <strong>denotational blueprint</strong> for effects, whereas effect handlers provide a <strong>runtime mechanism</strong> ‚Äì they meet in the middle by implementing the same equations (laws) of the effect. One practical upshot is that any program written with free monads could be executed by an effect handler, and conversely, an effect handler‚Äôs behavior can often be modeled by a free monad and an interpreter, proving the correctness of the handler.</p><h2 id="managing-control-flow-in-reconciliation">Managing Control Flow in Reconciliation</h2><p>React‚Äôs reconciliation algorithm is responsible for updating the UI by comparing (diffing) the new UI tree with the previous one and applying necessary changes. This process is essentially a <strong>tree traversal</strong>, which means React is managing control flow across a recursive structure of components. In older versions of React (pre-Fiber), reconciliation was implemented with a <strong>pure recursive algorithm</strong>: when a component needed updating, React would synchronously traverse into all of its children, depth-first, using the JavaScript call stack to manage the recursion. This is straightforward ‚Äì <em>each component‚Äôs render is like a function call</em>, and the call stack naturally handles entering child components and returning back up to parents. The control flow here is tied to the JS engine‚Äôs stack: it goes down the tree (pushing new frames for child component renders) and unwinds back up after reaching the leaves.</p><p>However, this recursive, synchronous strategy can lead to problems if the UI tree is large or updates are numerous, because it might block the main thread for too long (dropping frames in animations, for example). React addresses this by introducing the <strong>Fiber reconciler</strong>, which fundamentally changes how control flow is managed during rendering. Instead of letting the JavaScript call stack drive the whole update, React Fiber implements its own <strong>cooperative scheduling</strong> for reconciliation. It breaks the work into units and spreads them across frames when needed. To do this, React <strong>reimplemented the call stack on the heap</strong>: a Fiber is essentially a data structure that acts like a stack frame‚Äã</p><p><a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=That%27s%20the%20purpose%20of%20React,as%20a%20virtual%20stack%20frame" rel="noopener">github.com</a>. Each Fiber holds information about a component (state, props, etc.) and pointers to child, sibling, and parent (return) fibers, forming a linked structure of the component tree‚Äã<a href="https://blog.logrocket.com/deep-dive-react-fiber/?ref=interjectedfuture.com#:~:text=A%20fiber%20node%20represents%20a,node%20comprises%20the%20following%20members" rel="noopener">blog.logrocket.com</a>. React walks this fiber tree in a controlled manner: it can pause after processing one fiber (one component) and put off processing its children until later, if higher-priority updates need to run first.</p><p>In summary, React‚Äôs reconciliation now manages control flow explicitly by <strong>traversing the Fiber tree iteratively (using a while loop and pointers) rather than relying on recursive function calls</strong>. This gives React the ability to schedule, pause, abort, or resume rendering work as needed. For example, it can begin updating a part of the UI, then if it realizes there‚Äôs a more urgent update (like a user input), it can pause the current work (save the current Fiber pointer, akin to saving the stack state) and switch to the urgent work. This kind of fine-grained control flow management is how React avoids blocking the main thread for too long. Essentially, <strong>React‚Äôs reconciler acts like an interpreter of a tree, controlling the ‚Äúcall stack‚Äù of component renders itself</strong> ‚Äì doing work, yielding control, and coming back to do more work later‚Äã</p><p><a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=The%20advantage%20of%20reimplementing%20the,goals%20we%20have%20for%20scheduling" rel="noopener">github.com</a>.</p><h2 id="render-tree-traversal-vs-function-call-stack">Render Tree Traversal vs. Function Call Stack</h2><p>The traversal of React‚Äôs render tree can be directly compared to typical function call stack operations. In the traditional (pre-Fiber) approach, when a parent component calls (renders) a child, you can think of it exactly like a function call: the parent‚Äôs render function invokes the child‚Äôs render, pushing a new frame on the stack. Once the child (and its subtree) finishes rendering and returns, the parent can continue ‚Äì this is just like unwinding the call stack back to the parent frame. The <strong>depth-first traversal</strong> of the component tree naturally mirrors the last-in-first-out behavior of the call stack.</p><p>With Fiber, React explicitly maintains this traversal order via pointers. Each fiber has a link to its <strong>child</strong> (like a function making a call), its <strong>sibling</strong> (like moving to the next statement after a function returns, or a loop iteration), and a <strong>return</strong> pointer to its parent (equivalent to the return address on the call stack)‚Äã</p><p><a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=" rel="noopener">github.com</a>. The algorithm goes something like: start at the root fiber, process it, then go to its child fiber (down one level, like a recursive call), then that child‚Äôs child, and so on until a leaf is reached. When finishing a fiber (say a component has no more children), React uses the return pointer to go back up to the parent ‚Äì just as a function returns to its caller. If a fiber has a sibling, React will then move to that sibling (which is like after returning from a function call, moving to the next operation in the parent‚Äôs context). This approach is effectively <strong>simulating recursion using a linked list data structure</strong>‚Äã<a href="https://blog.logrocket.com/deep-dive-react-fiber/?ref=interjectedfuture.com#:~:text=In%20the%20case%20of%20a,first%20traversal" rel="noopener">blog.logrocket.com</a>. The major difference is that React can stop or pause at any point in this traversal, whereas a normal call stack would run to completion unless an external interrupt occurs.</p><p>So, the render tree traversal in React Fiber is very much like managing your own call stack frames manually. Each Fiber corresponds to a stack frame of work for a component, and the pointers (<code>child</code>, <code>sibling</code>, <code>return</code>) play the role of the program counter (which function to go into next, and where to return to). By controlling this traversal manually, React can ensure that after handling one component, it can decide whether to continue to the child, jump to a sibling, or yield to let the browser update the screen. In essence, <strong>React‚Äôs fiber tree traversal uses the same logic as a function call stack (parent -&gt; child -&gt; return to parent -&gt; next sibling), but it‚Äôs under React‚Äôs control rather than the JavaScript engine‚Äôs</strong>.</p><h2 id="similarities-to-delimited-continuations">Similarities to Delimited Continuations</h2><p>Interestingly, the Fiber architecture has parallels to the concept of <em>delimited continuations</em> from programming language theory. A <strong>delimited continuation</strong> captures a portion of the call stack ‚Äì up to a certain boundary ‚Äì and makes it a first-class object that can be resumed or invoked later. React Fiber is doing something analogous: it takes what would be the call stack of the rendering process and makes it manual and sliceable. Each fiber can be seen as a checkpoint in the computation (rendering) that can be paused and resumed. React can <strong>pause in the middle of the tree traversal (middle of what would be a recursive call stack)</strong>, and later continue from that exact point ‚Äì this is essentially resuming a saved continuation.</p><p>React‚Äôs ability to <em>keep stack frames in memory and execute them later</em>‚Äã</p><p><a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=That%27s%20the%20purpose%20of%20React,as%20a%20virtual%20stack%20frame" rel="noopener">github.com</a> is exactly the power that continuations provide. In Fiber, because each component‚Äôs work is an object on the heap, React can decide to resume that work at a later time or even abandon it if it‚Äôs no longer needed. For example, if an asynchronous data load triggers a low-priority update, React may start working on it but pause if a high-priority event (like a user typing) comes in, and then continue the low-priority work afterward. That‚Äôs similar to capturing the continuation of the low-priority task, storing it, and coming back to it later. Traditional call stacks can‚Äôt do this easily ‚Äì once you‚Äôre in deep calls, you‚Äôd have to unwind completely to do something else. Fiber breaks that rule by not using the real call stack for deep rendering; it can unwind partially or cooperatively. This is <strong>‚Äúinterrupting the call stack at will and manipulating stack frames manually‚Äù</strong>, which was exactly the design goal of Fiber‚Äã<a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=Wouldn%27t%20it%20be%20great%20if,and%20manipulate%20stack%20frames%20manually" rel="noopener">github.com</a>.</p><p>Another similarity is how <strong>error boundaries in React</strong> can catch errors in the tree without unwinding the whole app ‚Äì they capture the <em>rest of the tree‚Äôs work</em> and abort it, which is analogous to a continuation that is never resumed (like throwing to an exception handler, which is itself a delimited continuation scenario). In summary, React‚Äôs reconciliation (especially with Fiber) implements a form of <em>controlled, delimited continuation for rendering</em>. It doesn‚Äôt use the formalism of continuations, but the idea is the same: <strong>it turns the recursive UI update process into reified stack frames that it can pause, resume, or discard</strong>, achieving a level of control very comparable to what one can do with first-class continuations or coroutines.</p><h2 id="design-approach-in-python-no-generators-or-delimited-continuations">Design Approach in Python (No Generators or Delimited Continuations)</h2><p>Implementing algebraic effects in Python (which doesn‚Äôt natively support them) requires simulating the behavior of effect handlers. One practical way is to leverage Python‚Äôs exception-handling to imitate the <strong>‚Äúthrow and resume‚Äù</strong> pattern of algebraic effects‚Äã</p><p><a href="https://stackoverflow.com/questions/49626714/what-does-algebraic-effects-mean-in-fp?ref=interjectedfuture.com#:~:text=TL%3BDR%3A%20In%20short%2C%20Algebraic%20Effects,ing%20function%20continue%20its%20operation" rel="noopener">stackoverflow.com</a>. The core idea is that when an effect is performed, instead of immediately producing a value, it will <em>yield control</em> to a handler along with a description of the operation (and a placeholder for the continuation). In Python, we can do this by <strong>raising a special exception</strong> to signal an effect, and catching it at some handler level that knows what to do.</p><p>For example, suppose we want to design an effect called <code>Choose</code> that picks an option from a list of values. We can define an exception class to represent this effect:</p><pre><code>class ChooseEffect(Exception):
    def __init__(self, options, cont):
        self.options = options      # the choices to pick from
        self.continuation = cont   # a callable to resume the computation
</code></pre><p>Here <code>cont</code> will be a function representing the <em>continuation</em> of the computation ‚Äì what to do with the chosen value. Now, our effectful function can be written in a style where it checks if it needs to perform an effect and raises the exception. One way to achieve this is to structure the function so that whenever it wants to do <code>Choose</code>, it does something like:</p><pre><code>def do_something():
    # ... some code ...
    # Need to choose a value
    raise ChooseEffect(options=[1, 2, 3], cont=lambda val: continue_with(val))
    # ... rest of function in continue_with(val) ...
</code></pre><p>Of course, in normal Python, once you raise an exception, the function will exit. The trick is that the exception carries a <code>cont</code> function that, when called with a chosen value, will execute ‚Äúthe rest of the computation‚Äù as if the function had continued. The handler will catch the <code>ChooseEffect</code>, and <em>invoke the continuation with different values</em>. Pseudocode for a handler loop might look like:</p><pre><code>def handle_effects(func):
    try:
        result = func()  # run the effectful function
    except ChooseEffect as e:
        results = []
        for option in e.options:
            # resume the computation for each possible option
            try:
                res = e.continuation(option)
            except ChooseEffect as nested_e:
                # handle nested effects recursively
                res = handle_effects(lambda: e.continuation(option))
            results.append(res)
        return results
</code></pre><p>In this sketch, <code>handle_effects</code> runs an effectful function <code>func</code>. If no effect is raised, great ‚Äì we got a result. If a <code>ChooseEffect</code> is raised, we iterate over each possible <code>option</code>, and for each one, we call <code>e.continuation(option)</code> to resume the computation as if that choice was made. The continuation <code>cont</code> is essentially the remaining code of <code>func</code> after the point of the effect, packaged as a callable. Notably, if that continuation itself triggers another effect (nested effect), we catch it with a recursive call to <code>handle_effects</code>. This approach <strong>ensures that multiple resumptions are possible</strong>: the handler can call the continuation as many times as needed (here, once per option).</p><p>Crucially, designing <code>continuation=lambda val: continue_with(val)</code> requires splitting the original function at the effect point. In practice, you might write the function in CPS form or use a trampoline. Without generators or actual continuations, you often end up writing the function such that when an effect is needed, you <code>return</code> a description (like an object or lambda) instead of doing it inline. Another technique is to use a dispatcher: instead of raising an exception, have the function return a special <code>EffectRequest</code> object that contains the <code>options</code> and a continuation function. Then your <code>handle_effects</code> can pattern-match on that. The pattern is similar: <strong>represent the effect request and how to resume, then interpret it</strong>.</p><h2 id="enabling-multiple-resumptions">Enabling Multiple Resumptions</h2><p>The above design inherently supports <em>multiple resumptions</em>. In algebraic effect terms, most effects either don‚Äôt resume (like an exception ‚Äì once handled, it doesn‚Äôt go back), resume exactly once (like a state get/put ‚Äì after handling you continue exactly once), or can resume many times (like nondeterministic choice or backtracking). Our <code>ChooseEffect</code> example is a <strong>multi-resumption effect</strong>: the handler provided resumes the computation for each choice. Each time we call <code>e.continuation(option)</code>, we are effectively cloning the rest of the computation for that specific option. The result is that one execution of the effectful function can produce multiple outcomes ‚Äì e.g., exploring different branches of a decision tree.</p><p>This is analogous to the <em>amb (ambiguity)</em> or <em>nondeterminism</em> effect often shown in literature. For instance, one could implement a boolean choice effect <code>Flip</code> that non-deterministically returns true or false. A handler for <code>Flip</code> could invoke the continuation twice ‚Äì once with <code>True</code> and once with <code>False</code> ‚Äì collecting both results‚Äã</p><p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/algeff-in-c-tr.pdf?ref=interjectedfuture.com#:~:text=value%20random_amb_flip%28%20resume,true%29%29%3B%205" rel="noopener">microsoft.com</a>. In our Python approach, this is exactly what the loop over <code>e.options</code> does. Each iteration is a fresh resumption of the computation from the point of the effect. Python doesn‚Äôt clone call stacks, but because our continuation is a callable (closing over the remaining logic), calling it creates a new logical path of execution. We must be careful that any <em>mutable state</em> captured in that closure is properly isolated (or else each resume might interfere with others), but if we structure continuations as pure functions of the value, we‚Äôre effectively copying the execution.</p><p>To illustrate, imagine our effectful function is supposed to compute some result based on a user choice and a random coin flip. It might perform two effects in sequence: <code>choice = Choose([OptionA, OptionB])</code>, then <code>coin = Flip()</code>. With our system, the <code>Choose</code> handler will branch into two continuations (one where <code>choice=OptionA</code>, one where <code>choice=OptionB</code>). Each of those continuations when executed might raise <code>FlipEffect</code>, which a corresponding handler would then resume twice (once with <code>True</code>, once with <code>False</code>). In total, we‚Äôd end up exploring 4 combinations (A/true, A/false, B/true, B/false). Each branch is a result of <strong>multiple resumptions of continuations</strong> at different effect points.</p><h2 id="comparison-to-theoretical-model">Comparison to Theoretical Model</h2><p>Our Python design is essentially emulating the theoretical model of algebraic effects using ordinary language features. In the theoretical model (as seen in languages like Eff, Multicore OCaml, or Koka), when an effect is performed, the language runtime <em>captures the continuation</em> and passes it to a handler, and that handler can invoke (resume) that continuation however it sees fit. This is usually implemented with support from the runtime or compiler (often using a form of delimited continuation under the hood). In our design, we manually captured the continuation in the form of a lambda (or a function object). The <code>ChooseEffect</code> exception carried that lambda, which is conceptually the same as a runtime capturing the current continuation. We then manually iterated to simulate multiple resumes. So <strong>functionally, we achieved the same outcome</strong>: the computation paused at the effect, a handler decided how to continue (and how many times to continue).</p><p>One difference is that our approach requires writing the code in a stylized way (splitting the function at effect points, using exceptions or special return values), whereas a language with native algebraic effects allows you to write it in direct style and the compiler transforms it (via CPS or similar) behind the scenes‚Äã</p><p><a href="https://stackoverflow.com/questions/49626714/what-does-algebraic-effects-mean-in-fp?ref=interjectedfuture.com#:~:text=" rel="noopener">stackoverflow.com</a>. Another difference is performance: our Python simulation might be slower and use more heap (creating many lambdas and exceptions), while a real effect handler mechanism can optimize this (possibly by sharing stack frames or using jump instead of actual exception unwinding). Moreover, <strong>our handler uses Python control flow (try/except, loops)</strong> to mimic what in theory is handled by the language‚Äôs evaluator. This means edge cases (like interacting with Python‚Äôs own call stack or other exceptions) need careful management.</p><p>In the theoretical model, algebraic effects have well-defined <strong>scoping and composition</strong> rules: handlers can be scoped to regions of the computation, and multiple effects can be handled by different handlers without tangled logic. We can achieve something similar by nesting <code>handle_effects</code> contexts or by dispatching on exception types. For instance, we could have a base <code>Effect</code> class and multiple subclasses for different operations, and a single handler that knows how to route each type to the appropriate logic. This mirrors how an effect handler can handle multiple operation types.</p><p>Finally, our approach demonstrates multi-resumption explicitly with a loop. In a formal effect handler, writing a multi-resume handler (like exploring all choices) is as simple as calling the provided continuation multiple times. The outcome is the same. Notably, <strong>algebraic effects are often described as ‚Äúexceptions that can resume‚Äù</strong>‚Äã</p><p><a href="https://stackoverflow.com/questions/49626714/what-does-algebraic-effects-mean-in-fp?ref=interjectedfuture.com#:~:text=TL%3BDR%3A%20In%20short%2C%20Algebraic%20Effects,ing%20function%20continue%20its%20operation" rel="noopener">stackoverflow.com</a>, and our design literally treats them as exceptions but with the twist that the handler doesn‚Äôt just handle and end the story ‚Äì it injects a value and continues the computation. We even allowed it to continue <em>multiple times</em>. Thus, conceptually, we‚Äôve aligned with the theoretical model: an effect is an operation that, when invoked, offers a bundle (the continuation) to a handler, and the handler can decide to invoke that bundle any number of times (or not at all).</p><p>In conclusion, it‚Äôs entirely possible to build a <strong>mini effect system in Python</strong> with careful discipline. The multiple resumption feature shows the power: we can do things like backtracking search or multi-result computations in a single function, which ordinarily would require cumbersome state management. The trade-off is that without language-level support, the syntax is not as transparent ‚Äì but the underlying mechanics correspond closely to the formal semantics of algebraic effects and handlers (specifically, we manually implement the capture and resumption of delimited continuations). The approach illustrates the principles in a ‚ÄúPythonic‚Äù way, but a dedicated language feature would handle the bookkeeping invisibly and likely more efficiently.</p><p><strong>Sources:</strong> Monads and their control-flow abstraction‚Äã <a href="https://www.unison-lang.org/docs/fundamentals/abilities/for-monadically-inclined/?ref=interjectedfuture.com#:~:text=The%20actual%20superpower%20of%20monads,and%20use%20functions%20over%20values" rel="noopener">unison-lang.org</a>‚Äã<a href="https://williamyaoh.com/posts/2022-05-02-the-cont-monad.html?ref=interjectedfuture.com#:~:text=The%20definition%20looks,the%20way%20monadic%20binds%20work" rel="noopener">williamyaoh.com</a>; Free monads and algebraic effects ‚Äã<a href="https://calwoo.github.io/posts/2020-02-09-effects.html?ref=interjectedfuture.com#:~:text=An%20algebra%20for%20a%20monad,its%20interpretation%20in%20reified%20values" rel="noopener">calwoo.github.io</a>‚Äã<a href="https://www.reddit.com/r/ProgrammingLanguages/comments/vq86w1/efficient_compilation_of_algebraic_effect/?ref=interjectedfuture.com#:~:text=Free%20Monads%20are%20a%20,to%20work%20in%20a%20monad" rel="noopener">reddit.com</a>‚Äã<a href="https://www.reddit.com/r/functionalprogramming/comments/19f8s6b/what_is_the_actual_difference_from_monads_effect/?ref=interjectedfuture.com#:~:text=the%20operational%20difference" rel="noopener">reddit.com</a>; React Fiber as reified call stack‚Äã <a href="https://github.com/acdlite/react-fiber-architecture/blob/master/README.md?ref=interjectedfuture.com#:~:text=That%27s%20the%20purpose%20of%20React,as%20a%20virtual%20stack%20frame" rel="noopener">github.com</a>‚Äã<a href="https://blog.logrocket.com/deep-dive-react-fiber/?ref=interjectedfuture.com#:~:text=In%20the%20case%20of%20a,first%20traversal" rel="noopener">blog.logrocket.com</a>; Algebraic effects as resumable exceptions‚Äã <a href="https://stackoverflow.com/questions/49626714/what-does-algebraic-effects-mean-in-fp?ref=interjectedfuture.com#:~:text=TL%3BDR%3A%20In%20short%2C%20Algebraic%20Effects,ing%20function%20continue%20its%20operation" rel="noopener">stackoverflow.com</a>‚Äã<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/algeff-in-c-tr.pdf?ref=interjectedfuture.com#:~:text=value%20random_amb_flip%28%20resume,true%29%29%3B%205" rel="noopener">microsoft.com</a>.</p>
        </section>

    </article>


</div></div>
  </body>
</html>
