<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Jan/2/they-spy-on-you-but-not-like-that/">Original</a>
    <h1>I still don&#39;t think companies serve you ads based on your microphone</h1>
    
    <div id="readability-page-1" class="page"><div>


<div data-permalink-context="/2025/Jan/2/they-spy-on-you-but-not-like-that/">

<p>2nd January 2025</p>



<p>One of my weirder hobbies is trying to convince people that the idea that companies are listening to you through your phone’s microphone and serving you targeted ads is a conspiracy theory that isn’t true. I wrote about this previously: <a href="https://simonwillison.net/2023/Dec/14/ai-trust-crisis/#facebook-dont-spy-microphone">Facebook don’t spy on you through your microphone</a>.</p>
<p>(Convincing people of this is basically impossible. It doesn’t matter how good your argument is, if someone has ever seen an ad that relates to their previous voice conversation they are likely convinced and there’s nothing you can do to talk them out of it. Gimlet media did <a href="https://gimletmedia.com/amp/shows/reply-all/z3hlwr">a great podcast episode</a> about how impossible this is back in 2017.)</p>
<p>This is about to get even harder thanks to this proposed settlement: <a href="https://arstechnica.com/tech-policy/2025/01/apple-agrees-to-pay-95m-delete-private-conversations-siri-recorded/">Siri “unintentionally” recorded private convos; Apple agrees to pay $95M</a> (Ars Technica).</p>
<p>Apple are settling for $95m (nine hours of profit), agreeing to settle while “denying wrongdoing”.</p>
<p>What actually happened is it turns out Apple were capturing snippets of audio surrounding the “Hey Siri” wake word, sending those back to their servers and occasionally using them for QA, without informing users that they were doing this. This is bad.</p>
<p>The Reuters 2021 story <a href="https://www.reuters.com/technology/apple-must-face-siri-voice-assistant-privacy-lawsuit-us-judge-2021-09-02/">Apple must face Siri voice assistant privacy lawsuit -U.S. judge</a> reported that:</p>
<blockquote>
<p>One Siri user said his private discussions with his doctor about a “brand name surgical treatment” caused him to receive targeted ads for that treatment, while two others said their discussions about Air Jordan sneakers, Pit Viper sunglasses and “Olive Garden” caused them to receive ads for those products.</p>
</blockquote>
<p>The claim from that story was then repeated in <a href="https://www.reuters.com/legal/apple-pay-95-million-settle-siri-privacy-lawsuit-2025-01-02/">the 2025 Reuters story</a> about the settlement.</p>
<p>The <a href="https://arstechnica.com/tech-policy/2025/01/apple-agrees-to-pay-95m-delete-private-conversations-siri-recorded/">Ars Technica story</a> reframes that like this:</p>
<blockquote>
<p>The only clue that users seemingly had of Siri’s alleged spying was eerily accurate targeted ads that appeared after they had just been talking about specific items like Air Jordans or brands like Olive Garden, Reuters <a href="https://www.reuters.com/legal/apple-pay-95-million-settle-siri-privacy-lawsuit-2025-01-02/">noted</a>.</p>
</blockquote>
<p>Crucially, this was never <em>proven in court</em>. And if Apple settle the case it never will be.</p>
<p>Let’s think this through. For the accusation to be true, Apple would need to be recording those wake word audio snippets and transmitting them back to their servers for additional processing (likely true), but then they would need to be feeding those snippets <em>in almost real time</em> into a system which forwards them onto advertising partners who then feed that information into targeting networks such that next time you view an ad on your phone the information is available to help select the relevant ad.</p>
<p>That is <em>so far fetched</em>. Why would Apple do that? Especially given both their brand and reputation as a privacy-first company combined with the large amounts of product design and engineering work they’ve put into preventing apps from doing exactly this kind of thing by enforcing permission-based capabilities <em>and</em> ensuring a “microphone active” icon is available at all times when an app is listening in.</p>
<p>I really don’t think this is happening—in particular for Siri wake words!</p>

<p id="argued-these-points">I’ve <a href="https://simonwillison.net/2023/Dec/14/ai-trust-crisis/#facebook-dont-spy-microphone">argued these points before</a>, but I’ll do it again here for good measure.</p>
<ol>
<li>You don’t notice the hundreds of times a day you say something and <em>don’t</em> see a relevant add a short time later. You see thousands of ads a day, can you remember what <em>any</em> of them are?</li>
<li>The tiny fraction of times where you see an ad that’s relevant to something you’ve just said (hence breaking through your filter that prevents you from seeing most ads at all) stick in your head.</li>
<li>Human beings are pattern matching machines with a huge bias towards personal anecdotes. If we’ve seen direct evidence of something ourselves, good luck talking us out of it!</li>
</ol>
<p>I think the truth of the matter here is much more pedestrian: the quality of ad targeting that’s possible just through apps sharing data on your regular actions within those apps is shockingly high... combined with the fact that it turns out just knowing “male, 40s, NYC” is often more than enough—we’re all pretty basic!</p>
<p>I fully expect that this Apple story will be used as “proof” by conspiracy theorists effectively forever.</p>


</div>


</div></div>
  </body>
</html>
