<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ollama.ai/blog/python-javascript-libraries">Original</a>
    <h1>Ollama releases Python and JavaScript Libraries</h1>
    
    <div id="readability-page-1" class="page"><div>
      
      <h2>January 23, 2024</h2>
      <section>
        <p><img src="https://ollama.ai/public/blog/libraries.svg" alt="Python &amp; JavaScript Libraries"/></p>

<p>The initial versions of the Ollama Python and JavaScript libraries are now available:</p>

<ul>
<li><a href="https://github.com/ollama/ollama-python">Ollama Python Library</a></li>
<li><a href="https://github.com/ollama/ollama-js">Ollama JavaScript Library</a></li>
</ul>

<p>Both libraries make it possible to integrate new and existing apps with Ollama in a few lines of code, and share the features and feel of the Ollama REST API.</p>

<h2>Getting Started</h2>

<p><sub>Python</sub></p>

<pre><code>pip install ollama
</code></pre>

<pre><code>import ollama
response = ollama.chat(model=&#39;llama2&#39;, messages=[
  {
    &#39;role&#39;: &#39;user&#39;,
    &#39;content&#39;: &#39;Why is the sky blue?&#39;,
  },
])
print(response[&#39;message&#39;][&#39;content&#39;])
</code></pre>

<p><sub>JavaScript</sub></p>

<pre><code>npm install ollama
</code></pre>

<pre><code>import ollama from &#39;ollama&#39;

const response = await ollama.chat({
  model: &#39;llama2&#39;,
  messages: [{ role: &#39;user&#39;, content: &#39;Why is the sky blue?&#39; }],
})
console.log(response.message.content)
</code></pre>

<h2>Use cases</h2>

<p>Both libraries support Ollama’s full set of features. Here are some examples in Python:</p>

<h4>Streaming</h4>

<pre><code>for chunk in chat(&#39;mistral&#39;, messages=messages, stream=True):
  print(chunk[&#39;message&#39;][&#39;content&#39;], end=&#39;&#39;, flush=True)
</code></pre>

<h4>Multi-modal</h4>

<pre><code>with open(&#39;image.png&#39;, &#39;rb&#39;) as file:
  response = ollama.chat(
    model=&#39;llava&#39;,
    messages=[
      {
        &#39;role&#39;: &#39;user&#39;,
        &#39;content&#39;: &#39;What is strange about this image?&#39;,
        &#39;images&#39;: [file.read()],
      },
    ],
  )
print(response[&#39;message&#39;][&#39;content&#39;])
</code></pre>

<h4>Text Completion</h4>

<pre><code>result = ollama.generate(
  model=&#39;stable-code&#39;,
  prompt=&#39;// A c function to reverse a string\n&#39;,
)
print(result[&#39;response&#39;])
</code></pre>

<h4>Creating custom models</h4>

<pre><code>modelfile=&#39;&#39;&#39;
FROM llama2
SYSTEM You are mario from super mario bros.
&#39;&#39;&#39;

ollama.create(model=&#39;example&#39;, modelfile=modelfile)
</code></pre>

<h4>Custom client</h4>

<pre><code>ollama = Client(host=&#39;my.ollama.host&#39;)
</code></pre>

<p>More examples are available in the GitHub repositories for the <a href="https://github.com/ollama/ollama-python/tree/main/examples">Python</a> and <a href="https://github.com/ollama/ollama-js/tree/main/examples">JavaScript</a> libraries.</p>

<h2>New GitHub handle</h2>

<p><img src="https://ollama.ai/public/blog/github-handle.svg" alt="GitHub handle"/></p>

<p>These libraries, and the main Ollama repository now live in a new GitHub organization: <strong><a href="https://github.com/ollama">ollama</a></strong>!  Thank you to all the amazing community members who maintain libraries to interact with Ollama via Dart, Swift, C#, Java, PHP, Rust and more – a full list is available <a href="https://github.com/jmorganca/ollama?tab=readme-ov-file#libraries">here</a> – please don’t hesitate to make a pull request to add a library you’ve built or enjoy using.</p>

<p>Special thank you to <a href="https://github.com/saul-jb">Saul</a>, the original author of <code>ollama-js</code>, and everyone else who has worked on community libraries to make Ollama more accessible from different programming languages.</p>

      </section>
    </div></div>
  </body>
</html>
