<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=40129225">Original</a>
    <h1>Ask HN: How does deploying a fine-tuned model work</h1>
    
    <div id="readability-page-1" class="page"><div><td colspan="2"></td><td><p>If I&#39;ve managed to build my own model, say a fine-tuned version of Llama and trained it on some GPUs, how do I then deploy it and use it in an app. Does it need to be running on the GPUs all the time or can I host the model on a web server or something. Sorry if this is an obvious/misinformed question, I&#39;m a beginner in this space</p></td></div></div>
  </body>
</html>
