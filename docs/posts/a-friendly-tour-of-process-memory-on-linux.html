<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.0xkato.xyz/linux-process-memory/">Original</a>
    <h1>A friendly tour of process memory on Linux</h1>
    
    <div id="readability-page-1" class="page"><div>
        
            <div>
        

            



<nav>
    <ul>
        
            <li>
                <a href="https://www.0xkato.xyz/">Home</a>
            </li>
        

        
            
                <li>
                    <a href="https://www.0xkato.xyz/blog">Blog</a>
                </li>
            
        

        
            
                <li>
                    <a href="https://www.0xkato.xyz/projects">Research</a>
                </li>
            
        

        
            
                <li>
                    <a href="https://www.0xkato.xyz/about">About</a>
                </li>
            
        

        
            <li>
                <a href="https://github.com/0xkato/Portfolio/tree/main">Portfolio</a>
            </li>
        
    </ul>
</nav>







<p><span>
    <time datetime="01-11-2025">Saturday. November 01, 2025</time>
     - <span title="Estimated read time">
    

    
        24 mins
    
</span>

</span></p>




<p>You run a program. It reads and writes addresses as if a giant, continuous slab of memory had been waiting there all along. It didn’t. Linux builds that illusion on the fly, one page at a time. This is a walk through what your process actually owns, what happens on the first touch of a byte, how protections and huge pages fit in, how to see the truth from <code>/proc</code>, and why modern kernels do a little extra dance to defend against <a href="https://meltdownattack.com/">Meltdown</a>.</p>

<p>Note: This tour targets Linux on x86‑64, other architectures differ in details (page sizes, cache rules), but the ideas carry over.</p>

<h2 id="intro">Intro</h2>

<p>The picture below is a quick introduction. It is a simple map you can keep in mind as you read.</p>

<p>Physical RAM is the real memory. It is a bunch of frames scattered around.
The virtual view is the clean line your program sees. It does not match the real layout.
The page table is a list. It tells which spot on the virtual line points to which frame in RAM.
Disk is extra space the system can use when RAM is full.</p>

<p>Here is how it plays out.
When you read or write, the CPU looks in the page table. If there is an entry it goes to that frame. If there is no entry you get a page fault. The system then fills a frame and adds the entry, or it stops you with an error. We will explain faults later.</p>

<p>When RAM is tight the system makes room. It moves pages you have not used in a while to disk, or drops file pages it can load again. If you touch one of those later it brings it back.</p>

<p><img src="https://www.0xkato.xyz/assets/virtual-momory-show-case.png" alt="Markdown Image"/></p>

<p>Tiny explainers appear throughout so anyone can follow along, regardless of background.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>/proc</code></strong></p>
</blockquote>

<hr/>

<h2 id="the-floor-plan-you-never-see">The floor plan you never see</h2>

<p>Inside the kernel, your process owns one object that represents its whole address space. Think of it as a floor plan. Each room on that plan is a virtual memory area (VMA) a contiguous range with the same permissions (read, write, execute) and the same kind of backing (anonymous memory or a file).</p>

<blockquote>
  <p><strong>Tiny explainer: VMA</strong></p>
</blockquote>

<p>Under the plan sit the page tables that the hardware reads to translate your virtual addresses to real page frames.</p>

<blockquote>
  <p><strong>Tiny explainer: page tables and PTE</strong></p>
</blockquote>

<p>All threads in the process share the same plan. When the scheduler runs you, the CPU is pointed at your page tables, so pointer dereferences don’t need a syscall once a mapping exists, the hardware does the translation on its own.</p>

<p>You change the plan in three ways: <code>mmap</code> draws a room, <code>mprotect</code> changes the sign on its door (R/W/X), and <code>munmap</code> tears it down.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>mmap</code></strong></p>
</blockquote>

<p>Everything else (creating pages, reading file data, swapping) happens lazily when you touch memory.</p>

<blockquote>
  <p><strong>Tiny explainer: page</strong></p>
</blockquote>

<h2 id="a-quick-glance-at-your-own-house">A quick glance at your own house</h2>

<p>Run:</p>

<p>You’ll see your main binary’s segments (code, data, bss), the heap, anonymous mappings (allocators use these for big chunks), shared libraries, and thread stacks near the top.</p>

<p>You’ll typically also see two small regions:</p>
<ul>
  <li><code>[vdso]</code>: a tiny shared object the kernel maps in so a few calls like <code>gettimeofday</code> can run without a kernel trap.</li>
  <li><code>[vvar]</code>: read‑only data those helpers use.</li>
</ul>

<blockquote>
  <p><strong>Tiny explainer: <code>vdso</code> and <code>vvar</code></strong></p>
</blockquote>

<p>They’re why asking the time is fast.</p>

<hr/>

<h2 id="mmap-without-the-fog"><code>mmap</code>, without the fog</h2>

<p>When you call <code>mmap</code>, you’re not “allocating memory” so much as drawing a promise on the floor plan. You say give me a range of addresses with these rights and back it by this file plus offset or by anonymous memory. Linux picks an address, makes sure it doesn’t collide, adjusts VMAs so each remains uniform, and records the promise.</p>

<blockquote>
  <p><strong>Tiny explainer: ASLR</strong></p>
</blockquote>

<p>It does not allocate pages yet. That comes later at first touch.</p>

<p>Two gotchas come up over and over:</p>
<ul>
  <li>File mappings: <code>offset</code> must be page aligned or <code>mmap</code> returns <code>EINVAL</code>.</li>
  <li>Mapping past end of file is allowed, but touching beyond the true end raises <code>SIGBUS</code>. The VMA exists, the data does not.</li>
</ul>

<blockquote>
  <p><strong>Tiny explainer: <code>MAP_PRIVATE</code> and <code>MAP_SHARED</code></strong></p>
</blockquote>

<p>Anonymous mappings start life as zeroes. File mappings mirror the file. If the file ends mid page the tail of that last page reads as zeros but still belongs to the file.</p>

<p><code>MAP_FIXED</code> means exactly here and it overwrites anything already mapped at that address. Prefer <code>MAP_FIXED_NOREPLACE</code> to fail instead of clobbering. Without either flag your <code>addr</code> is just a hint.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>MAP_FIXED_NOREPLACE</code></strong></p>
</blockquote>

<hr/>

<h2 id="the-first-touch">The first touch</h2>

<p>Imagine <code>*p = 42;</code> to a fresh mapping. The CPU tries to translate the address. It finds no entry so it raises a page fault that includes the address and an error code.</p>

<blockquote>
  <p><strong>Tiny explainer: page fault</strong></p>
</blockquote>

<p>The kernel’s handler runs on your behalf and asks three questions in this order:</p>

<ol>
  <li>Is the address inside any VMA</li>
  <li>Do the rights allow this access</li>
  <li>If it is valid but missing make it real</li>
</ol>

<blockquote>
  <p><strong>Tiny explainer: page cache</strong></p>
</blockquote>

<p>People count these faults:</p>
<ul>
  <li>A minor fault means the data was already in RAM and only the translation was missing.</li>
  <li>A major fault means the kernel had to wait for I/O which is expensive.</li>
</ul>

<blockquote>
  <p><strong>Tiny explainer: stack guard</strong></p>
</blockquote>

<p>This same lazy first touch explains how memory is shared after <code>fork()</code> and how <code>MAP_PRIVATE</code> works. The next section shows that path.</p>

<hr/>

<h2 id="copy-on-write-with-fork-and-map_private">Copy on write with <code>fork()</code> and <code>MAP_PRIVATE</code></h2>

<p>Why this is here. We just talked about first touch. The same rule explains why pages do not copy on <code>fork</code> and why <code>MAP_PRIVATE</code> does not change the file.</p>

<p><code>fork</code> does not duplicate pages. The child points at the same physical pages as the parent. The kernel flips those pages to read only for both. The first write hits a copy on write fault. The kernel allocates a new page, copies the bytes, updates the writer’s page table entry to the new page with write permission, and returns. Reads still share the original page. That is why RSS stays flat after <code>fork</code> until you write.</p>

<blockquote>
  <p><strong>Tiny explainer: RSS</strong></p>
</blockquote>

<p><code>MAP_PRIVATE</code> uses the same idea. You read file data through the page cache. When you write, the kernel gives you a private page. The file stays unchanged.</p>

<p>Things you will also run into:</p>

<ul>
  <li><code>fork</code> then <code>execve</code>. The child replaces its whole address space soon after. That avoids most CoW work.</li>
  <li><code>vfork</code>. The child runs in the parent’s address space until it calls <code>exec</code> or <code>_exit</code>. The parent waits. Do not touch memory in the child.</li>
  <li><code>clone</code> with <code>CLONE_VM</code>. This makes a thread. One address space. No copy.</li>
  <li><code>MAP_SHARED</code>. Writes go to the shared page and to the file or shmem. No CoW.</li>
  <li><code>MADV_DONTFORK</code>. Leave this mapping out of the child.</li>
  <li><code>MADV_WIPEONFORK</code>. The child sees zeros for this mapping.</li>
  <li>Transparent huge pages. Breaking CoW on a huge page may split it first. Small extra cost.</li>
</ul>

<hr/>

<h2 id="changing-rights-and-the-little-pause-you-feel">Changing rights, and the little pause you feel</h2>

<p>Why you care. JITs and loaders flip a region from writable to executable after codegen which is W^X. That flip is not free.</p>

<blockquote>
  <p><strong>Tiny explainer: W^X</strong></p>
</blockquote>

<p><code>mprotect(addr, len, prot)</code> changes permissions. Internally the kernel may split VMAs so each remains uniform, edits the page table entries for the range, and then does one more necessary thing. It invalidates old translations from the CPU’s small cache of address translations which is the TLB. That invalidation is the small pause you sometimes feel when a JIT flips RW to RX or back.</p>

<blockquote>
  <p><strong>Tiny explainer: TLB</strong></p>
</blockquote>

<p>Most systems enforce W^X. A page should not be writable and executable at the same time. JITs keep to that by flipping after codegen or by keeping two virtual mappings of the same memory so no single mapping is both.</p>

<p>Remember there are two layers of permission checks:</p>
<ol>
  <li>Filesystem or mount policy like <code>noexec</code></li>
  <li>Page permissions like <code>PROT_EXEC</code></li>
</ol>

<p>Either layer can block execution.</p>

<hr/>

<h2 id="seeing-whats-really-mapped">Seeing what’s really mapped</h2>

<p>For everyday questions the friendly view is enough.</p>

<ul>
  <li><code>/proc/&lt;pid&gt;/maps</code> shapes: addresses, rights, file names</li>
  <li><code>/proc/&lt;pid&gt;/smaps</code> and <code>smaps_rollup</code> add per region accounting like how much is resident which is RSS, private vs shared, and whether huge pages were used like <code>AnonHugePages</code> and <code>FilePmdMapped</code></li>
</ul>

<p>When you need truth at the per page level Linux exposes sharper tools.</p>

<p><code>/proc/&lt;pid&gt;/pagemap</code> has one 64 bit entry per virtual page. It tells you whether a page is present, swapped, soft dirty, exclusively mapped with caveats for huge pages, whether it is write protected via userfaultfd, or part of a guard region. It can also reveal the page frame number which is PFN but modern kernels hide PFNs from unprivileged users. You need the right capability or root.</p>

<blockquote>
  <p><strong>Tiny explainer: PFN</strong></p>
</blockquote>

<p><code>/proc/kpagecount</code> is indexed by PFN and tells you how many mappings point at a given physical page.</p>

<p><code>/proc/kpageflags</code> is also indexed by PFN and tells you what kind of page it is and what is happening to it like anonymous or file backed, part of a transparent huge page, in the LRU, dirty, under writeback, a page table page, or the shared zero page.</p>

<h3 id="common-wrinkles">Common wrinkles</h3>
<ul>
  <li>Sparse files. To tell hole vs data, combine <code>mincore()</code> which says resident or not with <code>lseek(..., SEEK_DATA/SEEK_HOLE)</code> on the backing file.</li>
  <li>Shared memory and swap. Shared and shmem pages may be non present at the PTE level while still logically allocated. Expect swap entries and non present PTEs.</li>
  <li>Privileges. Modern kernels restrict PFN and some flag visibility to privileged users for security.</li>
</ul>

<blockquote>
  <p><strong>Tiny explainer: <code>mincore</code></strong></p>
</blockquote>

<blockquote>
  <p><strong>Tiny explainer: soft dirty vs written</strong></p>
</blockquote>

<hr/>

<h2 id="when-your-page-suddenly-gets-bigger">When your page suddenly gets bigger</h2>

<p>Your CPU would rather cover more ground with fewer entries in its TLB. Linux can help by backing hot memory with bigger pages.</p>

<blockquote>
  <p><strong>Tiny explainer: THP</strong></p>
</blockquote>

<p>Transparent Huge Pages do this automatically for anonymous memory and shmem or tmpfs. A fault can be satisfied with a 2 MiB page instead of 512 small ones. A background thread named khugepaged can also collapse adjacent base pages into a huge page when it is safe.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>khugepaged</code></strong></p>
</blockquote>

<p>Modern kernels add multi size THP which is mTHP on some architectures. Groups of base pages like 16 KiB or 64 KiB reduce fault count and TLB pressure without always jumping to 2 MiB. They are still PTE mapped but behave as larger folios inside the VM.</p>

<blockquote>
  <p><strong>Tiny explainer: mTHP</strong></p>
</blockquote>

<p>You can ask for THP in a region with <code>madvise(..., MADV_HUGEPAGE)</code> or opt out with <code>MADV_NOHUGEPAGE</code>. System wide behavior lives under <code>/sys/kernel/mm/transparent_hugepage/</code> with per size controls. <code>enabled</code> can be <code>always</code>, <code>madvise</code>, <code>never</code>, or <code>inherit</code>. Shmem or tmpfs have their own knobs like a <code>huge=</code> mount option with <code>always</code>, <code>advise</code>, <code>within_size</code>, <code>never</code>.</p>

<p>How to tell if it worked. In <code>/proc/self/smaps</code> the lines for a region include <code>AnonHugePages</code> for anonymous THP and <code>FilePmdMapped</code> for file or shmem huge mappings. System wide <code>/proc/meminfo</code> has <code>AnonHugePages</code>, <code>ShmemPmdMapped</code>, and <code>ShmemHugePages</code>. <code>/proc/vmstat</code> keeps a diary of THP events allocated on fault, fell back, split, swapped as a whole, and so on.</p>

<p>Controls plain map:</p>
<ul>
  <li>Top level: <code>/sys/kernel/mm/transparent_hugepage/enabled</code> which is <code>always</code> or <code>madvise</code> or <code>never</code></li>
  <li>Defrag effort: <code>/sys/kernel/mm/transparent_hugepage/defrag</code> tunes how hard the kernel tries on the fault path vs deferring to khugepaged</li>
  <li>Shmem or tmpfs: <code>huge=always|within_size|advise|never</code> plus shmem specific knobs</li>
</ul>

<p>Modern kernels may also create variable order large folios that are bigger than 4 KiB but PTE mapped not full 2 MiB PMD. This reduces fault count and TLB pressure without always jumping to 2 MiB. Behavior differs by kernel and architecture.</p>

<p>One trade off. Assembling a huge page may require compaction which moves other pages to free a contiguous chunk and this can add a small pause. If first touch latency matters more than steady state speed the defrag knob lets you temper how hard the kernel tries which pushes work to khugepaged instead of doing it inline.</p>

<blockquote>
  <p><strong>Tiny explainer: THP vs hugetlbfs</strong></p>
</blockquote>

<hr/>

<h2 id="dirtytracking-in-userspace-without-racing-the-kernel">Dirty‑tracking in userspace, without racing the kernel</h2>

<p>Imagine you want to copy only the pages an application modified since your last snapshot.</p>

<ol>
  <li>Give yourself the ability to catch write protect faults with userfaultfd in write protect mode.</li>
  <li>Use <code>PAGEMAP_SCAN</code> over your range with the category written since last write protect. Ask the kernel to write protect matching pages and to return compact ranges of what it found.</li>
  <li>Copy those ranges. When the app later writes to one of them userfaultfd wakes your thread. Log the dirtied page, clear write protect, and let it proceed.</li>
</ol>

<p>This avoids walking every PTE and avoids the classic race where a page is dirtied while you were looking. It is also fast because scan plus write protect happens as one atomic operation inside the kernel.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>PAGEMAP_SCAN</code></strong></p>
</blockquote>

<hr/>

<h2 id="the-tlb-and-why-mprotect-costs-a-little">The TLB, and why <code>mprotect</code> costs a little</h2>

<p>The Translation Lookaside Buffer remembers recent translations so the CPU does not walk page tables on every access. If Linux changes a mapping or its permissions it must make sure stale entries are not used.</p>

<p>On x86 there are two broad ways to do it.</p>

<ul>
  <li>Precise invalidation. Invalidate one page at a time with <code>INVLPG</code>. Good for small changes. A single invalidation on a huge page mapping drops the whole 2 MiB entry.</li>
  <li>Broader flushes. Drop many or all entries for example by reloading the page table root register. Fewer instructions now and more misses later while refilling.</li>
</ul>

<p>Which is better depends on how big a change you made, whether you are changing small or huge pages, and the microarchitecture.</p>

<blockquote>
  <p><strong>Tiny explainer: PCID</strong></p>
</blockquote>

<p>There is also a debug knob on some x86 builds named <code>tlb_single_page_flush_ceiling</code> that nudges when the kernel switches from per page invalidations to a broad flush.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>INVLPG</code></strong></p>
</blockquote>

<hr/>

<h2 id="meltdown-and-why-the-kernel-sometimes-switches-maps-on-entry">Meltdown, and why the kernel sometimes switches maps on entry</h2>

<p>Early 2018 brought Meltdown. Speculative execution plus a cache side channel could leak data across the user and kernel boundary. Even if a user mode load from a kernel address would fault, the CPU might speculatively execute it and touch data that leaves a measurable cache trace.</p>

<p>Linux’s defense on x86‑64 is Page Table Isolation which is PTI. Keep two views and switch between them on entry and exit.</p>

<blockquote>
  <p><strong>Tiny explainer: CR3</strong></p>
</blockquote>

<p>Cost. More page table switches, different TLB sharing behavior, and a small memory bump for extra top level tables and the per CPU entry area. With PCID Linux keeps separate TLB tags for the two views to reduce flushes. Some systems allow opting out with <code>nopti</code> when acceptable. Default is on.</p>

<blockquote>
  <p><strong>Tiny explainer: what Meltdown reads</strong></p>
</blockquote>

<hr/>

<h2 id="how-the-kernel-changes-mappings-safely">How the kernel changes mappings safely</h2>

<p>When Linux edits page tables the order is deliberate.</p>

<ol>
  <li>Handle cache rules first on architectures that need it.</li>
  <li>Modify page tables by adding, removing, or changing PTEs.</li>
  <li>Invalidate the TLB so the CPU forgets stale translations.</li>
</ol>

<p>Under the hood are functions that match the granularity of the change like flush an address space, flush a range, or flush a single page.</p>

<p>There is a parallel story for kernel only mappings made with <code>vmap</code> and <code>vmalloc</code>. Before I/O the kernel flushes the vmap range so the physical page sees the latest bytes. After I/O it invalidates the vmap range so speculative reads do not go stale.</p>

<blockquote>
  <p><strong>Tiny explainer: <code>vmap</code> and <code>vmalloc</code></strong></p>
</blockquote>

<p>On x86 you rarely think about the instruction cache because it is coherent with data stores. On others, copying code into executable memory requires an explicit instruction cache flush before running it. The VM has hooks like <code>copy_to_user_page</code> and <code>flush_icache_range</code> where architectures do this housekeeping.</p>

<blockquote>
  <p><strong>Tiny explainer: icache flush</strong></p>
</blockquote>

<hr/>

<h2 id="a-tiny-x86-aside-stacks-and-calls-without-the-haze">A tiny x86 aside: stacks and calls, without the haze</h2>

<p>In 64 bit mode registers wear an R. <code>RIP</code> is the instruction pointer, <code>RSP</code> is the stack, <code>RBP</code> is the frame. The stack grows down. <code>push</code> decrements <code>RSP</code> and stores. <code>pop</code> loads then increments. <code>CALL</code> pushes the return address and jumps. <code>RET</code> pops it into <code>RIP</code>.</p>

<p>On Linux the System V AMD64 ABI passes the first arguments in registers which are <code>RDI</code>, <code>RSI</code>, <code>RDX</code>, <code>RCX</code>, <code>R8</code>, <code>R9</code> and returns values in <code>RAX</code>. Large objects go by pointer. Your stack must be readable and writable.</p>

<blockquote>
  <p><strong>Tiny explainer: System V AMD64 ABI</strong></p>
</blockquote>

<p>User code runs in ring 3. The kernel runs in ring 0. Crossings like syscalls, interrupts, and exceptions go through CPU defined gates. In 64 bit mode Linux uses a flat segmentation model and relies on paging for isolation.</p>

<blockquote>
  <p><strong>Tiny explainer: rings</strong></p>
</blockquote>

<blockquote>
  <p><strong>Tiny note for ARM64 readers</strong></p>
</blockquote>

<hr/>

<h2 id="when-things-go-sideways-and-what-that-usually-means">When things go sideways (and what that usually means)</h2>

<ul>
  <li><code>mmap</code> → <code>EINVAL</code> often a misaligned file <code>offset</code> which must be page aligned or an impossible flag combo</li>
  <li><code>mmap</code> → <code>ENOMEM</code> you may be out of virtual space or VMA count or you hit strict overcommit</li>
  <li>Store to a file mapping → <code>SIGBUS</code> you walked past EOF. The VMA existed, the data did not</li>
  <li><code>mprotect(PROT_EXEC)</code> → <code>EACCES</code> could be a <code>noexec</code> mount or a W^X policy</li>
  <li>Big <code>malloc</code> creates a new line in <code>maps</code> your allocator used <code>mmap</code> for that size</li>
  <li>RSS balloons after <code>fork()</code> copy on write did its job and you wrote to lots of shared pages</li>
  <li>Accidentally clobbered a mapping you probably used <code>MAP_FIXED</code>. Prefer <code>MAP_FIXED_NOREPLACE</code> to fail instead of overwrite</li>
</ul>

<p>When it is mysterious, look. Start friendly with <code>smaps_rollup</code> for the big picture and <code>maps</code> for shapes. Drop to <code>pagemap</code> and the <code>kpage*</code> files only when you truly need per page truth and expect to need privileges.</p>

<hr/>

<h2 id="a-small-checklist-to-keep-nearby">A small checklist to keep nearby</h2>

<ul>
  <li>Need memory now. <code>mmap</code> anonymous with <code>PROT_READ|PROT_WRITE</code> and <code>MAP_PRIVATE|MAP_ANONYMOUS</code></li>
  <li>Generating code. Keep W^X. Write bytes then <code>mprotect(PROT_READ|PROT_EXEC)</code></li>
  <li>Mapping a file. <code>offset</code> must be page aligned. Touching beyond real EOF is <code>SIGBUS</code></li>
  <li>Lots of major faults. Nudge the kernel with <code>MADV_WILLNEED</code> or touch earlier. Watch page cache and storage</li>
  <li>Where did memory go. Start with <code>/proc/&lt;pid&gt;/smaps_rollup</code> then <code>/proc/&lt;pid&gt;/maps</code></li>
  <li>Forking big processes. Expect CoW. RSS grows as you write. Consider <code>exec</code> in the child for heavy work</li>
  <li>Latency sensitive. Consider THP or mTHP where it helps. <code>mlock</code> hot sets. Watch your TLB behavior</li>
</ul>



    



    



<section>
    <p>
        Feedback is extremely welcomed! You can reach out to me on X <a href="https://x.com/0xkato" target="_blank" rel="noopener noreferrer">@0xkato</a>
    </p>
</section>



    







            </div>
                </div></div>
  </body>
</html>
