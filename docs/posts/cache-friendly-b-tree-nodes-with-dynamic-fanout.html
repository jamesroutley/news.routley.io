<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/">Original</a>
    <h1>Cache-Friendly B&#43;Tree Nodes with Dynamic Fanout</h1>
    
    <div id="readability-page-1" class="page"><div>
        



<p>For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node&#39;s contents reside in the CPU cache.</p>
<p>In C++, achieving this means forgoing the use of <code>std::vector</code>, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.</p>
<pre><code>  +----------------------+</code></pre>
<figcaption>Fig 1. Memory Layout of a B+Tree Node as a single contiguous block in heap</figcaption>
<nav aria-labelledby="toc-heading">
  <h2 id="toc-heading">Table of Contents</h2>
  <ol>
    <li><a href="#challenges">Challenges</a></li>
    <li><a href="#the-struct-hack">The Struct Hack</a></li>
    <li><a href="#b+tree-node-declaration">B+Tree Node Declaration</a></li>
    <li><a href="#raw-memory-buffer">Raw Memory Buffer</a></li>
    <li>
      <a href="#the-price-of-fine-grained-control">The Price Of Fine-Grained Control</a>
      <ul>
        <li><a href="#manual-handling-of-deallocation">Manual Handling Of Deallocation</a></li>
        <li><a href="#adding-new-members-in-a-derived-class">Adding New Members In A Derived Class</a></li>
        <li><a href="#reinventing-the-wheel">Reinventing The Wheel</a></li>
        <li><a href="#hidden-data-type-assumptions">Hidden Data Type Assumptions</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ol>
</nav>
<h2 id="challenges" tabindex="-1">Challenges <a href="#challenges" aria-hidden="true"></a></h2>
<p>Using <code>std::vector</code> for a B+Tree node&#39;s entries is a non-starter. A <code>std::vector</code> object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.</p>
<p>This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array&#39;s size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.</p>
<p>This isn&#39;t just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?</p>
<p>The solution isn&#39;t obvious, but it&#39;s a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.</p>
<h2 id="the-struct-hack" tabindex="-1">The Struct Hack <a href="#the-struct-hack" aria-hidden="true"></a></h2>
<p>The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.</p>
<pre><code><span>struct</span> <span>Payload</span> <span>{</span></code></pre>
<p>At runtime, when the required size <code>N</code> is known, you allocate a single block of memory for the struct and the <code>N</code> elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.</p>
<pre><code></code></pre>
<p>This pattern was officially standardized in C99, where it is known as a <a href="https://en.wikipedia.org/wiki/Flexible_array_member">flexible array member</a>.</p>
<p>The C++11 standard formally incorporates the flexible array member, referring to it as an <strong>array of unknown bound</strong> when it is the last member of a struct.</p>
<blockquote>
<p><strong>Arrays of unknown bound</strong></p>
<p>If <code>expr</code> is omitted in the declaration of an array, the type declared is &#34;array of unknown bound of T&#34;, which is a kind of incomplete type, ...</p>
<pre><code><span>extern</span> <span>int</span> x<span>[</span><span>]</span><span>;</span>      </code></pre>
</blockquote>
<p>This means that in C++, the size can be omitted from the final array declaration (e.g. <code>entries_[]</code>), and the code will compile, enabling the same pattern.</p>
<h2 id="b+tree-node-declaration" tabindex="-1">B+Tree Node Declaration <a href="#b+tree-node-declaration" aria-hidden="true"></a></h2>
<p>Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.</p>
<pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>KeyType</span><span>,</span> <span>typename</span> <span>ValueType</span><span>&gt;</span></code></pre>
<p>Using a <code>std::vector&lt;KeyValuePair&gt;</code> for the node&#39;s entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.</p>
<p>A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.</p>
<p>This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.</p>
<h2 id="raw-memory-buffer" tabindex="-1">Raw Memory Buffer <a href="#raw-memory-buffer" aria-hidden="true"></a></h2>
<p>This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard <code>new</code> syntax which will attempt to allocate storage, and then initialize the object in the same storage.</p>
<p>Instead, we use the <a href="https://en.cppreference.com/w/cpp/language/new.html#Placement_new">placement new</a> syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard <code>new</code> operator does not have in this scenario because of the flexible array member.</p>
<pre><code></code></pre>
<p>The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.</p>
<h2 id="the-price-of-fine-grained-control" tabindex="-1">The Price Of Fine-Grained Control <a href="#the-price-of-fine-grained-control" aria-hidden="true"></a></h2>
<p>To create an instance of a B+Tree node with a fanout of <code>256</code>, it is not possible to write simple idiomatic code like this: <code>new BPlusTreeNode(256)</code>.</p>
<p>Instead we use the custom <code>BPlusTreeNode::Get</code> helper which knows how much raw memory to allocate for the object including the data section.</p>
<pre><code>BPlusTreeNode <span>*</span>root <span>=</span> <span>BPlusTreeNode</span><span>&lt;</span>KeyValuePair<span>&gt;</span><span>::</span><span>Get</span><span>(</span><span>256</span><span>)</span><span>;</span></code></pre>
<h3 id="manual-handling-of-deallocation" tabindex="-1">Manual Handling Of Deallocation <a href="#manual-handling-of-deallocation" aria-hidden="true"></a></h3>
<p>The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.</p>
<pre><code><span>class</span> <span>BPlusTreeNode</span> <span>{</span></code></pre>
<p>This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our <code>Get</code> function. We constructed the object outside in: <em>raw memory buffer -&gt; node object -&gt; individual elements</em>. So we teardown in the opposite direction, from the inside out: <em>individual elements -&gt; node object -&gt; raw memory buffer</em>.</p>
<h3 id="adding-new-members-in-a-derived-class" tabindex="-1">Adding New Members In A Derived Class <a href="#adding-new-members-in-a-derived-class" aria-hidden="true"></a></h3>
<p>Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized <code>InnerNode</code> or <code>LeafNode</code> class.</p>
<pre><code>+----------------------+</code></pre>
<figcaption>Fig 2. Adding new members in a derived class will overwrite the <code>entries_</code> array in memory.</figcaption>
<p>The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.</p>
<p>The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.</p>
<pre><code>+----------------------+</code></pre>
<figcaption>Fig 3. Memory layout of base class with members necessary for the derived <code>InnerNode</code> and <code>LeafNode</code> implementations.</figcaption>
<h3 id="reinventing-the-wheel" tabindex="-1">Reinventing The Wheel <a href="#reinventing-the-wheel" aria-hidden="true"></a></h3>
<p>By using a raw C-style array, we effectively reinvent parts of <code>std::vector</code>, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.</p>
<p>The engineering cost to make this implementation production-grade is significant.</p>
<h3 id="hidden-data-type-assumptions" tabindex="-1">Hidden Data Type Assumptions <a href="#hidden-data-type-assumptions" aria-hidden="true"></a></h3>
<p>The <code>BPlusTreeNode</code>&#39;s generic signature implies it will work for any <code>KeyType</code> or <code>ValueType</code>, but this is dangerously misleading. Using a non-trivial type like <code>std::string</code> will cause undefined behavior.</p>
<pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>KeyType</span><span>,</span> <span>typename</span> <span>ValueType</span><span>&gt;</span></code></pre>
<p>To understand why, let&#39;s look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.</p>
<pre><code><span>bool</span> <span>Insert</span><span>(</span><span>const</span> KeyValuePair <span>&amp;</span>element<span>,</span> KeyValuePair <span>*</span>pos<span>)</span> <span>{</span></code></pre>
<p>The use of <code>std::memmove</code> introduces a hidden constraint: <code>KeyValuePair</code> must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.</p>
<p>Using <code>std::memmove</code> on a <code>std::string</code> object creates a shallow copy. We now have two <code>std::string</code> objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.</p>
<h2 id="conclusion" tabindex="-1">Conclusion <a href="#conclusion" aria-hidden="true"></a></h2>
<p>The initial hurdle when implementing a B+Tree implementation is solving the contiguous memory layout puzzle avoiding heap indirection. The solution is flexible array members, which makes it possible to compile the program when the number of entries in the B+Tree node is dynamic, and a runtime value.</p>
<p>However, the implementation complexity goes up because of manual memory management, lack of inheritance, and hidden data type constraints. This is unavoidable for high performance.</p>

<hr/>
<ul><li>Next: <a href="https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/">A B+Tree Node Underflows: Merge or Borrow?</a></li>
</ul>

      </div></div>
  </body>
</html>
