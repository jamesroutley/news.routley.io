<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.understandingai.org/p/i-got-fooled-by-ai-for-science-hypeheres">Original</a>
    <h1>I got fooled by AI-for-science hype–here&#39;s what it taught me</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><article><div><div><div dir="auto"><p><em><span>I’m excited to publish this guest post by </span><a href="https://x.com/NMcGreivy/" rel="">Nick McGreivy</a><span>, a physicist who last year earned a PhD from Princeton. Nick used to be optimistic that AI could accelerate physics research. But when he tried to apply AI techniques to real physics problems the results were disappointing.</span></em></p><p><em><span>I’ve </span><a href="https://www.understandingai.org/p/six-principles-for-thinking-about" rel="">written before</a><span> about the Princeton School of AI Safety, which holds that the impact of AI is likely to be similar to that of past general-purpose technologies such as electricity, integrated circuits, and the Internet. I think of this piece from Nick as being in that same intellectual tradition.</span></em></p><p><em>—Timothy B. Lee</em></p><p><span>In 2018, as a second-year PhD student at Princeton studying </span><a href="https://en.wikipedia.org/wiki/Plasma_(physics)" rel="">plasma physics</a><span>, I decided to switch my research focus to machine learning. I didn’t yet have a specific research project in mind, but I thought I could make a bigger impact by using AI to accelerate physics research. (I was also, quite frankly, motivated by the </span><a href="https://www.nytimes.com/2017/10/22/technology/artificial-intelligence-experts-salaries.html?action=click&amp;module=RelatedCoverage&amp;pgtype=Article&amp;region=Footer" rel="">high</a><span> </span><a href="https://www.nytimes.com/2018/04/19/technology/artificial-intelligence-salaries-openai.html" rel="">salaries</a><span> in AI.)</span></p><p><span>I eventually chose to study what AI pioneer Yann LeCun later </span><a href="https://x.com/ylecun/status/1581648953275473921" rel="">described</a><span> as a “pretty hot topic, indeed”: using AI to solve partial differential equations (PDEs). But as I tried to build on what I thought were impressive results, I found that AI methods performed much worse than advertised.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png" width="1456" height="963" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:963,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:2532708,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:&#34;https://www.understandingai.org/i/163736413?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7a6c-a9d3-4c9a-b9ce-f515b811e219_2004x1325.png 1456w" sizes="100vw" fetchpriority="high"/></picture><div><div></div></div></div></a><figcaption>The author, Nick McGreivy.</figcaption></figure></div><p><span>At first, I tried applying a widely-cited AI method called PINN to some fairly simple PDEs, but found it to be unexpectedly brittle. Later, though dozens of papers had claimed that AI methods could solve PDEs faster than standard numerical methods—in some cases as much as a </span><a href="https://iopscience.iop.org/article/10.1088/1741-4326/ad313a" rel="">million times faster</a><span>—I discovered that a large majority of these comparisons were unfair. When </span><a href="https://www.nature.com/articles/s42256-024-00897-5" rel="">I compared</a><span> these AI methods on equal footing to state-of-the-art numerical methods, whatever narrowly defined advantage AI had usually disappeared.</span></p><p><span>This experience has led me to question the idea that AI is poised to “</span><a href="https://www.youtube.com/watch?v=yxAJohm0l_g&amp;ab_channel=TheRoyalSwedishAcademyofSciences" rel="">accelerate</a><span>” or even “</span><a href="https://www.youtube.com/watch?v=PKN95I93iGE&amp;ab_channel=TheEconomist" rel="">revolutionize</a><span>” science. Are we really about to enter what DeepMind </span><a href="https://deepmind.google/public-policy/ai-for-science/" rel="">calls</a><span> “a new golden age of AI-enabled scientific discovery,” or has the overall potential of AI in science been exaggerated—much like it was in my subfield?</span></p><p><span>Many others have identified similar issues. For example, in 2023 DeepMind </span><a href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/" rel="">claimed</a><span> to have discovered 2.2 million crystal structures, </span><a href="https://www.nature.com/articles/s41586-023-06735-9" rel="">representing</a><span> “an order-of-magnitude expansion in stable materials known to humanity.” But when </span><a href="https://x.com/Robert_Palgrave/status/1744383962913394758" rel="">materials</a><span> </span><a href="https://journals.aps.org/prxenergy/abstract/10.1103/PRXEnergy.3.011002" rel="">scientists</a><span> </span><a href="https://pubs.acs.org/doi/10.1021/acs.chemmater.4c00643" rel="">analyzed these compounds</a><span>, they found it was “</span><a href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool" rel="">mostly junk</a><span>” and “respectfully” suggested that the paper “does not report any new materials.”</span></p><p><span>Separately, Princeton computer scientists </span><a href="https://www.cs.princeton.edu/~arvindn/" rel="">Arvind Narayanan</a><span> and </span><a href="https://www.cs.princeton.edu/~sayashk/" rel="">Sayash Kapoor</a><span> have </span><a href="https://reproducible.cs.princeton.edu/" rel="">compiled a list</a><span> of 648 papers across 30 fields that all make a methodological error called </span><a href="http://en.wikipedia.org/wiki/Leakage_(machine_learning)" rel="">data leakage</a><span>. In each case data leakage leads to overoptimistic results. They argue that AI-based science is facing a “reproducibility crisis.”</span></p><p><span>Yet AI adoption in scientific research has been </span><a href="https://doi.org/10.1038/s41562-024-02020-5" rel="">rising sharply</a><span> </span><a href="https://arxiv.org/abs/2405.15828" rel="">over the last decade</a><span>. Computer science has seen the biggest impacts, of course, but other disciplines—physics, chemistry, biology, medicine, and the social sciences—have also seen rapidly increasing AI adoption. Across all scientific publications, </span><a href="https://www.csiro.au/en/research/technology-space/ai/artificial-intelligence-for-science-report" rel="">rates of AI usage grew</a><span> from 2 percent in 2015 to </span><a href="https://www.nature.com/articles/d41586-023-02980-0" rel="">almost 8 percent in 2022</a><span>. It’s harder to find data about the last few years, but there’s every reason to think that </span><a href="https://trends.google.com/trends/explore?date=all&amp;q=ai%20for%20science&amp;hl=en" rel="">hockey stick growth has continued</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png" width="1456" height="1092" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1092,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36a0461d-d4f1-497b-8a4e-b962fd14c880_1600x1200.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p><span>To be clear, AI </span><em>can</em><span> drive scientific breakthroughs. My concern is about their magnitude and frequency. Has AI really shown enough potential to justify such a massive shift in talent, training, time, and money away from existing research directions and towards a single paradigm?</span></p><p><span>Every field of science is experiencing AI differently, so we should be cautious about making generalizations. I’m convinced, however, that </span><em>some</em><span> of the lessons from my experience are broadly applicable across science:</span></p><ul><li><p><span>AI adoption is exploding among scientists less because it benefits science and more </span><a href="https://arxiv.org/abs/2412.07727" rel="">because it benefits the scientists themselves</a><span>.</span></p></li><li><p><span>Because AI researchers almost never publish negative results, AI-for-science is experiencing </span><a href="https://en.wikipedia.org/wiki/Survivorship_bias" rel="">survivorship bias</a><span>.</span></p></li><li><p>The positive results that get published tend to be overly optimistic about AI’s potential.</p></li></ul><p>As a result, I’ve come to believe that AI has generally been less successful and revolutionary in science than it appears to be.</p><p><span>Ultimately, I don’t know whether AI will reverse the decades-long trend of </span><a href="https://mattsclancy.substack.com/p/science-is-getting-harder" rel="">declining scientific productivity</a><span> and stagnating (or even decelerating) rates of </span><a href="https://substack.com/@aisnakeoil/note/c-92421948" rel="">scientific progress</a><span>. I don’t think anyone does. But barring major (and in my opinion unlikely) breakthroughs in advanced AI, I expect AI to be much more a </span><a href="https://knightcolumbia.org/content/ai-as-normal-technology" rel="">normal</a><span> tool of incremental, uneven scientific progress than a revolutionary one.</span></p><p><span>In the summer of 2019, I got a first taste of what would become my dissertation topic: solving PDEs with AI. </span><a href="https://en.wikipedia.org/wiki/Partial_differential_equation" rel="">PDEs</a><span> are mathematical equations used to model a wide range of physical systems, and solving (i.e., simulating) them is an extremely important task in computational physics and engineering. My lab uses PDEs to </span><a href="https://www.pppl.gov/research/computational-sciences" rel="">model</a><span> the behavior of plasmas, such as inside fusion reactors and in the interstellar medium of outer space.</span></p><p><span>The AI models being used to solve PDEs are custom deep learning models, much more analogous to </span><a href="https://deepmind.google/technologies/alphafold/" rel="">AlphaFold</a><span> than ChatGPT.</span></p><p><span>The first approach I tried was something called the physics-informed neural network. PINNs had recently been introduced in an </span><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yZ0-ywkAAAAJ&amp;citation_for_view=yZ0-ywkAAAAJ:eLRq4zTgah0C" rel="">influential paper</a><span> that had already racked up hundreds of citations.</span></p><p>PINNs were a radically different way of solving PDEs compared to standard numerical methods. Standard methods represent a PDE solution as a set of pixels (like in an image or video) and derive equations for each pixel value. In contrast, PINNs represent the PDE solution as a neural network and put the equations into the loss function.</p><p>As a naive grad student who didn’t even have an advisor yet, there was something incredibly appealing to me about PINNs. They just seemed so simple, elegant, and general.</p><p><span>They also seemed to have good results. The </span><a href="https://www.sciencedirect.com/science/article/abs/pii/S0021999118307125" rel="">paper</a><span> introducing PINNs found that their “effectiveness” had been “demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction-diffusion systems, and the propagation of nonlinear shallow-water waves.” If PINNs had solved all these PDEs, I figured, then surely they could solve some of the plasma physics PDEs that </span><a href="https://en.wikipedia.org/wiki/Princeton_Plasma_Physics_Laboratory" rel="">my lab</a><span> </span><a href="https://ammar-hakim.org/sj/je/je17/je17-hasegawa-wakatani.html" rel="">cared</a><span> </span><a href="https://en.wikipedia.org/wiki/Gyrokinetics" rel="">about</a><span>.</span></p><p><span>But when I replaced one of the </span><a href="https://github.com/maziarraissi/PINNs" rel="">examples from</a><span> that influential first paper (</span><a href="https://en.wikipedia.org/wiki/Burgers%27_equation" rel="">1D Burgers’</a><span>) with a different, but still extremely simple, PDE (</span><a href="https://ammar-hakim.org/sj/je/je14/je14-vlasov-fixed-pot.html" rel="">1D Vlasov</a><span>), the results didn’t look anything like the exact solution. Eventually, after extensive tuning, I was able to get something that looked correct. However, when I tried slightly more complex PDEs (such as </span><a href="https://en.wikipedia.org/wiki/Vlasov_equation#The_Vlasov%E2%80%93Poisson_equation" rel="">1D Vlasov-Poisson</a><span>), no amount of tuning could give me a decent solution.</span></p><p>After a few weeks of failure, I messaged a friend at a different university, who told me that he too had tried using PINNs, but hadn’t been able to get good results.</p><p>Eventually, I realized what had gone wrong. The authors of the original PINN paper had, like me, “observed that specific settings that yielded impressive results for one equation could fail for another.” But because they wanted to convince readers of how exciting PINNs were, they hadn’t shown any examples of PINNs failing.</p><p>This experience taught me a few things. First, to be cautious about taking AI research at face value. Most scientists aren’t trying to mislead anyone, but because they face strong incentives to present favorable results, there’s still a risk that you’ll be misled. Moving forward, I would have to be more skeptical, even (or perhaps especially) of high-impact papers with impressive results.</p><p><span>Second, people rarely publish papers about when AI methods fail, only when they succeed. The authors of the original PINN paper didn’t publish about the PDEs their method hadn’t been able to solve. I didn’t publish my unsuccessful experiments, presenting only a </span><a href="https://github.com/nickmcgreivy/PINN/blob/master/APS-Poster-McGreivy-2019.pdf" rel="">poster</a><span> at an obscure conference. So very few researchers heard about them. In fact, despite the huge popularity of PINNs, it took four years for anyone to publish </span><a href="https://proceedings.neurips.cc/paper/2021/hash/df438e5206f31600e6ae4af72f2725f1-Abstract.html" rel="">a paper about</a><span> their failure modes. That paper now has almost a thousand citations, suggesting that many other scientists tried PINNs and found similar issues.</span></p><p><span>Third, I concluded that PINNs weren’t the approach I wanted to use. They were simple and elegant, sure, but they were also far </span><a href="https://arxiv.org/abs/2205.14249" rel="">too unreliable</a><span>, </span><a href="https://arxiv.org/abs/2306.00230" rel="">too finicky</a><span>, and </span><a href="https://academic.oup.com/imamat/article/89/1/143/7680268" rel="">too slow</a><span>.</span></p><p><span>As of today, six years later, the original PINN paper has a whopping </span><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yZ0-ywkAAAAJ&amp;citation_for_view=yZ0-ywkAAAAJ:eLRq4zTgah0C" rel="">14,000 citations</a><span>, making it the most cited numerical methods paper of the 21st century (and, by my count, a year or two away from becoming the second most-cited numerical methods paper of all time).</span></p><p><span>Though it’s now widely accepted that PINNs generally aren’t competitive with standard numerical methods for </span><em>solving</em><span> PDEs, there remains debate over how well PINNs perform for a different class of problems known as </span><em>inverse problems</em><span>. Advocates claim that PINNs are “</span><a href="https://www.nature.com/articles/s42254-021-00314-5" rel="">particularly effective</a><span>” for inverse problems, but some researchers have </span><a href="https://academic.oup.com/pnasnexus/article/3/1/pgae005/7516080" rel="">vigorously contested</a><span> that idea.</span></p><p><span>I don’t know which side of the debate is right. I’d like to think that </span><a href="https://x.com/shoyer/status/1532278186901327872" rel="">something useful has come</a><span> from all this PINN research, but I also wouldn’t be surprised if one day we look back on PINNs as simply a massive citation bubble.</span></p><p>For my dissertation, I focused on solving PDEs using deep learning models that, like traditional solvers, treated the PDE solution as a set of pixels on a grid or a graph.</p><p><span>Unlike PINNs, this approach had shown a lot of promise on the complex, time-dependent PDEs that my lab cared about. Most impressively, </span><a href="https://arxiv.org/abs/2010.08895" rel="">paper</a><span> </span><a href="https://www.nature.com/articles/s42256-021-00302-5" rel="">after</a><span> </span><a href="https://openreview.net/forum?id=roNqYL0_XP" rel="">paper</a><span> </span><a href="https://www.pnas.org/doi/abs/10.1073/pnas.2101784118" rel="">had</a><span> </span><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13619" rel="">demonstrated</a><span> the ability to solve PDEs faster—often orders of magnitude faster—than standard numerical methods.</span></p><p><span>The examples that excited </span><a href="https://www.pppl.gov/people/ammar-hakim" rel="">my advisor</a><span> and me the most were PDEs from fluid mechanics, such as the </span><a href="https://www.quantamagazine.org/latest-neural-nets-solve-worlds-hardest-equations-faster-than-ever-before-20210419/" rel="">Navier-Stokes equations</a><span>. We thought we might see similar speedups because the PDEs we cared about—equations describing </span><a href="https://ammar-hakim.org/sj/je/je17/je17-hasegawa-wakatani.html" rel="">plasmas in</a><span> </span><a href="https://hal.science/hal-03974985/file/Gyrokinetics_fundamentals_XG_ML_23.pdf" rel="">fusion reactors</a><span>, for example—have a </span><a href="https://arxiv.org/abs/1908.01814" rel="">similar mathematical structure</a><span>. In theory, this could allow scientists and engineers like us to simulate larger systems, more rapidly optimize existing designs, and ultimately accelerate the pace of research.</span></p><p>By this point, I was seasoned enough to know that in AI research, things aren’t always as rosy as they seem. I knew that reliability and robustness might be serious issues. If AI models give faster simulations, but those simulations are less reliable, would that be worth the trade-off? I didn’t know the answer and set out to find out.</p><p><span>But as I tried—and </span><a href="https://arxiv.org/abs/2303.16110" rel="">mostly failed</a><span>—to make these models more reliable, I began to question how much promise AI models had really shown for accelerating PDEs.</span></p><p><span>According to a number of </span><a href="https://www.quantamagazine.org/latest-neural-nets-solve-worlds-hardest-equations-faster-than-ever-before-20210419/" rel="">high-profile papers</a><span>, AI had solved the Navier-Stokes equations orders of magnitude faster than standard numerical methods. I eventually discovered, however, that the baseline methods used in these papers were not the fastest numerical methods available. When I compared AI to more advanced numerical methods, I found that AI was no faster (or at most, only slightly faster) than the stronger baselines.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png" width="1422" height="574" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:574,&#34;width&#34;:1422,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57438099-02ae-4bcd-8bdc-a1767385befd_1422x574.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a><figcaption>When AI methods for solving PDEs were compared to strong baselines, whatever narrowly defined advantage AI had usually disappeared.</figcaption></figure></div><p><span>My advisor and I eventually </span><a href="https://www.nature.com/articles/s42256-024-00897-5" rel="">published</a><span> a systematic review of research using AI to solve PDEs from fluid mechanics. We found that 60 out of the 76 papers (79 percent) that claimed to outperform a standard numerical method had used a weak baseline, either because they hadn’t compared to more advanced numerical methods, or because they weren’t comparing them on an equal footing. Papers with large speedups </span><em>all</em><span> compared to weak baselines, suggesting that the more impressive the result, the more likely the paper had made an unfair comparison.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png" width="1300" height="700" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:700,&#34;width&#34;:1300,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031e6fe4-c936-4846-8f81-0e0029d1042d_1300x700.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a><figcaption>Results from a systematic review of research comparing AI methods for solving PDEs from fluid mechanics to standard numerical methods. Very few papers reported negative results, while those reporting positive results mostly compared to weak baselines.</figcaption></figure></div><p><span>We also found evidence, once again, that researchers tend not to report negative results, an effect known as </span><a href="https://en.wikipedia.org/wiki/Reporting_bias" rel="">reporting bias</a><span>. We ultimately </span><a href="https://www.nature.com/articles/s42256-024-00897-5" rel="">concluded</a><span> that AI-for-PDE-solving research is overoptimistic: “weak baselines lead to overly positive results, while reporting biases lead to under-reporting of negative results.”</span></p><p><span>These findings </span><a href="https://www.nature.com/articles/s42256-025-00989-w" rel="">sparked a debate</a><span> about AI in computational science and engineering:</span></p><ul><li><p><a href="https://engineering.gwu.edu/lorena-barba" rel="">Lorena Barba</a><span>, a professor at GWU who has previously discussed poor research practices in what she </span><a href="https://lorenabarba.com/figshare/anti-patterns-of-scientific-machine-learning-to-fool-the-massesa-call-for-open-science/" rel="">has called</a><span> “Scientific Machine Learning to Fool the Masses,” </span><a href="https://x.com/LorenaABarba/status/1839729358044574158" rel="">saw</a><span> our results as “solid evidence supporting our concerns in the computational science community over the hype and unscientific optimism” of AI.</span></p></li><li><p><a href="https://stephanhoyer.com/" rel="">Stephan Hoyer</a><span>, the lead of a </span><a href="https://arxiv.org/abs/2207.00556" rel="">team</a><span> at Google Research that independently reached </span><a href="https://x.com/shoyer/status/1362301955243057154" rel="">similar conclusions</a><span>, </span><a href="https://x.com/shoyer/status/1839195637474332850" rel="">described</a><span> our paper as “a nice summary of why I moved on from [AI] for PDEs” to weather prediction and climate modeling, applications of AI that seem </span><a href="https://www.nature.com/articles/d41586-024-02391-9" rel="">more promising</a><span>.</span></p></li><li><p><a href="https://brandstetter-johannes.github.io/" rel="">Johannes Brandstetter</a><span>, a professor at JKU Linz and co-founder of a </span><a href="https://www.emmi.ai/about" rel="">startup</a><span> that provides “AI-driven physics simulations”, </span><a href="https://www.nature.com/articles/s42256-024-00962-z" rel="">argued</a><span> that AI might achieve better results for more complex industrial applications and that “the future of the field remains undeniably promising and brimming with potential impact.”</span></p></li></ul><p><span>In </span><a href="https://www.nature.com/articles/s42256-025-00989-w" rel="">my opinion</a><span>, AI might eventually prove useful for certain applications related to solving PDEs, but I currently don’t see much reason for optimism. I’d like to see a lot more focus on trying to match the reliability of numerical methods and on </span><a href="https://cset.georgetown.edu/article/what-does-ai-red-teaming-actually-mean/" rel="">red teaming</a><span> AI methods; right now, they have neither the </span><a href="https://arxiv.org/abs/2303.16110" rel="">theoretical guarantees</a><span> nor empirically validated robustness of standard numerical methods.</span></p><p><span>I’d also like to see funding agencies incentivize scientists to create challenge problems for PDEs. A good model could be </span><a href="https://en.wikipedia.org/wiki/CASP" rel="">CASP</a><span>, a biennial protein folding competition that helped to motivate and focus research in this area over the last 30 years.</span></p><p><span>Besides </span><a href="https://www.nobelprize.org/prizes/chemistry/2024/press-release/" rel="">protein folding</a><span>, the canonical example of a scientific breakthrough from AI, a few examples of scientific progress from AI include:</span></p><ul><li><p><span>Weather forecasting, where </span><a href="https://www.ecmwf.int/en/about/media-centre/news/2025/ecmwfs-ai-forecasts-become-operational" rel="">AI forecasts</a><span> have had up to 20% higher accuracy (though still lower resolution) compared to traditional physics-based forecasts.</span></p></li><li><p><span>Drug discovery, where </span><a href="https://www.sciencedirect.com/science/article/pii/S135964462400134X?via%3Dihub" rel="">preliminary data</a><span> suggests that AI-discovered drugs have been more successful in Phase I (but not Phase II) clinical trials. If the trend holds, this would imply a nearly twofold increase in end-to-end drug approval rates.</span></p></li></ul><p><span>But </span><a href="https://deepmind.google/public-policy/ai-for-science/" rel="">AI</a><span> </span><a href="https://ai.google/applied-ai/science/" rel="">companies</a><span>, </span><a href="https://royalsociety.org/news-resources/projects/science-in-the-age-of-ai/" rel="">academic</a><span> and </span><a href="https://www.anl.gov/ai/reference/AI-for-Science-Energy-and-Security-Report-2023" rel="">governmental</a><span> organizations, and </span><a href="https://www.npr.org/2023/10/16/1198908289/ai-proteins-batteries-artificial-intelligence-scientific-discoveries" rel="">media outlets</a><span> increasingly present AI not only as a </span><a href="https://www.nature.com/articles/d41586-025-01069-0" rel="">useful scientific tool</a><span>, but </span><a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai-for-science/" rel="">one that</a><span> “will have a transformational impact” on science.</span></p><p><span>I don’t think we should necessarily dismiss these statements. While current LLMs, </span><a href="https://deepmind.google/public-policy/ai-for-science/" rel="">according to DeepMind</a><span>, “still struggle with the deeper creativity and reasoning that human scientists rely on”, </span><a href="https://helentoner.substack.com/p/long-timelines-to-advanced-ai-have" rel="">hypothetical advanced AI systems</a><span> might one day be capable of </span><a href="https://sakana.ai/ai-scientist/" rel="">fully</a><span> </span><a href="https://www.futurehouse.org/" rel="">automating</a><span> the scientific process. I don’t expect that to happen anytime soon—if ever. But if such systems are created, there’s no doubt they would transform and accelerate science.</span></p><p>However, based on some of the lessons from my research experience, I think we should be pretty skeptical of the idea that more conventional AI techniques are on pace to significantly accelerate scientific progress.</p><p><span>Most narratives about AI accelerating science come from AI companies or scientists working on AI who benefit, directly or indirectly, from those narratives. For example, NVIDIA CEO Jensen Huang </span><a href="https://blogs.nvidia.com/blog/supercomputing-24/" rel="">talks about how</a><span> “AI will drive scientific breakthroughs” and “</span><a href="https://www.youtube.com/watch?v=heshd3L6Kdk" rel="">accelerate science by a million-X</a><span>.” NVIDIA, whose </span><a href="https://www.technologyreview.com/2016/04/07/161131/the-man-selling-shovels-in-the-machine-learning-gold-rush/" rel="">financial conflicts of interest</a><span> make them a particularly unreliable narrator, regularly makes hyperbolic statements about AI in science.</span></p><p><span>You might think that the rising adoption of AI by scientists is </span><a href="https://deepmind.google/public-policy/ai-for-science/" rel="">evidence</a><span> </span><a href="https://arxiv.org/abs/2405.15828" rel="">of</a><span> </span><a href="https://www.nature.com/articles/s41562-024-02020-5" rel="">AI’s</a><span> </span><a href="https://www.csiro.au/en/research/technology-space/ai/artificial-intelligence-for-science-report" rel="">usefulness</a><span> </span><a href="https://bojan.substack.com/p/ai-is-eating-the-research-world" rel="">in science</a><span>. After all, if AI usage in scientific research is growing exponentially, it must be because scientists find it useful, right?</span></p><p><span>I’m not so sure. In fact, I suspect that scientists are switching to AI less because it benefits science, and more because it benefits them.</span></p><p><span>Consider my motives for switching to AI in 2018. While I sincerely thought that AI might be useful in plasma physics, I was mainly motivated by higher salaries, better job prospects, and academic prestige. I also noticed that higher-ups at my lab usually seemed more interested in the </span><a href="https://www.energy.gov/science/articles/department-energy-announces-68-million-funding-artificial-intelligence-scientific" rel="">fundraising potential</a><span> of AI than technical considerations.</span></p><p><span>Later research found that scientists who use AI are </span><a href="https://www.nature.com/articles/d41586-024-03355-9" rel="">more likely to publish top-cited papers</a><span> and receive on average </span><a href="https://arxiv.org/abs/2412.07727" rel="">three times as many citations</a><span>. With such strong incentives to use AI, it isn’t surprising that so many scientists are doing so.</span></p><p><span>So even when AI achieves genuinely impressive results </span><em>in</em><span> science, that doesn’t mean that AI has done something useful </span><em>for</em><span> science. More often, it reflects only the </span><em>potential</em><span> of AI to be useful down the road.</span></p><p><span>This is because scientists working on AI (myself included) often work backwards. Instead of identifying a problem and then trying to find a solution, we start by assuming that AI will be the solution and then looking for problems to solve. But because it’s difficult to identify open scientific challenges that can be solved using AI, this “</span><a href="https://x.com/MilesCranmer/status/1879542350541635882" rel="">hammer in search of a nail</a><span>” style of science means that researchers will often tackle problems which are suitable for using AI but which either have already been solved or don&#39;t create new scientific knowledge.</span></p><p>To accurately evaluate the impacts of AI in science, we need to actually look at the science. But unfortunately, the scientific literature is not a reliable source for evaluating the success of AI in science.</p><p><span>One issue is </span><a href="https://en.wikipedia.org/wiki/Survivorship_bias" rel="">survivorship bias</a><span>. Because AI research, </span><a href="https://research-information.bris.ac.uk/ws/portalfiles/portal/437692523/methods_failing_the_data.pdf" rel="">in the words of</a><span> one researcher, has “nearly complete non-publication of negative results,” we usually only see the successes of AI in science and not the failures. But without negative results, our attempts to evaluate the impacts of AI in science typically get distorted.</span></p><p><span>As anyone who’s studied the </span><a href="https://en.wikipedia.org/wiki/Replication_crisis" rel="">replication crisis</a><span> knows, survivorship bias is a </span><a href="https://en.wikipedia.org/wiki/Science_Fictions" rel="">major issue</a><span> in science. Usually, the culprit is a </span><a href="https://www.cambridge.org/core/journals/psychological-medicine/article/cumulative-effect-of-reporting-and-citation-biases-on-the-apparent-efficacy-of-treatments-the-case-of-depression/71D73CADE32C0D3D996DABEA3FCDBF57" rel="">selection process</a><span> in which results that are not statistically significant are filtered from the scientific literature.</span></p><p><span>For example, the distribution of </span><a href="https://x.com/JohnHolbein1/status/1903173893222711795" rel="">z-values from medical research</a><span> is shown below. A z-value between -1.96 and 1.96 indicates that a result is not statistically significant. The sharp discontinuity around these values suggests that many scientists either didn’t publish results between these values or massaged their data until they cleared the threshold of statistical significance.</span></p><p>The problem is that if researchers fail to publish negative results, it can cause medical practitioners and the general public to overestimate the effectiveness of medical treatments.</p><p><span>Something similar has been happening in AI-for-science, though the selection process is based not on statistical significance but on </span><em>whether the proposed method outperforms other approaches or successfully performs some novel task</em><span>. This means that AI-for-science researchers almost always report successes of AI, and rarely publish results when AI isn’t successful.</span></p><p><span>A second issue is that pitfalls often cause the successful results that do get published to reach overly optimistic conclusions about AI in science. The details and </span><a href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool" rel="">severity</a><span> seem to differ </span><a href="https://journals.aps.org/prxenergy/abstract/10.1103/PRXEnergy.3.011002" rel="">between</a><span> </span><a href="https://x.com/Robert_Palgrave/status/1744383962913394758" rel="">fields</a><span>, but </span><a href="https://www.nature.com/articles/d41586-019-02307-y#ref-CR2" rel="">pitfalls mostly</a><span> have fallen into one of </span><a href="https://arxiv.org/abs/2407.12220" rel="">four categories</a><span>: </span><a href="https://reproducible.cs.princeton.edu/" rel="">data leakage</a><span>, </span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184604" rel="">weak</a><span> </span><a href="https://x.com/tunguz/status/1853545690565058723" rel="">baselines</a><span>, </span><a href="https://news.ycombinator.com/item?id=36231147" rel="">cherry-picking</a><span>, and </span><a href="https://pubs.acs.org/doi/10.1021/acs.chemmater.4c00643" rel="">misreporting</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png" width="1456" height="819" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:819,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff83b0629-a6f1-49e1-9c19-6b9932db6f30_1600x900.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a><figcaption>The same people who evaluate AI models also benefit from those evaluations.</figcaption></figure></div><p><span>While the causes of this tendency towards overoptimism are complex, the core issue appears to be a </span><a href="https://arxiv.org/abs/2407.12220" rel="">conflict of interest</a><span> in which the same people who evaluate AI models also benefit from those evaluations.</span></p><p><span>These issues seem to be </span><a href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool" rel="">bad enough</a><span> that I encourage people to treat impressive results in AI-for-science the same way we treat surprising results in nutrition science: with </span><a href="https://www.theatlantic.com/magazine/archive/2023/05/ice-cream-bad-for-you-health-study/673487/" rel="">instinctive</a><span> </span><a href="https://www.cbsnews.com/news/how-the-chocolate-diet-hoax-fooled-millions/" rel="">skepticism</a><span>.</span></p></div></div></div></article></div></div></div><div><div id="discussion"><div><h4>Discussion about this post</h4></div></div></div></div>
  </body>
</html>
