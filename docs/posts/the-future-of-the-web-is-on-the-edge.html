<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://deno.com/blog/the-future-of-web-is-on-the-edge">Original</a>
    <h1>The Future of the Web Is on the Edge</h1>
    
    <div id="readability-page-1" class="page"><div><p>In the beginning, there was a single computer on a desk in a basement in
Switzerland. It had a red-inked label:</p>
<p><img src="https://deno.com/the-future-of-web-is-on-the-edge/this-machine-is-a-server.png" alt="This machine is a server. DO NOT POWER IT DOWN!!"/></p>
<p>32 years later, there are hundreds of millions of versions of that computer all
around the world. Some are even powered down by default.</p>
<p>But developing for the web still feels as if there is only one machine. We
develop as if our code is going to be deployed on a single instance of a server
somewhere in a huge data center in Virginia, California, or Switzerland.</p>
<p>But this doesn’t have to be the case anymore. For years, anything static was
served from CDNs around the globe, close to users. Now, the same is starting to
be true of dynamic web apps. You can deploy it all, everywhere.</p>
<h2 id="what-is-the-edge"><a aria-hidden="true" tabindex="-1" href="#what-is-the-edge"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What is the edge?</h2><p>When people say “the edge,” they mean that your site or app is going to be
hosted simultaneously on multiple servers around the globe, always close to a
user. When someone requests your site/app, they will be directed to the one
closest to them geographically. These distributed servers not only serve static
assets, but can also execute custom code that can power a dynamic web app.</p>
<p>Moving servers closer to end-users is also a physical approach towards latency
optimization. This means lower latency on every single page load. The longer
your pages take to load, the more likely users will bounce. 32% more likely
according to Google research when load speeds go from 1 second to 3 seconds. 90%
more likely when speeds go from 1 second to 5 seconds. Users will visit 9 pages
when pages load in 2 seconds, but only 3 pages when they load in 7 seconds.</p>
<p>That’s the gist. Now the nuance.</p>
<p>You’ve built an app. It’s cool. It does fun things. You want to show it to the
world, so you deploy it. For ease, you use Heroku. You <code>git push heroku main</code>
and then head to myfunapp.com to check out your handiwork.</p>
<p>By default, runtimes in Heroku are deployed in the AWS data center in northern
Virginia. This is great, for some people. For example, if you live mere miles
from the data farmlands of upstate Virginia. Pretty much any request you make
would be speedy as heck. But not everyone is lucky enough to live in the
vicinity of huge beige, windowless warehouses. As it turns out, some people live
in nice places.</p>
<p>Let’s look at the Time To First Byte (TTFB—how quickly the server responds with
the first byte of data) for an app hosted in Virginia for different locations
around the world:</p>
<table>
<thead>
<tr>
<th><strong>Location</strong></th>
<th><strong>Heroku TTFB</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Frankfurt</td>
<td>339.95ms</td>
</tr>
<tr>
<td>Amsterdam</td>
<td>382.62ms</td>
</tr>
<tr>
<td>London</td>
<td>338.09ms</td>
</tr>
<tr>
<td>New York</td>
<td>47.55ms</td>
</tr>
<tr>
<td>Dallas</td>
<td>144.64ms</td>
</tr>
<tr>
<td>San Francisco</td>
<td>302ms</td>
</tr>
<tr>
<td>Singapore</td>
<td>944.14ms</td>
</tr>
<tr>
<td>Sydney</td>
<td>889.85ms</td>
</tr>
<tr>
<td>Tokyo</td>
<td>672.49ms</td>
</tr>
<tr>
<td>Bangalore</td>
<td>984.39ms</td>
</tr>
</tbody></table>
<p>As they would say in Frankfurt, <em>nicht so gut</em>. Because every request has to
travel from these locations to the eastern United States and back again, the
further away a user is the longer they’re going to be waiting for their data.</p>
<p><img src="https://deno.com/the-future-of-web-is-on-the-edge/map-of-users-requesting-from-origin-server.png" alt="Map of users requesting from an origin server"/></p>
<p>Once you get to the other side of the world, it&#39;s taken almost one second to get
even the first byte back from the server, let alone all the data for that single
page. Add in all the pages on the site a user might want to visit, and you have
a very bad experience for anyone in Bangalore or Sydney (or, tbh, anyone not in
the eastern United States). You are losing pageviews, losing users, and losing
money.</p>
<p>Let’s retry our speed check on deno.com, which is deployed on Deno Deploy, our
edge network:</p>
<table>
<thead>
<tr>
<th><strong>Location</strong></th>
<th><strong>Heroku TTFB</strong></th>
<th><strong>Deno TTFB</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Frankfurt</td>
<td>339.95ms</td>
<td>28.45ms</td>
</tr>
<tr>
<td>Amsterdam</td>
<td>382.62ms</td>
<td>29.72ms</td>
</tr>
<tr>
<td>London</td>
<td>338.09ms</td>
<td>22.3ms</td>
</tr>
<tr>
<td>New York</td>
<td>47.55ms</td>
<td>41.29ms</td>
</tr>
<tr>
<td>Dallas</td>
<td>144.64ms</td>
<td>29.28ms</td>
</tr>
<tr>
<td>San Francisco</td>
<td>302ms</td>
<td>44.24ms</td>
</tr>
<tr>
<td>Singapore</td>
<td>944.14ms</td>
<td>528.57ms</td>
</tr>
<tr>
<td>Sydney</td>
<td>889.85ms</td>
<td>26.46ms</td>
</tr>
<tr>
<td>Tokyo</td>
<td>672.49ms</td>
<td>19.04ms</td>
</tr>
<tr>
<td>Bangalore</td>
<td>984.39ms</td>
<td>98.23ms</td>
</tr>
</tbody></table>
<p>Except Singapore, we’ve got a world of sub-100 millisecond TTFBs. This is
because instead of heading off to Virginia to get the site, each of these
locations can use an edge server nearest to them. The edge is about getting 50ms
response times vs 150ms response times. You can test this for yourself with a
VPN. If you:</p>
<pre><code>curl -I https://deno.land</code></pre><p>You’ll get the server nearest your location:</p>
<pre><code>server: deno/us-east4-a</code></pre><p>Using a VPN to route my request through a proxy server, We can see a response
from the nearest edge server to that location. Pretending we’re in Japan gives
us:</p>
<pre><code>server: deno/asia-northeast1-a</code></pre><p>Pretending we’re in Ireland gives us:</p>
<pre><code>server: deno/europe-west2-a</code></pre><p>And pretending we’re in Sydney, Australia gives us:</p>
<pre><code>server: deno/australia-southeast1-b</code></pre><p>Each time the request is routed to the best option.</p>
<p>The centralized server model worked and continues to work for a lot of
applications. But the scale of the web and the future of the web are fighting
against this model. Let’s go through how this architecture came to be and how
(and why) it’s changed over the years.</p>
<p><img src="https://deno.com/the-future-of-web-is-on-the-edge/timeline-history-of-the-edge.png" alt="The Timeline History of the Edge"/></p>
<p>Servers as a <em>concept</em> were introduced in a
<a href="https://www.rfc-editor.org/rfc/rfc5.html" rel="noopener noreferrer">1969 RFC from the Network Working Group</a>.
That NeXT machine in Tim Berners-Lee’s office was the first web server, but the
internet had already been rolling along for over 20 years by that point.</p>
<p><a href="https://www.reddit.com/r/pcmasterrace/comments/b086lz/tim_bernerslee_and_vint_cerf_wearing_funny_shirts/" rel="noopener noreferrer"><img src="https://deno.com/the-future-of-web-is-on-the-edge/tim-berners-lee-and-vint-cerf.jpg" alt="Tim Berners-Lee with Vint Cerf"/></a></p>
<p>The ‘69 RFC laid out the foundation for how to transmit and receive data between
a “server-host” and a user on ARPANET, the OG military-funded internet that
initially connected four universities in the western US. The server was up and
running by 1971 and a paper titled
<a href="https://dl.acm.org/doi/pdf/10.1145/800103.803337" rel="noopener noreferrer">“A Server Host System on the ARPANET”</a>
published in 1977 by Robert Braden at UCLA (one of the connections on ARPANET)
went into the details of that initial setup:</p>
<blockquote>
<p>This paper describes the design of host software extensions which allow a
large-scale machine running a widely-used operating system to provide service
to the ARPANET. This software has enabled the host, an IBM 360/91 at UCLA, to
provide production computing services to ARPANET users since 1971.</p>
</blockquote>
<p>This is the first <em>internet</em> server: an
<a href="https://en.wikipedia.org/wiki/IBM_System/360_Model_91" rel="noopener noreferrer">IBM 360/91</a>. The
hardware and software have changed, and you no longer roll your own, but
fundamentally this is still how the internet works today: servers providing a
service.</p>
<h2 id="caching-content-close-to-users"><a aria-hidden="true" tabindex="-1" href="#caching-content-close-to-users"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Caching content close to users</h2><p>This architecture has worked well for a long time. But by the late 90s and early
2000s, when the web started to become huge, cracks were starting to appear.</p>
<p>The first was what Akamai, when they launched the first Content Delivery Network
(CDN) in 1998, called “hot spots.” Basically, servers crashing from too much
traffic through popularity, or early
<a href="https://www.senki.org/ddos-attack-preparation-workbook/history-of-denial-of-services-dos-attacks/" rel="noopener noreferrer">DDoS attacks</a>
from <a href="https://www.youtube.com/watch?v=IESEcsjDcmM" rel="noopener noreferrer">90s hackers</a>.</p>
<p>Akamai’s CDN cached content in a distributed system of servers. A request was
routed to the nearest of these servers. However, these are limited to static
files: the HTML and CSS of your site, or images, videos, or other content on it.
Anything dynamic still had to be handled by your core server.</p>
<p>CDNs continue to be a core piece of kit for the modern web. Most static files
are cached somewhere. The first time you visit a website you might pull the
HTML, CSS, or images straight from the origin server, but then they will be
cached on a node close to you, so you (and others in your area of the network)
will be served the cached content thereafter.</p>
<h2 id="less-servers-more-serverless"><a aria-hidden="true" tabindex="-1" href="#less-servers-more-serverless"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Less servers, more serverless</h2><p>Servers also have problems in the opposite direction to overloading:
under-utility. A server, like Tim Berners-Lee’s machine that cannot be “powered
down”, has to be up 100% of the time. Even if your app gets one visit for ten
seconds a day, you still pay for the other 86,390.</p>
<p>Serverless mitigates this problem. They can be spooled up and powered down at
will. “Serverless” is a misnomer–a server is still involved. But you don’t have
a dedicated server that is up all the time. Instead, the server is event-driven,
only coming to life when a request is made.</p>
<p>Though there were earlier versions, AWS Lambda was the first serverless
framework that saw widespread use.</p>
<p><a href="https://aws.amazon.com/lambda/" rel="noopener noreferrer"><img src="https://deno.com/the-future-of-web-is-on-the-edge/diagram-of-aws-lambda.png" alt="Diagram of AWS Lambda"/></a></p>
<p>The benefits of serverless are two-fold:</p>
<ol>
<li>You only pay for what you use—just those 10 seconds if that’s all that’s
happening on your app.</li>
<li>You don’t have to worry about all the DevOps side of servers. No planning, no
management, no maintenance.</li>
</ol>
<p>The downsides mostly come with performance. You have a “cold start” problem with
serverless functions, where the resources have to be provisioned each time,
adding to latencies. And, the servers of serverless are still centralized, so
you still have a long round-trip.</p>
<p>So we come to the present. Servers aren’t dying, but are far away and can fall
over; CDNs cache your content close to users, but only the static stuff; and
serverless means less DevOps and (potentially) lower costs, but higher latencies
from cold starts.</p>
<h2 id="livin-on-the-edge"><a aria-hidden="true" tabindex="-1" href="#livin-on-the-edge"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Livin’ on the edge</h2><p>The beauty of the edge is that it is taking the best part of CDNs (being close
to users) and the best part of serverless (running functions) and marrying them
together.</p>
<p><img src="https://deno.com/the-future-of-web-is-on-the-edge/cdn-and-serverless.png" alt="CDNs + Serverless = The Edge"/></p>
<p>With the edge, you can execute custom code close to users. This has a ton of
benefits.</p>
<h2 id="better-performance"><a aria-hidden="true" tabindex="-1" href="#better-performance"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Better performance</h2><p>This is the only thing your users care about. Does your website load fast, does
it hang, is it frustrating to use?</p>
<p>As a site or app is served from an edge server near them, it’s going to be
faster than if on a centralized server.</p>
<p><img src="https://deno.com/the-future-of-web-is-on-the-edge/map-of-users-requesting-from-edge-server.png" alt="Map of users requesting from an edge server"/></p>
<p>But the performance benefits don’t end there. As compute is performed on the
edge, not by the user’s browser:</p>
<ol>
<li>The app is less resource-intensive on the end user’s machine, so less use of
CPU and memory and less chance of browser hangs.</li>
<li>Smaller payloads are sent to the end user, so less bandwidth is used.</li>
<li>As functions are run in a controlled environment, there is consistent
behavior of functions and APIs.</li>
</ol>
<h2 id="better-security"><a aria-hidden="true" tabindex="-1" href="#better-security"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Better security</h2><p>Moving computation from the client/device to the serverless edge also reduces
potential vectors of attack on your app. In
<a href="https://www.youtube.com/watch?v=G_2AgdgEbkI" rel="noopener noreferrer">the words</a> of Kitson Kelly, DX
Engineering Lead at Deno, “that means you immediately decrease the amount of
surface area that you expose to your end users.” He says (abbreviated for
clarity):</p>
<blockquote>
<p>Your device doesn’t have to make API calls to your backend services. I think
all of us had to defend against that. But if you take the compute off the
device and all you are sending is HTML and CSS, well, you’ve eliminated that
problem. The only thing that gets off your network is the stuff you want to
render to the customer.</p>
</blockquote>
<p>In addition, DDoS attacks are more difficult. Any attacker isn’t taking down one
server, they need to take down dozens, hundereds, maybe thousands across the
globe. Even if they succeed in taking 10 servers offline, there might still be
20 available servers that traffic can be rerouted to.</p>
<h2 id="better-developer-experience"><a aria-hidden="true" tabindex="-1" href="#better-developer-experience"><svg viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Better developer experience</h2><p>Right now, writing code for the edge is trickier than it needs to be. For the
most part, this is due to the hybrid nature of edge development. Most frameworks
that implement it aren’t edge-first, so developers must pick and choose whether
any given function or page is server-side rendered on the edge or rendered in
the browser.</p>
<p>This makes edge development more complex. But newer frameworks, such as
<a href="https://fresh.deno.dev/" rel="noopener noreferrer">Fresh</a>, which delivers zero JavaScript to the client
by default, simplifies optimizing for the edge by embracing server-side
rendering and islands architecture. Developers using Fresh with our globally
distributed JavaScript serverless edge network, Deno Deploy, can reap the
benefits of edge and latency optimization, such as
<a href="https://deno.com/blog/ecommerce-with-perfect-lighthouse-score" rel="noopener noreferrer">achieving a perfect Lighthouse score</a>.</p>
<p>The edge is the next iteration of the internet. From the IBM 360/91 to
Berners-Lee’s NeXT machine to Akamai’s CDNs to Amazon’s data farms to serverless
to the edge. Each stage has built on the last, learning lessons and fixing
mistakes. The edge is the next stage of making the web a faster, more secure
place for users and developers.</p>
<p><a href="https://deno.com/deploy" rel="noopener noreferrer"><em>Deploy to the edge globally in seconds with Fresh and Deno Deploy today.</em></a></p>
</div></div>
  </body>
</html>
