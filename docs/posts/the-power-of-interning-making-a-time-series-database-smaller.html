<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gendignoux.com/blog/2025/03/03/rust-interning-2000x.html">Original</a>
    <h1>The power of interning: making a time series database smaller</h1>
    
    <div id="readability-page-1" class="page"><article>
    <header>
        
        <p>
            <a href="https://writing.natwelch.com/blog/tags.html#rust"><i aria-hidden="true"></i> rust</a><a href="https://writing.natwelch.com/blog/tags.html#perf"><i aria-hidden="true"></i> perf</a><a href="https://writing.natwelch.com/blog/tags.html#json"><i aria-hidden="true"></i> json</a>
        </p>
        <p>March 3, 2025</p>
        <p>by <span>Guillaume Endignoux</span>
        </p>
    </header>
    <section>
        <p>This week-end project started by browsing the <a href="https://prim.iledefrance-mobilites.fr/en">open-data repository</a> of Paris’ public transport network, which contains <a href="https://prim.iledefrance-mobilites.fr/en/catalogue-data?type=api">various APIs</a> to query <a href="https://prim.iledefrance-mobilites.fr/en/apis/idfm-ivtr-requete_globale">real-time departures</a>, <a href="https://prim.iledefrance-mobilites.fr/en/apis/idfm-disruptions_bulk">current disruptions</a>, etc.
The <a href="https://prim.iledefrance-mobilites.fr/en/reutilisations">data reuse section</a> caught my eye, as it features external projects that use this open data.
In particular, the <a href="https://ratpstatus.fr/">RATP status website</a> provides a really nice interface to visualize historical disruptions on metro, RER/train and tramway lines.</p>

<!--more-->

<p><a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/ratp-status-2025-01-28.aUIZIqVMnogK.png"><img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/ratp-status-2025-01-28.BnEKVNacK-tC.webp" width="2559" height="1251" loading="lazy" alt="Screenshot of the RATP status website"/></a>
A usual day of disruptions on <a href="https://ratpstatus.fr/">ratpstatus.fr</a>.</p>

<p>Under the hood, the <a href="https://github.com/wincelau/ratpstatus">ratpstatus.fr GitHub repository</a> contains <a href="https://github.com/wincelau/ratpstatus/tree/main/datas">all the JSON files</a> queried from the open-data API, every 2 minutes for almost a year now.
A repository with 188K commits and more than 10 GB of accumulated data at the last commit alone (as measured by <code>git clone --depth=1</code>) is definitely an interesting database choice!
To be clear, this post isn’t in any way a critique of that.
RATP status is an excellent website providing useful information that runs blazingly fast<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup> and smoothly without the usual bloat you see on the web nowadays.</p>

<p>Nonetheless, the 10 GB of data got me to wonder: can we compress that better, by spending a reasonable amount of time (i.e. a week-end project)?
In this deep dive post, I’ll explain how I used the <a href="https://en.wikipedia.org/wiki/Interning_(computer_science)"><em>interning</em> design pattern</a> in Rust to compress this data set by a factor of two thousand!
We’ll investigate how to best structure the interner itself, how to tune our data schema to work well with it, and likewise how serialization can best leverage interning.</p>

<p>If you’ve got lots of JSON files accumulating in your storage, you should read on!</p>

<hr/>

<ul id="markdown-toc">
  <li><a href="#importing-the-data-135" id="markdown-toc-importing-the-data-135">Importing the data (135%)</a></li>
  <li><a href="#interning" id="markdown-toc-interning">Interning</a>    <ul>
      <li><a href="#strings-47" id="markdown-toc-strings-47">Strings (47%)</a></li>
      <li><a href="#arbitrary-types-76" id="markdown-toc-arbitrary-types-76">Arbitrary types (7.6%)</a></li>
      <li><a href="#dropping-the-reference-28" id="markdown-toc-dropping-the-reference-28">Dropping the reference (2.8%)</a></li>
    </ul>
  </li>
  <li><a href="#tuning-the-schema" id="markdown-toc-tuning-the-schema">Tuning the schema</a>    <ul>
      <li><a href="#sorting-sets-15" id="markdown-toc-sorting-sets-15">Sorting sets (1.5%)</a></li>
      <li><a href="#using-enums-14" id="markdown-toc-using-enums-14">Using enums (1.4%)</a></li>
      <li><a href="#splitting-structs-082" id="markdown-toc-splitting-structs-082">Splitting structs (0.82%)</a></li>
      <li><a href="#specializing-types-064" id="markdown-toc-specializing-types-064">Specializing types (0.64%)</a></li>
    </ul>
  </li>
  <li><a href="#serialization" id="markdown-toc-serialization">Serialization</a>    <ul>
      <li><a href="#writing-custom-deserializers-with-serde-029" id="markdown-toc-writing-custom-deserializers-with-serde-029">Writing custom (de)serializers with Serde (0.29%)</a></li>
      <li><a href="#compression-and-fighting-the-rust-borrow-checker-linux-pipes-005" id="markdown-toc-compression-and-fighting-the-rust-borrow-checker-linux-pipes-005">Compression and fighting <del>the Rust borrow checker</del> Linux pipes (0.05%)</a></li>
      <li><a href="#tuple-encoding" id="markdown-toc-tuple-encoding">Tuple encoding</a></li>
      <li><a href="#optimizing-sets-revisited" id="markdown-toc-optimizing-sets-revisited">Optimizing sets revisited</a></li>
    </ul>
  </li>
  <li><a href="#final-result-a-lightweight-append-only-database" id="markdown-toc-final-result-a-lightweight-append-only-database">Final result: a lightweight append-only database</a></li>
</ul>

<h2 id="importing-the-data-135"><span><a href="#importing-the-data-135"><i aria-hidden="true"></i></a></span>Importing the data (135%)</h2>

<p>The first step of this experiment was to import the source data.
To give a bit more context, each data point was a JSON file with many entries looking like this.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>&#34;disruptions&#34;</span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>&#34;id&#34;</span><span>:</span><span> </span><span>&#34;445a6032-d1ca-11ef-b3f5-0a58a9feac02&#34;</span><span>,</span><span>
      </span><span>&#34;applicationPeriods&#34;</span><span>:</span><span> </span><span>[</span><span>
        </span><span>{</span><span>
          </span><span>&#34;begin&#34;</span><span>:</span><span> </span><span>&#34;20250113T180000&#34;</span><span>,</span><span>
          </span><span>&#34;end&#34;</span><span>:</span><span> </span><span>&#34;20250228T230000&#34;</span><span>
        </span><span>}</span><span>
      </span><span>],</span><span>
      </span><span>&#34;lastUpdate&#34;</span><span>:</span><span> </span><span>&#34;20250113T172013&#34;</span><span>,</span><span>
      </span><span>&#34;cause&#34;</span><span>:</span><span> </span><span>&#34;PERTURBATION&#34;</span><span>,</span><span>
      </span><span>&#34;severity&#34;</span><span>:</span><span> </span><span>&#34;BLOQUANTE&#34;</span><span>,</span><span>
      </span><span>&#34;title&#34;</span><span>:</span><span> </span><span>&#34;Activities in Aincourt&#34;</span><span>,</span><span>
      </span><span>&#34;message&#34;</span><span>:</span><span> </span><span>&#34;&lt;p&gt;Due to work in Aincourt, the Centre and Eglise stops will not be served in both directions of traffic on line 95 15 and in the direction of Magny en Vexin Gare Routière only on line 95 44. &lt;br&gt;From 13/01 until further notice. &lt;/p&gt;&lt;br&gt;Please refer to Les Cadenas stops&#34;</span><span>
    </span><span>},</span><span>
  </span><span>...</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Let’s import this data into our program!
If you’re not familiar with <a href="https://www.rust-lang.org/">Rust</a>, this programming language makes it very easy to deserialize data from all sorts of formats via libraries like <a href="https://docs.rs/serde/"><code>serde</code></a> and <a href="https://docs.rs/serde_json/"><code>serde_json</code></a>.
I’m depending on the following versions in my <a href="https://doc.rust-lang.org/cargo/reference/manifest.html"><code>Cargo.toml</code> manifest</a>.</p>

<div><div><pre><code><span>[dependencies]</span>
<span>serde</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>&#34;1.0.217&#34;</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>&#34;derive&#34;</span><span>]</span> <span>}</span>
<span>serde_json</span> <span>=</span> <span>&#34;1.0.137&#34;</span>
</code></pre></div></div>

<p>With that, we can define a data schema as regular Rust structs/enums and simply annotate them with <code>serde</code>’s <a href="https://docs.rs/serde/1.0.217/serde/derive.Deserialize.html"><code>Deserialize</code> derive macro</a> to automatically implement deserialization for it.
I recommend using the <a href="https://serde.rs/container-attrs.html#deny_unknown_fields"><code>deny_unknown_fields</code> attribute</a> to make sure unknown JSON fields aren’t silently ignored.
These attributes are documented separately on the <a href="https://serde.rs/attributes.html">serde.rs website</a> (not on <a href="https://docs.rs/serde/">docs.rs</a>).</p>

<div><div><pre><code><span>use</span> <span>serde</span><span>::</span><span>Deserialize</span><span>;</span>

<span>#[derive(Debug,</span> <span>Deserialize)]</span>
<span>#[serde(deny_unknown_fields)]</span>
<span>struct</span> <span>Data</span> <span>{</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;statusCode&#34;</span><span>)]</span>
    <span>status_code</span><span>:</span> <span>Option</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>,</span>
    <span>error</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>message</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>disruptions</span><span>:</span> <span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>Disruption</span><span>&gt;&gt;</span><span>,</span>
    <span>lines</span><span>:</span> <span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>Line</span><span>&gt;&gt;</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;lastUpdatedDate&#34;</span><span>)]</span>
    <span>last_updated_date</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>One can then trivially deserialize a JSON file into a <code>Data</code> struct with functions like <a href="https://docs.rs/serde_json/1.0.137/serde_json/fn.from_reader.html"><code>serde_json::from_reader()</code></a>.</p>

<div><div><pre><code><span>// Open a file for reading.</span>
<span>let</span> <span>file</span> <span>=</span> <span>File</span><span>::</span><span>open</span><span>(</span><span>path</span><span>)</span><span>?</span><span>;</span>
<span>// Add a layer of buffering for performance.</span>
<span>let</span> <span>reader</span> <span>=</span> <span>BufReader</span><span>::</span><span>new</span><span>(</span><span>file</span><span>);</span>
<span>// Deserialize the JSON contents into a Data.</span>
<span>let</span> <span>data</span><span>:</span> <span>Data</span> <span>=</span> <span>serde_json</span><span>::</span><span>from_reader</span><span>(</span><span>reader</span><span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>To give more details about the specific data schema I’m importing, each <code>Disruption</code> contains informative fields, as well as a list of time periods during which it applies.
For example, there may be construction work on a line every evening for a month, so there would be an <code>ApplicationPeriod</code> for each of these evenings.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Deserialize)]</span>
<span>#[serde(deny_unknown_fields)]</span>
<span>struct</span> <span>Disruption</span> <span>{</span>
    <span>id</span><span>:</span> <span>String</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;applicationPeriods&#34;</span><span>)]</span>
    <span>application_periods</span><span>:</span> <span>Vec</span><span>&lt;</span><span>ApplicationPeriod</span><span>&gt;</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;lastUpdate&#34;</span><span>)]</span>
    <span>last_update</span><span>:</span> <span>String</span><span>,</span>
    <span>cause</span><span>:</span> <span>String</span><span>,</span>
    <span>severity</span><span>:</span> <span>String</span><span>,</span>
    <span>tags</span><span>:</span> <span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>String</span><span>&gt;&gt;</span><span>,</span>
    <span>title</span><span>:</span> <span>String</span><span>,</span>
    <span>message</span><span>:</span> <span>String</span><span>,</span>
    <span>disruption_id</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Deserialize)]</span>
<span>#[serde(deny_unknown_fields)]</span>
<span>struct</span> <span>ApplicationPeriod</span> <span>{</span>
    <span>begin</span><span>:</span> <span>String</span><span>,</span>
    <span>end</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>The data also contains an index by <code>Line</code>s, listing all the objects (e.g. stations) impacted by disruptions on each metro line.</p>

<div id="schema-line"><div><pre><code><span>#[derive(Debug,</span> <span>Deserialize)]</span>
<span>#[serde(deny_unknown_fields)]</span>
<span>struct</span> <span>Line</span> <span>{</span>
    <span>id</span><span>:</span> <span>String</span><span>,</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;shortName&#34;</span><span>)]</span>
    <span>short_name</span><span>:</span> <span>String</span><span>,</span>
    <span>mode</span><span>:</span> <span>String</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;networkId&#34;</span><span>)]</span>
    <span>network_id</span><span>:</span> <span>String</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;impactedObjects&#34;</span><span>)]</span>
    <span>impacted_objects</span><span>:</span> <span>Vec</span><span>&lt;</span><span>ImpactedObject</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Deserialize)]</span>
<span>#[serde(deny_unknown_fields)]</span>
<span>struct</span> <span>ImpactedObject</span> <span>{</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;type&#34;</span><span>)]</span>
    <span>typ</span><span>:</span> <span>String</span><span>,</span>
    <span>id</span><span>:</span> <span>String</span><span>,</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>#[serde(rename</span> <span>=</span> <span>&#34;disruptionIds&#34;</span><span>)]</span>
    <span>disruption_ids</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Lastly, I wanted to estimate how much space these objects take in memory, in order to benchmark the improvements obtained by interning methods.
Rust’s <a href="https://doc.rust-lang.org/std/mem/fn.size_of.html"><code>std::mem::size_of()</code> function</a> returns the “stack” size of an object, but that’s not sufficient as it ignores any data indirectly allocated on the heap (such as via a <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a> collection).
Therefore, I defined a new trait and implemented it for the needed types.</p>

<div><div><pre><code><span>trait</span> <span>EstimateSize</span><span>:</span> <span>Sized</span> <span>{</span>
    <span>/// Returns the number of bytes indirectly allocated on the heap by this object.</span>
    <span>fn</span> <span>allocated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span><span>;</span>

    <span>/// Returns the total number of bytes that this object uses.</span>
    <span>fn</span> <span>estimated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>std</span><span>::</span><span>mem</span><span>::</span><span>size_of</span><span>::</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>()</span> <span>+</span> <span>self</span><span>.allocated_bytes</span><span>()</span>
    <span>}</span>
<span>}</span>

<span>impl</span> <span>EstimateSize</span> <span>for</span> <span>i32</span> <span>{</span>
    <span>fn</span> <span>allocated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>0</span>  <span>// Nothing allocated on the heap.</span>
    <span>}</span>
<span>}</span>

<span>impl</span> <span>EstimateSize</span> <span>for</span> <span>String</span> <span>{</span>
    <span>fn</span> <span>allocated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>self</span><span>.len</span><span>()</span>  <span>// Each item is one byte long. Ignores the string capacity.</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>EstimateSize</span><span>&gt;</span> <span>EstimateSize</span> <span>for</span> <span>Vec</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>allocated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>// Recursively sum each item&#39;s total size.</span>
        <span>self</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>x</span><span>|</span> <span>x</span><span>.estimated_bytes</span><span>())</span><span>.sum</span><span>()</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>For compound types (structs), the implementation visits all the fields.
In principle, this could automatically be implemented by a <a href="https://doc.rust-lang.org/reference/procedural-macros.html#derive-macros">derive macro</a> (like serde’s <code>Deserialize</code>), but creating a new macro seemed overkill given the scale of my experiment.</p>

<div><div><pre><code><span>impl</span> <span>EstimateSize</span> <span>for</span> <span>Data</span> <span>{</span>
    <span>fn</span> <span>allocated_bytes</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>self</span><span>.status_code</span><span>.allocated_bytes</span><span>()</span>
            <span>+</span> <span>self</span><span>.error</span><span>.allocated_bytes</span><span>()</span>
            <span>+</span> <span>self</span><span>.message</span><span>.allocated_bytes</span><span>()</span>
            <span>+</span> <span>self</span><span>.disruptions</span><span>.allocated_bytes</span><span>()</span>
            <span>+</span> <span>self</span><span>.lines</span><span>.allocated_bytes</span><span>()</span>
            <span>+</span> <span>self</span><span>.last_updated_date</span><span>.allocated_bytes</span><span>()</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>With that, reading all the files from May 2024 gave the following result: expanding the 1.1 GB of JSON files into in-memory structs increased the size by 35% (commit <a href="https://github.com/gendx/rust-interning/commit/d961e6e5f0cce53c2b328a7fd70482811e80f26e">d961e6e</a>).
Not in the right direction… let’s start optimizing!</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
</code></pre></div></div>

<h2 id="interning"><span><a href="#interning"><i aria-hidden="true"></i></a></span>Interning</h2>

<p>In this section, I’ll present the basics of the interning pattern, and how to apply it to various types.</p>

<h3 id="strings-47"><span><a href="#strings-47"><i aria-hidden="true"></i></a></span>Strings (47%)</h3>

<p>The first use case that comes to mind in terms of interning is strings, as evidenced by the <a href="https://lib.rs/keywords/interning">top Rust interning libraries</a>.
We’re not going to use any of these packages, as my goal was to learn more about the inner details of interning.</p>

<p>I stumbled upon a blog post by <em>matklad</em> from 2020 titled <a href="https://matklad.github.io/2020/03/22/fast-simple-rust-interner.html"><em>Fast and Simple Rust Interner</em></a>, and my first iteration is inspired by this design.
The main difference is that I wrapped strings into an <a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a> (reference-counted wrapper) to avoid duplicating them in memory.
If the interner is intended to be used from multiple threads, I’d use an <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>Arc</code></a> instead, but I’m keeping things simple for this experiment.</p>

<p>So what is an interner?
It’s essentially a table of strings, consisting of a vector of strings paired with a hash map that allows looking up if a string is already in the database, and if so at which index in the vector.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>collections</span><span>::</span><span>HashMap</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>rc</span><span>::</span><span>Rc</span><span>;</span>

<span>#[derive(Default)]</span>
<span>struct</span> <span>StringInternerImpl</span> <span>{</span>
    <span>vec</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>String</span><span>&gt;&gt;</span><span>,</span>
    <span>map</span><span>:</span> <span>HashMap</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span> <span>usize</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span> <span>StringInternerImpl</span> <span>{</span>
    <span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>value</span><span>:</span> <span>String</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>&amp;</span><span>id</span><span>)</span> <span>=</span> <span>self</span><span>.map</span><span>.get</span><span>(</span><span>&amp;</span><span>value</span><span>)</span> <span>{</span>
            <span>return</span> <span>id</span><span>;</span>
        <span>}</span>

        <span>let</span> <span>id</span> <span>=</span> <span>self</span><span>.vec</span><span>.len</span><span>();</span>
        <span>let</span> <span>rc</span><span>:</span> <span>Rc</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>=</span> <span>Rc</span><span>::</span><span>new</span><span>(</span><span>value</span><span>);</span>
        <span>self</span><span>.vec</span><span>.push</span><span>(</span><span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>rc</span><span>));</span>
        <span>self</span><span>.map</span><span>.insert</span><span>(</span><span>rc</span><span>,</span> <span>id</span><span>);</span>
        <span>id</span>
    <span>}</span>

    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>id</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
        <span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>self</span><span>.vec</span><span>[</span><span>id</span><span>])</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>An interned string is then an index in the interner table.
The main advantage of this setup is to reduce the amount of memory used by the program, because an integer index is usually smaller than the full string.
This is especially effective when there are many repeated strings.</p>

<p><a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/string-interning.lrRCNfxir2Qy.svg"><img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/string-interning.lrRCNfxir2Qy.svg" width="744" height="440" loading="lazy" alt="Memory layout of strings without and with interning"/></a>
Memory layout of strings without and with interning.</p>

<p>There are several possible designs to represent an interned string object: as a first iteration I’ve chosen to pair the index with a reference to the interner that contains it.</p>

<div><div><pre><code><span>struct</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>StringInterner</span><span>,</span>
    <span>id</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>from</span><span>(</span><span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>StringInterner</span><span>,</span> <span>value</span><span>:</span> <span>String</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>let</span> <span>id</span> <span>=</span> <span>interner</span><span>.intern</span><span>(</span><span>value</span><span>);</span>
        <span>Self</span> <span>{</span> <span>interner</span><span>,</span> <span>id</span> <span>}</span>
    <span>}</span>

    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.interner</span><span>.lookup</span><span>(</span><span>self</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>At this point, you might have noticed that I’ve declared <code>StringInterner</code> and <code>StringInternerImpl</code> types.
What’s the difference?</p>

<p>The answer is that once an <code>IString</code> captures an interner handle <code>&amp;StringInterner</code>, the underlying <code>StringInterner</code> cannot be mutated anymore via an <code>intern()</code> function taking a <code>&amp;mut self</code> parameter, as it would break <a href="https://doc.rust-lang.org/rust-by-example/scope/borrow/alias.html">Rust’s aliasing rules</a>: there cannot be both a <code>&amp;StringInterner</code> and a <code>&amp;mut StringInterner</code> pointing to the same thing at the same time.
This is quite unfortunate, as it prevents interning more than one string!</p>

<p>The way to resolve this conflict is to use <a href="https://doc.rust-lang.org/reference/interior-mutability.html"><em>interior mutability</em></a> via the <a href="https://doc.rust-lang.org/std/cell/struct.RefCell.html"><code>RefCell</code> type</a>.
By defining a <code>StringInterner</code> as a <code>RefCell&lt;StringInternerImpl&gt;</code>, we can intern more values without needing a <code>&amp;mut self</code> reference to the interner.</p>

<div><div><pre><code><span>#[derive(Default)]</span>
<span>struct</span> <span>StringInterner</span> <span>{</span>
    <span>inner</span><span>:</span> <span>RefCell</span><span>&lt;</span><span>StringInternerImpl</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span> <span>StringInterner</span> <span>{</span>
    <span>// This function takes an immutable reference!</span>
    <span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>value</span><span>:</span> <span>String</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
        <span>// The borrow_mut() method performs runtime checks and releases a</span>
        <span>// mutable reference if it&#39;s safe to do so (or panics).</span>
        <span>self</span><span>.inner</span><span>.borrow_mut</span><span>()</span><span>.intern</span><span>(</span><span>value</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>id</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.inner</span><span>.borrow</span><span>()</span><span>.lookup</span><span>(</span><span>id</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>With this setup, we can for example overload the comparison operator <code>==</code> to directly compare interned strings with regular strings.</p>

<div><div><pre><code><span>impl</span> <span>PartialEq</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>for</span> <span>IString</span><span>&lt;</span><span>&#39;_</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>String</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.lookup</span><span>()</span><span>.deref</span><span>()</span> <span>==</span> <span>other</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Lastly, I’ve defined new structs for the data schema using the interned string type in place of all strings.
This means adding a lifetime <code>&#39;a</code> everywhere, which isn’t quite ergonomic, but we’ll revisit this pattern <a href="#dropping-the-reference-28">later</a>.</p>

<div><div><pre><code><span>struct</span> <span>Disruption</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>application_periods</span><span>:</span> <span>Vec</span><span>&lt;</span><span>ApplicationPeriod</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
    <span>last_update</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>cause</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>severity</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>tags</span><span>:</span> <span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;&gt;</span><span>,</span>
    <span>title</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>message</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>disruption_id</span><span>:</span> <span>Option</span><span>&lt;</span><span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> <span>ApplicationPeriod</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>begin</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>end</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>I’ve also defined functions to convert data from the original structs to their interned counterparts, as well as comparison functions to validate that the interned data is semantically equivalent to the original (and confirm that my benchmarks are not cheating).</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>ApplicationPeriod</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>from</span><span>(</span><span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>StringInterner</span><span>,</span> <span>source</span><span>:</span> <span>source</span><span>::</span><span>ApplicationPeriod</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>Self</span> <span>{</span>
            <span>begin</span><span>:</span> <span>IString</span><span>::</span><span>from</span><span>(</span><span>interner</span><span>,</span> <span>source</span><span>.begin</span><span>),</span>
            <span>end</span><span>:</span> <span>IString</span><span>::</span><span>from</span><span>(</span><span>interner</span><span>,</span> <span>source</span><span>.end</span><span>),</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>impl</span> <span>PartialEq</span><span>&lt;</span><span>source</span><span>::</span><span>ApplicationPeriod</span><span>&gt;</span> <span>for</span> <span>ApplicationPeriod</span><span>&lt;</span><span>&#39;_</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>source</span><span>::</span><span>ApplicationPeriod</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.begin</span> <span>==</span> <span>other</span><span>.begin</span> <span>&amp;&amp;</span> <span>self</span><span>.end</span> <span>==</span> <span>other</span><span>.end</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>With that, we can already see the effectiveness of interning: each string appeared on average 425 times in the input data, the in-memory data is three times smaller than the baseline, and twice smaller than the original JSON files (commit <a href="https://github.com/gendx/rust-interning/commit/5297faabef807c535bba8c29ca665c72957f3ca0">5297faa</a>).
We’re still quite far from the headline of this post though!</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 529308335 bytes (relative size = 46.55%)
- [0.84%] String interner: 56374 objects | 4433343 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
</code></pre></div></div>

<h3 id="arbitrary-types-76"><span><a href="#arbitrary-types-76"><i aria-hidden="true"></i></a></span>Arbitrary types (7.6%)</h3>

<p>The next step was to realize that strings aren’t the only objects that repeat a lot in the input data.
For example, a <code>Disruption</code> may last maybe an hour if it’s unexpected, or something like a month if it’s planned maintenance work.
Given that the input data is a time series sampled every 2 minutes, it’s expected that a given disruption will show up many times.</p>

<p>Fortunately, the interning technique isn’t unique to strings: any data that can be put into a vector and a hash map should work as well.
So we can use <a href="https://doc.rust-lang.org/rust-by-example/generics.html">generics</a> to make it work for arbitrary types that implement <a href="https://doc.rust-lang.org/std/cmp/trait.Eq.html"><code>Eq</code></a> and <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> (to work with a hash map).</p>

<div><div><pre><code><span>// Type alias for convenience.</span>
<span>type</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>=</span> <span>Interned</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>String</span><span>&gt;</span><span>;</span>

<span>struct</span> <span>Interned</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span>
    <span>id</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Interned</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>from</span><span>(</span><span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span> <span>value</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>let</span> <span>id</span> <span>=</span> <span>interner</span><span>.intern</span><span>(</span><span>value</span><span>);</span>
        <span>Self</span> <span>{</span> <span>interner</span><span>,</span> <span>id</span> <span>}</span>
    <span>}</span>

    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.interner</span><span>.lookup</span><span>(</span><span>self</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As a new requirement, we also need to implement the <a href="https://doc.rust-lang.org/std/cmp/trait.PartialEq.html"><code>PartialEq</code></a>, <a href="https://doc.rust-lang.org/std/cmp/trait.Eq.html"><code>Eq</code></a> and <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> traits on <code>Interned&lt;_&gt;</code>, so that it can be recursively used in structs that are themselves interned.
A naive implementation is to lookup the actual data and compare or hash it, but we’ll revisit that in a moment.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>hash</span><span>::{</span><span>Hash</span><span>,</span> <span>Hasher</span><span>};</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>PartialEq</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>&#39;_</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>Self</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.lookup</span><span>()</span><span>.deref</span><span>()</span> <span>==</span> <span>other</span><span>.lookup</span><span>()</span><span>.deref</span><span>()</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Eq</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>&#39;_</span><span>,</span> <span>T</span><span>&gt;</span> <span>{}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Hash</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>&#39;_</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>hash</span><span>&lt;</span><span>H</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>state</span><span>:</span> <span>&amp;</span><span>mut</span> <span>H</span><span>)</span>
    <span>where</span>
        <span>H</span><span>:</span> <span>Hasher</span><span>,</span>
    <span>{</span>
        <span>self</span><span>.lookup</span><span>()</span><span>.deref</span><span>()</span><span>.hash</span><span>(</span><span>state</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>On the schema side, we’ll now have a collection of interners: each type gets its own interner.</p>

<div><div><pre><code><span>#[derive(Default)]</span>
<span>struct</span> <span>Interners</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>string</span><span>:</span> <span>Interner</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>disruption</span><span>:</span> <span>Interner</span><span>&lt;</span><span>Disruption</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
    <span>line</span><span>:</span> <span>Interner</span><span>&lt;</span><span>Line</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
    <span>application_period</span><span>:</span> <span>Interner</span><span>&lt;</span><span>ApplicationPeriod</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
    <span>impacted_object</span><span>:</span> <span>Interner</span><span>&lt;</span><span>ImpactedObject</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>The data structs in the schema can now contain interned versions of other structs, such as <code>Interned&lt;&#39;a, ApplicationPeriod&lt;&#39;a&gt;&gt;</code>, and simply derive the comparison and hashing traits.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Hash,</span> <span>PartialEq,</span> <span>Eq)]</span>
<span>struct</span> <span>Disruption</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>application_periods</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Interned</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>ApplicationPeriod</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;&gt;</span><span>,</span>
    <span>last_update</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>cause</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>severity</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>tags</span><span>:</span> <span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;&gt;</span><span>,</span>
    <span>title</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>message</span><span>:</span> <span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span>
    <span>disruption_id</span><span>:</span> <span>Option</span><span>&lt;</span><span>IString</span><span>&lt;</span><span>&#39;a</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Conversion from the original data types now uses a reference to the whole collection of <code>Interners</code>.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>Disruption</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>from</span><span>(</span><span>interners</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>Interners</span><span>&lt;</span><span>&#39;a</span><span>&gt;</span><span>,</span> <span>source</span><span>:</span> <span>source</span><span>::</span><span>Disruption</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>Self</span> <span>{</span>
            <span>id</span><span>:</span> <span>Interned</span><span>::</span><span>from</span><span>(</span><span>&amp;</span><span>interners</span><span>.string</span><span>,</span> <span>source</span><span>.id</span><span>),</span>
            <span>application_periods</span><span>:</span> <span>source</span>
                <span>.application_periods</span>
                <span>.into_iter</span><span>()</span>
                <span>.map</span><span>(|</span><span>x</span><span>|</span> <span>{</span>
                    <span>Interned</span><span>::</span><span>from</span><span>(</span>
                        <span>&amp;</span><span>interners</span><span>.application_period</span><span>,</span>
                        <span>ApplicationPeriod</span><span>::</span><span>from</span><span>(</span><span>interners</span><span>,</span> <span>x</span><span>),</span>
                    <span>)</span>
                <span>})</span>
                <span>.collect</span><span>(),</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>With this generalization, the size improvement starts to be substantial, about 6 times smaller than the previous step and 12 times smaller than the baseline input files (commit <a href="https://github.com/gendx/rust-interning/commit/f532ef9aa822a77de496b8fae44b1642db47bef8">f532ef9</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 86349519 bytes (relative size = 7.59%)
[67.50%] Interners: 58288479 bytes
- [5.13%] String interner: 56374 objects | 4433343 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [1.81%] Disruption interner: 7550 objects | 1565896 bytes (207.40 bytes/object) | 625760 references (82.88 refs/object)
  - [0.28%] ApplicationPeriod interner: 5883 objects | 245688 bytes (41.76 bytes/object) | 631593 references (107.36 refs/object)
- [53.61%] Line interner: 97090 objects | 46289464 bytes (476.77 bytes/object) | 930026 references (9.58 refs/object)
  - [6.66%] ImpactedObject interner: 56110 objects | 5754088 bytes (102.55 bytes/object) | 3183332 references (56.73 refs/object)
</code></pre></div></div>

<h3 id="dropping-the-reference-28"><span><a href="#dropping-the-reference-28"><i aria-hidden="true"></i></a></span>Dropping the reference (2.8%)</h3>

<p>One thing you may have noticed is how the reference to an <code>Interner</code> proliferates well beyond the <code>Interned</code> struct.
It forces us (1) to add a lifetime <code>&#39;a</code> everywhere and (2) to use interior mutability which causes the <code>Interner</code>/<code>InternerImpl</code> split.</p>

<div><div><pre><code><span>struct</span> <span>Interned</span><span>&lt;</span><span>&#39;a</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>interner</span><span>:</span> <span>&amp;</span><span>&#39;a</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span>
    <span>id</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Crucially, it also means inflated memory usage due to a lot of duplication: a struct like <code>Disruption&lt;&#39;a&gt;</code> contains at least 7 references to the same string interner!
So what if we just got rid of it?</p>

<p>In the current design, the <code>Interned</code> type is <a href="https://stackoverflow.com/questions/5004162/what-does-it-mean-for-a-data-structure-to-be-intrusive"><em>intrusive</em></a> (as it’s aware of the surrounding <code>Interner</code>).
We can instead externalize the interner, and let the caller provide a reference to the interner when needed.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>usize</span><span>,</span>
    <span>// Marker to indicate that an interned object behaves like a function that</span>
    <span>// returns a T (via the lookup method).</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>T</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>// The interner reference is now provided by the caller.</span>
    <span>fn</span> <span>from</span><span>(</span><span>interner</span><span>:</span> <span>&amp;</span><span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span> <span>value</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>interner</span><span>.intern</span><span>(</span><span>value</span><span>)</span>
    <span>}</span>

    <span>// Same here.</span>
    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>interner</span><span>:</span> <span>&amp;</span><span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
        <span>interner</span><span>.lookup</span><span>(</span><span>self</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>One difficulty with this simplified design is how to implement comparison and hashing methods on <code>Interned&lt;T&gt;</code>.
Indeed, these operators have a fixed API given by traits such as <a href="https://doc.rust-lang.org/std/cmp/trait.PartialEq.html"><code>PartialEq</code></a>, so an interner reference cannot be provided as an additional value to the <a href="https://doc.rust-lang.org/std/cmp/trait.PartialEq.html#tymethod.eq"><code>eq()</code></a> function for example.</p>

<p>To solve this issue, we can remark that an interned index fully represents the underlying object (within the realm of an interner): two values will be interned to the same index if and only if they are equal.
So rather than doing a deep (recursive) comparison, we can simply compare the indices, i.e. <code>derive</code> their implementations for <code>Interned</code>.
Likewise for hashing.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Hash,</span> <span>PartialEq,</span> <span>Eq)]</span>
<span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>
</code></pre></div></div>

<p>However, the difficulty remains when we want to compare an <code>Interned&lt;T&gt;</code> with a <code>T</code>.
In that case, we really need to look up the underlying value and perform a deep comparison.
For that purpose, I ended up defining a new <code>EqWith</code> trait that allows passing the interner as a helper object for the comparison.</p>

<div><div><pre><code><span>trait</span> <span>EqWith</span><span>&lt;</span><span>Rhs</span><span>,</span> <span>Helper</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq_with</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>Rhs</span><span>,</span> <span>helper</span><span>:</span> <span>&amp;</span><span>Helper</span><span>)</span> <span>-&gt;</span> <span>bool</span><span>;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>EqWith</span><span>&lt;</span><span>T</span><span>,</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;&gt;</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq_with</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>T</span><span>,</span> <span>interner</span><span>:</span> <span>&amp;</span><span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.lookup</span><span>(</span><span>interner</span><span>)</span><span>.deref</span><span>()</span> <span>==</span> <span>other</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We can then compare structs from the source and optimized schemas.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Hash,</span> <span>PartialEq,</span> <span>Eq)]</span>
<span>struct</span> <span>ApplicationPeriod</span> <span>{</span>
    <span>begin</span><span>:</span> <span>IString</span><span>,</span>
    <span>end</span><span>:</span> <span>IString</span><span>,</span>
<span>}</span>

<span>impl</span> <span>EqWith</span><span>&lt;</span><span>source</span><span>::</span><span>ApplicationPeriod</span><span>,</span> <span>Interners</span><span>&gt;</span> <span>for</span> <span>ApplicationPeriod</span> <span>{</span>
    <span>fn</span> <span>eq_with</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>source</span><span>::</span><span>ApplicationPeriod</span><span>,</span> <span>interners</span><span>:</span> <span>&amp;</span><span>Interners</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.begin</span><span>.eq_with</span><span>(</span><span>&amp;</span><span>other</span><span>.begin</span><span>,</span> <span>&amp;</span><span>interners</span><span>.string</span><span>)</span>
            <span>&amp;&amp;</span> <span>self</span><span>.end</span><span>.eq_with</span><span>(</span><span>&amp;</span><span>other</span><span>.end</span><span>,</span> <span>&amp;</span><span>interners</span><span>.string</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>With that, we’ve halved the size of an <code>Interned&lt;T&gt;</code>, and therefore almost halved the total in-memory size (commit <a href="https://github.com/gendx/rust-interning/commit/59fae78b25aa2cfd013992c68f3692a2336f7f23">59fae78</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 49829943 bytes (relative size = 4.38%)
[68.66%] Interners: 34215191 bytes
- [8.90%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [2.17%] Disruption interner: 7550 objects | 1081928 bytes (143.30 bytes/object) | 625760 references (82.88 refs/object)
  - [0.30%] ApplicationPeriod interner: 5883 objects | 151552 bytes (25.76 bytes/object) | 631593 references (107.36 refs/object)
- [49.71%] Line interner: 97090 objects | 24768600 bytes (255.11 bytes/object) | 930026 references (9.58 refs/object)
  - [7.59%] ImpactedObject interner: 56110 objects | 3779776 bytes (67.36 bytes/object) | 3183332 references (56.73 refs/object)
</code></pre></div></div>

<p>Can we half it again?</p>

<p>Yes!
The <a href="https://matklad.github.io/2020/03/22/fast-simple-rust-interner.html">original blog post</a> by <em>matklad</em> was using a <code>u32</code> index, rather than <code>usize</code>.
This is indeed a fairly reasonable choice for objects that are supposed to be referenced multiple times.
In my case, the dataset didn’t contain any type with more than a million distinct objects, so there was enough margin.</p>

<div><div><pre><code><span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>u32</span><span>,</span>  <span>// Now a 32-bit index.</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>T</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>value</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
        <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>&amp;</span><span>id</span><span>)</span> <span>=</span> <span>self</span><span>.map</span><span>.get</span><span>(</span><span>&amp;</span><span>value</span><span>)</span> <span>{</span>
            <span>return</span> <span>id</span><span>;</span>
        <span>}</span>

        <span>// Runtime check that the identifier doesn&#39;t exceed a u32.</span>
        <span>let</span> <span>id</span> <span>=</span> <span>self</span><span>.vec</span><span>.len</span><span>();</span>
        <span>assert!</span><span>(</span><span>id</span> <span>&lt;=</span> <span>u32</span><span>::</span><span>MAX</span> <span>as</span> <span>usize</span><span>);</span>
        <span>let</span> <span>id</span> <span>=</span> <span>id</span> <span>as</span> <span>u32</span><span>;</span>

        <span>let</span> <span>rc</span><span>:</span> <span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>Rc</span><span>::</span><span>new</span><span>(</span><span>value</span><span>);</span>
        <span>self</span><span>.vec</span><span>.push</span><span>(</span><span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>rc</span><span>));</span>
        <span>self</span><span>.map</span><span>.insert</span><span>(</span><span>rc</span><span>,</span> <span>id</span><span>);</span>
        <span>id</span>
    <span>}</span>

    <span>fn</span> <span>lookup</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>id</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
        <span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>self</span><span>.vec</span><span>[</span><span>id</span> <span>as</span> <span>usize</span><span>])</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’re now down below 3% of the original data set size (commit <a href="https://github.com/gendx/rust-interning/commit/84d79e72fd0ec828d975ffeeed1f10d6cd1db906">84d79e7</a>).
Steady progress!</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 31391391 bytes (relative size = 2.76%)
[72.41%] Interners: 22730967 bytes
- [14.12%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [2.48%] Disruption interner: 7550 objects | 779548 bytes (103.25 bytes/object) | 625760 references (82.88 refs/object)
  - [0.33%] ApplicationPeriod interner: 5883 objects | 104488 bytes (17.76 bytes/object) | 631593 references (107.36 refs/object)
- [45.86%] Line interner: 97090 objects | 14396532 bytes (148.28 bytes/object) | 930026 references (9.58 refs/object)
  - [9.61%] ImpactedObject interner: 56110 objects | 3017064 bytes (53.77 bytes/object) | 3183332 references (56.73 refs/object)
</code></pre></div></div>

<h2 id="tuning-the-schema"><span><a href="#tuning-the-schema"><i aria-hidden="true"></i></a></span>Tuning the schema</h2>

<p>Using general interning techniques wasn’t the end of the journey.
Indeed, we can leverage business knowledge about the data to optimize it even more.</p>

<h3 id="sorting-sets-15"><span><a href="#sorting-sets-15"><i aria-hidden="true"></i></a></span>Sorting sets (1.5%)</h3>

<p>One common pattern in this data was a field containing a set of objects (themselves interned).
For example, a <code>Line</code> contains a set of impacted objects stored as a <code>Vec&lt;Interned&lt;ImpactedObject&gt;&gt;</code>, and each <code>ImpactedObject</code> contains a set of disruption IDs as a <code>Vec&lt;IString&gt;</code>.</p>

<div><div><pre><code><span>struct</span> <span>Line</span> <span>{</span>
    <span>id</span><span>:</span> <span>IString</span><span>,</span>
    <span>name</span><span>:</span> <span>IString</span><span>,</span>
    <span>short_name</span><span>:</span> <span>IString</span><span>,</span>
    <span>mode</span><span>:</span> <span>IString</span><span>,</span>
    <span>network_id</span><span>:</span> <span>IString</span><span>,</span>
    <span>impacted_objects</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Interned</span><span>&lt;</span><span>ImpactedObject</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> <span>ImpactedObject</span> <span>{</span>
    <span>typ</span><span>:</span> <span>IString</span><span>,</span>
    <span>id</span><span>:</span> <span>IString</span><span>,</span>
    <span>name</span><span>:</span> <span>IString</span><span>,</span>
    <span>disruption_ids</span><span>:</span> <span>Vec</span><span>&lt;</span><span>IString</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>What’s interesting is that these sets don’t have a particular order, semantically speaking: we only care about which objects are impacted on a given metro line, not whether one impacted object is “before” another (whatever that means).
However, in Rust the <code>Vec</code> collection type is semantically ordered!</p>

<p>This means that two <code>ImpactedObject</code>s with the same <code>typ</code>, <code>id</code> and <code>name</code> fields but <code>disruption_ids</code> equal to <code>[123, 42, 73]</code> in one case and <code>[73, 123, 42]</code> in the other would be considered different in terms of hashing and equality, even though they are semantically the same.</p>

<p>As it turns out, the API was returning such sets in arbitrary order from one call to the next (which I guess makes sense if they internally represent them using hash tables or hash sets).
So one object containing a set of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span> items could be represented as up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo stretchy="false">!</mo></mrow><annotation encoding="application/x-tex">N!</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span><span>!</span></span></span></span> JSON representations appearing distinct from the perspective of the interner (number of permutations of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span> items).</p>

<p>Unfortunately, the problem compounds: a <code>Line</code> contains a set of <code>ImpactedObject</code>s which themselves contain sets of <code>IString</code>.
Consider the following example: each of the two <code>ImpactedObject</code>s has <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo stretchy="false">!</mo><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">3! = 6</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>3</span><span>!</span><span></span><span>=</span><span></span></span><span><span></span><span>6</span></span></span></span> possible representations and there are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo stretchy="false">!</mo><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2! = 2</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>2</span><span>!</span><span></span><span>=</span><span></span></span><span><span></span><span>2</span></span></span></span> possible orderings of these two objects, so this <code>Line</code> has up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mo>⋅</mo><mn>6</mn><mo>⋅</mo><mn>2</mn><mo>=</mo><mn>72</mn></mrow><annotation encoding="application/x-tex">6 \cdot 6 \cdot 2 = 72</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>6</span><span></span><span>⋅</span><span></span></span><span><span></span><span>6</span><span></span><span>⋅</span><span></span></span><span><span></span><span>2</span><span></span><span>=</span><span></span></span><span><span></span><span>72</span></span></span></span> representations.
And that’s a fairly simple example, in reality the sets could be longer than 3 disruptions.
In practice, the <code>Interner&lt;Line&gt;</code> contained the most number of objects (97090), totaling 14 MB which was 45% of the optimized bytes.</p>

<div><div><pre><code><span>Line</span> <span>{</span>
    <span>impacted_objects</span><span>:</span> <span>vec!</span><span>[</span>
        <span>ImpactedObject</span> <span>{</span>
            <span>disruption_ids</span><span>:</span> <span>vec!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>],</span> <span>...</span>
        <span>},</span>
        <span>ImpactedObject</span> <span>{</span>
            <span>disruption_ids</span><span>:</span> <span>vec!</span><span>[</span><span>4</span><span>,</span> <span>5</span><span>,</span> <span>6</span><span>],</span> <span>...</span>
        <span>},</span>
    <span>],</span>
    <span>...</span>
<span>}</span>

<span>// Same object serialized differently.</span>
<span>Line</span> <span>{</span>
    <span>impacted_objects</span><span>:</span> <span>vec!</span><span>[</span>
        <span>ImpactedObject</span> <span>{</span>
            <span>disruption_ids</span><span>:</span> <span>vec!</span><span>[</span><span>6</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>],</span> <span>...</span>
        <span>},</span>
        <span>ImpactedObject</span> <span>{</span>
            <span>disruption_ids</span><span>:</span> <span>vec!</span><span>[</span><span>2</span><span>,</span> <span>1</span><span>,</span> <span>3</span><span>],</span> <span>...</span>
        <span>},</span>
    <span>],</span>
    <span>...</span>
<span>}</span>
</code></pre></div></div>

<p>To mitigate this problem, we can canonicalize such sets, the easiest way being to sort them.
However, adding ordering operators (via the <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html"><code>PartialOrd</code></a> and <a href="https://doc.rust-lang.org/std/cmp/trait.Ord.html"><code>Ord</code></a> traits) for all the structs in the schema would be annoying.
But that’s not required: we only need to order sets of <code>Interned&lt;T&gt;</code>, and we can do that by simply ordering the underlying indices!
Indeed, all we need is a canonical order, we don’t care if this order reflects the semantics of the objects.</p>

<p>Unfortunately, we cannot derive <code>PartialOrd</code> on <code>Interned&lt;T&gt;</code> if the underlying <code>T</code> doesn’t itself implement it.
This is a <a href="https://github.com/rust-lang/rust/issues/26925">known and long-standing limitation</a> of <code>derive</code> (<a href="https://github.com/rust-lang/rust/issues/7671">more than 10 years old</a>!).</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>#[derive(PartialEq,</span> <span>Eq,</span> <span>PartialOrd,</span> <span>Ord)]</span>
<span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>u32</span><span>,</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>T</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> <span>MyArbitraryType</span><span>;</span>

<span>fn</span> <span>foo</span><span>(</span><span>set</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>Interned</span><span>&lt;</span><span>MyArbitraryType</span><span>&gt;</span><span>])</span> <span>{</span>
    <span>// error[E0277]: the trait bound `MyArbitraryType: Ord` is not satisfied</span>
    <span>set</span><span>.sort_unstable</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<div id="derive-error-277"><div><pre><code>error[E0277]: the trait bound `MyArbitraryType: Ord` is not satisfied
    --&gt; src/lib.rs:13:9
     |
13   |     set.sort_unstable();
     |         ^^^^^^^^^^^^^ the trait `Ord` is not implemented for `MyArbitraryType`
     |
     = help: the trait `Ord` is implemented for `Interned&lt;T&gt;`
note: required for `Interned&lt;MyArbitraryType&gt;` to implement `Ord`
    --&gt; src/lib.rs:3:37
     |
3    | #[derive(PartialEq, Eq, PartialOrd, Ord)]
     |                                     ^^^ unsatisfied trait bound introduced in this `derive` macro
note: required by a bound in `core::slice::&lt;impl [T]&gt;::sort_unstable`
    --&gt; /playground/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/mod.rs:2932:12
     |
2930 |     pub fn sort_unstable(&amp;mut self)
     |            ------------- required by a bound in this associated function
2931 |     where
2932 |         T: Ord,
     |            ^^^ required by this bound in `core::slice::&lt;impl [T]&gt;::sort_unstable`
     = note: this error originates in the derive macro `Ord` (in Nightly builds, run with -Z macro-backtrace for more info)
help: consider annotating `MyArbitraryType` with `#[derive(Ord)]`
     |
9    + #[derive(Ord)]
10   | struct MyArbitraryType;
     |
</code></pre></div></div>

<p>So we have to implement the comparison traits manually on <code>Interned&lt;T&gt;</code>, which isn’t <em>that</em> bad.
Note that if we implement <code>PartialEq</code> manually, we can <code>derive(Hash)</code> it but a <a href="https://rust-lang.github.io/rust-clippy/master/index.html#derived_hash_with_manual_eq">Clippy lint</a> will warn against that.</p>

<div id="manual-comparisons"><div><pre><code><span>use</span> <span>std</span><span>::</span><span>cmp</span><span>::</span><span>Ordering</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>hash</span><span>::{</span><span>Hash</span><span>,</span> <span>Hasher</span><span>};</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>PartialEq</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>eq</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>Self</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
        <span>self</span><span>.id</span><span>.eq</span><span>(</span><span>&amp;</span><span>other</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Eq</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>PartialOrd</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>partial_cmp</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>Self</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>Ordering</span><span>&gt;</span> <span>{</span>
        <span>Some</span><span>(</span><span>self</span><span>.cmp</span><span>(</span><span>other</span><span>))</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Ord</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>cmp</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>&amp;</span><span>Self</span><span>)</span> <span>-&gt;</span> <span>Ordering</span> <span>{</span>
        <span>self</span><span>.id</span><span>.cmp</span><span>(</span><span>&amp;</span><span>other</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Hash</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>hash</span><span>&lt;</span><span>H</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>state</span><span>:</span> <span>&amp;</span><span>mut</span> <span>H</span><span>)</span>
    <span>where</span>
        <span>H</span><span>:</span> <span>Hasher</span><span>,</span>
    <span>{</span>
        <span>self</span><span>.id</span><span>.hash</span><span>(</span><span>state</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I then chose to create an <code>InternedSet&lt;T&gt;</code> abstraction, that will sort the items in canonical order.
Note the use of the <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.sort_unstable"><code>sort_unstable()</code></a> function, which is more efficient than the generic <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.sort"><code>sort()</code></a>.
Also note that we store the set as a boxed slice <code>Box&lt;[_]&gt;</code> instead of a <code>Vec&lt;_&gt;</code>, which is more compact for immutable sequences as it doesn’t require storing a capacity field to potentially grow the vector.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Hash,</span> <span>PartialEq,</span> <span>Eq)]</span>
<span>struct</span> <span>InternedSet</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>set</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span><span>]</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>InternedSet</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>new</span><span>(</span><span>set</span><span>:</span> <span>impl</span> <span>IntoIterator</span><span>&lt;</span><span>Item</span> <span>=</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>let</span> <span>mut</span> <span>set</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>_</span><span>]</span><span>&gt;</span> <span>=</span> <span>set</span><span>.into_iter</span><span>()</span><span>.collect</span><span>();</span>
        <span>set</span><span>.sort_unstable</span><span>();</span>
        <span>Self</span> <span>{</span> <span>set</span> <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We can then integrate it into the schema as follows.</p>

<div><div><pre><code><span>struct</span> <span>ImpactedObject</span> <span>{</span>
    <span>typ</span><span>:</span> <span>IString</span><span>,</span>
    <span>id</span><span>:</span> <span>IString</span><span>,</span>
    <span>name</span><span>:</span> <span>IString</span><span>,</span>
    <span>disruption_ids</span><span>:</span> <span>InternedSet</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span> <span>ImpactedObject</span> <span>{</span>
    <span>fn</span> <span>from</span><span>(</span><span>interners</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Interners</span><span>,</span> <span>source</span><span>:</span> <span>source</span><span>::</span><span>ImpactedObject</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>Self</span> <span>{</span>
            <span>typ</span><span>:</span> <span>Interned</span><span>::</span><span>from</span><span>(</span><span>&amp;</span><span>mut</span> <span>interners</span><span>.string</span><span>,</span> <span>source</span><span>.typ</span><span>),</span>
            <span>id</span><span>:</span> <span>Interned</span><span>::</span><span>from</span><span>(</span><span>&amp;</span><span>mut</span> <span>interners</span><span>.string</span><span>,</span> <span>source</span><span>.id</span><span>),</span>
            <span>name</span><span>:</span> <span>Interned</span><span>::</span><span>from</span><span>(</span><span>&amp;</span><span>mut</span> <span>interners</span><span>.string</span><span>,</span> <span>source</span><span>.name</span><span>),</span>
            <span>disruption_ids</span><span>:</span> <span>InternedSet</span><span>::</span><span>new</span><span>(</span>
                <span>source</span>
                    <span>.disruption_ids</span>
                    <span>.into_iter</span><span>()</span>
                    <span>.map</span><span>(|</span><span>x</span><span>|</span> <span>Interned</span><span>::</span><span>from</span><span>(</span><span>&amp;</span><span>mut</span> <span>interners</span><span>.string</span><span>,</span> <span>x</span><span>)),</span>
            <span>),</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This change divided the number of different <code>Line</code> objects by 14, and the total optimized size by two once again (commit <a href="https://github.com/gendx/rust-interning/commit/bdb00b523433db5f1f4a3150507f3b05eef76de5">bdb00b5</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 16578863 bytes (relative size = 1.46%)
[50.70%] Interners: 8405895 bytes
- [26.74%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [3.97%] Disruption interner: 7550 objects | 658748 bytes (87.25 bytes/object) | 625760 references (82.88 refs/object)
  - [0.63%] ApplicationPeriod interner: 5883 objects | 104488 bytes (17.76 bytes/object) | 631593 references (107.36 refs/object)
- [4.06%] Line interner: 6880 objects | 672568 bytes (97.76 bytes/object) | 930026 references (135.18 refs/object)
  - [15.30%] ImpactedObject interner: 55373 objects | 2536756 bytes (45.81 bytes/object) | 3183332 references (57.49 refs/object)
</code></pre></div></div>

<h3 id="using-enums-14"><span><a href="#using-enums-14"><i aria-hidden="true"></i></a></span>Using enums (1.4%)</h3>

<p>At this point, the <code>Data</code> root structs used half of the optimized size.
You might have noticed that it contained only optional fields.</p>

<div><div><pre><code><span>struct</span> <span>Data</span> <span>{</span>
    <span>status_code</span><span>:</span> <span>Option</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>,</span>
    <span>error</span><span>:</span> <span>Option</span><span>&lt;</span><span>IString</span><span>&gt;</span><span>,</span>
    <span>message</span><span>:</span> <span>Option</span><span>&lt;</span><span>IString</span><span>&gt;</span><span>,</span>
    <span>disruptions</span><span>:</span> <span>Option</span><span>&lt;</span><span>InternedSet</span><span>&lt;</span><span>Disruption</span><span>&gt;&gt;</span><span>,</span>
    <span>lines</span><span>:</span> <span>Option</span><span>&lt;</span><span>InternedSet</span><span>&lt;</span><span>Line</span><span>&gt;&gt;</span><span>,</span>
    <span>last_updated_date</span><span>:</span> <span>Option</span><span>&lt;</span><span>IString</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>However, in practice, the fields that are set come together: either the object contains an error, with <code>status_code</code>, <code>error</code> and <code>message</code> fields, or it contains useful data with <code>disruptions</code>, <code>lines</code> and <code>last_updated_date</code> fields.
So a better representation is to use an enumeration with two variants.</p>

<div><div><pre><code><span>enum</span> <span>Data</span> <span>{</span>
    <span>Success</span> <span>{</span>
        <span>disruptions</span><span>:</span> <span>InternedSet</span><span>&lt;</span><span>Disruption</span><span>&gt;</span><span>,</span>
        <span>lines</span><span>:</span> <span>InternedSet</span><span>&lt;</span><span>Line</span><span>&gt;</span><span>,</span>
        <span>last_updated_date</span><span>:</span> <span>IString</span><span>,</span>
    <span>},</span>
    <span>Error</span> <span>{</span>
        <span>status_code</span><span>:</span> <span>i32</span><span>,</span>
        <span>error</span><span>:</span> <span>IString</span><span>,</span>
        <span>message</span><span>:</span> <span>IString</span><span>,</span>
    <span>},</span>
<span>}</span>
</code></pre></div></div>

<p>This separation brings two benefits: the schema is more sound semantically and takes less space in memory.
Indeed, an <code>Interned&lt;T&gt;</code> uses 4 bytes (a <code>u32</code> index) but an <code>Option&lt;Interned&lt;T&gt;&gt;</code> uses 8 bytes: 1 bit for the option state and the rest to align to a multiple of 4 bytes.</p>

<p>The improvement was more modest this time (commit <a href="https://github.com/gendx/rust-interning/commit/c8ac2611348f271c8deffeb26b11aee022387baa">c8ac261</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 15847679 bytes (relative size = 1.39%)
[53.04%] Interners: 8405895 bytes
- [27.97%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [4.16%] Disruption interner: 7550 objects | 658748 bytes (87.25 bytes/object) | 625760 references (82.88 refs/object)
  - [0.66%] ApplicationPeriod interner: 5883 objects | 104488 bytes (17.76 bytes/object) | 631593 references (107.36 refs/object)
- [4.24%] Line interner: 6880 objects | 672568 bytes (97.76 bytes/object) | 930026 references (135.18 refs/object)
  - [16.01%] ImpactedObject interner: 55373 objects | 2536756 bytes (45.81 bytes/object) | 3183332 references (57.49 refs/object)
</code></pre></div></div>

<h3 id="splitting-structs-082"><span><a href="#splitting-structs-082"><i aria-hidden="true"></i></a></span>Splitting structs (0.82%)</h3>

<p>Another thing you may have noticed about the <code>ImpactedObject</code> example is that it contains both fields that are constant (type, identifier, name) and fields that change over time (list of disruptions).
This means that each time a disruption is added or removed from the list, a new <code>ImpactedObject</code> is created and added to the interner, even if the “header” fields that define the object haven’t changed.
A more optimized approach is to extract the fixed fields into a separate object, and to add a new interner for it.</p>

<div><div><pre><code><span>struct</span> <span>ImpactedObject</span> <span>{</span>
    <span>// Fixed part of an object.</span>
    <span>object</span><span>:</span> <span>Interned</span><span>&lt;</span><span>Object</span><span>&gt;</span><span>,</span>
    <span>disruption_ids</span><span>:</span> <span>InternedSet</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>// New struct grouping the fixed fields of an object.</span>
<span>struct</span> <span>Object</span> <span>{</span>
    <span>typ</span><span>:</span> <span>IString</span><span>,</span>
    <span>id</span><span>:</span> <span>IString</span><span>,</span>
    <span>name</span><span>:</span> <span>IString</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Note that this new design doesn’t change the total number of <code>ImpactedObject</code>s (55373), but makes each one smaller: one <code>u32</code> index for an <code>Interned&lt;Object&gt;</code> instead of three <code>IString</code> indices.
There are however much fewer <code>Object</code>s (1679) because each one is referenced by many <code>ImpactedObject</code>s (commit <a href="https://github.com/gendx/rust-interning/commit/8914a64497362cab7847796d60a27aeb117134b5">8914a64</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 15330607 bytes (relative size = 1.35%)
[51.46%] Interners: 7888823 bytes
- [28.92%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [4.30%] Disruption interner: 7550 objects | 658748 bytes (87.25 bytes/object) | 625760 references (82.88 refs/object)
  - [0.68%] ApplicationPeriod interner: 5883 objects | 104488 bytes (17.76 bytes/object) | 631593 references (107.36 refs/object)
- [3.67%] Line interner: 6880 objects | 562488 bytes (81.76 bytes/object) | 930026 references (135.18 refs/object)
  - [0.01%] LineHeader interner: 45 objects | 1428 bytes (31.73 bytes/object) | 930026 references (20667.24 refs/object)
  - [13.66%] ImpactedObject interner: 55373 objects | 2093772 bytes (37.81 bytes/object) | 3183332 references (57.49 refs/object)
    - [0.23%] Object interner: 1679 objects | 34564 bytes (20.59 bytes/object) | 3183332 references (1895.97 refs/object)
</code></pre></div></div>

<p>The improvement was small this time, but if we look at the second half of an <code>ImpactedObject</code> we can observe that several objects may be affected by the exact same set of disruptions, for example because they represent stations on the same line.
By adding another layer of indirection and interning the interned set, we can again reduce redundancy.
In practice there were only 9127 distinct sets of disruption IDs (commit <a href="https://github.com/gendx/rust-interning/commit/fcff0d5f1e9bc1089382170f5ed7f097190c48de">fcff0d5</a>).</p>

<div><div><pre><code><span>struct</span> <span>ImpactedObject</span> <span>{</span>
    <span>object</span><span>:</span> <span>Interned</span><span>&lt;</span><span>Object</span><span>&gt;</span><span>,</span>
    <span>// Also intern the set.</span>
    <span>disruption_ids</span><span>:</span> <span>Interned</span><span>&lt;</span><span>InternedSet</span><span>&lt;</span><span>String</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>This reduced the optimized size by more than a third.</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1531039733 bytes in memory (relative size = 134.63%)
Optimized to 9364491 bytes (relative size = 0.82%)
[94.79%] Interners: 8877035 bytes
- [47.34%] String interner: 56374 objects | 4433335 bytes (78.64 bytes/object) | 23964083 references (425.09 refs/object)
- [3.50%] InternedSet&lt;String&gt; interner: 9127 objects | 327620 bytes (35.90 bytes/object) | 3183332 references (348.78 refs/object)
- [7.90%] InternedSet&lt;Disruption&gt; interner: 7066 objects | 739652 bytes (104.68 bytes/object) | 30430 references (4.31 refs/object)
  - [7.03%] Disruption interner: 7550 objects | 658748 bytes (87.25 bytes/object) | 625760 references (82.88 refs/object)
    - [1.12%] ApplicationPeriod interner: 5883 objects | 104488 bytes (17.76 bytes/object) | 631593 references (107.36 refs/object)
- [11.88%] InternedSet&lt;Line&gt; interner: 7183 objects | 1112896 bytes (154.93 bytes/object) | 30430 references (4.24 refs/object)
  - [6.01%] Line interner: 6880 objects | 562488 bytes (81.76 bytes/object) | 930026 references (135.18 refs/object)
    - [0.02%] LineHeader interner: 45 objects | 1428 bytes (31.73 bytes/object) | 930026 references (20667.24 refs/object)
    - [9.63%] ImpactedObject interner: 55373 objects | 901816 bytes (16.29 bytes/object) | 3183332 references (57.49 refs/object)
      - [0.37%] Object interner: 1679 objects | 34564 bytes (20.59 bytes/object) | 3183332 references (1895.97 refs/object)
</code></pre></div></div>

<h3 id="specializing-types-064"><span><a href="#specializing-types-064"><i aria-hidden="true"></i></a></span>Specializing types (0.64%)</h3>

<p>After all these optimizations, strings were using half of the optimized space: each <code>Interner</code> is a table that other objects can reference by index.
In practice, the string interner contained values of very heterogeneous semantics: some strings were long error messages in HTML format, some were simple names of places, some were identifiers such as <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUIDs</a> and others were timestamps in human-readable format.
The latter two are particularly interesting: instead of storing them as plain strings, we could parse them into more compact and semantically rich formats.</p>

<p>For UUIDs, we can simply use the <code>Uuid</code> type from the <a href="https://docs.rs/uuid/"><code>uuid</code></a> crate as a drop-in replacement.
Internally, this type uses only 16 bytes to store each identifier, instead of 36 bytes for strings like <code>67e55044-10b1-426f-9247-bb680e5fe0c8</code> (overhead of hexadecimal encoding + separators).</p>

<p>For timestamps, I opted for the <a href="https://docs.rs/chrono/"><code>chrono</code></a> crate, aiming to store each one in 8 bytes (64-bit number of seconds since the Unix epoch) rather than 15 to 24 bytes for something like <code>20240428T044500</code> or <code>2024-05-01T00:59:25.384Z</code>.
There was a difficulty however: some timestamps were encoded in <a href="https://tools.ietf.org/html/rfc3339">RFC 3339</a> format with millisecond precision in the UTC time zone, others were a naive date + time in seconds implicitly in the Paris time zone.
In that case, I used the <a href="https://docs.rs/chrono-tz/"><code>chrono-tz</code></a> crate to handle the conversion and canonicalize them to UTC.</p>

<p>There is a caveat however when the time zone is implicit: on days when <a href="https://en.wikipedia.org/wiki/Daylight_saving_time">daylight saving</a> starts or end, the times between 2am and 3am may either be ambiguous (we don’t know if we’re in the CET or CEST time zone when the time jumps back from 3am to 2am) or invalid (when the time jumps from 2am to 3am).
That said, the metro network is normally closed at this time, so a small imprecision isn’t too dramatic.
It would be more annoying for the scheduling of night trains for example.</p>

<div><div><pre><code><span>use</span> <span>chrono</span><span>::</span><span>offset</span><span>::</span><span>LocalResult</span><span>;</span>
<span>use</span> <span>chrono</span><span>::{</span><span>DateTime</span><span>,</span> <span>NaiveDateTime</span><span>};</span>
<span>use</span> <span>chrono_tz</span><span>::</span><span>Europe</span><span>::</span><span>Paris</span><span>;</span>

<span>struct</span> <span>TimestampSecondsParis</span><span>(</span><span>i64</span><span>);</span>

<span>impl</span> <span>TimestampSecondsParis</span> <span>{</span>
    <span>fn</span> <span>from_formatted</span><span>(</span><span>x</span><span>:</span> <span>&amp;</span><span>str</span><span>,</span> <span>format</span><span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>let</span> <span>naive_datetime</span> <span>=</span> <span>NaiveDateTime</span><span>::</span><span>parse_from_str</span><span>(</span><span>x</span><span>,</span> <span>format</span><span>)</span><span>.unwrap_or_else</span><span>(|</span><span>_</span><span>|</span> <span>{</span>
            <span>panic!</span><span>(</span><span>&#34;Failed to parse datetime (custom format {format:?}) from {x}&#34;</span><span>)</span>
        <span>});</span>

        <span>// Handle the specifics of times falling during the daylight saving transition.</span>
        <span>let</span> <span>datetime</span> <span>=</span> <span>match</span> <span>naive_datetime</span><span>.and_local_timezone</span><span>(</span><span>Paris</span><span>)</span> <span>{</span>
            <span>LocalResult</span><span>::</span><span>Single</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span><span>,</span>
            <span>LocalResult</span><span>::</span><span>Ambiguous</span><span>(</span><span>earliest</span><span>,</span> <span>latest</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>eprintln!</span><span>(</span><span>&#34;Ambiguous mapping of {naive_datetime:?} to the Paris timezone: {earliest:?} or {latest:?}&#34;</span><span>);</span>
                <span>earliest</span>
            <span>}</span>
            <span>LocalResult</span><span>::</span><span>None</span> <span>=&gt;</span> <span>{</span>
                <span>panic!</span><span>(</span><span>&#34;Invalid mapping of {naive_datetime:?} to the Paris timezone&#34;</span><span>)</span>
            <span>}</span>
        <span>};</span>

        <span>TimestampSecondsParis</span><span>(</span><span>datetime</span><span>.timestamp</span><span>())</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>These changes removed a large majority of the interned strings, shaving off another 2 MB (commits <a href="https://github.com/gendx/rust-interning/commit/2031f428a7d91019486d896e25824c17b1f0ce8f">2031f42</a> and <a href="https://github.com/gendx/rust-interning/commit/ad29181ff2ce5c0dff8d6d4e7010244456b60842">ad29181</a>).</p>

<div><div><pre><code>Parsed 1137178883 bytes from 30466 files (+ 21 failed files)
Expanded to 1322690141 bytes in memory (relative size = 116.31%)
Optimized to 7264110 bytes (relative size = 0.64%)
[89.93%] Interners: 6532926 bytes
- [25.03%] String interner: 8050 objects | 1818466 bytes (225.90 bytes/object) | 17309489 references (2150.25 refs/object)
- [2.25%] Uuid interner: 6617 objects | 163296 bytes (24.68 bytes/object) | 4735218 references (715.61 refs/object)
- [10.18%] InternedSet&lt;Disruption&gt; interner: 7066 objects | 739652 bytes (104.68 bytes/object) | 30430 references (4.31 refs/object)
  - [9.90%] Disruption interner: 7550 objects | 719148 bytes (95.25 bytes/object) | 625760 references (82.88 refs/object)
    - [2.09%] ApplicationPeriod interner: 5883 objects | 151552 bytes (25.76 bytes/object) | 631593 references (107.36 refs/object)
- [15.32%] InternedSet&lt;Line&gt; interner: 7183 objects | 1112896 bytes (154.93 bytes/object) | 30430 references (4.24 refs/object)
  - [7.74%] Line interner: 6880 objects | 562488 bytes (81.76 bytes/object) | 930026 references (135.18 refs/object)
    - [0.02%] LineHeader interner: 45 objects | 1428 bytes (31.73 bytes/object) | 930026 references (20667.24 refs/object)
    - [12.41%] ImpactedObject interner: 55373 objects | 901816 bytes (16.29 bytes/object) | 3183332 references (57.49 refs/object)
      - [0.48%] Object interner: 1679 objects | 34564 bytes (20.59 bytes/object) | 3183332 references (1895.97 refs/object)
      - [4.51%] InternedSet&lt;Uuid&gt; interner: 9127 objects | 327620 bytes (35.90 bytes/object) | 3183332 references (348.78 refs/object)
</code></pre></div></div>

<h2 id="serialization"><span><a href="#serialization"><i aria-hidden="true"></i></a></span>Serialization</h2>

<p>At this point, we basically have an implicit in-memory database.
The next step is to serialize it, to see how interning plays out with persistence.
Serialization is also an important step to validate that the claimed space improvements are real.
Lastly, it’s an opportunity to further compress the data.</p>

<p>In Rust, the de-facto serialization framework is <a href="https://docs.rs/serde/"><code>serde</code></a>, which we’ve already used to <a href="#importing-the-data-135">import the JSON input</a>.
Serde supports many formats out-of-the-box, via extension crates, so I’ve decided to try a few of them.</p>

<ul>
  <li><a href="https://tools.ietf.org/html/rfc8949">CBOR</a>, via <a href="https://docs.rs/ciborium/"><code>ciborium</code></a>,</li>
  <li><a href="https://tools.ietf.org/html/rfc8259">JSON</a>, via <a href="https://docs.rs/serde_json/"><code>serde_json</code></a>,</li>
  <li><a href="https://postcard.jamesmunns.com/">Postcard</a>, via <a href="https://docs.rs/postcard/"><code>postcard</code></a>,</li>
  <li>The <a href="https://docs.rs/bincode/"><code>bincode</code></a> crate (no specification available).</li>
</ul>

<h3 id="writing-custom-deserializers-with-serde-029"><span><a href="#writing-custom-deserializers-with-serde-029"><i aria-hidden="true"></i></a></span>Writing custom (de)serializers with Serde (0.29%)</h3>

<p>Usually, all you have to do is to annotate each type in your schema with <code>#[derive(Serialize, Deserialize)]</code> and Serde provides you (de)serialization functions out-of-the-box, which is the whole appeal of the framework.
However, this wouldn’t be very efficient for the <code>Interner&lt;T&gt;</code> table, which contains the same objects twice (in a vector and in a hash map).
Additionally, Serde’s <a href="https://docs.rs/serde/1.0.217/serde/trait.Serialize.html#impl-Serialize-for-Rc%3CT%3E">documentation</a> mentions that even though <a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a> is (de)serializable if you opt into the <code>rc</code> feature, it copies the underlying content each time it’s referenced, which isn’t optimal nor semantically equivalent.</p>

<div><div><pre><code><span>struct</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>vec</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>T</span><span>&gt;&gt;</span><span>,</span>
    <span>map</span><span>:</span> <span>HashMap</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span> <span>u32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>In this case, we don’t want to serialize both the vector of objects and the lookup table of indices: the whole interner state can be recovered from the vector alone.
Indeed, if we deserialize the objects in the same order, they will get the same indices.
And hopefully, Serde makes it easy to serialize a sequence.</p>

<p>Indeed, the docs for <a href="https://docs.rs/serde/1.0.217/serde/trait.Serialize.html"><code>Serialize</code></a> and <a href="https://docs.rs/serde/1.0.217/serde/trait.Serializer.html"><code>Serializer</code></a> quickly guide us to a solution, namely the <a href="https://docs.rs/serde/1.0.217/serde/trait.Serializer.html#tymethod.serialize_seq"><code>serialize_seq()</code></a> or <a href="https://docs.rs/serde/1.0.217/serde/trait.Serializer.html#method.collect_seq"><code>collect_seq()</code></a> methods (the latter works well with functional-style iterators).</p>

<div><div><pre><code><span>use</span> <span>serde</span><span>::{</span><span>Serialize</span><span>,</span> <span>Serializer</span><span>};</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Serialize</span><span>&gt;</span> <span>Serialize</span> <span>for</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>serialize</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>serializer</span><span>:</span> <span>S</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>S</span><span>::</span><span>Ok</span><span>,</span> <span>S</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>S</span><span>:</span> <span>Serializer</span><span>,</span>
    <span>{</span>
        <span>// Tell Serde to serialize a sequence of items.</span>
        <span>serializer</span><span>.collect_seq</span><span>(</span><span>self</span><span>.vec</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>rc</span><span>|</span> <span>rc</span><span>.deref</span><span>()))</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Deserialization is more complex, which isn’t surprising as it needs to handle potential errors in the serialized stream.
Ultimately, you need to check the <a href="https://serde.rs/impl-deserialize.html">guide directly on Serde’s website</a>, as the regular API documentation doesn’t explain the details.</p>

<p>One needs not only to manipulate the <a href="https://docs.rs/serde/1.0.217/serde/trait.Deserialize.html"><code>Deserialize</code></a> and <a href="https://docs.rs/serde/1.0.217/serde/trait.Deserializer.html"><code>Deserializer</code></a> traits, but also write a <a href="https://docs.rs/serde/1.0.217/serde/de/trait.Visitor.html"><code>Visitor</code></a> and (in this case) manipulate a <a href="https://docs.rs/serde/1.0.217/serde/de/trait.SeqAccess.html"><code>SeqAccess</code></a>.
There’s a lot more boilerplate, but it works out.</p>

<div id="deserialize-impl"><div><pre><code><span>use</span> <span>serde</span><span>::</span><span>de</span><span>::{</span><span>SeqAccess</span><span>,</span> <span>Visitor</span><span>};</span>
<span>use</span> <span>serde</span><span>::{</span><span>Deserialize</span><span>,</span> <span>Deserializer</span><span>};</span>

<span>impl</span><span>&lt;</span><span>&#39;de</span><span>,</span> <span>T</span><span>&gt;</span> <span>Deserialize</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span> <span>for</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span>
<span>where</span>
    <span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span> <span>+</span> <span>Deserialize</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span><span>,</span>
<span>{</span>
    <span>fn</span> <span>deserialize</span><span>&lt;</span><span>D</span><span>&gt;</span><span>(</span><span>deserializer</span><span>:</span> <span>D</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>,</span> <span>D</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>D</span><span>:</span> <span>Deserializer</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span><span>,</span>
    <span>{</span>
        <span>// Tell Serde to deserialize a sequence of items using the given visitor.</span>
        <span>deserializer</span><span>.deserialize_seq</span><span>(</span><span>InternerVisitor</span><span>::</span><span>new</span><span>())</span>
    <span>}</span>
<span>}</span>

<span>// A visitor to create an Interner&lt;T&gt;.</span>
<span>struct</span> <span>InternerVisitor</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>// This visitor is stateless, but Rust requires to use the generic parameter T.</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>InternerVisitor</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>new</span><span>()</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>Self</span> <span>{</span>
            <span>_phantom</span><span>:</span> <span>PhantomData</span><span>,</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>&#39;de</span><span>,</span> <span>T</span><span>&gt;</span> <span>Visitor</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span> <span>for</span> <span>InternerVisitor</span><span>&lt;</span><span>T</span><span>&gt;</span>
<span>where</span>
    <span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span> <span>+</span> <span>Deserialize</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span><span>,</span>
<span>{</span>
    <span>// Tell Serde that the output will be an Interner.</span>
    <span>type</span> <span>Value</span> <span>=</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>

    <span>// Error message to display if the input stream doesn&#39;t contain a sequence of Ts.</span>
    <span>fn</span> <span>expecting</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>formatter</span><span>:</span> <span>&amp;</span><span>mut</span> <span>std</span><span>::</span><span>fmt</span><span>::</span><span>Formatter</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>fmt</span><span>::</span><span>Result</span> <span>{</span>
        <span>formatter</span><span>.write_str</span><span>(</span><span>&#34;a sequence of values&#34;</span><span>)</span>
    <span>}</span>

    <span>// Callback invoked by Serde with a sequence of items.</span>
    <span>fn</span> <span>visit_seq</span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>self</span><span>,</span> <span>mut</span> <span>seq</span><span>:</span> <span>A</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>::</span><span>Value</span><span>,</span> <span>A</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>A</span><span>:</span> <span>SeqAccess</span><span>&lt;</span><span>&#39;de</span><span>&gt;</span><span>,</span>
    <span>{</span>
        <span>// Serde may give us a hint about the number of items in the sequence.</span>
        <span>let</span> <span>mut</span> <span>interner</span> <span>=</span> <span>match</span> <span>seq</span><span>.size_hint</span><span>()</span> <span>{</span>
            <span>None</span> <span>=&gt;</span> <span>Interner</span><span>::</span><span>default</span><span>(),</span>
            <span>Some</span><span>(</span><span>size_hint</span><span>)</span> <span>=&gt;</span> <span>Interner</span> <span>{</span>
                <span>vec</span><span>:</span> <span>Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>size_hint</span><span>),</span>
                <span>map</span><span>:</span> <span>HashMap</span><span>::</span><span>with_capacity</span><span>(</span><span>size_hint</span><span>),</span>
                <span>references</span><span>:</span> <span>0</span><span>,</span>
            <span>},</span>
        <span>};</span>

        <span>// We gather the elements in a loop and return an Interner.</span>
        <span>while</span> <span>let</span> <span>Some</span><span>(</span><span>t</span><span>)</span> <span>=</span> <span>seq</span><span>.next_element</span><span>()</span><span>?</span> <span>{</span>
            <span>interner</span><span>.push</span><span>(</span><span>t</span><span>);</span>
        <span>}</span>

        <span>Ok</span><span>(</span><span>interner</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>// For completeness, here is the new push() function, slightly more efficient than intern().</span>
<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Eq</span> <span>+</span> <span>Hash</span><span>&gt;</span> <span>Interner</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>/// Unconditionally push a value, without validating that it&#39;s already interned.</span>
    <span>fn</span> <span>push</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>value</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
        <span>let</span> <span>id</span> <span>=</span> <span>self</span><span>.vec</span><span>.len</span><span>();</span>
        <span>assert!</span><span>(</span><span>id</span> <span>&lt;=</span> <span>u32</span><span>::</span><span>MAX</span> <span>as</span> <span>usize</span><span>);</span>
        <span>let</span> <span>id</span> <span>=</span> <span>id</span> <span>as</span> <span>u32</span><span>;</span>

        <span>let</span> <span>rc</span><span>:</span> <span>Rc</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>Rc</span><span>::</span><span>new</span><span>(</span><span>value</span><span>);</span>
        <span>self</span><span>.vec</span><span>.push</span><span>(</span><span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>rc</span><span>));</span>
        <span>self</span><span>.map</span><span>.insert</span><span>(</span><span>rc</span><span>,</span> <span>id</span><span>);</span>

        <span>id</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here is a comparison of the serialization formats at this point, sorted by encoded size.
Postcard is a clear winner at 3.2 MB, much less than JSON at 65 MB in pretty-printed form or 26 MB in minified form (commit <a href="https://github.com/gendx/rust-interning/commit/b5013e6ceed00263e4744ea4f6a7ce27b1e83b8d">b5013e6</a>).</p>

<table>
  <thead>
    <tr>
      <th>Format</th>
      <th>Bytes</th>
      <th>Relative size</th>
      <th>Encode time</th>
      <th>Decode time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Postcard</td>
      <td>3275869</td>
      <td>0.29%</td>
      <td>17 ms</td>
      <td>16 ms</td>
    </tr>
    <tr>
      <td>Bincode</td>
      <td>5437330</td>
      <td>0.48%</td>
      <td>16 ms</td>
      <td>24 ms</td>
    </tr>
    <tr>
      <td>CBOR</td>
      <td>17484567</td>
      <td>1.54%</td>
      <td>56 ms</td>
      <td>128 ms</td>
    </tr>
    <tr>
      <td>JSON</td>
      <td>26485131</td>
      <td>2.33%</td>
      <td>74 ms</td>
      <td>118 ms</td>
    </tr>
    <tr>
      <td>JSON (pretty)</td>
      <td>65026281</td>
      <td>5.72%</td>
      <td>152 ms</td>
      <td>135 ms</td>
    </tr>
  </tbody>
</table>

<p>It’s also interesting to compare the encoding and decoding times, as the more compact formats tend to be faster to process too.
Take them with a grain of salt though, that’s not a proper benchmark but a single data point on my machine, and without using any optimized library like <a href="https://docs.rs/simd-json/"><code>simd_json</code></a>.</p>

<h3 id="compression-and-fighting-the-rust-borrow-checker-linux-pipes-005"><span><a href="#compression-and-fighting-the-rust-borrow-checker-linux-pipes-005"><i aria-hidden="true"></i></a></span>Compression and fighting <del>the Rust borrow checker</del> Linux pipes (0.05%)</h3>

<p>Once we have serialized the database into bytes, we can apply general-purpose compression to it.
Indeed, even after interning we expect some amount of redundancy: for example disruption messages follow templates where only some details vary.</p>

<p>I didn’t really want to investigate the various Rust compression libraries, as I thought that spawning a command would be simpler for this experiment.
Indeed, the <a href="https://doc.rust-lang.org/std/process/struct.Command.html"><code>Command</code></a> type in the Rust standard library allows to easily run other programs, passing them arguments and inputs in a safe way, and collecting the output.
In principle, one should configure <a href="https://doc.rust-lang.org/std/process/struct.Stdio.html#method.piped"><code>Stdio::piped()</code></a> to interact with stdin/stdout/stderr of the child process, and we’re good to go… or so I thought.</p>

<div><div><pre><code><span>// Naive implementation, which doesn&#39;t work (inter-process deadlock).</span>
<span>fn</span> <span>gzip_compress</span><span>(</span><span>input</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>,</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>std</span><span>::</span><span>error</span><span>::</span><span>Error</span><span>&gt;&gt;</span> <span>{</span>
    <span>let</span> <span>compress</span> <span>=</span> <span>Command</span><span>::</span><span>new</span><span>(</span><span>&#34;gzip&#34;</span><span>)</span>
        <span>.arg</span><span>(</span><span>&#34;-c&#34;</span><span>)</span>  <span>// Compress to stdout.</span>
        <span>.arg</span><span>(</span><span>&#34;-6&#34;</span><span>)</span>  <span>// Compression level.</span>
        <span>.stdin</span><span>(</span><span>Stdio</span><span>::</span><span>piped</span><span>())</span>
        <span>.stdout</span><span>(</span><span>Stdio</span><span>::</span><span>piped</span><span>())</span>
        <span>.stderr</span><span>(</span><span>Stdio</span><span>::</span><span>null</span><span>())</span>
        <span>.spawn</span><span>()</span><span>?</span><span>;</span>

    <span>compress</span><span>.stdin</span><span>.as_mut</span><span>()</span><span>.expect</span><span>(</span><span>&#34;Failed to open stdin&#34;</span><span>)</span><span>.write_all</span><span>(</span><span>input</span><span>)</span><span>?</span><span>;</span>

    <span>let</span> <span>output</span> <span>=</span> <span>compress</span><span>.wait_with_output</span><span>()</span><span>?</span><span>;</span>
    <span>if</span> <span>!</span><span>output</span><span>.status</span><span>.success</span><span>()</span> <span>{</span>
        <span>/* Return an error */</span>
    <span>}</span>
    <span>Ok</span><span>(</span><span>output</span><span>.stdout</span><span>)</span>
<span>}</span>
</code></pre></div></div>

<p>Indeed, while this naive implementation worked for simple examples with a short input, it seemingly deadlocked once I tried to compress larger inputs!</p>

<p>The answer lies in the <a href="https://www.man7.org/linux/man-pages/man7/pipe.7.html">Linux manual for pipes</a>.
When a parent and child process communicate via stdin/stdout/stderr, this is done via a so-called <em>pipe</em>.
Under the hood, the kernel provides a buffer where one process can write and the other process can read.</p>

<p>However, to avoid exhausting the system resources, this buffer has a limited size.
In particular, <code>/proc/sys/fs/pipe-max-size</code> sets the maximum size (in bytes) of one pipe, which is 1 MiB on my system.
Additionally, <code>/proc/sys/fs/pipe-user-pages-hard</code> and <code>/proc/sys/fs/pipe-user-pages-soft</code> set the maximum number of pages that one user can create in terms of pipes (across all its processes), which is 64 MiB on my system.</p>

<div><div><pre><code><span>$ </span><span>cat</span> /proc/sys/fs/pipe-max-size
1048576
<span>$ </span><span>cat</span> /proc/sys/fs/pipe-user-pages-hard
0
<span>$ </span><span>cat</span> /proc/sys/fs/pipe-user-pages-soft
16384
</code></pre></div></div>

<p>Back to invoking <code>gzip</code>: the problem is that if the input is too large, the <code>write_all(input)</code> call will be blocked until the child (gzip) process reads from the pipe.
The <code>gzip</code> process will indeed start reading from it, but will also want to write compressed output as soon as possible to its standard output (to limit its own memory usage).
However, with the naive implementation, my parent process isn’t reading this output yet until it’s done writing all the input.
So the compressed output will fill its pipe too.</p>

<p><a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/pipes-writing.rcvX_WUfg9Zh.svg"><img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/pipes-writing.rcvX_WUfg9Zh.svg" width="840" height="275" loading="lazy" alt="Diagram of a compression process&#39; stdin and stdout pipes filling up"/></a>
Linux pipes around a compression process.</p>

<p>At some point, we’ll end up in a situation where my parent process is blocked on writing more input to the stdin pipe (waiting for gzip to read it) while the child gzip process is blocked on writing more compressed output to the stdout pipe (waiting for the parent process to read it).
In other words: an inter-process deadlock!</p>

<p><a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/pipes-full.WTvcH5bPcbn8.svg"><img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/pipes-full.WTvcH5bPcbn8.svg" width="840" height="275" loading="lazy" alt="Diagram with full stdin and stdout pipes"/></a>
Full pipes causing a deadlock.</p>

<p>Be really careful about this limitation: even if you think that you won’t need to write more than 1 MiB (or whatever <code>/proc/sys/fs/pipe-max-size</code> says on your system), the total per-user limit may restrict pipes to only one page (once <code>/proc/sys/fs/pipe-user-pages-soft</code> is reached) which is usually 4 KiB, i.e. much lower than the 1 MiB default.</p>

<p>To remediate that, we need to make sure to both write uncompressed input and read compressed output at the same time, i.e. use threads.
We can still use the convenient functions <a href="https://doc.rust-lang.org/std/io/trait.Write.html#method.write_all"><code>write_all()</code></a> and <a href="https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end"><code>read_to_end()</code></a> as long as they happen in parallel threads.</p>

<p>I ended up creating a utility function to automate this pattern of writing all of an input slice and reading all of the output.
Note the use of <a href="https://doc.rust-lang.org/stable/std/thread/fn.scope.html"><code>std::thread::scope()</code></a>, which allows to capture an input slice with non-static lifetime.</p>

<div><div><pre><code><span>#![feature(exit_status_error)]</span>

<span>fn</span> <span>io_command</span><span>(</span><span>mut</span> <span>child</span><span>:</span> <span>Child</span><span>,</span> <span>input</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>,</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>std</span><span>::</span><span>error</span><span>::</span><span>Error</span><span>&gt;&gt;</span> <span>{</span>
    <span>std</span><span>::</span><span>thread</span><span>::</span><span>scope</span><span>(|</span><span>s</span><span>|</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>,</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>std</span><span>::</span><span>error</span><span>::</span><span>Error</span><span>&gt;&gt;</span> <span>{</span>
        <span>let</span> <span>mut</span> <span>stdin</span> <span>=</span> <span>child</span><span>.stdin</span><span>.take</span><span>()</span><span>.expect</span><span>(</span><span>&#34;Failed to open stdin&#34;</span><span>);</span>
        <span>let</span> <span>mut</span> <span>stdout</span> <span>=</span> <span>child</span><span>.stdout</span><span>.take</span><span>()</span><span>.expect</span><span>(</span><span>&#34;Failed to open stdout&#34;</span><span>);</span>

        <span>let</span> <span>input_thread</span> <span>=</span> <span>s</span><span>.spawn</span><span>(</span><span>move</span> <span>||</span> <span>-&gt;</span> <span>std</span><span>::</span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
            <span>eprintln!</span><span>(</span><span>&#34;Writing {} bytes...&#34;</span><span>,</span> <span>input</span><span>.len</span><span>());</span>
            <span>stdin</span><span>.write_all</span><span>(</span><span>input</span><span>)</span><span>?</span><span>;</span>
            <span>drop</span><span>(</span><span>stdin</span><span>);</span>
            <span>Ok</span><span>(())</span>
        <span>});</span>

        <span>let</span> <span>output_thread</span> <span>=</span> <span>s</span><span>.spawn</span><span>(</span><span>move</span> <span>||</span> <span>-&gt;</span> <span>std</span><span>::</span><span>io</span><span>::</span><span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;&gt;</span> <span>{</span>
            <span>eprintln!</span><span>(</span><span>&#34;Reading bytes...&#34;</span><span>);</span>
            <span>let</span> <span>mut</span> <span>output</span> <span>=</span> <span>Vec</span><span>::</span><span>new</span><span>();</span>
            <span>stdout</span><span>.read_to_end</span><span>(</span><span>&amp;</span><span>mut</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(</span><span>output</span><span>)</span>
        <span>});</span>

        <span>eprintln!</span><span>(</span><span>&#34;Waiting for child...&#34;</span><span>);</span>
        <span>child</span><span>.wait</span><span>()</span><span>?</span><span>.exit_ok</span><span>()</span><span>?</span><span>;</span>

        <span>input_thread</span><span>.join</span><span>()</span><span>.expect</span><span>(</span><span>&#34;Failed to join input thread&#34;</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>output</span> <span>=</span> <span>output_thread</span>
            <span>.join</span><span>()</span>
            <span>.expect</span><span>(</span><span>&#34;Failed to join output thread&#34;</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>output</span><span>)</span>
    <span>})</span>
<span>}</span>
</code></pre></div></div>

<p>Back to the original topic, I’ve benchmarked a few common compression algorithms.
What they show is that the size difference between formats tends to get smaller after compression.
At this point, we’ve reached the 2000x size reduction mark on the most compact formats: from 1.1 GB down to 530 KB for the May 2024 data (commit <a href="https://github.com/gendx/rust-interning/commit/b7281f5da83da3235ec88348a409aefe17c15ac9">b7281f5</a>).</p>

<p>
<a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-b7281f5.AVEOpxGMp-tq.svg">
<picture>
  <source srcset="/blog/images/rust-interning-2000x/histogram-sizes-b7281f5-dark.gDT6pHGl_Zc1.svg" media="(prefers-color-scheme: dark)" width="800" height="600"/>
  <img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-b7281f5.AVEOpxGMp-tq.svg" width="800" height="600" loading="lazy" alt="Histogram of encoded sizes"/>
</picture>
</a>
</p>

<table id="table-sizes-b7281f5">
<thead>
<tr>
<th>Format</th>
<th colspan="2">Serialization</th>
<th colspan="2">gzip -6</th>
<th colspan="2">brotli -6</th>
<th colspan="2">xz -6</th>
</tr>
</thead>
<tbody>
<tr>
<td>Postcard</td><td>3275869</td><td>0.29%</td><td>861917</td><td>0.08%</td><td>721120</td><td>0.06%</td><td>539200</td><td>0.05%</td>
</tr>
<tr>
<td>Bincode</td><td>5437330</td><td>0.48%</td><td>893271</td><td>0.08%</td><td>700194</td><td>0.06%</td><td>529996</td><td>0.05%</td>
</tr>
<tr>
<td>CBOR</td><td>17484567</td><td>1.54%</td><td>1187575</td><td>0.10%</td><td>826739</td><td>0.07%</td><td>615124</td><td>0.05%</td>
</tr>
<tr>
<td>JSON</td><td>26485131</td><td>2.33%</td><td>1253219</td><td>0.11%</td><td>916683</td><td>0.08%</td><td>736036</td><td>0.06%</td>
</tr>
<tr>
<td>JSON (pretty)</td><td>65026281</td><td>5.72%</td><td>1563418</td><td>0.14%</td><td>1006035</td><td>0.09%</td><td>958624</td><td>0.08%</td>
</tr>
</tbody>
</table>

<p>However, similar sizes after compression doesn’t mean you should use JSON and forget about it: (de)serialization and (de)compression speed are faster with the more optimized formats like Postcard!</p>

<p>
<a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-times-b7281f5.ghE9gu7LV6EA.svg">
<picture>
  <source srcset="/blog/images/rust-interning-2000x/histogram-times-b7281f5-dark.XWoRDMwNKkia.svg" media="(prefers-color-scheme: dark)" width="800" height="600"/>
  <img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-times-b7281f5.ghE9gu7LV6EA.svg" width="800" height="600" loading="lazy" alt="Histogram of encoding and decoding times"/>
</picture>
</a>
</p>

<table id="table-times-b7281f5">
<thead>
<tr>
<th rowspan="2">Format</th>
<th colspan="2">Serialization</th>
<th colspan="2">gzip -6</th>
<th colspan="2">brotli -6</th>
<th colspan="2">xz -6</th>
</tr>
<tr>
<th>encode</th>
<th>decode</th>
<th>encode</th>
<th>decode</th>
<th>encode</th>
<th>decode</th>
<th>encode</th>
<th>decode</th>
</tr>
</thead>
<tbody>
<tr>
<td>Postcard</td><td>22 ms</td><td>27 ms</td><td>88 ms</td><td>21 ms</td><td>144 ms</td><td>18 ms</td><td>583 ms</td><td>37 ms</td>
</tr>
<tr>
<td>Bincode</td><td>9 ms</td><td>24 ms</td><td>166 ms</td><td>28 ms</td><td>191 ms</td><td>19 ms</td><td>1111 ms</td><td>39 ms</td>
</tr>
<tr>
<td>CBOR</td><td>72 ms</td><td>131 ms</td><td>189 ms</td><td>63 ms</td><td>230 ms</td><td>36 ms</td><td>3255 ms</td><td>51 ms</td>
</tr>
<tr>
<td>JSON</td><td>72 ms</td><td>100 ms</td><td>233 ms</td><td>96 ms</td><td>449 ms</td><td>44 ms</td><td>3314 ms</td><td>60 ms</td>
</tr>
<tr>
<td>JSON (pretty)</td><td>137 ms</td><td>129 ms</td><td>376 ms</td><td>180 ms</td><td>441 ms</td><td>74 ms</td><td>2934 ms</td><td>81 ms</td>
</tr>
</tbody>
</table>

<p>Another aspect that was out of scope for my experiment is the impact on code size: I expect the simpler formats to also compile to smaller code.
Be mindful of it especially if you’re deploying code for embedded systems or to <a href="https://webassembly.org/">WebAssembly</a> for a website.</p>

<h3 id="tuple-encoding"><span><a href="#tuple-encoding"><i aria-hidden="true"></i></a></span>Tuple encoding</h3>

<p>Upon inspecting the serialized outputs more closely, I noticed that a lot of <code>_phantom</code> strings were present in the JSON or CBOR outputs.</p>

<div><div><pre><code><span>{</span><span>&#34;id&#34;</span><span>:</span><span> </span><span>11</span><span>,</span><span> </span><span>&#34;_phantom&#34;</span><span>:</span><span> </span><span>null</span><span>}</span><span>
</span></code></pre></div></div>

<p>Something like <code>Interned&lt;T&gt;</code> which I would expect to be serialized as a simple integer was taking much more space.</p>

<div><div><pre><code><span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>u32</span><span>,</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>T</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Indeed, by default Serde serializes each struct as a map, which causes two problems:</p>
<ol>
  <li>field names are serialized as keys in a map,</li>
  <li>zero-sized types like <code>PhantomData</code> are serialized even though they don’t contain any information and should be trivial to re-create.</li>
</ol>

<p>This default might be useful if your types evolve over time (fields added, removed or renamed) and you want to retain some level of “out-of-the-box” compatibility, but that’s a design choice<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">2</a></sup>.
In my case however, the <code>Interned&lt;T&gt;</code> abstraction was so ubiquitous that it meant a lot of redundancy.</p>

<p>After digging into it, I found <a href="https://github.com/serde-rs/serde/issues/297">these</a> <a href="https://github.com/serde-rs/serde/issues/1648">issues</a> as well as <a href="https://github.com/dtolnay/request-for-implementation/issues/3">this discussion</a> by the maintainer of Serde, which boiled down to serializing a struct as a tuple rather than as a map.
Given that tuples don’t have field names, that should address the problem.
This feature request never got implemented in the <code>serde</code> crate itself, but a separate <a href="https://docs.rs/serde_tuple/"><code>serde_tuple</code></a> crate provides the <code>Serialize_tuple</code> and <code>Deserialize_tuple</code> derive macros.</p>

<div><div><pre><code><span>use</span> <span>serde_tuple</span><span>::{</span><span>Deserialize_tuple</span><span>,</span> <span>Serialize_tuple</span><span>};</span>

<span>#[derive(Serialize_tuple,</span> <span>Deserialize_tuple)]</span>
<span>struct</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>id</span><span>:</span> <span>u32</span><span>,</span>
    <span>_phantom</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>fn</span><span>()</span> <span>-&gt;</span> <span>T</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>This mitigated the first issue (commits <a href="https://github.com/gendx/rust-interning/commit/a9924e982e24805bf7f1cdbe417e4da4e10d4158">a9924e9</a> and <a href="https://github.com/gendx/rust-interning/commit/cec535911616652401202d6d7ff4367cb938123c">cec5359</a>).
However, the <code>PhantomData</code> still appeared in the serialized output as a <code>null</code> value.</p>



<p>Given how ubiquitous the <code>Interned</code> type is, I ended up <a href="#writing-custom-deserializers-with-serde-029">writing a custom serializer</a> once again.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Serialize</span> <span>for</span> <span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>serialize</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>serializer</span><span>:</span> <span>S</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>S</span><span>::</span><span>Ok</span><span>,</span> <span>S</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>S</span><span>:</span> <span>Serializer</span><span>,</span>
    <span>{</span>
        <span>serializer</span><span>.serialize_u32</span><span>(</span><span>self</span><span>.id</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>For the affected formats (CBOR and JSON), these optimizations reduced the encoded size by 72% to 75%.
The reduction was more modest after compression, ranging from 11% to 33% (commit <a href="https://github.com/gendx/rust-interning/commit/356bc0af128b19365a18145a12f816e90f9686d3">356bc0a</a>).</p>

<p>
<a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-b7281f5-356bc0a.S5UoLPSeolh-.svg">
<picture>
  <source srcset="/blog/images/rust-interning-2000x/histogram-sizes-b7281f5-356bc0a-dark.eoAr23sHfWWK.svg" media="(prefers-color-scheme: dark)" width="800" height="600"/>
  <img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-b7281f5-356bc0a.S5UoLPSeolh-.svg" width="800" height="600" loading="lazy" alt="Histogram of encoded sizes"/>
</picture>
</a>
</p>

<table id="table-sizes-b7281f5-356bc0a">
  <thead>
    <tr>
      <th>Format</th>
      <th>Serialization</th>
      <th>gzip -6</th>
      <th>brotli -6</th>
      <th>xz -6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Postcard</td>
      <td>3275869</td>
      <td>861917</td>
      <td>721120</td>
      <td>539200</td>
    </tr>
    <tr>
      <td>Bincode</td>
      <td>5437330</td>
      <td>893271</td>
      <td>700194</td>
      <td>529996</td>
    </tr>
    <tr>
      <td>CBOR</td>
      <td>4475821 (-74%)</td>
      <td>955541 (-20%)</td>
      <td>731878 (-11%)</td>
      <td>535068 (-13%)</td>
    </tr>
    <tr>
      <td>JSON</td>
      <td>6560658 (-75%)</td>
      <td>1005689 (-20%)</td>
      <td>777507 (-15%)</td>
      <td>545832 (-26%)</td>
    </tr>
    <tr>
      <td>JSON (pretty)</td>
      <td>18168838 (-72%)</td>
      <td>1162250 (-26%)</td>
      <td>890102 (-12%)</td>
      <td>639072 (-33%)</td>
    </tr>
  </tbody>
</table>

<p>Note that formats like Postcard and Bincode already perform this optimization by default, leveraging the fact that they are <a href="https://postcard.jamesmunns.com/wire-format#non-self-describing-format">not self-describing</a>.
By using the <code>serde_tuple</code> crate, you drop part of the self-describing guarantees for other formats like JSON too, as the sender and receiver must agree on the schema (e.g. the specific order of fields in each struct) to be able to communicate without data corruption.</p>

<h3 id="optimizing-sets-revisited"><span><a href="#optimizing-sets-revisited"><i aria-hidden="true"></i></a></span>Optimizing sets revisited</h3>

<p>I’ve <a href="#sorting-sets-15">previously described</a> how sets of objects could be better unified by sorting them.
The naive (default) approach to serialize them is a list of interned IDs.
However, in practice these IDs are often sequential, because the underlying objects were created around the same time.
For example, all the disruptions that happened on the same day would appear next to each other in the <code>Interned&lt;Disruption&gt;</code> table.</p>

<div><div><pre><code><span>[</span><span>0</span><span>,</span><span> </span><span>70</span><span>,</span><span> </span><span>72</span><span>,</span><span> </span><span>73</span><span>,</span><span> </span><span>74</span><span>,</span><span> </span><span>75</span><span>,</span><span> </span><span>77</span><span>,</span><span> </span><span>78</span><span>,</span><span> </span><span>79</span><span>,</span><span> </span><span>80</span><span>,</span><span> </span><span>81</span><span>]</span><span>
</span></code></pre></div></div>

<p>So instead of serializing the IDs directly, we can use <a href="https://en.wikipedia.org/wiki/Delta_encoding">delta encoding</a>: serializing each ID as the difference from the previous ID.</p>

<div><div><pre><code><span>[</span><span>0</span><span>,</span><span> </span><span>70</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>1</span><span>]</span><span>
</span></code></pre></div></div>

<p>This is beneficial for two reasons:</p>
<ul>
  <li>common serialization formats use variable-length encoding, meaning that small numbers are encoded in fewer bytes than larger numbers,</li>
  <li>if most of these differences are small numbers, there should be more redundancy that the compression algorithms should be able to exploit.</li>
</ul>

<p>As a <a href="#writing-custom-deserializers-with-serde-029">custom Serde serializer</a>, delta encoding is fairly straightforward to implement within each set.</p>

<div><div><pre><code><span>struct</span> <span>InternedSet</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>set</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>Interned</span><span>&lt;</span><span>T</span><span>&gt;</span><span>]</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Serialize</span> <span>for</span> <span>InternedSet</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>serialize</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>serializer</span><span>:</span> <span>S</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>S</span><span>::</span><span>Ok</span><span>,</span> <span>S</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>S</span><span>:</span> <span>Serializer</span><span>,</span>
    <span>{</span>
        <span>let</span> <span>mut</span> <span>prev</span> <span>=</span> <span>0</span><span>;</span>
        <span>serializer</span><span>.collect_seq</span><span>(</span><span>self</span><span>.set</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>x</span><span>|</span> <span>{</span>
            <span>let</span> <span>id</span> <span>=</span> <span>x</span><span>.id</span><span>();</span>
            <span>let</span> <span>diff</span> <span>=</span> <span>id</span> <span>-</span> <span>prev</span><span>;</span>
            <span>prev</span> <span>=</span> <span>id</span><span>;</span>
            <span>diff</span>
        <span>}))</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>While differential encoding didn’t affect the Bincode format (which encodes integers with a fixed size), the serialized size decreased by 9% to 19% for the others.
The size after compression saw a marked decrease (8% to 16%) with gzip and brotli, and a more modest one (4% to 8%) with xz (commit <a href="https://github.com/gendx/rust-interning/commit/4ea388f81630ba8750b258e824a120f37979549c">4ea388f</a>).</p>

<p>
<a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-356bc0a-4ea388f.Ek14Qs--wRbq.svg">
<picture>
  <source srcset="/blog/images/rust-interning-2000x/histogram-sizes-356bc0a-4ea388f-dark.OS4k2hmGzzHu.svg" media="(prefers-color-scheme: dark)" width="800" height="600"/>
  <img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-356bc0a-4ea388f.Ek14Qs--wRbq.svg" width="800" height="600" loading="lazy" alt="Histogram of encoded sizes"/>
</picture>
</a>
</p>

<table id="table-sizes-356bc0a-4ea388f">
  <thead>
    <tr>
      <th>Format</th>
      <th>Serialization</th>
      <th>gzip -6</th>
      <th>brotli -6</th>
      <th>xz -6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Postcard</td>
      <td>2966573 (-9%)</td>
      <td>746478 (-13%)</td>
      <td>624801 (-13%)</td>
      <td>499524 (-7%)</td>
    </tr>
    <tr>
      <td>Bincode</td>
      <td>5437330 (=)</td>
      <td>821573 (-8%)</td>
      <td>631655 (-10%)</td>
      <td>506956 (-4%)</td>
    </tr>
    <tr>
      <td>CBOR</td>
      <td>3688285 (-18%)</td>
      <td>814306 (-15%)</td>
      <td>634705 (-13%)</td>
      <td>493064 (-8%)</td>
    </tr>
    <tr>
      <td>JSON</td>
      <td>5317810 (-19%)</td>
      <td>841046 (-16%)</td>
      <td>708651 (-9%)</td>
      <td>504196 (-7%)</td>
    </tr>
    <tr>
      <td>JSON (pretty)</td>
      <td>15018136 (-17%)</td>
      <td>988869 (-15%)</td>
      <td>820774 (-8%)</td>
      <td>590380 (-7%)</td>
    </tr>
  </tbody>
</table>

<p>In practice, we can go one step further: not only were the deltas often small, but they were also often 1s, with long sequences of consecutive elements.
So I decided to add <a href="https://en.wikipedia.org/wiki/Run-length_encoding">run-length encoding</a> on top.
Note that because the IDs <a href="#sorting-sets-15">have been sorted</a>, the deltas are guaranteed to be non-negative, making a simple dual delta/RLE encoding possible: interpret a negative number <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span></span></span></span> as a run of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">-n</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>−</span><span>n</span></span></span></span> consecutive elements, and a non-negative number as a delta from the previous element.</p>

<div><div><pre><code><span>original:</span><span> </span><span>[</span><span>0</span><span>,</span><span> </span><span>70</span><span>,</span><span> </span><span>72</span><span>,</span><span> </span><span>73</span><span>,</span><span> </span><span>74</span><span>,</span><span> </span><span>75</span><span>,</span><span> </span><span>77</span><span>,</span><span> </span><span>78</span><span>,</span><span> </span><span>79</span><span>,</span><span> </span><span>80</span><span>,</span><span> </span><span>81</span><span>]</span><span>
</span><span>optimized:</span><span> </span><span>[</span><span>0</span><span>,</span><span> </span><span>70</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>-3</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>-4</span><span>]</span><span>
</span></code></pre></div></div>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Serialize</span> <span>for</span> <span>InternedSet</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
    <span>fn</span> <span>serialize</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>serializer</span><span>:</span> <span>S</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>S</span><span>::</span><span>Ok</span><span>,</span> <span>S</span><span>::</span><span>Error</span><span>&gt;</span>
    <span>where</span>
        <span>S</span><span>:</span> <span>Serializer</span><span>,</span>
    <span>{</span>
        <span>// Combined delta + RLE encoding.</span>
        <span>let</span> <span>mut</span> <span>rle_encoded</span> <span>=</span> <span>Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>self</span><span>.set</span><span>.len</span><span>());</span>
        <span>let</span> <span>mut</span> <span>prev</span><span>:</span> <span>Option</span><span>&lt;</span><span>u32</span><span>&gt;</span> <span>=</span> <span>None</span><span>;</span>
        <span>let</span> <span>mut</span> <span>streak</span><span>:</span> <span>i32</span> <span>=</span> <span>0</span><span>;</span>

        <span>for</span> <span>x</span> <span>in</span> <span>&amp;</span><span>self</span><span>.set</span> <span>{</span>
            <span>let</span> <span>id</span> <span>=</span> <span>x</span><span>.id</span><span>();</span>
            <span>let</span> <span>diff</span> <span>=</span> <span>id</span> <span>-</span> <span>prev</span><span>.unwrap_or</span><span>(</span><span>0</span><span>);</span>
            <span>if</span> <span>prev</span><span>.is_some</span><span>()</span> <span>&amp;&amp;</span> <span>diff</span> <span>==</span> <span>1</span> <span>{</span>
                <span>streak</span> <span>+=</span> <span>1</span><span>;</span>
            <span>}</span> <span>else</span> <span>{</span>
                <span>if</span> <span>streak</span> <span>!=</span> <span>0</span> <span>{</span>
                    <span>rle_encoded</span><span>.push</span><span>(</span><span>-</span><span>streak</span><span>);</span>
                    <span>streak</span> <span>=</span> <span>0</span><span>;</span>
                <span>}</span>
                <span>rle_encoded</span><span>.push</span><span>(</span><span>diff</span> <span>as</span> <span>i32</span><span>);</span>
            <span>}</span>
            <span>prev</span> <span>=</span> <span>Some</span><span>(</span><span>id</span><span>);</span>
        <span>}</span>
        <span>if</span> <span>streak</span> <span>!=</span> <span>0</span> <span>{</span>
            <span>rle_encoded</span><span>.push</span><span>(</span><span>-</span><span>streak</span><span>);</span>
        <span>}</span>

        <span>serializer</span><span>.collect_seq</span><span>(</span><span>rle_encoded</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This last optimization gave mixed results: while the encoded size decreased by 4% to 11%, the compressed size remained similar – within ±2% (commit <a href="https://github.com/gendx/rust-interning/commit/d09835640cce8f0ee6f9d849cc8f60c7d07bd01e">d098356</a>).</p>

<p>
<a href="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-4ea388f-d098356.uHWcoLxoRSjR.svg">
<picture>
  <source srcset="/blog/images/rust-interning-2000x/histogram-sizes-4ea388f-d098356-dark.3rag3jB5bSJc.svg" media="(prefers-color-scheme: dark)" width="800" height="600"/>
  <img src="https://writing.natwelch.com/blog/images/rust-interning-2000x/histogram-sizes-4ea388f-d098356.uHWcoLxoRSjR.svg" width="800" height="600" loading="lazy" alt="Histogram of encoded sizes"/>
</picture>
</a>
</p>

<table id="table-sizes-4ea388f-d098356">
  <thead>
    <tr>
      <th>Format</th>
      <th>Serialization</th>
      <th>gzip -6</th>
      <th>brotli -6</th>
      <th>xz -6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Postcard</td>
      <td>2832574 (-5%)</td>
      <td>751517 (+1%)</td>
      <td>632425 (+1%)</td>
      <td>504388 (+1%)</td>
    </tr>
    <tr>
      <td>Bincode</td>
      <td>4855254 (-11%)</td>
      <td>825177 (+0%)</td>
      <td>643860 (+2%)</td>
      <td>516736 (+2%)</td>
    </tr>
    <tr>
      <td>CBOR</td>
      <td>3539237 (-4%)</td>
      <td>813895 (-0%)</td>
      <td>637836 (+0%)</td>
      <td>495860 (+1%)</td>
    </tr>
    <tr>
      <td>JSON</td>
      <td>5103171 (-4%)</td>
      <td>846290 (+1%)</td>
      <td>714886 (+1%)</td>
      <td>510584 (+1%)</td>
    </tr>
    <tr>
      <td>JSON (pretty)</td>
      <td>13361128 (-11%)</td>
      <td>983777 (-1%)</td>
      <td>823720 (+0%)</td>
      <td>587044 (-1%)</td>
    </tr>
  </tbody>
</table>

<h2 id="final-result-a-lightweight-append-only-database"><span><a href="#final-result-a-lightweight-append-only-database"><i aria-hidden="true"></i></a></span>Final result: a lightweight append-only database</h2>

<p>To reproduce these results, you’ll find my code <a href="https://github.com/gendx/rust-interning">on GitHub</a>.
I’ve used the RATP Status data at <a href="https://github.com/wincelau/ratpstatus/tree/ef028cce567b6ce9183a185e699206e0f483b99d">commit <code>ef028cc</code></a> (files in the <a href="https://github.com/wincelau/ratpstatus/tree/ef028cce567b6ce9183a185e699206e0f483b99d/datas/json"><code>datas/json/</code> folder</a>).</p>

<div><div><pre><code>git init
git remote add origin https://github.com/wincelau/ratpstatus
git fetch <span>--depth</span> 1 origin ef028cce567b6ce9183a185e699206e0f483b99d
git checkout FETCH_HEAD
</code></pre></div></div>

<p>Conceptually, interning is a simple technique, yet we’ve seen that it can lead to many choices and optimizations.
It’s commonly applied to strings, but in practice what really made a difference was broadly interning all sorts of data structures!</p>

<p>At the end of this article, we have implicitly built one of the simplest relational database designs (without all the querying/SQL part).
It comes a few limitations, which are fine for a time series:</p>
<ul>
  <li><strong>append-only</strong>: we can’t modify nor delete existing objects,</li>
  <li><strong>in-memory</strong>: the serialized form doesn’t support random access of a value at an arbitrary index, so we need to deserialize the whole database in memory,</li>
  <li><strong>single-writer</strong>: to increment the index when interning a new object without synchronization.</li>
</ul>

<p>Something that should be fairly simple to add is supporting incremental updates: given that the interning tables are append-only with incremental indices, you could easily take a snapshot of the database and later create a diff containing only the new objects added since the snapshot.
Multiple reader nodes could then be implemented on top of that, which would give us a replicated database: the writer would broadcast incremental updates to the readers from time to time.</p>

<p>Now, practically, should you use one of the <a href="https://lib.rs/keywords/interning">countless existing interning crates</a>, or <a href="https://lucumr.pocoo.org/2025/1/24/build-it-yourself/">write it yourself</a>?
The answer is that it depends on what you’re doing!</p>

<p>Do you care about a very optimized in-memory layout for strings?
The naive <code>Rc&lt;String&gt;</code> representation I’ve shown may not be ideal.
Are you fine with a single global interner or do you want to manipulate local interner arenas like I’ve shown in this post?
Do you need to serialize your data, and if so should the serialization be compact?</p>

<p>You might even have come up with the interning pattern yourself without knowing it had a name nor that plenty of libraries implement it: that’s perfectly fine too!
Hopefully this post can help you evaluate the existing libraries and make an informed decision to reinvent the wheel or not.</p>

<hr/>



        
        <hr/>
        <h2><i aria-hidden="true"></i>Comments</h2>
        <p>
            To react to this blog post please check
            the <a href="https://infosec.exchange/@gendx/114099583779462472"><i aria-hidden="true"></i> Mastodon thread</a>, the <a href="https://lobste.rs/s/mlseaq/power_interning_making_time_series">Lobste.rs thread</a> and the <a href="https://www.reddit.com/r/rust/comments/1j2nfwt/the_power_of_interning_making_a_time_series/"><i aria-hidden="true"></i> Reddit thread</a>.
        </p>
        
        <hr/>
        <p>
            <a href="https://writing.natwelch.com/blog/feed.xml" target="_blank"><i aria-hidden="true"></i> RSS</a> |
            <a href="https://infosec.exchange/@gendx" target="_blank"><i aria-hidden="true"></i> Mastodon</a> |
            <a href="https://github.com/gendx" target="_blank"><i aria-hidden="true"></i> GitHub</a>
        </p>
        <hr/>
        <h2>You may also like</h2>
        <p>
            <span><i aria-hidden="true"></i> <a href="https://writing.natwelch.com/blog/2024/03/14/website-refresh.html">Making my website 10x smaller in 2024, with a dark mode</a></span>
            </p>
    </section>
</article></div>
  </body>
</html>
