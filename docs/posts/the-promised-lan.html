<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tpl.house/">Original</a>
    <h1>The Promised LAN</h1>
    
    <div id="readability-page-1" class="page"><div>
      
      <p>
The Promised LAN is a closed, membership only network of friends that operate
a 24/7 always-on LAN party, running since 2021. The vast majority of
documentation is maintained on the LAN, but this website serves to give
interested folks, prospective members or friends an idea of what the Promised
LAN is, and how it works.
      </p>
      <h2 id="manifesto">A Manifesto for The Promised LAN</h2>
      <p>
For background on why we started the lan, what we hope to achieve, and how we
approach the social-technical dynamics, we have
<a href="https://notes.pault.ag/tpl/">posted a Manifesto</a> to encourage more
similarly structured LANs. <b>It is worth reading this before moving on</b>.
The social and technical aspects are intertwined here.
      </p>
      <h2 id="backbone">Backbone Network</h2>
      <p>
Each Promised LAN segment connects to the Backbone network, since each LAN
connecting to every other LAN quickly becomes unmaintainable, even with a small
number of segments -- individual dynamic IPs change, keying material exchanges,
negotiating a cipher suite; it gets hard! As a result, we have all LANs connect
to the closest backbone node, and traffic is routed through the backbone network.
      </p>
<img src="https://tpl.house/imgs/network.svg"/>
      <p>
The network is made up of independently operated and heterogeneous nodes
(currently three nodes, a mix of Debian using <code>strongSwan</code> and
OpenBSD using <code>iked</code>), which peer over IPSec links. We&#39;ve decided on
a set of common algorithms which appear to be the best tradeoff of speed,
security and support for our existing backbone nodes.
      </p>
      <table>
  <tbody><tr>
    <th>Algorithms</th>
    <th></th>
  </tr>
  <tr>
    <td>IKE SA Auth</td>
    <td>HMAC SHA2 512</td>
  </tr>
  <tr>
    <td>IKE SA Encryption</td>
    <td>AES 256</td>
  </tr>
  <tr>
    <td>IKE SA DH</td>
    <td>Curve25519</td>
  </tr>
  <tr>
    <td>Child SA Encryption</td>
    <td>ChaCha20 Poly1305</td>
  </tr>
  <tr>
    <td>Child SA DH</td>
    <td>Curve25519</td>
  </tr>
</tbody></table>
      
      <p>
The Backbone network operates in a dedicated /24 allocation, where individual
backbones are issued an IP based on its &#34;Node ID&#34;. Each backbone is only
hardcoded with the routes for each directly connected backbone via its IPSec
connection. This network of nodes operates as The Promised LAN&#39;s
<a href="https://en.wikipedia.org/wiki/Default-free_zone">Default Free Zone (DFZ)</a>.
Once the IP links are established, backbones communicate using BGP (currently
<a href="https://bird.network.cz/">bird</a> on Debian and <code>bgpd</code>
on OpenBSD) in order to advertise directly connected user LANs to the rest of
the backbone network.
      </p>
      <h2 id="dns">DNS</h2>
      <p>
We&#39;re using our own non-standard and possibly ill-advised TLD, which is
<code>.tpl</code> — short for The Promised LAN. Each LAN gets a domain
automatically when it joins the LAN — and folks can request new domains
for whatever they want after joining. There are a set of root DNS servers
(<code>ns1.tpl</code>, <code>ns2.tpl</code>, <code>ns3.tpl</code>) which are
hosted on three different LANs which are each connected to a different backbone
node, in the event of network outages.  We strive to keep core services
running, even if a node is completely disconnected from all others. Each
<a href="https://en.wikipedia.org/wiki/Name_server#Authoritative_name_server">authoritative nameserver</a>
is running an <code>nsd</code>, with a config replicated by pulling a central
<code>git</code> repo on a cron.
      </p>
<img src="https://tpl.house/imgs/dns-roots.svg"/>
      <p>
By convention (mostly to avoid managing a bunch of
<a href="https://en.wikipedia.org/wiki/Domain_Name_System#Circular_dependencies_and_glue_records">glue records</a>),
we expect that each LAN runs their own authoritative nameserver at the fixed
IP of <code>x.x.x.254</code>. This allows us to automate and template the
configurations when LANs join, at a pretty minor cost.
      </p>
<img src="https://tpl.house/imgs/dns-lans.svg"/>
      <p>
Since each LAN doesn&#39;t really need to know all the roots themselves (unless
they want), we run a
<a href="https://en.wikipedia.org/wiki/Name_server#Recursive_Resolver">recursive resolver</a>
on an
<a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a> IP block (x.x.0.1),
running local on the backbones themselves. This is generally running
<code>unbound</code>.
      </p>
<img src="https://tpl.house/imgs/dns-rr.svg"/>
      <h2 id="pki">PKI</h2>
      <p>
Even though everything here is already secure enough for us, deploying services
that use <code>TLS</code> makes using existing/modern tools a lot easier. On
the whole PKI is way more work than it&#39;s worth here, but we decided to engineer
this properly.
      </p>
      <p>
We operate a set of root x509 Certificate Authorities, each with a three year
lifetime. The first year allows us to distribute the roots across the LAN and
let the roots update along with the cadence of routine system maintenance. The
second year is that root&#39;s &#34;operational&#34; year, where all x509 certificates are
issued by that root, and finally, the last year is the transition year to allow
issued certs to expire naturally without the CA being invalid.
      </p>
      <p>
Currently, we issue roots using the <code>ECDSA P-384</code> key type,
with <code>SHA384</code> signatures. Additionally, each CA contains
<code>X509v3 Name Constraints</code> (marked <code>critical</code>) which
limit validity to <code>DNS:.tpl</code> and <code>email:.tpl</code>.
      </p>
      <p>
Finally, we figured we&#39;d use our existing <a href="#dns">DNS</a> for managing
our x509 certificate issuance — so we don&#39;t have to send <code>CSR</code>s
around and wait for human action. Deploying something like <code>ACME</code>
is overkill (for now) and a maintenance nightmare. We wrote something fairly
basic instead, since we can easily constrain our problem space and rules.
Every LAN may set DNS <code>TXT</code> records named <code>_pki</code>
for a given domain, which contains an OpenSSH public key. Signing a new
certificate is done over SSH -- where a CSR is signed by checking the requested
SAN is against the key used to authenticate to the CA against the PKI DNS records
to make an issuance decision.
      </p>
    </div></div>
  </body>
</html>
