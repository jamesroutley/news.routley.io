<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arogozhnikov.github.io/2023/12/28/fastest-autograd.html">Original</a>
    <h1>Fastest autograd in the West</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Who needs fast autograd? Seemingly everyone these days!</p>

<p>And once upon a time I needed an autograd that is <strong>actually fast</strong>.
Leaving project details aside, here are the requirements:</p>

<ul>
  <li>we test many computation graphs (graph is changing constantly)</li>
  <li>many-many scalar operations with roughly <strong>10k—100k nodes</strong> in each graph</li>
  <li>every graph should be compiled and ran around <strong>10k times</strong> both forward and backward</li>
  <li>this should be done <strong>wicked fast</strong>, and with a convenient pythonic interface</li>
</ul>

<p>Path that awaits us ahead:</p>
<ol>
  <li>autograd in torch</li>
  <li>autograd in jax</li>
  <li>autograd in python</li>
  <li>autograd in rust</li>
  <li>autograd in C</li>
  <li>autograd in assembly</li>
</ol>

<p>Plus a significant amount of sloppy code and timings on M1 macbook.</p>

<h3 id="lets-autograd-in-pytorch">Let’s autograd in pytorch</h3>

<p>We start our journey with pytorch — the default autograd engine in research. 
We’ll create a graph with many nodes, and to keep things simple our benchmark has only several kinds of operations: unary (softplus), binary (multiplication), n-ary (sum) and n-to-n (softmax).</p>

<p>This allows using just a few operations, but resembles a realistic load.
All benchmarks in this post will reimplement the same logic as below.</p>

<div><div><pre><code><span>def</span> <span>run_graph</span><span>(</span><span>initial_variables</span><span>,</span> <span>n_operations</span><span>:</span> <span>int</span><span>):</span>
    <span>nodes</span> <span>=</span> <span>[</span><span>*</span><span>initial_variables</span><span>]</span>

    <span>for</span> <span>op</span> <span>in</span> <span>range</span><span>(</span><span>n_operations</span><span>):</span>
        <span>match</span> <span>op</span> <span>%</span> <span>4</span><span>:</span>
            <span>case</span> <span>0</span><span>:</span>
                <span># softplus
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>F</span><span>.</span><span>softplus</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>1</span><span>:</span>
                <span># sum
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>sum</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>30</span><span>:</span><span>-</span><span>10</span><span>:</span><span>5</span><span>]))</span>
            <span>case</span> <span>2</span><span>:</span>
                <span># prod
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>20</span><span>]</span> <span>*</span> <span>nodes</span><span>[</span><span>-</span><span>10</span><span>])</span>
            <span>case</span> <span>3</span><span>:</span>
                <span># softmax
</span>                <span>softmaxes</span> <span>=</span> <span>F</span><span>.</span><span>softmax</span><span>(</span><span>torch</span><span>.</span><span>stack</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>4</span><span>:],</span> <span>dim</span><span>=</span><span>0</span><span>),</span> <span>dim</span><span>=</span><span>0</span><span>)</span>
                <span>nodes</span><span>.</span><span>extend</span><span>(</span><span>softmaxes</span><span>)</span>

    <span>return</span> <span>nodes</span>


<span>def</span> <span>run_benchmark_pytorch</span><span>(</span><span>n_iterations</span><span>,</span> <span>n_operations</span><span>):</span>
    <span>init_vars</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>100</span><span>,</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>float32</span><span>,</span> <span>requires_grad</span><span>=</span><span>True</span><span>)</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>n_iterations</span><span>):</span>
        <span>nodes</span> <span>=</span> <span>run_graph</span><span>(</span>
            <span>initial_variables</span><span>=</span><span>init_vars</span><span>,</span>
            <span>n_operations</span><span>=</span><span>n_operations</span><span>,</span>
        <span>)</span>
        <span>nodes</span><span>[</span><span>-</span><span>1</span><span>].</span><span>backward</span><span>()</span>
</code></pre></div></div>

<p>Run-time for 10k ops x 100 iterations: 11.3 seconds
</p>

<p>Given we created 100M python objects, it’s actually quite fast.
And yes, that’s not going to deliver an interactive experience.</p>

<p>Let’s also discuss <code>torch.compile</code>, a major innovation in pytorch 2.0.</p>

<p>At 100 operations torch.compile takes 4.5 seconds. 
Execution gets faster: for 100 operations and 10k iterations it takes 4.52 seconds with torch.compile and 10.4 seconds without. 
Compilation + execution are still in the same ballpark. 
For bigger graphs (1k operations) <code>torch.compile</code> crashes.</p>

<h3 id="lets-autograd-in-jax">Let’s autograd in jax</h3>

<p>Jax is the new cool kid… well, not that new anymore.
But in some aspects it is very interesting. Jax’s focus on JIT-compiling static graphs is very suitable for the problem at hand.</p>

<p>Implementation for benchmark is similar to pytorch:</p>
<div><div><pre><code><span>import</span> <span>jax</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>run_graph_jax</span><span>(</span><span>initial_variables</span><span>):</span>
    <span>nodes</span> <span>=</span> <span>[</span><span>*</span><span>initial_variables</span><span>]</span>
    <span>for</span> <span>op</span> <span>in</span> <span>range</span><span>(</span><span>n_operations</span><span>):</span>
        <span>match</span> <span>op</span> <span>%</span> <span>4</span><span>:</span>
            <span>case</span> <span>0</span><span>:</span>
                <span># softplus
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>jax</span><span>.</span><span>nn</span><span>.</span><span>softplus</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>1</span><span>:</span> 
                <span># sum
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>sum</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>30</span><span>:</span><span>-</span><span>10</span><span>:</span><span>5</span><span>]))</span>
            <span>case</span> <span>2</span><span>:</span> 
                <span># prod 
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>20</span><span>]</span> <span>*</span> <span>nodes</span><span>[</span><span>-</span><span>10</span><span>])</span>
            <span>case</span> <span>3</span><span>:</span> 
                <span># softmax
</span>                <span>softmaxes</span> <span>=</span> <span>jax</span><span>.</span><span>nn</span><span>.</span><span>softmax</span><span>(</span><span>jax</span><span>.</span><span>numpy</span><span>.</span><span>stack</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>4</span><span>:]),</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
                <span>nodes</span><span>.</span><span>extend</span><span>(</span><span>softmaxes</span><span>)</span>
                
    <span>return</span> <span>nodes</span><span>[</span><span>-</span><span>1</span><span>]</span>

<span>run_graph_and_grad</span> <span>=</span> <span>jax</span><span>.</span><span>value_and_grad</span><span>(</span><span>run_graph_jax</span><span>)</span>
<span># or 
</span><span>run_graph_and_grad</span> <span>=</span> <span>jax</span><span>.</span><span>jit</span><span>(</span><span>jax</span><span>.</span><span>value_and_grad</span><span>(</span><span>run_graph_jax</span><span>))</span>
</code></pre></div></div>

<p>Without jit computations are extremely slow: 
</p>

<p>That’s a bit longer than forever! But whole point of jax is to JIT-compile stuff. So let’s do it.</p>

<p>jit: compilation of 1k ops = 47 seconds
</p>

<p>Speed up in execution time is more than impressive, but we spend  &gt;99% of time compiling.</p>

<h4 id="tensorflow">Tensorflow</h4>
<p>Someone will mention TF anyway. I’ll leave this as an exercise for you, TF fans.</p>

<h3 id="lets-autograd-in-python">Let’s autograd in python</h3>

<p>Done with baselines, time to see if we can speed things up.</p>

<p>Let’s create a simplistic pseudo-framework and see how it competes with previous candidates.
We’ll implement a tape-like autograd where operations order is explicitly tracked in a tape.</p>

<details>
  <summary>show autograd engine in plain python
</summary>
  <div><div><pre><code><span>class</span> <span>NaiveVar</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>val</span><span>):</span>
        <span>self</span><span>.</span><span>val</span> <span>=</span> <span>val</span>
        <span>self</span><span>.</span><span>grad</span> <span>=</span> <span>0.</span>
    
<span>class</span> <span>NaiveTape</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>input_values</span><span>):</span>
        <span>self</span><span>.</span><span>ops</span> <span>=</span> <span>[]</span>
        
    <span>def</span> <span>sum</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>vars</span><span>):</span>
        <span>res</span> <span>=</span> <span>NaiveVar</span><span>(</span><span>sum</span><span>(</span><span>v</span><span>.</span><span>val</span> <span>for</span> <span>v</span> <span>in</span> <span>vars</span><span>))</span>
        <span>self</span><span>.</span><span>ops</span><span>.</span><span>append</span><span>((</span><span>&#39;sum&#39;</span><span>,</span> <span>vars</span><span>,</span> <span>res</span><span>))</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>prod</span><span>(</span><span>self</span><span>,</span> <span>var1</span><span>,</span> <span>var2</span><span>):</span>
        <span>res</span> <span>=</span> <span>NaiveVar</span><span>(</span><span>var1</span><span>.</span><span>val</span> <span>*</span> <span>var2</span><span>.</span><span>val</span><span>)</span>
        <span>self</span><span>.</span><span>ops</span><span>.</span><span>append</span><span>((</span><span>&#39;prod&#39;</span><span>,</span> <span>[</span><span>var1</span><span>,</span> <span>var2</span><span>],</span> <span>res</span><span>))</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>softmax</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>vars</span><span>):</span>
        <span>vals</span> <span>=</span> <span>[</span><span>v</span><span>.</span><span>val</span> <span>for</span> <span>v</span> <span>in</span> <span>vars</span><span>]</span>
        <span>maxval</span> <span>=</span> <span>max</span><span>(</span><span>vals</span><span>)</span>
        <span>vals</span> <span>=</span> <span>[</span><span>v</span> <span>-</span> <span>maxval</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>]</span>
        <span>denom</span> <span>=</span> <span>sum</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>v</span><span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>)</span>
        <span>res</span> <span>=</span> <span>[</span><span>NaiveVar</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>v</span><span>)</span> <span>/</span> <span>denom</span><span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>]</span>
        <span>self</span><span>.</span><span>ops</span><span>.</span><span>append</span><span>((</span><span>&#39;softmax&#39;</span><span>,</span> <span>vars</span><span>,</span> <span>denom</span><span>))</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>softplus</span><span>(</span><span>self</span><span>,</span> <span>var</span><span>):</span>
        <span>res</span> <span>=</span> <span>NaiveVar</span><span>(</span><span>math</span><span>.</span><span>log1p</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>var</span><span>.</span><span>val</span><span>)))</span>
        <span>self</span><span>.</span><span>ops</span><span>.</span><span>append</span><span>((</span><span>&#39;splus&#39;</span><span>,</span> <span>var</span><span>,</span> <span>res</span><span>))</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>backward</span><span>(</span><span>self</span><span>,</span> <span>var</span><span>):</span>
        <span>assert</span> <span>var</span><span>.</span><span>grad</span> <span>==</span> <span>0</span>
        <span>var</span><span>.</span><span>grad</span> <span>+=</span> <span>1</span>
        <span>for</span> <span>op</span><span>,</span> <span>inputs</span><span>,</span> <span>outputs</span> <span>in</span> <span>self</span><span>.</span><span>ops</span><span>[::</span><span>-</span><span>1</span><span>]:</span>
            <span>match</span> <span>op</span><span>:</span>
                <span>case</span> <span>&#39;sum&#39;</span><span>:</span>
                    <span>out</span> <span>=</span> <span>outputs</span>
                    <span>for</span> <span>v</span> <span>in</span> <span>inputs</span><span>:</span>
                        <span>v</span><span>.</span><span>grad</span> <span>+=</span> <span>out</span><span>.</span><span>grad</span>
                <span>case</span> <span>&#39;prod&#39;</span><span>:</span>
                    <span>out</span> <span>=</span> <span>outputs</span>
                    <span>in1</span><span>,</span> <span>in2</span> <span>=</span> <span>inputs</span>
                    <span>in1</span><span>.</span><span>grad</span> <span>+=</span> <span>in2</span><span>.</span><span>val</span> <span>*</span> <span>out</span><span>.</span><span>grad</span>
                    <span>in2</span><span>.</span><span>grad</span> <span>+=</span> <span>in1</span><span>.</span><span>val</span> <span>*</span> <span>out</span><span>.</span><span>grad</span>
                <span>case</span> <span>&#39;splus&#39;</span><span>:</span>
                    <span>inputs</span><span>.</span><span>grad</span> <span>+=</span> <span>out</span><span>.</span><span>grad</span> <span>/</span> <span>(</span><span>1</span> <span>+</span> <span>math</span><span>.</span><span>exp</span><span>(</span><span>-</span><span>inputs</span><span>.</span><span>val</span><span>))</span>
                <span>case</span> <span>&#39;softmax&#39;</span><span>:</span>
                    <span>pass</span> <span># skip for now
</span>                <span>case</span> <span>_</span><span>:</span>
                    <span>raise</span> <span>NotImplementedError</span><span>()</span>
</code></pre></div>  </div>
</details>

<p>and reimplement reference task using our new pseudo-framework:</p>
<details>
  <summary>show benchmarking code
</summary>
  <div><div><pre><code><span>def</span> <span>run_graph_python_and_backward</span><span>(</span><span>initial_variables</span><span>,</span> <span>n_operations</span><span>):</span>
    <span>nodes</span> <span>=</span> <span>[</span><span>NaiveVar</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>initial_variables</span><span>]</span>
    <span>tape</span> <span>=</span> <span>NaiveTape</span><span>(</span><span>nodes</span><span>)</span>
    <span>for</span> <span>op</span> <span>in</span> <span>range</span><span>(</span><span>n_operations</span><span>):</span>
        <span>match</span> <span>op</span> <span>%</span> <span>4</span><span>:</span>
            <span>case</span> <span>0</span><span>:</span> 
                <span># softplus
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>softplus</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>1</span><span>:</span> 
                <span># sum
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>sum</span><span>(</span><span>*</span><span>nodes</span><span>[</span><span>-</span><span>30</span><span>:</span><span>-</span><span>10</span><span>:</span><span>5</span><span>]))</span>
            <span>case</span> <span>2</span><span>:</span> 
                <span># prod 
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>prod</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>20</span><span>],</span> <span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>3</span><span>:</span> 
                <span># softmax
</span>                <span>nodes</span><span>.</span><span>extend</span><span>(</span><span>tape</span><span>.</span><span>softmax</span><span>(</span><span>*</span><span>nodes</span><span>[</span><span>-</span><span>4</span><span>:]))</span>

    <span>tape</span><span>.</span><span>backward</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>1</span><span>])</span>
    <span>return</span> <span>tape</span>
</code></pre></div>  </div>
</details>

<p>Run-time for 10k ops and 10k iterations: <strong>312 seconds</strong>.</p>

<p>Expectably not fast. But compared to previous candidates, that’s actually quite competitive!</p>

<h3 id="lets-autograd-in-python-again">Let’s autograd in python, again</h3>

<p>This time we move all values into tape instead of keeping in variables. 
Additionally tape will keep a ‘static graph’ of computations by recording indices of variables participating in every operation.</p>

<details>
  <summary>show code for autograd in plain python
</summary>
  <div><div><pre><code><span>import</span> <span>numba</span>
<span>import</span> <span>math</span>

<span>class</span> <span>VarInd</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>index</span><span>):</span>
        <span>self</span><span>.</span><span>index</span> <span>=</span> <span>index</span> <span># variable is just a unique index in tape
</span>    
<span>class</span> <span>TapeInd</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>ops</span> <span>=</span> <span>[]</span>
        <span>self</span><span>.</span><span>vals</span> <span>=</span> <span>[]</span>  <span># flat memory with values
</span>        <span>self</span><span>.</span><span>grads</span> <span>=</span> <span>[]</span> <span># flat memory with gradients
</span>
    <span>def</span> <span>make_var</span><span>(</span><span>self</span><span>,</span> <span>value</span><span>):</span>
        <span>self</span><span>.</span><span>vals</span><span>.</span><span>append</span><span>(</span><span>value</span><span>)</span>
        <span>self</span><span>.</span><span>grads</span><span>.</span><span>append</span><span>(</span><span>0.</span><span>)</span>
        <span>return</span> <span>VarInd</span><span>(</span><span>len</span><span>(</span><span>self</span><span>.</span><span>vals</span><span>)</span> <span>-</span> <span>1</span><span>)</span>

    <span>def</span> <span>val</span><span>(</span><span>self</span><span>,</span> <span>v</span><span>:</span> <span>VarInd</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>vals</span><span>[</span><span>v</span><span>.</span><span>index</span><span>]</span>

    <span>def</span> <span>add_op</span><span>(</span><span>self</span><span>,</span> <span>kls</span><span>,</span> <span>input_vars</span><span>,</span> <span>output_vars</span><span>):</span>
	    <span># translate variable to indices. self.ops keeps only indices
</span>        <span>self</span><span>.</span><span>ops</span><span>.</span><span>append</span><span>((</span><span>kls</span><span>,</span> <span>[</span><span>x</span><span>.</span><span>index</span> <span>for</span> <span>x</span> <span>in</span> <span>input_vars</span><span>],</span> <span>[</span><span>x</span><span>.</span><span>index</span> <span>for</span> <span>x</span> <span>in</span> <span>output_vars</span><span>]))</span>        
        
    <span>def</span> <span>sum</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>vars</span><span>):</span>
        <span>res</span> <span>=</span> <span>self</span><span>.</span><span>make_var</span><span>(</span><span>sum</span><span>(</span><span>self</span><span>.</span><span>val</span><span>(</span><span>v</span><span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vars</span><span>))</span>
        <span>self</span><span>.</span><span>add_op</span><span>(</span><span>&#39;sum&#39;</span><span>,</span> <span>vars</span><span>,</span> <span>[</span><span>res</span><span>])</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>prod</span><span>(</span><span>self</span><span>,</span> <span>var1</span><span>,</span> <span>var2</span><span>):</span>
        <span>res</span> <span>=</span> <span>self</span><span>.</span><span>make_var</span><span>(</span><span>self</span><span>.</span><span>val</span><span>(</span><span>var1</span><span>)</span> <span>*</span> <span>self</span><span>.</span><span>val</span><span>(</span><span>var2</span><span>))</span>
        <span>self</span><span>.</span><span>add_op</span><span>(</span><span>&#39;prod&#39;</span><span>,</span> <span>[</span><span>var1</span><span>,</span> <span>var2</span><span>],</span> <span>[</span><span>res</span><span>])</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>softmax</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>vars</span><span>):</span>
        <span>vals</span> <span>=</span> <span>[</span><span>self</span><span>.</span><span>val</span><span>(</span><span>v</span><span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vars</span><span>]</span>
        <span>maxval</span> <span>=</span> <span>max</span><span>(</span><span>vals</span><span>)</span>
        <span>vals</span> <span>=</span> <span>[</span><span>v</span> <span>-</span> <span>maxval</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>]</span>
        <span>denom</span> <span>=</span> <span>sum</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>v</span><span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>)</span>
        <span>res</span> <span>=</span> <span>[</span><span>self</span><span>.</span><span>make_var</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>v</span><span>)</span> <span>/</span> <span>denom</span> <span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vals</span><span>]</span>
        <span>self</span><span>.</span><span>add_op</span><span>(</span><span>&#39;softmax&#39;</span><span>,</span> <span>vars</span><span>,</span> <span>res</span><span>)</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>softplus</span><span>(</span><span>self</span><span>,</span> <span>var</span><span>):</span>
        <span>res</span> <span>=</span> <span>self</span><span>.</span><span>make_var</span><span>(</span><span>math</span><span>.</span><span>log1p</span><span>(</span> <span>math</span><span>.</span><span>exp</span><span>(</span><span>self</span><span>.</span><span>val</span><span>(</span><span>var</span><span>))</span> <span>))</span>
        <span>self</span><span>.</span><span>add_op</span><span>(</span><span>&#39;splus&#39;</span><span>,</span> <span>[</span><span>var</span><span>],</span> <span>[</span><span>res</span><span>])</span>
        <span>return</span> <span>res</span>

    <span>def</span> <span>forward_backward_external</span><span>(</span><span>self</span><span>,</span> <span>grad_var</span><span>:</span> <span>VarInd</span><span>):</span>
        <span>return</span> <span>forward_backward_optimal</span><span>(</span><span>self</span><span>.</span><span>vals</span><span>,</span> <span>self</span><span>.</span><span>grads</span><span>,</span> <span>self</span><span>.</span><span>ops</span><span>,</span> <span>grad_var_index</span><span>=</span><span>grad_var</span><span>.</span><span>index</span><span>)</span>

<span>def</span> <span>forward_backward_external</span><span>(</span>
	<span>vals</span><span>:</span> <span>list</span><span>[</span><span>float</span><span>],</span> 
	<span>grads</span><span>:</span> <span>list</span><span>[</span><span>float</span><span>],</span> 
	<span>ops</span><span>:</span> <span>list</span><span>[</span><span>tuple</span><span>[</span><span>str</span><span>,</span> <span>list</span><span>[</span><span>int</span><span>],</span> <span>list</span><span>[</span><span>int</span><span>]]],</span>
	<span>grad_var_index</span><span>:</span> <span>int</span>
<span>):</span>
    <span>v</span><span>:</span> <span>list</span><span>[</span><span>float</span><span>]</span> <span>=</span> <span>vals</span>
    <span>g</span><span>:</span> <span>list</span><span>[</span><span>float</span><span>]</span> <span>=</span> <span>grads</span>
    <span># forward pass
</span>    <span>for</span> <span>op</span><span>,</span> <span>ins</span><span>,</span> <span>outs</span> <span>in</span> <span>ops</span><span>:</span>
        <span>match</span> <span>op</span><span>:</span>
            <span>case</span> <span>&#39;sum&#39;</span><span>:</span>
                <span>v</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>sum</span><span>(</span><span>v</span><span>[</span><span>i</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>ins</span><span>)</span>
            <span>case</span> <span>&#39;prod&#39;</span><span>:</span>
                <span>v</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>v</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>v</span><span>[</span><span>ins</span><span>[</span><span>1</span><span>]]</span>
            <span>case</span> <span>&#39;splus&#39;</span><span>:</span>
                <span>v</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>math</span><span>.</span><span>log1p</span><span>(</span><span>math</span><span>.</span><span>exp</span><span>(</span> <span>v</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>))</span>
            <span>case</span> <span>&#39;softmax&#39;</span><span>:</span>
                <span>maximal</span> <span>=</span> <span>max</span><span>(</span><span>v</span><span>[</span><span>i</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>ins</span><span>)</span>
                <span>exps</span> <span>=</span> <span>[</span><span>math</span><span>.</span><span>exp</span><span>(</span><span>v</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>maximal</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>ins</span><span>]</span>
                <span>denom</span> <span>=</span> <span>sum</span><span>(</span><span>outs</span><span>)</span>
                <span>for</span> <span>i</span><span>,</span> <span>exp</span> <span>in</span> <span>zip</span><span>(</span><span>outs</span><span>,</span> <span>exps</span><span>):</span>
                    <span>v</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>exp</span> <span>/</span> <span>denom</span>

    <span>g</span><span>[</span><span>grad_var_index</span><span>]</span> <span>+=</span> <span>1</span>

	<span># backward pass
</span>    <span>for</span> <span>op</span><span>,</span> <span>ins</span><span>,</span> <span>outs</span> <span>in</span> <span>ops</span><span>[::</span><span>-</span><span>1</span><span>]:</span>
        <span>match</span> <span>op</span><span>:</span>
            <span>case</span> <span>&#39;sum&#39;</span><span>:</span>
                <span>for</span> <span>i</span> <span>in</span> <span>ins</span><span>:</span>
                    <span>g</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>g</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span>
            <span>case</span> <span>&#39;prod&#39;</span><span>:</span>
                <span>out</span><span>:</span> <span>int</span> <span>=</span> <span>outs</span><span>[</span><span>0</span><span>]</span>
                <span>in1</span><span>,</span> <span>in2</span> <span>=</span> <span>ins</span>
                <span>g</span><span>[</span><span>in1</span><span>]</span> <span>+=</span> <span>v</span><span>[</span><span>in2</span><span>]</span> <span>*</span> <span>g</span><span>[</span><span>out</span><span>]</span>
                <span>g</span><span>[</span><span>in2</span><span>]</span> <span>+=</span> <span>v</span><span>[</span><span>in1</span><span>]</span> <span>*</span> <span>g</span><span>[</span><span>out</span><span>]</span>
            <span>case</span> <span>&#39;splus&#39;</span><span>:</span>
                <span>g</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>+=</span> <span>g</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>/</span> <span>(</span><span>1</span> <span>+</span> <span>math</span><span>.</span><span>exp</span><span>(</span><span>-</span><span>v</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]))</span>
            <span>case</span> <span>&#39;softmax&#39;</span><span>:</span>
				<span>avg_grad</span> <span>=</span> <span>sum</span><span>(</span><span>v</span><span>[</span><span>j</span><span>]</span> <span>*</span> <span>g</span><span>[</span><span>j</span><span>]</span> <span>for</span> <span>j</span> <span>in</span> <span>outs</span><span>)</span>
				<span>for</span> <span>i</span><span>,</span> <span>j</span> <span>in</span> <span>zip</span><span>(</span><span>ins</span><span>,</span> <span>outs</span><span>):</span>
					<span>g</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>v</span><span>[</span><span>j</span><span>]</span> <span>*</span> <span>(</span><span>g</span><span>[</span><span>j</span><span>]</span> <span>-</span> <span>avg_grad</span><span>)</span>
</code></pre></div>  </div>
  <p>and corresponding launching code</p>
  <div><div><pre><code><span>def</span> <span>run_graph_python_and_backward</span><span>(</span><span>n_operations</span><span>,</span> <span>n_iterations</span><span>):</span>
    <span>tape</span> <span>=</span> <span>TapeInd</span><span>()</span>
    <span>nodes</span> <span>=</span> <span>[</span><span>tape</span><span>.</span><span>make_var</span><span>(</span><span>float</span><span>(</span><span>x</span><span>))</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>100</span><span>)]</span>
    
    <span>for</span> <span>op</span> <span>in</span> <span>range</span><span>(</span><span>n_operations</span><span>):</span>
        <span>match</span> <span>op</span> <span>%</span> <span>4</span><span>:</span>
            <span>case</span> <span>0</span><span>:</span> 
                <span># softplus
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>softplus</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>1</span><span>:</span> 
                <span># sum
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>sum</span><span>(</span><span>*</span><span>nodes</span><span>[</span><span>-</span><span>30</span><span>:</span><span>-</span><span>10</span><span>:</span><span>5</span><span>]))</span>
            <span>case</span> <span>2</span><span>:</span> 
                <span># prod 
</span>                <span>nodes</span><span>.</span><span>append</span><span>(</span><span>tape</span><span>.</span><span>prod</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>20</span><span>],</span> <span>nodes</span><span>[</span><span>-</span><span>10</span><span>]))</span>
            <span>case</span> <span>3</span><span>:</span> 
                <span># softmax
</span>                <span>softmaxes</span> <span>=</span> <span>tape</span><span>.</span><span>softmax</span><span>(</span><span>*</span><span>nodes</span><span>[</span><span>-</span><span>4</span><span>:])</span>
                <span>nodes</span><span>.</span><span>extend</span><span>(</span><span>softmaxes</span><span>)</span>

    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>n_iterations</span><span>):</span>
        <span>tape</span><span>.</span><span>forward_backward</span><span>(</span><span>nodes</span><span>[</span><span>-</span><span>1</span><span>])</span>
</code></pre></div>  </div>
</details>

<p>Run-time for 10k ops x 10k iterations: <strong>94 seconds</strong></p>

<p>As we see, moving all values into tape and switching to operating on indices is quite an efficient strategy. 
We still use python, but are now ~5-10 fold faster than <code>pytorch</code> or <code>jax</code>.</p>

<p>At this point, I want to mention one more experiment: code above is organized to be <code>numba</code>-friendly. 
<a href="https://numba.readthedocs.io/en/stable/">Numba</a> is famous for speeding up number crunching in python with minimal changes by providing just-in-time compilation. 
Recent addition of <code>numba.typed.List</code>  makes it possible to efficiently handle list of lists.</p>

<p>Run-time with numba, 10k ops x 10k iterations: <strong>41 second</strong>. </p>

<h3 id="lets-autograd-in-rust">Let’s autograd in rust</h3>

<p>Once we moved graph tracking to tape, we can now use something fast to run computations for us. For instance, rust. 
For rust↔python interop I’ve used a small wrapper around <a href="https://github.com/mityax/rustimport">rustimport</a>.
<code>Rustimport</code> allows to conveniently “import” a single rust file without creating a full-fledged rust project.</p>

<p>Some optimization remarks:</p>
<ul>
  <li><code>softmax</code> was a bottleneck, so I switched to creating temporary arrays on stack instead of Vecs, which required specializing on input sizes</li>
  <li>I followed rust-y approach with iterators to reduce number of boundary checks</li>
  <li>I wondered if match with multiple options checked one-by-one is slow. In synthetic tests it seemed to be relatively fast, but I wish jump table optimization was implemented here
(e.g. it is supported for <a href="https://users.rust-lang.org/t/match-statement-efficiency/4488">enums</a> in rust, 
and clang <a href="https://stackoverflow.com/questions/60109992/why-is-a-switch-not-optimized-the-same-way-as-chained-if-else-in-c-c">uses</a> this optimization in C for switch-case)</li>
</ul>

<details>
  <summary>show rust code for minimal autograd
</summary>
  <div><div><pre><code><span>// rustimport:pyo3</span>
<span>use</span> <span>pyo3</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span>


<span>// slower softmax version for larger number of inputs</span>
<span>fn</span> <span>softmax_varlength</span><span>(</span><span>vals</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span> <span>ins</span><span>:</span> <span>&amp;</span><span>[</span><span>usize</span><span>],</span> <span>outs</span><span>:</span> <span>&amp;</span><span>[</span><span>usize</span><span>])</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>max</span> <span>=</span> <span>-</span><span>1e20_f32</span><span>;</span>
    <span>let</span> <span>loc_vals</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span> <span>=</span> <span>ins</span><span>.into_iter</span><span>()</span><span>.map</span><span>(|</span><span>i</span><span>|</span> <span>{</span> <span>let</span> <span>x</span> <span>=</span> <span>vals</span><span>[</span><span>*</span><span>i</span><span>];</span> <span>max</span> <span>=</span> <span>max</span><span>.max</span><span>(</span><span>x</span><span>);</span> <span>x</span><span>}</span> <span>)</span><span>.collect</span><span>();</span>
    <span>let</span> <span>mut</span> <span>sum</span><span>:</span> <span>f32</span> <span>=</span> <span>0.0_f32</span><span>;</span>
    <span>let</span> <span>exps</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span> <span>=</span> <span>loc_vals</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>v</span><span>|</span> <span>{</span><span>let</span> <span>_</span><span>exp</span> <span>=</span> <span>f32</span><span>::</span><span>exp</span><span>(</span><span>*</span><span>v</span> <span>-</span> <span>max</span><span>);</span> <span>sum</span> <span>+=</span> <span>_</span><span>exp</span><span>;</span> <span>_</span><span>exp</span><span>})</span><span>.collect</span><span>();</span>
    <span>outs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>exps</span><span>.iter</span><span>())</span><span>.for_each</span><span>(|(</span><span>j</span><span>,</span> <span>exp</span><span>)|</span> <span>vals</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>=</span> <span>exp</span> <span>/</span> <span>sum</span> <span>);</span>
<span>}</span>


<span>// vecs are slow! so allocate slices on stack, and explicit grouping of computations also helps</span>
<span>fn</span> <span>softmax</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>vals</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span> <span>ins</span><span>:</span> <span>&amp;</span><span>[</span><span>usize</span><span>],</span> <span>outs</span><span>:</span> <span>&amp;</span><span>[</span><span>usize</span><span>])</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>loc_vals</span><span>:</span> <span>[</span><span>f32</span><span>;</span> <span>N</span><span>]</span> <span>=</span> <span>[</span><span>0_f32</span><span>;</span> <span>N</span><span>];</span>
    <span>let</span> <span>mut</span> <span>exps</span><span>:</span> <span>[</span><span>f32</span><span>;</span> <span>N</span><span>]</span> <span>=</span> <span>[</span><span>0_f32</span><span>;</span> <span>N</span><span>];</span>
    <span>let</span> <span>mut</span> <span>max</span> <span>=</span> <span>-</span><span>1e20_f32</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum</span><span>:</span> <span>f32</span> <span>=</span> <span>0</span><span>.</span><span>;</span>
    <span>for</span> <span>(</span><span>n</span><span>,</span> <span>i</span><span>)</span> <span>in</span> <span>ins</span><span>.into_iter</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
        <span>let</span> <span>v</span> <span>=</span> <span>vals</span><span>[</span><span>*</span><span>i</span><span>];</span>
        <span>loc_vals</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>v</span><span>;</span>
        <span>max</span> <span>=</span> <span>max</span><span>.max</span><span>(</span><span>v</span><span>);</span>
    <span>}</span>
    <span>for</span> <span>(</span><span>n</span><span>,</span> <span>_</span><span>i</span><span>)</span> <span>in</span> <span>ins</span><span>.into_iter</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
        <span>let</span> <span>exp</span> <span>=</span> <span>f32</span><span>::</span><span>exp</span><span>(</span><span>loc_vals</span><span>[</span><span>n</span><span>]</span> <span>-</span> <span>max</span><span>);</span>
        <span>exps</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>exp</span><span>;</span>
        <span>sum</span> <span>+=</span> <span>exp</span><span>;</span>
    <span>}</span>
    <span>let</span> <span>invsum</span> <span>=</span> <span>1.0_f32</span> <span>/</span> <span>sum</span><span>;</span>
    <span>for</span> <span>(</span><span>n</span><span>,</span> <span>j</span><span>)</span> <span>in</span> <span>outs</span><span>.into_iter</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
        <span>vals</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>=</span> <span>exps</span><span>[</span><span>n</span><span>]</span> <span>*</span> <span>invsum</span><span>;</span>
    <span>}</span>
<span>}</span>

<span>fn</span> <span>sigmoid</span><span>(</span><span>x</span><span>:</span> <span>f32</span><span>)</span> <span>-&gt;</span> <span>f32</span> <span>{</span>
    <span>1.0</span> <span>/</span> <span>(</span><span>1.0</span> <span>+</span> <span>(</span><span>-</span><span>x</span><span>)</span><span>.exp</span><span>())</span>
<span>}</span>


<span>#[pyfunction]</span>
<span>unsafe</span> <span>fn</span> <span>autograd</span><span>(</span>
    <span>vals_input</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>ops</span><span>:</span> <span>Vec</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>,</span>
    <span>input_ids</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;&gt;</span><span>,</span> 
    <span>output_ids</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;&gt;</span><span>,</span>
    <span>backward_node_id</span><span>:</span> <span>usize</span><span>,</span>
    <span>n_iteration</span><span>:</span> <span>i32</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>(</span><span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>vals</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span> <span>=</span> <span>vals_input</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>x</span><span>|</span> <span>*</span><span>x</span><span>)</span><span>.collect</span><span>();</span>
    <span>let</span> <span>mut</span> <span>grad</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span> <span>=</span> <span>vals_input</span><span>.into_iter</span><span>()</span><span>.map</span><span>(|</span><span>_</span><span>|</span> <span>0.0_f32</span><span>)</span><span>.collect</span><span>();</span>

    <span>for</span> <span>_</span> <span>in</span> <span>0</span><span>..</span><span>n_iteration</span> <span>{</span>
        <span>for</span> <span>(</span><span>i_op</span><span>,</span> <span>op</span><span>)</span> <span>in</span> <span>ops</span><span>.iter</span><span>()</span><span>.enumerate</span><span>(){</span>
            <span>let</span> <span>ins</span><span>:</span> <span>&amp;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;</span> <span>=</span> <span>&amp;</span><span>input_ids</span><span>[</span><span>i_op</span><span>];</span>
            <span>let</span> <span>outs</span><span>:</span> <span>&amp;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;</span> <span>=</span> <span>&amp;</span><span>output_ids</span><span>[</span><span>i_op</span><span>];</span>
            
            <span>match</span> <span>op</span> <span>{</span>
                <span>0</span> <span>=&gt;</span> <span>{</span>
                    <span>// softplus</span>
                    <span>let</span> <span>x</span> <span>=</span> <span>vals</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]];</span>
                    <span>let</span> <span>max</span> <span>=</span> <span>f32</span><span>::</span><span>max</span><span>(</span><span>0</span><span>.</span><span>,</span> <span>x</span><span>);</span>
                    <span>let</span> <span>min</span> <span>=</span> <span>f32</span><span>::</span><span>min</span><span>(</span><span>0</span><span>.</span><span>,</span> <span>x</span><span>);</span>
                    <span>vals</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>max</span> <span>+</span> <span>f32</span><span>::</span><span>ln_1p</span><span>(</span><span>f32</span><span>::</span><span>exp</span><span>(</span><span>min</span> <span>-</span> <span>max</span><span>));</span>
                <span>}</span>
                <span>1</span> <span>=&gt;</span> <span>{</span>
                    <span>// sum</span>
                    <span>vals</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>ins</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>i</span><span>|</span> <span>vals</span><span>.get_unchecked</span><span>(</span><span>*</span><span>i</span><span>))</span><span>.sum</span><span>();</span>
                <span>}</span>
                <span>2</span> <span>=&gt;</span> <span>{</span>
                    <span>// prod</span>
                    <span>vals</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>=</span> <span>vals</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>vals</span><span>[</span><span>ins</span><span>[</span><span>1</span><span>]];</span>
                <span>}</span>
                <span>3</span> <span>=&gt;</span> <span>{</span>
                    <span>// softmax. we will need switch-case resolution here for most common cases</span>
                    <span>match</span> <span>ins</span><span>.len</span><span>()</span> <span>{</span>
                        <span>1</span> <span>=&gt;</span> <span>{</span><span>softmax</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                        <span>2</span> <span>=&gt;</span> <span>{</span><span>softmax</span><span>::</span><span>&lt;</span><span>2</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                        <span>3</span> <span>=&gt;</span> <span>{</span><span>softmax</span><span>::</span><span>&lt;</span><span>3</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                        <span>4</span> <span>=&gt;</span> <span>{</span><span>softmax</span><span>::</span><span>&lt;</span><span>4</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                        <span>5</span> <span>=&gt;</span> <span>{</span><span>softmax</span><span>::</span><span>&lt;</span><span>5</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                        <span>_</span> <span>=&gt;</span> <span>{</span><span>softmax_varlength</span><span>(</span><span>&amp;</span><span>mut</span> <span>vals</span><span>,</span> <span>&amp;</span><span>ins</span><span>,</span> <span>&amp;</span><span>outs</span><span>)}</span>
                    <span>}</span>
                <span>}</span>
                <span>_</span> <span>=&gt;</span> <span>{</span> <span>panic!</span><span>(</span><span>&#34;&#34;</span><span>);</span> <span>}</span>
           <span>}</span>
        <span>}</span>
        <span>grad</span><span>[</span><span>backward_node_id</span><span>]</span> <span>=</span> <span>1</span><span>.</span><span>;</span>
        
        <span>for</span> <span>(</span><span>i_op</span><span>,</span> <span>op</span><span>)</span> <span>in</span> <span>ops</span><span>.iter</span><span>()</span><span>.enumerate</span><span>(){</span>
            <span>let</span> <span>ins</span><span>:</span> <span>&amp;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;</span> <span>=</span> <span>&amp;</span><span>input_ids</span><span>[</span><span>i_op</span><span>];</span>
            <span>let</span> <span>outs</span><span>:</span> <span>&amp;</span><span>Vec</span><span>&lt;</span><span>usize</span><span>&gt;</span> <span>=</span> <span>&amp;</span><span>output_ids</span><span>[</span><span>i_op</span><span>];</span>
            
            <span>match</span> <span>op</span> <span>{</span>
                <span>0</span> <span>=&gt;</span> <span>{</span>
                    <span>// softplus</span>
                    <span>grad</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>+=</span> <span>grad</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>sigmoid</span><span>(</span><span>vals</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]);</span>
                <span>}</span>
                <span>1</span> <span>=&gt;</span> <span>{</span>
                    <span>// sum</span>
                    <span>ins</span><span>.iter</span><span>()</span><span>.for_each</span><span>(|</span><span>i</span><span>|</span> <span>grad</span><span>[</span><span>*</span><span>i</span><span>]</span> <span>+=</span> <span>grad</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]);</span>
                <span>}</span>
                <span>2</span> <span>=&gt;</span> <span>{</span>
                    <span>// prod</span>
                    <span>grad</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>+=</span> <span>grad</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>vals</span><span>[</span><span>ins</span><span>[</span><span>1</span><span>]];</span>
                    <span>grad</span><span>[</span><span>ins</span><span>[</span><span>1</span><span>]]</span> <span>+=</span> <span>grad</span><span>[</span><span>outs</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>vals</span><span>[</span><span>ins</span><span>[</span><span>0</span><span>]];</span>
                <span>}</span>
                <span>3</span> <span>=&gt;</span> <span>{</span>
	                <span>// softmax</span>
                    <span>let</span> <span>avg_grad</span><span>:</span> <span>f32</span> <span>=</span> <span>outs</span><span>.iter</span><span>()</span><span>.map</span><span>(|</span><span>j</span><span>|</span> <span>grad</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>*</span> <span>vals</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>)</span><span>.sum</span><span>();</span>
                    <span>for</span> <span>(</span><span>i</span><span>,</span> <span>j</span><span>)</span> <span>in</span> <span>ins</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>outs</span><span>.iter</span><span>())</span> <span>{</span>
                        <span>grad</span><span>[</span><span>*</span><span>i</span><span>]</span> <span>+=</span> <span>vals</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>*</span> <span>(</span><span>grad</span><span>[</span><span>*</span><span>j</span><span>]</span> <span>-</span> <span>avg_grad</span><span>);</span>
                    <span>}</span>
                <span>}</span>
                <span>_</span> <span>=&gt;</span> <span>{</span> <span>panic!</span><span>(</span><span>&#34;&#34;</span><span>);</span> <span>}</span>
           <span>}</span>
        <span>}</span>        
    <span>}</span>
    <span>(</span><span>vals</span><span>,</span> <span>grad</span><span>)</span>
<span>}</span>
</code></pre></div>  </div>
</details>

<p>Run-time for 10k ops x 10k iterations: <strong>1.4 seconds</strong></p>

<p>Success: we are in the realm of interactive experiences. </p>

<h3 id="lets-autograd-in-c">Let’s autograd in C</h3>

<p>Time to implement autograd logic in C. 
For interop with python I use <a href="https://cffi.readthedocs.io/en/stable/index.html">python-cffi</a>.</p>

<p>I went bananas on optimization:</p>
<ul>
  <li>I used the fact that output nodes are placed consequentially in memory, so we pass only index of the first output</li>
  <li>number of inputs is limited to 8, and those are baked into struct as <code>int[8]</code>, not <code>int *</code>  to avoid jumps in memory</li>
  <li>dynamic stack allocations of variable size (compared to rust, those are straightforward in C)</li>
  <li><code>-O3</code>, and unsafe math: <code>-ffast-math</code>. Even experimented memory alignment and restrict-ing pointers, but no luck</li>
</ul>

<details>
  <summary>show me some code in C
</summary>
  <div><div><pre><code><span>#include &lt;math.h&gt;
</span>
<span>typedef</span> <span>struct</span> <span>{</span> 
    <span>int</span> <span>opcode</span><span>;</span>
    <span>size_t</span> <span>n_arguments</span><span>;</span> <span>// used for softmax and sum</span>
    <span>int</span> <span>ins</span><span>[</span><span>8</span><span>];</span>         <span>// at most 8 inputs</span>
    <span>int</span> <span>out</span><span>;</span>            <span>// points to the first output variable</span>
<span>}</span> <span>MyOperation</span><span>;</span>


<span>MyOperation</span> <span>*</span> <span>allocate_memory</span><span>(</span><span>int</span> <span>n_elements</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span><span>MyOperation</span> <span>*</span><span>)</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>MyOperation</span><span>)</span> <span>*</span> <span>n_elements</span><span>);</span>
<span>}</span>

<span>// stable implementation</span>
<span>double</span> <span>logaddexp</span><span>(</span><span>double</span> <span>x</span><span>,</span> <span>double</span> <span>y</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>x</span> <span>&gt;</span> <span>y</span><span>)</span> <span>{</span> <span>return</span> <span>x</span> <span>+</span> <span>log1p</span><span>(</span><span>exp</span><span>(</span><span>y</span> <span>-</span> <span>x</span><span>));</span> <span>}</span>
    <span>else</span>       <span>{</span> <span>return</span> <span>y</span> <span>+</span> <span>log1p</span><span>(</span><span>exp</span><span>(</span><span>x</span> <span>-</span> <span>y</span><span>));</span> <span>}</span>
<span>}</span>

<span>double</span> <span>sigmoid</span><span>(</span><span>double</span> <span>x</span><span>)</span> <span>{</span> <span>return</span> <span>1.0</span> <span>/</span> <span>(</span><span>1.0</span> <span>+</span> <span>exp</span><span>(</span><span>-</span><span>x</span><span>));</span> <span>}</span>

<span>void</span> <span>run_multiple_passes</span><span>(</span>
    <span>int</span> <span>n_operations</span><span>,</span>
    <span>MyOperation</span> <span>*</span><span>ops</span><span>,</span>
    <span>double</span> <span>*</span><span>values</span><span>,</span>
    <span>double</span> <span>*</span><span>grads</span><span>,</span>
    <span>int</span> <span>n_iterations</span>
<span>)</span> <span>{</span>
    <span>for</span><span>(</span><span>int</span> <span>iteration</span> <span>=</span> <span>0</span><span>;</span> <span>iteration</span> <span>&lt;</span> <span>n_iterations</span><span>;</span> <span>iteration</span><span>++</span><span>)</span> <span>{</span>
        <span>for</span><span>(</span><span>int</span> <span>operation</span> <span>=</span> <span>0</span><span>;</span> <span>operation</span> <span>&lt;</span> <span>n_operations</span><span>;</span> <span>operation</span><span>++</span><span>)</span> <span>{</span>
            <span>MyOperation</span> <span>op</span> <span>=</span> <span>ops</span><span>[</span><span>operation</span><span>];</span>
            <span>switch</span><span>(</span><span>op</span><span>.</span><span>opcode</span><span>)</span> <span>{</span>
                <span>case</span> <span>1</span><span>:</span> 
                    <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>=</span> <span>logaddexp</span><span>(</span><span>0.</span><span>,</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]]);</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>2</span><span>:</span> 
                    <span>{</span>
                        <span>double</span> <span>out</span> <span>=</span> <span>0.</span><span>;</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span><span>=</span><span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>op</span><span>.</span><span>n_arguments</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>out</span> <span>+=</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>i</span><span>]];</span>
                        <span>}</span>
                        <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>=</span> <span>out</span><span>;</span>
                    <span>}</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>3</span><span>:</span>
                    <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>=</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>*</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>1</span><span>]];</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>4</span><span>:</span>
                    <span>{</span>
                        <span>double</span> <span>maximal</span> <span>=</span> <span>-</span><span>1e20</span><span>;</span>
                        <span>size_t</span> <span>n_arg</span> <span>=</span> <span>(</span><span>size_t</span><span>)</span> <span>op</span><span>.</span><span>n_arguments</span><span>;</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n_arg</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>maximal</span> <span>=</span> <span>fmax</span><span>(</span><span>maximal</span><span>,</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>i</span><span>]]);</span>
                        <span>}</span>
                        <span>double</span> <span>exps</span><span>[</span><span>n_arg</span><span>];</span>
                        <span>double</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n_arg</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>exps</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>exp</span><span>(</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>maximal</span><span>);</span>
                            <span>sum</span> <span>+=</span> <span>exps</span><span>[</span><span>i</span><span>];</span>
                        <span>}</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n_arg</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span> <span>+</span> <span>i</span><span>]</span> <span>=</span> <span>exps</span><span>[</span><span>i</span><span>]</span> <span>/</span> <span>sum</span><span>;</span>
                        <span>}</span>
                    <span>}</span>
                    <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>  <span>// end forward</span>

        <span>// TODO set grad for target variable.</span>

        <span>for</span><span>(</span><span>int</span> <span>operation</span> <span>=</span> <span>0</span><span>;</span> <span>operation</span> <span>&lt;</span> <span>n_operations</span><span>;</span> <span>operation</span><span>++</span><span>)</span> <span>{</span>
            <span>MyOperation</span> <span>op</span> <span>=</span> <span>ops</span><span>[</span><span>n_operations</span> <span>-</span> <span>1</span> <span>-</span> <span>operation</span><span>];</span>
            <span>switch</span><span>(</span><span>op</span><span>.</span><span>opcode</span><span>)</span> <span>{</span>
                <span>case</span> <span>1</span><span>:</span> 
                    <span>grads</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>+=</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>*</span> <span>sigmoid</span><span>(</span><span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]]);</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>2</span><span>:</span> 
                    <span>{</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span><span>=</span><span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>op</span><span>.</span><span>n_arguments</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>i</span><span>]]</span> <span>+=</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span><span>];</span> <span>}</span>
                    <span>}</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>3</span><span>:</span>
                    <span>grads</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]]</span> <span>+=</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>*</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>1</span><span>]];</span>
                    <span>grads</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>1</span><span>]]</span> <span>+=</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span><span>]</span> <span>*</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>0</span><span>]];</span>
                    <span>break</span><span>;</span>
                <span>case</span> <span>4</span><span>:</span>
                    <span>{</span>
                        <span>size_t</span> <span>n_arg</span> <span>=</span> <span>(</span><span>size_t</span><span>)</span> <span>op</span><span>.</span><span>n_arguments</span><span>;</span>
                        <span>double</span> <span>avg_grad</span> <span>=</span> <span>0.0</span><span>;</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n_arg</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>avg_grad</span> <span>+=</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span> <span>+</span> <span>i</span><span>]</span> <span>*</span> <span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span> <span>+</span> <span>i</span><span>];</span>
                        <span>}</span>
                        <span>for</span><span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n_arg</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
                            <span>grads</span><span>[</span><span>op</span><span>.</span><span>ins</span><span>[</span><span>i</span><span>]]</span> <span>+=</span> <span>values</span><span>[</span><span>op</span><span>.</span><span>out</span> <span>+</span> <span>i</span><span>]</span> <span>*</span> <span>(</span><span>grads</span><span>[</span><span>op</span><span>.</span><span>out</span> <span>+</span> <span>i</span><span>]</span> <span>-</span> <span>avg_grad</span><span>);</span>
                        <span>}</span>
                    <span>}</span>
                    <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>  <span>// end backward</span>
    <span>}</span>
<span>}</span>
</code></pre></div>  </div>
</details>

<p>Run-time for 10k ops x 10k iterations: <strong>0.99 second</strong></p>

<p>I liked ergonomics of rust better, but achieving high speed in C is way easier.
Rust’s interop with python is also way more convenient.</p>

<h3 id="lets-autograd-in-c-again">Let’s autograd in C (again)</h3>

<p>Another approach I’ve taken is to ‘compile’ traced graph to C.
So python produces a long C file where operations are called one-by-one with explicit indices, something like</p>
<div><div><pre><code><span>...</span>
<span>vals</span><span>[</span><span>215</span><span>]</span> <span>=</span> <span>vals</span><span>[</span><span>195</span><span>]</span> <span>*</span> <span>vals</span><span>[</span><span>205</span><span>];</span>
<span>vals</span><span>[</span><span>216</span><span>]</span> <span>=</span> <span>vals</span><span>[</span><span>196</span><span>]</span> <span>+</span> <span>vals</span><span>[</span><span>201</span><span>]</span> <span>+</span> <span>vals</span><span>[</span><span>204</span><span>];</span>
<span>...</span> <span>// etcetc, and then backward steps are also written the same way</span>
</code></pre></div></div>

<p>Source code is lengthy, outputs are enormous, and to speed up compilation we can set <code>-O0</code> in clang. Using <code>-O0</code> produces slower binaries, but interestingly <em>did not</em> speed up compilation.
Best results I got are around 1 minute for compilation and 1 second for a full run. Surprisingly, eliminating switch/case and memory lookups for arguments did not result in faster execution.</p>

<p>Given that recompilation is needed any time the graph is changed, real time experienced by user is 1 minute. That’s a no go.</p>

<h3 id="assembly">Assembly</h3>

<p>In this endeavor to get maximal speed, I decided to go down to assembly. Otherwise it feels like an incomplete journey. 
We can map a computational graph to just a set of low-level instruction, and avoid “costly” compilation.
These days x86/64 is not a king anymore, but neither armv7/armv8 is — 
and writing assembly for several architectures is totally unreasonable.</p>

<p>So … how about using webassembly? It is low-level, fast to compile, and still cross-platform. Projects like <code>wasmer</code>/<code>wasmtime</code> allow interacting with wasm code from other languages.
That’s my first encounter with WASM, and I’ve got quite positive impression: WASM mixes lisp-style syntax (for efficient streaming parsing) and execution model of stack machine. 
Unlike canonical stack machines, and unlike canonical assembly, WASM allows grouping expressions, e.g.</p>

<div><div><pre><code><span>;; canonical stack-machine way to compute a * b + c</span>
<span>(</span><span>local.get</span> <span>$a</span><span>)</span>
<span>(</span><span>local.get</span> <span>$b</span><span>)</span>
<span>f32.mul</span>
<span>(</span><span>local.get</span> <span>$c</span><span>)</span>
<span>f32.add</span>

<span>;; another way to say write the same, also perfectly legal in wasm</span>
<span>(</span><span>f32.add</span> 
    <span>(</span><span>f32.mul</span> <span>(</span><span>local.get</span> <span>$a</span><span>)</span> <span>(</span><span>local.get</span> <span>$b</span><span>))</span>  
    <span>(</span><span>local.get</span> <span>$c</span><span>)</span> 
<span>)</span>
</code></pre></div></div>

<p>This convenience allows writing significantly more readable code in WASM compared to ye-olde-assembly. 
Level of abstraction looks just right to me — low-level instructions, but no need to manage register allocations.</p>

<p>Webassembly is still very close to assembly in terms of instructions, i.e. there is no <code>exp</code>, <code>log</code>, let alone <code>log1p</code>  and alike. 
Fortunately, there is a WASM <a href="https://gist.github.com/going-digital/02e46c44d89237c07bc99cd440ebfa43">implementation</a> of <code>exp2</code>/<code>log2</code> by Peter Knight.</p>

<p>My major question was if speed of exponentiation is going to be sufficient, as <code>exp</code> consumes significant time in C implementation. 
Alas, in a simple benchmark computing just exponents in wasm takes ~1.9 seconds, leaving it behind rust/C. 
For reference, javascript computes the same number of exponents in 0.7 seconds.
Hence, I take WASM branding of ‘near-native speed’ with a grain of salt, at least in the context of number crunching. 
Hopefully this will improve, but for now WASM is out of competition.</p>

<h2 id="summary">Summary</h2>

<p>So, we achieved a <strong>1000X speed up</strong> compared to leading libraries.</p>

<p>I don’t find this surprising — major usecase for autograd system is manipulating large ndarrays. 
Memory management, copy elimination, device synchronization, parallelization of computations — these things are the main focus, 
and throughput of 1 million ops per second is totally reasonable for the vast majority of scenarios and users.</p>

<p>Not for me though. My scenario is totally different in terms of numbers and setup, and tensor-focused autograds are too slow.
For the problem at hand departing from the common autograd systems was the right and the only possible choice.
Exploring different options was quite fun, and my expectations were challenged several times along this exploration.</p>

<p>👋</p>

<p>❗ I’m currenlty open for new positions. Details in <a href="https://github.com/arogozhnikov">github profile</a>.</p>

  </article>

  <!-- adding temp info -->
  <!--
  <div class='job-looking' style='background: #DEF; font-size: 1.2em; padding: 30px;'  >
    Psst. Looking for a <strong>research scientist in machine learning</strong> to join your team? <br />
    Drop me an email, I'm currently open for opportunities! <a href='http://arogozhnikov.github.io/cv/AlexRogozhnikov.html' >My CV</a>.
  </div>
  -->
  <!-- end of temp info -->

</div>

      </div>
    </div></div>
  </body>
</html>
