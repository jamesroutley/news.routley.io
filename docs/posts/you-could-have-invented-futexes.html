<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tavianator.com/2023/futex.html">Original</a>
    <h1>You could have invented futexes</h1>
    
    <div id="readability-page-1" class="page">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                                
                

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<div>
<p><i></i> <time datetime="2023-04-21">2023-04-21</time>
<i></i> Tavian Barnes
<a href="https://github.com/tavianator/futex"><i></i> GitHub</a></p>
</div>
<p>The <em>futex</em> (<strong>f</strong>ast <strong>u</strong>serspace mu<strong>tex</strong>) is a Linux kernel feature designed for synchronization primitives (mutexes, condition variables, semaphores, etc.).
Like many topics in concurrency, they have a reputation for being tricky (for example, see the paper <a href="https://akkadia.org/drepper/futex.pdf"><em>Futexes Are Tricky</em></a>).
Despite that, they really are a well-motivated and simple but powerful API.
This post tries to explain that motivation, and even shows how to implement something similar yourself.</p>
<h2 id="spinlocks"><a href="#spinlocks">Spinlocks</a></h2>
<p>Let&#39;s say you&#39;ve found yourself implementing the C standard library (my condolences; hopefully this doesn&#39;t happen to you too often).
If your libc has threads, it&#39;s also going to need locks.
The easiest one to implement is probably a <a href="https://en.wikipedia.org/wiki/Spinlock">spinlock</a>, so you start there:</p>
<pre><code>#include &lt;stdatomic.h&gt;

typedef atomic_flag spinlock_t;

#define SPINLOCK_INITIALIZER ATOMIC_FLAG_INIT

void spin_lock(spinlock_t *lock) {
    while (atomic_flag_test_and_set_explicit(lock, memoy_order_acquire)) {
        // spin...
    }
}

void spin_unlock(spinlock_t *lock) {
    atomic_flag_clear(lock, memory_order_release);
}
</code></pre>
<p>This is not the best spinlock implementation (it could be more efficient with <a href="https://rigtorp.se/spinlock/">TTAS</a>, or more fair as a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a>), but it works.
Maybe you&#39;re not a memory ordering expert, but <code>acquire</code> sounds right for <em>acquiring</em> a lock, and <code>release</code> sounds right for <em>releasing</em> it, so that&#39;s probably correct (it is).</p>
<h2 id="mutexes"><a href="#mutexes">Mutexes</a></h2>
<p>Spinlocks are great when they don&#39;t actually have to spin.
But as soon as two threads are contending for the same lock, the one that loses the race starts spinning, at 100% CPU utilization, running up your power bill/killing your battery and contributing to global warming.
It would be better for the spinning thread to go to sleep, using 0% CPU, until the lock gets unlocked.</p>
<p>Okay, but how do you make a thread &#34;go to sleep&#34;?
You could literally <code>sleep(1)</code>, but that&#39;s way too much latency.
You could try <code>usleep(1)</code>, but then you&#39;re waking up a million times a second.
Ideally, we would go to sleep <em>indefinitely</em>, and get whoever unlocks the lock to wake us up.</p>
<p>There&#39;s a few ways to implement the &#34;<em>go to sleep</em>&#34; and &#34;<em>wake another thread up</em>&#34; operations, but they all involve system calls.
You might have heard that syscalls are slow, particularly since <a href="https://www.brendangregg.com/blog/2018-02-09/kpti-kaiser-meltdown-performance.html">Meltdown</a>/<wbr/><a href="https://www.phoronix.com/review/3-years-specmelt">Spectre</a>, so you want to avoid them when you can.
That means</p>
<ul>
<li><code>mutex_lock()</code> should avoid sleeping if possible, and</li>
<li><code>mutex_unlock()</code> should avoid waking anyone up if no one&#39;s asleep</li>
</ul>
<p>Whether any threads are asleep is a third state (in addition to <em>locked</em> and <em>unlocked</em>), so we can&#39;t use an <code>atomic_flag</code> any more.</p>
<pre><code>typedef atomic_int mutex_t;

enum {
    UNLOCKED,
    LOCKED,
    SLEEPING,
};

#define MUTEX_INITIALIZER UNLOCKED
</code></pre>
<p>Moving from the <code>UNLOCKED</code> to the <code>LOCKED</code> state is cheap, so that&#39;s the first thing we try.
Otherwise, we move to the <code>SLEEPING</code> state, and wait to be woken up.</p>
<pre><code>void mutex_lock(mutex_t *mutex) {
    int old = UNLOCKED;
    if (atomic_compare_exchange_weak_explicit(
        mutex, &amp;old, LOCKED,
        memory_order_acquire,  // Memory order if it succeeds
        memory_order_relaxed)) // Memory order if it fails
    {
        return;
    }

    while (true) {
        old = atomic_exchange_explicit(mutex, SLEEPING, memory_order_acquire);
        if (old == UNLOCKED) {
            return;
        }
        // üêõ
        go_to_sleep();
    }
}

void mutex_unlock(mutex_t *mutex) {
    int old = atomic_exchange_explicit(mutex, UNLOCKED, memory_order_release);
    if (old == SLEEPING) {
        wake_someone_up();
    }
}
</code></pre>
<p>You might have spotted a bug in this code: if one thread runs <code>wake_someone_up()</code> while another is at the line marked üêõ, before <code>go_to_sleep()</code> gets called, then no one will wake up (because no one is asleep yet).
Then when <code>go_to_sleep()</code> does get called, it might sleep forever, as no one else will wake it up.
This condition is known as a <em>lost wakeup</em>, and left untreated, would cause a deadlock.</p>

<div id="race-1">
<pre><code><span>// mutex_lock()
</span><span>old = exchange(mutex, SLEEPING, acquire);
</span><span>if (old == UNLOCKED) {
</span><span>    return;
</span><span>}
</span><span>// üêõ
</span><span>go_to_sleep();
</span><span></span></code></pre>
<pre><code><span>// mutex_unlock()
</span><span>old = exchange(mutex, UNLOCKED, release);
</span><span>if (old == SLEEPING) {
</span><span>    wake_someone_up();
</span><span>}
</span><span></span></code></pre>
</div>


<p>It&#39;s not obvious how to fix this.
We could try to detect the race and avoid sleeping, but that just moves the race window, rather than closing it completely.</p>
<div id="race-2">
<pre><code><span>// mutex_lock()
</span><span>old = exchange(mutex, SLEEPING, acquire);
</span><span>if (old == UNLOCKED) {
</span><span>    return;
</span><span>}
</span><span>if (load(mutex, relaxed) == SLEEPING) {
</span><span>    // üêõ
</span><span>    go_to_sleep();
</span><span>}
</span><span></span></code></pre>
<pre><code><span>// mutex_unlock()
</span><span>old = exchange(mutex, UNLOCKED, release);
</span><span>if (old == SLEEPING) {
</span><span>    wake_someone_up();
</span><span>}
</span><span></span></code></pre>
</div>

<p>If you had an <em>atomic</em> version of</p>
<pre><code>if (atomic_load_explicit(mutex, memory_order_relaxed) == SLEEPING) {
    go_to_sleep();
}
</code></pre>
<p>so that the wakeup could not possibly happen between the <code>if</code> and the <code>go_to_sleep()</code>, that would fix the bug.
That&#39;s what a futex is!</p>
<h2 id="futexes"><a href="#futexes">Futexes</a></h2>
<p>A minimal futex API looks something like this:</p>
<pre><code>// Atomically check if `*futex == value`, and if so, go to sleep
void futex_wait(atomic_int *futex, int value);

// Wake up a thread currently waiting on `futex`
void futex_wake(atomic_int *futex);
</code></pre>
<p>Your mutex implementation could use them like this:</p>
<pre><code>void mutex_lock(mutex_t *mutex) {
    ...

    while (true) {
        old = atomic_exchange_explicit(mutex, SLEEPING, memory_order_acquire);
        if (old == UNLOCKED) {
            return;
        }
        futex_wait(mutex, SLEEPING);
    }
}

void mutex_unlock(mutex_t *mutex) {
    int old = atomic_exchange_explicit(mutex, UNLOCKED, memory_order_release);
    if (old == SLEEPING) {
        futex_wake(mutex, 1);
    }
}
</code></pre>
<p>This implementation is finally bug-free (I hope, anyway; after all, <em>futexes are tricky</em>).
You could implement <code>futex_wait()</code> and <code>futex_wake()</code> using the <code>futex()</code> system call, but it&#39;s instructive to implement them a different way: with <a href="https://en.wikipedia.org/wiki/Signal_(IPC)">signals</a>.
<code>futex_wait()</code> will go to sleep until a signal arrives, and <code>futex_wake()</code> will send a signal to the waiting thread(s).
To do this, we&#39;ll keep track of the waiting threads on a <em>wait queue</em>:</p>
<pre><code>// A single waiting thread
struct waiter {
    // The waiting thread
    pthread_t thread;
    // The futex it&#39;s waiting on
    atomic_int *futex;
    // A linked list of waiters.
    struct waiter *prev, *next;
};

// A wait queue
struct waitq {
    // Lock that protects the wait queue (can&#39;t be a mutex,
    // since we&#39;re implementing mutexes)
    spinlock_t lock;
    // A circular linked list of waiters
    struct waiter list;
};

// The global wait queue
struct waitq waitq = {
    .lock = SPINLOCK_INITIALIZER,
    .list = {
        .prev = &amp;waitq.list,
        .next = &amp;waitq.list,
    },
};
</code></pre>
<p><code>futex_wait()</code> adds the calling thread to the wait queue and sleeps until a signal arrives with <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/sigwait.html"><code>sigwait()</code></a>.</p>
<pre><code>void futex_wait(atomic_int *futex, int value) {
    spin_lock(&amp;waitq.lock);

    struct waiter *head = &amp;waitq.list;
    struct waiter waiter = {
        .thread = pthread_self(),
        .futex = futex,
        .prev = head,
        .next = head-&gt;next,
    };

    // Insert the waiter into the list
    waiter.prev-&gt;next = &amp;waiter;
    waiter.next-&gt;prev = &amp;waiter;

    // Block the signal in the current thread so we can wait for it
    sigset_t old_mask, mask;
    sigemptyset(&amp;mask);
    sigaddset(&amp;mask, SIGCONT);
    pthread_sigmask(SIG_BLOCK, &amp;mask, &amp;old_mask);

    while (atomic_load_explicit(futex, memory_order_relaxed) == value) {
        // Unlock the wait queue before we sleep
        spin_unlock(&amp;waitq.lock);
        // Sleep until we receive SIGCONT
        int sig;
        sigwait(&amp;mask, &amp;sig);
        // Re-lock the wait queue
        spin_lock(&amp;waitq.lock);
    }

    // Remove ourselves from the wait queue
    waiter.prev-&gt;next = waiter.next;
    waiter.next-&gt;prev = waiter.prev;

    // Restore the old signal mask
    pthread_sigmask(SIG_SETMASK, &amp;old_mask, NULL);

    spin_unlock(&amp;waitq.lock);
}
</code></pre>
<p><code>futex_wake()</code> walks the wait queue, signalling any threads waiting on the same futex:</p>
<pre><code>void futex_wake(atomic_int *futex) {
    spin_lock(&amp;waitq.lock);

    struct waiter *head = &amp;waitq.list;
    for (struct waiter *waiter = head-&gt;next; waiter != head; waiter = waiter-&gt;next) {
        if (waiter-&gt;futex == futex) {
            pthread_kill(waiter-&gt;thread, SIGCONT);
            break;
        }
    }

    spin_unlock(&amp;waitq.lock);
}
</code></pre>
<p>You might think this has the same race condition as before, that if <code>pthread_kill()</code> happens right before <code>sigwait()</code>, the wakeup will be lost.
But in fact, because we blocked <code>SIGCONT</code> first, it will remain pending, and <code>sigwait()</code> will return immediately.</p>
<div id="race-3">
<pre><code><span>// futex_wait()
</span><span>while (load(futex, relaxed) == value) {
</span><span>    spin_unlock(&amp;waitq.lock);
</span><span>    int sig;
</span><span>    sigwait(&amp;mask, &amp;sig);
</span><span>    spin_lock(&amp;waitq.lock);
</span><span>}
</span><span></span></code></pre>
<pre><code><span>// futex_wake()
</span><span>spin_lock(&amp;waitq.lock);
</span><span>...
</span><span>pthread_kill(waiter-&gt;thread, SIGCONT);
</span><span>...
</span><span>spin_unlock(&amp;waitq.lock);
</span><span></span></code></pre>
</div>

<h2 id="scaling"><a href="#scaling">Scaling</a></h2>
<p>The above implementation works, but the single wait could cause a lot of unnecessary contention if many threads are waiting on different futexes.
We could reduce that contention by having multiple wait queues, and using a hash function to assign each futex to a (hopefully) different wait queue.</p>
<pre><code>struct waitq table[TABLE_SIZE];

// Use the address of the futex to pick a wait queue
struct waitq *get_waitq(atomic_int *futex) {
    size_t i = hash((uintptr_t)futex);
    return &amp;table[i % TABLE_SIZE];
}
</code></pre>
<p>That&#39;s basically what the <a href="https://github.com/torvalds/linux/blob/master/kernel/futex/core.c">actual futex implementation</a> does.
It&#39;s also what WebKit&#39;s <a href="https://webkit.org/blog/6161/locking-in-webkit/">ParkingLot</a> does, and in general it&#39;s a very useful trick for reducing contention.</p>

                    </main>

                    
                </div>
            </div>

            

        </div>






        
        
        

        
        
        

        <!-- Custom JS scripts -->


    </div>
    

</div>
  </body>
</html>
