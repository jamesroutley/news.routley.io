<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.frontiersin.org/articles/10.3389/fnbeh.2021.634158/full">Original</a>
    <h1>Paper vs. Devices: Brain Activation Differences During Memory Retrieval</h1>
    
    <div id="readability-page-1" class="page"><div>
<h2>Introduction</h2>
<p>The properties of human memory have been investigated with several approaches, including clinical, psychological, and neuroimaging studies (<a href="#B34">Tulving, 2002</a>; <a href="#B33">Schacter et al., 2007</a>; <a href="#B21">Miyashita, 2019</a>). It remains to be elucidated how brain activations during retrieval processes are modulated by different encoding procedures, because it has been reported that retrieval performances on paired words became worse when the categorically similar target words were simultaneously encoded, suggesting the importance of the context-dependent encoding (<a href="#B26">Nairne, 2002</a>; <a href="#B12">Goh and Lu, 2012</a>). It is also possible that the manner with which specific information is encoded—e.g., whether by using a paper notebook, computer, or mobile device—may affect retrieval processes. A recent behavioral study showed that students who took longhand notes performed better on conceptual questions than those who took notes on laptop computers (<a href="#B25">Mueller and Oppenheimer, 2014</a>). A reasonable explanation for this interesting finding would be that the use of a paper notebook enables users to summarize and reframe information in their own words for encoding, while the use of a laptop tends to encourage them to write down information more passively (i.e., more nearly verbatim). The former processes thus naturally ensure deeper and more solid encoding <i>via</i> the active process of making notes. Moreover, it has been reported that longhand note-taking enhanced the performance of students on recognition of memorized words, even though typing on a computer keyboard allowed greater speed (<a href="#B1">Aragón-Mendizábal et al., 2016</a>).</p>
<p>Another possible explanation for the superiority of longhand note-taking for conceptual understanding is related to the use of paper for writing/reading since a behavioral study reported the superiority of paper to computer screens in terms of reading comprehension (<a href="#B36">Wästlund et al., 2005</a>; <a href="#B20">Mangen et al., 2013</a>). These studies indicated the importance of visual and tactile cues for perceiving <i>constant</i> physical sizes and spatial locations, because “the material substrate of paper provides physical, tactile, spatiotemporally fixed cues to the length of the text” (<a href="#B20">Mangen et al., 2013</a>). We hypothesized that the use of a paper notebook, together with longhand note-taking, would enhance both memory encoding and later retrieval processes that could then be investigated at the brain level. More specifically, the utilization of the paper likely enhances the processes of associating episodic (<i>what</i>) and spatial (<i>where</i>) information, especially in the hippocampus, given its well-established role in the integration of what/where/when information (<a href="#B4">Broadbent et al., 2004</a>; <a href="#B7">Eichenbaum, 2004</a>; <a href="#B5">Chadwick et al., 2010</a>).</p>
<p>To address this issue, we compared three groups of participants who used a paper notebook (Note), electronic tablet (Tablet), or smartphone (Phone) during the encoding phase. Participants in the Tablet group used a stylus pen, thereby controlling for the effects of longhand writing with a pen in the Note group. It should be noted that physical sizes and spatial locations of a document remain constant for a paper notebook, whereas they become variable on the display of a tablet or smartphone. Moreover, not only the physical interaction of the hand with the pen/paper during note-taking but the actual writing of notes relative to each page of the real paper provides more concrete encoding information, because that information can be easily erased and updated by new information on the physically same screen of a tablet or smartphone.</p>
<p>We asked participants to write down scheduled appointments, and then, after one hour during which they performed an interference task, we conducted a retrieval task in which we tested participants’ recognition memory of those appointments (<a href="#F1">Figure 1</a>). We further hypothesized that the interaction with physical paper, rather than the mental editing/preparation of the notes or the physical act of handwriting, provides episodic and spatial information of notes relative to each page of real paper, together with visual/tactile information from the paper. These properties and cues of papers could help to retrieve specific information, and thus lead to increased activations in specified brain regions for the Note group, compared with the other groups using mobile devices lacking such processes.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g001.jpg" name="figure1" target="_blank">
<img id="F1" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g001.jpg"/></a></p><p><strong>Figure 1</strong>. Recording and retrieval of schedule information. Participants first read dialogues (in Japanese), then extracted scheduled appointments contained in the dialogues, and wrote them down with a paper notebook (<i>Note</i> group), electronic tablet (<i>Tablet</i> group), or smartphone (<i>Phone</i> group). This procedure reproduces the daily making of to-do lists and naturally involves encoding processes. The upper panel shows a typical example (English translation) written by a participant. After an hour including an interference task, the participants were asked to answer questions about the appointments and reported their level of confidence in their answer to each question. The lower panel shows a typical trial in this retrieval task.</p>
</div> 


<p>It has been proposed that the hippocampus and the prefrontal cortex support complementary functions in episodic memory and that the bidirectional information flow between these regions may play a crucial role in integrating and consolidating individual information (<a href="#B23">Moscovitch et al., 2016</a>; <a href="#B8">Eichenbaum, 2017</a>). A previous functional magnetic resonance imaging (fMRI) study reported that episodic memory of a word or picture is related to a functional network that includes the left posterior precuneus and the left lateral prefrontal cortex (<a href="#B19">Lundstrom et al., 2003</a>). On the other hand, language function is critically involved in human episodic memory, and some language-related regions would be recruited during both memory encoding and retrieval. The left lateral premotor cortex (LPMC) and left opercular/triangular parts of the inferior frontal gyrus (F3op/F3t) are suggested to have central roles in syntactic processing, whereas the left angular/supramarginal gyri (AG/SMG) make a major contribution to lexical processing (<a href="#B31">Sakai, 2005</a>). Moreover, the right frontal cortex was identified as a supportive region for syntactic processing (<a href="#B17">Kinno et al., 2014</a>). Activations in these regions would be observed during memory retrieval because fMRI studies showed that the hippocampus and language-related regions involved in the encoding phase were also activated during the retrieval phase (<a href="#B30">Rugg et al., 2008</a>). The retrieval task we used critically involved episodic memory of scheduled appointments, and thus activations in these regions would be increased more for the Note group than the other groups.</p>
<h2>Materials and Methods</h2>
<h3>Participants</h3>
<p>University student volunteers (48 native Japanese speakers, 18 females) aged 18–29 years were openly recruited from multiple sources, including the University of Tokyo and Sophia University, as well as the participant pool of the NTT Data Institute of Management Consulting. The laterality quotient (LQ) was measured according to the Edinburgh inventory (<a href="#B27">Oldfield, 1971</a>); all participants but one were right-handed, and the exception was both-handed (LQ: −14). As stated above, the participants were divided into three groups: Note, Tablet, and Phone groups (<a href="#T1">Table 1</a>). These three groups were age- and LQ-matched (Kruskal–Wallis test, <i>p</i> &gt; 0.1), as well as gender-matched (Fisher’s exact test for count data, <i>p</i> = 0.17). Each participant first answered a questionnaire on their daily use of paper notebooks, electronic tablets, and smartphones for scheduling in an academic or personal context (seven-point scale for each). Based on this result, electronic tablet users were assigned to the Tablet group, and smartphone users (those on the highest scale for smartphone use) were assigned to either the Tablet or Phone group. To estimate short-term memory ability, we used the number-letter sequencing in the Wechsler Adult Intelligence Scale—Fourth Edition (<a href="#B6">Drozdick et al., 2012</a>), and the maximum length of memorized sequences was not significantly different among the three groups (<i>p</i> = 0.4). All participants in the Note group used paper notebooks for daily schedule management, whereas eight and seven participants in the Tablet and Phone groups, respectively, also used paper notebooks for that purpose. To control the experience and accustomedness of using paper notebooks for daily schedule management, these 15 participants (with eight females) were separately designated the <i>Device</i> group, which was used in behavioral and activation analyses.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t001.jpg" name="Table1" target="_blank">
<img id="T1" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t001.jpg"/></a></p><p><strong>Table 1</strong>. Basic data on participants.</p></div> 


<p>Before they participated in the study, the nature and possible consequences of the studies were explained to each participant and written informed consent was obtained afterward. None of the participants had a history of neurological or psychological disorders. Approval for the experiments was obtained from the institutional review board of the University of Tokyo, Komaba.</p>
<h3>Stimuli and Tasks</h3>
<p>Two sets of written dialogues between two or three persons (a set of dialogues on academic matters and a set on personal matters) were presented to the participants, who were asked to imagine that they were participating in those dialogues. There were seven daily scheduled appointments for the academic context and seven for the personal context (in February and March, respectively). While silently reading the dialogues, participants were asked to enter each of these appointments into a monthly calendar (<a href="#F1">Figure 1</a>, upper panel). The participants used either a paper notebook [Noritsu NOLTY Notebook (2017), size 20.6 × 17.6 cm<sup>2</sup> when opened], an electronic tablet [iPad Pro 10.5 inch (2017), screen size 21.4 × 16.1 cm<sup>2</sup> in landscape orientation], or a smartphone (Google Nexus 5 LG-D821, screen size 6.2 × 10.9 cm<sup>2</sup> in portrait orientation), where the paper notebook and electronic tablet were similar in physical layout (size and orientation). All three types of calendars had a day, week, and month view, but we used only the month view. In the case of the paper notebook and electronic tablet, appointments could only be viewed and edited individually in the relevant month (i.e., discrete views). In the smartphone, individual weeks could be viewed and edited by swiping continuously (i.e., continuous views). This difference was notable, in that schedule information would be encoded relative to the <i>spatial configuration</i> of one month (see <a href="#F1">Figure 1</a>) for the paper notebook and electronic tablet.</p>
<p>Regarding input methods, a four-color pen was used to write in the paper notebook [the use of color(s) was up to each participant], and a stylus pen was used to write on the electronic tablet with a free choice of multiple colors (without using a virtual keyboard). In the case of the smartphone, the text was written by either flick input with the finger(s) or by using a virtual keyboard. In Japanese, there are three types of characters (<i>hiragana</i>, <i>katakana</i>, and <i>kanji</i>; kanji basically consists of Chinese characters), and kana-kanji transformation is usually used for inputs in mobile devices and computers (kana-kanji transformation converts a limited number of hiragana to vast numbers of kanji by requiring users to select appropriate kanji from multiple candidates). The flick input utilizes a telephone keypad with a three by four layout, and one hiragana character can be selected by either tapping a keypad or flicking from a keypad to one of four directions (up, down, left, or right) to enter one of five hiragana characters sharing the same initial consonant.</p>
<p>We measured the time required by participants to write down the appointments, but we set no time limit. When the participants finished writing down, they were instructed to review the calendar for 30 s. Then, after the retention period for an hour including an interference task, participants were asked to recall those appointments in a retrieval task; the experimental purpose of writing down the appointments was not disclosed to them. The interference task involved listening comprehension; participants were informed that they would hear a story, and then be asked about its contents while lying in an MRI scanner. We used the first 6 min of a narrated version of a Japanese classic short story called “<i>Ma-jutsu</i> (<i>Magic</i>)” (written by Ryūnosuke Akutagawa, narrated by Takeshi Sasaki, and published by Pan Rolling, Japan). This story was unfamiliar to all participants. The auditory stimuli were presented through a headphone and participants were not permitted to take notes while listening. Sixteen questions about the detailed contents of the story were displayed inside the scanner (two questions per run), and the participants pressed one of four buttons to select the right answer.</p>
<p>After a short break outside the scanner to adjust the time between the encoding and retrieval phases to 1 h, participants performed a retrieval task inside the scanner (<a href="#F1">Figure 1</a>, lower panel), in which 16 questions about detailed contents of the appointments were displayed (two questions per run). Out of the 16 questions, seven required recalling of the relationships between multiple appointments, one required the conversion from the date to the day of the week (using the spatial information of the calendar), and three required recalling from similar or confusing appointments. The remaining five questions were more straightforward and thus considered as the <i>easier</i> questions. In each trial, a question was presented with four choices, and the participants pressed a button to select the right answer within 10 s. After an interval of 1 s, participants reported their level of confidence (1–4 scale, 4 = very confident) for that answer by pressing one of four buttons within 2 s. These responses were used to assess the correctness of each participant’s self-evaluation, where the true positive rate vs. the false positive rate was plotted for each of the four levels of confidence. By connecting these plots, we obtained a receiver operating characteristics curve (<a href="#B9">Fawcett, 2006</a>), and we used the area under the curve (AUC) for this assessment (0 = perfectly wrong; 0.5 = no distinction; 1 = perfectly correct).</p>
<p>As a control condition, we added a 2-back task into the run with the retrieval task. In each trial of the 2-back task, two different non-words, each with three Japanese characters, were sequentially displayed (each for 2 s). These characters were randomly selected from those used in the retrieval tasks, where the same type of characters (either hiragana, katakana, or kanji) was presented in a block of trials. Then four choices were shown for 5 s with a new non-word to be remembered. The correct answer was the non-word that appeared 2-back before but in a different order of three characters. There were two to four continuous trials with button pressings in each block.</p>
<p>Each run consisted of three 2-back blocks and two retrieval task trials, in which a 2-back block always started first, and the 2-back blocks and retrieval task trials were alternated. As fMRI events, we estimated the 6-s memory retrieval phase [determined by response times (RTs)] and the subsequent 4-s <i>post hoc</i> period from each 10-s period of the retrieval task, as well as a 5-s event for the 2-back task. With regards to contrasts between events, we always applied an exclusive mask of negative activations for the control conditions (one-sample <i>t-test</i>, uncorrected <i>p</i> &lt; 0.05). During the scans, the participants wore earplugs and an eyeglass-like MRI-compatible display (resolution = 800 × 600 pixels, framerate = 60 fps; VisuaStim Digital, Resonance Technology Inc., Northridge, CA, USA). The stimuli were all presented in yellow letters on a black background. For fixation, a small red cross was shown at the center of the screen when a stimulus was not shown. The stimulus presentation and collection of behavioral data (accuracy and RTs) were controlled using the Presentation software package (Neurobehavioral Systems, Albany, CA, USA).</p>
<h3>MRI Data Acquisition</h3>
<p>The MRI scans were conducted in a 3.0 T scanner (Signa HDxt; GE Healthcare, Milwaukee, WI, USA) with a bird-cage head coil. Each participant was in a supine position, and his or her head was immobilized inside the coil. As regards the structural images, high-resolution T1-weighted images of the whole brain (136 axial slices, 1 × 1 × 1 mm<sup>3</sup>) were acquired with a three-dimensional fast spoiled gradient-echo (3D FSPGR) acquisition [repetition time (TR) = 8.6 ms, echo time (TE) = 2.6 ms, flip angle (FA) = 25°, field of view (FOV) = 256 × 256 mm<sup>2</sup>]. With respect to the time-series data of fMRI, we used a gradient-echo echo-planar imaging (EPI) sequence (TR = 2 s, TE = 30 ms, FA = 78°, FOV = 192 × 192 mm<sup>2</sup>, resolution = 3 × 3 mm<sup>2</sup>). We scanned a set of 30 axial slices that were 3-mm thick with a 0.5-mm gap, covering the range of −38.5 to 66 mm from the line of the anterior commissure to the posterior commissure (AC-PC). In a single scanning run, we obtained 45 volumes and dropped the initial four volumes from analyses due to MR signal increases.</p>
<h3>fMRI Data Analyses</h3>
<p>The fMRI data were analyzed in a standard manner using SPM12 statistical parametric mapping software (Wellcome Trust Center for Neuroimaging; <a href="#B10">Friston et al., 1994</a>) implemented on MATLAB (Math Works, Natick, MA, USA). The acquisition timing of each slice was corrected using the middle slice (the 15th slice chronologically) as a reference for the functional images. We spatially realigned each volume to the first volume of consecutive runs, and a mean volume was obtained. We set the threshold of head movement during a single run as follows: within a displacement of 2 mm in any of the three directions, and a rotation of 1.4° around any of the three axes. These thresholds were empirically determined in our previous studies (<a href="#B16">Kinno et al., 2008</a>). If a run included one or several images over this threshold, we replaced the outlying image with an interpolated image, which was the average of the chronologically former and latter ones, and conducted the realignment procedure again. The realigned data were resliced every 3 mm using seventh-degree B-spline interpolation.</p>
<p>Each individual’s structural image was matched with the mean functional image generated during realignment. The resultant structural image was spatially normalized to the standard brain space as defined by the Montreal Neurological Institute (MNI) using the extended version of the unified segmentation algorithm with light regularization; this is a generative model that combines tissue segmentation, bias correction, and spatial normalization in a single model (<a href="#B2">Ashburner and Friston, 2005</a>). The resultant deformation field was applied to each realigned functional image to be spatially normalized with non-linear transformation. All normalized functional images were then smoothed by using an isotropic Gaussian kernel of 9 mm full-width at half maximum (FWHM). Low-frequency noise was removed by high-pass filtering at 1/128 Hz.</p>
<p>In the first-level analysis (i.e., the fixed-effects analysis within a participant), each participant’s hemodynamic responses were modeled for the following types of events: initial 2-back trials with encoding alone, other 2-back trials, 6-s memory retrieval phase of retrieval trials, and 4-s <i>post hoc</i> period of retrieval trials. These event types were separately set for each group. Each event was modeled with the boxcar function overlaid with a hemodynamic response function. To minimize the effects of head movement, the six realignment parameters obtained from preprocessing were included as a nuisance factor in a general linear model.</p>
<p>These modeled responses were then generated in a general linear model for each participant and used for the inter-subject comparison in a second-level analysis (i.e., the random-effects analysis for a group). To examine the activation of the regions in an unbiased manner, we adopted whole-brain analyses. For statistical analyses, a two-way ANOVA (group × event type) with <i>t</i>-tests was performed with three nuisance factors (age, gender, and laterality quotient), where the statistical threshold was set to family-wise error (FWE) corrected <i>p</i> &lt; 0.05 for the voxel level. For the anatomical identification of activated regions, essentially we used the Anatomical Automatic Labeling (AAL) method (<a href="#B35">Tzourio-Mazoyer et al., 2002</a>) and the labeled data as provided by Neuromorphometrics Inc., under academic subscription. In addition to whole-brain analyses, we adopted analyses of each region of interest (ROI) by using the MarsBaR-toolbox, in which an ROI was taken from a cluster identified by the “retrieval—2-back” contrast for all participants, which were further extracted with an AAL mask of each region.</p>
<h2>Results</h2>
<h3>Behavioral Results</h3>
<p>We first compared the amounts of time required to write down the scheduled appointments (i.e., the duration of schedule recording) among the Note, Tablet, and Phone groups, and we observed a significant difference by a one-way ANOVA (<i>F</i><sub>(2,45)</sub> = 6.5, <i>p</i> = 0.003; <a href="#F2">Figure 2A</a>). The duration was significantly shorter for the Note group compared to the Tablet and Phone groups combined (<i>t-test</i>, <i>t</i><sub>(46)</sub> = 3.2, <i>p</i> = 0.002). We also confirmed a significant difference between the Note and Device groups (<i>t</i><sub>(29)</sub> = 3.0, <i>p</i> = 0.003).</p>
<p>Relative to the chance level of 25% accuracy, the accuracy for the retrieval task was reliable and well below the ceiling level (<a href="#F2">Figure 2B</a>). The participants’ self-evaluation on confidence was also correct, because the AUC for the Note, Tablet, and Phone groups were 0.77 ± 0.14, 0.77 ± 0.12, and 0.74 ± 0.11, respectively, where group differences were not significant (<i>F</i><sub>(2,45)</sub> = 0.2, <i>p</i> = 0.8). The accuracy or RTs in the retrieval was not significantly different among the three groups (accuracy: <i>F</i><sub>(2,45)</sub> = 0.5, <i>p</i> = 0.6; RTs: <i>F</i><sub>(2,45)</sub> = 0.8, <i>p</i> = 0.5; <a href="#F2">Figure 2C</a>); the accuracy and RTs in the interference and 2-back tasks were also comparable among the three groups (<i>p</i> &gt; 0.4). However, we observed significant group differences when we focused on the easier questions of scheduled appointments (see “Materials and Methods” section; <a href="#F2">Figure 2B</a>). According to non-parametric tests for the data showing ceiling effects, the accuracy of the easier questions was significantly higher for the Note group than the Tablet group (Wilcoxon rank-sum test, <i>W</i> = 179, <i>p</i> = 0.04), and the difference between the Note and Device groups was marginally significant (<i>W</i> = 164, <i>p</i> = 0.06).</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g002.jpg" name="figure2" target="_blank">
<img id="F2" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g002.jpg"/></a></p><p><strong>Figure 2</strong>. Behavioral data. <strong>(A)</strong> The intergroup differences in the mean duration of schedule recording (see <a href="#F1">Figure 1</a>), together with individual data points overlapped. In addition to the three groups (Note, Tablet, and Phone), we also introduced a <i>Device</i> group, which consisted of participants who used mainly notebooks daily and were assigned to either the Tablet or Phone group. <strong>(B)</strong> Accuracy in the retrieval task. The broken line denotes the chance level of 25% accuracy. For the easier (i.e., more straightforward) questions, the Note group showed significantly higher accuracy than the Tablet group. <strong>(C)</strong> Response times (RTs) in the retrieval task. Error bars indicate standard errors of the mean. *<i>p</i> &lt; 0.05.</p>
</div> 


<p>The Tablet and Phone groups (or Device group) took more time for writing down (<a href="#F2">Figure 2A</a>), and this might be due to slower input of characters with such mobile devices (no typing on the computer keyboard). However, at least between the Note and Tablet groups, the use of a stylus pen was just similar to writing with a four-color pen, and the physical layout of a notebook or tablet was equated as much as possible (see “Materials and Methods” section). Moreover, there was ample time for every group to write down all appointments into a monthly calendar. Therefore, <i>shorter</i> amounts of time for writing down and <i>higher</i> accuracy in easier questions for the Note group suggest that those cognitive processes for the Note group were actually deeper and more solid.</p>
<p>When all participants in the three groups were combined, the accuracy in the retrieval and 2-back tasks were significantly correlated (Pearson’s correlation, <i>r</i> = 0.31, <i>t</i><sub>(46)</sub> = 2.2, <i>p</i> = 0.03). RTs showed a significant correlation as well (<i>r</i> = 0.33, <i>t</i><sub>(46)</sub> = 2.4, <i>p</i> = 0.02). These results confirm consistent immediate- and short-term memory capacities for every participant.</p>
<h3>Enhanced Activations in Bilateral Regions for the Note Group</h3>
<p>To identify brain regions specifically involved in the memory retrieval process, we directly compared activations between the 6-s memory retrieval phase and the 4-s <i>post hoc</i> period from each 10-s period of the retrieval task, denoted as “First 6 s—Last 4 s” contrast. This was because the mean RTs were less than 6 s for all but two participants (see <a href="#F2">Figure 2C</a>). With this stringent contrast during the same stimulus presentation and task, dynamic signal changes induced by such active retrieval processes should be revealed. As shown in <a href="#F3">Figure 3A</a>, localized activations were found bilaterally in the middle frontal gyrus, F3op/F3t, fusiform gyrus, AG/SMG, middle/inferior occipital gyrus (MOG/IOG), pallidum, and hippocampus; we also observed left-lateralized activation in the LPMC and precuneus.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g003.jpg" name="figure3" target="_blank">
<img id="F3" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g003.jpg"/></a></p><p><strong>Figure 3</strong>. Activated regions for the retrieval task. <strong>(A)</strong> Results of the “First 6 s—Last 4 s” contrast within the retrieval task period are shown for all participants. <strong>(B)</strong> Results of the “retrieval—2-back” contrast are shown for all participants. The lines indicate the locations of the sections. Localized activations were observed bilaterally in the lateral premotor cortex/opercular/triangular parts of the inferior frontal gyrus (LPMC/F3op/F3t), angular/supramarginal gyri (AG/SMG), hippocampus, precuneus, and lingual gyrus/calcarine/inferior occipital gyrus (LG/calcarine/IOG; see <a href="#T2">Table 2</a> for the list of local maxima).</p>
</div> 


<p>It is still possible that these activations reflect immediate memory processes that were necessary to solve the retrieval task; note the above-mentioned correlation between performances of the two tasks. Thus, we further compared activations in the retrieval task (10-s period) against those in the 2-back task with more demanding immediate memory, which successfully removed common factors in both tasks (<a href="#F3">Figure 3B</a>). The result of activations replicated the above-mentioned regions (<a href="#T2">Table 2</a>), providing appropriate ROIs for further analyses. Additional activations were found bilaterally in the lingual gyrus (LG) and calcarine sulcus; we also observed left-lateralized activation in the orbital part of the inferior frontal gyrus (F3O).</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t002.jpg" name="Table2" target="_blank">
<img id="T2" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t002.jpg"/></a></p><p><strong>Table 2</strong>. ROIs determined by the contrast of “retrieval—2-back” for all participants.</p></div> 


<p>We assessed percent signal changes for these ROIs, and found significant intergroup differences in the posterior hippocampus, precuneus, LG/calcarine/IOG, LPMC/F3op/F3t, and AG/SMG (<a href="#F4">Figures 4A–E</a>). Activations in the first four regions were significantly different between the Note group and the combined Tablet and Phone groups (hippocampus: <i>t</i><sub>(94)</sub> = 2.4, <i>p</i> = 0.02; precuneus: <i>t</i><sub>(94)</sub> = 2.3, <i>p</i> = 0.03; LG/calcarine/IOG: <i>t</i><sub>(94)</sub> = 2.7, <i>p</i> = 0.008; LPMC/F3op/F3t: <i>t</i><sub>(94)</sub> = 2.0, <i>p</i> = 0.05), whereas those in the last region were significantly different between the Note and Phone groups (<i>t</i><sub>(62)</sub> = 2.2, <i>p</i> = 0.03). Activations in the LG/calcarine/IOG and LPMC/F3op/F3t were also significantly different between the Note and Device groups (LG/calcarine/IOG: <i>t</i><sub>(60)</sub> = 2.2, <i>p</i> = 0.03; LPMC/F3op/F3t: <i>t</i><sub>(60)</sub> = 2.4, <i>p</i> = 0.02), even when the experience/accustomedness of using paper notebooks was equated. Moreover, we observed a significant positive correlation between the RTs in the retrieval task and the averaged signal changes in the ROIs of LPMC/F3op/F3t and AG/SMG for all participants (<i>r</i> = 0.31, <i>t</i><sub>(46)</sub> = 2.2, <i>p</i> = 0.03; <a href="#F4">Figure 4F</a>). This link between behavioral results and brain activations indicates that inner language processes were indeed involved in during memory retrieval <i>via</i> the function of the language-related regions.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g004.jpg" name="figure4" target="_blank">
<img id="F4" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g004.jpg"/></a></p><p><strong>Figure 4</strong>. Intergroup differences in brain activations for the retrieval task. <strong>(A–E)</strong> Mean percent signal changes, together with individual data points overlapped, for the three groups in the regions of interest (ROIs) of the hippocampus <strong>(A)</strong>, precuneus <strong>(B)</strong>, LG/calcarine/IOG <strong>(C)</strong>, LPMC/F3op/F3t <strong>(D)</strong>, and AG/SMG <strong>(E)</strong>. The signal changes of an ROI in each hemisphere were treated as independent samples, in reference to those in the 2-back task. Error bars indicate standard errors of the mean. *<i>p</i> &lt; 0.05. <strong>(F)</strong> A significant correlation between the RTs in the retrieval task and the averaged signal changes in the ROIs of the LPMC/F3op/F3t and AG/SMG (the language-related regions) for all participants.</p>
</div> 


<h2>Discussion</h2>
<p>Using three groups of participants who performed a schedule-recording task using a paper notebook, electronic tablet, or smartphone, followed by a retrieval task (<a href="#F1">Figure 1</a>), we obtained three major results. First, the duration of schedule recording was significantly shorter for the Note group than the Tablet and Phone groups, and accuracy was much higher for the Note group in easier (i.e., more straightforward) questions (<a href="#F2">Figure 2</a>). Because the input methods were equated as much as possible between the Note and Tablet groups, these results indicate that the cognitive processes for the Note group were actually deeper and more solid. Second, brain activations for all groups during the retrieval phase were localized in the bilateral hippocampus, precuneus, LG/calcarine/IOG, and LPMC/F3op/F3t (<a href="#F3">Figure 3</a>), confirming the involvement of verbalized memory retrieval processes for appointments. Third, activations in these regions were significantly higher for the Note group than those for the Tablet and Phone groups (<a href="#F4">Figure 4</a>). These enhanced activations for the Note group could not be explained by general cognitive loads or task difficulty, because overall task performances were similar among the groups. Brain activations for the Tablet and Phone groups were similar, where the difference in input methods did not affect the results. On the other hand, the Note and Tablet groups showed a clear difference in brain activations even if the physical layout and input methods were controlled. Brain activations were significantly different also between the Note and Device groups, even when accustomedness to paper notebooks or mobile devices was equated for daily usage. The significant superiority in both accuracy and activations for the Note group suggested that the use of a paper notebook promoted the acquisition of rich encoding information and/or spatial information of real papers (see the “Introduction” section) and that this information could be utilized as effective retrieval clues, leading to higher activations in these specific regions.</p>
<p>The hippocampus is crucially involved not only in memory encoding and retrieval processes but also in spatial memory itself. The hippocampal-entorhinal cortex provides spatial representations, as demonstrated by grid cells (<a href="#B13">Hartley et al., 2014</a>; <a href="#B24">Moser et al., 2015</a>). It has also been suggested that activations in the human hippocampus encode distances between locations in the real world (<a href="#B22">Morgan et al., 2011</a>; <a href="#B15">Howard et al., 2014</a>). In a recent fMRI study using a graph structure of pictures, the adaptation signals in the hippocampal-entorhinal cortex were suppressed for shorter distances on the graph, indicating that non-spatial relationships were also encoded in these regions (<a href="#B11">Garvert et al., 2017</a>). Other neuroimaging studies have shown that activations in the left posterior hippocampus were enhanced during retrieval compared with the encoding of word pairs (<a href="#B29">Prince et al., 2005</a>) and that better recollection of proverbs was associated with a larger volume of the bilateral posterior hippocampus (<a href="#B28">Poppenk and Moscovitch, 2011</a>). The results of the present study are consistent with these previous findings, in that the scheduled appointments included various cues of spatial and structural information in the calendar, which were especially abundant when participants used paper notebooks. Moreover, the retrieval of such encoded information was explicitly required by our retrieval task and was shown to elicit activations in the bilateral posterior hippocampus.</p>
<p>Concerning activation in the visual cortex, a previous study reported that the visual cortex was activated during the retrieval of pictorial visual information without actual visual stimulation (<a href="#B37">Wheeler et al., 2000</a>). The visual areas play a key role in visual imagery as well, and activations in those regions could be affected by focal attention during imagery (<a href="#B32">Sakai and Miyashita, 1994</a>). Indeed, a study with fMRI decoding revealed activation in the V1–V3 when participants reported visual imagery of an object during dreaming, about which was inquired afterward (<a href="#B14">Horikawa et al., 2013</a>). Another study reported that retrieval of visual information was related to activation patterns in the V1–V3, and further showed that the activation patterns in the hippocampus predicted the mnemonic strength (<a href="#B3">Bosch et al., 2014</a>). As regards the precuneus, a positron emission tomography (PET) study with a paired-word retrieval task showed memory-related activation for both visual and auditory stimuli, indicating a modality-general role of the precuneus (<a href="#B18">Krause et al., 1999</a>). The internal representation for visual imagery of the encoded calendar provides a plausible account for our results, in which the paper notebook provides richer information than mobile devices.</p>
<p>According to our previous study, the left F3op/F3t, right LPMC, and right F3op/F3t are included in the network for syntax and its supportive system (Network I; <a href="#B17">Kinno et al., 2014</a>), whereas the left LPMC is critical to the network for syntax and input/output interface (Network II). In the present study, we observed activation in the left F3t/F3O, which is an essential part of the network for syntax and semantics (Network III). Thus all three networks that are crucial for syntactic processing were involved in the retrieval of scheduled appointments. The enhanced activations for the Note group suggest that the use of paper notebooks even influenced natural language processes, possibly reflecting the encoding of specific episodes.</p>
<p>Our present experiments demonstrated that brain activations related to memory, visual imagery, and language during the retrieval of specific information, as well as the deeper encoding of that information, were stronger in participants using a paper notebook than in those using electronic devices. Our results suggest that the use of a paper notebook affects these higher-order brain functions, and this could have important implications for education, particularly in terms of the pros and cons of e-learning. The expanded use of mobile devices or computers could undercut the use of traditional textbooks and paper notebooks, which may in fact provide richer information from the perspective of memory encoding. Further research is needed to elucidate the actual changes in brain activation due to the long-term exposure to mobile devices.</p>
<h2>Data Availability Statement</h2>
<p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p>
<h2>Ethics Statement</h2>
<p>The studies involving human participants were reviewed and approved by the Institutional Review Board of the University of Tokyo, Komaba Campus. The patients/participants provided their written informed consent to participate in this study.</p>
<h2>Author Contributions</h2>
<p>KU and KLS designed the study, analyzed the data, and wrote the manuscript. TI and TY contributed to the initial discussion. KU conducted the experiment. All authors contributed to the article and approved the submitted version.</p>
<h2>Funding</h2>
<p>The authors declare that this study received funding from the Consortium for Applied Neuroscience, NTT Data Institute of Management Consulting, Inc. The funder was not involved in the study design, collection, analysis, interpretation of data, the writing of this article, or the decision to submit it for publication.</p>
<h2>Conflict of Interest</h2>
<p>TI and TY were employed by the company NTT Data Institute of Management Consulting, Inc.</p>
<p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<h2>Acknowledgments</h2>
<p>We would like to thank the members of the Consortium for Applied Neuroscience for their input on the use of media, Yuma Tsuta for contributions to the design of the experiments, the MR scanning, and the analysis of behavioral results, Naoko Komoro for technical assistance, and Hiromi Matsuda for administrative assistance.</p>
<h2>Footnotes</h2>
<ol>
<li id="note1"><strong><a href="#note1a" title="">^</a></strong> <a href="http://www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</a></li>
<li id="note2"><strong><a href="#note2a" title="">^</a></strong> <a href="http://www.gin.cnrs.fr/AAL2/">www.gin.cnrs.fr/AAL2/</a></li>
<li id="note3"><strong><a href="#note3a" title="">^</a></strong> <a href="http://Neuromorphometrics.com/">http://Neuromorphometrics.com/</a></li>
<li id="note4"><strong><a href="#note4a" title="">^</a></strong> <a href="http://marsbar.sourceforge.net/">http://marsbar.sourceforge.net/</a></li>
</ol>
<h2>References</h2>
<div>
<p><a name="B1" id="B1"></a>Aragón-Mendizábal, E., Delgado-Casas, C., Navarro-Guzmán, J., Menacho-Jiménez, I., and Romero-Oliva, M. (2016). A comparative study of handwriting and computer typing in note-taking by university students. <i>Comunicar</i> 48, 101–107. doi: 10.1038/s42003-020-1052-8</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/32581304" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s42003-020-1052-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+comparative+study+of+handwriting+and+computer+typing+in+note-taking+by+university+students&amp;author=Aragón-Mendizábal+E.&amp;author=Delgado-Casas+C.&amp;author=Navarro-Guzmán+J.&amp;author=Menacho-Jiménez+I.&amp;author=Romero-Oliva+M.&amp;publication_year=2016&amp;journal=Comunicar&amp;volume=48&amp;pages=101-107" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B3" id="B3"></a>Bosch, S. E., Jehee, J. F. M., Fernández, G., and Doeller, C. F. (2014). Reinstatement of associative memories in early visual cortex is signaled by the hippocampus. <i>J. Neurosci.</i> 34, 7493–7500. doi: 10.1523/JNEUROSCI.0805-14.2014</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24872554" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.0805-14.2014" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Reinstatement+of+associative+memories+in+early+visual+cortex+is+signaled+by+the+hippocampus&amp;author=Bosch+S.+E.&amp;author=Jehee+J.+F.+M.&amp;author=Fernández+G.&amp;author=Doeller+C.+F.&amp;publication_year=2014&amp;journal=J.+Neurosci.&amp;volume=34&amp;pages=7493-7500" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B4" id="B4"></a>Broadbent, N. J., Squire, L. R., and Clark, R. E. (2004). Spatial memory, recognition memory and the hippocampus. <i>Proc. Natl. Acad. Sci. U S A</i> 101, 14515–14520. doi: 10.1073/pnas.0406344101</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15452348" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1073/pnas.0406344101" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Spatial+memory,+recognition+memory+and+the+hippocampus&amp;author=Broadbent+N.+J.&amp;author=Squire+L.+R.&amp;author=Clark+R.+E.&amp;publication_year=2004&amp;journal=Proc.+Natl.+Acad.+Sci.+U+S+A&amp;volume=101&amp;pages=14515-14520" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B5" id="B5"></a>Chadwick, M. J., Hassabis, D., Weiskopf, N., and Maguire, E. A. (2010). Decoding individual episodic memory traces in the human hippocampus. <i>Curr. Biol.</i> 20, 544–547. doi: 10.1016/j.cub.2010.01.053</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/20226665" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2010.01.053" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Decoding+individual+episodic+memory+traces+in+the+human+hippocampus&amp;author=Chadwick+M.+J.&amp;author=Hassabis+D.&amp;author=Weiskopf+N.&amp;author=Maguire+E.+A.&amp;publication_year=2010&amp;journal=Curr.+Biol.&amp;volume=20&amp;pages=544-547" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B6" id="B6"></a>Drozdick, L. W., Wahlstrom, D., Zhu, J., and Weiss, L. G. (2012). “The Wechsler adult intelligence scale—fourth edition and the wechsler memory scale—fourth edition,” in <i>Contemporary Intellectual Assessment: Theories, Tests and Issues</i> eds D. P. Flanagan and P. L. Harrison (New York, NY: Guilford Press), 197–223.</p>
<p><a href="http://scholar.google.com/scholar_lookup?title=The+Wechsler+adult+intelligence+scale—fourth+edition+and+the+wechsler+memory+scale—fourth+edition&amp;author=Drozdick+L.+W.&amp;author=Wahlstrom+D.&amp;author=Zhu+J.&amp;author=Weiss+L.+G.&amp;publication_year=2012&amp;pages=197-223" target="_blank">Google Scholar</a></p>
</div>


<div>
<p><a name="B9" id="B9"></a>Fawcett, T. (2006). An introduction to ROC analysis. <i>Pattern Recognit. Lett.</i> 27, 861–874. doi: 10.1016/j.patrec.2005.10.010</p>
<p><a href="https://doi.org/10.1016/j.patrec.2005.10.010" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=An+introduction+to+ROC+analysis&amp;author=Fawcett+T.&amp;publication_year=2006&amp;journal=Pattern+Recognit.+Lett.&amp;volume=27&amp;pages=861-874" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B10" id="B10"></a>Friston, K. J., Holmes, A. P., Worsley, K. J., Poline, J.-P., Frith, C. D., and Frackowiak, R. S. J. (1994). Statistical parametric maps in functional imaging: a general linear approach. <i>Hum. Brain Mapp.</i> 2, 189–210. doi: 10.1002/hbm.460020402</p>
<p><a href="https://doi.org/10.1002/hbm.460020402" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Statistical+parametric+maps+in+functional+imaging%3A+a+general+linear+approach&amp;author=Friston+K.+J.&amp;author=Holmes+A.+P.&amp;author=Worsley+K.+J.&amp;author=Poline+J.-P.&amp;author=Frith+C.+D.&amp;author=Frackowiak+R.+S.+J.&amp;publication_year=1994&amp;journal=Hum.+Brain+Mapp.&amp;volume=2&amp;pages=189-210" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B11" id="B11"></a>Garvert, M. M., Dolan, R. J., and Behrens, T. E. J. (2017). A map of abstract relational knowledge in the human hippocampal-entorhinal cortex. <i>eLife</i> 6, 1–20. doi: 10.7554/eLife.17086</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28448253" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.7554/eLife.17086" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+map+of+abstract+relational+knowledge+in+the+human+hippocampal-entorhinal+cortex&amp;author=Garvert+M.+M.&amp;author=Dolan+R.+J.&amp;author=Behrens+T.+E.+J.&amp;publication_year=2017&amp;journal=eLife&amp;volume=6&amp;pages=1-20" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B13" id="B13"></a>Hartley, T., Lever, C., Burgess, N., and O’keefe, J. (2014). Space in the brain: how the hippocampal formation supports spatial cognition. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> 369, 1–18. doi: 10.1098/rstb.2012.0510</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24366125" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1098/rstb.2012.0510" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Space+in+the+brain%3A+how+the+hippocampal+formation+supports+spatial+cognition&amp;author=Hartley+T.&amp;author=Lever+C.&amp;author=Burgess+N.&amp;author=O’keefe+J.&amp;publication_year=2014&amp;journal=Philos.+Trans.+R.+Soc.+Lond.+B+Biol.+Sci.&amp;volume=369&amp;pages=1-18" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B15" id="B15"></a>Howard, L. R., Javadi, A. H., Yu, Y., Mill, R. D., Morrison, L. C., Knight, R., et al. (2014). The hippocampus and entorhinal cortex encode the path and euclidean distances to goals during navigation. <i>Curr. Biol.</i> 24, 1331–1340. doi: 10.1016/j.cub.2014.05.001</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24909328" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2014.05.001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=The+hippocampus+and+entorhinal+cortex+encode+the+path+and+euclidean+distances+to+goals+during+navigation&amp;author=Howard+L.+R.&amp;author=Javadi+A.+H.&amp;author=Yu+Y.&amp;author=Mill+R.+D.&amp;author=Morrison+L.+C.&amp;author=Knight+R.&amp;+&amp;publication_year=2014&amp;journal=Curr.+Biol.&amp;volume=24&amp;pages=1331-1340" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B16" id="B16"></a>Kinno, R., Kawamura, M., Shioda, S., and Sakai, K. L. (2008). Neural correlates of noncanonical syntactic processing revealed by a picture-sentence matching task. <i>Hum. Brain Mapp.</i> 29, 1015–1027. doi: 10.1002/hbm.20441</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17924553" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1002/hbm.20441" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Neural+correlates+of+noncanonical+syntactic+processing+revealed+by+a+picture-sentence+matching+task&amp;author=Kinno+R.&amp;author=Kawamura+M.&amp;author=Shioda+S.&amp;author=Sakai+K.+L.&amp;publication_year=2008&amp;journal=Hum.+Brain+Mapp.&amp;volume=29&amp;pages=1015-1027" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B17" id="B17"></a>Kinno, R., Ohta, S., Muragaki, Y., Maruyama, T., and Sakai, K. L. (2014). Differential reorganization of three syntax-related networks induced by a left frontal glioma. <i>Brain</i> 137, 1193–1212. doi: 10.1093/brain/awu013</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24519977" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1093/brain/awu013" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Differential+reorganization+of+three+syntax-related+networks+induced+by+a+left+frontal+glioma&amp;author=Kinno+R.&amp;author=Ohta+S.&amp;author=Muragaki+Y.&amp;author=Maruyama+T.&amp;author=Sakai+K.+L.&amp;publication_year=2014&amp;journal=Brain&amp;volume=137&amp;pages=1193-1212" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B18" id="B18"></a>Krause, B. J., Schmidt, D., Mottaghy, F. M., Taylor, J., Halsband, U., Herzog, H., et al. (1999). Episodic retrieval activates the precuneus irrespective of the imagery content of word pair associates—a PET study. <i>Brain</i> 122, 255–263. doi: 10.1093/brain/122.2.255</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10071054" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1093/brain/122.2.255" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Episodic+retrieval+activates+the+precuneus+irrespective+of+the+imagery+content+of+word+pair+associates—a+PET+study&amp;author=Krause+B.+J.&amp;author=Schmidt+D.&amp;author=Mottaghy+F.+M.&amp;author=Taylor+J.&amp;author=Halsband+U.&amp;author=Herzog+H.&amp;+&amp;publication_year=1999&amp;journal=Brain&amp;volume=122&amp;pages=255-263" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B19" id="B19"></a>Lundstrom, B. N., Petersson, K. M., Andersson, J., Johansson, M., Fransson, P., and Ingvar, M. (2003). Isolating the retrieval of imagined pictures during episodic memory: activation of the left precuneus and left prefrontal cortex. <i>NeuroImage</i> 20, 1934–1943. doi: 10.1016/j.neuroimage.2003.07.017</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/14683699" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2003.07.017" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Isolating+the+retrieval+of+imagined+pictures+during+episodic+memory%3A+activation+of+the+left+precuneus+and+left+prefrontal+cortex&amp;author=Lundstrom+B.+N.&amp;author=Petersson+K.+M.&amp;author=Andersson+J.&amp;author=Johansson+M.&amp;author=Fransson+P.&amp;author=Ingvar+M.&amp;publication_year=2003&amp;journal=NeuroImage&amp;volume=20&amp;pages=1934-1943" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B20" id="B20"></a>Mangen, A., Walgermo, B. R., and Brønnick, K. (2013). Reading linear texts on paper versus computer screen: effects on reading comprehension. <i>Int. J. Educ. Res.</i> 58, 61–68. doi: 10.1016/j.ijer.2012.12.002</p>
<p><a href="https://doi.org/10.1016/j.ijer.2012.12.002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Reading+linear+texts+on+paper+versus+computer+screen%3A+effects+on+reading+comprehension&amp;author=Mangen+A.&amp;author=Walgermo+B.+R.&amp;author=Brønnick+K.&amp;publication_year=2013&amp;journal=Int.+J.+Educ.+Res.&amp;volume=58&amp;pages=61-68" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B22" id="B22"></a>Morgan, L. K., Macevoy, S. P., Aguirre, G. K., and Epstein, R. A. (2011). Distances between real-world locations are represented in the human hippocampus. <i>J. Neurosci.</i> 31, 1238–1245. doi: 10.1523/JNEUROSCI.4667-10.2011</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/21273408" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.4667-10.2011" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Distances+between+real-world+locations+are+represented+in+the+human+hippocampus&amp;author=Morgan+L.+K.&amp;author=Macevoy+S.+P.&amp;author=Aguirre+G.+K.&amp;author=Epstein+R.+A.&amp;publication_year=2011&amp;journal=J.+Neurosci.&amp;volume=31&amp;pages=1238-1245" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B23" id="B23"></a>Moscovitch, M., Cabeza, R., Winocur, G., and Nadel, L. (2016). Episodic memory and beyond: the hippocampus and neocortex in transformation. <i>Annu. Rev. Psychol.</i> 67, 105–134. doi: 10.1146/annurev-psych-113011-143733</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/26726963" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1146/annurev-psych-113011-143733" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Episodic+memory+and+beyond%3A+the+hippocampus+and+neocortex+in+transformation&amp;author=Moscovitch+M.&amp;author=Cabeza+R.&amp;author=Winocur+G.&amp;author=Nadel+L.&amp;publication_year=2016&amp;journal=Annu.+Rev.+Psychol.&amp;volume=67&amp;pages=105-134" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B25" id="B25"></a>Mueller, P. A., and Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: advantages of longhand over laptop note taking. <i>Psychol. Sci.</i> 25, 1159–1168. doi: 10.1177/0956797614524581</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24760141" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1177/0956797614524581" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=The+pen+is+mightier+than+the+keyboard%3A+advantages+of+longhand+over+laptop+note+taking&amp;author=Mueller+P.+A.&amp;author=Oppenheimer+D.+M.&amp;publication_year=2014&amp;journal=Psychol.+Sci.&amp;volume=25&amp;pages=1159-1168" target="_blank">Google Scholar</a></p>
</div>


<div>
<p><a name="B28" id="B28"></a>Poppenk, J., and Moscovitch, M. (2011). A hippocampal marker of recollection memory ability among healthy young adults: contributions of posterior and anterior segments. <i>Neuron</i> 72, 931–937. doi: 10.1016/j.neuron.2011.10.014</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/22196329" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuron.2011.10.014" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+hippocampal+marker+of+recollection+memory+ability+among+healthy+young+adults%3A+contributions+of+posterior+and+anterior+segments&amp;author=Poppenk+J.&amp;author=Moscovitch+M.&amp;publication_year=2011&amp;journal=Neuron&amp;volume=72&amp;pages=931-937" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B29" id="B29"></a>Prince, S. E., Daselaar, S. M., and Cabeza, R. (2005). Neural correlates of relational memory: successful encoding and retrieval of semantic and perceptual associations. <i>J. Neurosci.</i> 25, 1203–1210. doi: 10.1523/JNEUROSCI.2540-04.2005</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15689557" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.2540-04.2005" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Neural+correlates+of+relational+memory%3A+successful+encoding+and+retrieval+of+semantic+and+perceptual+associations&amp;author=Prince+S.+E.&amp;author=Daselaar+S.+M.&amp;author=Cabeza+R.&amp;publication_year=2005&amp;journal=J.+Neurosci.&amp;volume=25&amp;pages=1203-1210" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B30" id="B30"></a>Rugg, M. D., Johnson, J. D., Park, H., and Uncapher, M. R. (2008). “Encoding- retrieval overlap in human episodic memory: a functional neuroimaging perspective,” in <i>Essence of Memory, Progress in Brain Research 169</i>, eds W. S. Sossin, J.-C. Lacaille, V. F. Castellucci and S. Belleville (Amsterdam: Elsevier), 339–352.</p>
<p><a href="http://scholar.google.com/scholar_lookup?title=Encoding-+retrieval+overlap+in+human+episodic+memory%3A+a+functional+neuroimaging+perspective&amp;author=Rugg+M.+D.&amp;author=Johnson+J.+D.&amp;author=Park+H.&amp;author=Uncapher+M.+R.&amp;publication_year=2008&amp;pages=339-352" target="_blank">Google Scholar</a></p>
</div>




<div>
<p><a name="B35" id="B35"></a>Tzourio-Mazoyer, N., Landeau, B., Papathanassiou, D., Crivello, F., Etard, O., Delcroix, N., et al. (2002). Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain. <i>NeuroImage</i> 15, 273–289. doi: 10.1006/nimg.2001.0978</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11771995" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1006/nimg.2001.0978" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Automated+anatomical+labeling+of+activations+in+SPM+using+a+macroscopic+anatomical+parcellation+of+the+MNI+MRI+single-subject+brain&amp;author=Tzourio-Mazoyer+N.&amp;author=Landeau+B.&amp;author=Papathanassiou+D.&amp;author=Crivello+F.&amp;author=Etard+O.&amp;author=Delcroix+N.&amp;+&amp;publication_year=2002&amp;journal=NeuroImage&amp;volume=15&amp;pages=273-289" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B36" id="B36"></a>Wästlund, E., Reinikka, H., Norlander, T., and Archer, T. (2005). Effects of VDT and paper presentation on consumption and production of information: psychological and physiological factors. <i>Comput. Human Behav.</i> 21, 377–394. doi: 10.1016/j.chb.2004.02.007</p>
<p><a href="https://doi.org/10.1016/j.chb.2004.02.007" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Effects+of+VDT+and+paper+presentation+on+consumption+and+production+of+information%3A+psychological+and+physiological+factors&amp;author=Wästlund+E.&amp;author=Reinikka+H.&amp;author=Norlander+T.&amp;author=Archer+T.&amp;publication_year=2005&amp;journal=Comput.+Human+Behav.&amp;volume=21&amp;pages=377-394" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B37" id="B37"></a>Wheeler, M. E., Petersen, S. E., and Buckner, R. L. (2000). Memory’s echo: vivid remembering reactivates sensory-specific cortex. <i>Proc. Natl. Acad. Sci. U S A</i> 97, 11125–11129. doi: 10.1073/pnas.97.20.11125</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11005879" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1073/pnas.97.20.11125" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Memory&#39;s+echo%3A+vivid+remembering+reactivates+sensory-specific+cortex&amp;author=Wheeler+M.+E.&amp;author=Petersen+S.+E.&amp;author=Buckner+R.+L.&amp;publication_year=2000&amp;journal=Proc.+Natl.+Acad.+Sci.+U+S+A&amp;volume=97&amp;pages=11125-11129" target="_blank">Google Scholar</a></p>
</div>
</div></div>
  </body>
</html>
