<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/products/search/hum-to-search/">Original</a>
    <h1>Song stuck in your head? Just hum to search (2020)</h1>
    
    <div id="readability-page-1" class="page"><article ng-init="drawerToggle = {&#39;open&#39;: true}">

    
    


<section data-analytics-module="{
  &#34;module_name&#34;: &#34;Article Hero&#34;,
  &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
}">
  
</section>


    

    
      



    

    
      







<div>
  <div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/H2s-_phone_frame.width-600.format-webp.webp 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/H2s-_phone_frame.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/H2s-_phone_frame.width-1600.format-webp.webp 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/H2s-_phone_frame.width-1200.format-webp.webp" fetchpriority="high" alt="Phone screen showing Google Assistant &#34;What is this song&#34; search"/>
  </p>
</div>

      
    </figure>
  </div>
</div>


    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">
            
            
<!--article text-->

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="9zs61">Do you know that song that goes, “da daaaa da da daaaa na naa naa ooohh yeah”? Or the one that starts with the guitar chords going, “da na na naa”? We all know how frustrating it is when you can’t remember the name of a song or any of the words but the tune is stuck in your head. Today at <a href="https://www.blog.google/products/search/search-on/">Search On</a>, we announced that Google can now help you figure it out—no lyrics, artist name or perfect pitch required. </p><h3 data-block-key="9u86d">Hum to search for your earworm</h3><p data-block-key="0lzz8">Starting today, you can hum, whistle or sing a melody to Google to solve your earworm. On your mobile device, open the latest version of the Google app or find your <a href="https://blog.google/products/google-on-ios/easier-access-search-chrome-and-gmail-ios-14/">Google Search widget</a>, tap the mic icon and say “what&#39;s this song?” or click the “Search a song” button. Then start humming for 10-15 seconds. On Google Assistant, it’s just as simple. Say “Hey Google, what’s this song?” and then hum the tune. This feature is currently available in English on iOS, and in more than 20 languages on Android. And we hope to expand this to more languages in the future.</p><p data-block-key="pyk6x">After you’re finished humming, our machine learning algorithm helps identify potential song matches. And don’t worry, you don’t need perfect pitch to use this feature. We’ll show you the most likely options based on the tune. Then you can select the best match and explore information on the song and artist, view any accompanying music videos or listen to the song on your favorite music app, find the lyrics, read analysis and even check out other recordings of the song when available. </p></div>
      </div>
    </div>
  

  
    







  
      <div data-analytics-module="{
          &#34;module_name&#34;: &#34;Inline Images&#34;,
          &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/HumToSearch_GIF_UI_v04.mp4" type="video/mp4" title="An example of hum to search on a mobile phone" alt="hum to search">
            Video format not supported
          </video>
        
      
    
    </p>
    
  
    </div>
  



  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="65say">How machines learn melodies </h3><p data-block-key="cbbta">So how does it work? An easy way to explain it is that a song’s melody is like its fingerprint: They each have their own unique identity. We&#39;ve built machine learning models that can match your hum, whistle or singing to the right “fingerprint.”</p><p data-block-key="s197q">When you hum a melody into Search, our machine learning models transform the audio into a number-based sequence representing the song’s melody. Our models are trained to identify songs based on a variety of sources, including humans singing, whistling or humming, as well as studio recordings. The algorithms also take away all the other details, like accompanying instruments and the voice&#39;s timbre and tone. What we’re left with is the song’s number-based sequence, or the fingerprint.</p><p data-block-key="rn6n4">We compare these sequences to thousands of songs from around the world and identify potential  matches in real time. For example, if you listen to Tones and I’s “Dance Monkey,” you’ll recognize the song whether it was sung, whistled, or hummed. Similarly, our machine learning models recognize the melody of the studio-recorded version of the song, which we can use to match it with a person’s hummed audio. </p><p data-block-key="9qwp7">This builds on the work of our Research team’s <a href="https://ai.googleblog.com/2018/09/googles-next-generation-music.html">music recognition technology</a>. We launched Now Playing on the Pixel 2 in 2017, using deep neural networks to bring low-power recognition of music to mobile devices. In 2018, we brought the same technology to the SoundSearch feature in the Google app and expanded the reach to a catalog of millions of songs. This new experience takes it a step further, because now we can recognize songs without the lyrics or original song. All we need is a hum.</p></div>
      </div>
    </div>
  

  
    







  
      <div data-analytics-module="{
          &#34;module_name&#34;: &#34;Inline Images&#34;,
          &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Frame_7.mp4" type="video/mp4" title="A graphic that demonstrates music recognition technology" alt="hum to search melodies">
            Video format not supported
          </video>
        
      
    
    </p>
    
  
    </div>
  



  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Song stuck in your head? Just hum to search&#34;
         }">
      <div data-component="uni-article-paragraph">
        <p data-block-key="lkxon">So next time you can’t remember the name of some catchy song you heard on the radio or that classic jam your parents love, just start humming. You’ll have your answer in record time. </p>
      </div>
    </div>
  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
