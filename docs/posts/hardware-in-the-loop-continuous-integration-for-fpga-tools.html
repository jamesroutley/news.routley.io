<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://pepijndevos.nl/2026/02/17/hardware-in-the-loop-continuous-integration-for-fpga-tools.html">Original</a>
    <h1>Hardware in the Loop Continuous Integration for FPGA tools</h1>
    
    <div id="readability-page-1" class="page"><div>
            
<article>
    
    <section>
    <p>Imagine you are the maintainer of an open source FPGA toolchain such as <a href="https://github.com/YosysHQ/apicula">Apicula</a> and you want to make sure your code works. The industry standard for making sure software works is to set up continuous integration that tests your code for every change you make.</p>

<p>But what do you test? We are reverse engineering the inner workings of complicated devices, and if you’re slightly wrong you can generate a good looking bitstream that just doesn’t work. So of course during development you test your bitstreams on real hardware to make sure they work. And on top of that we <em>do</em> set up CI, but it can only test that we can generate a bitstream.</p>

<p>This is not idle thought, just <a href="https://github.com/YosysHQ/apicula/pull/462">yesterday</a> we had one FPGA silently fail due to improvements in another. It is very hard to catch these regressions reliably without constantly manually testing every single devices, which is completely infeasible.</p>

<p>For a long time I’ve dreamed of setting up a raspberry pi with a bunch of FPGAs and somehow running automated tests on it. But it always felt like a huge ordeal to really put everything together. Running and maintaining a raspberry pi with a bunch of FPGAs, writing useful self-tests that automatically verify correct behaviour, triggering a test run, downloading or generating bitstreams, programming the FPGAs, obtaining and verifying the results, and communicating that back to Github.</p>

<p>But this week I looked at the problem again and realized all the pieces had falling into place to make this not only feasible but almost trivial.</p>

<ol>
  <li>I am already running a Raspberry Pi with Home Assistant on my very own Mini-ITX motherboard: <a href="https://www.crowdsupply.com/sanctuary-systems/sentinel-core">Sentinel Core</a></li>
  <li>For running LLMs on my pi, I built <a href="https://github.com/sanctuary-systems-com/llm-addons">custom Docker addons</a> for Home Assistant</li>
  <li>To build those Docker containers, I’m using a Github <a href="https://docs.github.com/en/actions/concepts/runners/self-hosted-runners">self-hosted runner</a> on my VPS</li>
  <li>We have <a href="https://github.com/YosysHQ/apicula/blob/master/examples/femto-riscv-18.v">femto RISC-V UART</a> examples now based on Bruno Levy’s <a href="https://github.com/BrunoLevy/learn-fpga">FPGA tutorials</a></li>
</ol>

<p>So the plan is simple, plug some FPGAs into Home Assistant, run a self-hosted runner as an addon, and add a CI task that uploads an example and verifies its UART output against a reference.</p>

<p>For the addon I just forked an existing addon and added USB access and openFPGALoader: <a href="https://github.com/pepijndevos/home-assistant-github-runner-add-on">home-assistant-github-runner-add-on</a></p>

<p>For the CI side, it basically just adds a self-hosted step after our current bitstream generation that fetches the bitstream artifacts, uploads them, and diffs the UART output: <a href="https://github.com/YosysHQ/apicula/pull/461">Add hardware-in-the-loop CI test infrastructure</a></p>

<p>I’m excited to bring this new level of reliability to Apicula, and curious if other projects could do something similar.</p>

    </section>
    
</article>




        </div></div>
  </body>
</html>
