<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.newsguardtech.com/ai-monitor/august-2025-ai-false-claim-monitor/">Original</a>
    <h1>AI False information rate for news nearly doubles in one year</h1>
    
    <div id="readability-page-1" class="page"><div id="content" role="main">



   
       
    
                
                                        
            

                        
                        
                        
        
                                                    

                                

                <section>
                    <div>
                                               <div>
                            <p>
                                                                    <h2>AI False Information Rate Nearly Doubles in One Year</h2>
                                                                                                <h3>NewsGuard’s audit of the 10 leading generative AI tools and their propensity to repeat false claims on topics in the news reveals the rate of publishing false information nearly doubled — now providing false claims to news prompts more than one third of the time.</h3>
                                                            </p>
                        </div>
                                            </div>
                </section>
            
























           
                    



    <section>
        <div>
            <div>
                <div>
                    <p><em><strong>Published Sept. 4, 2025</strong></em></p>
<p><span>Despite a year of technical advancements in the AI industry, generative AI tools fail at a nearly doubled rate when it comes to one of the most basic tasks:  distinguishing facts from falsehoods. The 10 leading AI tools repeated false information on topics in the news </span><span>more than one third of the time </span><span>— 35 percent — in August 2025, up from 18 percent in August 2024. When it comes to providing reliable information about current affairs, the industry’s promises of safer, more reliable systems have not translated into real-world progress.  </span></p>
<p><span>The increase reflects a structural tradeoff. As chatbots adopted real-time web searches, they moved away from declining to answer questions. Their non-response rates fell from 31 percent in August 2024 to 0 percent in August 2025. But </span><span>at 35 percent, </span><span>their likelihood of repeating false information almost doubled.  Instead of citing data cutoffs or refusing to weigh in on sensitive topics, the LLMs now pull from a polluted online information ecosystem — sometimes deliberately seeded by vast networks of malign actors, including Russian disinformation operations — and treat unreliable sources as credible.</span></p>
<p><span>Malign actors are exploiting this new eagerness to answer news queries to launder falsehoods via low-engagement websites, social media posts, and AI-generated content farms that the models fail to distinguish from credible outlets. In short, the push to make chatbots more responsive and timely has inadvertently made them more likely to spread </span><span>propaganda</span><span>.</span></p>
                </div>
            </div>
        </div>
    </section>























           
                    











            <section>
            
        </section>















           
                
            
                
                
    

        
        
                
                        
            
            </div></div>
  </body>
</html>
