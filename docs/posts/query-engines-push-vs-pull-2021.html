<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://justinjaffray.com/query-engines-push-vs.-pull/">Original</a>
    <h1>Query Engines: Push vs. Pull (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
    

<p><small>26 Apr 2021</small></p><p>People talk a lot about “pull” vs. “push” based query engines, and it’s
pretty obvious what that means colloquially, but some of the
details can be a bit hard to figure out.</p>
<p>Important people clearly have thought hard about this distinction, judging by this paragraph from <a href="http://info.snowflake.net/rs/252-RFO-227/images/Snowflake_SIGMOD.pdf">Snowflake’s Sigmod paper</a>:</p>
<blockquote>
<p>Push-based execution refers to the fact that relational operators push their
results to their downstream operators, rather than waiting for these
operators to pull data (classic Volcano-style model). Push-based execution
improves cache efficiency, because it removes control flow logic from tight
loops. It also enables Snowflake to efficiently process DAG-shaped plans, as
opposed to just trees, creating additional opportunities for sharing and
pipelining of intermediate results.</p>
</blockquote>
<p>And…that’s all they really have to say on the matter.
It leaves me with two major unanswered questions:</p>
<ol>
<li>Why does a push-based system “enable Snowflake to efficiently process DAG-shaped plans” in a way not supported by a pull-based system, and who cares? (DAG stands for directed, acyclic graph.)</li>
<li>Why does this improve cache efficiency, what does it mean to “remove control flow logic from tight loops?”</li>
</ol>
<p>In this post, we’re going to talk about some of the philosophical differences
between how pull and push based query engines work, and then talk about the
practical differences of why you might prefer one over the other, guided by
these questions we’re trying to answer.</p>
<p>Consider this SQL query.</p>
<div><pre><code data-lang="sql"><span>SELECT</span><span> </span><span>DISTINCT</span><span> </span>customer_first_name<span> </span><span>FROM</span><span> </span>customer<span> </span><span>WHERE</span><span> </span>customer_balance<span> </span><span>&gt;</span><span> </span><span>0</span><span>
</span></code></pre></div><p>Query planners typically compile a SQL query like this into a sequence of
discrete <em>operators</em>:</p>
<p><img src="https://justinjaffray.com/images/babyplan.png" alt="A simple query plan"/></p>
<pre><code>Distinct
&lt;- Map(customer_first_name)
&lt;- Select(customer_balance &gt; 0)
&lt;- customer
</code></pre><p>In a <em>pull based</em> system, <em>consumers</em> drive the system. Each operator
produces a row when asked for it: the user will ask the root node
(<code>Distinct</code>) for a row, which will ask <code>Map</code> for a row, which will ask
<code>Select</code> for a row, and so on.</p>
<p>In a <em>push based</em> system, the <em>producers</em> drive the system. Each operator, when it has some data,
will tell its downstream operators about it. <code>customer</code>, being a base table in this query,
will tell <code>Select</code> about all of its rows, which will cause it to tell <code>Map</code> about of <em>its</em> rows, and so on.</p>
<p>Let’s start by building a super simple implementation of each kind of query engine.</p>
<h2 id="a-basic-pull-based-query-engine">A basic pull-based query engine</h2>
<p>A pull-based query engine is also generally said to use the <em>Volcano</em> or <em>Iterator</em> model.
This is the oldest and most well-known query execution model, and is named for the paper
which standardized its conventions in
<a href="https://paperhub.s3.amazonaws.com/dace52a42c07f7f8348b08dc2b186061.pdf">1994</a>.</p>
<p>First, we’ll start with a relation and a way to turn that into an <em>iterator</em>:</p>
<div><pre><code data-lang="javascript"><span>let</span> customer <span>=</span> [
  { id<span>:</span> <span>1</span>, firstName<span>:</span> <span>&#34;justin&#34;</span>, balance<span>:</span> <span>10</span> },
  { id<span>:</span> <span>2</span>, firstName<span>:</span> <span>&#34;sissel&#34;</span>, balance<span>:</span> <span>0</span> },
  { id<span>:</span> <span>3</span>, firstName<span>:</span> <span>&#34;justin&#34;</span>, balance<span>:</span> <span>-</span><span>3</span> },
  { id<span>:</span> <span>4</span>, firstName<span>:</span> <span>&#34;smudge&#34;</span>, balance<span>:</span> <span>2</span> },
  { id<span>:</span> <span>5</span>, firstName<span>:</span> <span>&#34;smudge&#34;</span>, balance<span>:</span> <span>0</span> },
];

<span>function</span><span>*</span> Scan(coll) {
  <span>for</span> (<span>let</span> x <span>of</span> coll) {
    <span>yield</span> x;
  }
}
</code></pre></div><p>Once we have our hands on an iterator, we can repeatedly ask it for its <code>next</code> element.</p>
<div><pre><code data-lang="javascript"><span>let</span> iterator <span>=</span> Scan(customer);

console.log(iterator.next());
console.log(iterator.next());
console.log(iterator.next());
console.log(iterator.next());
console.log(iterator.next());
console.log(iterator.next());
</code></pre></div><p>This outputs:</p>
<pre><code>{ value: { id: 1, firstName: &#39;justin&#39;, balance: 10 }, done: false }
{ value: { id: 2, firstName: &#39;sissel&#39;, balance: 0 }, done: false }
{ value: { id: 3, firstName: &#39;justin&#39;, balance: -3 }, done: false }
{ value: { id: 4, firstName: &#39;smudge&#39;, balance: 2 }, done: false }
{ value: { id: 5, firstName: &#39;smudge&#39;, balance: 0 }, done: false }
{ value: undefined, done: true }
</code></pre><p>We can then create some operators to transform an iterator into another form.</p>
<div><pre><code data-lang="javascript"><span>function</span><span>*</span> Select(p, iter) {
  <span>for</span> (<span>let</span> x <span>of</span> iter) {
    <span>if</span> (p(x)) {
      <span>yield</span> x;
    }
  }
}

<span>function</span><span>*</span> Map(f, iter) {
  <span>for</span> (<span>let</span> x <span>of</span> iter) {
    <span>yield</span> f(x);
  }
}

<span>function</span><span>*</span> Distinct(iter) {
  <span>let</span> seen <span>=</span> <span>new</span> Set();
  <span>for</span> (<span>let</span> x <span>of</span> iter) {
    <span>if</span> (<span>!</span>seen.has(x)) {
      <span>yield</span> x;
      seen.add(x);
    }
  }
}
</code></pre></div><p>Then we can translate our original query:</p>
<div><pre><code data-lang="sql"><span>SELECT</span><span> </span><span>DISTINCT</span><span> </span>customer_first_name<span> </span><span>FROM</span><span> </span>customer<span> </span><span>WHERE</span><span> </span>customer_balance<span> </span><span>&gt;</span><span> </span><span>0</span><span>
</span></code></pre></div><p>into this:</p>
<div><pre><code data-lang="javascript">console.log([
  ...Distinct(
    Map(
      (c) =&gt; c.firstName,
      Select((c) =&gt; c.balance <span>&gt;</span> <span>0</span>, Scan(customer))
    )
  ),
]);
</code></pre></div><p>which outputs, as expected:</p>
<pre><code>[ &#39;justin&#39;, &#39;smudge&#39; ]
</code></pre><h2 id="a-basic-push-based-query-engine">A basic push-based query engine</h2>
<p>A push based query engine, sometimes known as the <em>Reactive</em>, <em>Observer</em>, <em>Stream</em>, or
<em>callback hell</em> model, as you might expect, is like our previous example, but
turned on its head.</p>
<p>Let’s start by defining an appropriate <code>Scan</code> operator.</p>
<div><pre><code data-lang="javascript"><span>let</span> customer <span>=</span> [
  { id<span>:</span> <span>1</span>, firstName<span>:</span> <span>&#34;justin&#34;</span>, balance<span>:</span> <span>10</span> },
  { id<span>:</span> <span>2</span>, firstName<span>:</span> <span>&#34;sissel&#34;</span>, balance<span>:</span> <span>0</span> },
  { id<span>:</span> <span>3</span>, firstName<span>:</span> <span>&#34;justin&#34;</span>, balance<span>:</span> <span>-</span><span>3</span> },
  { id<span>:</span> <span>4</span>, firstName<span>:</span> <span>&#34;smudge&#34;</span>, balance<span>:</span> <span>2</span> },
  { id<span>:</span> <span>5</span>, firstName<span>:</span> <span>&#34;smudge&#34;</span>, balance<span>:</span> <span>0</span> },
];

<span>function</span> Scan(relation, out) {
  <span>for</span> (r <span>of</span> relation) {
    out(r);
  }
}
</code></pre></div><p>We model “this operator tells a downstream operator” as a closure that it calls.</p>
<div><pre><code data-lang="javascript">Scan(customer, (r) =&gt; console.log(<span>&#34;row:&#34;</span>, r));
</code></pre></div><p>Which outputs:</p>
<pre><code>row: { id: 1, firstName: &#39;justin&#39;, balance: 10 }
row: { id: 2, firstName: &#39;sissel&#39;, balance: 0 }
row: { id: 3, firstName: &#39;justin&#39;, balance: -3 }
row: { id: 4, firstName: &#39;smudge&#39;, balance: 2 }
row: { id: 5, firstName: &#39;smudge&#39;, balance: 0 }
</code></pre><p>We can define the rest of our operators similarly:</p>
<div><pre><code data-lang="javascript"><span>function</span> Select(p, out) {
  <span>return</span> (x) =&gt; {
    <span>if</span> (p(x)) out(x);
  };
}

<span>function</span> Map(f, out) {
  <span>return</span> (x) =&gt; {
    out(f(x));
  };
}

<span>function</span> Distinct(out) {
  <span>let</span> seen <span>=</span> <span>new</span> Set();
  <span>return</span> (x) =&gt; {
    <span>if</span> (<span>!</span>seen.has(x)) {
      seen.add(x);
      out(x);
    }
  };
}
</code></pre></div><p>Our query is now written:</p>
<div><pre><code data-lang="javascript"><span>let</span> result <span>=</span> [];
Scan(
  customer,
  Select(
    (c) =&gt; c.balance <span>&gt;</span> <span>0</span>,
    Map(
      (c) =&gt; c.firstName,
      Distinct((r) =&gt; result.push(r))
    )
  )
);

console.log(result);
</code></pre></div><p>Outputting, as expected,</p>
<pre><code>[ &#39;justin&#39;, &#39;smudge&#39; ]
</code></pre><h2 id="comparison">Comparison</h2>
<p>In a pull-based system, the operators sit idle until someone asks them for a row.
This means it’s obvious how to get results out of the system: you ask it
for a row and it gives it to you.
However, this also means that the behaviour of the system is very tightly coupled to its consumers;
you do work if asked to and not otherwise.</p>
<p>In the push-based system, the system sits idle until someone tells it about a row.
Thus, the work the system is doing and its consumption are decoupled.</p>
<p>You might have noticed that compared to our pull-based system, in our
push-based system above we had to do a strange dance with creating a buffer
(<code>result</code>) which we instructed the query to shove its results into.
This is how push-based systems wind up feeling, they don’t exist in
relation to their designated consumer, they kind of just exist, and when things happen,
they do stuff in response.</p>
<h2 id="dag-yo">DAG, yo</h2>
<p>Let’s go back to our first major question:</p>
<blockquote>
<p>Why does a push-based system “enable Snowflake to efficiently process DAG-shaped plans” in a way not supported by a pull-based system, and who cares?</p>
</blockquote>
<p>By “DAG-shaped plans” they mean operators which output their data to multiple downstream operators.
It turns out this is more useful than it sounds, even in the context of SQL, which we
often think of as inherently tree-structured.</p>
<p>SQL has a construct called <code>WITH</code> that allows users to reference a result set multiple times in a query.
This means the following query is valid SQL:</p>
<div><pre><code data-lang="sql"><span>WITH</span><span> </span>foo<span> </span><span>as</span><span> </span>(<span>&lt;</span><span>some</span><span> </span>complex<span> </span>query<span>&gt;</span>)<span>
</span><span></span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span>
</span><span>    </span>(<span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> </span>foo<span> </span><span>WHERE</span><span> </span><span>c</span>)<span> </span><span>AS</span><span> </span>foo1<span>
</span><span>  </span><span>JOIN</span><span>
</span><span>    </span>foo<span> </span><span>AS</span><span> </span>foo2<span>
</span><span>  </span><span>ON</span><span> </span>foo1.a<span> </span><span>=</span><span> </span>foo2.b<span>
</span></code></pre></div><p>Which has a query plan that looks something like this:</p>
<p><img src="https://justinjaffray.com/images/dagplan.png" alt="A DAG query plan"/></p>
<p>Outside of this explicit example, a smart query planner can often make use of
DAG-ness to reuse results.
For instance, Jamie Brandon has a
<a href="https://scattered-thoughts.net/writing/materialize-decorrelation">post</a>
describing a general method for decorrelating subqueries in SQL that makes extensive use
of DAG query plans in order to be efficient.
Because of all this, it’s valuable to be able to handle
these cases without simply duplicating a branch of the plan tree.</p>
<p>There are two main things that make this hard in a pull model: scheduling and lifetimes.</p>
<h3 id="scheduling">Scheduling</h3>
<p>In a setting where every operator has exactly one output,
when to run an operator to produce some output is obvious: when your consumer needs it.
This becomes, at the very least, messier with multiple outputs, since “requests for
rows” and “computations to produce rows” are no longer one-to-one.</p>
<p>By comparison, in a push-based system, scheduling of operators was never tied
to their outputs in the first place, so losing that information makes no difference.</p>
<h3 id="lifetime">Lifetime</h3>
<p>The other tricky thing with DAGs in a pull-based model is that an operator in
such a system is at the mercy of its downstream operators: a row that might
be read in the future by any of its consumers must be kept around (or must be
able to be re-computed).
One general solution to this is for an operator to buffer all of its rows
that get output so you can re-hand them out, but introducing potentially
unbounded buffering at every operator boundary is undesirable (but is, by
necessity, what Postgres and CockroachDB do for <code>WITH</code> having multiple
consumers).</p>
<p>This is not as much of a problem in a push-based system, because operators
now drive when their consumers process a row, they can effectively <em>force</em>
them to take ownership of a row and deal with it.
In most cases, this will either result in some kind of essential buffering that would
have been needed even in the absence of a DAG (say, for a <code>Distinct</code> or hash join
operation), or will simply be processed and passed on immediately.</p>
<h2 id="cache-efficiency">Cache Efficiency</h2>
<p>Now let’s talk about the second question.</p>
<blockquote>
<p>Why does this improve cache efficiency, what does it mean to “remove control flow logic from tight loops?”</p>
</blockquote>
<p>First of all, the Snowflake paper cites a
<a href="https://www.vldb.org/pvldb/vol4/p539-neumann.pdf">paper by Thomas Neumann</a>
in support of this claim.
I don’t really think this paper supports the claim in isolation though,
if I had to sum up the paper, it’s more like,
“we would like to compile queries to machine code in service of improved
cache efficiency, and to that end, a push-based paradigm is preferable.”
The paper is very interesting and I recommend you give it a read, but it seems to me that
its conclusions don’t really apply unless you’re starting from a position of wanting to
compile your queries using something like LLVM (which, from some cursory
research, it’s not clear to me if Snowflake does).</p>
<p>In doing research for this section I found this
<a href="https://arxiv.org/pdf/1610.09166.pdf">paper</a>
by Shaikhha, Dashti, and Koch, that does a great job of highlighting some
of the strengths and weaknesses of each model.
In fact, they reference the Neumann paper:</p>
<blockquote>
<p>More recently, an operator chaining model has been proposed that shares the
advantage of avoiding materialisation of intermediate results but which
reverses the control flow; tuples are pushed forward from the source
relations to the operator producing the final result. Recent papers
seem to suggest that this push-model consistently leads to better query
processing performance than the pull model, even though no direct, fair
comparisons are provided.</p>
<p>One of the main contributions of this paper is to debunk this myth. As we
show, if compared fairly, push and pull based engines have very similar
performance, with individual strengths and weaknesses, and neither is a clear
winner. Push engines have in essence only been considered in the context of
query compilation, conflating the potential advantages of the push paradigm
with those of code inlining. To compare them fairly, one has to decouple these
aspects.</p>
</blockquote>
<p>They conclude that there’s no clear winner here but observe that
compiling a push-based query makes for simpler code.
The main idea is that it turns out it’s actually extremely easy to unroll a
synchronous, push-based query into the equivalent code you’d write by hand.
Take our query from before:</p>
<div><pre><code data-lang="javascript"><span>let</span> result <span>=</span> [];
Scan(
  customer,
  Select(
    (c) =&gt; c.balance <span>&gt;</span> <span>0</span>,
    Map(
      (c) =&gt; c.firstName,
      Distinct((r) =&gt; result.push(r))
    )
  )
);

console.log(result);
</code></pre></div><p>This very naturally unrolls to:</p>
<div><pre><code data-lang="javascript"><span>let</span> result <span>=</span> [];
<span>let</span> seen <span>=</span> <span>new</span> Set();
<span>for</span> (<span>let</span> c <span>of</span> customer) {
  <span>if</span> (c.balance <span>&gt;</span> <span>0</span>) {
    <span>if</span> (<span>!</span>seen.has(c.firstName)) {
      seen.add(c.firstName);
      result.push(c.firstName);
    }
  }
}

console.log(result);
</code></pre></div><p>If you try to unroll the equivalent pull-based query you’ll find the resulting code is much less natural.</p>
<p>I think it’s hard to come to any real conclusions about which is “better” based on this, and I think
the most sensible thing is to make choices based on the needs of any particular
query engine.</p>
<h2 id="considerations">Considerations</h2>
<h3 id="impedance-mismatch">Impedance Mismatch</h3>
<p>One thing that can come up with these systems is a mismatch at their boundaries.
Crossing a boundary from a pull system to a push system requires <em>polling</em> its state, and
crossing a boundary from a push system to a pull system requires <em>materialization</em> of its state.
Neither of these are dealbreakers, but both incur some cost.</p>
<p>This is why in a streaming system like Flink or Materialize you’ll typically
see push-based systems used: the inputs to such a system are <em>inherently</em>
push-based, since you’re listening to incoming Kafka streams, or something
similar.</p>
<p>In a streaming setting, if you want your end consumer to actually be able to
interact with the system in a pull-based way (say, by running queries against
it when it needs to), you need to introduce some kind of materialization
layer where you build an index out of the results.</p>
<p>Conversely, in a system that doesn’t expose some kind of streaming/tailing mechanism,
if you want to know when some data has changed, your only option will be to poll
it periodically.</p>
<!--
### Laziness

Pull systems have the benefit that they only ever need to construct results
when they are asked for them.
As one concrete example, SQL databases typically have a plethora of
introspection tables that allow users to query things like the schema
of the system.
In a pull system, users who don't ever query those tables (and many users don't) incur no cost from them:
they don't ever need to be constructed or considered unless someone is reading from them.
In a push system where you're materializing these tables (short of some
possibly abstraction-breaking tricks one could pull), they
must always be maintained in full.
In general, if there is data that one could conceivably need in a push system, that data must be
present and updated at all times, even when nobody is asking for it.

This implies that there exist workloads where pull is preferable:
those where queries tend to touch small amounts of disjoint data.
To me, this is a compelling justification for why OLTP systems (Postgres, SQL
Server, etc.) generally seem to use pull-based systems: the possibility for
sharing of results is diminished when your queries are largely small and
disjoint (as they would be if, say, each query only touches data for a single
user).
-->
<h3 id="algorithms">Algorithms</h3>
<p>Some algorithms are simply not appropriate for use in a push system.
As discussed in the Shaikhha paper: the merge join algorithm working is fundamentally
based around the ability to traverse two iterators in lockstep, which is not
practical in a push system where the consumer has little-to-no control.</p>
<p>Similarly, <code>LIMIT</code> operators can be problematic in the push model.
Short of introducing bidirectional communication, or fusing the <code>LIMIT</code> to
the underlying operator (which is not always possible), the producing
operators cannot know they can stop doing work once their consumer has been
satisfied.
In a pull system this is not a problem, since the consumer can just stop
asking for more results when it doesn’t need any more.</p>
<h3 id="cycles">Cycles</h3>
<p>Without going into too much detail, having not just DAGs but full on cyclic graphs in either
of these models is nontrivial, but the most well-known system that solved this is
<a href="https://users.soe.ucsc.edu/~abadi/Papers/naiad_final.pdf">Naiad, a Timely Dataflow System</a>,
whose modern incarnation is
<a href="https://github.com/timelydataflow/timely-dataflow">Timely Dataflow</a>.
Both of these systems are push systems, and as with DAGs, many things just
work better in a push model here.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Overwhelmingly introductory database materials focus on the iterator model, but
modern systems, especially analytic ones, are starting to explore the push model more.
As noted in the Shaikhha paper, it’s hard to find apples-to-apples comparisons, since
a lot of the migration to push models are motivated by a desire to compile
queries to lower level code and the benefits that come from that cloud the results.</p>
<p>Despite that, there are some quantitative differences that make each model appropriate in
different scenarios and if you’re interested in databases it’s worth having a general idea
of how they both work.
In the future I’d like to go into more detail about how these systems are constructed and
try to expose some of the magic that makes them work.</p>


  </div></div>
  </body>
</html>
