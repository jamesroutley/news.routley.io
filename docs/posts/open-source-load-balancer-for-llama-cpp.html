<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/distantmagic/paddler">Original</a>
    <h1>Show HN: Open-Source Load Balancer for Llama.cpp</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Paddler is an open-source load balancer and reverse proxy designed specifically for optimizing servers running <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">Typical strategies like round robin or least connections are not effective for <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> servers, which need slots for continuous batching and concurrent requests.</p>
<p dir="auto">Paddler overcomes this by maintaining a stateful load balancer that is aware of each server&#39;s available slots, ensuring efficient request distribution. Additionally, Paddler uses agents to monitor the health of individual <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> instances, providing feedback to the load balancer for optimal performance. Paddler also supports the dynamic addition or removal of <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> servers, enabling integration with autoscaling tools.</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">Registering llama.cpp Instances</h3><a id="user-content-registering-llamacpp-instances" aria-label="Permalink: Registering llama.cpp Instances" href="#registering-llamacpp-instances"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The sequence repeats for each agent. Agents should be installed alongside llama.cpp instance to report their health status to the load balancer.</p>
<section data-identity="468ddd19-274f-4657-ad8f-9802a7362b2d" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div data-json="{&#34;data&#34;:&#34;sequenceDiagram\n    participant loadbalancer as Paddler Load Balancer\n    participant agent as Paddler Agent\n    participant llamacpp as llama.cpp\n\n    agent-&amp;gt;&amp;gt;llamacpp: Hey, are you alive?\n    llamacpp--&amp;gt;&amp;gt;agent: Yes, this is my health status\n    agent--&amp;gt;&amp;gt;loadbalancer: llama.cpp is still working\n    loadbalancer-&amp;gt;&amp;gt;llamacpp: I have a request for you to handle\n&#34;}" data-plain="sequenceDiagram
    participant loadbalancer as Paddler Load Balancer
    participant agent as Paddler Agent
    participant llamacpp as llama.cpp

    agent-&gt;&gt;llamacpp: Hey, are you alive?
    llamacpp--&gt;&gt;agent: Yes, this is my health status
    agent--&gt;&gt;loadbalancer: llama.cpp is still working
    loadbalancer-&gt;&gt;llamacpp: I have a request for you to handle
" dir="auto">
    <div dir="auto">
      <pre lang="mermaid" aria-label="Raw mermaid code">sequenceDiagram
    participant loadbalancer as Paddler Load Balancer
    participant agent as Paddler Agent
    participant llamacpp as llama.cpp

    agent-&gt;&gt;llamacpp: Hey, are you alive?
    llamacpp--&gt;&gt;agent: Yes, this is my health status
    agent--&gt;&gt;loadbalancer: llama.cpp is still working
    loadbalancer-&gt;&gt;llamacpp: I have a request for you to handle
</pre>
    </div>
  </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>


<ul dir="auto">
<li><a href="https://github.com/distantmagic/paddler/blob/main/infra/tutorial-installing-llamacpp-aws-cuda.md">Installing llama.cpp on AWS EC2 CUDA Instance</a></li>
<li><a href="https://github.com/distantmagic/paddler/blob/main/tutorial-installing-llamacpp-aws-ec2-image-builder.md">Installing llama.cpp with AWS EC2 Image Builder</a></li>
</ul>


<p dir="auto">You can download the latest release from the
<a href="https://github.com/distantmagic/paddler/releases">releases page</a>.</p>
<p dir="auto">Alternatively you can build the project yourself. You need <code>go&gt;=1.21</code> and
<code>nodejs</code> (for dashboard&#39;s front-end code) to build the project.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:distantmagic/paddler.git
$ cd paddler
$ pushd ./management
$ make esbuild # dashboard front-end
$ popd
$ go build -o paddler"><pre>$ git clone git@github.com:distantmagic/paddler.git
$ <span>cd</span> paddler
$ <span>pushd</span> ./management
$ make esbuild <span><span>#</span> dashboard front-end</span>
$ <span>popd</span>
$ go build -o paddler</pre></div>

<p dir="auto">The agent should be installed in the same host as <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">It needs a few pieces of information:</p>
<ol dir="auto">
<li><code>external-*</code> tells how the load balancer can connect to the llama.cpp instance</li>
<li><code>local-*</code> tells how the agent can connect to the llama.cpp instance</li>
<li><code>management-*</code> tell where the agent should report the health status</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./paddler agent \
    --external-llamacpp-host 127.0.0.1 \
    --external-llamacpp-port 8088 \
    --local-llamacpp-host 127.0.0.1 \
    --local-llamacpp-port 8088 \
    --management-host 127.0.0.1 \
    --management-port 8085"><pre>./paddler agent \
    --external-llamacpp-host 127.0.0.1 \
    --external-llamacpp-port 8088 \
    --local-llamacpp-host 127.0.0.1 \
    --local-llamacpp-port 8088 \
    --management-host 127.0.0.1 \
    --management-port 8085</pre></div>
<p dir="auto">Replace hosts and ports with your own server addresses when deploying.</p>

<p dir="auto">Load balancer collects data from agents and exposes reverse proxy to the outside world.</p>
<p dir="auto">It requires two sets of flags:</p>
<ol dir="auto">
<li><code>management-*</code> tells where the load balancer should listen for updates from agents</li>
<li><code>reverseproxy-*</code> tells how load balancer can be reached from the outside hosts</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./paddler balancer \
    --management-host 127.0.0.1 \
    --management-port 8085 \
    --reverseproxy-host 196.168.2.10 \
    --reverseproxy-port 8080"><pre>./paddler balancer \
    --management-host 127.0.0.1 \
    --management-port 8085 \
    --reverseproxy-host 196.168.2.10 \
    --reverseproxy-port 8080</pre></div>
<p dir="auto"><code>management-host</code> and <code>management-port</code> in agents should be the same as in the load balancer.</p>
<p dir="auto">You can enable dashboard to see the status of the agents with
<code>--management-dashboard-enable=true</code> flag. If enabled it is available at the
management server address under <code>/dashboard</code> path.</p>


<ul dir="auto">
<li>New feature: <a href="https://github.com/distantmagic/paddler/releases/tag/v0.1.0">Aggregated Health Status Responses</a></li>
</ul>

<ul>
<li> <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> reverse proxy</li>
<li> Basic load balancer</li>
<li> Circuit breaker</li>
<li> <a href="https://opentelemetry.io/" rel="nofollow">OpenTelemetry</a> observer</li>
<li> Integration with AWS Auto Scaling (and other cloud providers) - out of
the box endpoint with a custom metric to scale up/down</li>
</ul>

<p dir="auto">Discord: <a href="https://discord.gg/kysUzFqSCK" rel="nofollow">https://discord.gg/kysUzFqSCK</a></p>
</article></div></div>
  </body>
</html>
