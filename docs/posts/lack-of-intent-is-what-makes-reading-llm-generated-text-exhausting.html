<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lambdaland.org/posts/2025-08-04_artifical_inanity/">Original</a>
    <h1>Lack of intent is what makes reading LLM-generated text exhausting</h1>
    
    <div id="readability-page-1" class="page"><div>
    

    <div>
      

      
      
<article>
  
  
  <h5>4 Aug 2025</h5>



  

  
  
  



<p>There’s something icky about LLM-generated text when you think it’s written by a human. I think I finally put my finger on one reason why I feel this way.</p>
<p>Note on the title: “Artificial Inanity” comes from Neal Stephenson’s novel <em>Anathem</em>.</p>
<p>At work I was sent a long design document and asked for my thoughts on it. As I read, I had a really hard time following it. Eventually I guessed correctly (confirmed via a follow-up conversation I had with the “author”<label for="sn1"></label>

<span>
I have “author” in quotes because, if a machine wrote it, you don’t merit being called the <em>author</em> of the work.
</span>
) that an LLM had generated the majority of the document. Parts of it <em>sounded</em> like a decent design document, but there was just way too much fluff that served only to confuse me.</p>
<p>When I read technical documents, I read to understand the content. In this mode of reading, I operate under the assumption that the author had a reason for choosing the words they did, and that every sentence is there to convey something that the author wishes me to understand.</p>
<p>This mode fails when an LLM or the like has generated the text. When I read something I know came out of a computer’s probabilistic sampling of a token-space, I have read knowing that every statement might be some hallucinated slop or incidental filler. I <em>cannot</em> trust that the human operator’s intent is expressed by the machine. In fact, I am confident that it is often <em>not</em>, but I have to waste tremendous effort trying to find that gap. Reading slop text when I think I’m reading real text is exhausting: since I am not on the alert for hallucinations or irrelevancies, every turn of phrase that seems out of place causes me to wonder <em>why that phrase it there</em> and <em>what am I missing</em> when in reality, such questions are ill formed: that was just a phrase composed by accident that <em>sounds</em> good but actually is devoid of much intent at all.</p>
<p><em>Intent</em> is the core thing: the <em>lack</em> of intent is what makes reading AI-slop so revolting. There needs to be a human intent—human will and human care—behind everything that is demanded of our care and attention. Even if you agree with Rolland Barthes’<label for="sn2"></label>

<span>
The author of <em>The Death of the Author</em>, an essay where Barthes argues that focusing on the author’s intent is fruitless—the meaning of a text is the effect it has on the audience.
</span>
views on literary criticism, the fact that there <em>is</em> an author who put care and intent into a work imbues that work with infinitely more meaning than if it were spat out by a machine.</p>
<p>Counterfeits to human connection will—unfortunately—always be in demand. The multi-billion dollar industry churning out pornography is proof enough. People will probably always, from here on out, be using LLMs to cheat their way through classes and themselves out of learning. Some might turn to them for some faux-companionship. Others will be prompting themselves to death by offloading more and more of their reasoning to machines, convinced that the computer—like a slot machine—somehow will let them win bigger in life.</p>
<p>I am <strong>not</strong> saying that LLMs are worthless—they are marvels of engineering and can solve some particularly thorny problems that have confounded us for decades. But it’s important to remember that, no matter how capable these machines get, they are not humans. And no human is so worthless as to be replaceable with a machine.</p></article>
 
      

      

      
  
  
  
 

      </div>

  </div></div>
  </body>
</html>
