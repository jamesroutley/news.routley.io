<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://squeaky.ai/blog/development/why-we-dont-use-a-staging-environment">Original</a>
    <h1>We don’t use a staging environment</h1>
    
    <div id="readability-page-1" class="page"><article><h2 id="introduction">Introduction</h2>
<p>It’s common in the tech industry to create several pre-live environments, such as development, staging, and even team, or feature-level environments. There are lots of reasons for this, but mostly we rely on pre-production environments to help us test our latest changes before they end up in front of our users.</p>
<h2 id="whats-wrong-with-staging-environments">What’s wrong with staging environments?</h2>
<p>In our experience, there are a number of problems with having pre-live environments, including, but not limited to:</p>
<h3>Pre-live environments are never at parity with production</h3>
<p>More often than not, each environment uses different hardware, configurations, and software versions. Most companies are not prepared to pay for a staging environment identical to production, and it adds a lot of extra time and complexity to ensure that all services are synchronised with production.</p>
<h3>There’s always a queue</h3>
<p>Typically, multiple people use staging to validate their changes before release. This often leads to times when you can’t merge your code because someone else is testing code on staging, and they don’t want your changes to interfere with their validation. Not only that, but in the event that the person testing on staging encounters problems that need fixing, the entire pipeline is blocked until the problem is resolved.</p>
<figure><img src="https://cdn.squeaky.ai/blog/branching-strategy.png" width="1440" height="692"/></figure>
<h3>Releases are too large</h3>
<p>As queues slow down development and lead to multiple changes being bundled into larger releases, this leads to Big Bang releases where it’s more likely you’ll introduce bugs, harder to isolate the issues, and more difficult to roll back effectively..</p>
<h3>Poor ownership of changes</h3>
<p>In larger codebases, when you merge changes into the main branch, there is a lengthy suite of tests and checks that run before it is deployed to staging. During this period, which could end up being hours, engineers will likely pick up another task. I’ve seen people merge, and then forget that their changes are on staging, more times than I can count. In the meantime, another engineer may have merged changes into main, and now there are multiple sets of changes waiting to be released.</p>
<h3>People mistakenly let process replace accountability</h3>
<p>By utilising a pre-production environment, you’re creating a situation where developers often merge code and “throw it over the fence”, either for them to tidy up later, or other members of the team to deal with. This practice discourages accountability, and leads to less complete test coverage.</p>
<h2 id="how-we-ship-changes-at-squeaky">How we ship changes at Squeaky</h2>
<p>When shipping at Squeaky our process resolves, or avoids, the issues mentioned above. There are various elements to our approach, but most importantly:</p>
<h3>We only merge code that is ready to go live</h3>
<p>If we’re not confident that changes are ready to be in production, then we don’t merge them. This usually means we&#39;ve written sufficient tests and have validated our changes in development.</p>
<h3>We have a flat branching strategy</h3>
<p>All branches are cut from main, and all changes get merged back into main. Whenever a feature is ready to be merged, it is rebased and smoke-tested locally. If we ever have an issue in production, we always roll forward.</p>
<h3>High risk features are always feature flagged</h3>
<p>If we are concerned that our changes may cause issues in production we ship them behind a feature flag. Sometimes this is because we’re uncertain about how a feature will behave under load, or it may be because we’re unsure how users will react to a change. Feature flags can be enabled on a per-user basis so we can monitor performance and gather feedback. Experimental features can be enabled by users in their account settings.</p>
<h3>Hands-on deployments</h3>
<p>Whenever we deploy changes, we monitor the situation continuously until we are certain there are no issues. To help us do this, we have monitoring, logging, and alarms around all of our services. We also blue/green deploy, by draining and replacing a percentage of containers. This allows a subset of users to receive traffic from the new services while we validate.</p>
<h2 id="in-conclusion">In conclusion</h2>
<p>Dropping your staging environment in favour of true continuous integration and deployment can create a different mindset for shipping software. When there is no buffer for changes before they go live, you need to be confident that your changes are fit for production. You also need to be alert and take full ownership of any changes you make. You’ll reduce cost and complexity in your infrastructure, and you’ll simplify, and speed up your development lifecycle.</p></article></div>
  </body>
</html>
