<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.helix.ml/p/building-reliable-genai-applications">Original</a>
    <h1>Test Driven Development (TDD) for your LLMs? Yes please, more of that please</h1>
    
    <div id="readability-page-1" class="page"><div><div><article><div><div><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp" width="1344" height="768" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:768,&#34;width&#34;:1344,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:65668,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/webp&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6288c-4428-4599-97e9-e272ee2e8125_1344x768.webp 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a></figure></div><p>Testing LLM-based applications has become one of the most crucial challenges in modern software development. While traditional software testing gives us clear pass/fail criteria, how do you verify that your AI is consistently giving good responses? When is a response &#34;correct enough&#34;? And how do you automate this testing process in a way that scales?</p><div id="youtube2-Wz1HXUBSThA" data-attrs="{&#34;videoId&#34;:&#34;Wz1HXUBSThA&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/Wz1HXUBSThA?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>In this hands-on workshop, we tackle these challenges head-on by building and testing three different types of AI applications. Rather than getting lost in theoretical discussions, we focus on practical solutions that you can implement today.</p><p><span>Watch the recap video above, and/or sign up to join the next one! </span><strong><a href="https://mlops-l.ink/helix-workshop" rel="">Register here</a></strong><span> - we are running them at 9am PT / 5pm UK every Monday.</span></p><p>The traditional approach to testing AI applications often relies on manual review and subjective evaluation – also known as testing based on “vibes”! A team member might spend hours chatting with the AI, trying to catch edge cases and inconsistencies. While this has its place, it&#39;s neither scalable nor reproducible.</p><p><span>Instead, we demonstrate a more systematic approach using </span><a href="https://github.com/helixml/helix/tree/main/examples/test" rel="">Helix.ml&#39;s testing framework</a><span>. The key insight is using another AI model as an automated evaluator (judge), with clearly defined criteria for what makes a response acceptable. This, plus the tooling and configuration format to run these tests automatically, creates a reproducible testing process that can be integrated into your CI/CD pipeline.</span></p><p><span>Throughout the workshop, we create </span><a href="https://github.com/helixml/testing-genai" rel="">three distinct applications</a><span> that showcase different testing challenges:</span></p><ol><li><p><strong>A Comedian Chatbot:</strong><span> Seems simple, but raises interesting questions about consistency and personality. How do you verify that every response is actually a joke? We show how precise prompt engineering and automated testing can ensure consistent behavior.</span></p></li><li><p><strong>Document Q&amp;A System:</strong><span> Using real HR documentation, we build a system that can accurately answer policy questions. This demonstrates how to test against ground truth while allowing for natural language variation.</span></p></li><li><p><strong>Exchange Rate API Integration:</strong><span> We tackle the challenges of testing AI systems that interact with external APIs, ensuring they handle currency pairs correctly and present information clearly.</span></p></li></ol><p>The most exciting part? We show how to automate all of this testing in your CI pipeline. By the end of the workshop, you&#39;ll see how to:</p><ul><li><p>Write testable specifications for AI applications in YAML</p></li><li><p>Create automated evaluations using LLM judges</p></li><li><p>Integrate these tests into GitHub Actions or GitLab CI</p></li><li><p>Deploy tested changes automatically</p></li></ul><p>We&#39;re running regular workshops to help teams implement these testing practices. Join the next workshop to learn these critical skills to build reliable GenAI applications that have access to knowledge and API integrations to business systems.</p><p><span>Register for the next workshop here: </span><strong><a href="https://mlops-l.ink/helix-workshop" rel="">Register</a><span> </span></strong><span>- workshops run at 9am PT / 5pm UK every Monday.</span></p><p><span>We also offer private workshops to help you implement these testing practices with your specific use cases. Email </span><strong><a href="mailto:luke@helix.ml" rel="">luke@helix.ml</a></strong><span> to schedule a session.</span></p><p><span>The code and examples from this workshop are available on GitHub: </span><strong><a href="https://github.com/helixml/testing-genai" rel="">https://github.com/helixml/testing-genai</a></strong></p><p>Watch the walkthrough video:</p><div id="youtube2-Wz1HXUBSThA" data-attrs="{&#34;videoId&#34;:&#34;Wz1HXUBSThA&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/Wz1HXUBSThA?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>Building reliable AI applications doesn&#39;t have to be a shot in the dark. With the right testing framework and practices, you can develop AI systems with the same confidence you bring to traditional software development. Join us in the next workshop to learn how.</p></div></div></div></article></div></div></div>
  </body>
</html>
