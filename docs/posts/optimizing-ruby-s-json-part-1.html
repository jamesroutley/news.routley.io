<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html">Original</a>
    <h1>Optimizing Ruby&#39;s JSON, Part 1</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I was recently made maintainer of the <code>json</code> gem, and aside from fixing some old bugs, I focused quite a bit on its performance,
so that it is now the fastest JSON parser and generator for Ruby on most benchmarks.</p>

<p>Contrary to what one might think, there wasn’t any black magic or deep knowledge involved.
Most of the performance patches I applied were fairly simple optimizations driven by profiling.
As such, I’d like to go over these changes to show how they are quite generic and that many don’t only apply to C code.</p>

<p>But before I dive into these, let me explain why I came about working on this in the first place.</p>

<h2 id="there-should-be-no-need-for-alternatives">There Should Be No Need For Alternatives</h2>

<p>My motivation was never really performance per se. <code>ruby/json</code> was indeed slower than popular alternatives such as <code>oj</code>, but not by that much.</p>

<p>To take one benchmark as an example, parsing a JSON document consisting of <a href="https://github.com/ruby/json/blob/e1f6456499d497f33f69ae4c1afdaf9b2b9c50b3/benchmark/data/twitter.json">one hundred tweets or 467kiB</a>
would take <code>1.9ms</code> with <code>json 2.7.2</code>, and <code>1.6ms</code> with <code>oj</code>. So not that big of a difference.</p>

<p>On the generation side, <code>json 2.7.2</code> would take <code>0.8ms</code> to generate that document, and <code>oj</code> would take <code>0.4ms</code>.
Twice better, but unlikely to make a significant difference for the vast majority of use cases.
In general what’s slow is the layer above the JSON serialization, the one that turns Active Record models into basic Ruby Hashes and Arrays to feed them to the JSON serializer.
But the JSON serializer itself is generally negligible.</p>

<p>And yet, <code>oj</code> is extremely popular, I highly suspect because of its speed, and is included in the vast majority of projects I know, including Shopify’s codebase, and that annoys me.</p>

<p>This may surprise you, given generally when <code>oj</code> is mentioned online, all you can read is praises and how it’s just “free performance”, but my opinion differs very significantly here.</p>

<p>Why? Because <code>oj</code> has caused me innumerable headaches over the years, so many I couldn’t list them all here, but I can mention a few.</p>

<h3 id="with-monkey-patching-comes-great-responsibility">With Monkey Patching Comes Great Responsibility</h3>

<p>One way <code>oj</code> is frequently used is by monkey patching the <code>json</code> gem via <code>Oj.mimic_JSON</code> or <code>ActiveSupport::JSON</code> via <code>Oj.optimize_rails</code>.</p>

<p>The premise of these methods is that they’re supposed to replace less efficient implementations of JSON and do the same thing but faster.
For the most part, it holds true, but in some cases, it can go terribly wrong.</p>

<p>For instance, one day I had to deal with a security issue caused by <code>Oj.mimic_json</code>.
One gem was using <code>JSON.dump(data, script_safe: true)</code>, to safely include a JSON document inside a <code>&lt;script&gt;</code> tag:</p>

<figure><pre><code data-lang="ruby"><span>JSON</span><span>.</span><span>generate</span><span>(</span><span>&#34;&lt;/script&gt;&#34;</span><span>)</span> <span># =&gt; &lt;/script&gt;</span>
<span>JSON</span><span>.</span><span>generate</span><span>(</span><span>&#34;&lt;/script&gt;&#34;</span><span>,</span> <span>script_safe: </span><span>true</span><span>)</span> <span># =&gt; &lt;\/script&gt;</span></code></pre></figure>

<p>Except that <code>oj</code> doesn’t know about the <code>script_safe</code> option, and simply ignores it. So the gem was safe when ran alone,
but once used in an application that called <code>Oj.mimic_JSON</code>, it would open the door to XSS attacks…:</p>

<figure><pre><code data-lang="ruby"><span>Oj</span><span>.</span><span>mimic_JSON</span>
<span>JSON</span><span>.</span><span>generate</span><span>(</span><span>&#34;&lt;/script&gt;&#34;</span><span>,</span> <span>script_safe: </span><span>true</span><span>)</span> <span># =&gt; &lt;/script&gt;</span></code></pre></figure>

<p>This isn’t to say monkey patching is wrong in essence, but it should be done with great care,
considering how the patched API may evolve in the future and how to safety fallback or at least explictly error when something is amiss.</p>

<p><code>Oj.optimize_rails</code> similarly can cause some very subtle differences in how objects are serialized, e.g.</p>

<figure><pre><code data-lang="ruby"><span>ActiveSupport</span><span>::</span><span>JSON</span><span>::</span><span>Encoding</span><span>.</span><span>time_precision</span> <span>=</span> <span>0</span>

<span>t</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>

<span>puts</span> <span>ActiveSupport</span><span>::</span><span>JSON</span><span>.</span><span>encode</span><span>(</span><span>t</span><span>)</span> <span># =&gt; &#34;2024-12-16T16:00:51+01:00&#34;</span>

<span>require</span> <span>&#39;oj&#39;</span>
<span>Oj</span><span>.</span><span>optimize_rails</span>
<span>Oj</span><span>.</span><span>mimic_JSON</span>

<span>puts</span> <span>ActiveSupport</span><span>::</span><span>JSON</span><span>.</span><span>encode</span><span>(</span><span>t</span><span>)</span> <span># =&gt; &#34;2024-12-16T16:00:51.790+01:00&#34;</span></code></pre></figure>

<p>This one is a bit of a corner case caused by load order, but I had to waste a lot of time fighting with it in the past.
<a href="https://github.com/ohler55/oj/pull/936">And until very recently, it changed the behavior way more than that</a>.</p>

<h3 id="quite-unstable">Quite Unstable</h3>

<p>Another big reason I don’t recommend <code>oj</code> is that from my experience of running it at scale, it has been one of the most prominent sources of
Ruby crashes for us, only second to <code>grpc</code>.</p>

<p>I and my teammates had to submit quite several patches for weird crashes we ran into, which in itself isn’t a red flag,
as we did as much for many other native gems, but <code>oj</code> is <em>very</em> actively developed, so we’d often run into new crashes and never
felt like the gem was fixed.</p>

<p>Writing a native gem isn’t inherently hard, but it does require some substantial understanding of how the Ruby VM works, especially its GC,
to not cause crashes or worse, memory corruption.
And while working on these patches for <code>Oj</code>, we’ve seen quite a few dirty hacks in the codebase that made us worried about trusting it.
Just to give an example (that has been thankfully fixed since), <a href="https://github.com/ohler55/oj/blob/8a1773dded9da5365f51c8c70026c5a98650f76d/ext/oj/fast.c#L1105-L1109"><code>oj</code> used to disable GC in some cases to workaround a bug</a>,
which in addition to being worrying, also causes a major GC cycle to be triggered when GC is re-enabled later.
This is the sort of code that makes for great results on micro-benchmarks, but tank performance in actual production code.</p>

<p>That’s why a couple of years back I decided to remove Oj from Shopify’s monolith, and that’s when I discovered all the subtle differences
between <code>Oj.mimic_JSON</code> and the real <code>json</code>.</p>

<h2 id="ground-work">Ground Work</h2>

<p>So my motivation was to hopefully make <code>ruby/json</code> perform about as well as <code>oj</code> on both real-world and micro-benchmark so that users
would no longer feel the need to monkey patch <code>json</code> for speed reasons. If they still feel like they need one of the more advanced <code>oj</code> APIs
that’s fine, but <code>Oj.mimic_JSON</code> should no longer feel appealing.</p>

<p>So <a href="https://github.com/ruby/json/pull/606">the very first step was to setup a suite of benchmarks</a>, comprising both micro-benchmarks and more meaty,
real-world benchmarks.
Thankfully, <a href="https://github.com/jhawthorn/rapidjson-ruby/">John Hawthorn’s rapidjson-ruby gem</a> had such a benchmark suite, which I stole as a basis with some minor additions.</p>

<p>With that, all I needed was a decent C profiler. There are several options, but my favorite is <a href="https://github.com/mstange/samply">samply</a>,
which has the nice property of outputting Firefox Profiler compatible reports that are easy to share.</p>

<h2 id="avoid-redundant-checks">Avoid Redundant Checks</h2>

<p>I then started profiling the <code>JSON.dump</code> benchmark with the <code>twitter.json</code> payload:</p>

<p><img src="https://byroot.github.io/assets/articles/json-1/is-valid-utf8.png" alt=""/></p>

<p><a href="https://share.firefox.dev/3VHqFUO">Full profile</a></p>

<p>You need to know Ruby internals a bit to understand it all, but almost immediately something that surprised me was <code>9%</code> of the time
spent in JSON’s own <code>isLegalUTF8</code>, and also <code>1.9%</code> in <code>rb_enc_str_asciionly_p</code>, which is the <code>C</code> API version of <code>String#ascii_only?</code>.</p>

<p>The reason this is surprising is that Ruby string have some internal property called a <code>coderange</code>. For most string operations, Ruby does need to
known if it’s properly encoded, and for some operations, it can take shortcuts if the string only contains ASCII.</p>

<p>Since scanning a string to validate its encoding is somewhat costly, it keeps that property around so a string is only scanned once as long as it’s not mutated.</p>

<p>A coderange can be one of 4 values:</p>

<ul>
  <li><code>ENC_CODERANGE_UNKNOWN</code>: the string wasn’t scanned yet.</li>
  <li><code>ENC_CODERANGE_VALID</code>: the string encoding is valid.</li>
  <li><code>ENC_CODERANGE_7BIT</code>: the string encoding is valid and only contains ASCII characters.</li>
  <li><code>ENC_CODERANGE_INVALID</code>: the string encoding is invalid.</li>
</ul>

<p>And some functions like <code>rb_enc_str_asciionly_p</code> are called, what they do is that if the coderange is unknown, they scan the string to compute it.
After that, it’s a very cheap integer comparison against <code>ENC_CODERANGE_7BIT</code>.</p>

<p>So <code>convert_UTF8_to_JSON_ASCII</code> had this weird thing where it would call <code>rb_enc_str_asciionly_p</code> at the very beginning, but then later it would
manually scan the string to see if it contains valid UTF-8, doing redundant work already performed by <code>rb_enc_str_asciionly_p</code>.</p>

<p>All this UTF-8 scanning could simply be replaced by a comparison of the string already computed coderange:</p>

<figure><pre><code data-lang="c"><span>int</span> <span>ascii_only</span> <span>=</span> <span>rb_enc_str_asciionly_p</span><span>(</span><span>string</span><span>);</span>

<span>if</span> <span>(</span><span>!</span><span>ascii_only</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>RB_ENCODING_GET_INLINED</span><span>(</span><span>string</span><span>)</span> <span>!=</span> <span>rb_utf8_encindex</span><span>()</span> <span>||</span>
        <span>RB_ENC_CODERANGE</span><span>(</span><span>string</span><span>)</span> <span>!=</span> <span>RUBY_ENC_CODERANGE_VALID</span><span>)</span> <span>{</span>
        <span>rb_raise</span><span>(</span><span>rb_path2class</span><span>(</span><span>&#34;JSON::GeneratorError&#34;</span><span>),</span>
                <span>&#34;source sequence is illegal/malformed utf-8&#34;</span><span>);</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Since C extensions code can be a bit cryptic when you’re not familiar with it, the Ruby version of that is simply:</p>

<figure><pre><code data-lang="ruby"><span>unless</span> <span>string</span><span>.</span><span>ascii_only?</span>
  <span>if</span> <span>string</span><span>.</span><span>encoding</span> <span>!=</span> <span>Encoding</span><span>::</span><span>UTF_8</span> <span>||</span> <span>!</span><span>string</span><span>.</span><span>valid_encoding?</span>
    <span>raise</span> <span>JSON</span><span>::</span><span>GeneratorError</span><span>,</span> <span>&#34;source sequence is illegal/malformed utf-8&#34;</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>Here both <code>#ascii_only?</code> and <code>#valid_encoding?</code> rely on the cached coderange, so the string would be scanned at most once, while previously
it could be scanned twice.</p>

<p>Unfortunately, that optimization didn’t perform as well as I initially expected:</p>

<div><div><pre><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   105.000 i/100ms
Calculating -------------------------------------
               after      1.113k (± 0.8%) i/s  (898.26 μs/i) -      5.670k in   5.093474s

Comparison:
              before:     1077.3 i/s
               after:     1113.3 i/s - 1.03x  faster
</code></pre></div></div>

<p>Given that <code>isLegalUTF8</code> was reported as being <code>9%</code> of the overall runtime, you’d expect that skipping it would speed up the code by <code>9%</code>,
but it’s not that simple. A large part of the time that used to be spent in <code>isLegalUTF8</code> instead went to <code>convert_UTF8_to_JSON</code>, while I’m not 100% sure.
The likely reason is that the larger part of these 9% was spent loading the strings content from RAM into the CPU cache, and not processing it.
Since we still go over these bytes later on, they still do the actually costly part of fetching the memory.</p>

<p>Still, a 3% improvement was nice to see.</p>

<h2 id="check-the-cheaper-more-likely-condition-first">Check the Cheaper, More Likely Condition First</h2>

<p>In parallel to the previous patch, another function I looked at was <code>fbuffer_inc_capa</code>, reported as <code>5.7%</code> of total runtime.</p>

<p><img src="https://byroot.github.io/assets/articles/json-1/is-valid-utf8.png" alt=""/></p>

<p><a href="https://share.firefox.dev/3VHqFUO">Full profile</a></p>

<p>Looking at the profiler heat map of that function, I noticed that most of the time is spent checking if the buffer was already allocated or not:</p>

<p><img src="https://byroot.github.io/assets/articles/json-1/fbuffer_inc_capa_heatmap.png" alt=""/></p>

<p>But this function is called every time we’re trying to write anything to the buffer and after the first call, the buffer is always already allocated.
So that’s a lot of wasted effort for a condition that doesn’t match 99% of the time.</p>

<p>Also, that condition is a bit redundant with the <code>if (required &gt; fb-&gt;capa)</code> one, as if the buffer wasn’t allocated yet, <code>fb-&gt;capa</code> would be <code>0</code>,
hence, there’s no point checking it first, we should check it after we establish that the buffer capacity needs to be increased.</p>

<p>Another thing to know about modern CPUs is that <a href="https://en.wikipedia.org/wiki/Superscalar_processor">they’re “superscalar”</a>, meaning they don’t actually
perform instruction one by one, but concurrently, and when faced with a branch, they take an educated guess at which branch is more likely to be taken
and start executing that one immediately.</p>

<p>Based on that, it would be advantageous to instruct the CPU that both the <code>if (required &gt; fb-&gt;capa)</code> and the <code>if (!fb-&gt;ptr)</code> conditions are very
unlikely to match.</p>

<p>To do that, compilers have various constructs, but Ruby helpfully exposes a macro to support most compilers with the same syntax: <code>RB_LIKELY</code> and <code>RB_UNLIKELY</code>.</p>

<p>Combining all these, led me to rewrite that function as:</p>

<figure><pre><code data-lang="c"><span>static</span> <span>inline</span> <span>void</span> <span>fbuffer_inc_capa</span><span>(</span><span>FBuffer</span> <span>*</span><span>fb</span><span>,</span> <span>unsigned</span> <span>long</span> <span>requested</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>RB_UNLIKELY</span><span>(</span><span>requested</span> <span>&gt;</span> <span>fb</span><span>-&gt;</span><span>capa</span> <span>-</span> <span>fb</span><span>-&gt;</span><span>len</span><span>))</span> <span>{</span>
        <span>unsigned</span> <span>long</span> <span>required</span><span>;</span>

        <span>if</span> <span>(</span><span>RB_UNLIKELY</span><span>(</span><span>!</span><span>fb</span><span>-&gt;</span><span>ptr</span><span>))</span> <span>{</span>
            <span>fb</span><span>-&gt;</span><span>ptr</span> <span>=</span> <span>ALLOC_N</span><span>(</span><span>char</span><span>,</span> <span>fb</span><span>-&gt;</span><span>initial_length</span><span>);</span>
            <span>fb</span><span>-&gt;</span><span>capa</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>initial_length</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>required</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>capa</span><span>;</span> <span>requested</span> <span>&gt;</span> <span>required</span> <span>-</span> <span>fb</span><span>-&gt;</span><span>len</span><span>;</span> <span>required</span> <span>&lt;&lt;=</span> <span>1</span><span>);</span>

        <span>if</span> <span>(</span><span>required</span> <span>&gt;</span> <span>fb</span><span>-&gt;</span><span>capa</span><span>)</span> <span>{</span>
            <span>REALLOC_N</span><span>(</span><span>fb</span><span>-&gt;</span><span>ptr</span><span>,</span> <span>char</span><span>,</span> <span>required</span><span>);</span>
            <span>fb</span><span>-&gt;</span><span>capa</span> <span>=</span> <span>required</span><span>;</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>With this new version, we first check for the most common case, which is when the buffer still has enough capacity, and we instruct the CPU that
it’s the most likely case. Also, the function is now marked as <code>inline</code>, to suggest to the compiler not to go through the cost of calling a function,
but to directly embed that logic in the caller. As a result, the vast majority of the time, the work necessary to ensure the buffer is large enough
is just a subtraction and a comparison, very much negligible on modern CPUs.</p>

<p>That change led to a 15% improvement.</p>

<div><div><pre><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   121.000 i/100ms
Calculating -------------------------------------
               after      1.225k (± 0.8%) i/s  (816.54 μs/i) -      6.171k in   5.039186s

Comparison:
              before:     1068.6 i/s
               after:     1224.7 i/s - 1.15x  faster
</code></pre></div></div>

<p>And if you think about it, it’s not that specific to C, you can apply the same general idea to Ruby code as well, by checking the cheapest and most
likely conditions first.</p>

<h2 id="reducing-setup-cost">Reducing Setup Cost</h2>

<p>I also wasn’t alone in optimizing <code>ruby/json</code>, <a href="https://github.com/mame">Yusuke Endoh aka Mame</a>, a fellow Ruby committer also had <a href="https://github.com/ruby/json/pull/562">an old open PR with
numerous optimizations</a>. Many of these reduced the “setup” cost of generating JSON.</p>

<p>What I describe as setup cost, is all the busy work that needs to be done before you can get to do the work you want.
In the case of JSON generation, it includes parsing the arguments, allocating the generator and associated structures, etc.</p>

<p><code>ruby/json</code> setup cost was quite higher than the alternative, and it’s because of this it always looked bad on micro-benchmarks.
For instance <code>JSON.generate</code> has 3 options to allow to generate “pretty” JSON:</p>

<figure><pre><code data-lang="ruby"><span>&gt;&gt;</span> <span>puts</span> <span>JSON</span><span>.</span><span>generate</span><span>({</span><span>foo: </span><span>[</span><span>1</span><span>]},</span> <span>array_nl: </span><span>&#34;</span><span>\n</span><span>&#34;</span><span>,</span> <span>object_nl: </span><span>&#34;</span><span>\n</span><span>&#34;</span><span>,</span> <span>indent: </span><span>&#34;  &#34;</span><span>,</span> <span>space: </span><span>&#34; &#34;</span><span>)</span>
<span>{</span>
  <span>&#34;foo&#34;</span><span>:</span> <span>[</span>
    <span>1</span>
  <span>]</span>
<span>}</span></code></pre></figure>

<p>Before Mame’s changes, the provided strings would be used to precompute delimiters into dedicated buffers.
A Ruby equivalent of the code would be:</p>

<figure><pre><code data-lang="ruby"><span>def</span> <span>initialize</span><span>(</span><span>opts</span><span>)</span>
  <span>@array_delim</span> <span>=</span> <span>&#34;,</span><span>#{</span><span>opts</span><span>[</span><span>:array_nl</span><span>]</span><span>}</span><span>&#34;</span>
  <span>@object_delim</span> <span>=</span> <span>&#34;,</span><span>#{</span><span>opts</span><span>[</span><span>:object_nl</span><span>]</span><span>}</span><span>&#34;</span>
  <span>@object_delim2</span> <span>=</span> <span>&#34;:</span><span>#{</span><span>opts</span><span>[</span><span>:space</span><span>]</span><span>}</span><span>&#34;</span>
<span>end</span></code></pre></figure>

<p>The idea makes sense, you precompute some string segments so you can append a single longer segment instead of two smaller ones.</p>

<p>But in practice this ended up much slower, both because this precompute doesn’t really save much work, but also because most of the time these options aren’t used.
So <a href="https://github.com/mame/json/compare/e125072130229e54a651f7b11d7d5a782ae7fb65...4c984b20176e3989aec5c0c148dba92a2bb89fd7">by essentially reverting this optimization</a>,
Mame reduced the setup cost significantly. On larger benchmarks, the difference isn’t big, but on micro-benchmarks, it’s quite massive:</p>

<div><div><pre><code>== Encoding small hash (65 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   308.914k i/100ms
Calculating -------------------------------------
               after      3.199M (± 1.1%) i/s  (312.57 ns/i) -     16.064M in   5.021536s

Comparison:
              before:  2112189.3 i/s
               after:  3199311.0 i/s - 1.51x  faster
</code></pre></div></div>

<h2 id="avoid-chasing-pointers">Avoid Chasing Pointers</h2>

<p>Another notable optimization in Mame’s pull request was to eliminate one call to <code>rb_enc_get</code>.</p>

<p>In many places, JSON needs to check that strings are UTF-8 compatible, and was doing it this way:</p>

<figure><pre><code data-lang="c"><span>static</span> <span>int</span> <span>enc_utf8_compatible_p</span><span>(</span><span>rb_encoding</span> <span>*</span><span>enc</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>enc</span> <span>==</span> <span>rb_usascii_encoding</span><span>())</span> <span>return</span> <span>1</span><span>;</span>
    <span>if</span> <span>(</span><span>enc</span> <span>==</span> <span>rb_utf8_encoding</span><span>())</span> <span>return</span> <span>1</span><span>;</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span><span>!</span><span>enc_utf8_compatible_p</span><span>(</span><span>rb_enc_get</span><span>(</span><span>obj</span><span>)))</span> <span>{</span>
    <span>// try to convert the string</span>
<span>}</span></code></pre></figure>

<p>At first sight, this might seem quite straightforward. But <code>rb_enc_get</code> is quite slow. Here’s most of its implementation:</p>

<figure><pre><code data-lang="c"><span>int</span>
<span>rb_enc_get_index</span><span>(</span><span>VALUE</span> <span>obj</span><span>)</span>
<span>{</span>
    <span>int</span> <span>i</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
    <span>VALUE</span> <span>tmp</span><span>;</span>

    <span>if</span> <span>(</span><span>SPECIAL_CONST_P</span><span>(</span><span>obj</span><span>))</span> <span>{</span>
        <span>if</span> <span>(</span><span>!</span><span>SYMBOL_P</span><span>(</span><span>obj</span><span>))</span> <span>return</span> <span>-</span><span>1</span><span>;</span>
        <span>obj</span> <span>=</span> <span>rb_sym2str</span><span>(</span><span>obj</span><span>);</span>
    <span>}</span>
    <span>switch</span> <span>(</span><span>BUILTIN_TYPE</span><span>(</span><span>obj</span><span>))</span> <span>{</span>
      <span>case</span> <span>T_STRING</span><span>:</span>
      <span>case</span> <span>T_SYMBOL</span><span>:</span>
      <span>case</span> <span>T_REGEXP</span><span>:</span>
        <span>i</span> <span>=</span> <span>enc_get_index_str</span><span>(</span><span>obj</span><span>);</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>T_FILE</span><span>:</span>
        <span>tmp</span> <span>=</span> <span>rb_funcallv</span><span>(</span><span>obj</span><span>,</span> <span>rb_intern</span><span>(</span><span>&#34;internal_encoding&#34;</span><span>),</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
        <span>if</span> <span>(</span><span>NIL_P</span><span>(</span><span>tmp</span><span>))</span> <span>{</span>
            <span>tmp</span> <span>=</span> <span>rb_funcallv</span><span>(</span><span>obj</span><span>,</span> <span>rb_intern</span><span>(</span><span>&#34;external_encoding&#34;</span><span>),</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
        <span>}</span>
        <span>if</span> <span>(</span><span>is_obj_encoding</span><span>(</span><span>tmp</span><span>))</span> <span>{</span>
            <span>i</span> <span>=</span> <span>enc_check_encoding</span><span>(</span><span>tmp</span><span>);</span>
        <span>}</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>T_DATA</span><span>:</span>
        <span>if</span> <span>(</span><span>is_data_encoding</span><span>(</span><span>obj</span><span>))</span> <span>{</span>
            <span>i</span> <span>=</span> <span>enc_check_encoding</span><span>(</span><span>obj</span><span>);</span>
        <span>}</span>
        <span>break</span><span>;</span>
      <span>default:</span>
        <span>break</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>i</span><span>;</span>
<span>}</span>

<span>rb_encoding</span><span>*</span>
<span>rb_enc_get</span><span>(</span><span>VALUE</span> <span>obj</span><span>)</span>
<span>{</span>
    <span>return</span> <span>rb_enc_from_index</span><span>(</span><span>rb_enc_get_index</span><span>(</span><span>obj</span><span>));</span>
<span>}</span></code></pre></figure>

<p>As you can see, it’s a higher-level API implemented in a fairly defensive way, it performs a lot of type checks
to ensure it won’t cause a crash and to be able to deal with different types of objects.
All these conditionals don’t look like much, but as mentioned before, modern CPUs are very fast at computing things but pay a high price for conditionals unless they’re correctly predicted.</p>

<p>Then the thing to know is that conceptually, Ruby strings have a reference to their encoding, e.g.:</p>

<figure><pre><code data-lang="ruby"><span>&#34;Hello World&#34;</span><span>.</span><span>encoding</span> <span># =&gt; Encoding::UTF_8</span></code></pre></figure>

<p>So conceptually, they have a reference to another object, which naively should be a full-on 64-bit pointer. But since there’s only a (not so) small number of possible encodings,
instead of wasting a full 8 bytes to keep that reference, the Ruby VM instead stores a much smaller 7-bit number in a bitmap inside each String, which is called the <code>encoding_index</code>
or <code>enc_idx</code> for short.
That’s an offer you can use to then look up the actual encoding in a global array inside the virtual machine.
In low-level code that’s what we tend to call “pointer chasing” as in we have an address of memory, and go fetch its content from RAM.
If that RAM was recently loaded and is already in the CPU cache, it’s relatively fast, but if it isn’t, the CPU has to wait quite a long time for the data to be fetched.</p>

<p>If you are mostly working with higher-level languages, that probably doesn’t sound like much, but with low-level programming, fetching
memory from RAM is a bit like performing a SQL query for a Rails application, it’s way slower than doing a computation on already fetched data,
so similarly, that’s something you try hard not to do in hot spots.</p>

<p>In this case, there are several shortcuts <code>json</code> could take.</p>

<p>First <code>json</code> already knows it is dealing with a String, as such it doesn’t need to go through all the checks in <code>rb_enc_get_index</code> and can directly
use the lower level and much faster <code>RB_ENCODING_GET</code>.</p>

<p>Then, since all it cares about is whether the String is encoded in either ASCII or UTF-8, it doesn’t need the real <code>rb_encoding *</code> pointer, and
can directly check the returned index, skipping the need to load data from RAM.</p>

<p>So here’s how Mame rewrote that code:</p>

<figure><pre><code data-lang="c"><span>static</span> <span>int</span> <span>enc_utf8_compatible_p</span><span>(</span><span>int</span> <span>enc_idx</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>enc_idx</span> <span>==</span> <span>usascii_encindex</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
    <span>if</span> <span>(</span><span>enc_idx</span> <span>==</span> <span>utf8_encindex</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span><span>!</span><span>enc_utf8_compatible_p</span><span>(</span><span>RB_ENCODING_GET</span><span>(</span><span>obj</span><span>)))</span> <span>{</span>
    <span>// try to convert the string</span>
<span>}</span></code></pre></figure>

<p>Notice how it is now comparing encoding indexes instead of encoding pointers.</p>

<p>That very small change improved the <code>twitter.json</code> benchmark by another <code>8%</code>:</p>

<div><div><pre><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   126.000 i/100ms
Calculating -------------------------------------
               after      1.253k (± 1.5%) i/s  (797.91 μs/i) -      6.300k in   5.028081s

Comparison:
              before:     1159.6 i/s
               after:     1253.3 i/s - 1.08x  faster
</code></pre></div></div>

<h2 id="lookup-tables">Lookup Tables</h2>

<p>Yet another patch in Mame’s PR was to use <a href="https://lemire.me/blog/2024/10/14/table-lookups-are-efficient/">one of my favorite performance tricks, what’s called a “lookup table”</a>.</p>

<p>Dumping a string into JSON can be quite costly because for each character there are multiple checks to do first to know if the character
can simply be copied or if it needs to be escaped. The naive way looks like this (implemented in Ruby for better readability):</p>

<figure><pre><code data-lang="ruby"><span>buffer</span> <span>=</span> <span>+</span><span>&#34;&#34;</span>
<span>string</span><span>.</span><span>each_char</span> <span>do</span> <span>|</span><span>char</span><span>|</span>
  <span>if</span> <span>char</span><span>.</span><span>ord</span> <span>&lt;</span> <span>0x20</span> <span># ASCII control character</span>
    <span>case</span> <span>char</span>
    <span>when</span> <span>&#34;</span><span>\n</span><span>&#34;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\\</span><span>n&#34;</span>
    <span>when</span> <span>&#34;</span><span>\r</span><span>&#34;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\\</span><span>r&#34;</span>
    <span>when</span> <span>&#34;</span><span>\t</span><span>&#34;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\\</span><span>t&#34;</span>
    <span>when</span> <span>&#34;</span><span>\f</span><span>&#34;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\\</span><span>f&#34;</span>
    <span>when</span> <span>&#34;</span><span>\b</span><span>&#34;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\\</span><span>b&#34;</span>
    <span>else</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\u</span><span>00</span><span>#{</span><span>char</span><span>.</span><span>ord</span><span>}</span><span>&#34;</span>
    <span>end</span>
  <span>else</span>
    <span>case</span> <span>char</span>
    <span>when</span> <span>&#39;&#34;&#39;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#39;\\&#34;&#39;</span>
    <span>when</span> <span>&#39;\\&#39;</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>&#39;\\\\&#39;</span>
    <span>else</span>
      <span>buffer</span> <span>&lt;&lt;</span> <span>char</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>As you can see, it’s a lot of conditional, even in the fast path, we need to check for <code>c &lt; 0x20</code> and then for <code>&#34;</code> and <code>\</code> characters.</p>

<p>The idea of lookup tables is that you precompute a static array with that algorithm so that instead of doing multiple comparisons per character, all you do is read a boolean at a dynamic offset.
In Ruby that would look like this:</p>

<figure><pre><code data-lang="ruby"><span>JSON_ESCAPE_TABLE</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>256</span><span>,</span> <span>false</span><span>)</span>
<span>0x20</span><span>.</span><span>times</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>JSON_ESCAPE_TABLE</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>true</span>
<span>end</span>
<span>JSON_ESCAPE_TABLE</span><span>[</span><span>&#39;&#34;&#39;</span><span>]</span> <span>=</span> <span>true</span>
<span>JSON_ESCAPE_TABLE</span><span>[</span><span>&#39;\\&#39;</span><span>]</span> <span>=</span> <span>true</span>

<span>buffer</span> <span>=</span> <span>+</span><span>&#34;&#34;</span>
<span>string</span><span>.</span><span>each_char</span> <span>do</span> <span>|</span><span>char</span><span>|</span>
  <span>if</span> <span>JSON_ESCAPE_TABLE</span><span>[</span><span>char</span><span>]</span>
    <span># do the slow thing</span>
  <span>else</span>
    <span>buffer</span> <span>&lt;&lt;</span> <span>char</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>This uses a bit more static memory, but that’s negligible and makes the loop much faster.</p>

<p>With this, and based on the assumption that most strings don’t contain any character that needs to be escaped, Mame added a precondition to first cheaply check if we’re on the fast path,
and if we are, directly copy the entire string in the buffer all at once, so something like:</p>

<figure><pre><code data-lang="ruby"><span>buffer</span> <span>=</span> <span>+</span><span>&#34;&#34;</span>
<span>if</span> <span>string</span><span>.</span><span>each_char</span><span>.</span><span>none?</span> <span>{</span> <span>|</span><span>c</span><span>|</span> <span>JSON_ESCAPE_TABLE</span><span>[</span><span>c</span><span>]</span> <span>}</span>
  <span>buffer</span> <span>&lt;&lt;</span> <span>string</span>
<span>else</span>
  <span># do the slow char by char escaping</span>
<span>end</span></code></pre></figure>

<p>You can see <a href="https://github.com/ruby/json/pull/562/commits/a81ec4770af4a2f20a9dc06d0295cf5b93a7af91">Mame’s patch</a>, it’s a bit more cryptic because in C, but you should be able to
see the same pattern as described here, and that alone made a massive 30% gain on the <code>twitter.json</code> benchmark:</p>

<div><div><pre><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   164.000 i/100ms
Calculating -------------------------------------
               after      1.630k (± 2.3%) i/s  (613.43 μs/i) -      8.200k in   5.032935s

Comparison:
              before:     1258.1 i/s
               after:     1630.2 i/s - 1.30x  faster
</code></pre></div></div>

<h2 id="to-be-continued">To Be Continued</h2>

<p>I have way more optimizations than these ones to talk about, but I feel like it’s already a pretty packed blog post.</p>

<p>So I’ll stop here and work on some followup soon, hopefully I won’t lose my motivation to write :).</p>

  </div>
</article>

      </div>
    </div></div>
  </body>
</html>
