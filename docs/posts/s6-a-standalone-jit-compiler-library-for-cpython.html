<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/deepmind/s6">Original</a>
    <h1>S6: A standalone JIT compiler library for CPython</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">S6 was a project that started within DeepMind in 2019 to accelerate CPython with
just-in-time compilation (“JIT”). These features would be provided as a regular
Python library, and no changes to the CPython interpreter itself would be
necessary. S6 was aiming to do for Python what V8 did for Javascript (the name
is an <a href="https://en.wikipedia.org/wiki/Straight-six_engine" rel="nofollow">homage</a> to V8).
Work was based on CPython verison 3.7. Depending on the workload, we saw
speedups as high as 9.5x on common benchmarks.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import s6

@s6.jit
def foo(x):
  return x + 1"><pre><span>import</span> <span>s6</span>

<span>@<span>s6</span>.<span>jit</span></span>
<span>def</span> <span>foo</span>(<span>x</span>):
  <span>return</span> <span>x</span> <span>+</span> <span>1</span></pre></div>
<h2 dir="auto"><a id="user-content-project-goals" aria-hidden="true" href="#project-goals"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Project goals</h2>
<p dir="auto">Python is slow, and a lot of researchers use Python as their primary interface
to build models. This can create friction for researchers, and speeding up the
model building process can improve iteration and development time. The
<a href="https://en.wikipedia.org/wiki/Network_effect" rel="nofollow">network effect</a> of Python has
made moving to a different language very difficult. So with Python here to stay,
we looked to improve upon it.</p>
<p dir="auto">The requirements we set ourselves were:</p>
<ul dir="auto">
<li>Increase the speed of common programs x-fold: not 10%, but 10x.</li>
<li>Be fully compatible with CPython. Most tools, libraries, and infrastructure
that researchers use only work with CPython.</li>
<li>Not require any code changes. Users should be able to import S6, wrap their
top level function in a JIT annotation, and that’s it.</li>
</ul>
<h2 dir="auto"><a id="user-content-status-and-support" aria-hidden="true" href="#status-and-support"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Status and support</h2>
<p dir="auto">We have stopped working on S6 internally. As such, this repository has been
archived and we are not accepting pull requests or issues. We open-sourced the
code and provided a design overview below to spur conversations within the
Python community and inspire future work on improving Python.</p>
<h2 dir="auto"><a id="user-content-setting-it-up-locally" aria-hidden="true" href="#setting-it-up-locally"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Setting it up locally</h2>
<p dir="auto">We set up a Docker container and some Jupyter notebooks to allow you to build
and experiment with S6. To do so, follow these steps.</p>
<p dir="auto">Set up the S6 Docker container:</p>
<ol dir="auto">
<li>
<p dir="auto"><a href="https://docs.docker.com/get-started/#download-and-install-docker" rel="nofollow">Install docker</a>.</p>
</li>
<li>
<p dir="auto">Build the S6 docker container:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build -t deepmind-s6:latest ."><pre>docker build -t deepmind-s6:latest <span>.</span></pre></div>
</li>
</ol>
<p dir="auto">You can run the docker container in two different ways:</p>
<ol dir="auto">
<li>
<p dir="auto">By running a notebook server:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -p 8888:8888 deepmind-s6:latest jupyter lab --port 8888 --ip 0.0.0.0 --no-browser --allow-root --NotebookApp.token=SECRET_TOKEN"><pre>docker run -p 8888:8888 deepmind-s6:latest jupyter lab --port 8888 --ip 0.0.0.0 --no-browser --allow-root --NotebookApp.token=SECRET_TOKEN</pre></div>
<p dir="auto">Then open <code>localhost:8888/lab?token=SECRET_TOKEN</code> in a web browser.</p>
<p dir="auto">Demo <a href="https://github.com/deepmind/s6/blob/main/src/notebooks/hello_world.ipynb">notebooks</a> are found in the
<code>notebooks</code> directory.</p>
</li>
<li>
<p dir="auto">By running an interactive shell session:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -it deepmind-s6:latest /bin/bash"><pre>docker run -it deepmind-s6:latest /bin/bash</pre></div>
<p dir="auto">The test suite for S6 can be run from within a Docker shell session with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(cd /open-s6/s6/build; ninja test)"><pre>(cd /open-s6/s6/build<span>;</span> ninja test)</pre></div>
</li>
</ol>
<h2 dir="auto"><a id="user-content-benchmark-results" aria-hidden="true" href="#benchmark-results"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Benchmark results</h2>
<p dir="auto">Overall, S6 provides a speed of up to 10x over CPython for pure Python
benchmarks. Workloads that heavily rely on C APIs, like those that use NumPy,
are bottlenecked by the C API calltime. Future work could include targeted
optimisations in the C code to improve this; for example, use the profiling
metadata to skip all the type checks normally done by C APIs.</p>
<p dir="auto">Most testing during development was against internal benchmarks, or private
variants of external benchmarks. Here we report results on three public
<a href="https://github.com/python/pyperformance">pyperformance</a> benchmarks; their
docstrings detail minor modifications.</p>
<h3 dir="auto"><a id="user-content-richards" aria-hidden="true" href="#richards"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Richards</h3>
<p dir="auto"><a href="https://github.com/python/pyperformance/blob/main/pyperformance/data-files/benchmarks/bm_richards/run_benchmark.py">Richards</a>
is a common benchmark that best represents pure Python code that researchers
write. For the Richards benchmark located under the benchmarks directory, if you
run with 100 iterations, depending on your hardware, you should see a 7x speedup
over the default Python 3.7 interpreter.</p>
<ul dir="auto">
<li>On our internal dev machines, we saw speedups of 9.5x on average.</li>
</ul>
<h3 dir="auto"><a id="user-content-raytrace" aria-hidden="true" href="#raytrace"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Raytrace</h3>
<p dir="auto"><a href="https://github.com/python/pyperformance/blob/main/pyperformance/data-files/benchmarks/bm_raytrace/run_benchmark.py">Raytrace</a>
is a pure-Python mathematical benchmark.</p>
<ul dir="auto">
<li>On our internal dev machines, we saw speedups of 3-4.5x on average.</li>
</ul>
<h3 dir="auto"><a id="user-content-unpack-sequence" aria-hidden="true" href="#unpack-sequence"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Unpack Sequence</h3>
<p dir="auto"><a href="https://github.com/python/pyperformance/blob/main/pyperformance/data-files/benchmarks/bm_unpack_sequence/run_benchmark.py">Unpack sequence</a>
is the worst performing benchmark we ran on S6. The cause is that S6 has its own
<code>ceval.c</code> interpreter that is not as well optimized as the standard CPython one.
We had to write a separate <code>ceval.c</code>-like interpreter in order to add hooks for
S6 to compile functions and collect type feedback. With the standard unpack
sequence benchmark you can see a 5x slowdown as the main <code>do_unpacking</code> function
is called once and with that one call, we use our own, slower interpreter.</p>
<p dir="auto">Even then, <code>UNPACK_SEQUENCE</code> is a difficult bytecode to handle from a type
checking perspective. Even if the input to the function is an array/tuple, an
array/tuple can contain any different type and in different orderings. So we
need to type check every element to make sure that the JIT&#39;d function is being
passed the correct input types. Because of all this type checking, if a function
either unpacks a giant array/tuple or does a lot of unpacking (like the
benchmark), our compiled code can end up being slower than interpreted CPython.
As such, if we detect there are many or a large unpack, we avoid compiling the
function and bail out to the optimized <code>ceval.c</code> interpreter in CPython
everytime we come back to this function.</p>
<p dir="auto">With the issues of <code>UNPACK_SEQUENCE</code> in mind, we included two version of the
unpack sequence benchmark. The super slow one (0.2x speedup) is where the
for-loop is in <code>do_unpacking</code> so we never bail out to <code>ceval.c</code> and then a
faster one (0.97x speedup) where we took the for-loop out of <code>do_unpacking</code> and
instead call <code>do_unpacking</code> <code>loops</code> number of times.</p>
<h2 dir="auto"><a id="user-content-known-limitations" aria-hidden="true" href="#known-limitations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Known limitations</h2>
<p dir="auto">S6 exists as a standalone dependency and does not require any <em>code</em> changes in
CPython. However, it was developed for an environment with two unusual features:</p>
<ol dir="auto">
<li>Native code needs to store a frame pointer, which typically requires the
<code>-fno-omit-frame-pointer</code> compiler flag when building CPython and native
extensions. Without this change, jit compilation might crash in some cases.</li>
<li>In the CPython interpreter, the function <code>PyFrame_FastToLocalsWithError</code>
needs to be intercepted by S6. We used to do this by linking Python and
Python extensions with the linker flag
<code>--wrap=PyFrame_FastToLocalsWithError</code>, but this is not part of the current
release, and jit compilation might misbehave in some cases.</li>
</ol>
<p dir="auto">As discussed in the <a href="#unpack-sequence">unpack_sequence</a> benchmark section, S6
does not run well on giant functions. To mitigate this, break up your function
into smaller pieces.</p>
<p dir="auto">S6 only supports CPython 3.7, but with some changes it could be made to support
later CPython versions.</p>
<p dir="auto">There is further work to be done optimising S6&#39;s strongjit. Further performance
improvements would be expected from additional compiler optimisations, such as
inlining.</p>
<h2 dir="auto"><a id="user-content-design" aria-hidden="true" href="#design"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Design</h2>
<p dir="auto">S6 replaces the existing CPython interpreter/bytecode handler
<a href="https://github.com/python/cpython/blob/3.7/Python/ceval.c"><code>ceval.c</code></a> with our
own <code>interpreter.cc</code>. For every <code>PyCodeObject</code>, S6 does the following:</p>
<ul dir="auto">
<li>
<p dir="auto">Check to see if the function has already been compiled; if the code has, S6
looks up and runs the compiled code.</p>
</li>
<li>
<p dir="auto">If the code is not compiled, S6 runs the S6 bytecode interpreter, which is
very similar to the CPython interpreter.</p>
</li>
</ul>
<p dir="auto">Similarly to V8, we maintain a counter that counts how many interpreter
instructions have been executed. When this reaches a threshold, the PyCodeObject
at the top of the call stack is considered for compilation.</p>
<p dir="auto">To determine what code to compile, we use the Oracle which asynchronously
compiles the function after a certain number of bytecode instructions and
function visits. When compiling code, S6 translates it to <em>strongjit</em>: an
intermediate representation suitable for various optimization passes. CPython
bytecode implementations can be complex, and translation may create many
strongjit instructions per Python bytecode.</p>
<p dir="auto">Given type feedback, we may choose to make assumptions about inputs to a
function in order to generate optimisation opportunities (for instance that an
input is always an integer). We refer to this as function specialization. Guards
are put in place to check that these assumptions hold. If they do not, then the
function must be de-optimized and the bytecode is interpreted as before. Because
checking the type of all arguments at every function call may be costly, and to
avoid producing huge numbers of specializations, we only specialize on the
common case of the type of the first argument (usually <code>self</code>).</p>
<p dir="auto">When deoptimizing, we convert the optimized function state into CPython state
(PyFrameObject) and continue with the normal interpreter. However in many cases
we are not at a bytecode boundary when we deoptimize. In this case we interpret
the strongjit IR until we get to a boundary point. After writing and optimizing
the strongjit IR, S6 lowers it to x86 machine code using the <code>asmjit</code> library.</p>
<h3 dir="auto"><a id="user-content-hidden-classes" aria-hidden="true" href="#hidden-classes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hidden classes</h3>
<p dir="auto">In its initial design, S6 used inline caching keyed on an object’s <em>Map</em>. A Map
comes from prototype-based languages (introduced in
<a href="https://link.springer.com/chapter/10.1007/BFb0057013" rel="nofollow">SELF</a>). It is also termed
a <em>Shape</em> (in V8). It attempts to describe the location of attributes within an
object. All objects with the same Map have the same attributes in the same
locations. An <em>inline cache</em> memoizes the last result of an operation based on
the Map of the input.</p>
<p dir="auto">Frequently we used the Map as a cache key, as any modification to the behavior
of an object should result in a <em>Map transition</em> (Maps are immutable).</p>
<p dir="auto">For example, if we have the following in Python:</p>

<p dir="auto">The pseudo code of lookup would look like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if map(c) == M:
  return c.__attributes__[0]
else:
  return __getattr__(c, &#34;x&#34;)"><pre><span>if</span> <span>map</span>(<span>c</span>) <span>==</span> <span>M</span>:
  <span>return</span> <span>c</span>.<span>__attributes__</span>[<span>0</span>]
<span>else</span>:
  <span>return</span> <span>__getattr__</span>(<span>c</span>, <span>&#34;x&#34;</span>)</pre></div>
<p dir="auto">Or for example, as shown in the diagram below, to get the <code>x</code> attribute we:</p>
<ol dir="auto">
<li>Obtain the <code>tp_dictptr</code> field from the object’s type.</li>
<li>Use the <code>tp_dictptr</code> to get the <code>__dict__</code> field’s address from the object.</li>
<li>Follow the <code>__dict__</code> to get the <code>PyDictObject</code> itself.</li>
<li>Look at the <code>values</code> array. The <code>Map</code> from step 2 tells you how to map from
key to value.</li>
</ol>
<p dir="auto"><em>(below, the red arrows are direct pointers, while purple arrows are indirect
using the offset int value)</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/s6/blob/main/src/images/attribute_access.png"><img src="https://github.com/deepmind/s6/raw/main/src/images/attribute_access.png" alt="Attribute access diagram."/></a></p>
<p dir="auto">However, there are at least three issues with this approach:</p>
<p dir="auto">In almost all instances <strong>a cache keyed on a <code>Map</code> is insufficient</strong>, as
Python’s type system allows modifications to an object’s <code>Type</code> to modify
attribute lookup on the object, even if the object has overridden a given
attribute already. The example of this is data descriptors. A modification to a
<code>Type</code> potentially invalidates all associated <code>Map</code>s. A <code>Map</code> could be
specialized on the <em>type version</em> of its type, but this loses all the benefits
of structural typing. So when we should have a monomorphic cache lookup since
two types look the same (duck typing), we still require a polymorphic lookup.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class C(object):
  def __init__(self):
    self.x = 2
class D(object):
  def __init__(self):
    self.x = 3
def f(a : Union[C or D]):
  return a.x  # Structurally monomorphic, nominally polymorphic."><pre><span>class</span> <span>C</span>(<span>object</span>):
  <span>def</span> <span>__init__</span>(<span>self</span>):
    <span>self</span>.<span>x</span> <span>=</span> <span>2</span>
<span>class</span> <span>D</span>(<span>object</span>):
  <span>def</span> <span>__init__</span>(<span>self</span>):
    <span>self</span>.<span>x</span> <span>=</span> <span>3</span>
<span>def</span> <span>f</span>(<span>a</span> : <span>Union</span>[<span>C</span> <span>or</span> <span>D</span>]):
  <span>return</span> <span>a</span>.<span>x</span>  <span># Structurally monomorphic, nominally polymorphic.</span></pre></div>
<p dir="auto"><strong>Inline caches reference mutable data</strong>. This can be a problem when dealing
with functions. Holding borrowed references to function objects is unsafe, and
acquiring references to function objects can be costly.</p>
<div dir="auto" data-snippet-clipboard-copy-content="def f(l, a):
  def g(x): ...
  for x in l:
    a += g(x) # inline cache holds reference to &#34;g&#34;. Unsafe if borrowed, costly
              # if increffed every time, and changes the lifetime of any object
              # captured by `g`.
  return a"><pre><span>def</span> <span>f</span>(<span>l</span>, <span>a</span>):
  <span>def</span> <span>g</span>(<span>x</span>): ...
  <span>for</span> <span>x</span> <span>in</span> <span>l</span>:
    <span>a</span> <span>+=</span> <span>g</span>(<span>x</span>) <span># inline cache holds reference to &#34;g&#34;. Unsafe if borrowed, costly</span>
              <span># if increffed every time, and changes the lifetime of any object</span>
              <span># captured by `g`.</span>
  <span>return</span> <span>a</span></pre></div>
<p dir="auto">We needed to <strong>add an extra field to <code>PyObject</code></strong> to store the map pointer, but
this would have broken ABI guarantees and made the possibility of upstreaming S6
into CPython very challenging.</p>
<p dir="auto">So instead we implemented hidden classes. Hidden classes are a parallel type
system to Python’s types. They are a subcategorization of types - objects of a
unique type may have different hidden classes, but objects of a unique hidden
class always have the same type. In this way they are distinct from <em>Maps</em> or
<em>Shapes</em> that provide uniqueness based only on structural typing.</p>
<p dir="auto">Hidden classes provide:</p>
<ul dir="auto">
<li>Behavioral stability; if an object’s hidden class has not changed, its
behavior has not changed.</li>
<li>A dense numbering; for efficient lookup in a global dispatch table.</li>
<li>A compile-time-inspectable enumeration of members and methods.</li>
<li>Type information about member variables and methods.</li>
<li>Type information is provided as a lattice in which information becomes
weaker but never stronger.</li>
</ul>
<p dir="auto">Given that hidden classes contain a lattice of type information, they are not
immutable, but they do change in well-defined and observable ways.</p>
<p dir="auto">CPython never uses hidden classes. They are invisible to CPython and no type
queries, subclass queries will never return different information based on
hidden classes.</p>
<h4 dir="auto"><a id="user-content-obtaining-a-class-from-a-pyobject" aria-hidden="true" href="#obtaining-a-class-from-a-pyobject"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Obtaining a class from a PyObject</h4>
<p dir="auto">We must be able to store a mapping between PyObjects and hidden classes. The
mapping must be incredibly fast.</p>
<p dir="auto">One of the goals of S6 is to be import-compatible with existing CPython.
Modifications to the PyObject class were not allowed, and as PyObject only
contains two members (ob_refcnt and ob_type), there is nowhere to hide a class
ID. Instead, we hide the hidden class ID inside PyDictObjects and PyTypeObjects.</p>
<p dir="auto">We observe that there are two categories of object - objects that behave the
same as a newly created object of their type, and those that behave differently.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class A(object): pass
a = A()
b = A()  # a and b behave the same, and are of the same type, so same class ID.
b.x = 2  # Now b behaves differently from A, they must have differing class IDs."><pre><span>class</span> <span>A</span>(<span>object</span>): <span>pass</span>
<span>a</span> <span>=</span> <span>A</span>()
<span>b</span> <span>=</span> <span>A</span>()  <span># a and b behave the same, and are of the same type, so same class ID.</span>
<span>b</span>.<span>x</span> <span>=</span> <span>2</span>  <span># Now b behaves differently from A, they must have differing class IDs.</span></pre></div>
<p dir="auto">For objects that behave the same a a newly created object of the same type, we
can store the class ID in the type object.</p>
<p dir="auto">For objects that behave differently: in order to behave differently they must
have a <code>__dict__</code>. This is the only means of changing behaviour. Therefore we
can store the class ID in the PyDictObject used as <code>__dict__</code>.</p>
<p dir="auto">Specifically: Class identifiers are dense integers &lt;= 20 bits in size.</p>
<p dir="auto">If the PyObject has a <code>__dict__</code>, the class identifier uses the uppermost 20
bits of the <code>dict</code>’s <code>ma_version_tag</code> field.</p>
<p dir="auto">Otherwise the class identifier uses the uppermost 20 bits of <code>PyTypeObject</code>’s
<code>tp_flags</code> field. This field is 64-bits long and is already zeroed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/s6/blob/main/src/images/class_identifier_storage.png"><img src="https://github.com/deepmind/s6/raw/main/src/images/class_identifier_storage.png" alt="Class identifier storage diagram."/></a></p>
<p dir="auto">This has implications:</p>
<ul dir="auto">
<li>We don’t support hidden classes for objects with custom attribute getters or
setters, because modifications to an object’s attributes require a <code>dict</code>
for us to store the class ID.</li>
<li>If an object’s <code>dict</code> is modified outside the visibility of S6, a new
<code>ma_version_tag</code> will be set by CPython. This will have the upper 20 bits
zeroed, setting the effective class ID to 0. This allowed us to notice if
our assumptions have been broken behind our back. Note that wrap-around for
the other 44 bits would take 5 years if dicts were modified at 100kHz.</li>
<li>We don’t support objects with <code>tp_dictoffset &lt; 0</code>. This means the <code>dict</code> is
offset from the end of the object in memory, which is a more complex
calculation. This is rare and only really used for <code>str</code> or <code>long</code>
subclasses.</li>
</ul>
<p dir="auto">The ability to store class IDs inside the <code>PyTypeObject</code> allows us to store a
hidden class for all objects even if they do not have a <code>dict</code>. An example of
this is builtin types, which are generally immutable. Objects that have custom
attribute setters are still excluded however, because tracking whether an object
still has the behaviors of its base type or not is impossible.</p>
<h4 dir="auto"><a id="user-content-behavioral-changes" aria-hidden="true" href="#behavioral-changes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Behavioral changes</h4>
<p dir="auto">There are two classes of behavioral change: modifications to the type or a
supertype and modifications to an object.</p>
<h5 dir="auto"><a id="user-content-type-modification" aria-hidden="true" href="#type-modification"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Type modification</h5>
<p dir="auto">Modification of a type potentially changes the behavior of all hidden classes
indirectly derived from that type. Therefore, in order to use a hidden class
with a type, we must ensure that we can detect all behavioral changes of the
type and its supertypes.</p>
<p dir="auto">This is achieved by wrapping the modifiable members of the type and all its
supertypes (<code>tp_setattro</code>, <code>__bases__</code>, <code>__class__</code>) with a wrapper function
that informs S6. If the type has a custom <code>setattro</code>, we do not optimize the
type.</p>
<p dir="auto">When a type is modified, the world is stopped (easy because of the GIL),
compilations are halted, all affected classes are modified and if any attribute
of a class was changed that generated code relied upon, the generated code is
thrown away.</p>
<h5 dir="auto"><a id="user-content-object-modification" aria-hidden="true" href="#object-modification"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Object modification</h5>
<p dir="auto">If an attribute is added or deleted from an object, the object must take a class
transition and have a new class. This is so that all attribute loads and stores
can load and store without <code>nullptr</code> or out of bounds guards.</p>
<p dir="auto">If an existing attribute is <em>modified</em>, then it is possible the behavior of an
object changes. Examples include modifying a method. The method table for the
object is then incorrect; the object must undergo a class transition. Attributes
for which modification <em>requires</em> a class transition are marked as ‘behavioral’.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class C(object):
  def f(self): pass

a = C()  # Has hidden class H
a.x = 2  # New hidden class, H -&gt; H2 because new attribute `x`.
a.x = 3  # Same class H2 - attribute merely changed.
a.f = 4  # New hidden class, H2 -&gt; H3, because `f` was a member function before
         # and thus was marked &#34;behavioral&#34;."><pre><span>class</span> <span>C</span>(<span>object</span>):
  <span>def</span> <span>f</span>(<span>self</span>): <span>pass</span>

<span>a</span> <span>=</span> <span>C</span>()  <span># Has hidden class H</span>
<span>a</span>.<span>x</span> <span>=</span> <span>2</span>  <span># New hidden class, H -&gt; H2 because new attribute `x`.</span>
<span>a</span>.<span>x</span> <span>=</span> <span>3</span>  <span># Same class H2 - attribute merely changed.</span>
<span>a</span>.<span>f</span> <span>=</span> <span>4</span>  <span># New hidden class, H2 -&gt; H3, because `f` was a member function before</span>
         <span># and thus was marked &#34;behavioral&#34;.</span></pre></div>
<h5 dir="auto"><a id="user-content-cacheable-attributes" aria-hidden="true" href="#cacheable-attributes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cacheable attributes</h5>
<p dir="auto">Attributes that do not change value across all object instances of a class are
termed ‘cacheable’. These attributes have a stable value and the code generator
may emit code that relies upon this value being stable. Simple cases include a
boolean attribute. An attribute-write to an attribute that is currently marked
‘cacheable’ to a different value simply removes the ‘cacheable’ flag and any
code generated that relied on the attribute is thrown away.</p>
<h4 dir="auto"><a id="user-content-globals" aria-hidden="true" href="#globals"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Globals</h4>
<p dir="auto">Python code contains a large number of lookups to the <code>__globals__</code> dict. Even a
function call requires consulting the globals dict to obtain the
<code>PyFunctionObject</code> for a symbol name.</p>
<p dir="auto">We can consider this dict in the same way as we treat object <code>__dict__</code> fields;
we store a class ID in the globals dict, and can use all of the fast attribute
tricks implemented for objects on global values.</p>
<p dir="auto">In particular, the <code>cacheable</code> property described above implicitly allows us to
optimize away code hidden behind global booleans that are never modified:</p>
<div dir="auto" data-snippet-clipboard-copy-content="DEBUG_MODE = False  # Set this to True to enable debug statements.

def f(a):
  if DEBUG_MODE:  # This is a load of globals.DEBUG_MODE, which is known to be
    print(a)      # always False at runtime.
  return a + 1"><pre><span>DEBUG_MODE</span> <span>=</span> <span>False</span>  <span># Set this to True to enable debug statements.</span>

<span>def</span> <span>f</span>(<span>a</span>):
  <span>if</span> <span>DEBUG_MODE</span>:  <span># This is a load of globals.DEBUG_MODE, which is known to be</span>
    <span>print</span>(<span>a</span>)      <span># always False at runtime.</span>
  <span>return</span> <span>a</span> <span>+</span> <span>1</span></pre></div>
<h4 dir="auto"><a id="user-content-adoption-of-new-types-and-objects" aria-hidden="true" href="#adoption-of-new-types-and-objects"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Adoption of new types and objects</h4>
<p dir="auto"><em>Adoption</em> of a type or object is where S6 determines the correct hidden class
and sets it. Adoption of an object involves ensuring that its type is adopted
and setting its hidden class. This may involve inspecting the dictionary to see
which attributes have already been set. Adoption of a type involves creating a
new hidden class, setting the <code>Py_TPFLAGS_S6_Adopted</code> flag and overriding
<code>tp_new</code> to a wrapper function that allows us to adopt all new instances of the
object.</p>
<p dir="auto">When S6 is initialized, we eagerly scan the type hierarchy to adopt all types.
We override <code>PyTypeObject::tp_new</code> to a wrapper that lets us detect and adopt
newly created types.</p>
<p dir="auto">This should allow us to catch all new instances of all objects except some
extension objects (Extension types that call <code>Py_Ready()</code> for the first time
<em>after</em> we have greedily scanned the type hierarchy). These will be small in
number and we can add mitigations if needed (like adopting in tactical places
like <code>GetAttr</code>).</p>
<h3 dir="auto"><a id="user-content-oracle" aria-hidden="true" href="#oracle"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Oracle</h3>
<p dir="auto">The <code>Oracle</code> class determines which functions are worth compiling and manages
the compilation queue. For development/debugging, you can configure whether
functions should be compiled asynchronously/synchronously, how often functions
are profiled and compiled, and more.</p>
<p dir="auto">Compilation in the Oracle is a two step process. We don’t immediately compile
the function we first step into. Every <code>profile_bytecode_instructions_interval</code>
instructions, the current <code>PyCodeObject</code> is inspected and <code>hotness_threshold</code>
decremented; if <code>hotness_threshold</code> reaches zero, the object will be optimized.
This two-stage process reduces the frequency of accessing code metadata.</p>
<h3 dir="auto"><a id="user-content-arithmetic-unboxing" aria-hidden="true" href="#arithmetic-unboxing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Arithmetic Unboxing</h3>
<p dir="auto">Since <code>bool</code>s/<code>float</code>s/<code>long</code>s in Python are all objects, they are boxed types.
Doing arithmetic operations on these boxed types can be very expensive compared
to a single assembly instruction on values in registers. And since we collect
type information, we can unbox the values from the CPython boxed types to do
much faster arithmetic operations. Refer to <code>UnboxInst</code> and <code>BoxInst</code> for more
information.</p>
<h2 dir="auto"><a id="user-content-api" aria-hidden="true" href="#api"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>API</h2>
<h3 dir="auto"><a id="user-content-s6jit" aria-hidden="true" href="#s6jit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>@s6.jit</code></h3>
<p dir="auto">Decorator to mark the function as JITable to S6. When the callable is invoked,
just-in-time compilation mode is enabled if it was not enabled already. All
functions called transitively by the decorated function are considered for
just-in-time compilation, but only one function is compiled at a time. Note that
a function in the call stack is not necessarily compiled on the first call, but
only after some number of calls. See the Oracle section for more details.</p>
<h3 dir="auto"><a id="user-content-developer-apis" aria-hidden="true" href="#developer-apis"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Developer APIs</h3>
<p dir="auto">A number of internal APIs are exposed by calling <code>s6.inspect(foo)</code> for any
function <code>foo</code> that is decorated with <code>@s6.jit</code> or have been marked for tracing
if the decorated function called the function. These are completely unnecessary
during normal operation, and are made accessible for users to inspect and
introspect the JIT process.</p>
<h4 dir="auto"><a id="user-content-strongjit" aria-hidden="true" href="#strongjit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>strongjit</code></h4>
<p dir="auto">Returns a string version of the intermediate representation used by S6 of <code>fn</code>,
which is named “strongjit”. The version returned here is the version after
optimizations before it is compiled to machine code. The strongjit can be
interpreted by using the <code>_evaluate</code> method of the s6.jit object.</p>
<h4 dir="auto"><a id="user-content-is_compiled" aria-hidden="true" href="#is_compiled"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>is_compiled</code></h4>
<p dir="auto">Returns <code>True</code> if <code>fn</code> is currently compiled, and <code>False</code> otherwise.</p>
<h4 dir="auto"><a id="user-content-force_compile" aria-hidden="true" href="#force_compile"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>force_compile()</code></h4>
<p dir="auto">Compiles <code>fn</code>, if it has not already been compiled. Throws an exception if the
compilation fails.</p>
<h4 dir="auto"><a id="user-content-deoptimize" aria-hidden="true" href="#deoptimize"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>deoptimize()</code></h4>
<p dir="auto">Deoptimize <code>fn</code>. This only deoptimizes the main specialization. Throws
<code>NotCompiledError</code> if not compiled</p>
<h4 dir="auto"><a id="user-content-_evaluate" aria-hidden="true" href="#_evaluate"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>_evaluate(...)</code></h4>
<p dir="auto">Evaluates <code>fn</code> with the S6 evaluator. &#34;Evaluating&#34; means interpreting the S6
strongjit of <code>fn</code>.</p>
<p dir="auto">The function <code>fn</code> needs to be compiled, otherwise execution will fall back to
using the CPython interpreter and compilation will never be triggered. This
function has no purpose other than debugging. If calling a compiled function
with <code>_evaluate</code> doesn&#39;t result in the same behavior as when calling it will the
normal call (of a jitted function), then S6 code generation has a bug.</p>
<p dir="auto">This will apply to all functions called by <code>fn</code> recursively except if another
explicit call to the S6 API changes it. If a called function wasn&#39;t compiled,
execution will revert to using the plain CPython interpreter.</p>
<h2 dir="auto"><a id="user-content-strongjit-ir" aria-hidden="true" href="#strongjit-ir"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Strongjit IR</h2>
<p dir="auto">Strongjit is a static single-assignment form intermediate representation (SSA
IR) that uses block arguments instead of PHI instructions for control flow. To
produce optimized code, Python bytecode is translated to strongjit. Successive
optimisation passes improve the strongjit. The improved strongjit is then
translated to assembly. The design goals of the IR were:</p>
<ul dir="auto">
<li>Textually round-trippable for testing.</li>
<li>Compact, cache efficient. This is a JIT compiler, and we manipulate existing
instructions/ops much less than frameworks like MLIR. Strongjit is,
however, designed to be easily translatable to MLIR.</li>
<li>Amenable to standard operations and traversals found in optimizing compilers</li>
<li>Certain operations should be cheap:
<ul dir="auto">
<li>Instruction insertion.</li>
<li>Instruction deletion.</li>
<li>Block insertion, deletion, splitting.</li>
<li>RPO traversal.</li>
<li>Traversing def-use chains (at least from use to def; traversing from a
def to all uses is less common).</li>
<li>Holding a handle to an instruction that is invariant to instruction
insertion/deletion.</li>
</ul>
</li>
</ul>
<h3 dir="auto"><a id="user-content-blocks-and-instructions" aria-hidden="true" href="#blocks-and-instructions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blocks and Instructions</h3>
<ul dir="auto">
<li>
<p dir="auto"><code>Value</code>s are the base of the hierarchy. Basic blocks, instructions and block
arguments are all values. They can use other <code>Value</code>s and be used in turn.
<code>Value</code>s have an operand list.</p>
</li>
<li>
<p dir="auto"><code>Instruction</code>s are <code>Value</code>s that reside inside a <code>Block</code>. Their address is
constant and is never reused.</p>
</li>
<li>
<p dir="auto"><code>Block</code>s are <code>Value</code>s. <code>Instruction</code>s can refer to <code>Block</code>s as operands, for
example <code>jmp &amp;0</code>. <code>Block</code>s contain a doubly linked list of <code>Instruction</code>s.
<code>Block</code>s do not own the storage for <code>Instruction</code>s - this is owned by
<code>Function</code>.</p>
</li>
<li>
<p dir="auto"><code>Function</code>s are the outermost unit of the hierarchy. They maintain a list of
<code>Block</code>s and own the storage for all <code>Block</code>s and <code>Instruction</code>s. The list
of <code>Block</code>s is again a doubly linked list.</p>
</li>
<li>
<p dir="auto"><code>Offset</code>: a bytecode instruction offsets. Gives a location within
interpreted code. Used for exception/tracing location information and for
deoptimization out of generated code.</p>
</li>
</ul>
<p dir="auto">For cache locality, all instructions reside in a single deque-like container
that uses tombstones when instructions are erased to keep all instruction
addresses constant. This allows pointers to instructions to be stored.</p>
<p dir="auto">There is a lightweight class hierarchy that uses the instruction opcode as a
discriminator (See: <code>casts</code>) and allows rich, type safe accessors/mutators.</p>
<h3 dir="auto"><a id="user-content-instructions" aria-hidden="true" href="#instructions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Instructions</h3>
<p dir="auto">See implementation in <a href="https://github.com/deepmind/s6/blob/main/src/strongjit/instructions.h"><code>instructions.h</code></a>.</p>
<ul dir="auto">
<li>
<p dir="auto"><code>ConstantInst</code>: Materializes an <code>int64</code> immediate as a <code>Value</code>.</p>
</li>
<li>
<p dir="auto"><code>JmpInst</code>: An unconditional jump to a single successor.</p>
</li>
<li>
<p dir="auto"><code>BrInst</code>: A conditional branch to two successors.</p>
</li>
<li>
<p dir="auto"><code>CompareInst</code>: Compares two operands.</p>
</li>
<li>
<p dir="auto"><code>ExceptInst</code>: Unconditional jump to the exception handler.</p>
</li>
<li>
<p dir="auto"><code>DeoptimizeIfInst</code>: A conditional deoptimize. The <code>true_successor</code> is a
deoptimized block. Maintains a set of values that are required in order to
run the deoptimized code.</p>
</li>
<li>
<p dir="auto"><code>ReturnInst</code>: Unconditional return.</p>
</li>
<li>
<p dir="auto"><code>UnreachableInst</code>: Terminate the current control flow arc with an error.</p>
</li>
<li>
<p dir="auto"><code>NegateInst</code>: Unary arithmetic negation.</p>
</li>
<li>
<p dir="auto"><code>NotInst</code>: Unary boolean <code>not</code>.</p>
</li>
<li>
<p dir="auto"><code>AddInst</code>: Binary arithmetic addition.</p>
</li>
<li>
<p dir="auto"><code>SubtractInst</code>: Binary arithmetic subtraction.</p>
</li>
<li>
<p dir="auto"><code>MultiplyInst</code>: Binary arithmetic multiplication.</p>
</li>
<li>
<p dir="auto"><code>DivideInst</code>: Binary arithmetic division.</p>
</li>
<li>
<p dir="auto"><code>RemainderInst</code>: Binary arithmetic modulo operation.</p>
</li>
<li>
<p dir="auto"><code>AndInst</code>: Binary boolean <code>and</code> operation.</p>
</li>
<li>
<p dir="auto"><code>OrInst</code>: Binary boolean <code>or</code> operation.</p>
</li>
<li>
<p dir="auto"><code>XorInst</code>: Binary boolean <code>xor</code> operation.</p>
</li>
<li>
<p dir="auto"><code>ShiftLeftInst</code>: Binary shift-left operation.</p>
</li>
<li>
<p dir="auto"><code>ShiftRightSignedInst</code>: Binary signed shift-right operation.</p>
</li>
<li>
<p dir="auto"><code>IntToFloatInst</code>: integer to float conversion.</p>
</li>
<li>
<p dir="auto"><code>SextInst</code>: Sign-extension operation.</p>
</li>
<li>
<p dir="auto"><code>IncrefInst</code>: Increase reference count.</p>
</li>
<li>
<p dir="auto"><code>DecrefInst</code>: Decrease reference count.</p>
</li>
<li>
<p dir="auto"><code>LoadInst</code>: Loads from a pointer location with optional extension.</p>
</li>
<li>
<p dir="auto"><code>LoadGlobalInst</code>: Loads a global by name, given an index into the <code>kNames</code>
tuple. Lookup follows the Python convention, looking in the frame globals
dict and then in builtins if not found in globals. The result is a borrowed
reference to a <code>PyObject*</code> or <code>0</code> (with an appropriate exception set) if the
lookup failed.</p>
</li>
<li>
<p dir="auto"><code>StoreInst</code>: Stores to a pointer location with optional truncation.</p>
</li>
<li>
<p dir="auto"><code>FrameVariableInst</code>: Obtains the address of a local variable. This
instruction also takes an index <code>i</code>, used with the <code>kConsts</code>, <code>kNames</code>,
<code>kFastLocals</code> and <code>kFreeVars</code> kinds.</p>
</li>
<li>
<p dir="auto"><code>CallNativeInst</code>: Calls a C function by symbol. The callee must be in a
known <code>allowlist</code>.</p>
</li>
<li>
<p dir="auto"><code>RematerializeInst</code>: A lazily called <code>CallNativeInst</code>. It exists to allow
eliding work on the fast path that needs to be done if we deoptimize. An
example here is eliding an attribute load for a method call. If we are
forced to deoptimize before the call, for example while computing arguments,
we are forced to materialize the attribute load. A <code>RematerializeInst</code> is
only run during deoptimization, if the de-optimizer finds a
<code>RematerializeInst</code> in the value stack it will call the runtime function to
materialize the true value.</p>
</li>
<li>
<p dir="auto"><code>CallPythonInst</code>: Calls a Python value.</p>
</li>
<li>
<p dir="auto"><code>CallAttributeInst</code>: Calls an attribute on a value. This is equivalent to
<code>(call_python (call_native s6::GetAttr $x, &#34;attr&#34;), ...)</code>. The attribute is
stored as a string inside the function&#39;s string table.</p>
</li>
<li>
<p dir="auto"><code>CallNativeIndirectInst</code>: Calls a native function through a function
pointer.</p>
</li>
<li>
<p dir="auto"><code>SafepointInst</code>: A <code>BytecodeBeginInst</code>, <code>YieldValueInst</code> or a
<code>DeoptimizeIfSafepointInst</code>. It contains a bytecode offset, value stack and
try handler stack; enough information to construct an accurate interpreter
frame.</p>
</li>
<li>
<p dir="auto"><code>BytecodeBeginInst</code>: Marks the beginning of a bytecode instruction. This
contains all the information required to reconstruct a CPython interpreter
state: bytecode offset, value stack contents and try-block stack contents.</p>
</li>
<li>
<p dir="auto"><code>YieldValueInst</code>: Yields within a generator function. The function&#39;s state
is saved, and can be resumed after the yield. <code>YieldValueInst</code> takes a
single operand that is yielded to its caller, and its result is the value
the caller sends back. Because generators may be deoptimized while paused,
<code>YieldValueInst</code> also holds enough information to reconstruct an interpreter
frame (it is a <code>SafepointInst</code>).</p>
</li>
<li>
<p dir="auto"><code>DeoptimizeIfSafepointInst</code>: Deoptimizes if a condition is <code>true</code> or
optionally <code>false</code>. This instruction has enough information to materialize
an interpreter frame (it is a <code>SafepointInst</code>), so it does not need to act
as control flow - if deoptimization occurs then no more strongjit IR code is
run.</p>
</li>
<li>
<p dir="auto">In this way it is distinguished from <code>DeoptimizeIfInst</code>, which deoptimizes
but is not at a <code>Safepoint</code> boundary and needs to run more strongjit code
(in the evaluator, usually) to get to a boundary.</p>
</li>
<li>
<p dir="auto"><code>AdvanceProfileCounterInst</code>: Adds amount to the profile counter. This
indicates that approximately the amount of CPython bytecodes of work has
been performed.</p>
</li>
<li>
<p dir="auto"><code>IncrementEventCounterInst</code>: Increments a named event counter managed by the
<code>EventCounters</code> singleton. Each event counter counts the number of times
that it has been incremented by reaching a trace point during the execution
of compiled code.</p>
</li>
<li>
<p dir="auto"><code>TraceBeginInst</code>: Starts a trace event with a named argument in the trace
category <code>TraceCategories::kFunctionExecution</code>. The name is stored in the
global intern table. Deoptimization is handled implicitly. Each
<code>TraceBeginInst</code> must be balanced by a <code>TraceEndInst</code>. This means that a
<code>TraceBeginInst</code> inserted at the beginning of a function must be balanced by
a <code>TraceEndInst</code> at all exit points, which include:</p>
<ul dir="auto">
<li><code>ReturnInst</code></li>
<li><code>ExceptInst</code>, where the instruction has no successors.</li>
<li><code>YieldInst</code>, with a matching <code>TraceBeginInst</code> after the <code>YieldInst</code> to
resume the event.</li>
</ul>
</li>
<li>
<p dir="auto"><code>TraceEndInst</code>: Ends a trace event with a named argument in the trace
category <code>TraceCategories::kFunctionExecution</code>. The trace event must have
been started by a corresponding <code>TraceBeginInst</code>.</p>
</li>
<li>
<p dir="auto"><code>BoxInst</code>: Constructs a Python <code>Long</code>/<code>Float</code>/<code>Boolean</code> from the operand.</p>
</li>
<li>
<p dir="auto"><code>UnboxInst</code>: Extracts a native <code>Long</code>/<code>Float</code>/<code>Boolean</code> from a Python
object. If the object is not of the correct type (e.g. <code>PyFloat</code> where
<code>PyLong</code> is expected) or, in the case of <code>PyLong</code>, its value exceeds 64
bits, then the <code>overflow</code> flag is set. This can be detected using
<code>overflowed?</code> as the very next instruction.</p>
</li>
<li>
<p dir="auto"><code>OverflowedInst</code>: Determines whether the operand overflowed. The operand
must be an arithmetic or unbox instruction, and must occur immediately
before this instruction in the same block.</p>
</li>
<li>
<p dir="auto"><code>FloatZeroInst</code>: Determines whether the operand is floating point zero,
either positive or negative.</p>
</li>
<li>
<p dir="auto"><code>GetClassIdInst</code>: Given an object, returns its class ID.</p>
</li>
<li>
<p dir="auto"><code>GetObjectDictInst</code>: Given an object, returns its dict or zero on failure.</p>
<ul dir="auto">
<li>If the <code>dictoffset</code> or type are known, this instruction can operate more
efficiently.</li>
</ul>
</li>
<li>
<p dir="auto"><code>GetInstanceClassIdInst</code>: Given an object&#39;s <code>__dict__</code>, returns its class
ID.</p>
</li>
<li>
<p dir="auto"><code>CheckClassIdInst</code>: Checks if an object has a particular class ID.</p>
</li>
<li>
<p dir="auto"><code>LoadFromDictInst</code>: Given an object&#39;s <code>__dict__</code>, loads
<code>__dict__.ma_values[index]</code>.</p>
</li>
<li>
<p dir="auto"><code>StoreToDictInst</code>: Given an object&#39;s <code>__dict__</code>, stores to
<code>__dict__.ma_values[index]</code> and returns the value replaced.</p>
</li>
<li>
<p dir="auto"><code>CallVectorcallInst</code>: Calls a native function with CPython&#39;s vectorcall
calling convention.</p>
</li>
<li>
<p dir="auto"><code>SetObjectClassInst</code>: Sets the class ID of an object. The object and its
instance dictionary are passed, and the <code>ma_version_tag</code> of the instance
dictionary is written.</p>
</li>
</ul>
</article>
          </div></div>
  </body>
</html>
