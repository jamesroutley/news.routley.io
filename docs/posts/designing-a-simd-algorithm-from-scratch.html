<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mcyoung.xyz/2023/11/27/simd-base64/">Original</a>
    <h1>Designing a SIMD Algorithm from Scratch</h1>
    
    <div id="readability-page-1" class="page"><div> <p><span> <span> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> <a href="https://mcyoung.xyz/tags.html#optimization">#optimization</a> </span> <span> 2023-11-27 </span> </span></p> <p><span ,=""> <span> <em> 6485 words • 36 minutes </em> </span> </span></p><p>Another explainer on a fun, esoteric topic: optimizing code with SIMD (single instruction multiple data, also sometimes called <em>vectorization</em>). Designing a good, fast, portable SIMD algorithm is not a simple matter and requires thinking a little bit like a circuit designer.</p> <p>Here’s the mandatory performance benchmark graph to catch your eye.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="perf perf perf"/></p> <p>“SIMD” often gets thrown around as a buzzword by performance and HPC (high performance computing) nerds, but I don’t think it’s a topic that has very friendly introductions out there, for a lot of reasons.</p> <ul> <li>It’s not something you will really want to care about unless you think performance is cool.</li> <li>APIs for programming with SIMD in most programming languages are <em>garbage</em> (I’ll get into why).</li> <li>SIMD algorithms are hard to think about if you’re very procedural-programming-brained. A functional programming mindset can help a lot.</li> </ul> <p>This post is mostly about <a href="https://docs.rs/vb64/latest/vb64/"><code>vb64</code></a> (which stands for <em>v</em>ector <em>b</em>ase<em>64</em>), a base64 codec I wrote to see for myself if Rust’s <code>std::simd</code> library is any good, but it’s also an excuse to talk about SIMD in general.</p> <p>What <em>is</em> SIMD, anyways? Let’s dive in.</p> <p>If you want to skip straight to the writeup on <code>vb64</code>, click <a href="#parsing-with-simd">here</a>.</p> <h2 id="problems-with-physics"><a href="#problems-with-physics">Problems with Physics</a></h2> <p>Unfortunately, computers exist in the real world<sup>[citation-needed]</sup>, and are bound by the laws of nature. SIMD has relatively little to do with theoretical CS considerations, and everything to do with <em>physics</em>.</p> <p>In the infancy of modern computing, you could simply improve performance of existing programs by buying new computers. This is often incorrectly attributed to Moore’s law (the number of transistors on IC designs doubles every two years). Moore’s law still appears to hold as of 2023, but some time in the last 15 years the <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> effect broke down. This means that denser transistors eventually means increased power dissipation density. In simpler terms, we don’t know how to continue to increase the clock frequency of computers without literally <em>liquefying</em> them.</p> <p>So, since the early aughts, the hot new thing has been bigger core counts. Make your program more multi-threaded and it will run faster on bigger CPUs. This comes with synchronization overhead, since now the cores need to cooperate. All control flow, be it jumps, virtual calls, or synchronization will result in “stall”.</p> <p>The main causes of stall are <em>branches</em>, instructions that indicate code can take one of two possible paths (like an <code>if</code> statement), and <em>memory operations</em>. Branches include all control flow: <code>if</code> statements, loops, function calls, function returns, even <code>switch</code> statements in C. Memory operations are loads and stores, especially ones that are cache-unfriendly.</p> <h3 id="procedural-code-is-slow"><a href="#procedural-code-is-slow">Procedural Code Is Slow</a></h3> <p>Modern compute cores do not execute code line-by-line, because that would be very inefficient. Suppose I have this program:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>a</span> <span>=</span> <span>x</span> <span>+</span> <span>y</span><span>;</span>
<span>let</span> <span>b</span> <span>=</span> <span>x</span> <span>^</span> <span>y</span><span>;</span>
<span>println!</span><span>(</span><span>&#34;{a}, {b}&#34;</span><span>);</span></code></pre></figure></div> <p>There’s no reason for the CPU to wait to finish computing <code>a</code> before it begins computing <code>b</code>; it does not depend on <code>a</code>, and while the add is being executed, the xor circuits are idle. Computers say “program order be damned” and issue the add for <code>a</code> and the xor for <code>b</code> simultaneously. This is called <em>instruction-level parallelism</em>, and dependencies that get in the way of it are often called <em>data hazards</em>.</p> <p>Of course, the Zen 2 in the machine I’m writing this with does not have one measly adder per core. It has dozens and dozens! The opportunities for parallelism are massive, as long as the compiler in your CPU’s execution pipeline can clear any data hazards in the way.</p> <p>The better the core can do this, the more it can saturate all of the “functional units” for things like arithmetic, and the more numbers it can crunch per unit time, approaching maximum utilization of the hardware. Whenever the compiler can’t do this, the execution pipeline stalls and your code is slower.</p> <p>Branches stall because they need to wait for the branch condition to be computed before fetching the next instruction (speculative execution is a somewhat iffy workaround for this). Memory operations stall because the data needs to physically arrive at the CPU, and the speed of light is finite in this universe.</p> <p>Trying to reduce stall by improving opportunities for single-core parallelism is not a new idea. Consider the not-so-humble GPU, whose purpose in life is to render images. Images are vectors of pixels (i.e., color values), and rendering operations tend to be highly local. For example, a convolution kernel for a Gaussian blur will be two or even three orders of magnitude smaller than the final image, lending itself to locality.</p> <p>Thus, GPUs are built for divide-and-conquer: they provide primitives for doing batched operations, and extremely limited control flow.</p> <p>“SIMD” is synonymous with “batching”. It stands for “single instruction, multiple data”: a single instruction dispatches parallel operations on multiple <em>lanes</em> of data. GPUs are the original SIMD machines.</p> <h2 id="lane-wise"><a href="#lane-wise">Lane-Wise</a></h2> <p>“SIMD” and “vector” are often used interchangeably. The fundamental unit a SIMD instruction (or “vector instruction”) operates on is a vector: a fixed-size array of numbers that you primarily operate on component-wise These components are called <em>lanes</em>.</p> <p>SIMD vectors are usually quite small, since they need to fit into registers. For example, on my machine, the largest vectors are 256 bits wide. This is enough for 32 bytes (a <code>u8x32</code>), 4 double-precision floats (an <code>f64x8</code>), or all kinds of things in between.</p> <p><img src="https://mcyoung.xyz/public/simd-img/vectors.png" alt="some 256-bit vectors"/></p> <p>Although this doesn’t seem like much, remember that offloading the overhead of keeping the pipeline saturated by a factor of 4x can translate to that big of a speedup in latency.</p> <h3 id="one-bit-lanes"><a href="#one-bit-lanes">One-Bit Lanes</a></h3> <p>The simplest vector operations are bitwise: and, or, xor. Ordinary integers can be thought of as vectors themselves, with respect to the bitwise operations. That’s literally what “bitwise” means: lanes-wise with lanes that are one bit wide. An <code>i32</code> is, in this regard, an <code>i1x32</code>.</p> <p>In fact, as a warmup, let’s look at the problem of counting the number of 1 bits in an integer. This operation is called “population count”, or <code>popcnt</code>. If we view an <code>i32</code> as an <code>i1x32</code>, <code>popcnt</code> is just a fold or reduce operation:</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bits</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>32</span><span>];</span>
  <span>for</span> <span>(</span><span>i</span><span>,</span> <span>bit</span><span>)</span> <span>in</span> <span>bits</span><span>.iter_mut</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
    <span>*</span><span>bit</span> <span>=</span> <span>(</span><span>x</span> <span>&gt;&gt;</span> <span>i</span><span>)</span> <span>&amp;</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>bits</span><span>.into_iter</span><span>()</span><span>.fold</span><span>(</span><span>0</span><span>,</span> <span>|</span><span>total</span><span>,</span> <span>bit</span><span>|</span> <span>total</span> <span>+</span> <span>bit</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>In other words, we interpret the integer as an array of bits and then add the bits together to a 32-bit accumulator. Note that the accumulator needs to be higher precision to avoid overflow: accumulating into an <code>i1</code> (as with the <code>Iterator::reduce()</code> method) will only tell us whether the number of 1 bits is even or odd.</p> <p>Of course, this produces… comically bad code, frankly. We can do much better if we notice that we can <em>vectorize</em> the addition: first we add all of the adjacent pairs of bits together, then the pairs of pairs, and so on. This means the number of adds is logarithmic in the number of bits in the integer.</p> <p>Visually, what we do is we “unzip” each vector, shift one to line up the lanes, add them, and then repeat with lanes twice as big.</p> <p><img src="https://mcyoung.xyz/public/simd-img/popcnt.png" alt="first two popcnt merge steps"/></p> <p>This is what that looks like in code.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>// View x as a i1x32, and split it into two vectors</span>
  <span>// that contain the even and odd bits, respectively.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x55555555</span><span>;</span> <span>// 0x5 == 0b0101.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xaaaaaaaa</span><span>;</span> <span>// 0xa == 0b1010.</span>
  <span>// Shift odds down to align the bits, and then add them together.</span>
  <span>// We interpret x now as a i2x16. When adding, each two-bit</span>
  <span>// lane cannot overflow, because the value in each lane is</span>
  <span>// either 0b00 or 0b01.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>1</span><span>);</span>

  <span>// Repeat again but now splitting even and odd bit-pairs.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x33333333</span><span>;</span> <span>// 0x3 == 0b0011.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xcccccccc</span><span>;</span> <span>// 0xc == 0b1100.</span>
  <span>// We need to shift by 2 to align, and now for this addition</span>
  <span>// we interpret x as a i4x8.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>2</span><span>);</span>

  <span>// Again. The pattern should now be obvious.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0f0f0f0f</span><span>;</span> <span>// 0x0f == 0b00001111.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xf0f0f0f0</span><span>;</span> <span>// 0xf0 == 0b11110000.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>4</span><span>);</span> <span>// i8x4</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x00ff00ff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xff00ff00</span><span>;</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>8</span><span>);</span>  <span>// i16x2</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0000ffff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xffff0000</span><span>;</span>
  <span>// Because the value of `x` is at most 32, although we interpret this as a</span>
  <span>// i32x1 add, we could get away with just one e.g. i16 add.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>16</span><span>);</span>

  <span>x</span> <span>// Done. All bits have been added.</span>
<span>}</span></code></pre></figure></div> <p>This still won’t optimize down to a <code>popcnt</code> instruction, of course. The search scope for such a simplification is in the regime of superoptimizers. However, the generated code is small and fast, which is why this is the ideal implementation of <code>popcnt</code> for systems without such an instruction.</p> <p>It’s <em>especially</em> nice because it is implementable for e.g. <code>u64</code> with only one more reduction step (remember: it’s <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log n)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>O</span><span>(</span><span>lo<span>g</span></span><span></span><span>n</span><span>)</span></span></span></span></span>!), and does not at any point require a full <code>u64</code> addition.</p> <p>Even though this is “just” using scalars, divide-and-conquer approaches like this are the bread and butter of the SIMD programmer.</p> <h3 id="scaling-up-operations-on-real-vectors"><a href="#scaling-up-operations-on-real-vectors">Scaling Up: Operations on Real Vectors</a></h3> <p>Proper SIMD vectors provide more sophisticated semantics than scalars do, particularly because there is more need to provide replacements for things like control flow. Remember, control flow is slow!</p> <p>What’s actually available is highly dependent on the architecture you’re compiling to (more on this later), but the way vector instruction sets are usually structured is something like this.</p> <p>We have <em>vector registers</em> that are kind of like really big general-purpose registers. For example, on x86, most “high performance” cores (like my Zen 2) implement AVX2, which provides 256 bit <code>ymm</code> vectors. The registers themselves do not have a “lane count”; that is specified by the instructions. For example, the “vector byte add instruction” interprets the register as being divided into eight-byte lanes and adds them. The corresponding x86 instruction is <code>vpaddb</code>, which interprets a <code>ymm</code> as an <code>i8x32</code>.</p> <p>The operations you usually get are:</p> <ol> <li> <p>Bitwise operations. These don’t need to specify a lane width because it’s always implicitly <code>1</code>: they’re <em>bit</em>wise.</p> </li> <li> <p>Lane-wise arithmetic. This is addition, subtraction, multiplication, division (both int and float), and shifts<sup id="fnref:shifts-are-arithmetic" role="doc-noteref"><a href="#fn:shifts-are-arithmetic" rel="footnote">1</a></sup> (int only). Lane-wise min and max are also common. These require specifying a lane width. Typically the smallest number of lanes is two or four.</p> </li> <li> <p>Lane-wise compare. Given <code>a</code> and <code>b</code>, we can create a new <em>mask vector</em> <code>m</code> such that <code>m[i] = a[i] &lt; b[i]</code> (or any other comparison operation). A mask vector’s lanes contain boolean values with an unusual bit-pattern: all-zeros (for false) or all-ones (for true)<sup id="fnref:minus-true" role="doc-noteref"><a href="#fn:minus-true" rel="footnote">2</a></sup>.</p> <ul> <li>Masks can be used to select between two vectors: for example, given <code>m</code>, <code>x</code>, and <code>y</code>, you can form a fourth vector <code>z</code> such that <code>z[i] = m[i] ? a[i] : b[i]</code>.</li> </ul> </li> <li> <p>Shuffles (sometimes called swizzles). Given <code>a</code> and <code>x</code>, create a third vector <code>s</code> such that <code>s[i] = a[x[i]]</code>. <code>a</code> is used as a lookup table, and <code>x</code> as a set of indices. Out of bounds produces a special value, usually zero. This emulates parallelized array access without needing to actually touch RAM (RAM is extremely slow).</p> <ul> <li>Often there is a “shuffle2” or “riffle” operation that allows taking elements from one of two vectors. Given <code>a</code>, <code>b</code>, and <code>x</code>, we now define <code>s</code> as being <code>s[i] = (a ++ b)[x[i]]</code>, where <code>a ++ b</code> is a double-width concatenation. How this is actually implemented depends on architecture, and it’s easy to build out of single shuffles regardless.</li> </ul> </li> </ol> <p>(1) and (2) are ordinary number crunching. Nothing deeply special about them.</p> <p>The comparison and select operations in (3) are intended to help SIMD code stay “branchless”. Branchless code is written such that it performs the same operations regardless of its inputs, and relies on the properties of those operations to produce correct results. For example, this might mean taking advantage of identities like <code>x * 0 = 0</code> and <code>a ^ b ^ a = b</code> to discard “garbage” results.</p> <p>The shuffles described in (4) are much more powerful than meets the eye.</p> <p>For example, “broadcast” (sometimes called “splat”) makes a vector whose lanes are all the same scalar, like Rust’s <code>[42; N]</code> array literal. A broadcast can be expressed as a shuffle: create a vector with the desired value in the first lane, and then shuffle it with an index vector of <code>[0, 0, ...]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/broadcast.png" alt="diagram of a broadcast"/></p> <p>“Interleave” (also called “zip” or “pack”) takes two vectors <code>a</code> and <code>b</code> and creates two new vectors <code>c</code> and <code>d</code> whose lanes are alternating lanes from <code>a</code> and <code>b</code>. If the lane count is <code>n</code>, then <code>c = [a[0], b[0], a[1], b[1], ...]</code> and <code>d = [a[n/2], b[n/2], a[n/2 + 1], b[n/2 + 1], ...]</code>. This can also be implemented as a shuffle2, with shuffle indices of <code>[0, n, 1, n + 1, ...]</code>. “Deinterleave” (or “unzip”, or “unpack”) is the opposite operation: it interprets a pair of vectors as two halves of a larger vector of pairs, and produces two new vectors consisting of the halves of each pair.</p> <p>Interleave can also be interpreted as taking a <code>[T; N]</code>, transmuting it to a <code>[[T; N/2]; 2]</code>, performing a matrix transpose to turn it into a <code>[[T; 2]; N/2]</code>, and then transmuting that back to <code>[T; N]</code> again. Deinterleave is the same but it transmutes to <code>[[T; 2]; N/2]</code> first.</p> <p><img src="https://mcyoung.xyz/public/simd-img/interleave.png" alt="diagram of a interleave"/></p> <p>“Rotate” takes a vector <code>a</code> with <code>n</code> lanes and produces a new vector <code>b</code> such that <code>b[i] = a[(i + j) % n]</code>, for some chosen integer <code>j</code>. This is yet another shuffle, with indices <code>[j, j + 1, ..., n - 1, 0, 1, ... j - 1]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/rotate.png" alt="diagram of a rotate"/></p> <p>Shuffles are worth trying to wrap your mind around. SIMD programming is all about reinterpreting larger-than-an-integer-sized blocks of data as smaller blocks of varying sizes, and shuffling is important for getting data into the right “place”.</p> <h3 id="intrinsics-and-instruction-selection"><a href="#intrinsics-and-instruction-selection">Intrinsics and Instruction Selection</a></h3> <p>Earlier, I mentioned that what you get varies by architecture. This section is basically a giant footnote.</p> <p>So, there’s two big factors that go into this.</p> <ol> <li>We’ve learned over time which operations tend to be most useful to programmers. x86 might have something that ARM doesn’t because it “seemed like a good idea at the time” but turned out to be kinda niche.</li> <li>Instruction set extensions are often market differentiators, even within the same vendor. Intel has AVX-512, which provides even more sophisticated instructions, but it’s only available on high-end server chips, because it makes manufacturing more expensive.</li> </ol> <p>Toolchains generalize different extensions as “target features”. Features can be detected at runtime through architecture-specific magic. On Linux, the <code>lscpu</code> command will list what features the CPU advertises that it recognizes, which correlate with the names of features that e.g. LLVM understands. What features are enabled for a particular function affects how LLVM compiles it. For example, LLVM will only emit <code>ymm</code>-using code when compiling with <code>+avx2</code>.</p> <p>So how do you write portable SIMD code? On the surface, the answer is mostly “you don’t”, but it’s more complicated than that, and for that we need to understand how the later parts of a compiler works.</p> <p>When a user requests an add by writing <code>a + b</code>, how should I decide which instruction to use for it? This seems like a trick question… <em>just</em> an <code>add</code> right? On x86, even this isn’t so easy, since you have a choice between the actual <code>add</code> instruction, or a <code>lea</code> instruction (which, among other things, preserves the <code>rflags</code> register). This question becomes more complicated for more sophisticated operations. This general problem is called <em>instruction selection</em>.</p> <p>Because which “target features” are enabled affects which instructions are available, they affect instruction selection. When I went over operations “typically available”, this means that compilers will usually be able to select good choices of instructions for them on most architectures.</p> <p>Compiling with something like <code>-march=native</code> or <code>-Ctarget-cpu=native</code> gets you “the best” code possible for the machine you’re building on, but it might not be portable<sup id="fnref:abi" role="doc-noteref"><a href="#fn:abi" rel="footnote">3</a></sup> to different processors. Gentoo was quite famous for building packages from source on user machines to take advantage of this (not to mention that they loved using <code>-O3</code>, which mostly exists to slow down build times with little benefit).</p> <p>There is also runtime feature detection, where a program decides which version of a function to call at runtime by asking the CPU what it supports. Code deployed on heterogenous devices (like cryptography libraries) often make use of this. Doing this correctly is very hard and something I don’t particularly want to dig deeply into here.</p> <p>The situation is made worse by the fact that in C++, you usually write SIMD code using “intrinsics”, which are special functions with inscrutable names like <code>_mm256_cvtps_epu32</code> that represent a low-level operation in a specific instruction set (this is a float to int cast from AVX2). Intrinsics are defined by hardware vendors, but don’t necessarily map down to single instructions; the compiler can still optimize these instructions by merging, deduplication, and through instruction selection.</p> <p>As a result you wind up writing the same code multiple times for different instruction sets, with only minor maintainability benefits over writing assembly.</p> <p>The alternative is a portable SIMD library, which does some instruction selection behind the scenes at the library level but tries to rely on the compiler for most of the heavy-duty work. For a long time I was skeptical that this approach would actually produce good, competitive code, which brings us to the actual point of this article: using Rust’s portable SIMD library to implement a somewhat fussy algorithm, and measuring performance.</p> <h2 id="parsing-with-simd"><a href="#parsing-with-simd">Parsing with SIMD</a></h2> <p>Let’s design a SIMD implementation for a well-known algorithm. Although it doesn’t look like it at first, the power of shuffles makes it possible to parse text with SIMD. And this parsing can be very, very fast.</p> <p>In this case, we’re going to implement base64 decoding. To review, base64 is an encoding scheme for arbitrary binary data into ASCII. We interpret a byte slice as a bit vector, and divide it into six-bit chunks called <em>sextets</em>. Then, each sextet from 0 to 63 is mapped to an ASCII character:</p> <ol> <li><code>0</code> to <code>25</code> go to <code>&#39;A&#39;</code> to <code>&#39;Z&#39;</code>.</li> <li><code>26</code> to <code>51</code> go to <code>&#39;a&#39;</code> to <code>&#39;z&#39;</code>.</li> <li><code>52</code> to <code>61</code> go to <code>&#39;0&#39;</code> to <code>&#39;9&#39;</code>.</li> <li><code>62</code> goes to <code>+</code>.</li> <li><code>63</code> goes to <code>/</code>.</li> </ol> <p>There <em>are</em> other variants of base64, but the bulk of the complexity is the same for each variant.</p> <p>There are a few basic pitfalls to keep in mind.</p> <ol> <li> <p>Base64 is a “big endian” format: specifically, the bits in each byte are big endian. Because a sextet can span only parts of a byte, this distinction is important.</p> </li> <li> <p>We need to beware of cases where the input length is not divisible by 4; ostensibly messages should be padded with <code>=</code> to a multiple of 4, but it’s easy to just handle messages that aren’t padded correctly.</p> </li> </ol> <p>The length of a decoded message is given by this function:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>match</span> <span>input</span> <span>%</span> <span>4</span> <span>{</span>
    <span>1</span> <span>|</span> <span>2</span> <span>=&gt;</span> <span>1</span><span>,</span>
    <span>3</span> <span>=&gt;</span> <span>2</span><span>,</span>
    <span>_</span> <span>=&gt;</span> <span>0</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>Given all this, the easiest way to implement base64 is something like this.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span> <span>{</span>
  <span>// Tear off at most two trailing =.</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>// Split the input into chunks of at most 4 bytes.</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
    <span>for</span> <span>&amp;</span><span>byte</span> <span>in</span> <span>chunk</span> <span>{</span>
      <span>// Translate each ASCII character into its corresponding</span>
      <span>// sextet, or return an error.</span>
      <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
        <span>b&#39;A&#39;</span><span>..=</span><span>b&#39;Z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;A&#39;</span><span>,</span>
        <span>b&#39;a&#39;</span><span>..=</span><span>b&#39;z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;a&#39;</span> <span>+</span> <span>26</span><span>,</span>
        <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;0&#39;</span> <span>+</span> <span>52</span><span>,</span>
        <span>b&#39;+&#39;</span> <span>=&gt;</span> <span>62</span><span>,</span>
        <span>b&#39;/&#39;</span> <span>=&gt;</span> <span>63</span><span>,</span>
        <span>_</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>(</span><span>...</span><span>)),</span>
      <span>};</span>

      <span>// Append the sextet to the temporary buffer.</span>
      <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
      <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>}</span>

    <span>// Shift things so the actual data winds up at the</span>
    <span>// top of `bytes`.</span>
    <span>bytes</span> <span>&lt;&lt;=</span> <span>32</span> <span>-</span> <span>6</span> <span>*</span> <span>chunk</span><span>.len</span><span>();</span>

    <span>// Append the decoded data to `out`, keeping in mind that</span>
    <span>// `bytes` is big-endian encoded.</span>
    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>.to_be_bytes</span><span>()[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>So, what’s the process of turning this into a SIMD version? We want to follow one directive with inexorable, robotic dedication.</p> <p><strong>Eliminate all branches.</strong></p> <p>This is not completely feasible, since the input is of variable length. But we can try. There are several branches in this code:</p> <ol> <li>The <code>for chunk in</code> line. This one is is the length check: it checks if there is any data left to process.</li> <li>The <code>for &amp;byte in</code> line. This is the hottest loop: it branches once per input byte.</li> <li>The <code>match byte</code> line is several branches, to determine which of the five “valid” match arms we land in.</li> <li>The <code>return Err</code> line. Returning in a hot loop is extra control flow, which is not ideal.</li> <li>The call to <code>decoded_len</code> contains a <code>match</code>, which generates branches.</li> <li>The call to <code>Vec::extend_from_slice</code>. This contains not just branches, but potential calls into the allocator. Extremely slow.</li> </ol> <p>(5) is the easiest to deal with. The <code>match</code> is mapping the values <code>0, 1, 2, 3</code> to <code>0, 1, 1, 2</code>. Call this function <code>f</code>. Then, the sequence given by <code>x - f(x)</code> is <code>0, 0, 1, 1</code>. This just happens to equal <code>x / 2</code> (or <code>x &gt;&gt; 1</code>), so we can write a completely branchless version of <code>decoded_len</code> like so.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>let</span> <span>mod4</span> <span>=</span> <span>input</span> <span>%</span> <span>4</span><span>;</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>(</span><span>mod4</span> <span>-</span> <span>mod4</span> <span>/</span> <span>2</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>That’s one branch eliminated<sup id="fnref:why-cant-llvm-do-it" role="doc-noteref"><a href="#fn:why-cant-llvm-do-it" rel="footnote">4</a></sup>. ✅</p> <p>The others will not prove so easy. Let’s turn our attention to the innermost loop next, branches (2), (3), and (4).</p> <h3 id="the-hottest-loop"><a href="#the-hottest-loop">The Hottest Loop</a></h3> <p>The superpower of SIMD is that because you operate on so much data at a time, you can unroll the loop so hard it becomes branchless.</p> <p>The insight is this: we want to load at most four bytes, do something to them, and then spit out at most three decoded bytes. While doing this operation, we may encounter a syntax error so we need to report that somehow.</p> <p>Here’s some facts we can take advantage of.</p> <ol> <li>We don’t need to figure out how many bytes are in the “output” of the hot loop: our handy branchless <code>decoded_len()</code> does that for us.</li> <li>Invalid base64 is extremely rare. We want that syntax error to cost as little as possible. If the user still cares about which byte was the problem, they can scan the input for it after the fact.</li> <li><code>A</code> is zero in base64. If we’re parsing a truncated chunk, padding it with <code>A</code> won’t change the value<sup id="fnref:pad-with-A" role="doc-noteref"><a href="#fn:pad-with-A" rel="footnote">5</a></sup>.</li> </ol> <p>This suggests an interface for the body of the “hottest loop”. We can factor it out as a separate function, and simplify since we can assume our input is always four bytes now.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>-&gt;</span> <span>([</span><span>u8</span><span>;</span> <span>3</span><span>],</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>let</span> <span>mut</span> <span>ok</span> <span>=</span> <span>true</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>ascii</span> <span>{</span>
    <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
      <span>b&#39;A&#39;</span><span>..=</span><span>b&#39;Z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;A&#39;</span><span>,</span>
      <span>b&#39;a&#39;</span><span>..=</span><span>b&#39;z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;a&#39;</span> <span>+</span> <span>26</span><span>,</span>
      <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;0&#39;</span> <span>+</span> <span>52</span><span>,</span>
      <span>b&#39;+&#39;</span> <span>=&gt;</span> <span>62</span><span>,</span>
      <span>b&#39;/&#39;</span> <span>=&gt;</span> <span>63</span><span>,</span>
      <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
    <span>};</span>

    <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>ok</span> <span>&amp;=</span> <span>byte</span> <span>==</span> <span>!</span><span>0</span><span>;</span>
  <span>}</span>

  <span>// This is the `to_be_bytes()` call.</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>_</span><span>]</span> <span>=</span> <span>bytes</span><span>.to_le_bytes</span><span>();</span>
  <span>([</span><span>b3</span><span>,</span> <span>b2</span><span>,</span> <span>b1</span><span>],</span> <span>ok</span><span>)</span>
<span>}</span>

<span>// In decode()...</span>
<span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>4</span><span>];</span>
  <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

  <span>let</span> <span>(</span><span>bytes</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>);</span>
  <span>if</span> <span>!</span><span>ok</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>)</span>
  <span>}</span>

  <span>let</span> <span>len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
  <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
<span>}</span></code></pre></figure></div> <p>You’re probably thinking: why not return <code>Option&lt;[u8; 3]&gt;</code>? Returning an enum will make it messier to eliminate the <code>if !ok</code> branch later on (which we will!). We want to write branchless code, so let’s focus on finding a way of producing that three-byte output without needing to do early returns.</p> <p>Now’s when we want to start talking about vectors rather than arrays, so let’s try to rewrite our function as such.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>unimplemented!</span><span>()</span>
<span>}</span></code></pre></figure></div> <p>Note that the output is now four bytes, not three. SIMD lane counts need to be powers of two, and that last element will never get looked at, so we don’t need to worry about what winds up there.</p> <p>The callsite also needs to be tweaked, but only slightly, because <code>Simd&lt;u8, 4&gt;</code> is <code>From&lt;[u8; 4]&gt;</code>.</p> <h3 id="ascii-to-sextet"><a href="#ascii-to-sextet">ASCII to Sextet</a></h3> <p>Let’s look at the first part of the <code>for byte in ascii</code> loop. We need to map each lane of the <code>Simd&lt;u8, 4&gt;</code> to the corresponding sextet, and somehow signal which ones are invalid. First, notice something special about the <code>match</code>: almost every arm can be written as <code>byte - C</code> for some constant <code>C</code>. The non-range case looks a little silly, but humor me:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
  <span>b&#39;A&#39;</span><span>..=</span><span>b&#39;Z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;A&#39;</span><span>,</span>
  <span>b&#39;a&#39;</span><span>..=</span><span>b&#39;z&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;a&#39;</span> <span>+</span> <span>26</span><span>,</span>
  <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;0&#39;</span> <span>+</span> <span>52</span><span>,</span>
  <span>b&#39;+&#39;</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;+&#39;</span> <span>+</span> <span>62</span><span>,</span>
  <span>b&#39;/&#39;</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b&#39;/&#39;</span> <span>+</span> <span>63</span><span>,</span>
  <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
<span>};</span></code></pre></figure></div> <p>So, it should be sufficient to build a vector <code>offsets</code> that contains the appropriate constant <code>C</code> for each lane, and then <code>let sextets = ascii - offsets;</code></p> <p>How can we build <code>offsets</code>? Using compare-and-select.</p> <div><figure><pre><code data-lang="rust"><span>// A lane-wise version of `x &gt;= start &amp;&amp; x &lt;= end`.</span>
<span>fn</span> <span>in_range</span><span>(</span><span>bytes</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>start</span><span>:</span> <span>u8</span><span>,</span> <span>end</span><span>:</span> <span>u8</span><span>)</span> <span>-&gt;</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>bytes</span><span>.simd_ge</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>start</span><span>))</span> <span>&amp;</span> <span>bytes</span><span>.simd_le</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>end</span><span>))</span>
<span>}</span>

<span>// Create masks for each of the five ranges.</span>
<span>// Note that these are disjoint: for any two masks, m1 &amp; m2 == 0.</span>
<span>let</span> <span>uppers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b&#39;A&#39;</span><span>,</span> <span>b&#39;Z&#39;</span><span>);</span>
<span>let</span> <span>lowers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b&#39;a&#39;</span><span>,</span> <span>b&#39;z&#39;</span><span>);</span>
<span>let</span> <span>digits</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b&#39;0&#39;</span><span>,</span> <span>b&#39;9&#39;</span><span>);</span>
<span>let</span> <span>pluses</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b&#39;+&#39;</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>
<span>let</span> <span>solidi</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b&#39;/&#39;</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>

<span>// If any byte was invalid, none of the masks will select for it,</span>
<span>// so that lane will be 0 in the or of all the masks. This is our</span>
<span>// validation check.</span>
<span>let</span> <span>ok</span> <span>=</span> <span>(</span><span>uppers</span> <span>|</span> <span>lowers</span> <span>|</span> <span>digits</span> <span>|</span> <span>pluses</span> <span>|</span> <span>solidi</span><span>)</span><span>.all</span><span>();</span>

<span>// Given a mask, create a new vector by splatting `value`</span>
<span>// over the set lanes.</span>
<span>fn</span> <span>masked_splat</span><span>(</span><span>mask</span><span>:</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>value</span><span>:</span> <span>i8</span><span>)</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>mask</span><span>.select</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>val</span><span>),</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>0</span><span>))</span>
<span>}</span>

<span>// Fill the the lanes of the offset vector by filling the</span>
<span>// set lanes with the corresponding offset. This is like</span>
<span>// a &#34;vectorized&#34; version of the `match`.</span>
<span>let</span> <span>offsets</span> <span>=</span> <span>masked_splat</span><span>(</span><span>uppers</span><span>,</span>  <span>65</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>lowers</span><span>,</span>  <span>71</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>digits</span><span>,</span>  <span>-</span><span>4</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>pluses</span><span>,</span> <span>-</span><span>19</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>solidi</span><span>,</span> <span>-</span><span>16</span><span>);</span>

<span>// Finally, Build the sextets vector.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span><span>.cast</span><span>::</span><span>&lt;</span><span>i8</span><span>&gt;</span><span>()</span> <span>-</span> <span>offsets</span><span>;</span></code></pre></figure></div> <p>This solution is quite elegant, and will produce very competitive code, but it’s not actually ideal. We need to do a lot of comparisons here: eight in total. We also keep lots of values alive at the same time, which might lead to unwanted register pressure.</p> <h3 id="simd-hash-table"><a href="#simd-hash-table">SIMD Hash Table</a></h3> <p>Let’s look at the byte representations of the ranges. <code>A-Z</code>, <code>a-z</code>, and <code>0-9</code> are, as byte ranges, <code>0x41..0x5b</code>, <code>0x61..0x7b</code>, and <code>0x30..0x3a</code>. Notice they all have different high nybbles! What’s more, <code>+</code> and <code>/</code> are <code>0x2b</code> and <code>0x2f</code>, so the function <code>byte &gt;&gt; 4</code> is <em>almost</em> enough to distinguish all the ranges. If we subtract one if <code>byte == b&#39;/&#39;</code>, we have a <em>perfect hash</em> for the ranges.</p> <p>In other words, the value <code>(byte &gt;&gt; 4) - (byte == &#39;/&#39;)</code> maps the ranges as follows:</p> <ul> <li><code>A-Z</code> goes to 4 or 5.</li> <li><code>a-z</code> goes to 6 or 7.</li> <li><code>0-9</code> goes to 3.</li> <li><code>+</code> goes to 2.</li> <li><code>/</code> goes to 1.</li> </ul> <p>This is small enough that we could cram a lookup table of values for building the <code>offsets</code> vector into another SIMD vector, and use a shuffle operation to do the lookup.</p> <p>This is not my original idea; I came across a <a href="https://github.com/WojciechMula/base64simd/issues/3">GitHub issue</a> where an anonymous user points out this perfect hash.</p> <p>Our new ascii-to-sextet code looks like this:</p> <div><figure><pre><code data-lang="rust"><span>// Compute the perfect hash for each lane.</span>
<span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
  <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b&#39;/&#39;</span><span>))</span>
    <span>.to_int</span><span>()</span>  <span>// to_int() is equivalent to masked_splat(-1, 0).</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Look up offsets based on each hash and subtract them from `ascii`.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>// This lookup table corresponds to the offsets we used to build the</span>
    <span>// `offsets` vector in the previous implementation, placed in the</span>
    <span>// indices that the perfect hash produces.</span>
  <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
    <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span></code></pre></figure></div> <p>There is a small wrinkle here: <a href="https://doc.rust-lang.org/std/simd/struct.Simd.html#method.swizzle_dyn"><code>Simd::swizzle_dyn()</code></a> requires that the index array be the same length as the lookup table. This is annoying because right now <code>ascii</code> is a <code>Simd&lt;u8, 4&gt;</code>, but that will not be the case later on, so I will simply sweep this under the rug.</p> <p>Note that we no longer get validation as a side-effect of computing the sextets vector. The same GitHub issue also provides an exact bloom-filter for checking that a particular byte is valid; you can see my implementation <a href="https://github.com/mcy/vb64/blob/894f833e933860e070dabcfcc189430c45fecbd7/src/simd.rs#L93">here</a>. I’m not sure how the OP constructed the bloom filter, but the search space is small enough that you could have written a little script to brute force it.</p> <h3 id="riffling-the-sextets"><a href="#riffling-the-sextets">Riffling the Sextets</a></h3> <p>Now comes a much tricker operation: we need to somehow pack all four sextets into three bytes. One way to try to wrap our head around what the packing code in <code>decode_hot()</code> is doing is to pass in the all-ones sextet in one of the four bytes, and see where those ones end up in the return value.</p> <p>This is not unlike how they use radioactive dyes in biology to track the moment of molecules or cells through an organism.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>bits</span><span>(</span><span>value</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>b4</span><span>]</span> <span>=</span> <span>value</span><span>.reverse_bits</span><span>()</span><span>.to_le_bytes</span><span>();</span>
  <span>format!</span><span>(</span><span>&#34;{b1:08b} {b2:08b} {b3:08b} {b4:08b}&#34;</span><span>)</span>
<span>}</span>

<span>fn</span> <span>decode_pack</span><span>(</span><span>input</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>output</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>input</span> <span>{</span>
    <span>output</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>output</span> <span>|</span><span>=</span> <span>byte</span> <span>as</span> <span>u32</span><span>;</span>
  <span>}</span>
  <span>output</span> <span>&lt;&lt;=</span> <span>8</span><span>;</span>

  <span>println!</span><span>(</span><span>&#34;{}</span><span>\n</span><span>{}</span><span>\n</span><span>&#34;</span><span>,</span> <span>bits</span><span>(</span><span>u32</span><span>::</span><span>from_be_bytes</span><span>(</span><span>input</span><span>)),</span> <span>bits</span><span>(</span><span>output</span><span>));</span>
<span>}</span>

<span>decode_pack</span><span>([</span><span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>]);</span>

<span>// Output:</span>
<span>// 11111100 00000000 00000000 00000000</span>
<span>// 00111111 00000000 00000000 00000000</span>
<span>//</span>
<span>// 00000000 11111100 00000000 00000000</span>
<span>// 11000000 00001111 00000000 00000000</span>
<span>//</span>
<span>// 00000000 00000000 11111100 00000000</span>
<span>// 00000000 11110000 00000011 00000000</span>
<span>//</span>
<span>// 00000000 00000000 00000000 11111100</span>
<span>// 00000000 00000000 11111100 00000000</span></code></pre></figure></div> <p>Bingo. Playing around with the inputs lets us verify which pieces of the bytes wind up where. For example, by passing <code>0b110000</code> as <code>input[1]</code>, we see that the two high bits of <code>input[1]</code> correspond to the low bits of <code>output[0]</code>. I’ve written the code so that the bits in each byte are printed in little-endian order, so bits on the left are the low bits.</p> <p>Putting this all together, we can draw a schematic of what this operation does to a general <code>Simd&lt;u8, 4&gt;</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/riffle.png" alt="the riffling operation"/></p> <p>Now, there’s no single instruction that will do this for us. Shuffles can be used to move bytes around, but we’re dealing with <em>pieces</em> of bytes here. We also can’t really do a shift, since we need bits that are overshifted to move into adjacent lanes.</p> <p>The trick is to just make the lanes bigger.</p> <p>Among the operations available for SIMD vectors are lane-wise casts, which allow us to zero-extend, sign-extend, or truncate each lane. So what we can do is cast <code>sextets</code> to a vector of <code>u16</code>, do the shift there and then… somehow put the parts back together?</p> <p>Let’s see how far shifting gets us. How much do we need to shift things by? First, notice that the order of the bits within each chunk that doesn’t cross a byte boundary doesn’t change. For example, the four low bits of <code>input[1]</code> are in the same order when they become the high bits of <code>output[1]</code>, and the two high bits of <code>input[1]</code> are also in the same order when they become the low bits of <code>output[0]</code>.</p> <p>This means we can determine how far to shift by comparing the bit position of the lowest bit of a byte of <code>input</code> with the bit position of the corresponding bit in <code>output</code>.</p> <p><code>input[0]</code>’s low bit is the third bit of <code>output[0]</code>, so we need to shift <code>input[0]</code> by 2. <code>input[1]</code>’s lowest bit is the fifth bit of <code>output[1]</code>, so we need to shift by 4. Analogously, the shifts for <code>input[2]</code> and <code>input[3]</code> turn out to be 6 and 0. In code:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextets</span> <span>=</span> <span>...</span><span>;</span>
<span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>0</span><span>]);</span></code></pre></figure></div> <p>So now we have a <code>Simd&lt;u16, 4&gt;</code> that contains the individual chunks that we need to move around, in the high and low bytes of each <code>u16</code>, which we can think of as being analogous to a <code>[[u8; 2]; 4]</code>. For example, <code>shifted[0][0]</code> contains <code>sextet[0]</code>, but shifted. This corresponds to the red segment in the first schematic. The smaller blue segment is given by <code>shifted[1][1]</code>, i.e., the high byte of the second <code>u16</code>. It’s already in the right place within that byte, so we want <code>output[0] = shifted[0][0] | shifted[1][1]</code>.</p> <p>This suggests a more general strategy: we want to take two vectors, the low bytes and the high bytes of each <code>u16</code> in <code>shifted</code>, respectively, and somehow shuffle them so that when or’ed together, they give the desired output.</p> <p>Look at the schematic again: if we had a vector consisting of <code>[..aaaaaa, ....bbbb, ......cc]</code>, we could or it with a vector like <code>[bb......, cccc...., dddddd..]</code> to get the desired result.</p> <p>One problem: <code>dddddd..</code> is <code>shifted[3][0]</code>, i.e., it’s a low byte. If we change the vector we shift by to <code>[2, 4, 6, 8]</code>, though, it winds up in <code>shifted[3][1]</code>, since it’s been shifted up by <code>8</code> bits: a full byte.</p> <div><figure><pre><code data-lang="rust"><span>// Split shifted into low byte and high byte vectors.</span>
<span>// Same way you&#39;d split a single u16 into bytes, but lane-wise.</span>
<span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
<span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>8</span><span>;</span> <span>4</span><span>]))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Align the lanes: we want to get shifted[0][0] | shifted[1][1],</span>
<span>// shifted[1][0] | shifted[2][1], etc.</span>
<span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span></code></pre></figure></div> <p>Et voila, here is our new, totally branchless implementation of <code>decode_hot()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b&#39;/&#39;</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Note quite right yet, see next section.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>The compactness of this solution should not be understated. The simplicity of this solution is a large part of what makes it so efficient, because it aggressively leverages the primitives the hardware offers us.</p> <h3 id="scaling-up"><a href="#scaling-up">Scaling Up</a></h3> <p>Ok, so now we have to contend with a new aspect of our implementation that’s crap: a <code>Simd&lt;u8, 4&gt;</code> is tiny. That’s not even 128 bits, which are the smallest vector registers on x86. What we need to do is make <code>decode_hot()</code> generic on the lane count. This will allow us to tune the number of lanes to batch together depending on benchmarks later on.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b&#39;/&#39;</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Works fine now, as long as N &gt;= 8.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span>

<span>/// Generates a new vector made up of repeated &#34;tiles&#34; of identical</span>
<span>/// data.</span>
<span>const</span> <span>fn</span> <span>tiled</span><span>&lt;</span><span>T</span><span>,</span> <span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>tile</span><span>:</span> <span>&amp;</span><span>[</span><span>T</span><span>])</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>T</span><span>,</span> <span>N</span><span>&gt;</span>
<span>where</span>
  <span>T</span><span>:</span> <span>SimdElement</span><span>,</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>mut</span> <span>out</span> <span>=</span> <span>[</span><span>tile</span><span>[</span><span>0</span><span>];</span> <span>N</span><span>];</span>
  <span>let</span> <span>mut</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>N</span> <span>{</span>
    <span>out</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>tile</span><span>[</span><span>i</span> <span>%</span> <span>tile</span><span>.len</span><span>()];</span>
    <span>i</span> <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>Simd</span><span>::</span><span>from_array</span><span>(</span><span>out</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>We have to change virtually nothing, which is pretty awesome! But unfortunately, this code is subtly incorrect. Remember how in the <code>N = 4</code> case, the result of <code>output</code> had a garbage value that we ignore in its highest lane? Well, now that garbage data is interleaved into output: every fourth lane contains garbage.</p> <p>We can use a shuffle to delete these lanes, thankfully. Specifically, we want <code>shuffled[i] = output[i + i / 3]</code>, which skips every forth index. So, <code>shuffled[3] = output[4]</code>, skipping over the garbage value in <code>output[3]</code>. If <code>i + i / 3</code> overflows <code>N</code>, that’s ok, because that’s the high quarter of the final output vector, which is ignored anyways. In code:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>

  <span>let</span> <span>decoded_chunks</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>swizzle!</span><span>(</span><span>N</span><span>;</span> <span>decoded_chunks</span><span>,</span> <span>array!</span><span>(</span><span>N</span><span>;</span> <span>|</span><span>i</span><span>|</span> <span>i</span> <span>+</span> <span>i</span> <span>/</span> <span>3</span><span>));</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <blockquote> <p><code>swizzle!()</code> is a helper macro<sup id="fnref:macros" role="doc-noteref"><a href="#fn:macros" rel="footnote">6</a></sup> for generating generic implementations of <code>std::simd::Swizzle</code>, and <code>array!()</code> is something I wrote for generating generic-length array constants; the closure is called once for each <code>i in 0..N</code>.</p> </blockquote> <p>So now we can decode 32 base64 bytes in parallel by calling <code>decode_hot::&lt;32&gt;()</code>. We’ll try to keep things generic from here, so we can tune the lane parameter based on benchmarks.</p> <h3 id="the-outer-loop"><a href="#the-outer-loop">The Outer Loop</a></h3> <p>Let’s look at <code>decode()</code> again. Let’s start by making it generic on the internal lane count, too.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>if</span> <span>(</span><span>!</span><span>ok</span><span>)</span> <span>{</span>
      <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
    <span>}</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>dec</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>What branches are left? There’s still the branch from <code>for chunks in ...</code>. It’s not ideal because it can’t do an exact pointer comparison, and needs to do a <code>&gt;=</code> comparison on a length instead.</p> <p>We call <code>[T]::copy_from_slice</code>, which is super slow because it needs to make a variable-length <code>memcpy</code> call, which can’t be inlined. Function calls are branches! The bounds checks are also a problem.</p> <p>We branch on <code>ok</code> every loop iteration, still. Not returning early in <code>decode_hot</code> doesn’t win us anything (yet).</p> <p>We potentially call the allocator in <code>extend_from_slice</code>, and perform another non-inline-able <code>memcpy</code> call.</p> <h3 id="preallocating-with-slop"><a href="#preallocating-with-slop">Preallocating with Slop</a></h3> <p>The last of these is the easiest to address: we can reserve space in <code>out</code>, since we know exactly how much data we need to write thanks to <code>decoded_len</code>. Better yet, we can reserve some “slop”: i.e., scratch space past where the end of the message would be, so we can perform full SIMD stores, instead of the variable-length memcpy.</p> <p>This way, in each iteration, we write the full SIMD vector, including any garbage bytes in the upper quarter. Then, the next write is offset <code>3/4 * N</code> bytes over, so it overwrites the garbage bytes with decoded message bytes. The garbage bytes from the final right get “deleted” by not being included in the final <code>Vec::set_len()</code> that “commits” the memory we wrote to.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b&#39;=&#39;</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>let</span> <span>final_len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>data</span><span>);</span>
  <span>out</span><span>.reserve</span><span>(</span><span>final_len</span> <span>+</span> <span>N</span> <span>/</span> <span>4</span><span>);</span>  <span>// Reserve with slop.</span>

  <span>// Get a raw pointer to where we should start writing.</span>
  <span>let</span> <span>mut</span> <span>ptr</span> <span>=</span> <span>out</span><span>.as_mut_ptr_range</span><span>()</span><span>.end</span><span>();</span>
  <span>let</span> <span>start</span> <span>=</span> <span>ptr</span><span>;</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>/* snip */</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>unsafe</span> <span>{</span>
      <span>// Do a raw write and advance the pointer.</span>
      <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>dec</span><span>);</span>
      <span>ptr</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>decoded</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>// Update the vector&#39;s final length.</span>
    <span>// This is the final &#34;commit&#34;.</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>This is safe, because we’ve pre-allocated exactly the amount of memory we need, and where <code>ptr</code> lands is equal to the amount of memory actually decoded. We could also compute the final length of <code>out</code> ahead of time.</p> <p>Note that if we early return due to <code>if !ok</code>, <code>out</code> remains unmodified, because even though we did write to its buffer, we never execute the “commit” part, so the code remains correct.</p> <h3 id="delaying-failure"><a href="#delaying-failure">Delaying Failure</a></h3> <p>Next up, we can eliminate the <code>if !ok</code> branches by waiting to return an error until as late as possible: just before the <code>set_len</code> call.</p> <p>Remember our observation from before: most base64 encoded blobs are valid, so this unhappy path should be very rare. Also, syntax errors cannot cause code that follows to misbehave arbitrarily, so letting it go wild doesn’t hurt anything.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>

    <span>/* snip */</span>
  <span>}</span>

  <span>if</span> <span>error</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>The branch is still “there”, sure, but it’s out of the hot loop.</p> <p>Because we never hit the <code>set_len</code> call and commit whatever garbage we wrote, said garbage essentially disappears when we return early, to be overwritten by future calls to <code>Vec::push()</code>.</p> <h3 id="unroll-it-harder"><a href="#unroll-it-harder">Unroll It Harder</a></h3> <p>Ok, let’s look at the memcpy from <code>copy_from_slice</code> at the start of the hot loop. The loop has already been partly unrolled: it does <code>N</code> iterations with SIMD each step, doing something funny on the last step to make up for the missing data (padding with <code>A</code>).</p> <p>We can take this a step further by doing an “unroll and jam” optimization. This type of unrolling splits the loop into two parts: a hot vectorized loop and a cold remainder part. The hot loop <em>always</em> handles length <code>N</code> input, and the remainder runs at most once and handles <code>i &lt; N</code> input.</p> <p>Rust provides an iterator adapter for hand-rolled (lol) unroll-and-jam: <code>Iterator::chunks_exact()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>let</span> <span>mut</span> <span>chunks</span> <span>=</span> <span>data</span><span>.chunks_exact</span><span>(</span><span>N</span><span>);</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>&amp;</span><span>mut</span> <span>chunks</span> <span>{</span>
    <span>// Simd::from_slice() can do a load in one instruction.</span>
    <span>// The bounds check is easy for the compiler to elide.</span>
    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>Simd</span><span>::</span><span>from_slice</span><span>(</span><span>chunk</span><span>));</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>let</span> <span>rest</span> <span>=</span> <span>chunks</span><span>.remainder</span><span>();</span>
  <span>if</span> <span>!</span><span>rest</span><span>.empty</span><span>()</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>/* snip */</span>
<span>}</span></code></pre></figure></div> <p>Splitting into two parts lets us call <code>Simd::from_slice()</code>, which performs a single, vector-sized load.</p> <h2 id="so-how-fast-is-it"><a href="#so-how-fast-is-it">So, How Fast Is It?</a></h2> <p>At this point, it looks like we’ve addressed every branch that we can, so some benchmarks are in order. I wrote a benchmark that decodes messages of every length from 0 to something like 200 or 500 bytes, and compared it against the baseline base64 implementation on crates.io.</p> <p>I compiled with <code>-Zbuild-std</code> and <code>-Ctarget-cpu=native</code> to try to get the best results. Based on some tuning, <code>N = 32</code> was the best length, since it used one YMM register for each iteration of the hot loop.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph-old.png" alt="a performance graph; our code is really good compared to the baseline, but variance is high"/></p> <p>So, we have the baseline beat. But what’s up with that crazy heartbeat waveform? You can tell it has something to do with the “remainder” part of the loop, since it correlates strongly with <code>data.len() % 32</code>.</p> <p>I stared at the assembly for a while. I don’t remember what was there, but I think that <code>copy_from_slice</code> had been inlined and unrolled into a loop that loaded each byte at a time. The moral equivalent of this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>N</span><span>];</span>
<span>for</span> <span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>in</span> <span>Iterator</span><span>::</span><span>zip</span><span>(</span><span>&amp;</span><span>mut</span> <span>ascii</span><span>,</span> <span>chunk</span><span>)</span> <span>{</span>
  <span>*</span><span>a</span> <span>=</span> <span>*</span><span>b</span><span>;</span>
<span>}</span></code></pre></figure></div> <p>I decided to try <code>Simd::gather_or()</code>, which is kind of like a “vectorized load”. It wound up producing worse assembly, so I gave up on using a gather and instead wrote a carefully optimized loading function by hand.</p> <h3 id="unroll-and-jam-revisited"><a href="#unroll-and-jam-revisited">Unroll and Jam, Revisited</a></h3> <p>The idea here is to perform the largest scalar loads Rust offers where possible. The strategy is again unroll and jam: perform <code>u128</code> loads in a loop and deal with the remainder separately.</p> <p>The hot part looks like this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>buf</span> <span>=</span> <span>[</span><span>b&#39;A&#39;</span><span>;</span> <span>N</span><span>];</span>

<span>// Load a bunch of big 16-byte chunks. LLVM will lower these to XMM loads.</span>
<span>let</span> <span>ascii_ptr</span> <span>=</span> <span>buf</span><span>.as_mut_ptr</span><span>();</span>
<span>let</span> <span>mut</span> <span>write_at</span> <span>=</span> <span>ascii_ptr</span><span>;</span>
<span>if</span> <span>slice</span><span>.len</span><span>()</span> <span>&gt;=</span> <span>16</span> <span>{</span>
  <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>slice</span><span>.len</span><span>()</span> <span>/</span> <span>16</span> <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>write_at</span> <span>=</span> <span>write_at</span><span>.add</span><span>(</span><span>i</span> <span>*</span> <span>16</span><span>);</span>

      <span>let</span> <span>word</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.add</span><span>(</span><span>i</span><span>)</span><span>.read_unaligned</span><span>();</span>
      <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>word</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The cold part seems hard to optimize at first. What’s the least number of unaligned loads you need to do to load 15 bytes from memory? It’s two! You can load a <code>u64</code> from <code>p</code>, and then another one from <code>p + 7</code>; these loads (call them <code>a</code> and <code>b</code>) overlap by one byte, but we can or them together to merge that byte, so our loaded value is <code>a as u128 | (b as u128 &lt;&lt; 56)</code>.</p> <p>A similar trick works if the data to load is between a <code>u32</code> and a <code>u64</code>. Finally, to load 1, 2, or 3 bytes, we can load <code>p</code>, <code>p + len/2</code> and <code>p + len-1</code>; depending on whether <code>len</code> is 1, 2, or 3, this will potentially load the same byte multiple times; however, this reduces the number of branches necessary, since we don’t need to distinguish the 1, 2, or 3 lines.</p> <p>This is the kind of code that’s probably easier to read than to explain.</p> <div><figure><pre><code data-lang="rust"><span>unsafe</span> <span>{</span>
  <span>let</span> <span>ptr</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.offset</span><span>(</span><span>write_at</span><span>.offset_from</span><span>(</span><span>ascii_ptr</span><span>));</span>
  <span>let</span> <span>len</span> <span>=</span> <span>slice</span><span>.len</span><span>()</span> <span>%</span> <span>16</span><span>;</span>

  <span>if</span> <span>len</span> <span>&gt;=</span> <span>8</span> <span>{</span>
    <span>// Load two overlapping u64s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>8</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>8</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u128</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b&#39;A&#39;</span><span>;</span> <span>16</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>if</span> <span>len</span> <span>&gt;=</span> <span>4</span> <span>{</span>
    <span>// Load two overlapping u32s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>4</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>4</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u64</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b&#39;A&#39;</span><span>;</span> <span>8</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>// Load 3 overlapping u8s.</span>

    <span>// For len       1       2       3     ...</span>
    <span>// ... this is  ptr[0]  ptr[0]  ptr[0]</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[1]</span>
    <span>let</span> <span>mid</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>/</span> <span>2</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[2]</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>1</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>

    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>mid</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>/</span> <span>2</span><span>)</span> <span>*</span> <span>8</span><span>))</span> <span>|</span> <span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>8</span><span>);</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u32</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b&#39;A&#39;</span><span>;</span> <span>4</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>I learned this type of loading code while contributing to Abseil: it’s very useful for loading variable-length data for data-hungry algorithms, like a codec or a hash function.</p> <p>Here’s the same benchmark again, but with our new loading code.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="a performance graph; our code is even better and the variance is very tight"/></p> <p>The results are really, really good. The variance is super tight, and our performance is 2x that of the baseline pretty much everywhere. <em>Success.</em></p> <h3 id="encoding-web-safe"><a href="#encoding-web-safe">Encoding? Web-Safe?</a></h3> <p>Writing an encoding function is simple enough: first, implement an <code>encode_hot()</code> function that reverses the operations from <code>decode_hot()</code>. The perfect hash from before won’t work, so you’ll need to <a href="https://github.com/mcy/vb64/blob/main/src/simd.rs#L170">invent a new one</a>.</p> <p>Also, the loading/storing code around the encoder is slightly different, too. <code>vb64</code> implements a very efficient encoding routine too, so I suggest taking a look at the source code if you’re interested.</p> <p>There is a base64 variant called web-safe base64, that replaces the <code>+</code> and <code>/</code> characters with <code>-</code> and <code>_</code>. Building a perfect hash for these is trickier: you would probably have to do something like <code>(byte &gt;&gt; 4) - (byte == &#39;_&#39; ? &#39;_&#39; : 0)</code>. I don’t support web-safe base64 yet, but only because I haven’t gotten around to it.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>My library doesn’t really solve an important problem; base64 decoding isn’t a bottleneck… anywhere that I know of, really. But writing SIMD code is really fun! Writing branchless code is often overkill but can give you a good appreciation for what your compilers can and <em>can’t</em> do for you.</p> <p>This project was also an excuse to try <code>std::simd</code>. I think it’s great overall, and generates excellent code. There’s some rough edges I’d like to see fixed to make SIMD code even simpler, but overall I’m very happy with the work that’s been done there.</p> <p>This is probably one of the most complicated posts I’ve written in a long time. SIMD (and performance in general) is a complex topic that requires a breadth of knowledge of tricks and hardware, a lot of which isn’t written down. More of it is written down now, though.</p>  </div></div>
  </body>
</html>
