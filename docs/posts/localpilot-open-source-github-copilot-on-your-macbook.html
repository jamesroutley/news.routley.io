<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/danielgross/localpilot">Original</a>
    <h1>LocalPilot: Open-source GitHub Copilot on your MacBook</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto"><em>Use GitHub Copilot locally on your Macbook with one-click!</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/279531/271988855-521d0613-7423-4839-a5e8-42098cd65a5e.png"><img src="https://user-images.githubusercontent.com/279531/271988855-521d0613-7423-4839-a5e8-42098cd65a5e.png" alt="image"/></a></p>
<h2 tabindex="-1" id="user-content-demo-video" dir="auto"><a href="#demo-video">Demo Video<svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></h2>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description demo.mov">demo.mov</span>
    <span></span>
  </summary>

  <video src="https://user-images.githubusercontent.com/279531/272003079-3259981b-39f7-4bfa-8a45-84bde6d4ba4c.mov" data-canonical-src="https://user-images.githubusercontent.com/279531/272003079-3259981b-39f7-4bfa-8a45-84bde6d4ba4c.mov" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><em>This video is not sped up or slowed down.</em></p>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation<svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></h2>
<ol dir="auto">
<li>First, open VS Code Settings and add the following to your settings.json file:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="&#34;github.copilot.advanced&#34;: {
    &#34;debug.testOverrideProxyUrl&#34;: &#34;http://localhost:5001&#34;,
    &#34;debug.overrideProxyUrl&#34;: &#34;http://localhost:5001&#34;
}"><pre><span>&#34;github.copilot.advanced&#34;</span>: {
    <span>&#34;debug.testOverrideProxyUrl&#34;</span>: <span><span>&#34;</span>http://localhost:5001<span>&#34;</span></span>,
    <span>&#34;debug.overrideProxyUrl&#34;</span>: <span><span>&#34;</span>http://localhost:5001<span>&#34;</span></span>
}</pre></div>
<ol start="2" dir="auto">
<li>Create a virtualenv to run this Python process, install the requirements, and download the models.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="virtualenv venv
source venv/bin/activate
pip install -r requirements.txt
# First setup run. This will download several models to your ~/models folder.
python app.py --setup "><pre><span>virtualenv</span> <span>venv</span>
<span>source</span> <span>venv</span><span>/</span><span>bin</span><span>/</span><span>activate</span>
<span>pip</span> <span>install</span> <span>-</span><span>r</span> <span>requirements</span>.<span>txt</span>
<span># First setup run. This will download several models to your ~/models folder.</span>
<span>python</span> <span>app</span>.<span>py</span> <span>-</span><span>-</span><span>setup</span> </pre></div>
<ol start="3" dir="auto">
<li>Run it!</li>
</ol>

<p dir="auto">Enjoy your on-device Copilot!</p>
<h2 tabindex="-1" id="user-content-caveat-faq" dir="auto"><a href="#caveat-faq">Caveat FAQ<svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></h2>
<p dir="auto"><strong>Is the code as good as GitHub Copilot?</strong></p>
<p dir="auto">For simple line completions yes. For simple function completions, mostly. For complex functions... maybe.</p>
<p dir="auto"><strong>Is it as fast as GitHub Copilot?</strong></p>
<p dir="auto">On my Macbook Pro with an Apple M2 Max, the 7b models are roughly as fast. The 34b models are not. Please consider this repo a demonstration of a very inefficient implementation. I&#39;m sure we can make it faster; please do submit a pull request if you&#39;d like to help. For example, I think we need debouncer because sometimes llama.cpp/GGML isn&#39;t fast at interrupting itself when a newer request comes in.</p>
<p dir="auto"><strong>Can this be packaged as a simple Mac app?</strong></p>
<p dir="auto">Yes!, I&#39;m sure it can be, I just haven&#39;t had the time. Please do submit a pull request if you&#39;re into that sort of thing!</p>
<p dir="auto"><strong>Should there be a meta-model that routes to a 1b for autocomplete, 7b for more complex autocomplete, and a 34b for program completion?</strong></p>
<p dir="auto">Hmm, that seems like an interesting idea.</p>
<p dir="auto"><strong>OK, but in summary, is it good?</strong></p>
<p dir="auto">Only if your network is bad. I don&#39;t think it&#39;s competitive if you have fast Internet. But it sure is awesome on airplanes and while tethering!</p>
</article>
          </div></div>
  </body>
</html>
