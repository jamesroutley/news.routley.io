<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://archaeologist.dev/artifacts/anthropic">Original</a>
    <h1>Anthropic made a mistake in cutting off third-party clients</h1>
    
    <div id="readability-page-1" class="page"><div><p>Anthropic may have just committed the biggest business blunder of 2026 -- and we&#39;re less than two weeks in. To understand why, let&#39;s briefly rewind to 2025, the year when agentic AI went mainstream.</p>
<p>On 3 February 2025, Andrej Karpathy <a href="https://x.com/karpathy/status/1886192184808149383?s=20">coined the term &#34;vibe coding&#34;</a> to describe the new paradigm.</p>
<p>Less than three weeks later, Anthropic <a href="https://www.anthropic.com/news/claude-3-7-sonnet">released the first research preview of Claude Code</a>, bringing large language models directly into developers&#39; native habitat: the terminal.</p>
<p>OpenAI <a href="https://techcrunch.com/2025/04/16/openai-debuts-codex-cli-an-open-source-coding-tool-for-terminals/">followed with Codex CLI</a> in April, and Google released <a href="https://blog.google/innovation-and-ai/technology/developers-tools/introducing-gemini-cli-open-source-ai-agent/">Gemini CLI</a> in June.</p>
<p>All of these terminal-based coding agents follow the same principle:</p>
<ol>
<li>you type a prompt</li>
<li>the agent sends it to a large language model</li>
<li>the LLM responds and may instruct the agent to carry out actions like editing files or running commands</li>
<li>the agent carries out the actions and appends the results to the prompt</li>
</ol>
<p>These steps are repeated in a loop, but with a twist: the agent can continue working through the loop until the LLM decides that it requires user input.</p>
<p>The principle is so simple that it immediately gave rise to a bunch of alternative coding agents, including OpenCode, Roo, and Amp Code (to name but a few).
Each brought its own unique philosophy and approach to the table, but what they all have in common is that they ultimately rely on large language models for intelligence.
Their job is purely to collect user input, execute tool calls, and pass those to the model, over and over again.
Therefore, they tend to provide a way to select from a predefined set of models and a means of authenticating with the relevant providers (such as Anthropic or OpenAI),
generally using an API key.</p>
<p>When Claude Code launched for real in June 2025, usage of the Anthropic models was <a href="https://www.zdnet.com/article/anthropics-popular-claude-code-ai-tool-now-included-with-its-20month-pro-plan/">included</a> in the Pro and Max plans, for a flat monthly or annual subscription.
These plans quickly became very popular when users realised that the effective cost per token was much lower compared to Anthropic&#39;s API pricing.
So popular, in fact, that it <a href="https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone">reached $1 billion in annualised revenue</a> after only six months.</p>
<p>Meanwhile, OpenCode rapidly gained popularity, <a href="http://archive.today/OftjM">amassing</a> over 50,000 GitHub stars and more than 650,000 monthly active users in the same short timeframe.
One of its key selling points was the ability to &#34;Log in with Anthropic to use your Claude Pro or Max account&#34;, thus enabling developers to benefit from the attractive Claude subscription pricing.
In contrast, other coding agents such as Amp only provided the ability to connect to Claude models via the much more expensive pay-per-token API.</p>
<p>It turns out that logging into third-party coding agents with an Anthropic OAuth token was a bit of a loophole. This was evident from the fact that it would only work if the client-supplied system prompt contained a specific phrase <a href="https://github.com/anomalyco/opencode/issues/417">identifying itself as Claude Code</a>. Nevertheless, many (presumably) unsuspecting Anthropic customers used OpenCode in this way; from their perspective, they were simply using the same service that they were already paying for, just in the comfort of their preferred coding harness.</p>
<p>However, Anthropic clearly didn&#39;t see it this way. On 9 January 2026, Anthropic unceremoniously closed the loophole, changing their API to detect and reject requests from third-party clients. The renowned vibe-coder Peter Steinberger soon <a href="https://x.com/steipete">posted</a> about it on the website formerly known as Twitter, and disgruntled Anthropic customers <a href="https://github.com/anthropics/claude-code/issues/17118">expressed their discontent</a> in a GitHub issue, requesting the decision to be reversed, many threatening to cancel their Claude subscription otherwise.</p>
<p>It&#39;s notable that Anthropic has not formally announced this change in ToS enforcement, neither ahead of time nor after the fact. The only quasi-announcement of this change was <a href="https://x.com/trq212/status/2009689809875591565">this thread</a>, posted by an Anthropic employee on their personal account the day after the changes took effect, presumably in response to customer complaints. The stated motivation for the change was the allegation that &#34;third-party harnesses using Claude subscriptions create problems for users and generate unusual traffic patterns [...] making it really hard for us to help debug when they have questions about rate limit usage or account bans and they donâ€™t have any other avenue for this support.&#34;</p>
<p>I will leave it to the reader to decide for themselves whether they consider this a credible explanation or not; frankly, it doesn&#39;t matter. The truth is that Anthropic is free to put whatever they want into their ToS, and customers have to abide by it or leave. It appears quite a few have opted for the latter. However, what does matter is what Anthropic has implicitly revealed through its actions last Friday:</p>
<ol>
<li>Anthropic is willing to go to war with their paying customers over a trivial ToS violation, and</li>
<li>they really, really want to own the entire value chain rather than being relegated to becoming just another &#34;model provider&#34;, and</li>
<li>they utterly failed to consider the second-order effects of this business decision.</li>
</ol>
<p>The first point has received ample discussion already, so I want to focus on the second and third points.</p>
<p>It was <a href="https://www.theguardian.com/technology/2026/jan/07/ai-anthropic-funding-valuation">reported</a> just a few days earlier that Anthropic has signed a term sheet to raise $10bn at a humongous $350bn valuation. Related or not, the incentives are clear. Model-agnostic harnesses such as OpenCode present a real threat to Anthropic. Whilst its models are incredibly popular in the software developer community and it has made big inroads in enterprise LLM usage, the Claude chatbot itself reportedly commands a market share of... wait for it... <a href="https://gs.statcounter.com/ai-chatbot-market-share">1.07%</a>. So it&#39;s no surprise that they are trying to avoid being commoditized in their core market.</p>
<p>Which brings us to the final point: without anticipating it, Anthropic just found itself in a classic <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">prisoner&#39;s dilemma</a> with OpenAI -- and OpenAI just <a href="https://x.com/thsottiaux/status/2009742187484065881?s=20">defected</a>. Not only are they officially supporting OpenCode users to use their Codex subscriptions and usage limits in OpenCode, they are <a href="https://x.com/thsottiaux/status/2010064438033104966">extending the same support</a> to other open-source coding harnesses such as OpenHands, RooCode, and Pi. And it&#39;s not just a theoretical announcement either: support for connecting ChatGPT Pro/Plus subscriptions with OpenCode has already <a href="https://x.com/thdxr/status/2009803906461905202?s=20">shipped</a>.</p>
<p>What are we to take away from all this?</p>
<p>For me personally, I have decided I will never be an Anthropic customer, because I refuse to do business with a company that takes its customers for granted. Beyond my personal choices, though, I predict that the folks at Anthropic will come to regret their actions last week. By cracking down on their own customers in a vain attempt to quash healthy competition, they have destroyed a lot of goodwill and <a href="https://x.com/archeologistdev/status/2009763760748278110?s=20">gave their main rival an opening that was ripe for the picking</a>. Whilst they have plenty of cash in the bank for now, they will eventually need to learn to treat their customers with respect if they are to survive in the ever-more-competitive LLM provider landscape.</p>
<p><em>The views expressed here are my own. While the analysis is based on publicly available information, I welcome any factual corrections -- please feel free to <a href="https://x.com/archeologistdev">reach out</a>.</em></p>
</div></div>
  </body>
</html>
