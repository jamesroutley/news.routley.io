<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/HarryR/z80ai">Original</a>
    <h1>Show HN: Z80-μLM, a &#39;Conversational AI&#39; That Fits in 40KB</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Z80-μLM is a &#39;conversational AI&#39; that generates short character-by-character sequences, with quantization-aware training (QAT) to run on a Z80 processor with 64kb of ram.</p>
<p dir="auto">The root behind this project was the question: how small can we go while still having personality, and can it be trained or fine-tuned easily? With easy self-hosted distribution?</p>
<p dir="auto">The answer is Yes! And a 40kb .com binary (including inference, weights &amp; a chat-style UI) running on a 4MHz processor from 1976.</p>
<p dir="auto">It won&#39;t pass the Turing test, but it might make you smile at the green screen.</p>
<p dir="auto">For insight on how to best train your own model, see <a href="https://github.com/HarryR/z80ai/blob/main/TRAINING.md">TRAINING.md</a>.</p>

<p dir="auto">Two pre-built examples are included:</p>

<p dir="auto">A conversational chatbot trained on casual Q&amp;A pairs. Responds to greetings, questions about itself, and general banter with terse personality-driven answers.</p>
<div data-snippet-clipboard-copy-content="&gt; hello
HI
&gt; are you a robot
YES
&gt; do you dream
MAYBE"><pre><code>&gt; hello
HI
&gt; are you a robot
YES
&gt; do you dream
MAYBE
</code></pre></div>

<p dir="auto">A 20 Questions game where the model knows a secret topic and answers YES/NO/MAYBE to your questions. Guess correctly to WIN.</p>
<div data-snippet-clipboard-copy-content="&gt; is it alive
YES
&gt; is it big
YES
&gt; does it have a trunk
YES
&gt; is it grey
MAYBE
&gt; elephant
WIN"><pre><code>&gt; is it alive
YES
&gt; is it big
YES
&gt; does it have a trunk
YES
&gt; is it grey
MAYBE
&gt; elephant
WIN
</code></pre></div>
<p dir="auto">Includes tools for generating training data with LLMs (Ollama or Claude API) and balancing class distributions.</p>

<ul dir="auto">
<li><strong>Trigram hash encoding</strong>: Input text is hashed into 128 buckets - typo-tolerant, word-order invariant</li>
<li><strong>2-bit weight quantization</strong>: Each weight is {-2, -1, 0, +1}, packed 4 per byte</li>
<li><strong>16-bit integer inference</strong>: All math uses Z80-native 16-bit signed arithmetic</li>
<li><strong>~40KB .COM file</strong>: Fits in CP/M&#39;s Transient Program Area (TPA)</li>
<li><strong>Autoregressive generation</strong>: Outputs text character-by-character</li>
<li><strong>No floating point</strong>: Everything is integer math with fixed-point scaling</li>
<li><strong>Interactive chat mode</strong>: Just run <code>CHAT</code> with no arguments</li>
</ul>

<p dir="auto">The model doesn&#39;t understand you. But somehow, it <em>gets</em> you.</p>
<p dir="auto">Your input is hashed into 128 buckets via trigram encoding - an abstract &#34;tag cloud&#34; representation. The model responds to the <em>shape</em> of your input, not the exact words:</p>
<div data-snippet-clipboard-copy-content="&#34;hello there&#34;  →  [bucket 23: 64, bucket 87: 32, ...]
&#34;there hello&#34;  →  [bucket 23: 64, bucket 87: 32, ...]  (same!)
&#34;helo ther&#34;    →  [bucket 23: 32, bucket 87: 32, ...]  (similar - typo tolerant)"><pre><code>&#34;hello there&#34;  →  [bucket 23: 64, bucket 87: 32, ...]
&#34;there hello&#34;  →  [bucket 23: 64, bucket 87: 32, ...]  (same!)
&#34;helo ther&#34;    →  [bucket 23: 32, bucket 87: 32, ...]  (similar - typo tolerant)
</code></pre></div>
<p dir="auto">This is semantically powerful for short inputs, but there&#39;s a limit: longer or order-dependent sentences blur together as concepts compete for the same buckets. &#34;Open the door and turn on the lights&#34; will likely be too close to distringuish from &#34;turn on the door and open the lights.&#34;</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Small Responses, Big Meaning</h3><a id="user-content-small-responses-big-meaning" aria-label="Permalink: Small Responses, Big Meaning" href="#small-responses-big-meaning"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">A 1-2 word response can convey surprising nuance:</p>
<ul dir="auto">
<li><code>OK</code> - acknowledged, neutral</li>
<li><code>WHY?</code> - questioning your premise</li>
<li><code>R U?</code> - casting existential doubt</li>
<li><code>MAYBE</code> - genuine uncertainty</li>
<li><code>AM I?</code> - reflecting the question back</li>
</ul>
<p dir="auto">This isn&#39;t necessarily a limitation - it&#39;s a different mode of interaction. The terse responses force you to infer meaning from context or ask probing direct yes/no questions to see if it understands or not (e.g. &#39;are you a bot&#39;, &#39;are you human&#39;, &#39;am i human&#39; displays logically consistent memorized answers)</p>

<ul dir="auto">
<li>Short, varied inputs with consistent categorized outputs</li>
<li>Fuzzy matching (typos, rephrasing, word order)</li>
<li>Personality through vocabulary choice</li>
<li>Running on constrianed 8-bit hardware</li>
</ul>

<ul dir="auto">
<li>A chatbot that generates novel sentences</li>
<li>Something that tracks multi-turn context deeply</li>
<li>A parser that understands grammar</li>
<li>Anything approaching general intelligence</li>
</ul>
<p dir="auto">It&#39;s small, but functional. And sometimes that&#39;s exactly what you need</p>

<ul dir="auto">
<li><strong>Input</strong>: 128 query trigram buckets + 128 context buckets</li>
<li><strong>Hidden layers</strong>: Configurable depth/width, e.g., 256 → 192 → 128</li>
<li><strong>Output</strong>: One neuron per character in charset</li>
<li><strong>Activation</strong>: ReLU between hidden layers</li>
</ul>

<p dir="auto">The Z80 is an 8-bit CPU, but we use its 16-bit register pairs (HL, DE, BC) for activations and accumulators. Weights are packed 4-per-byte (2-bit each) and unpacked into 8-bit signed values for the multiply-accumulate.</p>
<p dir="auto">The 16-bit accumulator gives us numerical stability (summing 256 inputs without overflow), but the model&#39;s expressiveness is still bottlenecked by the 2-bit weights, and naive training may overflow or act &#39;weirdly&#39; without QAT.</p>

<p dir="auto">The core of inference is a tight multiply-accumulate loop. Weights are packed 4-per-byte:</p>
<div data-snippet-clipboard-copy-content="; Unpack 2-bit weight from packed byte
ld a, (PACKED)      ; Get packed weights
and 03h             ; Mask bottom 2 bits
sub 2               ; Map 0,1,2,3 → -2,-1,0,+1
ld (WEIGHT), a

; Rotate for next weight
ld a, (PACKED)
rrca
rrca
ld (PACKED), a"><pre lang="z80"><code>; Unpack 2-bit weight from packed byte
ld a, (PACKED)      ; Get packed weights
and 03h             ; Mask bottom 2 bits
sub 2               ; Map 0,1,2,3 → -2,-1,0,+1
ld (WEIGHT), a

; Rotate for next weight
ld a, (PACKED)
rrca
rrca
ld (PACKED), a
</code></pre></div>
<p dir="auto">The multiply-accumulate handles the 4 possible weight values:</p>
<div data-snippet-clipboard-copy-content="MULADD:
    or a
    jr z, DONE       ; weight=0: skip entirely
    jp m, NEG        ; weight&lt;0: subtract
    ; weight=+1: add activation
    ld hl, (ACC)
    add hl, de
    ld (ACC), hl
    ret
NEG:
    cp 0FFh
    jr z, NEG1       ; weight=-1
    ; weight=-2: subtract twice
    ld hl, (ACC)
    sbc hl, de
    sbc hl, de
    ld (ACC), hl
    ret
NEG1:
    ; weight=-1: subtract once
    ld hl, (ACC)
    sbc hl, de
    ld (ACC), hl
    ret"><pre lang="z80"><code>MULADD:
    or a
    jr z, DONE       ; weight=0: skip entirely
    jp m, NEG        ; weight&lt;0: subtract
    ; weight=+1: add activation
    ld hl, (ACC)
    add hl, de
    ld (ACC), hl
    ret
NEG:
    cp 0FFh
    jr z, NEG1       ; weight=-1
    ; weight=-2: subtract twice
    ld hl, (ACC)
    sbc hl, de
    sbc hl, de
    ld (ACC), hl
    ret
NEG1:
    ; weight=-1: subtract once
    ld hl, (ACC)
    sbc hl, de
    ld (ACC), hl
    ret
</code></pre></div>
<p dir="auto">After each layer, arithmetic right-shift by 2 to prevent overflow:</p>
<div data-snippet-clipboard-copy-content="sra h        ; Shift right arithmetic (preserves sign)
rr l
sra h
rr l         ; ACC = ACC / 4"><pre lang="z80"><code>sra h        ; Shift right arithmetic (preserves sign)
rr l
sra h
rr l         ; ACC = ACC / 4
</code></pre></div>
<p dir="auto">That&#39;s the entire neural network: unpack weight, multiply-accumulate, shift. Repeat ~100K times per character generated.</p>
<hr/>
<p dir="auto">License: MIT or Apache-2.0 as you see fit.</p>
</article></div></div>
  </body>
</html>
