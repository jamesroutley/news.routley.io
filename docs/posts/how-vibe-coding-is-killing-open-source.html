<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://hackaday.com/2026/02/02/how-vibe-coding-is-killing-open-source/">Original</a>
    <h1>How Vibe Coding Is Killing Open Source</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>Does vibe coding risk destroying the Open Source ecosystem? According to <a href="https://arxiv.org/abs/2601.15494" target="_blank">a pre-print paper</a> by a number of high-profile researchers, this might indeed be the case based on observed patterns and some modelling. Their warnings mostly center around the way that user interaction is pulled away from OSS projects, while also making starting a new OSS project significantly harder.</p>
<p>“Vibe coding” here is defined as software development that is assisted by an LLM-backed chatbot, where the developer asks the chatbot to effectively write the code for them. Arguably this turns the developer into more of a customer/client of the chatbot, with no requirement for the former to understand what the latter’s code does, just that what is generated does the thing that the chatbot was asked to create.</p>
<p>This also removes the typical more organic selection process of libraries and tooling, replacing it with whatever was most prevalent in the LLM’s training data. Even for popular projects visits to their website decrease as downloads and documentation are replaced by LLM chatbot interactions, reducing the possibility of promoting commercial plans, sponsorships, and community forums. Much of this is also reflected in the plummet in usage of community forums like Stack Overflow.</p>

<figure id="attachment_914310" aria-describedby="caption-attachment-914310"><a href="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg"><img decoding="async" data-attachment-id="914310" data-permalink="https://hackaday.com/2026/02/02/how-vibe-coding-is-killing-open-source/vibe_coding_impact_oss_communities_koren_et_al_2026/" data-orig-file="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg" data-orig-size="912,452" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="vibe_coding_impact_oss_communities_koren_et_al_2026" data-image-description="&lt;p&gt;https://arxiv.org/abs/2601.15494&lt;/p&gt;
" data-image-caption="&lt;p&gt;(Credit: Koren et al., 2026)&lt;/p&gt;
" data-medium-file="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?w=800" src="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?w=800" alt="(Credit: Koren et al., 2026)" width="800" height="396" srcset="https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg 912w, https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?resize=250,124 250w, https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?resize=400,198 400w, https://hackaday.com/wp-content/uploads/2026/01/vibe_coding_impact_oss_communities_koren_et_al_2026.jpg?resize=800,396 800w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-914310">(Credit: <a href="https://arxiv.org/abs/2601.15494" target="_blank">Koren et al.</a>, 2026)</figcaption></figure>
<p>If we consider this effect of ‘AI-assisted’ software development to be effectively the delegating of the actual engineering and development to the statistical model of an LLM, then it’s easy to see the problems here. The LLM will not interact with the developers of a library or tool, nor submit <a href="https://hackaday.com/2026/01/26/the-curl-project-drops-bug-bounties-due-to-ai-slop/">usable bug reports</a>, or be aware of any potential issues no matter how well-documented.</p>
<p>Although the authors of this paper are still proponents of ‘AI technology’, their worries seem well-warranted, even if it’s unclear at this point how big the impact is going to be. Software ecosystems like those involving JavaScript, Python, and web technologies are likely to suffer the impact from vibe coding first, as their audiences appear to be more into such vibes, and the training sets were largest.</p>
<p>It’s also a topic that is highly controversial, ever since Microsoft <a href="https://hackaday.com/2021/08/02/github-copilot-and-the-unfulfilled-promises-of-an-artificial-intelligence-future/">launched GitHub Copilot</a> in 2021. Since then we saw <a href="https://hackaday.com/2024/10/15/assessing-developer-productivity-when-using-ai-coding-assistants/">reports in 2024</a> that ‘vibe coding’ using Copilot and similar chatbots offered no real benefits unless adding 41% more bugs is a measure of success.</p>
<p>By the time we hit 2025, we can observe an even more negative mood, with LLM chatbots in general being accused of <a href="https://hackaday.com/2025/02/13/why-ai-usage-may-degrade-human-cognition-and-blunt-critical-thinking-skills/">degrading the cognitive skills</a> of those using them, vibe coding chatbots <a href="https://hackaday.com/2025/07/11/measuring-the-impact-of-llms-on-experienced-developer-productivity/">reducing productivity</a> by 19%, and experienced developers who gave them a whirl subsequently burning them to the ground in <a href="https://hackaday.com/2025/07/04/why-github-copilot-isnt-your-coding-partner/">scathing reviews</a>.</p>
<p>All of which reinforces the notion that perhaps this ‘AI revolution’ is more of a stress test for human intelligence than an actual boost to productivity or code quality. Despite the authors <a href="https://www.theregister.com/2026/01/26/vibe_coding_hazardous_open_source/" target="_blank">pitching the idea</a> that OpenAI or Google could toss a few cents the way of OSS projects when their code is being used, the comparison with Spotify is painfully apt, since about <a href="https://www.musicbusinessworldwide.com/over-75-of-artists-on-spotify-have-fewer-than-50-monthly-listeners/" target="_blank">80% of artists</a> on Spotify rarely have their tracks played and thus receive basically no money for their efforts.</p>
<p>With an LLM statistical model we know with extremely high likelihood that only the dependencies that are most prevalent in the training data set will realistically be used for the output, and we expect that we’ll see something similar happen with this vibe coding compensation scheme.</p>
<p>Even today we can already observe many negative effects from ‘AI slop’ in software development. Whether it’ll be something that’ll choke the life out of the entire OSS ecosystem remains to be seen, but it is hard to envision a bright vibe coding future.</p>
	            </div></div>
  </body>
</html>
