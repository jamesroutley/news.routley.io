<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://the-decoder.com/stanfords-alpaca-shows-that-openai-may-have-a-problem/">Original</a>
    <h1>Stanford’s Alpaca shows that OpenAI may have a problem</h1>
    
    <div id="readability-page-1" class="page"><div><p><strong>Researchers train a language model from Meta with text generated by OpenAI’s GPT-3.5 for less than $600 – and achieve similar performance.</strong></p><p>Training large language models is expensive, and powerful models remain the monopoly of large technology companies – right?</p><p>Perhaps not.</p><p>Researchers at Stanford used 52,000 instruction-following demonstrations generated by OpenAI’s <a href="https://the-decoder.com/openais-latest-gpt-3-model-generates-better-and-longer-texts/">GPT-3.5</a> (text-davinci-003) to fine-tune a seven-billion-parameter variant of Meta’s recently announced <a href="https://the-decoder.com/metas-llama-language-model-shows-that-parameters-are-not-everything/">LLaMA</a> model.</p><div><div><p>Ad</p><div><div><div>
<svg width="40" height="38" viewBox="0 0 167 160" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
<path d="M103.175 86.95c-5.101-5.101-12.187-7.937-19.558-7.937-7.37 0-14.173 2.835-19.559 7.937l-6.519 6.518-47.052-31.745c-1.701-1.133-3.686-1.418-5.669-.85-1.985.567-3.4 1.985-3.968 3.968C.283 66.258 0 67.676 0 69.092v77.948c0 3.4 1.418 6.518 3.685 8.786 1.133 1.133 2.836 1.985 4.536 1.985 1.7 0 3.118-.567 4.536-1.985 0 0 0-.283.282-.283l59.808-59.807c2.835-2.835 6.518-4.251 10.487-4.251 3.968 0 7.653 1.418 10.487 4.251l51.02 51.02H37.131c-3.4 0-6.235 2.836-6.235 6.236 0 3.401 2.835 6.236 6.235 6.236h117.064c3.401 0 6.519-1.418 8.786-3.685 2.268-2.268 3.686-5.386 3.686-8.787l-.002-77.664c0-1.985-.568-4.251-1.418-5.954-.85-1.417-1.7-2.55-3.118-3.685L98.07 5.315c-8.504-7.087-20.408-7.087-28.912 0L20.972 45.849c-2.55 2.267-3.118 6.235-.85 9.071 2.268 2.55 6.236 3.118 9.072.85l48.185-40.532c3.685-3.118 9.071-3.118 12.472 0l53.855 45.068 6.803 5.668L125 83.264c-2.835 1.985-3.685 5.954-1.7 8.787 1.133 1.7 3.118 2.835 5.386 2.835 1.133 0 2.55-.283 3.685-1.133L154.48 78.73v59.524L103.175 86.95ZM48.47 102.54l-35.431 35.431V78.73l35.431 23.81Z" fill="#28293d" fill-rule="nonzero"></path>
</svg><div><p>THE DECODER Newsletter</p><p>The most important AI news straight to your inbox.</p><p>✓ Weekly</p><p>✓ Free</p><p>✓ Cancel at any time</p></div></div></div></div></div></div><p>Instruction training is one of the key techniques that make GPT-3.5 superior to the original GPT-3 model, and the training data used is proprietary to OpenAI.</p><p>While RLHF is critical for tuning models like <a href="https://the-decoder.com/chatgpt-is-a-gpt-3-chatbot-from-openai-that-you-can-test-now/">ChatGPT</a> or even <a href="https://the-decoder.com/open-ai-gpt-4-announcement/">GPT-4</a>, the essential capabilities of the models are based on their original training – i.e., training with instructions as well.</p><h2>Stanford’s Alpaca trains with OpenAI output</h2><p>In their work, the Stanford group used the AI-generated instructions to train Alpaca 7B, a language model that the researchers say exhibits many GPT-3.5-like behaviors. In a blind test using input from the <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl">Self-Instruct Evaluation Set</a> both models performed comparably, the team says.</p><p>Alpaca has problems common to other language models, such as hallucinations, toxicity, and stereotyping. In particular, hallucinations occur more frequently than in the OpenAI model.</p><p>The team is releasing an interactive demo, the training dataset, and the training code. They have also asked Meta for permission to release the model. With the release, the team hopes to enable research on language models trained with instructions. To prevent misuse, they have included a content filter via the OpenAI API and a watermark in the demo.</p><div><p>Recommendation</p><div><div><p><a href="https://the-decoder.com/deepminds-latest-ai-has-better-visual-understanding/" aria-hidden="true" tabindex="-1"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzNzUiIGhlaWdodD0iMTk0IiB2aWV3Qm94PSIwIDAgMzc1IDE5NCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2YyZjJmMjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" data-src="https://the-decoder.com/wp-content/uploads/2022/09/flamingo-pexels-pixabay-39627-375x194.jpg" loading="lazy" alt="Deepmind’s latest AI has better visual understanding" width="375" height="194"/>
</a></p></div></div></div><p>The model cannot be used for commercial purposes. In addition to safety concerns and the non-commercial license of Meta’s LLaMA model, the team points to the OpenAI GPT-3.5 terms of use, which state that the model may not be used to develop AI models that compete with OpenAI.</p><h2>Alpaca’s training was so cheap that OpenAI has a problem</h2><p>The last point is an indication that OpenAI is aware that the output of its own models can be used as a data source for potential replicas. <a href="https://the-decoder.com/metas-llama-leak-shows-secure-ai-deployment-is-more-of-a-pipe-dream/">With the leak of the larger LLaMA models</a> with up to 65 billion parameters, it is conceivable that such projects are already in the works – and could also use the output of GPT-4.</p><p>In addition to its impressive performance for such a small model, Alpaca also shows how affordable AI training has become: the team trained Alpaca 7B for less than $600. Larger models will be more expensive, but the expected cost should be in a range that can be easily funded by companies or crowdsourced projects.</p><p>Alignment researcher Eliezer Yudkowsky summarizes the problem this poses for companies like OpenAI:” If you allow any sufficiently wide-ranging access to your AI model, even by paid API, you’re giving away your business crown jewels to competitors that can then nearly-clone your model without all the hard work you did to build up your own fine-tuning dataset.”</p><p>What can OpenAI do about that? Not much, says Yudkowsky: “If you successfully enforce a restriction against commercializing an imitation trained on your I/O – a legal prospect that’s never been tested, at this point – that means the competing checkpoints go up on BitTorrent.”</p><blockquote><p dir="ltr" lang="en">I don’t think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**.</p><p>It means: If you allow any sufficiently wide-ranging access to your AI… https://t. <a target="_blank" rel="noopener" href="https://t.co/rr5zag6C8Z">co/rr5zag6C8Z</a></p><p>– Eliezer Yudkowsky (@ESYudkowsky) <a target="_blank" rel="noopener" href="https://twitter.com/ESYudkowsky/status/1635577836525469697?ref_src=twsrc%5Etfw">March 14, 2023</a></p></blockquote>  <p>You can <a target="_blank" rel="noopener" href="https://alpaca-ai-custom2.ngrok.io/">try Stanford’s Alpaca 7B for free</a>.</p></div></div>
  </body>
</html>
