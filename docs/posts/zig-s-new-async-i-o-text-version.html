<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://andrewkelley.me/post/zig-new-async-io-text-version.html">Original</a>
    <h1>Zig&#39;s New Async I/O (Text Version)</h1>
    
    <div id="readability-page-1" class="page"><div>



<p>In celebration of the
<a href="https://github.com/ziglang/zig/pull/25592">std.Io introduction patchset landing today</a>,
here is the text version of
<a href="https://www.youtube.com/watch?v=mdOxIc0HM04">a short, interactive demo I gave</a> at
<a href="https://zigtoberfest.de/">Zigtoberfest 2025</a>.</p>

<p>This is a preview of the new async I/O primitives that will be available in the upcoming Zig 0.16.0, to be
released in about 3-4 months. There is a lot more to get into, but for now here is an introduction
into some of the core synchronization API that will be available for all Zig code to use.</p>

<p>To begin, let&#39;s try to keep it simple and understand the basics, and then we&#39;ll then slowly add more
asynchronous things into it.</p>


<h2>Example 0</h2>

<p>With our first example, there is nothing asynchronous here. It&#39;s basically &#34;Hello, World!&#34; in Zig.</p>

<pre><code>const std = @import(&#34;std&#34;);

pub fn main() !void {
    doWork();
}

fn doWork() void {
    std.debug.print(&#34;working\n&#34;, .{});
    var timespec: std.posix.timespec = .{ .sec = 1, .nsec = 0 };
    _ = std.posix.system.nanosleep(&amp;timespec, &amp;timespec);
}</code></pre>

<p>Output:</p>

<pre>0s $ zig run example0.zig
0s working
1s $</pre>

<h2>Example 1</h2>

<p>Next, we&#39;re going to set up a little bit. Still not using async/await yet, but I need some tools in my
toolbox before we add complexity.</p>


<pre><code>const std = @import(&#34;std&#34;);
const Io = std.Io;
const Allocator = std.mem.Allocator;
const assert = std.debug.assert;

fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    doWork(io);
}

fn doWork(io: Io) void {
    std.debug.print(&#34;working\n&#34;, .{});
    io.sleep(.fromSeconds(1), .awake) catch {};
}

pub fn main() !void {
    // Set up allocator.
    var debug_allocator: std.heap.DebugAllocator(.{}) = .init;
    defer assert(debug_allocator.deinit() == .ok);
    const gpa = debug_allocator.allocator();

    // Set up our I/O implementation.
    var threaded: std.Io.Threaded = .init(gpa);
    defer threaded.deinit();
    const io = threaded.io();

    return juicyMain(gpa, io);
}</code></pre>

<p>Output (same as before):</p>

<pre>0s $ zig run example0.zig
0s working
1s $</pre>

<p>Setting up a <code>std.Io</code> implementation is a lot like setting up an allocator.
You typically do it once, in main(), and then pass the instance throughout the application.
Reusable code should accept an Allocator parameter if it needs to allocate, and it should accept
an Io parameter if it needs to perform I/O operations.</p>

<p>In this case, this is an Io implementation based on threads. This is not using
KQueue, this is not using IO_Uring, this is not using an event loop. It is a <em>threaded</em> implementation
of the new <code>std.Io</code> interface.</p>

<p>This setup will be the same in all the examples, so now we can focus on our example code, which is the same
as last time. Still nothing interesting - we just call <code>doWork</code> which of course is just calling sleep().</p>

<h2>Example 2</h2>

<p>Redundant setup code omitted from here on out.</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    var future = io.async(doWork, .{io});

    future.await(io); // idempotent
}

fn doWork(io: Io) void {
    std.debug.print(&#34;working\n&#34;, .{});
    io.sleep(.fromSeconds(1), .awake) catch {};
}</code></pre>

<p>Output (same as before):</p>

<pre>0s $ zig run example0.zig
0s working
1s $</pre>

<p>Now we&#39;re using async/await to call doWork. What async/await means to Zig is to <em>decouple</em> the
<strong>calling</strong> of the function to the <strong>returning</strong> of the function.</p>

<p>This code is the same as before. It&#39;s exactly the same, because we didn&#39;t put any code between the async
and await. We do the call, and then immediately wait for the return.</p>

<h2>Example 3</h2>

<p>In the next example, we have two things at the same time:</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    var a = io.async(doWork, .{ io, &#34;hard&#34; });
    var b = io.async(doWork, .{ io, &#34;on an excuse not to drink Spezi&#34; });

    a.await(io);
    b.await(io);
}

fn doWork(io: Io, flavor_text: []const u8) void {
    std.debug.print(&#34;working {s}\n&#34;, .{flavor_text});
    io.sleep(.fromSeconds(1), .awake) catch {};
}</code></pre>

<p>Output:</p>

<pre>0s $ zig run example3.zig
0s working on an excuse not to drink Spezi
0s working hard
1s $</pre>

<p>If you look carefully, you can see that it did not wait two seconds; it waited one second because
these operations are happening at the same time. This demonstrates why using async/await is useful -
you can express asynchrony. Depending on the I/O implementation that you
choose, it may be able to take advantage of the asynchrony that you have
expressed and make your code go faster. For example in this case,
<code>std.Io.Threaded</code> was able to do two seconds of work in one second
of actual time.</p>

<h2>Example 4</h2>

<p>Let&#39;s start to bring the example closer to a real world scenario by introducing <strong>failure</strong>.</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, &#34;hard&#34; });
    var b = io.async(doWork, .{ gpa, io, &#34;on an excuse not to drink Spezi&#34; });

    try a.await(io);
    try b.await(io);
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == &#39;h&#39;) return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print(&#34;working {s}\n&#34;, .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}</code></pre>

<p>It&#39;s the same code as before, except the first task will return an error.</p>

<p>Guess what happens when this code is run?</p>

<p>Output:</p>

<pre>0s $ zig run example4.zig
0s working on an excuse not to drink Spezi
1s error(gpa): memory address 0x7f99ce6c0080 leaked:
1s /home/andy/src/zig/lib/std/Io/Threaded.zig:466:67: 0x1053aae in async (std.zig)
1s     const ac: *AsyncClosure = @ptrCast(@alignCast(gpa.alignedAlloc(u8, .of(AsyncClosure), n) catch {
1s                                                                   ^
1s /home/andy/src/zig/lib/std/Io.zig:1548:40: 0x1164f94 in async__anon_27344 (std.zig)
1s     future.any_future = io.vtable.async(
1s                                        ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:8:21: 0x116338a in juicyMain (example4.zig)
1s     var b = io.async(doWork, .{ gpa, io, &#34;on an excuse not to drink Spezi&#34; });
1s                     ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:35:21: 0x1163663 in main (example4.zig)
1s     return juicyMain(gpa, io);
1s                     ^
1s /home/andy/src/zig/lib/std/start.zig:696:37: 0x1163c83 in callMain (std.zig)
1s             const result = root.main() catch |err| {
1s                                     ^
1s /home/andy/src/zig/lib/std/start.zig:237:5: 0x1162f61 in _start (std.zig)
1s     asm volatile (switch (native_arch) {
1s     ^
1s 
1s thread 1327233 panic: reached unreachable code
1s error return context:
1s /home/andy/src/zig/lib/std/Io.zig:1003:13: 0x11651a8 in await (std.zig)
1s             return f.result;
1s             ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:10:5: 0x11633e8 in juicyMain (example4.zig)
1s     try a.await(io);
1s     ^
1s 
1s stack trace:
1s /home/andy/src/zig/lib/std/debug.zig:409:14: 0x103e5a9 in assert (std.zig)
1s     if (!ok) unreachable; // assertion failure
1s              ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:27:17: 0x1163698 in main (example4.zig)
1s     defer assert(debug_allocator.deinit() == .ok);
1s                 ^
1s /home/andy/src/zig/lib/std/start.zig:696:37: 0x1163c83 in callMain (std.zig)
1s             const result = root.main() catch |err| {
1s                                     ^
1s /home/andy/src/zig/lib/std/start.zig:237:5: 0x1162f61 in _start (std.zig)
1s     asm volatile (switch (native_arch) {
1s     ^
1s fish: Job 1, &#39;zig run example4.zig&#39; terminated by signal SIGABRT (Abort)
1s $</pre>

<p>The problem is that when the first <code>try</code> activates, it skips the second <code>await</code> which
is then caught by the leak checker.</p><p>This is a bug. It&#39;s unfortunate though, isn&#39;t it? Because we would like to write the code this way.</p>

<h2>Example 5</h2>

<p>Here&#39;s a fix:</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, &#34;hard&#34; });
    var b = io.async(doWork, .{ gpa, io, &#34;on an excuse not to drink Spezi&#34; });

    const a_result = a.await(io);
    const b_result = b.await(io);

    try a_result;
    try b_result;
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == &#39;h&#39;) return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print(&#34;working {s}\n&#34;, .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}</code></pre>

<p>We do the awaits, then we do the tries. This will fix the problem.</p>

<p>Output:</p>

<pre>0s $ zig run example5.zig
0s working on an excuse not to drink Spezi
1s error: OutOfMemory
1s /home/andy/src/zig/lib/std/Io.zig:1003:13: 0x11651d8 in await (std.zig)
1s             return f.result;
1s             ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example5.zig:13:5: 0x1163416 in juicyMain (example5.zig)
1s     try a_result;
1s     ^
1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example5.zig:38:5: 0x11636e9 in main (example5.zig)
1s     return juicyMain(gpa, io);
1s     ^
1s $</pre>

<p>This failed successfully. The error was handled and no resources leaked. But
it&#39;s a footgun. Let&#39;s find a better way to express this...</p>

<h2>Example 6</h2>

<p>This is where <strong>cancellation</strong> comes in. cancellation is an extremely handy primitive,
because now we can use <code>defer</code>, <code>try</code>, and <code>await</code> like normal,
and not only do we fix the bug, but we also get more optimal code.</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, &#34;hard&#34; });
    defer a.cancel(io) catch {};

    var b = io.async(doWork, .{ gpa, io, &#34;on an excuse not to drink Spezi&#34; });
    defer b.cancel(io) catch {};

    try a.await(io);
    try b.await(io);
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == &#39;h&#39;) return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print(&#34;working {s}\n&#34;, .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}</code></pre>

<p>Thanks to cancellation, we now get instant results, because the moment that the first
task returns an error, the cancels get run.</p>

<p>Output:</p>

<pre>0s $ zig run example6.zig
0s working on an excuse not to drink Spezi
0s error: OutOfMemory
0s /home/andy/misc/talks/zigtoberfest/async-io-examples/example6.zig:13:5: 0x116348c in juicyMain (example6.zig)
0s     try a.await(io);
0s     ^
0s /home/andy/misc/talks/zigtoberfest/async-io-examples/example6.zig:38:5: 0x1163909 in main (example6.zig)
0s     return juicyMain(gpa, io);
0s     ^
0s $</pre>

<p><code>cancel</code> is your best friend, because it&#39;s going to prevent you from leaking the
resource, and it&#39;s going to make your code run more optimally.</p>

<p><code>cancel</code> is trivial to understand: it has identical semantics as <code>await</code>, except
that it <em>also requests cancellation</em>. The conditions under which cancellation requests are honored
are defined by each I/O implementation.</p>

<p>Both <code>cancel</code> and <code>await</code> are idempotent with respect to themselves and each other.</p>

<h2>Example 7</h2>

<p>Next, let&#39;s introduce another real-world scenario: <strong>resource allocation</strong>.
In this case, we allocate a string on success, which the caller needs to manage.</p>

<pre><code>fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, &#34;hard&#34; });
    defer if (a.cancel(io)) |s| gpa.free(s) else |_| {};

    var b = io.async(doWork, .{ gpa, io, &#34;on an excuse not to drink Spezi&#34; });
    defer if (b.cancel(io)) |s| gpa.free(s) else |_| {};

    const a_string = try a.await(io);
    const b_string = try b.await(io);
    std.debug.print(&#34;finished {s}\n&#34;, .{a_string});
    std.debug.print(&#34;finished {s}\n&#34;, .{b_string});
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) ![]u8 {
    const copied_string = try gpa.dupe(u8, flavor_text);
    std.debug.print(&#34;working {s}\n&#34;, .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
    return copied_string;
}</code></pre>

<p>Now we see why <code>cancel</code> and <code>await</code> have the same API.
The deferred cancel calls above free the allocated resource, handling both
successful calls (resource allocated) and failed calls (resource not allocated).</p>

<p>Output:</p>

<pre>0s $ zig run example7.zig
0s working on an excuse not to drink Spezi
0s working hard
1s finished hard
1s finished on an excuse not to drink Spezi
1s $</pre>

<p>The important thing here is that by doing resource management like this, we are
able to write standard, idiomatic Zig code below, using <code>try</code> and <code>return</code>
like normal without worrying about special resource management cases.</p>

<h2>Example 8</h2>

<p>Now we&#39;re switching gears a little bit. It&#39;s time to learn why
<a href="https://kristoff.it/blog/asynchrony-is-not-concurrency/">asynchrony is not concurrency</a>.

</p><p>In this example we have a producer sending one item across an unbuffered queue to a consumer.</p>

<pre><code>fn juicyMain(io: Io) !void {
    var queue: Io.Queue([]const u8) = .init(&amp;.{});

    var producer_task = io.async(producer, .{
        io, &amp;queue, &#34;never gonna give you up&#34;,
    });
    defer producer_task.cancel(io) catch {};

    var consumer_task = io.async(consumer, .{ io, &amp;queue });
    defer _ = consumer_task.cancel(io) catch {};

    const result = try consumer_task.await(io);
    std.debug.print(&#34;message received: {s}\n&#34;, .{result});
}

fn producer(
    io: Io,
    queue: *Io.Queue([]const u8),
    flavor_text: []const u8,
) !void {
    try queue.putOne(io, flavor_text);
}

fn consumer(
    io: Io,
    queue: *Io.Queue([]const u8),
) ![]const u8 {
    return queue.getOne(io);
}</code></pre>

<p>We use <code>async</code> to spawn the producer and <code>async</code> to spawn the consumer.</p>

<p>Output:</p>
<pre>0s $ zig run example8.zig
0s message received: never gonna give you up
0s $</pre>

<p>This incorrectly succeeds. Depending on your perspective, we either got &#34;lucky&#34; or &#34;unlucky&#34; due
to the thread pool having spare concurrency that happened to be available.</p>

<p>To observe the problem, we can artificially limit the <code>std.Io.Threaded</code> instance to
use a thread pool size of one:</p>

<h2>Example 9</h2>

<pre><code>// Set up our I/O implementation.
    var threaded: std.Io.Threaded = .init(gpa);
    threaded.cpu_count = 1;
    defer threaded.deinit();
    const io = threaded.io();

    return juicyMain(io);
}</code></pre>

<p>Output: (deadlock) </p>

<p>Now that it&#39;s only using one thread, it deadlocks, because the consumer is waiting to get something from
the queue, and the producer is scheduled to run, but it has not run yet.</p>

<p>The problem is that <em>we needed concurrency, but we asked for asynchrony</em>.</p>

<h2>Example 10</h2>

<p>In order to fix this, we use <code>io.concurrent</code> instead of <code>io.async</code>.
This one can fail with <code>error.ConcurrencyUnavailable</code>.</p>

<pre><code>fn juicyMain(io: Io) !void {
    var queue: Io.Queue([]const u8) = .init(&amp;.{});

    var producer_task = try io.concurrent(producer, .{
        io, &amp;queue, &#34;never gonna give you up&#34;,
    });
    defer producer_task.cancel(io) catch {};

    var consumer_task = try io.concurrent(consumer, .{ io, &amp;queue });
    defer _ = consumer_task.cancel(io) catch {};

    const result = try consumer_task.await(io);
    std.debug.print(&#34;message received: {s}\n&#34;, .{result});
}

fn producer(
    io: Io,
    queue: *Io.Queue([]const u8),
    flavor_text: []const u8,
) !void {
    try queue.putOne(io, flavor_text);
}

fn consumer(
    io: Io,
    queue: *Io.Queue([]const u8),
) ![]const u8 {
    return queue.getOne(io);
}</code></pre>

<p>Output:</p>

<pre>0s $ zig run example10.zig
0s message received: never gonna give you up
0s $</pre>

<p>Now the code is fixed because we correctly expressed that we needed concurrency, which
<code>std.Io.Threaded</code> honored by oversubscribing.</p>

<p>If I add <code>-fsingle-threaded</code> which truly limits the executable to one thread,
oversubscription is not available, causing this output:</p>

<pre>error: ConcurrencyUnavailable
/home/andy/src/zig/lib/std/Io/Threaded.zig:529:34: 0x1051863 in concurrent (std.zig)
    if (builtin.single_threaded) return error.ConcurrencyUnavailable;
                                 ^
/home/andy/src/zig/lib/std/Io.zig:1587:25: 0x1158b5f in concurrent__anon_26591 (std.zig)
    future.any_future = try io.vtable.concurrent(
                        ^
/home/andy/misc/talks/zigtoberfest/async-io-examples/example10.zig:9:25: 0x1157198 in juicyMain (example10.zig)
    var producer_task = try io.concurrent(producer, .{
                        ^
/home/andy/misc/talks/zigtoberfest/async-io-examples/example10.zig:48:5: 0x115776a in main (example10.zig)
    return juicyMain(io);
    ^</pre>

<h2>Conclusion</h2>

<p>There are proof-of-concept <code>std.Io</code> implementations using IoUring and KQueue combined
with stackful coroutines which show a lot of promise, however that work depends on some language
enhancements to be practical. There is also ongoing design work about stackless coroutines. Here
are some relevant issues to track for those interested:</p>

<ul>
  <li><a href="https://github.com/ziglang/zig/issues/23367">Restricted Function Types</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/157">Builtin function to tell you the maximum stack size of a given function</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/1639">Eliminate Stack Overflow</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/23446">Stackless Coroutines</a></li>
  <li><a href="https://github.com/ziglang/zig/issues/24510">Juicy Main</a></li>
</ul>

<p>These APIs are not set in stone. It will probably take a few iterations to
get it right. Please try them out in <em>real world applications</em> and let
us know how it goes! Let&#39;s collaborate on making the I/O interface practical
and optimal.</p>

</div><p>Thanks for reading my blog post.</p></div>
  </body>
</html>
