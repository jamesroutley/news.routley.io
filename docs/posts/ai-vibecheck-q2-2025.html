<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.jschear.dev/blog/2025-04-26-ai-vibecheck/">Original</a>
    <h1>AI Vibecheck, Q2 2025</h1>
    
    <div id="readability-page-1" class="page"><div data-astro-cid-bvzihdzo=""> <article data-astro-cid-bvzihdzo="">   <time datetime="2025-04-26T00:00:00.000Z"> Apr 26, 2025 </time>  <hr data-astro-cid-bvzihdzo=""/>  <p>We’re solidly in the <a href="https://maxread.substack.com/p/the-ai-backlash-backlash">AI backlash backlash</a>. Here are some thoughts about using large language model-based tooling (like <a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview">Claude Code</a>, <a href="https://www.cursor.com/en">Cursor</a> and <a href="https://github.com/block/goose">Goose</a>) for software development in 2025.</p>
<h3 id="on-determinism">On determinism</h3>
<p>One thing that drew me to computing in the first place was the sense that, however complex computers were, they were fundamentally understandable. <a href="https://speakerdeck.com/bcantrill/things-i-learned-the-hard-way?slide=9">Computers aren’t magic</a>. I always find it extremely empowering when I can figure out a tricky bug by peeling back a few layers of abstraction.</p>
<p>LLMs are closer to magic. Unless I’ve missed some new development in interpretability, you can’t stare at the matrices powering them to figure out <em>why</em> a model has given you a certain response. If you’re having trouble with a tool, the solution is fuzzy: try a different model; try to stuff more relevant code in the context window; IDK, have you tried writing your prompt in all caps or asking more nicely? I would find it frustrating to be responsible for the quality of such a system. Maybe <a href="https://www.distributional.com">someone</a> will figure out how to make useful assertions about the quality of their output.</p>
<p>Nondeterminism isn’t new: probabilistic data structures are useful, and everything these days is asynchronous and distributed and horrifyingly complex. But do we have to inject <em>more</em> chaos into everything? I am heartened by newer tools that use LLMs to write a script or plan for invoking deterministic tools.</p>
<p>Also, just an aesthetic objection: dealing with tools that are confidently and cheerily wrong is annoying! Have some shame!</p>
<h3 id="ai-as-anti-expertise">AI as anti-expertise</h3>
<p>LLM tools are great at creating greenfield, prototype apps. I support the democratization of software engineering: I’m excited for more people to try building software, even if they vibe-code their way to victory.</p>
<p>But some of the excitement around AI tools feels like it’s trying to devalue software engineering broadly. If a CEO can clone a SaaS app in a few days, who needs those highly-paid engineers? Part of what I love about writing software is understanding a topic deeply and crafting something that will stand the test of time, and I think that will still require deep expertise.</p>
<p>There’s undoubtedly some “kids these days” energy here — people have long made similar arguments whenever a new technology makes the practice of programming more approachable. <em>Real</em> engineers write in assembly code. How can you call yourself a programmer if you’ve never done manual memory management? These web developers are ruining the desktop with their Electron apps.</p>
<p>I just hope that the vibe-coders still have curiosity about the systems they’re building on top of. In the near future, I see a lot of haphazardly built software, in desperate need of people to understand and maintain it. Maybe not all that different from today.</p>  </article> </div></div>
  </body>
</html>
