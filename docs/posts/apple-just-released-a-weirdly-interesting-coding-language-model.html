<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://9to5mac.com/2025/07/04/apple-just-released-a-weirdly-interesting-coding-language-model/">Original</a>
    <h1>Apple just released a weirdly interesting coding language model</h1>
    
    <div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/02/Apple-tells-competition-watchdog-it-cannot-give-developers-new-WebKit-features-for-free.jpg?quality=82&amp;strip=all&amp;w=1600" alt="UK competition regulator wants iPhone browser competition, but Apple not allowed to win | Computer code seen on a monitor" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/02/Apple-tells-competition-watchdog-it-cannot-give-developers-new-WebKit-features-for-free.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/02/Apple-tells-competition-watchdog-it-cannot-give-developers-new-WebKit-features-for-free.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/02/Apple-tells-competition-watchdog-it-cannot-give-developers-new-WebKit-features-for-free.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/02/Apple-tells-competition-watchdog-it-cannot-give-developers-new-WebKit-features-for-free.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"/></figure>

<p>Apple quietly dropped a <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">new AI model on Hugging Face</a> with an interesting twist. Instead of writing code like traditional LLMs generate text (left to right, top to bottom), it can also write out of order, and improve multiple chunks at once.</p>



<p>The result is faster code generation, at a performance that rivals top open-source coding models. Here’s how it works.</p>



<h2 id="h-the-nerdy-bits">The nerdy bits</h2>



<p>Here are some (overly simplified, in the name of efficiency) concepts that are important to understand before we can move on.</p>



<h4 id="h-autoregression">Autoregression</h4>



<p>Traditionally, most LLMs have been autoregressive. This means that when you ask them something, they process your entire question, predict the first token of the answer, reprocess the entire question with the first token, predict the second token, and so on. This makes them generate text like most of us read: left to right, top to bottom.</p>



<h4 id="h-temperature">Temperature</h4>



<p>LLMs have a setting called temperature that controls how random the output can be. When predicting the next token, the model assigns probabilities to all possible options. A lower temperature makes it more likely to choose the most probable token, while a higher temperature gives it more freedom to pick less likely ones.</p>



<h4 id="h-diffusion">Diffusion</h4>



<p>An alternative to autoregressive models is diffusion models, which have been more often used by image models like Stable Diffusion. In a nutshell, the model starts with a fuzzy, noisy image, and it iteratively removes the noise while keeping the user request in mind, steering it towards something that looks more and more like what the user requested.</p>



<figure><img decoding="async" height="341" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg 1422w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=155,52 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=655,218 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=768,256 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=1024,341 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=350,117 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=140,47 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffusion-nvidia.jpg?resize=150,50 150w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Diffusion model processes moving to and from data and noise. Image: <a href="https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/">NVIDIA</a></figcaption></figure>



<p>Still with us? Great!</p>



<p>Lately, some large language models have looked to the diffusion architecture to generate text, and the results have been pretty promising. If you want to dive deeper into how it works, here’s a great explainer:</p>



<figure><p>
<iframe id="post-youtube-video-1" title="How Diffusion Works for Text" width="500" height="281" data-src="https://www.youtube.com/embed/1mG678f1ZYU?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Why am I telling you all this? Because now you can see why diffusion-based text models can be faster than autoregressive ones, since they can basically (again, <em>basically</em>) iteratively refine the entire text in parallel.</p>



<p>This behavior is especially useful for programming, where global structure matters more than linear token prediction.</p>



<h2 id="h-phew-we-made-it-so-apple-released-a-model">Phew! We made it. So Apple released a model?</h2>



<p>Yes. They released an open-source model called <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">DiffuCode-7B-cpGRPO</a>, that builds on top of a paper called <a href="https://arxiv.org/abs/2506.20639">DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation</a>, released just last month.</p>



<p>The paper describes a model that takes a diffusion-first approach to code generation, but with a twist:</p>



<blockquote>
<p>“When the sampling temperature is increased from the default 0.2 to 1.2, DiffuCoder becomes more flexible in its token generation order, freeing itself from strict left-to-right constraints”</p>
</blockquote>



<p>This means that by adjusting the temperature, it can also behave either more (or less) like an autoregressive model. In essence, Higher temperatures give it more flexibility to generate tokens out of order, while lower temperatures keep it closer to a strict left-to-right decoding. </p>



<p>And with an extra training step called coupled-GRPO, it learned to generate higher-quality code with fewer passes. The result? Code that’s faster to generate, globally coherent, and competitive with some of the best open-source programming models out there.</p>



<figure><img loading="lazy" decoding="async" height="379" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg 1661w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=155,57 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=655,243 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=768,284 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=1024,379 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=1536,569 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=350,130 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=140,52 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=1600,592 1600w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder.jpg?resize=150,56 150w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption>From the <a href="https://arxiv.org/html/2506.20639v2">study</a>: “(a) A real example of DiffuCoder-Instruct’s decoding process with sampling temperature 1.2. (b) Results on coding benchmarks. (c) When decoding steps are halved, DiffuCoder-Instruct trained with coupled-GRPO experiences a smaller performance drop, compared to Instruct itself.”</figcaption></figure>



<h2 id="h-built-on-top-of-an-open-source-llm-by-alibaba">Built on top of an open-source LLM by Alibaba</h2>



<p>Even more interestingly, Apple’s model is built on top of Qwen2.5‑7B, an open-source foundation model from Alibaba. Alibaba first fine-tuned that model for better code generation (as Qwen2.5‑Coder‑7B), then Apple took it and made its own adjustments.</p>



<p>They turned it into a new model with a diffusion-based decoder, as described in the DiffuCoder paper, and then adjusted it again to better follow instructions. Once that was done, they trained yet another version of it using more than 20,000 carefully picked coding examples.</p>



<figure><img loading="lazy" decoding="async" height="335" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg 2276w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=155,51 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=655,214 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=768,251 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=1024,335 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=1536,503 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=2048,670 2048w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=350,115 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=140,46 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=1600,524 1600w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/model-tree-diffu-coder.jpg?resize=150,49 150w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/></figure>



<p>And all this work paid off. <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">DiffuCoder-7B-cpGRPO</a> got a 4.4% boost on a popular coding benchmark, and it maintained its lower dependency on generating code strictly from left to right.</p>



<p>Of course, there is plenty of room for improvement. Although DiffuCoder did better than many diffusion-based coding models (and that was before the 4.4% bump from <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">DiffuCoder-7B-cpGRPO</a>), it still doesn’t quite reach the level of GPT-4 or Gemini Diffusion.</p>



<figure><img loading="lazy" decoding="async" height="720" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg 1668w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=155,109 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=655,460 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=768,540 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=1024,720 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=1536,1079 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=350,246 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=140,98 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=1423,1000 1423w, https://9to5mac.com/wp-content/uploads/sites/6/2025/07/diffu-coder-benchmark.jpg?resize=150,105 150w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/></figure>



<p>And while some have pointed out that 7 billion parameters might be limiting, or that its diffusion-based generation still resembles a sequential process, the bigger point is this: little by little, Apple has been laying the groundwork for its generative AI efforts with some pretty interesting and novel ideas.</p>



<p>Whether (or if? When?) that will actually translate into real features and products for users and developers is another story.</p>



<h4>AirPods deals on Amazon</h4>



<ul>
<li><a href="https://www.amazon.com/Apple-Cancellation-Transparency-Personalized-High-Fidelity/dp/B0D1XD1ZV3/?tag=marcmendes-20">AirPods Pro 2, USB-C Charging</a>: 20% off at $199</li>



<li><a href="https://www.amazon.com/Apple-Generation-Bluetooth-Headphones-Personalized/dp/B0D1WXVQTN/?tag=marcmendes-20">AirPods (3rd Generation)</a>: 20% off, at $134.99</li>



<li><a href="https://www.amazon.com/Apple-Headphones-Cancellation-Transparency-Personalized/dp/B0DGJ7HYG1/?tag=marcmendes-20">AirPods 4, USB-C and Wireless Charging</a>: 17% off at $148.99</li>



<li><a href="https://www.amazon.com/Apple-Bluetooth-Headphones-Personalized-Effortless/dp/B0DGHMNQ5Z/?tag=marcmendes-20">AirPods 4 USB-C Charging</a>: 8% off at $119</li>



<li><a href="https://www.amazon.com/Apple-Headphones-Cancellation-Transparency-Personalized/dp/B0DGJC52FP/?tag=marcmendes-20">AirPods Max Wireless, USB-C Charging, Midnight</a>: 13% off at $479.99</li>
</ul>
	
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>
  </body>
</html>
