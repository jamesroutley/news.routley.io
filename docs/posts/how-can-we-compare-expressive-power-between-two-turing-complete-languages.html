<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://langdev.stackexchange.com/questions/2015/how-can-we-compare-expressive-power-between-two-turing-complete-languages">Original</a>
    <h1>How can we compare expressive power between two Turing-complete languages?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="text">
<p>Surprisingly <strong>yes</strong>, this is possible!</p>
<p>This is actually pretty important for people that work on optimizing compilers. If I add this new feature, will it break any existing optimization pass? I will show why this is a concern later in the answer.</p>
<p>And this is good since all of us are interested in programming languages. Surely we should have at least one clear-cut way to distinguish between them, beyond the names of keywords, etc! Most people would rather write a large system in <em>[insert your favorite language here]</em> than, say, <a href="https://en.wikipedia.org/wiki/Befunge" rel="noreferrer">Befunge</a> or <a href="https://en.wikipedia.org/wiki/INTERCAL" rel="noreferrer">INTERCAL</a>. But those languages <em>are</em> Turing-complete.</p>
<p>So, what&#39;s going on here?</p>
<p>Not only that, the concept we need here has significance in formal semantics beyond this question. I&#39;ll briefly mention this at the end of the answer.</p>
<p>Can you ever distinguish between <code>2 * 3</code> and <code>3 + 3</code> in a programming language? Are you <em>sure</em>? Are there any &#34;reasonable&#34; languages in which you can distinguish between these? What, exactly, would it mean to be able to distinguish between them and how can we give a definition for &#34;this language distinguishes between these things?&#34; Read on to find out more!</p>
<p>The concept we need is called &#34;observational equivalence.&#34;</p>
<p>A roadmap:</p>
<ul>
<li>First I&#39;ll give an intuitive description of how you could understand the statement <em>&#34;feature X adds expressive power to language L&#34;</em>.</li>
<li>Next, I&#39;ll need to talk about programs that have a hole in them. These are called <em>&#34;one-hole contexts&#34;</em>. Sometimes this is abbreviated to just <em>&#34;context.&#34;</em></li>
<li>Then I&#39;ll use one-hole contexts to define <em>&#34;observational equivalence.&#34;</em> This is one way to talk about certain programs being &#34;equivalent.&#34;</li>
<li>Finally, we will see that we can say adding feature X to language L makes the language <em>more expressive</em> if, by adding feature X, we end up with <em>fewer</em> observational equivalences in the resulting language L+X. That might sound backward. I&#39;ll get to this, though.</li>
</ul>
<p>The <strong>key idea</strong> is this: Consider taking a Turing-complete language L and adding feature X. Now think about how we could translate code written in L+X back into into L. If feature X makes the language &#34;more expressive,&#34; then this transformation will require you to apply a large-scale, <em>&#34;global&#34;</em> transformation. On the other hand, if language L and L+X are &#34;equally expressive,&#34; then L+X can be transformed into L using only a <em>&#34;local&#34;</em> transformation.</p>

<p>I will state upfront that this answer (and the way I framed the original question) is inspired by <a href="https://www.youtube.com/watch?v=43XaZEn2aLc" rel="noreferrer">Shriram Krishnamurthi&#39;s excellent and approachable 2019 talk</a> about Matthias Felleisen&#39;s paper &#34;On the Expressive Power of Programming Languages.&#34; Anyone who is interested in this question should absolutely watch it. The corresponding paper is <a href="https://www.sciencedirect.com/science/article/pii/016764239190036W" rel="noreferrer">here</a>.</p>
<p>I actually think that talk would be interesting to everyone here, in fact. There are many questions that have variations on &#34;... what if I add feature X to a language ...&#34; and this talk gives a way to understand one aspect of that kind of question!</p>
<p>Incidentally, I <em>will</em> be giving spoilers for the talk in this answer!</p>

<p>Let&#39;s say we start with a language that only has functions, conditionals, integer literals, addition, subtraction, and multiplication. This is Turing-complete if we allow recursion. Let&#39;s also say that functions are first-class. This won&#39;t come up right now, though.</p>
<p>If we add, say, a unary negation operator to our language, this does not intuitively &#34;increase expressive power.&#34; However, if we add <em>exceptions</em> to the language, well, that <em>does</em> seem to intuitively &#34;increase expressive power.&#34;</p>
<p>Why? Well, for the first feature, whenever we see a unary negation <code>-x</code> we can just translate it, right then and there, into <code>0 - x</code>. <em>However</em>, for the second feature, when we see an exception being thrown or a <code>try-catch</code> block, then we actually have to do a large scale transformation of the program.</p>
<p>I chose exceptions since they are of greater interest, but let&#39;s consider a simpler example of a feature that &#34;adds expressiveness.&#34; How about a keyword <code>halt</code> that immediately terminates the program? You certainly cannot implement this as a <em>local</em> transformation to our language! You actually have to apply a transformation that starts at <em>the beginning of the program</em>!</p>
<p>With the negation feature, we only had to transform the exact part of the code where the unary negation is used. For the <code>halt</code> feature, we had to transform the code far beyond where that keyword is used.</p>
<p>This distinction between &#34;feature only requiring local transformation&#34; and &#34;feature requiring global transformation&#34; is what we want to formalize.</p>
<p>We can get closer to a formal statement by saying: a feature does not &#34;add expressive power&#34; if we can implement it as a <em>macro</em> that turns it into something in the original language. Even if the language doesn&#39;t have macros, you could imagine using some kind of preprocessor to implement a local transformation as a kind of macro.</p>
<p>This is not <em>quite</em> a formal description yet, but we&#39;re getting there! For one thing, how do we <em>prove that a macro cannot exist</em> for some feature? To do this, we still need a formal description of the problem.</p>

<p>First, we need a way to compare programs for equality.</p>
<p>You might wonder: why not just use the equality built in to the language? Well, there are a few reasons:</p>
<ul>
<li>The equality operation might not cover everything. For example, it&#39;s actually impossible to compare arbitrary functions for equality in a Turing-complete programming language (in a way that is always correct and always halts).</li>
<li>The language might not even <em>have</em> an equality operation, even though it&#39;s Turing-complete. This is the case for many esoteric languages, like FRACTRAN.</li>
</ul>
<p>So we really want something that&#39;s somehow <em>&#34;more fundamental&#34;</em> than that and more broadly applicable. We actually <em>do</em> want something that&#39;s <em>inside</em> the language that can distinguish between two things, though. But how do we do this?</p>
<p>What it really boils down to is this: given two things in our language <code>x</code> and <code>y</code>, is there <em>any</em> way to write a program in our language that behaves differently if you used <code>x</code> vs if you used <code>y</code>?</p>
<p>A specific question: Is it possible to distinguish between <code>2 * 3</code> and <code>3 + 3</code>? I will return to this particular question in the <em>Expressiveness</em> section.</p>
<p>Formalizing all this is where we get observational equivalence.</p>
<p>But first, we need to talk about what happens when you take a program and cut a hole out of it.</p>

<p>Imagine you take a valid program in your language and print it out. Then you physically cut out exactly one subterm and throw it away. What you have left is a &#34;program with a hole in it,&#34; or a printout of a &#34;one-hole context&#34; (sometimes just called &#34;a context&#34;).</p>
<p>If you take a slip of paper, write a term on it, and tape it into the hole you now have a program again (as long as the result of this process is well-typed). This is the primary thing you can <em>do</em> with a one-hole context: You can obtain a program by combining it with a term that can fill in the hole.</p>
<p>If we call our context <code>C</code> and the new term we&#39;re taping into it <code>t</code> then the complete program we obtain when we tape <code>t</code> into <code>C</code> is called <code>C[t]</code>.</p>
<p>Note that this definition actually always makes sense no matter what programming language we are looking at! I&#39;ve made <em>no</em> assumptions about the language.</p>
<p>Our definition of observational equivalence will center around these contexts (that is, programs with exactly one hole in them).</p>

<p>One way to define what it means for two programs to be &#34;equivalent&#34; is that every observation you can make about them is the same. There is actually a decent amount of nuance to <em>&#34;what counts as an observation?&#34;</em> but that&#39;s outside the scope of this answer.</p>
<p>We will define observational equivalence like this (<em>first attempt</em>):</p>
<ul>
<li>Two expressions e<sub>1</sub> and e<sub>2</sub> are called &#34;observationally equivalent&#34; if, for <em>every</em> context C, we have C[e<sub>1</sub>] = C[e<sub>2</sub>]</li>
</ul>
<p>This is <em>the same</em> as saying, given those two expressions, does the language provide you a way to tell them apart! It&#39;s asking &#34;Are the two expressions identical when plugged into any context?&#34;</p>
<p><em>&#34;Uh, wait a minute...&#34;</em> I hear you say. <em>&#34;But there&#39;s still an equals sign! What does that mean? The whole point was to <em>avoid</em> using an existing notion of equality!&#34;</em></p>
<p>That is very true! We need to improve our definition. We need to be a bit more clever (this new definition is due to James Morris&#39;s 1969 PhD thesis):</p>
<blockquote>
<p>Two expressions e<sub>1</sub> and e<sub>2</sub> are called &#34;observationally equivalent&#34; if, for <em>every</em> context C, we have: C[e<sub>1</sub>] halts if and only if C[e<sub>2</sub>] halts</p>
</blockquote>
<p>This might seem a bit weird. Think about this for a minute. Does this seem, somehow, wrong?</p>
<p>Take a moment to consider this question: &#34;Are we saying that 1 and 2 are &#39;observationally equivalent&#39;? Both 1 and 2 very straightforwardly terminate!&#34; (I&#39;ve taken this from <a href="https://youtu.be/43XaZEn2aLc?t=1575" rel="noreferrer">this part of Shriram&#39;s talk</a>. Spoilers for the talk ahead!)</p>
<p>I am <em>not</em> saying they are observationally equivalent! An example: Can you write a Python program with one hole in it that will halt if the hole is filled with <code>1</code> but will loop forever if it is filled with <code>2</code> (you could just write <code>&lt;hole&gt;</code> for the hole and fill it in as appropriate)? If so, you&#39;ve proven that <code>1</code> and <code>2</code> are observationally <em>distinct</em> in Python! To show that they are <em>distinct</em>, all you have to do is find <em>one</em> context <code>C</code> where <code>C[1]</code> halts but <code>C[2]</code> does not (or visa-versa). If they were <em>the same</em> then every context would behave the same (with regard to halting) regardless of whether you plugged in <code>1</code> or <code>2</code>.</p>
<p>What if we only have a <code>isZero(x)</code> builtin function, but no builtin equality operation? Can we still tell <code>1</code> apart from <code>2</code>? Well, how about the context <code>while (isZero(1 - &lt;hole&gt;)) { }</code>? This is why the definition works well: we need to consider <em>all possible contexts</em>!</p>
<p>Okay, but what if there is <em>actually</em> no way to tell <code>1</code> and <code>2</code> apart? Then we would actually say that <em>are</em> observationally equivalent! Observational equivalence captures the idea of what it means for two things to be indistinguishable inside a programming language.</p>

<p>Now how does all of this relate to expressiveness? I&#39;m going to start by way of example. I&#39;ll return to the question: <em>Is it possible to distinguish between <code>2 * 3</code> and <code>3 + 3</code></em>?</p>
<p>My answer: It depends on the features of the language! It certainly is not possible in the language which only has basic arithmetic, functions and recursion. Can you think of a feature we could add where it <em>is</em> possible to distinguish them?</p>
<p>Operator overloading! Say we have operator overloading and the ability to redefine existing function. If we overload <code>*</code> to do something weird, like return the first argument but we don&#39;t overload <code>+</code>. We can now distinguish between those two expressions!</p>
<p>By adding that feature, we <em>broke</em> an observational equivalence. The expressions <code>2 * 3</code> and <code>3 + 3</code> <em>used to be</em> observationally equivalent. Then we added operator overloading and now they are <em>observationally distinct</em>.</p>
<p>Now we need to address how to tell if a feature requires a &#34;local&#34; transformation vs &#34;global&#34; transformation.</p>
<h2>The key theorem</h2>
<blockquote>
<p>If feature X can be implemented for language L as a local transformation to obtain the language L+X, then for any two expressions e<sub>1</sub> and e<sub>2</sub> that are observationally equivalent in L, it is also the case that they are observationally equivalent in L+X</p>
</blockquote>
<p>The theorem is proven in <a href="https://www.sciencedirect.com/science/article/pii/016764239190036W" rel="noreferrer">the paper</a>.</p>
<p>This is saying that if feature X only required a local transformation to implement, then it did not &#34;break&#34; any observational equivalences. All of the observational equivalences from L are still true in L+X.</p>
<p>Note that this was <em>not</em> the case for operator overloading. Adding operator overloading <em>did</em> break some observational equivalences. On the other hand, when we added unary negation we <em>did not</em> break any observational equivalences.</p>
<p>Now we can say that when we <em>add</em> expressiveness to a language, we <em>break</em> some observational equivalences.</p>
<p>One practical implication of this is that some optimization passes might be broken when you add a new feature. This is because optimizations assume that certain things are identical. But when you add a new &#34;expressive&#34; feature, you will break some of those equivalences!</p>
<p><em>Exercise for the reader</em>: I mentioned adding <code>halt</code> to a simple language and I said that this is an <em>expressive</em> new feature for that language. Can you give an example of an observational equivalence that holds in the original language, but not the new language with <code>halt</code>?</p>

<p>Even though this is just a small part of the answer that is only tangentially relevant to my question, this is what motivated me to write the question and this answer. Particularly, to partially clear up some confusion about denotational semantics <a href="https://langdev.stackexchange.com/questions/1953/how-can-i-understand-a-recursive-function-in-terms-of-denotational-semantics">from the comments of my previous question and answer</a>. This is only one component of that, but it is an important one.</p>
<p>Up until now, we see one useful application of observation equivalence. This allowed me to define it and motivate it. Now we can see, briefly, another application of observational equivalence that is relevant to defining a denotational semantics. It would really be a different answer to a different question to address this in more detail, however, so I will gloss over some things.</p>
<p>There are two very crucial properties you want from your denotation function when you create a denotational semantics. One is called &#34;compositionality&#34; and the other is called &#34;adequacy.&#34; &#34;Adequacy&#34; is defined using observational equivalence. Observational equivalence is derived from an operational semantics.</p>
<ul>
<li>&#34;Adequacy&#34;: If two programs are <em>observationally distinct</em>, then they must have <em>distinct denotations</em>.</li>
</ul>
<p>Consider what it would be like if our denotation function was not &#34;adequate.&#34; We would have two programs that we can observe are different, but they would be mapped to the same mathematical object. That&#39;s not very useful way to denote programs!</p>

<h2>Papers</h2>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/016764239190036W" rel="noreferrer"><em>On the expressive power of programming languages</em></a> by Matthias Felleisen. This paper introduced the formal notion of &#34;expressiveness&#34; I&#39;ve described above.</li>
<li><a href="https://dspace.mit.edu/handle/1721.1/64850" rel="noreferrer"><em>Lambda-calculus models of programming languages</em></a>, James Morris&#39;s 1969 PhD thesis. This is the origin of the concept of &#34;observational equivalence&#34; (he called it &#34;extensional equivalence&#34;).</li>
</ul>
<h2>Books</h2>
<ul>
<li><em>Types and Programming Languages</em> by Benjamin Pierce</li>
<li><em>The Formal Semantics of Programming Languages: An Introduction</em> by Glynn Winskel</li>
<li><a href="https://plfa.github.io/ContextualEquivalence/" rel="noreferrer"><em>Programming Language Foundations in Agda: Contextual Equivalence</em></a> (&#34;contextual equivalence&#34; is another name for &#34;observational equivalence&#34;)</li>
<li><a href="https://softwarefoundations.cis.upenn.edu/plf-current/toc.html" rel="noreferrer"><em>Software Foundations, Vol 2: Programming Language Foundations</em> by Benjamin Pierce et al</a></li>
</ul>
    </div></div>
  </body>
</html>
