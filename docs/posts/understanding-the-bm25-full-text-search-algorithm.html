<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://emschwartz.me/understanding-the-bm25-full-text-search-algorithm/">Original</a>
    <h1>Understanding the BM25 full text search algorithm</h1>
    
    <div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2024-11-19T16:20Z">
                    Nov 19, 2024
                </time>
            </i>
        </p>
    

    <p>BM25, or Best Match 25, is a widely used algorithm for full text search. It is the default in Lucene/Elasticsearch and SQLite, among others. Recently, it has become common to combine full text search and vector similarity search into &#34;hybrid search&#34;. I wanted to understand how full text search works, and specifically BM25, so here is my attempt at understanding by re-explaining.</p>
<ol>
<li><a href="#motivation-can-bm25-scores-be-compared-across-queries">Motivation: can BM25 scores be compared across queries?</a></li>
<li><a href="#ranking-documents-probabilistically">Ranking documents probabilistically</a></li>
<li><a href="#components-of-bm25">Components of BM25</a></li>
<li><a href="#behold-math">Behold, Math!</a><ol>
<li><a href="#query-terms">Query terms</a></li>
<li><a href="#inverse-document-frequency-idf">Inverse Document Frequency (IDF)</a></li>
<li><a href="#term-frequency-in-the-document">Term frequency in the document</a></li>
<li><a href="#document-length-normalization">Document length normalization</a></li>
<li><a href="#putting-it-all-together">Putting it all together</a></li>
</ol>
</li>
<li><a href="#cleverness-of-bm25-and-its-precursors">Cleverness of BM25 and its precursors</a><ol>
<li><a href="#ranking-by-probability-without-calculating-probability">Ranking by probability without calculating probability</a></li>
<li><a href="#assuming-most-documents-are-irrelevant">Assuming most documents are irrelevant</a></li>
</ol>
</li>
<li><a href="#conclusion-bm25-scores-can-be-compared-within-the-same-collection">Conclusion: BM25 scores can be compared <em>within the same collection</em></a></li>
<li><a href="#further-reading">Further reading</a></li>
</ol>
<h2 id="motivation-can-bm25-scores-be-compared-across-queries">Motivation: can BM25 scores be compared across queries?</h2><p>For a quick bit of context on why I&#39;m thinking about search algorithms, I&#39;m building a <a href="https://scour.ing">personalized content feed</a> that scours noisy sources for content related to your interests. I started off using <a href="https://emschwartz.me/binary-vector-embeddings-are-so-cool/">vector similarity search</a> and wanted to also include full-text search to improve the handling of exact keywords (for example, a friend has &#34;Solid.js&#34; as an interest and using vector similarity search alone, that turns up more content related to React than Solid).</p>
<p>The question that motivated this deep dive into BM25 was: <strong>can I compare the BM25 scores of documents across multiple queries to determine which query the document best matches?</strong></p>
<p>Initially, both ChatGPT and Claude told me no ‚Äî though annoyingly, after doing this deep dive and formulating a more precise question, they both said yes ü§¶‚Äç‚ôÇÔ∏è. Anyway, let&#39;s get into the details of BM25 and then I&#39;ll share my conclusions about this question.</p>
<h2 id="ranking-documents-probabilistically">Ranking documents probabilistically</h2><p>At the most basic level, the goal of a full text search algorithm is to take a query and find the <em>most relevant</em> documents from a set of possibilities.</p>
<p>However, we don&#39;t <em>really</em> know which documents are &#34;relevant&#34;, so the best we can do is guess. Specifically, we can rank documents based on the <em>probability</em> that they are relevant to the query. (This is called <em>The Probability Ranking Principle</em>.)</p>
<p>How do we calculate the probability that a document is relevant?</p>
<p>For full text or <em>lexical</em> search, we are only going to use qualities of the search query and each of the documents in our collection. (In contrast, vector similarity search might use an embedding model trained on an external corpus of text to represent the meaning or <em>semantics</em> of the query and document.)</p>
<h2 id="components-of-bm25">Components of BM25</h2><p>BM25 uses a couple of different components of the query and the set of documents:</p>
<ul>
<li><strong>Query terms</strong>: if a search query is made up of multiple terms, BM25 will calculate a separate score for each term and then sum them up.</li>
<li><strong>Inverse Document Frequency (IDF)</strong>: how rare is a given search term across the entire document collection? We assume that common words (such as &#34;the&#34; or &#34;and&#34;) are less informative than rare words. Therefore, we want to boost the importance of rare words.</li>
<li><strong>Term frequency in the document</strong>: how many times does a search term appear in a given document? We assume that more repetition of a query term in a given document increases the likelihood that that document is related to the term. However, BM25 also adjusts this so that there are diminishing returns each time a term is repeated.</li>
<li><strong>Document length</strong>: how long is the given document compared to others? Long documents might repeat the search term more, just by virtue of being longer. We don&#39;t want to unfairly boost long documents, so BM25 applies some normalization based on how the document&#39;s length compares to the average.</li>
</ul>
<p>These four components are what make up BM25. Now, let&#39;s look at exactly how they&#39;re used.</p>
<h2 id="behold-math">Behold, math!</h2><p>The BM25 algorithm might look scary to non-mathematicians (my eyes glazed over the first time I saw it), but I promise, it&#39;s not too hard to understand!</p>
<p>Here is the full equation:</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mtext>score</mtext><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>ln</mi><mrow><mo stretchy="true" fence="true" form="prefix">(</mo><mfrac><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow></mfrac><mo>+</mo><mn>1</mn><mo stretchy="true" fence="true" form="postfix">)</mo></mrow><mi>¬∑</mi><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mi>¬∑</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>k</mi><mn>1</mn></msub><mi>¬∑</mi><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><mi>b</mi><mo>+</mo><mi>b</mi><mi>¬∑</mi><mfrac><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow><mrow><mtext>avgdl</mtext></mrow></mfrac><mo stretchy="false">)</mo></mrow></mfrac></mrow></math><p>Now, let&#39;s go through it piece-by-piece.</p>
<h3 id="query-terms">Query terms</h3><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mtext>score</mtext><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>.</mo><mo>.</mo><mo>.</mo></mrow></math><ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>D</mi></mrow></math> is a given document</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Q</mi></mrow></math> is the full query, potentially composed of multiple query terms</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>n</mi></mrow></math> is the number of query terms</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow></math> is each of the query terms</li>
</ul>
<p>This part of the equation says: given a document and a query, sum up the scores for each of the query terms.</p>
<p>Now, let&#39;s dig into how we calculate the score for each of the query terms.</p>
<h3 id="inverse-document-frequency-idf">Inverse Document Frequency (IDF)</h3><p>The first component of the score calculates how rare the query term is within the whole collection of documents using the Inverse Document Frequency (IDF).</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi>ln</mi><mrow><mo stretchy="true" fence="true" form="prefix">(</mo><mfrac><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow></mfrac><mo>+</mo><mn>1</mn><mo stretchy="true" fence="true" form="postfix">)</mo></mrow></mrow></math><p>The key elements to focus on in this equation are:</p>
<ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi></mrow></math> is the total number of documents in our collection</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math> is the number of documents that contain the query term</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math> therefore is the number of documents that <em>do not</em> contain the query term</li>
</ul>
<p>In simple language, this part boils down to the following: common terms will appear in many documents. If the term appears in many documents, we will have a small number (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math>, or the number of documents that <em>do not</em> have the term) divided by <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi></mrow></math>. As a result, common terms will have a small effect on the score.</p>
<p>In contrast, rare terms will appear in few documents so <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math> will be small and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math> will be large. Therefore, rare terms will have a greater impact on the score.</p>
<p>The constants <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0.5</mn></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>1</mn></mrow></math> are there to smooth out the equation and ensure that we don&#39;t end up with wildly varying results if the term is either very rare or very common.</p>
<h3 id="term-frequency-in-the-document">Term frequency in the document</h3><p>In the previous step, we looked at how rare the term is across the whole set of documents. Now, let&#39;s look at how frequent the given query is in the given document.</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>k</mi><mn>1</mn></msub></mrow></mfrac></mrow></math><p>The terms in this equation are:</p>
<ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow></math> is a given query</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>D</mi></mrow></math> is a given document</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></math> is the frequency of the given query in the given document</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>k</mi><mn>1</mn></msub></mrow></math> is a tuning parameter that is generally set between <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>1.2</mn></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>2</mn></mrow></math></li>
</ul>
<p>This equation takes the term frequency within the document into effect, but ensures that term repetition has diminishing returns. The intuition here is that, at some point, the document is probably related to the query term and we don&#39;t want an infinite amount of repetition to be weighted too heavily in the score.</p>
<p>The <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>k</mi><mn>1</mn></msub></mrow></math> parameter controls how quickly the returns to term repetition diminish. You can see how the slope changes based on this setting:</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/emschwartz/50-pm.webp" alt="Effect of the k parameter"/></p>
<blockquote>
<p>From <a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf">The Probabilistic Relevance Framework: BM25 and Beyond</a></p>
</blockquote>
<h3 id="document-length-normalization">Document length normalization</h3><p>The last thing we need is to compare the length of the given document to the lengths of the other documents in the collection.</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><mi>b</mi><mo>+</mo><mi>b</mi><mi>¬∑</mi><mfrac><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow><mrow><mtext>avgdl</mtext></mrow></mfrac><mo stretchy="false">)</mo></mrow></math><p>From right to left this time, the parameters are:</p>
<ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow></math> is the length of the given document</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>a</mi><mi>v</mi><mi>g</mi><mi>d</mi><mi>l</mi></mrow></math> is the average document length in our collection</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>b</mi></mrow></math> is another tuning parameter that controls how much we normalize by the document length</li>
</ul>
<p>Long documents are likely to contain the search term more frequently, just by virtue of being longer. Since we don&#39;t want to unfairly boost long documents, this whole term is going to go in the denominator of our final equation. That is, a document that is longer than average (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mfrac><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow><mrow><mi>a</mi><mi>v</mi><mi>g</mi><mi>d</mi><mi>l</mi></mrow></mfrac><mo>&gt;</mo><mn>1</mn></mrow></math>) will be penalized by this adjustment.</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>b</mi></mrow></math> can be adjusted by the user. Setting <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>b</mi><mo>=</mo><mn>0</mn></mrow></math> turns off document length normalization, while setting <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow></math> applies it fully. It is normally set to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0.75</mn></mrow></math>.</p>
<h3 id="putting-it-all-together">Putting it all together</h3><p>If we take all of the components we&#39;ve just discussed and put them together, we arrive back at the full BM25 equation:</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><munder><munder><mrow><mtext>score</mtext><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow><mo>‚èü</mo></munder><mrow><mtext>Summing¬†each¬†query¬†term&#39;s¬†score</mtext></mrow></munder><munder><munder><mrow><mi>ln</mi><mrow><mo stretchy="true" fence="true" form="prefix">(</mo><mfrac><mrow><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.5</mn></mrow></mfrac><mo>+</mo><mn>1</mn><mo stretchy="true" fence="true" form="postfix">)</mo></mrow></mrow><mo>‚èü</mo></munder><mrow><mtext>Inverse¬†Document¬†Frequency</mtext></mrow></munder><mi>¬∑</mi><mover><mover><mrow><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mi>¬∑</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>k</mi><mn>1</mn></msub><mi>¬∑</mi><munder><munder><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><mi>b</mi><mo>+</mo><mi>b</mi><mi>¬∑</mi><mfrac><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow><mrow><mtext>avgdl</mtext></mrow></mfrac><mo stretchy="false">)</mo></mrow><mo>‚èü</mo></munder><mrow><mtext>Document¬†length¬†normalization</mtext></mrow></munder></mrow></mfrac></mrow><mo>‚èû</mo></mover><mrow><mtext>Term¬†frequency¬†in¬†the¬†document</mtext></mrow></mover></mrow></math><p>Reading from left to right, you can see that we are summing up the scores for each query term. For each, we are taking the Inverse Document Frequency, multiplying it by the term frequency in the document (with diminishing returns), and then normalizing by the document length.</p>
<h2 id="cleverness-of-bm25-and-its-precursors">Cleverness of BM25 and its precursors</h2><p>We&#39;ve just gone through the components of the BM25 equation, but I think it&#39;s worth pausing to emphasize two of its most ingenious aspects.</p>
<h3 id="ranking-by-probability-without-calculating-probability">Ranking by probability without calculating probability</h3><p>As mentioned earlier, BM25 is based on an idea called the Probability Ranking Principle. In short, it says:</p>
<blockquote>
<p>If retrieved documents are ordered by decreasing probability of relevance on the data available, then the system‚Äôs effectiveness is the best that can be obtained for the data.</p>
<ul>
<li><a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf">The Probabilistic Relevance Framework: BM25 and Beyond</a></li>
</ul>
</blockquote>
<p>Unfortunately, calculating the &#34;true&#34; probability that a document is relevant to a query is nearly impossible.</p>
<p>However, we really care about the <em>order</em> of the documents more than we care about the exact probability. Because of this, researchers realized that you could simplify the equations and make it practicable. Specifically, you could drop terms from the equation that would be required to calculate the full probability but where leaving them out would not affect the <em>order</em>.</p>
<p>Even though we are using the Probability Ranking Principle, we are actually calculating a &#34;weight&#34; instead of a probability.</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi>W</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>‚àë</mo><mrow><mstyle scriptlevel="1"><mtable><mtr><mtd><mi>t</mi><mo>‚àà</mo><mi>q</mi><mo>,</mo></mtd></mtr><mtr><mtd><msub><mi>f</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>&gt;</mo><mn>0</mn></mtd></mtr></mtable></mstyle></mrow></msub><mi>log</mi><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>F</mi><mo>=</mo><msub><mi>f</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub><mo stretchy="false">|</mo><mi>R</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>P</mi><mo stretchy="false">(</mo><mi>F</mi><mo>=</mo><mn>0</mn><mo stretchy="false">|</mo><mi>R</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>F</mi><mo>=</mo><msub><mi>f</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub><mo stretchy="false">|</mo><mi>R</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>P</mi><mo stretchy="false">(</mo><mi>F</mi><mo>=</mo><mn>0</mn><mo stretchy="false">|</mo><mi>R</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></math><p>This equation calculates the weight using term frequencies. Specifically:</p>
<ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>W</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></math> is the weight for a given document</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>F</mi><mo>=</mo><msub><mi>f</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub><mo stretchy="false">|</mo><mi>R</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math> is the probability that the query term would appear in the document with a given frequency (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>f</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub></mrow></math>) if the document is relevant (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>R</mi><mo>=</mo><mn>1</mn></mrow></math>)</li>
</ul>
<p>The various terms boil down to the probability that we would see a certain query term frequency within the document if the document is relevant or not relevant, and the probabilities that the term would not appear at all if the document is relevant or not.</p>
<p>The Robertson/Sparck Jones Weight is a way of estimating these probabilities but only using the counts of different sets of documents:</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><msup><mi>w</mi><mrow><mi>R</mi><mi>S</mi><mi>J</mi></mrow></msup><mo>=</mo><mi>log</mi><mfrac><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>N</mi><mo>‚àí</mo><mi>R</mi><mo>‚àí</mo><mi>n</mi><mo>+</mo><mi>r</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>n</mi><mo>‚àí</mo><mi>r</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>R</mi><mo>‚àí</mo><mi>r</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></math><p>The terms here are:</p>
<ul>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi></mrow></math> is the number of relevant documents that contain the query term</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>N</mi></mrow></math> is the total number of documents in the collection</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>R</mi></mrow></math> is the number of relevant documents in the collection</li>
<li><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>n</mi></mrow></math> is the number of documents that contain the query term</li>
</ul>
<p>The big, glaring problem with this equation is that you first need to know which documents are relevant to the query. How are we going to get those?</p>
<h3 id="assuming-most-documents-are-irrelevant">Assuming most documents are irrelevant</h3><p>The question about how to make use of the Robertson/Sparck Joes weight apparently stumped the entire research field for about 15 years. The equation was built up from a solid theoretical foundation, but relying on already having relevance information made it nearly impossible to put to use.</p>
<p>The BM25 developers made a very clever assumption to get to the next step.</p>
<p>For any given query, we can assume that most documents are not going to be relevant. If we assume that the number of relevant documents is so small as to be negligible, we can just set those numbers to zero!</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi>R</mi><mo>=</mo><mi>r</mi><mo>=</mo><mn>0</mn></mrow></math><p>If we substitute this into the Robertson/Sparck Jones Weight equation, we get nearly the IDF term used in BM25:</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi>log</mi><mfrac><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>N</mi><mo>‚àí</mo><mn>0</mn><mo>‚àí</mo><mi>n</mi><mo>+</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>n</mi><mo>‚àí</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>0</mn><mo>‚àí</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>log</mi><mfrac><mrow><mn>0.5</mn><mo stretchy="false">(</mo><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo><mn>0.5</mn></mrow></mfrac><mo>=</mo><mi>log</mi><mfrac><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>‚àí</mo><mi>n</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></math><p>Not relying on relevance information made BM25 much more useful, while keeping the same theoretical underpinnings. Victor Lavrenko described this as a <a href="https://youtu.be/_UxUZvPfEKo?si=QF7YRldXUcRuhh78">&#34;very impressive leap of faith&#34;</a>, and I think this is quite a neat bit of BM25&#39;s backstory.</p>
<h2 id="conclusion-bm25-scores-can-be-compared-emwithin-the-same-collectionem">Conclusion: BM25 scores can be compared <em>within the same collection</em></h2><p>As I mentioned at the start, my motivating question was whether I could compare BM25 scores for a document across queries to understand which query the document best matches.</p>
<p>In general, BM25 scores cannot be directly compared (and this is what ChatGPT and Claude stressed to me in response to my initial inquiries üôÇ‚Äç‚ÜîÔ∏è). The algorithm does not produce a score from 0 to 1 that is easy to compare across systems, and it doesn&#39;t even try to estimate the probability that a document is relevant. It only focuses on ranking documents within a certain collection in an order that approximates the probability of their relevance to the query. A higher BM25 score means the document is likely to be <em>more relevant</em>, but it isn&#39;t the actual probability that it is relevant.</p>
<p>As far as I understand now, it is possible to compare the BM25 scores across queries <em>for the same document within the same collection of documents</em>.</p>
<p>My hint that this was the case was the fact that BM25 sums the scores of each query term. There should not be a semantic difference between comparing the scores for two query term and two whole queries.</p>
<p>The important caveat to stress, however, is the <em>same document within the same collection</em>. BM25 uses the IDF or rarity of terms as well as the average document length within the collection. Therefore, you cannot necessarily compare scores across time because any modifications to the overall collection could change the scores.</p>
<p>For my purposes, though, this is useful enough. It means that I can do a full text search for each of a user&#39;s interests in my collection of content and compare the BM25 scores to help determine which pieces best match their interests.</p>
<p>I&#39;ll write more about ranking algorithms and how I&#39;m using the relevance scores in future posts, but in the meantime I hope you&#39;ve found this background on BM25 useful or interesting!</p>
<p><em>Thanks to Alex Kesling and Natan Last for feedback on drafts of this post.</em></p>
<h2 id="further-reading">Further reading</h2><p>If you are interested in diving further into the theory and history of BM25, I would highly recommend watching Elastic engineer Britta Weber&#39;s 2016 talk <a href="https://www.elastic.co/elasticon/conf/2016/sf/improved-text-scoring-with-bm25">Improved Text Scoring with BM25</a> and reading <a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf">The Probabilistic Relevance Framework: BM25 and Beyond</a> by Stephen Robertson and Hugo Zaragoza.</p>
<p>Also, I had initially included comparisons between BM25 and some other algorithms in this post. But, as you know, it was already a bit long üòÖ. So, you can now find those in this other post: <a href="https://punchagan.muse-amuse.in/comparing-full-text-search-algorithms-bm25-tf-idf-and-postgres">Comparing full text search algorithms: BM25, TF-IDF, and Postgres</a>.</p>
<hr/>
<p>Discuss on <a href="https://lobste.rs/s/ovbb1u/understanding_bm25_full_text_search">Lobsters</a> and <a href="https://news.ycombinator.com/item?id=42185233">Hacker News</a>.</p>


    

    
        
            <p>
                
                    <a href="https://punchagan.muse-amuse.in/blog/?q=scour">#scour</a>
                
                    <a href="https://punchagan.muse-amuse.in/blog/?q=search">#search</a>
                
                    <a href="https://punchagan.muse-amuse.in/blog/?q=understanding">#understanding</a>
                
            </p>
        

        
            


        
    


  </div></div>
  </body>
</html>
