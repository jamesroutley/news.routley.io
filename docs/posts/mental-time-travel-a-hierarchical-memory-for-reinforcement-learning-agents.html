<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2105.14039">Original</a>
    <h1>Mental time travel: a hierarchical memory for reinforcement learning agents</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2105.14039">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Reinforcement learning agents often forget details of the past, especially
after delays or distractor tasks. Agents with common memory architectures
struggle to recall and integrate across multiple timesteps of a past event, or
even to recall the details of a single timestep that is followed by distractor
tasks. To address these limitations, we propose a Hierarchical Chunk Attention
Memory (HCAM), which helps agents to remember the past in detail. HCAM stores
memories by dividing the past into chunks, and recalls by first performing
high-level attention over coarse summaries of the chunks, and then performing
detailed attention within only the most relevant chunks. An agent with HCAM can
therefore &#34;mentally time-travel&#34; -- remember past events in detail without
attending to all intervening events. We show that agents with HCAM
substantially outperform agents with other memory architectures at tasks
requiring long-term recall, retention, or reasoning over memory. These include
recalling where an object is hidden in a 3D environment, rapidly learning to
navigate efficiently in a new neighborhood, and rapidly learning and retaining
new object names. Agents with HCAM can extrapolate to task sequences much
longer than they were trained on, and can even generalize zero-shot from a
meta-learning setting to maintaining knowledge across episodes. HCAM improves
agent sample efficiency, generalization, and generality (by solving tasks that
previously required specialized architectures). Our work is a step towards
agents that can learn, interact, and adapt in complex and temporally-extended
environments.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Andrew Lampinen [<a href="https://arxiv.org/show-email/28e3082e/2105.14039">view email</a>]
      </p></div></div>
  </body>
</html>
