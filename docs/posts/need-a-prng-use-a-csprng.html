<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sortingsearching.com/2023/11/25/random.html">Original</a>
    <h1>Need a PRNG? Use a CSPRNG</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is about <a href="https://en.wikipedia.org/wiki/Random_number_generation">Random Number Generators</a>, RNGs for short.</p>

<p>We often want computers to behave randomly, for various reasons:</p>

<ul>
  <li><strong>Cryptography.</strong> Encryption keys need to be random to prevent attackers from guessing them.</li>
  <li><strong>Monte Carlo simulations.</strong> We want to calculate the statistics of some random phenomenon by random sampling.</li>
  <li><a href="https://en.wikipedia.org/wiki/Monte_Carlo_algorithm"><strong>Monte Carlo algorithms.</strong></a> Certain computational problems are easier to solve with high probability using randomness than deterministically with certainty. <a href="https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test">Primality testing</a> is an example.</li>
  <li><a href="https://en.wikipedia.org/wiki/Las_Vegas_algorithm"><strong>Las Vegas algorithms.</strong></a> These always produce the correct answer, but their efficiency depends on using randomness. <a href="https://en.wikipedia.org/wiki/Quicksort">Quicksort</a> is an example.</li>
  <li><strong>Machine learning.</strong> Neural network weights are initialized randomly, training uses random sampling.</li>
  <li><strong>Games with randomness.</strong> An online backgammon server needs random dice.</li>
  <li><strong>Video games.</strong> We want certain elements of the game to behave randomly.</li>
  <li><strong>Art.</strong> Predictable patterns are boring.</li>
</ul>

<p>There are several ways to generate random numbers. You can use a <a href="https://en.wikipedia.org/wiki/Hardware_random_number_generator">Hardware RNG</a>, or you can use a <a href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">Pseudorandom Number Generator</a>, PRNG for short. There are several PRNG algorithms available. The question I will try to answer is: which one should you use?</p>

<p>I have already given away my answer is the title. You should <strong>always</strong> use a <a href="https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator">Cryptographically Secure PRNG</a>, CSPRNG for short, and ignore all other PRNGs. There is no good reason to use anything else. I know it sounds simplistic, but I will explain why it is the only reasonable way to do it.</p>

<p>This advice goes somewhat against the common practice and the usual advice. What people typically say is: use a CSPRNG if you are doing cryptography and need security against adversarial attackers. For all other purposes pick among the “classic” non-cryptographic PRNGs. It sounds reasonable. After all, it’s in the name: CSPRNG stands for “cryptographically secure” PRNG. If you don’t need to worry about security, why bother doing that?</p>

<p>But I will argue that always using CSPRNGs is the only thing that really makes sense.</p>

<h2 id="a-motivating-example">A motivating example</h2>

<p>Consider the following problem in linear algebra:</p>

<p>What is the probability that a random <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n \times n</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>×</span><span></span></span><span><span></span><span>n</span></span></span></span> matrix in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="double-struck">Z</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbb{Z}_2</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>Z</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> (modulo 2) is full rank, i.e. invertible?</p>

<p>We can test this experimentally. I wrote a <a href="https://github.com/tczajka/sorting-searching/blob/master/_code/random/rank.cc">C++ program</a> that calculates this for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≤</mo><mn>700</mn></mrow><annotation encoding="application/x-tex">n \le 700</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>≤</span><span></span></span><span><span></span><span>700</span></span></span></span> by sampling 1000 random matrices for each <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span></span></span></span>.</p>

<p><img src="https://sortingsearching.com/assets/images/random/rank.png" alt="Probability full rank"/></p>

<p>It looks like we get about 30% for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≤</mo><mn>491</mn></mrow><annotation encoding="application/x-tex">n \le 491</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>≤</span><span></span></span><span><span></span><span>491</span></span></span></span>, then we suddenly start flipping between 0% and 30% for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>492</mn><mo>≤</mo><mi>n</mi><mo>≤</mo><mn>526</mn></mrow><annotation encoding="application/x-tex">492 \le n \le 526</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>492</span><span></span><span>≤</span><span></span></span><span><span></span><span>n</span><span></span><span>≤</span><span></span></span><span><span></span><span>526</span></span></span></span>, then we get 100% for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>527</mn></mrow><annotation encoding="application/x-tex">n = 527</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>=</span><span></span></span><span><span></span><span>527</span></span></span></span>, and then 0% for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>528</mn><mo>≤</mo><mi>n</mi><mo>≤</mo><mn>700</mn></mrow><annotation encoding="application/x-tex">528 \le n \le 700</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>528</span><span></span><span>≤</span><span></span></span><span><span></span><span>n</span><span></span><span>≤</span><span></span></span><span><span></span><span>700</span></span></span></span>.</p>

<p>You can try running this code yourself and see if you get the same answers. This experiment is repeatable.</p>

<p>Such interesting results! We have some sort of phase transition around 500. You can easily imagine somebody writing a scientific paper based on an experiment similar to this.</p>

<p>But the effect is not real. The true answer is that the probability is:</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mi>i</mi></mrow></msup><mo stretchy="false">)</mo><mo>→</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mn>2</mn><mrow><mo>−</mo><mi>i</mi></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mn>0.2887</mn><mo>…</mo></mrow><annotation encoding="application/x-tex">\prod_{i=1}^n (1 - 2^{-i}) \rightarrow \prod_{i=1}^\infty (1 - 2^{-i}) = 0.2887\ldots</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∏</span></span></span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span>(</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span><span>2</span><span><span><span><span><span><span></span><span><span><span>−</span><span>i</span></span></span></span></span></span></span></span></span><span>)</span><span></span><span>→</span><span></span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∏</span></span></span><span><span></span><span><span>∞</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span>(</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span><span>2</span><span><span><span><span><span><span></span><span><span><span>−</span><span>i</span></span></span></span></span></span></span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0.2887</span><span></span><span>…</span></span></span></span></span></p><p>I used the <code>rand()</code> function from the GNU C library to generate the random matrices. This PRNG uses a <a href="https://www.mathstat.dal.ca/~selinger/random/">Lagged Fibonacci Generator</a>. The results are an artifact of this particular PRNG. There are detectable dependencies between the pseudo-random bits generated by the generator which results in matrix rows being linearly dependent for large <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span></span></span></span> (and, surprisingly, always independent for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>527</mn></mrow><annotation encoding="application/x-tex">n = 527</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>=</span><span></span></span><span><span></span><span>527</span></span></span></span>).</p>

<p>What should I have used instead? How can I know that if I use a different PRNG, I will get more trustworthy results?</p>

<p>I can’t if I use any old PRNG. But if I use a CSPRNG, then I know by definition of cryptographic security that one of two things will happen:</p>
<ul>
  <li>Either the results will be statistically correct, or</li>
  <li>I will have broken the cryptographic security of that particular CSPRNG.</li>
</ul>

<p>Both cases are pretty neat!</p>

<p>If, hypothetically, my results are statistically off with a CSPRNG, I will have just found a way to break cryptographic security of the cryptographic primitive used
byt that CSPRNG. By definition, that’s what it means to break cryptographic security. That’s even better than learning about matrices!</p>

<p>That scenario is very unlikely in practice. A lot of people have deliberately tried and failed to break the security of standard CSPRNGs – that’s why we treat them as cryptographically secure. It’s unlikely that just messing around with matrices I have stumbled upon a way to break one without even really deliberately trying.</p>

<h2 id="hardware-rngs">Hardware RNGs</h2>

<p>Maybe we should just use true randomness rather than settling with pseudorandomness? There are hardware devices that generate random bits.
Some modern processors have them built in, for instance, modern x86-64 CPUs have the <a href="https://en.wikipedia.org/wiki/RDRAND">RDRAND</a> instruction.
One could use <code>/dev/random</code> in Linux, or the online service <a href="https://www.random.org/">random.org</a>.</p>

<p>There are a few reasons PRNGs are usually preferred:</p>
<ul>
  <li>Truly random bits are hard to obtain efficiently.</li>
  <li>It’s difficult to make them unbiased.</li>
  <li>With PRNGs, we can easily replay the whole random sequence without having to store all the bits.</li>
</ul>

<p>In fact, for the first two reasons, the RDRAND instruction is implemented in hardware with a hybrid of a hardware generator and a CSPRNG. <code>/dev/random</code> also does this.</p>

<p>Hardware generators are still very important however. We need them to <strong>seed</strong> PRNGs. A PRNG takes a small truly random seed and uses it to
generate a long sequence of pseudorandom bits.</p>

<h2 id="non-cryptographic-prngs">Non-cryptographic PRNGs</h2>

<p>There are several non-cryptographic PRNGs in common use:</p>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Lehmer_random_number_generator"><strong>Lehmer generator.</strong></a> Available in C++ as <code>minstd_rand0</code> and <code>minstd_rand</code>.</li>
  <li><a href="https://en.wikipedia.org/wiki/Linear_congruential_generator"><strong>Linear congruential generator.</strong></a> Previously used by the <code>rand</code> function in the GNU C library.</li>
  <li><a href="https://en.wikipedia.org/wiki/Lagged_Fibonacci_generator"><strong>Lagged Fibonacci generator.</strong></a> Currently used by the <code>rand</code> functions in the GNU C library.</li>
  <li><a href="https://en.wikipedia.org/wiki/Linear-feedback_shift_register"><strong>Linear-feedback shift register.</strong></a></li>
  <li><a href="https://en.wikipedia.org/wiki/Mersenne_Twister"><strong>Mersenne Twister.</strong></a> Very popular. Available in C++ as <code>mt19937</code>, the default PRNG used by the Python <code>random</code> module.</li>
  <li><a href="https://www.pcg-random.org/"><strong>PCG, Permuted Congruential Generator.</strong></a></li>
  <li><a href="https://vigna.di.unimi.it/xorshift/"><strong>Xorshift / Xoroshiro.</strong></a> A popular recent generator. Used by default in JavaScript engines in Chrome, Firefox, Safari.</li>
</ul>

<p>I am arguing: these should never be used! They are weak generators. They all are easily predictable and have statistical weaknesses. Of course they do – if they didn’t, they would be considered CSPRNGs!</p>

<p>It is a bad state of affairs that they are provided as the default PRNG in various programming languages.</p>

<h2 id="the-dark-art-of-choosing-a-weak-prng">The Dark Art of choosing a weak PRNG</h2>

<p>Donald Knuth in his classic books <a href="https://www-cs-faculty.stanford.edu/~knuth/taocp.html">The Art of Computer Programming</a> devotes
a good part of Volume 2 just to this topic. He analyzes various parameters of Linear Congruential Generators and Lagged Fibonacci Generators and considers their strengths and weaknesses.</p>

<p>He never considers CSPRNGs at all. That’s because modern cryptographic primitives on which CSPRNGs are built didn’t exist yet when the books were written in the 1960s.</p>

<p>There are a lot of papers analyzing the pros and cons of various algorithms and their weak spots.</p>

<p>Sebastiano Vigna, one of the authors of xoroshiro, has written a paper about <a href="https://arxiv.org/pdf/1910.06437.pdf">why one shouldn’t use the Mersenne Twister</a> and has argued online about <a href="https://pcg.di.unimi.it/pcg.php">why PCG is flawed</a>.</p>

<p>The arguments got rather heated when PCG’s author M.E. O’Neill <a href="https://www.pcg-random.org/posts/on-vignas-pcg-critique.html">wrote in defense of PCG</a>.</p>

<p>My take: just use a CSPRNG and you will never have to worry about any of this. CSPRNGs don’t have any such weaknesses, by design! As long as their security claims hold up.</p>

<h2 id="csprngs">CSPRNGs</h2>

<p>Cryptographically secure PRNGs are closely related to encryption. Any CSPRNG can be turned into a stream cipher, and vice-versa. What a stream cipher really is is a CSPRNG that you xor your message with in order to encrypt it.</p>

<p>To generate a CSPRNG from a block cipher, you can simply run the block cipher in counter mode. In other words, you process the numbers 0, 1, 2, 3, etc using a random encryption key, and that gives you the pseudo-random bits.</p>

<p>There are other ways to do this in order to get some extra protection <a href="https://en.wikipedia.org/wiki/Forward_secrecy">when your key leaks</a> but let’s not get into that because it’s not really relevant outside of cryptography.</p>

<p>Two common CSPRNGs are:</p>
<ul>
  <li>AES-CTR, based on <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a> encryption.</li>
  <li><a href="https://en.wikipedia.org/wiki/Salsa20">ChaCha20</a>.</li>
</ul>

<p>I recommend ChaCha20. It’s rather simple. It’s easy to implement from scratch in not that many lines of code. It doesn’t require special hardware support. AES uses special hardware instructions to be efficient.</p>

<p>The de-facto standard Rust library for random numbers, <a href="https://docs.rs/rand/latest/rand/"><code>rand</code></a>, uses ChaCha12, a reduced-round variant of ChaCha20, as its default PRNG.</p>

<h2 id="what-makes-a-good-prng">What makes a good PRNG</h2>

<p>A good PRNG generates a sequence that “looks random”. This is usually taken as “it passes as many various statistical tests as possible”. Statistical tests try to distinguish pseudo-random numbers from truly random numbers.</p>

<p>The definition of a CSPRNG is: given the first n bits, there is no efficient algorithm that will predict the next bit with success rate non-negligibly better than 50%.</p>

<p>This implies that a CSPRNG will pass <strong>all</strong> statistical tests that run in reasonable time.</p>

<p>Can you see the similarity between what makes a good PRNG and what makes a CSPRNG? A CSPRNG is the ultimate PRNG, by definition.</p>

<h2 id="csprngs-are-better">CSPRNGs are better</h2>

<p>Suppose you are creating an online backgammon server. Backgammon uses dice. You need fair dice. What PRNG should you choose?</p>

<p>If you use a weak PRNG, players can relatively easily reverse engineer what is going on and <strong>predict future dice</strong> based on previous dice rolls. Clearly a bad situation all around!</p>

<p>How about if you are running a scientific Monte Carlo simulation. We already saw an example with matrices. You can’t trust the results if you use a weak PRNG!</p>

<p>Can you trust the results if you use a CSPRNG? Sort of.</p>

<p>Hypothetically you could get biased results because there is no proof that any particular CSPRNG really is secure. But if you do see biased results, you will have accidentally broken the security of that CSPRNG, by the very definition of cryptographic security. You would be able to read encrypted messages by exploiting this bias.</p>

<p>So for practical purposes: yes, you can trust the results obtained by CSPRNG.</p>

<p>What if you’re just running some Las Vegas algorithm such as quicksort? Do you really need a CSPRNG?</p>

<p>Yes! The analysis of quicksort assumes that the numbers are truly random. If they can be distinguished from truly random, that analysis doesn’t hold any more. Your quicksort might become quadratically slow for certain types of data. You never know. Why risk it?</p>

<p>With CSPRNG, if you notice that your quicksort becomes quadratically slow, again you would have accidentally broken the cryptographic security of that PRNG.</p>

<p>What if you’re just building a video game? Do you <em>really</em> care about the quality of the random numbers used for the behavior of characters in the game? Well, in this case maybe not. But then, why bother even thinking about this? Just plug in a CSPRNG and forget about it. There is no harm.</p>

<h2 id="what-about-performance">What about performance?</h2>

<p>By this point many of you are probably thinking: what about performance? Aren’t CSPRNGs less efficient than simple weak PRNGs?</p>

<p>Let’s <a href="https://rust-random.github.io/book/guide-rngs.html">look at some numbers</a>.</p>

<p>If you use a weak PRNGs such as <code>Xoshiro256PlusPlus</code>, you are getting 7 GB/s.</p>

<p>If you use <code>ChaCha20</code>, you are getting 1.8 GB / s. About 4x less.</p>

<p>This seems like a reasonable argument for weak PRNGs: 4x speed-up is a lot!</p>

<p>But that would only be true if generating random bits was the hot spot, the bottleneck of your program. It never is in practice.</p>

<p>1.8 GB / s is <strong>14 billion random bits per second</strong>. Do you <strong>really</strong> need 14 billion random bits per second in your video game, or in your Monte Carlo simulation? Probably not. Probably many orders of magnitude less. Whatever you do with those random bits most likely takes orders of magnitude more effort than just generating those bits.</p>

<p>And if you ever do need billions or trillions of bits, you probably care a lot about the quality of those bits. Any bias will show with such a large sample.</p>

<h2 id="but-i-dont-care-about-quality">“But I don’t care about quality”</h2>

<p>So you might say: in my program I don’t care whether the numbers are really all that random, so shouldn’t I just use some weak PRNG?</p>

<p>I have two answers to this.</p>

<p>The first answer is: even if you don’t care, there is no harm from using CSPRNG. So why not just always use it?</p>

<p>My second answer is: if you really don’t care, why not just do <a href="https://xkcd.com/221/">this</a>?</p>
<div><div><pre><code>int getRandomNumber() {
    return 4;
}
</code></pre></div></div>

<p>Or more realistically, if you only care that the numbers don’t repeat too often, why not use a simple counter that returns 0, 1, 2, 3, …?</p>

<p>If you say “that’s not random enough”, that indicates that you do care about quality, and so you should just use a CSPRNG and be done.</p>

<h2 id="my-favorite-language-doesnt-provide-csprngs">“My favorite language doesn’t provide CSPRNGs”</h2>

<p>That’s the only reasonable argument for using a weaker PRNG. I hope this situation changes in the future.</p>

<p>You can still use a third-party library. Or you can just implement ChaCha20 yourself. It’s not that complicated. <a href="https://en.wikipedia.org/wiki/Salsa20">Wikipedia</a> has an implementation of the core algorithm in 31 lines of C code.</p>

<h2 id="weak-prngs-are-poor-mans-wanna-be-csprngs">Weak PRNGs are poor man’s wanna-be CSPRNGs</h2>

<p>If you look at how a weak PRNG such as <a href="https://vigna.di.unimi.it/xorshift/xoroshiro128starstar.c">Xoroshiro128**</a> is implemented, you will see a bunch of xors, bit shifts, and multiplications.</p>

<p>If you look at how <a href="https://en.wikipedia.org/wiki/Salsa20">ChaCha20</a> is implemented, you will see a bunch of xors and bit shifts and additions. There are just more iterations of them.</p>

<p>The way I see it: weak PRNGs are wanna-be CSPRNGs that don’t quite get there. They do the same kinds of things that CSPRNGs do, they just don’t quite get the job done fully. They don’t mix the bits enough that the output becomes indistinguishable from truly random.</p>

<p>Just use the real thing!</p>

<h2 id="summary">Summary</h2>

<p>I hope that this convincingly argues that CSPRNGs are the way to go. We should all just stop using weaker PRNGs altogether.</p>

<p>It is a shame that major programming languages provide weak PRNGs as the default in their standard libraries.</p>

<p>Rust’s third-party crate <code>rand</code> that is the de-facto Rust standard for PRNGs is a notable exception: it uses a CSPRNG as the default generator.</p>

<p>I hope everybody else follows suit and does the same.</p>

  </div>
  
  
</article>

      </div>
    </div></div>
  </body>
</html>
