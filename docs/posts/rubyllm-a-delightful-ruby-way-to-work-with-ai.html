<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/crmne/ruby_llm">Original</a>
    <h1>RubyLLM: A delightful Ruby way to work with AI</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/crmne/ruby_llm/blob/main/docs/assets/images/logotype.svg"><img src="https://github.com/crmne/ruby_llm/raw/main/docs/assets/images/logotype.svg" alt="RubyLLM" height="120" width="250"/></a></p>
<p dir="auto">A delightful Ruby way to work with AI. No configuration madness, no complex callbacks, no handler hell â€“ just beautiful, expressive Ruby code.</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/efcee9c912e112d1388bb7490e7250d1ab1c3da863f29585c17523d59aa7470e/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f342f34642f4f70656e41495f4c6f676f2e737667"><img src="https://camo.githubusercontent.com/efcee9c912e112d1388bb7490e7250d1ab1c3da863f29585c17523d59aa7470e/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f342f34642f4f70656e41495f4c6f676f2e737667" alt="OpenAI" height="40" width="120" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/4/4d/OpenAI_Logo.svg"/></a>
  Â Â Â Â 
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/cb96992c07bc9bbd3cf2e7529399cd6a8bb06424eb3a2c40a2b4e446612cf7a0/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f372f37382f416e7468726f7069635f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/cb96992c07bc9bbd3cf2e7529399cd6a8bb06424eb3a2c40a2b4e446612cf7a0/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f372f37382f416e7468726f7069635f6c6f676f2e737667" alt="Anthropic" height="40" width="120" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/7/78/Anthropic_logo.svg"/></a>
  Â Â Â Â 
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/29ce596da06d31c33b76274804260efb818e6e66fd7be0333088ba699d945196/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f382f38612f476f6f676c655f47656d696e695f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/29ce596da06d31c33b76274804260efb818e6e66fd7be0333088ba699d945196/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f382f38612f476f6f676c655f47656d696e695f6c6f676f2e737667" alt="Google" height="40" width="120" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg"/></a>
  Â Â Â Â 
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4f90a64824c96fbb15a45d3d82f9789209817dd5cef8a7afc68c6ccd44d42a7d/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f652f65632f446565705365656b5f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/4f90a64824c96fbb15a45d3d82f9789209817dd5cef8a7afc68c6ccd44d42a7d/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f652f65632f446565705365656b5f6c6f676f2e737667" alt="DeepSeek" height="40" width="120" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/e/ec/DeepSeek_logo.svg"/></a>
</p>
<p dir="auto"><a href="https://badge.fury.io/rb/ruby_llm" rel="nofollow"><img src="https://camo.githubusercontent.com/0bc526571d371742b464982e9832fb8fbb3140e53e99641892fe255c751c3779/68747470733a2f2f62616467652e667572792e696f2f72622f727562795f6c6c6d2e7376673f64756d6d793d756e75736564" alt="Gem Version" data-canonical-src="https://badge.fury.io/rb/ruby_llm.svg?dummy=unused"/></a>
<a href="https://github.com/testdouble/standard"><img src="https://camo.githubusercontent.com/5338a68a0f130dc684279ff3e42e45c9c74006018a1bdeaac76905979b3ccd49/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64655f7374796c652d7374616e646172642d627269676874677265656e2e737667" alt="Ruby Style Guide" data-canonical-src="https://img.shields.io/badge/code_style-standard-brightgreen.svg"/></a>
<a href="https://rubygems.org/gems/ruby_llm" rel="nofollow"><img alt="Gem Downloads" src="https://camo.githubusercontent.com/e8293faa37d2acb91ae94e4462f4c2625eafa8c800b48cb1d80f25384cc973ce/68747470733a2f2f696d672e736869656c64732e696f2f67656d2f64742f727562795f6c6c6d" data-canonical-src="https://img.shields.io/gem/dt/ruby_llm"/></a>
<a href="https://codecov.io/gh/crmne/ruby_llm" rel="nofollow"><img src="https://camo.githubusercontent.com/d0b6206243cfea675afcec22d7439ebdd59ef5746889cacc88e5777937295fd2/68747470733a2f2f636f6465636f762e696f2f67682f63726d6e652f727562795f6c6c6d2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/crmne/ruby_llm/branch/main/graph/badge.svg"/></a></p>
<p dir="auto">ğŸ¤º Battle tested at <a href="https://chatwithwork.com" rel="nofollow">ğŸ’¬  Chat with Work</a></p>
<div dir="auto"><h2 tabindex="-1" dir="auto">The problem with AI libraries</h2><a id="user-content-the-problem-with-ai-libraries" aria-label="Permalink: The problem with AI libraries" href="#the-problem-with-ai-libraries"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Every AI provider comes with its own client library, its own response format, its own conventions for streaming, and its own way of handling errors. Want to use multiple providers? Prepare to juggle incompatible APIs and bloated dependencies.</p>
<p dir="auto">RubyLLM fixes all that. One beautiful API for everything. One consistent format. Minimal dependencies â€” just Faraday and Zeitwerk. Because working with AI should be a joy, not a chore.</p>

<ul dir="auto">
<li>ğŸ’¬ <strong>Chat</strong> with OpenAI, Anthropic, Gemini, and DeepSeek models</li>
<li>ğŸ‘ï¸ <strong>Vision and Audio</strong> understanding</li>
<li>ğŸ“„ <strong>PDF Analysis</strong> for analyzing documents</li>
<li>ğŸ–¼ï¸ <strong>Image generation</strong> with DALL-E and other providers</li>
<li>ğŸ“Š <strong>Embeddings</strong> for vector search and semantic analysis</li>
<li>ğŸ”§ <strong>Tools</strong> that let AI use your Ruby code</li>
<li>ğŸš‚ <strong>Rails integration</strong> to persist chats and messages with ActiveRecord</li>
<li>ğŸŒŠ <strong>Streaming</strong> responses with proper Ruby patterns</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="# Just ask questions
chat = RubyLLM.chat
chat.ask &#34;What&#39;s the best way to learn Ruby?&#34;

# Analyze images
chat.ask &#34;What&#39;s in this image?&#34;, with: { image: &#34;ruby_conf.jpg&#34; }

# Analyze audio recordings
chat.ask &#34;Describe this meeting&#34;, with: { audio: &#34;meeting.wav&#34; }

# Analyze documents
chat.ask &#34;Summarize this document&#34;, with: { pdf: &#34;contract.pdf&#34; }

# Generate images
RubyLLM.paint &#34;a sunset over mountains in watercolor style&#34;

# Create vector embeddings
RubyLLM.embed &#34;Ruby is elegant and expressive&#34;

# Let AI use your code
class Weather &lt; RubyLLM::Tool
  description &#34;Gets current weather for a location&#34;
  param :latitude, desc: &#34;Latitude (e.g., 52.5200)&#34;
  param :longitude, desc: &#34;Longitude (e.g., 13.4050)&#34;

  def execute(latitude:, longitude:)
    url = &#34;https://api.open-meteo.com/v1/forecast?latitude=#{latitude}&amp;longitude=#{longitude}&amp;current=temperature_2m,wind_speed_10m&#34;

    response = Faraday.get(url)
    data = JSON.parse(response.body)
  rescue =&gt; e
    { error: e.message }
  end
end

chat.with_tool(Weather).ask &#34;What&#39;s the weather in Berlin? (52.5200, 13.4050)&#34;"><pre><span># Just ask questions</span>
<span>chat</span> <span>=</span> <span>RubyLLM</span><span>.</span><span>chat</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;What&#39;s the best way to learn Ruby?&#34;</span>

<span># Analyze images</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;What&#39;s in this image?&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>image</span>: <span>&#34;ruby_conf.jpg&#34;</span> <span>}</span>

<span># Analyze audio recordings</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Describe this meeting&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>audio</span>: <span>&#34;meeting.wav&#34;</span> <span>}</span>

<span># Analyze documents</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Summarize this document&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>pdf</span>: <span>&#34;contract.pdf&#34;</span> <span>}</span>

<span># Generate images</span>
<span>RubyLLM</span><span>.</span><span>paint</span> <span>&#34;a sunset over mountains in watercolor style&#34;</span>

<span># Create vector embeddings</span>
<span>RubyLLM</span><span>.</span><span>embed</span> <span>&#34;Ruby is elegant and expressive&#34;</span>

<span># Let AI use your code</span>
<span>class</span> <span>Weather</span> &lt; <span>RubyLLM</span>::<span>Tool</span>
  <span>description</span> <span>&#34;Gets current weather for a location&#34;</span>
  <span>param</span> <span>:latitude</span><span>,</span> <span>desc</span>: <span>&#34;Latitude (e.g., 52.5200)&#34;</span>
  <span>param</span> <span>:longitude</span><span>,</span> <span>desc</span>: <span>&#34;Longitude (e.g., 13.4050)&#34;</span>

  <span>def</span> <span>execute</span><span>(</span><span>latitude</span>:<span>,</span> <span>longitude</span>:<span>)</span>
    <span>url</span> <span>=</span> <span>&#34;https://api.open-meteo.com/v1/forecast?latitude=<span><span>#{</span><span>latitude</span><span>}</span></span>&amp;longitude=<span><span>#{</span><span>longitude</span><span>}</span></span>&amp;current=temperature_2m,wind_speed_10m&#34;</span>

    <span>response</span> <span>=</span> <span>Faraday</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
    <span>data</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>.</span><span>body</span><span>)</span>
  <span>rescue</span> <span>=&gt;</span> <span>e</span>
    <span>{</span> <span>error</span>: <span>e</span><span>.</span><span>message</span> <span>}</span>
  <span>end</span>
<span>end</span>

<span>chat</span><span>.</span><span>with_tool</span><span>(</span><span>Weather</span><span>)</span><span>.</span><span>ask</span> <span>&#34;What&#39;s the weather in Berlin? (52.5200, 13.4050)&#34;</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# In your Gemfile
gem &#39;ruby_llm&#39;

# Then run
bundle install

# Or install it yourself
gem install ruby_llm"><pre><span># In your Gemfile</span>
<span>gem</span> <span>&#39;ruby_llm&#39;</span>

<span># Then run</span>
<span>bundle</span> <span>install</span>

<span># Or install it yourself</span>
<span>gem</span> <span>install</span> <span>ruby_llm</span></pre></div>
<p dir="auto">Configure with your API keys:</p>
<div dir="auto" data-snippet-clipboard-copy-content="RubyLLM.configure do |config|
  config.openai_api_key = ENV[&#39;OPENAI_API_KEY&#39;]
  config.anthropic_api_key = ENV[&#39;ANTHROPIC_API_KEY&#39;]
  config.gemini_api_key = ENV[&#39;GEMINI_API_KEY&#39;]
  config.deepseek_api_key = ENV[&#39;DEEPSEEK_API_KEY&#39;] # Optional
end"><pre><span>RubyLLM</span><span>.</span><span>configure</span> <span>do</span> |<span>config</span>|
  <span>config</span><span>.</span><span>openai_api_key</span> <span>=</span> <span>ENV</span><span>[</span><span>&#39;OPENAI_API_KEY&#39;</span><span>]</span>
  <span>config</span><span>.</span><span>anthropic_api_key</span> <span>=</span> <span>ENV</span><span>[</span><span>&#39;ANTHROPIC_API_KEY&#39;</span><span>]</span>
  <span>config</span><span>.</span><span>gemini_api_key</span> <span>=</span> <span>ENV</span><span>[</span><span>&#39;GEMINI_API_KEY&#39;</span><span>]</span>
  <span>config</span><span>.</span><span>deepseek_api_key</span> <span>=</span> <span>ENV</span><span>[</span><span>&#39;DEEPSEEK_API_KEY&#39;</span><span>]</span> <span># Optional</span>
<span>end</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# Start a chat with the default model (GPT-4o-mini)
chat = RubyLLM.chat

# Or specify what you want
chat = RubyLLM.chat(model: &#39;claude-3-7-sonnet-20250219&#39;)

# Simple questions just work
chat.ask &#34;What&#39;s the difference between attr_reader and attr_accessor?&#34;

# Multi-turn conversations are seamless
chat.ask &#34;Could you give me an example?&#34;

# Stream responses in real-time
chat.ask &#34;Tell me a story about a Ruby programmer&#34; do |chunk|
  print chunk.content
end

# Understand content in multiple forms
chat.ask &#34;Compare these diagrams&#34;, with: { image: [&#34;diagram1.png&#34;, &#34;diagram2.png&#34;] }
chat.ask &#34;Summarize this document&#34;, with: { pdf: &#34;contract.pdf&#34; }
chat.ask &#34;What&#39;s being said?&#34;, with: { audio: &#34;meeting.wav&#34; }

# Need a different model mid-conversation? No problem
chat.with_model(&#39;gemini-2.0-flash&#39;).ask &#34;What&#39;s your favorite algorithm?&#34;"><pre><span># Start a chat with the default model (GPT-4o-mini)</span>
<span>chat</span> <span>=</span> <span>RubyLLM</span><span>.</span><span>chat</span>

<span># Or specify what you want</span>
<span>chat</span> <span>=</span> <span>RubyLLM</span><span>.</span><span>chat</span><span>(</span><span>model</span>: <span>&#39;claude-3-7-sonnet-20250219&#39;</span><span>)</span>

<span># Simple questions just work</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;What&#39;s the difference between attr_reader and attr_accessor?&#34;</span>

<span># Multi-turn conversations are seamless</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Could you give me an example?&#34;</span>

<span># Stream responses in real-time</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Tell me a story about a Ruby programmer&#34;</span> <span>do</span> |<span>chunk</span>|
  <span>print</span> <span>chunk</span><span>.</span><span>content</span>
<span>end</span>

<span># Understand content in multiple forms</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Compare these diagrams&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>image</span>: <span>[</span><span>&#34;diagram1.png&#34;</span><span>,</span> <span>&#34;diagram2.png&#34;</span><span>]</span> <span>}</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;Summarize this document&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>pdf</span>: <span>&#34;contract.pdf&#34;</span> <span>}</span>
<span>chat</span><span>.</span><span>ask</span> <span>&#34;What&#39;s being said?&#34;</span><span>,</span> <span>with</span>: <span>{</span> <span>audio</span>: <span>&#34;meeting.wav&#34;</span> <span>}</span>

<span># Need a different model mid-conversation? No problem</span>
<span>chat</span><span>.</span><span>with_model</span><span>(</span><span>&#39;gemini-2.0-flash&#39;</span><span>)</span><span>.</span><span>ask</span> <span>&#34;What&#39;s your favorite algorithm?&#34;</span></pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Rails integration that makes sense</h2><a id="user-content-rails-integration-that-makes-sense" aria-label="Permalink: Rails integration that makes sense" href="#rails-integration-that-makes-sense"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="# app/models/chat.rb
class Chat &lt; ApplicationRecord
  acts_as_chat

  # Works great with Turbo
  broadcasts_to -&gt;(chat) { &#34;chat_#{chat.id}&#34; }
end

# app/models/message.rb
class Message &lt; ApplicationRecord
  acts_as_message
end

# app/models/tool_call.rb
class ToolCall &lt; ApplicationRecord
  acts_as_tool_call
end

# In your controller
chat = Chat.create!(model_id: &#34;gpt-4o-mini&#34;)
chat.ask(&#34;What&#39;s your favorite Ruby gem?&#34;) do |chunk|
  Turbo::StreamsChannel.broadcast_append_to(
    chat,
    target: &#34;response&#34;,
    partial: &#34;messages/chunk&#34;,
    locals: { chunk: chunk }
  )
end

# That&#39;s it - chat history is automatically saved"><pre><span># app/models/chat.rb</span>
<span>class</span> <span>Chat</span> &lt; <span>ApplicationRecord</span>
  <span>acts_as_chat</span>

  <span># Works great with Turbo</span>
  <span>broadcasts_to</span> <span>-&gt;</span><span>(</span><span>chat</span><span>)</span> <span>{</span> <span>&#34;chat_<span><span>#{</span><span>chat</span><span>.</span><span>id</span><span>}</span></span>&#34;</span> <span>}</span>
<span>end</span>

<span># app/models/message.rb</span>
<span>class</span> <span>Message</span> &lt; <span>ApplicationRecord</span>
  <span>acts_as_message</span>
<span>end</span>

<span># app/models/tool_call.rb</span>
<span>class</span> <span>ToolCall</span> &lt; <span>ApplicationRecord</span>
  <span>acts_as_tool_call</span>
<span>end</span>

<span># In your controller</span>
<span>chat</span> <span>=</span> <span>Chat</span><span>.</span><span>create!</span><span>(</span><span>model_id</span>: <span>&#34;gpt-4o-mini&#34;</span><span>)</span>
<span>chat</span><span>.</span><span>ask</span><span>(</span><span>&#34;What&#39;s your favorite Ruby gem?&#34;</span><span>)</span> <span>do</span> |<span>chunk</span>|
  <span>Turbo</span>::<span>StreamsChannel</span><span>.</span><span>broadcast_append_to</span><span>(</span>
    <span>chat</span><span>,</span>
    <span>target</span>: <span>&#34;response&#34;</span><span>,</span>
    <span>partial</span>: <span>&#34;messages/chunk&#34;</span><span>,</span>
    <span>locals</span>: <span>{</span> <span>chunk</span>: <span>chunk</span> <span>}</span>
  <span>)</span>
<span>end</span>

<span># That&#39;s it - chat history is automatically saved</span></pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Creating tools is a breeze</h2><a id="user-content-creating-tools-is-a-breeze" aria-label="Permalink: Creating tools is a breeze" href="#creating-tools-is-a-breeze"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="class Search &lt; RubyLLM::Tool
  description &#34;Searches a knowledge base&#34;

  param :query, desc: &#34;The search query&#34;
  param :limit, type: :integer, desc: &#34;Max results&#34;, required: false

  def execute(query:, limit: 5)
    # Your search logic here
    Document.search(query).limit(limit).map(&amp;:title)
  end
end

# Let the AI use it
chat.with_tool(Search).ask &#34;Find documents about Ruby 3.3 features&#34;"><pre><span>class</span> <span>Search</span> &lt; <span>RubyLLM</span>::<span>Tool</span>
  <span>description</span> <span>&#34;Searches a knowledge base&#34;</span>

  <span>param</span> <span>:query</span><span>,</span> <span>desc</span>: <span>&#34;The search query&#34;</span>
  <span>param</span> <span>:limit</span><span>,</span> <span>type</span>: <span>:integer</span><span>,</span> <span>desc</span>: <span>&#34;Max results&#34;</span><span>,</span> <span>required</span>: <span>false</span>

  <span>def</span> <span>execute</span><span>(</span><span>query</span>:<span>,</span> <span>limit</span>: <span>5</span><span>)</span>
    <span># Your search logic here</span>
    <span>Document</span><span>.</span><span>search</span><span>(</span><span>query</span><span>)</span><span>.</span><span>limit</span><span>(</span><span>limit</span><span>)</span><span>.</span><span>map</span><span>(</span>&amp;<span>:title</span><span>)</span>
  <span>end</span>
<span>end</span>

<span># Let the AI use it</span>
<span>chat</span><span>.</span><span>with_tool</span><span>(</span><span>Search</span><span>)</span><span>.</span><span>ask</span> <span>&#34;Find documents about Ruby 3.3 features&#34;</span></pre></div>

<p dir="auto">Check out the guides at <a href="https://rubyllm.com" rel="nofollow">https://rubyllm.com</a> for deeper dives into conversations with tools, streaming responses, embedding generations, and more.</p>

<p dir="auto">Released under the MIT License.</p>
</article></div></div>
  </body>
</html>
