<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sunset1995.github.io/dvgo/">Original</a>
    <h1>Direct Voxel Grid Optimization</h1>
    
    <div id="readability-page-1" class="page"><p id="paper-title">
            
            <h3>
                Super-fast Convergence for Radiance Fields Reconstruction
            </h3>
            <h3>
                <small>CVPR 2022 (Oral)</small>
            </h3>
        </p><div>
            <div>
                <h4>Results on real-world captured data</h4>

            </div>
        </div><div>
            <div>
                <h4>Custom casually captured data</h4>
                <p>Coming soon hopefully.</p>
            </div>
        </div><div id="my_features">
            <div>
                <h4>Features</h4>
                <ul>
                    <li>Speedup NeRF by replacing the MLP with the voxel grid.</li>
                    <li>Simple scene representation:</li>
                    <ul>
                        <li><p>Volume densities:</p><p>dense voxel grid (3D).</p></li>
                        <li><p>View-dependent colors:</p><p>dense feature grid (4D) + shallow MLP.</p></li>
                    </ul>
                    <li>Pytorch implementation.</li>
                    <li><sup>â€ </sup>Pytorch cuda extention built just-in-time for <b>another 2--3x speedup</b>.</li>
                    <li><sup>â€ </sup>O(N) realization for the distortion loss proposed by <a href="https://jonbarron.info/mipnerf360/">mip-nerf 360</a>.</li>
                    <ul>
                        <li>The loss improves our training time and quality.</li>
                        <li>We have released a self-contained pytorch package: <a href="https://github.com/sunset1995/torch_efficient_distloss">torch_efficient_distloss</a>.</li>
                        <li>Consider a batch of 8192 rays X 256 points.</li>
                        <ul>
                            <li>GPU memory consumption: 6192MB =&gt; 96MB.</li>
                            <li>Run times for 100 iters: 20 sec =&gt; 0.2sec.</li>
                        </ul>
                    </ul>
                    <li>Supported datasets:</li>
                    <ul>
                        <li><p>Bounded inward-facing:</p></li>
                        <li><p><sup>â€ </sup>Unbounded inward-facing:</p></li>
                        <li><p><sup>â€ </sup>Foward-facing:</p></li>
                    </ul>
                </ul>
                <p><sup>â€  means new stuff after publication.</sup></p>
            </div>
        </div><div id="my_postact">
            <div>
                <h4>Post-activation</h4>

                <p><b>Observation.</b>
                To produce sharp surface, we have to activate density into alpha </p><u>after</u><p> interpolation.
                </p><div>
                    <p><img src="https://sunset1995.github.io/dvgo/img/post_act.png"/>
                    </p>
                </div>
                

                <p><b>Proof.</b> Post-activation can be arbitrarily close to a surface beyond linear. Detail in paper.</p>
                <p><b>Toy example 1.</b> Fitting a surface with a single 2D grid cell.
                </p><div>
                    <p><img src="https://sunset1995.github.io/dvgo/img/post_toy1.png"/>
                    </p>
                </div>
                

                <p><b>Toy example 2.</b> Fitting a binary (occupancy) image with a 2D grid.
                </p><div>
                    <p><img src="https://sunset1995.github.io/dvgo/img/post_toy2.png"/>
                    </p>
                </div>
                

                <p>
                    <b>Ablation study.</b> Up to 2.88 PSNR difference for novel-view synthesis.
                </p>
            </div>
        </div><div id="my_init">
            <div>
                <h4>Low-density initialization</h4>
                <p>
                    <b>Observation.</b>
                    The initial alpha values (activated from the volume densities) should be close to 0.
                    We introduce a hyperparameter <code>alpha-init</code> to control it.
                </p>

                <p><b>Ablation study.</b>
                The <code>alpha-init</code> should be small enough to achieve good quality and avoid <span>floater</span>.
                </p><div>
                    <p><img src="https://sunset1995.github.io/dvgo/img/low_density.png"/>
                    </p>
                </div>
                

                <p>
                    <b>Caveat.</b>
                    We empirically find that the qualities and the training times are sensitive to the <code>alpha-init</code>. We set <code>alpha-init</code> to 3 different values for bounded, unbounded inward-facing, and forward-facining datasets respectively. You may want to try a few different values for new datasets.
                </p>

                <p>
                    <b>ðŸ¤”</b>
                    It seems that the explicit (grid-based) representation needs careful regularizations, while the implicit (MLP network) doesn&#39;t.
                    We still don&#39;t know the root cause for this empirical finding at this moment.
                </p>
            </div>
        </div></div>
  </body>
</html>
