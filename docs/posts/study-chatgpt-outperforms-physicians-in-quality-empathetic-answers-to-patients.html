<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions">Original</a>
    <h1>Study: ChatGPT outperforms physicians in quality, empathetic answers to patients</h1>
    
    <div id="readability-page-1" class="page"><div id="content">



		
	
		


	<section id="feature-detail-hero">
		<p>   
			
					
			
			
			<h2>While AI won’t replace your doctor, the JAMA Internal Medicine paper suggests physicians working together with technologies like ChatGPT may revolutionize medicine</h2>
			
		</p>
		
		
		
			
				<!-- This hero holds a single image -->
				<div id="slideshow">
					<figure data-slideshow-item="" data-slideshow-image-src="https://today.ucsd.edu/news_uploads/ChatGPT_Media_Multimedia.jpg" data-slideshow-image-alt="Graphs show average quality and empathy ratings for chatbot vs physician responses to patient questions, with an average preference for chatbot responses" data-slideshow-image-caption="As part of a new JAMA Internal Medicine study, independent licensed healthcare professionals evaluated both quality (left) and empathy (right) for ChatGPT and physician responses to patient questions, preferring ChatGPT’s responses 79% of the time.">
						<p><img data-src="https://today.ucsd.edu/news_uploads/ChatGPT_Media_Multimedia.jpg" alt="Graphs show average quality and empathy ratings for chatbot vs physician responses to patient questions, with an average preference for chatbot responses"/>
						</p>
						
					   <figcaption>
					     As part of a new JAMA Internal Medicine study, independent licensed healthcare professionals evaluated both quality (left) and empathy (right) for ChatGPT and physician responses to patient questions, preferring ChatGPT’s responses 79% of the time.
					   </figcaption>
					   
					</figure>
				</div>
				
			
			
			
			
			
			
	</section>
	
		<section id="wysiwyg">
    
  
  
    
	 <!-- START DATE STORIES IN NEW FORMAT -->
	 
	 <!-- START OF AUTHORS-BLOCK FOR MOBILE  -->
	 
	 <!-- END OF AUTHORS-BLOCK FOR MOBILE -->
	 
	 

		  <!-- START NEW CONTENT BLOCK -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
		        <div>
			        
					  		<!-- START If this is the first module, we render the authors block -->
				           
				            <!-- START OF AUTHORS-BLOCK FOR DESKTOP  -->
				            
				            <!-- END OF AUTHORS-BLOCK FOR DESKTOP -->
				           
		               <!-- END If this is the first module, we render the authors block -->
		          
						<div>
							
							
							
						   <p>There has been widespread speculation about how advances in artificial intelligence (AI) assistants like ChatGPT could be used in medicine. </p>

<p>A new study published in <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/10.1001/jamainternmed.2023.1838?guestAccessKey=6d6e7fbf-54c1-49fc-8f5e-ae7ad3e02231&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=042823">JAMA Internal Medicine</a> led by <a href="http://www.johnwayers.com">John W. Ayers</a><u>,</u> Ph.D.<u>,</u> from <a href="https://qi.ucsd.edu/">the Qualcomm Institute at University of California San Diego</a> provides an early glimpse into the role that AI assistants could play in medicine. The study compared written responses from physicians and those from ChatGPT to real-world health questions. A panel of licensed healthcare professionals preferred ChatGPT’s responses 79% of the time and rated ChatGPT’s responses as higher quality and more empathetic. </p>

<p><span>“The opportunities for improving healthcare with AI are massive,” said </span>Ayers, who is also vice chief of innovation in the UC San Diego School of Medicine Division of Infectious Disease and Global Public Health. “<span>AI-augmented care is the future of medicine.” </span></p>

<p><b>Is ChatGPT Ready for Healthcare?</b></p>

<p>In the new study, the research team set out to answer the question: Can ChatGPT respond accurately to questions patients send to their doctors? If yes, AI models could be integrated into health systems to improve physician responses to questions sent by patients and ease the ever-increasing burden on physicians.</p>

<p>“ChatGPT might be able to pass a medical <a href="https://www.ama-assn.org/practice-management/digital/chatgpt-passed-usmle-what-does-it-mean-med-ed">licensing exam</a>,&#34; said study co-author Davey Smith, M.D., M.A.S., a <span>physician-scientist, co-director of the UC San Diego Altman Clinical and Translational Research Institute</span> and professor at the UC San Diego School of Medicine, “but directly answering patient questions accurately and empathetically is a different ballgame.” </p>

<p>“The COVID-19 pandemic accelerated virtual healthcare adoption,” added study co-author Eric Leas, Ph.D., M.P.H., a Qualcomm Institute affiliate and assistant professor in the UC San Diego Herbert Wertheim School of Public Health and Human Longevity Science. “While this made accessing care easier for patients, physicians are burdened by a barrage of electronic patient messages seeking medical advice that have contributed to <a href="https://www.mayoclinicproceedings.org/article/S0025-6196(22)00515-8/fulltext">record-breaking</a> levels of physician burnout.”</p>

<p><b>Designing a Study to Test ChatGPT in a Healthcare Setting</b></p>

<p>To obtain a large and diverse sample of healthcare questions and physician answers that did not contain identifiable personal information, the team turned to social media where millions of patients publicly post medical questions to which doctors respond: <a href="https://www.reddit.com/r/AskDocs/">Reddit’s AskDocs</a>. </p>

<p>r/AskDocs is a subreddit with approximately 452,000 members who post medical questions and verified healthcare professionals submit answers. While anyone can respond to a question, moderators verify healthcare professionals’ credentials and responses display the respondent’s level of credentials. The result is a large and diverse set of patient medical questions and accompanying answers from licensed medical professionals.</p>

<p>While some may wonder if question-answer exchanges on social media are a fair test, team members noted that the exchanges were reflective of their clinical experience. </p>

<p>The team randomly sampled 195 exchanges from AskDocs where a verified physician responded to a public question. The team provided the original question to ChatGPT and asked it to author a response. A panel of three licensed healthcare professionals assessed each question and the corresponding responses and were blinded to whether the response originated from a physician or ChatGPT. They compared responses based on information quality and empathy, noting which one they preferred.</p>

<p>The panel of healthcare professional evaluators preferred ChatGPT responses to physician responses 79% of the time. </p>

<p>“ChatGPT messages responded with nuanced and accurate information that often addressed more aspects of the patient’s questions than physician responses,” said Jessica Kelley, M.S.N, a nurse practitioner with San Diego firm Human Longevity and study co-author.   </p>

<p>Additionally, ChatGPT responses were rated significantly higher in quality than physician responses: good or very good quality responses were 3.6 times higher for ChatGPT than physicians (physicians 22.1% versus ChatGPT 78.5%). The responses were also more empathic: empathetic or very empathetic responses were 9.8 times higher for ChatGPT than for physicians (physicians 4.6% versus ChatGPT 45.1%). </p>

<p>“I never imagined saying this,” added Aaron Goodman, M.D., an associate clinical professor at UC San Diego School of Medicine and study coauthor, “but ChatGPT is a prescription I’d like to give to my inbox. The tool will transform the way I support my patients.”</p>

<p><b>Harnessing AI Assistants for Patient Messages  </b></p>

<p><span>“While our study pitted ChatGPT against physicians, the ultimate solution isn’t throwing your doctor out altogether,” said Adam Poliak, Ph.D., an assistant professor of Computer Science at Bryn Mawr College and study co-author. “Instead, a physician harnessing ChatGPT is the answer for better and empathetic care.”</span></p>

<p>“Our study is among the first to show how AI assistants can potentially solve real world healthcare delivery problems,” said Christopher Longhurst, M.D., M.S., Chief Medical Officer and Chief Digital Officer at UC San Diego Health. “These results suggest that tools like ChatGPT can efficiently draft high quality, personalized medical advice for review by clinicians, and we are beginning that <a href="https://www.modernhealthcare.com/digital-health/himss-2023-epic-microsoft-bring-openais-gpt-4-ehrs">process</a> at UCSD Health.” </p>

<p>Mike Hogarth, M.D., a physician-bioinformatician, co-director of the Altman Clinical and Translational Research Institute at UC San Diego, professor in the UC San Diego School of Medicine and study co-author, added, “It is important that integrating AI assistants into healthcare messaging be done in the context of a <span>randomized controlled trial</span> to judge how the use of AI assistants impact outcomes for both physicians and patients.”  </p>

<p><span>In addition to improving workflow, investments into AI assistant messaging could impact patient health and physician performance. </span></p>

<p><span>Mark Dredze, Ph.D., the John C Malone Associate Professor of Computer Science at Johns Hopkins and study co-author, noted: “We could use these technologies to train doctors in patient-centered communication, eliminate health disparities suffered by minority populations who often seek healthcare via messaging, build new medical safety systems, and assist doctors by delivering higher quality and more efficient care.” </span></p>

<p><span>In addition to Ayers, Poliak, Dredze, Leas, Kelley, Goodman, Longhurst, Hogarth and Smith, authors of the JAMA Internal Medicine paper, “Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum” (JAMA Intern Med. doi:</span><a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/10.1001/jamainternmed.2023.1838?guestAccessKey=6d6e7fbf-54c1-49fc-8f5e-ae7ad3e02231&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=042823"><span>10.1001/jamainternmed.2023.1838</span></a><span>), are Zechariah Zhu, B.S., of UC San Diego and Dr. Dennis J. Faix, M.D., M.P.H., of the Naval Health Research Center.  </span></p>
													
						</div>
					 
		          
		          <!-- START If block also has image, video, quote, or related stories -->
						 
						 <!-- START OF OPTIONAL VIDEO -->
						 
						 <!-- END OF OPTIONAL VIDEO -->
						 
						 <!-- START OF OPTIONAL SLIDESHOW -->
						  
						  <!-- END OF OPTIONAL SLIDESHOW -->
						
						 <!-- START OF OPTIONAL QUOTE -->
						 
						 <!-- END OF OPTIONAL QUOTE -->
						
						 <!-- START OF OPTIONAL RELATED-STORIES -->
						 
						 <!-- END OF OPTIONAL REATED-STORIES -->
						
						 <!-- START OF OPTIONAL IMAGE -->
						 
						 <!-- END OF OPTIONAL IMAGE -->
						 				 
		          <!-- END If block also has image, video, quote, or related stories -->	
		        </div>
		      </div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		    
		  <!-- END CONTENT BLOCK -->
		  
	
	  
      
  

  <!-- START TOPICS & SHARE MOBILE  -->
  
  <!-- END TOPICS & SHARE MOIBILE -->
</section>

	

	<div>
    <div>
    <section>
        
        
        <div>
            
               
                 <div>
                     
                     
                     
	                     <p><a href="https://today.ucsd.edu/story/probing-lithium-ions-near-a-solids-surface-reveals-clues-to-boost-solid-state-battery-performance" alt="Probing Lithium Ions Near a Solid’s Surface Reveals Clues to Boost Solid-State Battery Performance">
	                             <img srcset="https://today.ucsd.edu/news_uploads/_special-lead-mobile/lithium-solid-interface-UCSD-teaser.jpg 350w, https://today.ucsd.edu/news_uploads/_special-lead-desk/lithium-solid-interface-UCSD-teaser.jpg 864w" sizes="(min-width: 768px) 864px, 350px" data-src="https://today.ucsd.edu/news_uploads/_special-lead-desk/lithium-solid-interface-UCSD-teaser.jpg" alt="Probing Lithium Ions Near a Solid’s Surface Reveals Clues to Boost Solid-State Battery Performance" width="750" height="488"/>
	                         </a>
	                     </p>
                     
                     
                 </div>
               
            
            
        </div>
        
        
        
        
        <div>
            
               
                    <div>
                        
                        
                        
	                        <p><a href="https://today.ucsd.edu/story/probing-lithium-ions-near-a-solids-surface-reveals-clues-to-boost-solid-state-battery-performance" alt="Probing Lithium Ions Near a Solid’s Surface Reveals Clues to Boost Solid-State Battery Performance">
	                                <img srcset="https://today.ucsd.edu/news_uploads/_special-lead-mobile/lithium-solid-interface-UCSD-teaser.jpg 350w, https://today.ucsd.edu/news_uploads/_special-lead-desk/lithium-solid-interface-UCSD-teaser.jpg 864w" sizes="(min-width: 768px) 864px, 350px" data-src="https://today.ucsd.edu/news_uploads/_special-lead-desk/lithium-solid-interface-UCSD-teaser.jpg" alt="Probing Lithium Ions Near a Solid’s Surface Reveals Clues to Boost Solid-State Battery Performance" width="750" height="488"/>
	                            </a>
	                        </p>
                        
                    </div>
                 
            
            
        </div>
    </section>
    </div>
</div>
	<section id="subscribe">
  <div>
    <div>
      <div>
        <h2>Stay in the Know</h2>
        <p>Keep up with all the latest from UC San Diego. Subscribe
          to the newsletter today.
        </p>
      </div>
    </div>
    <div>
      <div>
        <form novalidate="" data-subscribe-form="" action="subscribe.html" method="post" data-form_type="newsletter_signup">
          <div>
            <p><label for="subscriber-email">
              Email
            </label>
            </p><div data-validation-message="email">
              <p>Please provide a valid email address.</p></div>
          </div>
          
        </form>
      </div>
    </div>
  </div>
</section>
<!-- START Subscribe Modal -->
<div id="subscribeConfirmation" tabindex="-1" aria-labelledby="subscribeConfirmationLabel" aria-hidden="true">
  <div>
    <div>
      
      <div>
        <h2>
          Thank you!
        </h2>
        <p>You have been successfully subscribed to the UC San Diego Today
          Newsletter.</p>
      </div>
      
    </div>
  </div>
</div>
<!-- STOP Subscribe Modal -->
			</div></div>
  </body>
</html>
