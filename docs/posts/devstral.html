<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mistral.ai/news/devstral">Original</a>
    <h1>Devstral</h1>
    
    <div id="readability-page-1" class="page"><div><div><p dir="ltr">Today we introduce Devstral, our agentic LLM for software engineering tasks. Devstral is built under a collaboration between Mistral AI and <a href="https://www.all-hands.dev/" target="_blank" rel="noopener">All Hands AI</a> ğŸ™Œ, and outperforms all open-source models on SWE-Bench Verified by a large margin. We release Devstral under the Apache 2.0 license.Â </p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a8f418f6-f7ee-4f21-8ab8-08bd76c37186.png?width=1600&amp;height=882" alt="Devstral Swe"/></p>
<h2 dir="ltr">Agentic LLMs for software development</h2>
<p dir="ltr">While typical LLMs are excellent at atomic coding tasks such as writing standalone functions or code completion, they currently struggle to solve real-world software engineering problems. Real-world development requires contextualising code within a large codebase, identifying relationships between disparate components, and identifying subtle bugs in intricate functions.Â </p>
<p dir="ltr">Devstral is designed to tackle this problem. Devstral is trained to solve real GitHub issues; it runs over code agent scaffolds such as OpenHands or SWE-Agent, which define the interface between the model and the test cases. Here, we show Devstralâ€™s performance on the popular SWE-Bench Verified benchmark, a dataset of 500 real-world GitHub issues which have been manually screened for correctness.</p>
<p dir="ltr">Devstral achieves a score of 46.8% on SWE-Bench Verified, outperforming prior open-source SoTA models by more than 6% points. When evaluated under the same test scaffold (OpenHands, provided by <a href="https://www.all-hands.dev/" target="_blank" rel="noopener">All Hands AI</a> ğŸ™Œ), Devstral exceeds far larger models such as Deepseek-V3-0324 (671B) and Qwen3 232B-A22B.Â </p>
<p dir="ltr">In the table below, we also compare Devstral to closed and open models evaluated under any scaffold (including ones custom for the model). Here, we find that Devstral achieves substantially better performance than a number of closed-source alternatives. For example, Devstral surpasses the recent GPT-4.1-mini by over 20%.Â </p>


<h2 dir="ltr">Versatile: local deployment â†”ï¸ enterprise use â†”ï¸ copilots</h2>
<p dir="ltr">Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an ideal choice for local deployment and on-device use. Coding platforms such as <a href="https://github.com/All-Hands-AI/OpenHands" target="_blank" rel="noopener">OpenHands</a> can allow the model to interact with local codebases and provide fast resolution to issues. To try it yourself, view the <a href="https://docs.all-hands.dev/modules/usage/llms/local-llms" target="_blank" rel="noopener">documentation</a> or <a href="https://www.youtube.com/watch?v=oV9tAkS2Xic" target="_blank" rel="noopener">tutorial video</a>.</p>
<p dir="ltr">The performance of the model also makes it a suitable choice for agentic coding on privacy-sensitive repositories in enterprises, especially ones subject to stringent security and compliance requirements.Â </p>
<p dir="ltr">Finally, if youâ€™re building or using an agentic coding IDE, plugin, or environment, Devstral is a great choice to add to your model selector.Â </p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">We release this model for free under an Apache 2.0 license for the community to build on, customize, and accelerate autonomous software development. To try it for yourself, head over to our <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noopener">model card</a>.Â </p>
<p dir="ltr">The model is also available on our API under the name devstral-small-2505 at the same price as Mistral Small 3.1: $0.1/M input tokens and $0.3/M output tokens.Â </p>
<p dir="ltr">Should you choose to self-deploy, you can download the model on <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noopener">HuggingFace</a>, <a href="https://ollama.com/library/devstral" target="_blank" rel="noopener">Ollama</a>, <a href="https://www.kaggle.com/models/mistral-ai/devstral-small-2505" target="_blank" rel="noopener">Kaggle</a>, <a href="https://docs.unsloth.ai/basics/devstral" target="_blank" rel="noopener">Unsloth</a>, <a href="https://lmstudio.ai/model/devstral-small-2505-MLX" target="_blank" rel="noopener">LM Studio</a>Â starting today.Â </p>
<p dir="ltr">For enterprise deployments that require fine-tuning on private codebases, or higher-fidelity customization such as continued pre-training or distilling Devstralâ€™s capabilities into other models, please <a href="https://mistral.ai/contact">contact us</a> to connect with our applied AI team.Â </p>
<h2 dir="ltr">Whatâ€™s next</h2>
<p dir="ltr">Devstral is a research preview and we welcome feedback! Weâ€™re hard at work building a larger agentic coding model that will be available in the coming weeks.</p>
<p dir="ltr">Interested in discussing how we can help your team put Devstral to use, and about our portfolio of models, products and solutions? <a href="https://mistral.ai/contact">Contact us</a> and weâ€™ll be happy to help.</p></div></div></div>
  </body>
</html>
