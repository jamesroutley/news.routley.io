<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/SubscriberLink/893686/8978976335696804/">Original</a>
    <h1>Modern Python Performance Considerations</h1>
    
    <div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
There is a lot of work going on right now on speeding up Python; Kevin
Modzelewski gave a presentation at 
<a href="https://us.pycon.org/2022/">PyCon 2022</a> on some of that
work.  Much of it has implications for Python programmers in terms of how
to best take advantage of these optimizations in their code.  He gave an
overview of some of the projects, the kinds of optimizations being worked
on, and provided some benchmarks to give a general idea of how much faster
various Python implementations are getting—and which operations are most affected.
</p>

<p>
Modzelewski works at <a href="https://www.anaconda.com/">Anaconda</a> on the <a href="https://www.pyston.org/">Pyston</a> 
&#34;optimized Python interpreter&#34;.  He wanted to focus on &#34;modern Python&#34; in
the talk; there are lots of tips about how to speed up Python code available,
but many of those are &#34;not quite as useful anymore&#34;.  There are some
new tips, however, that can be used with these up and coming optimized implementations, which
he wanted to talk about.
</p>

<h4>Why Python is slow</h4>

<p>
The first topic he raised, &#34;why Python is slow&#34;,  is somewhat divisive, he said;
everyone seems to have a different view on that, but he would be presenting
his personal views on it.
This is not the first time we have reported on a talk by Modzelewski on this
subject; he <a href="https://lwn.net/Articles/691243/">spoke at the 2016 Python Language
Summit</a> on the question of why the language is slow, along with a bit
about Pyston.
</p>

<p><a href="https://lwn.net/Articles/893959/">
<img src="https://static.lwn.net/images/2022/pycon-modzelewski-sm.png" alt="[Kevin Modzelewski]" title="Kevin Modzelewski" width="221" height="300"/>
</a></p><p>
The most common reason given is that interpreted languages are slow and,
since Python is interpreted, it is slow, but that is not what he has
found.  In his measurements of web servers, the overhead of interpretation
is about 10%; that is &#34;significant, and people don&#39;t want it, but it doesn&#39;t
explain why Python can be ten to 100 times slower than C&#34;. In order to
explain that, you need to look at the dynamic nature of Python.
</p>

<p>
&#34;Python is a very dynamic language&#34;, in lots of different ways, but he
wanted to focus on just a few of those in the talk.  The first is perhaps
the most obvious, the interpreter does not know the types of any of the
variables.  That means any operation on a variable needs to look up
what type it is in order to figure out how to perform the operation on that type.
</p>

<p>
The second dynamic behavior is in variable lookups, though that is a less
obvious one.  For example, &#34;<tt>print</tt>&#34; is not a keyword in Python, so
a simple print statement needs to look up the value for the
&#34;<tt>print</tt>&#34; name in order to call it as a function.  In particular, it
has to determine whether the name has been overridden by anything in the
scope and it has to do that every time <tt>print()</tt> is called.  The
same goes things like <tt>len()</tt>, <tt>int()</tt>, and many more
built-in functions; all of them require expensive lookups every time they
are used.
</p>

<p>
The third aspect is Python&#39;s dynamic attribute lookup.  In general, even in
a single class, the interpreter does not know what attributes exist on an
object of that class.  That means it needs a dynamic representation for the
object to track the
attributes.  Looking up the attributes in Python is pretty fast, but still
much slower than it would be if the list of attributes were static.
</p>

<p>
There are three separate projects that are currently being worked on to try
to speed up Python in various ways; all of them are &#34;coming out in various
forms either last year or this year&#34;.  There is his project, Pyston, which
is a fork of CPython, the <a href="https://github.com/faster-cpython/">Faster CPython</a> project that is being
worked on in the main CPython repository by a team at Microsoft, and there
is <a href="https://github.com/facebookincubator/cinder">Cinder</a>, which
is a fork of CPython that is being worked on at Instagram.  All of them are
available now in one form or another.
</p>

<h4>Benchmarks</h4>

<p>
The &#34;controversial slide&#34; of his talk did not look like much at the outset,
as it was just an empty table.  He would be filling it in with his
benchmarks of various projects over the next
part of the talk &#34;with a lot of disclaimers&#34;.  The first controversial
piece of that is the choice of which benchmarks to use to analyze performance.
</p>

<p>
There is the well-established <a href="https://pyperformance.readthedocs.io/">pyperformance benchmark</a>,
which is &#34;nice in a lot of ways&#34;.  It is a semi-standard that is used by a
lot of people for reporting Python benchmark numbers.  In his experience,
though, it tends to overstate performance benefits, so he likes to look
more at application code for benchmarks.
</p>

<p>
To that end, he wrote a benchmark using the <a href="https://flask.palletsprojects.com/en/2.1.x/">Flask web
framework</a>.  He chose Flask because it is one of the simpler Python web
frameworks, so he thought he would be able to get more of the projects
working with it.  He would be showing results for both of those benchmarks
for several different projects.
</p>

<p>
The &#34;next controversial thing&#34; is which CPython version to choose as a
baseline to measure the others against.  He chose Python 3.8 because
that is what Pyston is based on; all of the comparison numbers he presented
were in relation to that baseline.  He used the Ubuntu version of
Python 3.8 because it is one of the faster builds of that version of
Python.  He was surprised to find that different builds were significantly
faster or slower than others; Ubuntu is fast, while the macOS and Windows
builds are slow.
</p>

<p>
&#34;I get to list my project first&#34;, he said with a grin. He measured Pyston 2.3.2 as 62%
faster on pyperformance, but only 34% faster on the flask benchmark.  Those
numbers are quite different, obviously, and he was not claiming that one benchmark
was more accurate than the other.  It just shows that it is important to
choose a benchmark that is more representative of the kinds of programs you
will be running.
</p>

<p>
He moved on to Python 3.11a7 from early April, which includes most of the Faster
CPython work. &#34;They also show good improvements on both of these numbers.&#34;
On pyperformance, it was 15% faster; 10% faster for flask.  The Faster
CPython folks are reporting a different number for pyperformance, 25%,
but that is not what he measured; &#34;I don&#39;t know exactly where the 
difference is&#34;.
</p>

<p>
Cinder does not have releases, so he just grabbed the code from GitHub and
built it.  He got strange numbers that showed a marked decrease in
performance compared to Python 3.8 (-51% for pyperformance and -18% for
flask).  He put question marks next to those because he does not believe
they are real numbers; Instagram is using it internally and he doubts they
would be using something slower.  He wondered if perhaps there were patches
that were not yet released into the GitHub tree.
</p>

<p>
He also benchmarked two other projects, both of which use just-in-time
(JIT) compilers, <a href="https://www.pypy.org/">PyPy</a> and <a href="https://www.trypyjion.com/">Pyjion</a>.  PyPy is fairly well-known,
while Pyjion is less so, but he was curious to see the measurements for
them.  PyPy 7.3.9 is not able to run pyperformance because it does not
support all of its dependencies and it was 36% slower on flask, which he
believes reflects the different set of tradeoffs that PyPy has made.
Pyjion was effectively a bust since he measured it at 1000 times slower on
flask.  That number got a double question mark because he does not think
that reflects the numbers that the project is getting, but he &#34;did not have
time to sort all these things out before the talk, unfortunately&#34;.
</p>

<h4>What is being done</h4>

<p>
In a variety of ways, these projects are addressing the problems he
identified that contribute to making
Python slow.   The interpretation overhead is being addressed in projects
like Pyston and Cinder by way of JIT compilers.  They convert the Python
code as it is running into assembly instructions; &#34;this sort of
definitionally gets rid of interpretation overhead&#34;. While JIT compilation
is interesting from a technical perspective, he would not be talking much
about it because its gains come for free; the 10% overhead is nice to
get back, but programmers 
cannot affect it much.  Changing your code will not really make much
of a difference one way or the other to the performance gains that JIT compilation brings, he said.
</p>

<p>
In what he called a &#34;sweeping generalization&#34;, Modzelewski said that the three main
projects he was focusing on were applying the same &#34;bread and butter
technique&#34; in a variety of ways.  Those techniques are based on the idea
that most code &#34;does not use the full dynamic power that it could at any
given time&#34; and that Python can quickly check to see if they are using the
dynamic features.  If those features are not being used, the language can do
something fast instead of following the slower path needed to handle them.
</p>

<p>
That is the source of most of the speedups shown in the benchmarks.
It sounds great, he said, &#34;Python has dynamic features but you are not paying for them 
if you are not using them anymore.&#34;  You can turn that statement around,
however: you are paying for the dynamic features if you use them.  Those
features used to come for free, because you paid for them whether you used
them or not. 
</p>

<p>
But that situation has changed.  You do not need to avoid dynamic features,
and code will still get performance improvements if you continue to use
them.  But if you want to get the best performance possible, thinking about
these things, and avoiding those features where possible,  will make your code even faster, Modzelewski said.
</p>

<h4>Examples</h4>

<p>
The penalty for looking up built-ins (and other global variables) that he
described at the beginning of the talk is one of the areas that has been
optimized.  If the code is using lots of <tt>print()</tt> or <tt>len()</tt>
calls, for example, these newer Pythons speculate that that they have not
been reassigned since the last time the lookup was done.  It is easy in
CPython to know whether <i>any</i> global variable has been reassigned since the
last time the lookup was done; if not, the value of the lookup has to be
the same as it was the last time.  He showed two function definitions to demonstrate
what he meant by reassignment:
</p><pre>    def f():
	global l
	l = []
	# slow:
	print()

    def f():
	global l
	l.append(1)
	# not slow:
	print()
</pre><p>

In the first function, an explicitly global variable has been reassigned,
which means that the slower path needs to be used to look up </p><tt>print()</tt><p>.
In the second function, </p><tt>l</tt><p> has simply been mutated, which does not
affect the speed since no global reassignment has been done.
</p>

<p>
He showed his measurements of a benchmark both with and without
reassignments.  For Python 3.8, the times were the same (12.3ns),
which indicates that the price is paid in either case.  For Pyston, there
was a sizable reduction for the case with reassignments (9.5ns) and a huge
boost for the case without them (1.7ns).  Python 3.11a7 had a nearly
two-fold increase in speed even with reassignments (6.4ns), and a less
dramatic drop from there without them (5.9ns).
</p>

<p>
He cautioned that the numbers should not be taken too literally as he
thinks they will evolve rapidly.  He was a bit surprised by the
measurements and suspects that the Faster CPython team will get some ideas
from them as well.  But the overall conclusion is that, in modern Python, not
reassigning global variables will make the rest of the code run faster.  He
suggested that any needed global mutable state be stored in an object if
faster performance is the goal.
</p>

<p>
Attribute lookup is similar in some ways.  In general, an object&#39;s
attributes are stored in a dictionary, which has a fast hash table
implementation in Python, but it is still slower than in C where a value
can be retrieved using a pointer.  An individual attribute lookup is not
terribly slow, but Python programs do a <i>lot</i> of them so it adds up.
</p>

<p>
The technical details are rather complex, he said, but at a high level the
same idea is being applied to attributes: speculating that if a lookup
&#34;looks the same&#34; as the previous one, it can be executed the same way it
was done before.  He showed two ways that changing an object&#39;s &#34;shape&#34; will
affect its run-time performance:
</p><pre>    # different shape
    class Cls: pass
    obj1 = Cls()
    obj2 = Cls()
    obj1.x = 1
    obj2.y = 2

    # type mutated
    class Cls: pass
    obj = Cls()
    obj.x = 1
    Cls.y = 2
</pre><p>

In the first case, attribute lookup on the two objects will be slow for the
rest of the program once those statements have been executed.  There are a
lot of ways that a class can intercept the lookup of its attributes, 
but they are not usually used; the interpreter can know that
those interceptions have not been used before, but once the class itself is
changed, that situation may have changed. In the
second case, changing the class means that the current fast path for
class attribute lookup has to be bypassed because the
interpreter cannot know whether the change affects attribute lookups.
</p>

<p>
He made a benchmark to measure the two cases above and the &#34;happy case&#34;
where neither of those was done.  He reported those numbers, which showed
that both Pyston and Faster CPython improved things considerably in nearly
all of the cases, with the happy case showing roughly 6x speedup for Pyston
and 3x for Python 3.11a7. The baseline measurement showed that the
cost was much the same for all three, which demonstrates that the price of
doing these kinds of things is always being paid.
</p>

<p>
Once again, those numbers are going to change over time, but the general
idea is that avoiding those kinds of changes will improve the performance
of programs.  Changing the shape of the object is the worst of the two and
the code where he has seen that being done looks to him like it was meant
to be a memory-saving technique.  But doing so forces the interpreter to
use a less-efficient representation for the object, so that savings is
illusory.  In general, code should set attributes with the same names on
all objects of the same class, and
do so in the same order, if it can.  In passing, he noted that using <a href="https://docs.python.org/3/reference/datamodel.html#slots"><tt>__slots__</tt></a>
is now the fastest way to handle attributes on classes in Python.
</p>

<p>
Method calls are a special-case of attribute lookup where the attribute&#39;s
value is immediately used to call a function.  There is some old advice
that if you are repeatedly doing a method call, say in a loop, that
retrieving the method once before the loop and caching it to use inside the
loop is a way to get better
performance.  For Python 3.8, there is a noticeable improvement of
about 66% when doing so, but the newer Pythons actually see a performance
degradation.
</p>

<p>
The reason is that method calls is one of the areas where optimizations
have been focused and, in general, the new Pythons &#34;want to see more of your
code at once to optimize more of it, especially in this particular case&#34;.
But caching the method outside of the loop will mean that those
optimizations no longer apply.  That is most true for built-in types; for
methods on Python classes, there is still an improvement for caching the
method lookup, but it is much smaller for all three of the interpreters measured.
</p>

<p>
He also measured lookups for functions in modules.  He chose
<tt>math.sqrt()</tt> because it is effectively just a single instruction,
so everything measured is the overhead of the lookup and call.  There is an
improvement, especially in Python 3.8 (86%), for caching that lookup,
but it is fairly modest for the others (roughly 15% for both).  Maybe that
15% is enough, he said,  but it is quite a bit smaller than before. For more typical
calls from modules that actually perform some work, the savings is even
more modest in all cases. 
</p>

<p>
As attribute lookups get faster, the benefits of this caching technique get
smaller, Modzelewski said.  His personal advice is to stop caching method and
function lookups; it is not worth the mental overhead and readability hit.
As these optimized Pythons get smarter, the savings will get even smaller.
He did not think that kind of code should be removed from existing programs
but thinks that particular piece of advice can be left by the wayside going forward.
</p>

<h4>Other considerations</h4>

<p>
There are dynamic features in Python that are expensive now, but will
likely get even more expensive over time.  He did not go into any detail
about them, but pointed out that using some of them may have wide-ranging
effects because they inhibit some of the optimizations that are being
added.  So they are not just expensive where you are using them, but they
might affect the performance of other parts of the code.
</p>

<p>
A problem that the community needs to address is that attaching a profiler
to a Python program effectively disables almost all of the optimizations.
At least that is true for Pyston; he is not sure if it is the case
for Faster CPython or Cinder. It is, in general, a hard problem, he said;
developers may be profiling a different version of the code than will
actually be running.  There may need to be a different profiling API or
some other way to solve that problem.
</p>

<p>
The last thing Modzelewski wanted to talk about was C extensions, which are
generally used either for bindings to another language or for providing
better performance.  The common wisdom is to use <a href="https://cython.org/">Cython</a> or some other mechanism to convert
performance-critical code to C, &#34;but this situation is getting pretty murky
now&#34;. All of the optimizations that he had been talking about currently
only apply to Python code, so C extensions have a certain set of
optimizations, while the interpreter has a different set.  So which is
going to improve performance depends on which set is going to help your
code the most.
</p>

<p>
It is hard to give a good rubric for when to choose one over the other, but
he converted his attribute lookup benchmark to a C extension using Cython
to see.  It showed a good improvement over Python 3.8, but was far
worse for Pyston.  He apparently was unable to measure Faster CPython but
did not say why that was.  He noted that Cython does not do any of the
optimizations he had been talking about, but there is no barrier to doing
so that he is aware of, so those could be adopted by Cython over time.
</p>

<p>
His feeling is that object-oriented code is going to be helped more by the
new interpreters, while numeric code will continue to be improved using C
extensions. It is something that developers will need to verify for
themselves, however, as the situation is rather complicated right now.
Unfortunately there is not a lot of help available to guide developers
toward writing more performant Python; using these tips, doing experiments,
and benchmarking is the way forward at this point.
</p>

<p>
The overall goal of the new optimizations is to not make Python code pay
for dynamic features that it is not using.  That is great, he concluded, but it adds new
complexity to the decisions programmers will need to make when they are
trying to squeeze the best performance out of their code.  Avoiding
unneeded dynamic features, and finding other ways to accomplish the same
goals, is generally the new path to follow, though.
</p>

<p>
[I would like to thank LWN subscribers for supporting my trip to Salt Lake
City for PyCon.]
</p></div></div>
  </body>
</html>
