<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.kumio.org/posts/2025/01/bananapim7-hvm.html">Original</a>
    <h1>Setting Up an RK3588 SBC QEMU Hypervisor with ZFS on Debian</h1>
    
    <div id="readability-page-1" class="page"><div> <p>The <a href="https://wiki.banana-pi.org/Banana_Pi_BPI-M7">BananaPi M7</a><sup><a href="#user-content-fn-bpi-guide" id="user-content-fnref-bpi-guide" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> <sup><a href="#user-content-fn-bpi-wiki" id="user-content-fnref-bpi-wiki" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> aka <a href="https://www.armsom.org/sige7">ArmSoM-Sige7</a><sup><a href="#user-content-fn-armsom-docs" id="user-content-fnref-armsom-docs" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> has attractive specs for use as an efficient but capable device for small-scale server deployment. As it’s performant enough to be interesting for real-world mixed workloads with some margin, it makes sense to consider it as a KVM hypervisor. Very relevant for setting up a small private cloud (雲立て or “kumotate”). This article documents preparing such board for use as a general Linux server (using Armbian), and then setting it up as a KVM hypervisor (using QEMU and libvirtd) to run Linux virtual machines.</p>
<p><img alt="ArmSoM-Sige7" width="526" height="251" loading="lazy" decoding="async" src="https://blog.kumio.org/assets/sige7.BPA2qCOf_Z278sro.webp"/></p>
<p>Some interesting use-cases:</p>
<ul>
<li>Web server</li>
<li>DNS server</li>
<li>Mail server</li>
<li>Proxy / VPN gateway</li>
<li>Load balancer / Reverse proxy</li>
<li>Monitoring agent</li>
<li>Control plane node in orchestration mesh</li>
<li>Blockchain node</li>
<li>etc etc</li>
</ul>
<p>Whatever our intentions, there are some reasons we may want to run VMs on such a small machine:</p>
<ul>
<li>Isolation between workloads
<ul>
<li>Better control over resource contention: Your load balancer has less chance of bringing down your database and vice versa</li>
<li>Security: Less risk of information flowing between domains</li>
<li>OS upgrades and reboots: Reboot into fresh kernel without taking down the whole machine</li>
</ul>
</li>
<li>Ease of deployment
<ul>
<li>Allows you to rebuild (and configure) OS images centrally and deploy over the network</li>
<li>Atomic upgrades</li>
</ul>
</li>
<li>Dynamic resource provisioning
<ul>
<li>Networking and port assignment</li>
<li>Guest-specific kernel-level routing and filtering rules: Wire up VPN and proxy chains with the usual configuration</li>
</ul>
</li>
</ul>
<p>As the RK3588 SoC is relatively recent and the board newer, it still took some effort to figure out the right pieces to get a stable configuration with Debian. RK3588 compatibility is still not fully mainlined into the Linux kernel and you need the right device-tree overlay (dtb). This is expected for this class of boards and <a href="https://www.jeffgeerling.com/blog/2024/why-raspberry-pi-sbc-guy">why some people still prefer RasPis</a>. While we want as close to vanilla upstream Debian as possible, it does not run directly on the board. Patching it ourselves is not attractive. Hence we turn to Armbian.
We will also perform a rudimentary <a href="https://libvirt.org/manpages/libvirtd.html">libvirtd</a> installation and set it up to run <a href="https://www.qemu.org/">QEMU</a> virtual machines from a ZFS zpool on the attached m.2 NVME storage.</p>
<h3 id="hardware-notes">Hardware notes</h3>
<h4 id="spec-summary">Spec summary</h4>
<ul>
<li>8 core RK3588<sup><a href="#user-content-fn-rk3588" id="user-content-fnref-rk3588" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> CPU (4c Cortex-A76 @2.4GHz + 4c ARM Cortex-A55 @1.8GHz)</li>
<li>8/16/32 GB DDR4 LPDDR4 RAM</li>
<li>32/64/128 GB eMMC on-board storage</li>
<li>PCIe 3.0x4 PCIe m.2 port</li>
<li>2x 2.5GbE Realtek RTL8125 NICs</li>
<li>USB 3.0 up to 5Gbps</li>
<li>HDMI out</li>
<li>Wifi 6 (BCM43752 802.11ax)</li>
</ul>


<ul>
<li>This board is picky with NVMe drives. Drives that work fine in other computers will be especially slow, or not get detected at all (with or without associated dmesg errors). PCIe usability also varies kernel version. Some may reportedly only pick up the drive after a reboot. Keep track of known good kernel versions and drive models.</li>
<li>Ensure you have sufficient power supply. A typical 5V3A will probabably not be sufficient. Failing NVMe drive may also be indicative of power issues. You can use either:
<ul>
<li>PD 2.0</li>
<li>Fixed-voltage over USB-C port (9V/2A, 12V/2A, 15V/2A)</li>
</ul>
</li>
<li>Watch the thermals. The performance of the RK3588 brings heat and it needs cooling under load. The same may hold for your SSD.</li>
<li><a href="https://www.jeffgeerling.com/blog/2024/popular-rockchip-sbc-distro-limbo-after-maintainer-burns-out">Better vendor support for the kernel could be nice…</a></li>
</ul>
<h4 id="kernel-versions">Kernel versions</h4>
<p><a name="kernel-versions"></a>
It took some trial-and-error to identify a kernel which is both compatible with distribution ZFS and has working NVMe PCIe. Ubuntu <code dir="auto">noble-updates</code> repositories have OpenZFS <a href="https://packages.ubuntu.com/noble-updates/zfs-dkms"><code dir="auto">v2.2.2</code></a>, which does not have support for Linux Kernel 6.6+. Meanwhile, Debian <code dir="auto">bookworm-backports</code> provides <a href="https://packages.debian.org/bookworm-backports/zfs-dkms"><code dir="auto">v2.2.7</code></a>, supporting up to 6.12. This means we will build a <code dir="auto">bookworm</code> image.
Armbian has support for building the following kernel versions for BananaPi M7:</p>



































<table><thead><tr><th>Alias</th><th>Name</th><th>Version</th><th>Comment</th></tr></thead><tbody><tr><td><code dir="auto">vendor</code> <sup><a href="#user-content-fn-nico-benchmark" id="user-content-fnref-nico-benchmark" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup></td><td><code dir="auto">vendor-rk35xx</code></td><td><code dir="auto">6.1.75</code></td><td>NVMe unstable</td></tr><tr><td><code dir="auto">collabora</code> <sup><a href="#user-content-fn-collabora1" id="user-content-fnref-collabora1" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup> <sup><a href="#user-content-fn-collabora2" id="user-content-fnref-collabora2" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup> <sup><a href="#user-content-fn-collabora3" id="user-content-fnref-collabora3" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup></td><td><code dir="auto">collabora-rockchip-rk3588</code></td><td><code dir="auto">6.9.0</code></td><td>Does not even boot</td></tr><tr><td><code dir="auto">current</code></td><td><code dir="auto">current-rockchip-rk3588</code></td><td><code dir="auto">6.12.0</code></td><td>Works</td></tr><tr><td><code dir="auto">edge</code></td><td><code dir="auto">edge-rockchip-rk3588</code></td><td><code dir="auto">6.12.1</code></td><td>Untested</td></tr></tbody></table>
<h2 id="goals">Goals</h2>
<ul>
<li>Locally built Armbian image for flashing to microSD card
<ul>
<li><code dir="auto">/boot</code> and encrypted <code dir="auto">/</code> on microSD card</li>
<li>Remember that the eMMC is basically a non-replacable on-board microSD card. Consider this before you start writing heavily to it. For this excercise, we leave the on-board storage unused.</li>
</ul>
</li>
<li>cryptroot unlock either locally or remotely via SSH</li>
<li>ZFS zpool on NVME drive for VMs and data
<ul>
<li>Can be complemented with SATA-over-USB</li>
</ul>
</li>
</ul>
<p>In order to build a suitable custom Armbian image, we need to prepare our build environment. These notes are current as of Jan 2025. Armbian will by default attempt to build the image in a Docker container, which means you are not expected to install all further development dependencies on your build host.</p>
<h2 id="armbian-build-and-install">Armbian build and install</h2>
<p>This was performed on an Arch Linux amd64 host but should work on any reasonable Linux distribution.
Since the board and the host have different CPU architectures, we will have to rely on QEMU emulation without KVM.</p>
<h3 id="requirements">Requirements</h3>
<ul>
<li>BananaPi M7</li>
<li>microSD card</li>
<li>m.2 SSD
<ul>
<li>USB-C PSU</li>
<li>Either PD 2.0 or fixed-voltage (12v/15v/19v)</li>
</ul>
</li>
<li>Build host
<a href="https://wiki.archlinux.org/title/QEMU">QEMU</a> packages installed
<ul>
<li><code dir="auto">qemu-system-aarch64</code> and <code dir="auto">qemu-aarch64</code> under <code dir="auto">$PATH</code></li>
<li>Git</li>
<li>Docker
<ul>
<li>Current user is member of <code dir="auto">docker</code> group</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="setup-build-environment">Setup build environment</h3>
<p>Clone and fork <a href="https://docs.armbian.com/Developer-Guide_Overview/">Armbian Build Framework</a>.</p>
<div><pre data-language="bash"><code><div><p><span># Clone Armbian Build System</span></p></div><div><p><span>git</span><span> </span><span>clone</span><span> </span><span>https://github.com/armbian/build</span><span> </span><span>-b</span><span> </span><span>v24.11</span></p></div><div><p><span># Make a local branch for your configuration</span></p></div></code></pre></div>
<h3 id="build-armbian-image">Build Armbian image</h3>
<p>Issuing the following should proceed with the build inside a docker container:</p>
<div><pre data-language="bash"><code><div><p><span>  </span><span>NETWORKING_STACK=systemd-networkd</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_PASSPHRASE=changeme123</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_SSH_UNLOCK=yes</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_SSH_UNLOCK_PORT=</span><span>2020</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>ARTIFACT_IGNORE_CACHE=yes</span><span> </span><span>\</span></p></div></code></pre></div>
<details><summary>Getting errors?</summary>
<p>Refer to the <a href="https://docs.armbian.com/Developer-Guide_Build-Preparation/">Armbian documentation</a>.
You can iterate a bit tighter by working from a shell inside the build container:</p>
<div><pre data-language="bash"><code><div><p><span>  </span><span>NETWORKING_STACK=systemd-networkd</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_PASSPHRASE=changeme123</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_SSH_UNLOCK=yes</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>CRYPTROOT_SSH_UNLOCK_PORT=</span><span>2020</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>ARTIFACT_IGNORE_CACHE=yes</span><span> </span><span>\</span></p></div></code></pre></div>
</details>
<h3 id="flashing-the-image">Flashing the image</h3>
<p>If the build succeeded, you should find it under the <code dir="auto">output/</code> directory:</p>
<div><pre data-language="bash"><code><div><p><span>output/images/Armbian-unofficial_24.11.1_Bananapim7_bookworm_current_6.12.0-crypt_minimal.img</span></p></div><div><p><span>$</span><span> </span><span>file</span><span> </span><span>output/images/Armbian-unofficial_24.11.1_Bananapim7_bookworm_current_6.12.0-crypt_minimal.img</span></p></div><div><p><span>output/images/Armbian-unofficial_24.11.1_Bananapim7_bookworm_current_6.12.0-crypt_minimal.img:</span><span> </span><span>DOS/MBR</span><span> </span><span>boot</span><span> </span><span>sector</span><span>; </span><span>partition</span><span> </span><span>1</span><span> </span><span>:</span><span> [...]</span></p></div></code></pre></div>
<p>Plug in the microSD card to your host and flash the image to it:</p>
<div><pre data-language="bash"><code><div><p><span>sudo</span><span> </span><span>dd</span><span> </span><span>of=/dev/sdxx</span><span> </span><span>if=output/images/Armbian-unofficial_24.11.1_Bananapim7_noble_current_6.12.0-crypt_minimal.img</span><span> </span><span>bs=4M</span><span> </span><span>status=progress</span><span> &amp;&amp; </span><span>sync</span></p></div></code></pre></div>
<h3 id="first-boot">First boot</h3>
<p>Plug in monitor, keyboard, network, and the newly flashed microSD card before finally plugging in the power and letting the board turn on.
After a few seconds of both the red and green LEDs shinging, only the green LED should be active and you should see the screen turn on.</p>
<p>You should see a prompt for the passphrase of encrypted root partition on the monitor. If you have the Ethernet port connected to a network with DHCP, you should also be able to unlock it remotely already:</p>
<div><pre data-language="bash"><code><div><p><span>ssh</span><span> </span><span>-p</span><span> </span><span>2020</span><span> </span><span>root@192.168.1.123</span></p></div></code></pre></div>
<p>You should now be prompted for the passphrase we supplied in the build command. On a subsequent first login, Armbian’s login script asks us to create a default user:</p>

<p>After another reboot, the growroot script will expand the root partition to fill up the remainder of the card.</p>
<h4 id="basic-security">Basic security</h4>
<div><pre data-language="bash"><code><div><p><span># Upgrade system packages</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>update</span><span> &amp;&amp; </span><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>upgrade</span></p></div><div><p><span># Change the default passphrase</span></p></div><div><p><span>sudo</span><span> </span><span>cryptsetup</span><span> </span><span>luksChangeKey</span><span> </span><span>/dev/mmcblk1p2</span></p></div><div><p><span># Install and enable firewalld</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>firewalld</span><span> </span><span>nftables</span></p></div><div><p><span>sudo</span><span> </span><span>systemctl</span><span> </span><span>enable</span><span> </span><span>--now</span><span> </span><span>firewalld</span></p></div></code></pre></div>
<h2 id="storage-preparation">Storage preparation</h2>
<p>With the base OS set up (why don’t we shut down and take a backup ;)), it’s time to set up our storage pool. This is where we will store our VM images and dynamic data that we don’t want to thrash the SD card with. Even with a single drive, ZFS gives us:</p>
<ul>
<li>integrity guarantees through checksums - no silent corruption</li>
<li>instant snapshots, clones, and rollbacks</li>
<li>dynamic provisioning of volumes integrating with libvirt[^libvirt-zfs]</li>
<li>better use of memory for caching (ARC)</li>
<li>native encryption and compression</li>
</ul>
<p>…at the cost of:</p>
<ul>
<li>some performance and IO overhead</li>
<li>having to do all filesystem operations as root</li>
<li>kernel modules under a non-free license</li>
<li>one more thing to consider when switching kernel
<ul>
<li>OpenZFS tends to lag behind the Linux kernel a bit - staying on LTS is recommended.</li>
</ul>
</li>
</ul>
<p>Seems worth it. Let’s look at what we have:</p>
<div><pre data-language="bash"><code><div><p><span>NAME</span><span>             </span><span>MAJ:MIN</span><span> </span><span>RM</span><span>   </span><span>SIZE</span><span> </span><span>RO</span><span> </span><span>TYPE</span><span>  </span><span>MOUNTPOINTS</span></p></div><div><p><span>mmcblk0</span><span>          </span><span>179:0</span><span>    </span><span>0</span><span> </span><span>115.3G</span><span>  </span><span>0</span><span> </span><span>disk</span></p></div><div><p><span>mmcblk0boot0</span><span>     </span><span>179:32</span><span>   </span><span>0</span><span>     </span><span>4M</span><span>  </span><span>1</span><span> </span><span>disk</span></p></div><div><p><span>mmcblk0boot1</span><span>     </span><span>179:64</span><span>   </span><span>0</span><span>     </span><span>4M</span><span>  </span><span>1</span><span> </span><span>disk</span></p></div><div><p><span>mmcblk1</span><span>          </span><span>179:96</span><span>   </span><span>0</span><span>  </span><span>29.7G</span><span>  </span><span>0</span><span> </span><span>disk</span></p></div><div><p><span>├─mmcblk1p1</span><span>      </span><span>179:97</span><span>   </span><span>0</span><span>   </span><span>256M</span><span>  </span><span>0</span><span> </span><span>part</span><span>  </span><span>/boot</span></p></div><div><p><span>└─mmcblk1p2</span><span>      </span><span>179:98</span><span>   </span><span>0</span><span>     </span><span>9G</span><span>  </span><span>0</span><span> </span><span>part</span></p></div><div><p><span>  </span><span>└─armbian-root</span><span> </span><span>252:0</span><span>    </span><span>0</span><span>     </span><span>9G</span><span>  </span><span>0</span><span> </span><span>crypt</span><span> </span><span>/</span></p></div><div><p><span>zram0</span><span>            </span><span>251:0</span><span>    </span><span>0</span><span>  </span><span>15.5G</span><span>  </span><span>0</span><span> </span><span>disk</span><span>  [SWAP]</span></p></div><div><p><span>nvme0n1</span><span>          </span><span>259:0</span><span>    </span><span>0</span><span> </span><span>238.5G</span><span>  </span><span>0</span><span> </span><span>disk</span></p></div></code></pre></div>
<p>Looking good.</p>
<details><summary>nvme drive doesn&#39;t show?</summary>
First look if it&#39;s mentioned at all in kernel logs:
<div><pre data-language="bash"><code><div><p><span>sudo</span><span> </span><span>dmesg</span><span> </span><span>-T</span><span> </span><span>|</span><span> </span><span>grep</span><span> </span><span>-Ei</span><span> </span><span>-U1</span><span> </span><span>&#39;</span><span>nvm|pci</span><span>&#39;</span></p></div></code></pre></div>
<p>See notes under <a href="#kernel-versions">kernel versions</a>.</p>
</details>
<p>Verify prerequisites and install packages:</p>
<div><pre data-language="bash"><code><div><p><span># zfs module should already be available</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>zpool</span><span> </span><span>list</span></p></div><div><p><span># if module not available:</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>modprobe</span><span> </span><span>zfs</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>zpool</span><span> </span><span>list</span></p></div><div><p><span> </span><span>if</span><span> </span><span>module</span><span> </span><span>still</span><span> </span><span>not</span><span> </span><span>available:</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>zfs-dkms</span><span> </span><span>zfs-zed</span><span> </span><span>zfsutils-linux</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>pciutils</span><span> </span><span>hdparm</span><span> </span><span>smartmontools</span><span> </span><span>nvme-cli</span></p></div></code></pre></div>
<h3 id="zpool-creation">zpool creation</h3>
<p>We should enable encryption here as well. While it’s possible to use a passphrase for the encryption of the zpool (like we do with the LUKS encryption of the root filesystem), it’s annoying and redundant to manually type multiple passphrases on each reboot. Instead, we can piggyback on the LUKS encryption by storing the encryption file for the VM zpool on the encrypted root filesystem.</p>
<details><summary>caveat</summary>
Storing the encryption key directly on the root filesystem does increase exposure of the key material during runtime. This is not ideal and could be improved upon.
In lack of proper hardware keys, one could still do better by instead storing the keyfile on a separate partition which is only available for unlock and then unmounted.
</details>
<p>Now we can go ahead and generate the key and create the zpool:</p>
<div><pre data-language="bash"><code><div><p><span>root@janice:/home/user#</span><span> </span><span>mkdir</span><span> </span><span>/root/keys</span></p></div><div><p><span>root@janice:/home/user#</span><span> </span><span>chmod</span><span> </span><span>0700</span><span> </span><span>/root/keys</span></p></div><div><p><span>root@janice:~/keys#</span><span> </span><span>umask</span><span> </span><span>0277</span></p></div><div><p><span>root@janice:~/keys#</span><span> </span><span>dd</span><span> </span><span>if=/dev/urandom</span><span> </span><span>bs=</span><span>32</span><span> </span><span>count=</span><span>1</span><span> </span><span>of=/root/keys/janice1-vm1.zfskey</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>zpool</span><span> </span><span>create</span><span> </span><span>-oashift=12</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>-Onormalization=formD</span><span> </span><span>-Outf8only=on</span><span> </span><span>-Oxattr=sa</span><span> </span><span>-Oacltype=posix</span><span> </span><span>-Ocanmount=off</span><span> </span><span>-Omountpoint=none</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>-Oatime=off</span><span> </span><span>-Orelatime=off</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>-Ocompression</span><span>=</span><span>zstd-fast</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>-Oencryption=aes-256-gcm</span><span> </span><span>-Okeyformat=raw</span><span> </span><span>-Okeylocation=file:///root/keys/janice1-vm1.zfskey</span><span> </span><span>\</span></p></div></code></pre></div>
<p>Since we only have one drive we can’t make a mirror but can get some peace of mind from <code dir="auto">copies=2</code>. Creating the zpool creates an associated dataset (~thin volume+filesystem) which we do not mount directly. Instead we create child datasets (<code dir="auto">zfs create janice1/tank</code>) and zvols (<code dir="auto">zfs create -V 10G janice1/tank</code>) for actual use.</p>
<p>For now, we can prepare a dataset where VM images can be stored and mount it on libvirt’s default image path <code dir="auto">/var/lib/libvirt/images</code>:</p>
<div><pre data-language="bash"><code><div><p><span># confirm that we don&#39;t mount over anything existing</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>ls</span><span> </span><span>-la</span><span> </span><span>/var/lib/libvirt/images</span></p></div><div><p><span>ls:</span><span> </span><span>cannot</span><span> </span><span>access</span><span> </span><span>&#39;</span><span>/var/lib/libvirt/images</span><span>&#39;</span><span>:</span><span> </span><span>No</span><span> </span><span>such</span><span> </span><span>file</span><span> </span><span>or</span><span> </span><span>directory</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>zfs</span><span> </span><span>create</span><span> </span><span>-ocanmount=on</span><span> </span><span>-omountpoint=/var/lib/libvirt/images</span><span> </span><span>janice1/vm-images</span></p></div><div><p><span># check out the fresh dataset</span></p></div><div><p><span>user@janice1:~$</span><span> </span><span>sudo</span><span> </span><span>zfs</span><span> </span><span>list</span></p></div><div><p><span>NAME</span><span>                      </span><span>USED</span><span>  </span><span>AVAIL</span><span>  </span><span>REFER</span><span>  </span><span>MOUNTPOINT</span></p></div><div><p><span>janice1</span><span>                    </span><span>400K</span><span>   </span><span>229G</span><span>   </span><span>196K</span><span>  </span><span>none</span></p></div><div><p><span>janice1/vm-images</span><span>          </span><span>200K</span><span>   </span><span>229G</span><span>   </span><span>200K</span><span>  </span><span>/var/lib/libvirt/images</span></p></div><div><p><span>user@janice1:~$</span><span> </span><span>sudo</span><span> </span><span>zfs</span><span> </span><span>get</span><span> </span><span>mounted</span></p></div><div><p><span>NAME</span><span>                               </span><span>PROPERTY</span><span>  </span><span>VALUE</span><span>    </span><span>SOURCE</span></p></div><div><p><span>janice1/vm-images</span><span>                   </span><span>mounted</span><span>   </span><span>yes</span><span>      </span><span>-</span></p></div></code></pre></div>
<h3 id="auto-mount-encrypted-zfs-dataset-on-boot">Auto-mount encrypted zfs dataset on boot</h3>
<p>On Debian, automating importing of zpools and mounting of datasets is handled by a set of systemd units:</p>
<div><pre data-language="bash"><code><div><p><span>user@janice1:~$</span><span> </span><span>systemctl</span><span> </span><span>list-unit-files</span><span> </span><span>|</span><span> </span><span>grep</span><span> </span><span>-E</span><span> </span><span>&#39;</span><span>^UNIT|zfs</span><span>&#39;</span><span> </span><span>|</span><span> </span><span>sort</span></p></div><div><p><span>zfs-import-cache.service</span><span>                   </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-import-scan.service</span><span>                    </span><span>disabled</span><span>        </span><span>disabled</span></p></div><div><p><span>zfs-import.service</span><span>                         </span><span>masked</span><span>          </span><span>enabled</span></p></div><div><p><span>zfs-import.target</span><span>                          </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-load-key.service</span><span>                       </span><span>masked</span><span>          </span><span>enabled</span></p></div><div><p><span>zfs-load-module.service</span><span>                    </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-mount.service</span><span>                          </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-scrub-monthly@.timer</span><span>                   </span><span>disabled</span><span>        </span><span>enabled</span></p></div><div><p><span>zfs-scrub@.service</span><span>                         </span><span>static</span><span>          </span><span>-</span></p></div><div><p><span>zfs-scrub-weekly@.timer</span><span>                    </span><span>disabled</span><span>        </span><span>enabled</span></p></div><div><p><span>zfs-share.service</span><span>                          </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs.target</span><span>                                 </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-trim-monthly@.timer</span><span>                    </span><span>disabled</span><span>        </span><span>enabled</span></p></div><div><p><span>zfs-trim@.service</span><span>                          </span><span>static</span><span>          </span><span>-</span></p></div><div><p><span>zfs-trim-weekly@.timer</span><span>                     </span><span>disabled</span><span>        </span><span>enabled</span></p></div><div><p><span>zfs-volumes.target</span><span>                         </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-volume-wait.service</span><span>                    </span><span>enabled</span><span>         </span><span>enabled</span></p></div><div><p><span>zfs-zed.service</span><span>                            </span><span>enabled</span><span>         </span><span>enabled</span></p></div></code></pre></div>
<p>After a reboot, we should have our zpool imported by <code dir="auto">zfs-import-cache.service</code> and the dataset(s) mounted by <code dir="auto">zfs-mount.service</code>. This typically works out of the box for unencrypted datasets. For encrypted datasets, however, <code dir="auto">zfs-load-key.service</code> doesn’t seem to work as expected even if unmasked and enabled, meaning a <code dir="auto">manual zfs load-key -a</code> is required before the mounting can proceed.</p>
<p>To rectify this and have the key automatically load at boot, we can add a simple systemd override to the <code dir="auto">zfs-import.service</code> unit:</p>
<div><pre data-language="bash"><code><div><p><span>user@janice1:~$</span><span> </span><span>sudo</span><span> </span><span>mkdir</span><span> </span><span>/etc/systemd/system/zfs-mount.service.d</span></p></div><div><p><span>user@janice1:~$</span><span> </span><span>cat</span><span> </span><span>&lt;&lt;</span><span>EOT</span><span> </span><span>|</span><span> </span><span>sudo</span><span> </span><span>tee</span><span> </span><span>/etc/systemd/system/zfs-mount.service.d/override.conf</span></p></div><div><p><span>ExecStart=/sbin/zfs mount -a -l</span></p></div></code></pre></div>
<p>By using an override, we ensure that the change does not get undone by a future package upgrade.</p>
<p>Now we should see the encrypted dataset mounted after rebooting.</p>
<h2 id="hypervisor-setup">Hypervisor setup</h2>
<p>Time to install libvirtd and get ready to run some VMs! As often the case, <a href="https://wiki.archlinux.org/title/Libvirt">Arch wiki</a> is a good starting reference even on Debian.</p>
<h3 id="libvirtd-installation">Libvirtd installation</h3>
<p>This will install the necessary packages to run libvirtd as a hypervisor for QEMU VMs using default configuration:</p>
<div><pre data-language="bash"><code><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>libvirt-{daemon,daemon-system,daemon-driver-qemu,clients-qemu,login-shell,daemon-driver-storage-zfs}</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>libnss-mymachines</span><span> </span><span>libxml2-utils</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>dnsmasq</span><span> </span><span>dns-root-data</span><span> </span><span>ipset</span><span> </span><span>iptables</span><span> </span><span>python3-cap-ng</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>ipxe-qemu</span><span> </span><span>qemu-{kvm,utils,efi-aarch64,block-extra,efi-arm}</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>dmidecode</span><span> </span><span>mdevctl</span><span> </span><span>fancontrol</span></p></div><div><p><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>\</span></p></div><div><p><span>  </span><span>curl</span><span> </span><span>htop</span><span> </span><span>ncdu</span><span> </span><span>neovim</span><span> </span><span>netcat-openbsd</span><span> </span><span>tcpdump</span><span> </span><span>tar</span><span> </span><span>tmux</span><span> </span><span>wget</span><span> </span><span>unzip</span><span> </span><span>xz-utils</span></p></div><div><p><span># start libvirtd and enable on boot</span></p></div><div><p><span>sudo</span><span> </span><span>systemctl</span><span> </span><span>enable</span><span> </span><span>--now</span><span> </span><span>libvirtd</span></p></div></code></pre></div>
<h3 id="running-a-vm">Running a VM</h3>
<p>As a “hello world”, let’s verify that we can install and run a vanilla debian netinst image using <a href="https://github.com/virt-manager/virt-manager/blob/v4.1.0/man/virt-install.rst"><code dir="auto">virt-install</code></a>:</p>
<div><pre data-language="bash"><code><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>apt</span><span> </span><span>install</span><span> </span><span>--no-install-recommends</span><span> </span><span>virtinst</span></p></div><div><p><span># start debian installation on new domain (vm) terry</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>virt-install</span><span> </span><span>--name</span><span> </span><span>terry</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>--memory</span><span> </span><span>2048</span><span> </span><span>--vcpus</span><span> </span><span>2</span><span> </span><span>--os-variant=debian11</span><span> </span><span>--graphics</span><span> </span><span>none</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>--cdrom</span><span> </span><span>http://cdimage.debian.org/cdimage/release/12.9.0/arm64/iso-cd/debian-12.9.0-arm64-netinst.iso</span><span> </span><span>\</span></p></div><div><p><span>    </span><span>--disk</span><span> </span><span>path=/var/lib/libvirt/images/testdeb.qcow2,bus=virtio,format=qcow2,size=</span><span>10</span></p></div></code></pre></div>
<p><img alt="debian netinst splash running" width="1050" height="277" loading="lazy" decoding="async" src="https://blog.kumio.org/assets/netinst.xvC7zAd9_2350Fa.webp"/>
<em>It’s alive! the pon̷y he comes</em></p>
<p>Note that user domains and root domains are in separate namespaces so make sure to be consistent if you <code dir="auto">sudo</code> or not:</p>
<div><pre data-language="bash"><code><div><p><span>user@janice:~$</span><span> </span><span>sudo</span><span> </span><span>virsh</span><span> </span><span>--all</span></p></div><div><p><span>user@janice:~$</span><span> </span><span>virsh</span><span> </span><span>list</span><span> </span><span>--all</span></p></div></code></pre></div>
<p>In order to completely remove the VM <strong>and wipe all storage</strong>:</p>
<div><pre data-language="bash"><code><div><p><span>virsh</span><span> </span><span>undefine</span><span> </span><span>--remove-all-storage</span><span> </span><span>--nvram</span><span> </span><span>terry</span></p></div></code></pre></div>
<p>That’s all for today!</p>
<hr/>
<p><code dir="auto">2025-01</code></p>
<hr/>
 </div></div>
  </body>
</html>
