<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mlcontests.com/neurips-2023/expo-day/">Original</a>
    <h1>NeurIPS 2023: Expo Day</h1>
    
    <div id="readability-page-1" class="page"><div>
    
    <article>
        <p>Sunday was Expo day — featuring a mixture of talks, workshops, and demonstrations.</p>
<h3 id="small-large-language-models">
<em>Small</em> Large Language Models<a href="#small-large-language-models">
    <i></i>
</a></h3><p>One recurring theme throughout the Expo was efficiency — (how) can we do more with less?</p>
<p>Less power, fewer model parameters, smaller chips, …</p>
<p>The most popular session based on attendee numbers in the conference app
(and judging by people being unable to get into the room, causing the talk to be repeated later in a larger room)
was a talk by Amazon titled “Smaller models can pack a punch in the era of large language models”.
The talk explored how
relatively small 7-billion-parameter models like Mistral 7B are able to outperform 13B models,
and be competitive in some areas against other models with as many as 34B parameters.</p>
<p>Other sessions around efficiency in generative applications included Qualcomm’s demonstration of running Stable Diffusion
on their Snapdragon mobile processor; Positron AI introducing their new inference chips which aim to operate at significantly
improved performance/watt and performance/$ compared to the current state-of-the-art, and AMD’s talk on improving energy
efficiency through quantization.</p>
<figure>
    <img src="https://mlcontests.com/neurips-2023/expo-day/images/positron_ai.jpeg" alt="Positron AI’s inference chip"/>
    
    <figcaption>Positron AI’s inference chip</figcaption>
    
</figure>
<p>This will remain a theme throughout the rest of the week — for example, in the <a href="https://neurips.cc/virtual/2023/session/74037">Efficient Learning</a>
Oral Session (Tuesday 3:40-4:40pm, including <a href="https://arxiv.org/abs/2305.14314">QLoRA</a> at 3:55pm) and the <a href="https://llm-efficiency-challenge.github.io/">LLM Efficiency Challenge</a> (Friday 1.30pm-4.30pm),
with the latter exploring what teams can achieve by fine-tuning on a single GPU for 24 hours.</p>
<h3 id="other-talks">
Other talks<a href="#other-talks">
    <i></i>
</a></h3><p>Some brief highlights from other sessions…</p>
<p>Amazon’s AutoML talk did a great job of introducing version 1.0 of their open-source <a href="https://github.com/autogluon/autogluon">AutoGluon</a> library.
Helpfully, the workshop has an <a href="https://autogluon.github.io/neurips-autogluon-workshop/?ref=mlcontests">accompanying website</a> with various helpful resources
including cheatsheets and some Colab notebooks to get started.</p>
<figure>
    <img src="https://mlcontests.com/neurips-2023/expo-day/images/autogluon.png" alt="AutoGluon"/>
    
    <figcaption>Source: <a href="https://docs.google.com/presentation/d/1vKi7_kZsE0gckOOdRagsEnLgp5QUFZKH/edit#slide=id.p41">AWS Presentation</a></figcaption>
    
</figure>
<p>Many of the talks were very well-attended, and not just the ones related to generative models. Other notably popular talks
were MathWorks’ Reinforcement Learning talk, Google’s Graph Learning talk, and Microsoft’s Autonomous Agents talk.</p>
<figure>
    <img src="https://mlcontests.com/neurips-2023/expo-day/images/astrazeneca.jpeg" alt="AstraZeneca’s talk on AI &amp; ML Across the Entire Drug Development Pipeline"/>
    
    <figcaption>AstraZeneca’s talk on AI &amp; ML Across the Entire Drug Development Pipeline</figcaption>
    
</figure>
<p>Tomorrow is the start of the main conference, starting with the <a href="https://blog.neurips.cc/2023/07/18/announcing-the-neurips-2023-affinity-workshops/">Affinity Workshops</a>,
followed by the <a href="https://blog.neurips.cc/2023/11/06/introducing-the-neurips-2023-tutorials/">Tutorials</a>,
the first of the <a href="https://blog.neurips.cc/2023/12/10/announcing-neurips-2023-invited-talks/">Invited Talks</a> at 5:25pm,
a welcome reception, and the first of the <a href="https://blog.neurips.cc/2023/05/02/call-for-neurips-creative-ai-track/">Creative AI Performances</a> at 6:30pm.</p>
<p>Keep an eye on our <a href="https://mlcontests.com/neurips-2023">NeurIPS 2023</a> page for more daily blogs as the week goes on.</p>

    </article>
</div></div>
  </body>
</html>
