<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://daniel.lawrence.lu/blog/2025-09-21-line-scan-camera-image-processing/">Original</a>
    <h1>Line scan camera image processing</h1>
    
    <div id="readability-page-1" class="page"><div>
<header>

<p>2025-09-21</p>
</header>
<p>I use my line scan camera to take cool pictures of trains and other stuff.</p>
<p>But there’s a lot that goes into properly processing the images.</p>
<figure id="fig1"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-600.jpg" alt="" width="600" height="392" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-3840.jpg 3840w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig1">FIGURE 1</a> A cool tram.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-600.jpg">600 × 392</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-1200.jpg">1200 × 784</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-2400.jpg">2400 × 1568</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa-3840.jpg">3840 × 2509</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_a8414d74520f4baa.jpg">original 6270 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig2"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-600.jpg" alt="" width="1200" height="150" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig2">FIGURE 2</a> A cool train, the Renfe AVE Class 102, nicknamed <em>Pato</em> because of its duck bill-like appearance.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-600.jpg">600 × 75</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-1200.jpg">1200 × 150</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-2400.jpg">2400 × 300</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-3840.jpg">3840 × 480</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f-7680.jpg">7680 × 960</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_0d9fee240b0c6e5f.jpg">original 32768 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig3"><img src="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-600.jpg" alt="" width="600" height="339" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-600.jpg 600w, https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-1200.jpg 1200w, https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-2400.jpg 2400w, https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-3840.jpg 3840w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig3">FIGURE 3</a> Cool diesel locomotive.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-600.jpg">600 × 339</a></li><li><a href="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-1200.jpg">1200 × 678</a></li><li><a href="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-2400.jpg">2400 × 1357</a></li><li><a href="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e-3840.jpg">3840 × 2171</a></li><li><a href="https://i.dllu.net/rgb_9_prod_no_denoise_20704300acae5f1e.jpg">original 7246 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig4"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-600.jpg" alt="" width="1200" height="300" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig4">FIGURE 4</a> Nice CRH6A intercity electric multiple unit.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-600.jpg">600 × 150</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-1200.jpg">1200 × 300</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-2400.jpg">2400 × 600</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-3840.jpg">3840 × 960</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00-7680.jpg">7680 × 1920</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_dd93f40ada264e00.jpg">original 16384 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig5"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-600.jpg" alt="" width="1200" height="300" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig5">FIGURE 5</a> Awesome CR400AF. Super fast.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-600.jpg">600 × 150</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-1200.jpg">1200 × 300</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-2400.jpg">2400 × 600</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-3840.jpg">3840 × 960</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a-7680.jpg">7680 × 1920</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_685eacc3349ba19a.jpg">original 16384 × 4096</a></li></ul></nav></details></figcaption></figure>

<p>The way it works is that the camera has a single column of pixels (or in this case, two columns), that scans at a super high speed.
The camera is stationary, but as a train moves past it, it gets scanned.</p>
<p>This is essentially also how a <a href="https://en.wikipedia.org/wiki/Photo_finish">photo finish camera</a> works.</p>
<p>Since the background is static, it gets repeated for every column of the image, giving it its distinctive striped look.</p>
<figure id="fig6"><img src="https://i.dllu.net/Strip_photography_principle.svg" alt="" width="600" height="400" loading="lazy" decoding="async" srcset="https://i.dllu.net/Strip_photography_principle.svg 600w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig6">FIGURE 6</a> Principle of operation of a line scan camera, which produces an image where the horizontal dimension is time rather than space. <a href="https://en.wikipedia.org/wiki/File:Strip_photography_principle.svg">source: cmglee on Wikimedia Commons</a></p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/Strip_photography_principle.svg">Original</a></li></ul></nav></details></figcaption></figure>
<figure id="fig7"><img src="https://i.dllu.net/Triple_dead-heat-600.jpg" alt="" width="462" height="600" loading="lazy" decoding="async" srcset="https://i.dllu.net/Triple_dead-heat-600.jpg 600w, https://i.dllu.net/Triple_dead-heat.jpg 1039w" sizes="(max-width: 462px) 100vw, 462px"/><figcaption><p><a href="#fig7">FIGURE 7</a> A 1953 photo finish. <a href="https://en.wikipedia.org/wiki/File:Triple_dead-heat.jpg">source</a></p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/Triple_dead-heat-462.jpg">462 × 600</a></li><li><a href="https://i.dllu.net/Triple_dead-heat-600.jpg">600 × 779</a></li><li><a href="https://i.dllu.net/Triple_dead-heat.jpg">original 1039 × 1349</a></li></ul></nav></details></figcaption></figure>
<p>Line scan cameras are very suitable for capturing trains, since I can capture the full length of the train with minimal perspective distortion.
This is super nice for train nerds who want to make models of the trains.
Also, as you keep the camera running, you can get incredibly high resolution photos that span over 100,000 pixels wide.</p>
<p>By the way, film photo finish cameras and strip cameras behave almost the same as line scan cameras but with one subtle distinction, which is that you have to pull the film across a strip that’s somewhat wider than a single column of pixels.
This is because film is less sensitive than modern digital image sensors.
However, you’ll need to know the approximate speed of the subject and pull the film across at roughly the right speed.</p>

<p>I’m using an <a href="https://www.alkeria.com/products/necta-series">Alkeria Necta N4K2-7C</a>.
It has a 4096×2 <a href="https://en.wikipedia.org/wiki/Bayer_filter">Bayer array</a> image sensor.
I’m saving its raw data in 16 bit binary arrays.</p>
<figure id="fig8"><img src="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-600.jpg" alt="" width="600" height="450" loading="lazy" decoding="async" srcset="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-600.jpg 600w, https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-1200.jpg 1200w, https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-2400.jpg 2400w, https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-3840.jpg 3840w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig8">FIGURE 8</a> My camera.</p><details><summary>EXIF data</summary><dl><dt>Camera</dt><dd>FUJIFILM GFX100S</dd><dt>Lens</dt><dd>125</dd><dt>Aperture</dt><dd>f/NaN</dd><dt>Shutter</dt><dd><data value="12">12.0 s</data></dd><dt>ISO</dt><dd><data value="100">ISO 100</data></dd><dt>Software</dt><dd>darktable 4.8.1</dd><dt>Date</dt><dd><time datetime="2024-09-12T18:31:00">2024-09-12 18:31:00</time></dd></dl></details><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-600.jpg">600 × 450</a></li><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-1200.jpg">1200 × 900</a></li><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-2400.jpg">2400 × 1799</a></li><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-3840.jpg">3840 × 2879</a></li><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5-7680.jpg">7680 × 5758</a></li><li><a href="https://i.dllu.net/2024-09-12-18-31-00_DSCF0249_d644edd144f26bdabd7a876eda224c2a673ad9ec_d6e13378a10243e5.jpg">original 11662 × 8744</a></li></ul></nav></details></figcaption></figure>
<figure id="fig9"><img src="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-600.jpg" alt="" width="600" height="400" loading="lazy" decoding="async" srcset="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-600.jpg 600w, https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-1200.jpg 1200w, https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-2400.jpg 2400w, https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-3840.jpg 3840w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig9">FIGURE 9</a> Image sensor of my camera.</p><details><summary>EXIF data</summary><dl><dt>Camera</dt><dd>SONY ILCE-7RM2</dd><dt>Lens</dt><dd>----</dd><dt>Aperture</dt><dd><data value="0">f/0.0</data></dd><dt>Shutter</dt><dd><data value="0.005">1/200 s</data></dd><dt>ISO</dt><dd><data value="100">ISO 100</data></dd><dt>Software</dt><dd>ILCE-7RM2 v3.30</dd><dt>Date</dt><dd><time datetime="2018-11-30T09:43:59">2018-11-30 09:43:59</time></dd></dl></details><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-600.jpg">600 × 400</a></li><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-1200.jpg">1200 × 800</a></li><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-2400.jpg">2400 × 1601</a></li><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-3840.jpg">3840 × 2561</a></li><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088-7680.jpg">7680 × 5123</a></li><li><a href="https://i.dllu.net/2018-11-30-09-43-59_DSC01279_1d13b959659d336df947496982f51bc5cfe38e87_979e4d2ecf060088.jpg">original 7952 × 5304</a></li></ul></nav></details></figcaption></figure>
<iframe width="320" height="400" src="https://www.youtube.com/embed/r-GHYwkQD1o" title="line scan photography of Shanghai Transrapid" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<figure id="fig10"><img src="https://i.dllu.net/IMG_6801_654e71a21ee44795-600.jpg" alt="" width="450" height="600" loading="lazy" decoding="async" srcset="https://i.dllu.net/IMG_6801_654e71a21ee44795-600.jpg 600w, https://i.dllu.net/IMG_6801_654e71a21ee44795-1200.jpg 1200w, https://i.dllu.net/IMG_6801_654e71a21ee44795-2400.jpg 2400w, https://i.dllu.net/IMG_6801_654e71a21ee44795.jpg 2582w" sizes="(max-width: 450px) 100vw, 450px"/><figcaption><p><a href="#fig10">FIGURE 10</a> Waiting for a subway train to roll by in Brooklyn, New York.</p><details><summary>EXIF data</summary><dl><dt>Software</dt><dd>Google</dd><dt>Date</dt><dd><time datetime="2021-09-19T15:57:17">2021-09-19 15:57:17</time></dd></dl></details><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/IMG_6801_654e71a21ee44795-450.jpg">450 × 600</a></li><li><a href="https://i.dllu.net/IMG_6801_654e71a21ee44795-600.jpg">600 × 800</a></li><li><a href="https://i.dllu.net/IMG_6801_654e71a21ee44795-1200.jpg">1200 × 1600</a></li><li><a href="https://i.dllu.net/IMG_6801_654e71a21ee44795-2400.jpg">2400 × 3200</a></li><li><a href="https://i.dllu.net/IMG_6801_654e71a21ee44795.jpg">original 2582 × 3443</a></li></ul></nav></details></figcaption></figure>

<p>Sometimes, I keep the line scan camera running for a while, and it generates tons of boring data of the background.
To detect moving things, I compute an “energy function” that’s defined as</p>
<p><a href="#eq1">1</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>energy</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mrow><mn>0.1</mn><msub><mtext>max</mtext><mi mathvariant="bold">I</mi></msub><mo>+</mo><msqrt><mrow><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mo fence="true">)</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">I</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{energy}(x, y) = \frac{
    \frac{\partial \mathbf{I}}{\partial x}
}{
    0.1 \text{max}_\mathbf{I} + \sqrt{\left(\frac{\partial \mathbf{I}}{\partial x}\right)^2 + 
    \left(\frac{\partial \mathbf{I}}{\partial y}\right)^2}
}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span>energy</span></span><span>(</span><span>x</span><span>,</span><span></span><span>y</span><span>)</span><span></span><span>=</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>0.1</span><span><span><span>max</span></span><span><span><span><span><span><span></span><span><span>I</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span><span><span><span><span></span><span><span><span><span><span>(</span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>∂</span><span>x</span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>∂</span><span>I</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>)</span></span></span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span><span><span>(</span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>∂</span><span>y</span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>∂</span><span>I</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>)</span></span></span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span></span></span><span><span></span><span><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="2.48em" viewBox="0 0 400000 2592" preserveAspectRatio="xMinYMin slice"><path d="M424,2478
c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514
c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20
s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121
s209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081
l0 -0c4,-6.7,10,-10,18,-10 H400000
v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185
c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80
h400000v40h-400000z"></path></svg></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span></span><span><span><span><span><span><span></span><span><span><span>∂</span><span>x</span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>∂</span><span>I</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>max</mtext><mi mathvariant="bold">I</mi></msub></mrow><annotation encoding="application/x-tex">\text{max}_\mathbf{I}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>max</span></span><span><span><span><span><span><span></span><span><span>I</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> is the maximum pixel value of the image, and the partial derivative are the <a href="https://en.wikipedia.org/wiki/Image_gradient">image gradient</a>.</p>
<figure id="fig11"><img src="https://i.dllu.net/score_sample_91b1560a90ba63f2-600.png" alt="" width="600" height="400" loading="lazy" decoding="async" srcset="https://i.dllu.net/score_sample_91b1560a90ba63f2-600.png 600w, https://i.dllu.net/score_sample_91b1560a90ba63f2-1200.png 1200w, https://i.dllu.net/score_sample_91b1560a90ba63f2.png 1536w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig11">FIGURE 11</a> Example energy image.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/score_sample_91b1560a90ba63f2-600.png">600 × 400</a></li><li><a href="https://i.dllu.net/score_sample_91b1560a90ba63f2-1200.png">1200 × 800</a></li><li><a href="https://i.dllu.net/score_sample_91b1560a90ba63f2.png">original 1536 × 1024</a></li></ul></nav></details></figcaption></figure>
<p>This is because, for a static background, it will be full of horizontal stripes.
By weighing the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span></span></span></span>-direction (time direction) gradient against the total gradient norm, we can find areas where it’s a more vertical-ish structure rather than a horizontal structure.
However, doing this by itself risks noisy gradients in empty (but noisy) areas where the gradient direction is completely random.
The maximum pixel value term ensures that whatever gradient we see is salient.</p>
<p>The image is divided into chunks and the score of a chunk is the 99th percentile energy.</p>
<p>Finally, chunks containing moving objects are defined to be ones where the score is at least 1.5× that of the minimum score.</p>
<p>This heuristic took me longer than I would like to admit to figure out.
Previously, I came up with heuristics that worked well on one capture but couldn’t generalize well to other captures.
Sometimes, the background will contain slowly moving foliage waving in the wind, that would screw up other methods of detection.
That resulted in a lot of wasted time because time spent processing empty regions seriously slows down iteration speed when developing the later steps.</p>

<p>The most common question I get is, how do I estimate the speed of the subject?
If I don’t do it properly, it will appear stretched out, squished, or flipped.</p>
<p>Typically, I just set the camera to scan as fast as possible while maintaining a decent exposure, so the scan rate is independent of the subject.
Faster subjects will appear squished, and slower subjects will appear stretched out.</p>
<p>For most of my earlier works, I just eyeballed it. A good rule of thumb is to look for round things such as the wheels and “no smoking” signs.
But now I have a fully automated technique that works fairly robustly.</p>
<p>The key idea is to exploit the fact that the line scan camera actually has two lines in a <a href="https://en.wikipedia.org/wiki/Bayer_filter">Bayer array</a>, where one line is red, green, red, green, and the second line is green, blue, green blue.
By comparing the two green channels, we are able to figure out how fast stuff is moving.</p>
<p>The problem is that the data is very noisy, and salient features are sparse.
Here’s the general approach:</p>
<ul><li>Divide image into chunks.</li><li>Compute the absolute difference between the 2 green channels of each chunk for various small shifts (from -7 to +7). This gives us a cost array for each chunk.</li><li>Perform subpixel peak interpolation in the cost array using an iteratively reweighted Gaussian, <a href="https://en.wikipedia.org/wiki/Mean_shift">mean shift</a> style. This gives us a shift estimate per chunk.</li><li>Fit a robust spline to the shift estimates.</li></ul>
<figure id="fig12"><img src="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-600.png" alt="" width="600" height="338" loading="lazy" decoding="async" srcset="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-600.png 600w, https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-1200.png 1200w, https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-2400.png 2400w, https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-3840.png 3840w, https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e.png 4800w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig12">FIGURE 12</a> Interpolating to find the peak using mean shift.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-600.png">600 × 338</a></li><li><a href="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-1200.png">1200 × 675</a></li><li><a href="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-2400.png">2400 × 1350</a></li><li><a href="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e-3840.png">3840 × 2160</a></li><li><a href="https://i.dllu.net/mean_shift_0080_e3d219d77b34d22e.png">original 4800 × 2700</a></li></ul></nav></details></figcaption></figure>
<figure id="fig13"><img src="https://i.dllu.net/spline_8457468cc8c5d06a-600.png" alt="" width="600" height="338" loading="lazy" decoding="async" srcset="https://i.dllu.net/spline_8457468cc8c5d06a-600.png 600w, https://i.dllu.net/spline_8457468cc8c5d06a-1200.png 1200w, https://i.dllu.net/spline_8457468cc8c5d06a-2400.png 2400w, https://i.dllu.net/spline_8457468cc8c5d06a-3840.png 3840w, https://i.dllu.net/spline_8457468cc8c5d06a.png 4800w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig13">FIGURE 13</a> Sample spacing and fitted spline.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/spline_8457468cc8c5d06a-600.png">600 × 338</a></li><li><a href="https://i.dllu.net/spline_8457468cc8c5d06a-1200.png">1200 × 675</a></li><li><a href="https://i.dllu.net/spline_8457468cc8c5d06a-2400.png">2400 × 1350</a></li><li><a href="https://i.dllu.net/spline_8457468cc8c5d06a-3840.png">3840 × 2160</a></li><li><a href="https://i.dllu.net/spline_8457468cc8c5d06a.png">original 4800 × 2700</a></li></ul></nav></details></figcaption></figure>
<p>As you can see, the data is noisy, but we have surprisingly decent granularity for this very subpixel case where we were scanning slower than needed so the spacing is like 0.5.</p>
<p>The value of the spline is actually the <em>sample spacing</em>. It tells us how close together or far apart the sample points in the original time series we should be using.
This leads us to the next section.</p>
<figure id="fig14"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-600.jpg" alt="" width="1200" height="150" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig14">FIGURE 14</a> Uncorrected left end. It’s squished!!!</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-600.jpg">600 × 75</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-1200.jpg">1200 × 150</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-2400.jpg">2400 × 300</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-3840.jpg">3840 × 480</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381-7680.jpg">7680 × 960</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_b83579bd26d10381.jpg">original 32768 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig15"><img src="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-600.jpg" alt="" width="1200" height="150" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-600.jpg 600w, https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-1200.jpg 1200w, https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-2400.jpg 2400w, https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig15">FIGURE 15</a> Uncorrected right end. It’s slightly squished but not nearly as much.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-600.jpg">600 × 75</a></li><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-1200.jpg">1200 × 150</a></li><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-2400.jpg">2400 × 300</a></li><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-3840.jpg">3840 × 480</a></li><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa-7680.jpg">7680 × 960</a></li><li><a href="https://i.dllu.net/rgb_2_prod_no_denoise_32cd95888d846ffa.jpg">original 32768 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig16"><img src="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-600.jpg" alt="" width="1200" height="150" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-600.jpg 600w, https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-1200.jpg 1200w, https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-2400.jpg 2400w, https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig16">FIGURE 16</a> Left end of New York subway train.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-600.jpg">600 × 75</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-1200.jpg">1200 × 150</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-2400.jpg">2400 × 300</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-3840.jpg">3840 × 480</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936-7680.jpg">7680 × 960</a></li><li><a href="https://i.dllu.net/rgb_0_prod_no_denoise_e458634bcd3cc936.jpg">original 32768 × 4096</a></li></ul></nav></details></figcaption></figure>
<figure id="fig17"><img src="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-600.jpg" alt="" width="1200" height="150" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-600.jpg 600w, https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-1200.jpg 1200w, https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-2400.jpg 2400w, https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig17">FIGURE 17</a> Right end of New York subway train.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-600.jpg">600 × 75</a></li><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-1200.jpg">1200 × 150</a></li><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-2400.jpg">2400 × 300</a></li><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-3840.jpg">3840 × 480</a></li><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333-7680.jpg">7680 × 960</a></li><li><a href="https://i.dllu.net/rgb_3_prod_no_denoise_fa356ca82a22b333.jpg">original 32768 × 4096</a></li></ul></nav></details></figcaption></figure>
<p>Hmm, I think my speed estimation still isn’t perfect. It could be off by about 10%.
For future work, I think I might be able to extract features correspondences such as SIFT or LightGlue. Trains are full of repeating elements that are supposed to be evenly spaced. I can detect those, and add a cost function to evenly space them, and optimize.
Another idea is to use a circle Hough transform to find circles.</p>

<p>From the spline that gives us the sample spacing, we can basically generate the samples as such:</p>
<pre><span>samples</span> <span>=</span> <span>[</span><span>]</span>
<span>sample_position</span> <span>=</span> <span>0.0</span>
<span>while</span> <span>sample_position</span> <span>&lt;</span> <span>raw_width</span><span>:</span>
    <span>samples</span><span>.</span><span>append</span><span>(</span><span>sample_position</span><span>)</span>
    <span>sample_position</span> <span>+=</span> <span>spline</span><span>(</span><span>sample_position</span><span>)</span>
</pre>
<p>However, there are a few gotchas:</p>
<ul><li>If the spline is negative-valued, it means the subject is going the other way, i.e. the image is flipped. In this case, I start with <code>sample_position</code> set to <code>raw_width</code> and go from right to left.</li><li>If the spline goes to zero, we are doomed because the while loop will never terminate. I clamp the steps to at least 0.1 and throw an error if the spline has both positive and negative values.</li><li>This is sort of a naive integration compared to the trapezoidal rule or something. However, given that the spline moves very slowly, it is fine.</li></ul>
<p>Now, for each sample position, we also store the sample width, which is the value of the spline.
If we were to simply extract a single column from the raw data, we would be throwing away a lot of data, and the result wouldn’t be antialiased.
Instead, it is better to pick a window of width proportional to the sample spacing.
I chose a <a href="https://en.wikipedia.org/wiki/Hann_function">Hann window</a>.</p>
<figure id="fig18"><img src="https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579-600.png" alt="" width="600" height="332" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579-600.png 600w, https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579-1200.png 1200w, https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579.png 1970w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig18">FIGURE 18</a> Naively selecting columns instead of using a windowing function.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579-600.png">600 × 332</a></li><li><a href="https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579-1200.png">1200 × 663</a></li><li><a href="https://i.dllu.net/2025-08-19-12-10-58_b5c58484522b4579.png">original 1970 × 1089</a></li></ul></nav></details></figcaption></figure>
<figure id="fig19"><img src="https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c-600.png" alt="" width="600" height="373" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c-600.png 600w, https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c-1200.png 1200w, https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c.png 2093w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig19">FIGURE 19</a> Using a rectangular window.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c-600.png">600 × 373</a></li><li><a href="https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c-1200.png">1200 × 746</a></li><li><a href="https://i.dllu.net/2025-08-19-12-11-19_006f733f714d000c.png">original 2093 × 1302</a></li></ul></nav></details></figcaption></figure>
<p>Not only is the first image very grainy, but the rapidly blinking LED display showing the characters for 筲箕灣 is completely illegible without proper sampling.</p>
<figure id="fig20"><img src="https://i.dllu.net/2025-08-21-23-01-25_b836f51e7b72da06-600.png" alt="" width="600" height="508" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-21-23-01-25_b836f51e7b72da06-600.png 600w, https://i.dllu.net/2025-08-21-23-01-25_b836f51e7b72da06.png 831w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig20">FIGURE 20</a> Upsampling using a rectangular window.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-21-23-01-25_b836f51e7b72da06-600.png">600 × 508</a></li><li><a href="https://i.dllu.net/2025-08-21-23-01-25_b836f51e7b72da06.png">original 831 × 703</a></li></ul></nav></details></figcaption></figure>
<figure id="fig21"><img src="https://i.dllu.net/2025-08-21-23-00-57_cf42ac3a31b6cdf8-600.png" alt="" width="600" height="499" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-21-23-00-57_cf42ac3a31b6cdf8-600.png 600w, https://i.dllu.net/2025-08-21-23-00-57_cf42ac3a31b6cdf8.png 762w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig21">FIGURE 21</a> Upsampling using a Hann window.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-21-23-00-57_cf42ac3a31b6cdf8-600.png">600 × 499</a></li><li><a href="https://i.dllu.net/2025-08-21-23-00-57_cf42ac3a31b6cdf8.png">original 762 × 634</a></li></ul></nav></details></figcaption></figure>
<p>As you can see, the rectangular window performs very poorly when upsampling and introduces horrible jagged artifacts. The Hann window does better. Some other windows like the Sinc are even better supposedly.</p>

<p>Recall that the camera has two lines forming a Bayer array.</p>
<p>If we simply create an image of half resolution (i.e. 2048 pixels tall instead of 4096), by grouping each RGGB group into one pixel, we would have some nasty fringing problems since the red and blue pixels are offset.</p>
<figure id="fig22"><img src="https://i.dllu.net/2025-08-19-17-57-15_ea319c5f717e47df.png" alt="" width="455" height="365" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-19-17-57-15_ea319c5f717e47df.png 455w" sizes="(max-width: 455px) 100vw, 455px"/><figcaption><p><a href="#fig22">FIGURE 22</a> Fringing due to bad demosaicing.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-19-17-57-15_ea319c5f717e47df.png">original 455 × 365</a></li></ul></nav></details></figcaption></figure>
<figure id="fig23"><img src="https://i.dllu.net/2025-08-19-17-57-35_41dc85cc57217678.png" alt="" width="543" height="402" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-19-17-57-35_41dc85cc57217678.png 543w" sizes="(max-width: 543px) 100vw, 543px"/><figcaption><p><a href="#fig23">FIGURE 23</a> Better.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-19-17-57-35_41dc85cc57217678.png">original 543 × 402</a></li></ul></nav></details></figcaption></figure>
<p>Instead we should write out the image with careful attention to offsets, interpolating as necessary.
Note that the horizontal offsets must be done <em>after</em> speed estimation, because, before speed estimation, the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span></span></span></span>-axis is time, and after speed estimation, the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span></span></span></span>-axis is space.
But the 2-pixel wide Bayer array is physically a <em>spatial</em> offset.</p>
<p>I implemented a basic interpolation scheme that uses bilinear interpolation.
This fixes most of the fringing, although we can do even better. That will be left for future work.</p>
<p>Unlike a traditional Bayer array, here we have the possibility that the green channels cover 100% of the pixels, so we can potentially do better than traditional demosaicing algorithms.
But there’s currently an annoying problem, which is that the two green channels on my line scan camera don’t match.</p>

<p>Vertical stripes in the image are common and are due to two main reasons:</p>
<ul><li>Clock jitter. The exposure time of each column may be randomly slightly off for some reason.</li><li>I’ve noticed that when a dark object shows up, like the coupling between train cars, the whole slice of the image there is brighter (and vice versa; if there’s something really bright, then the whole slice becomes darker).</li></ul>
<p>To fix this, I use linear regression to fit a basic model of the form:</p>
<p><a href="#eq2">2</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>model</mtext><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mi mathvariant="bold">x</mi><mo>+</mo><mi>c</mi><mi mathvariant="bold">k</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{model}(\mathbf{x}) = a + b\mathbf{x} + c\mathbf{k}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span>model</span></span><span>(</span><span>x</span><span>)</span><span></span><span>=</span><span></span><span>a</span><span></span><span>+</span><span></span><span>b</span><span>x</span><span></span><span>+</span><span></span><span>c</span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>a</span></span></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>b</span></span></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>c</span></span></span></span> are scalar parameters of the model, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span></span></span></span> is a 2048-element vector containing the luminance value of the column (mean over the 4 channels), and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">k</mi></mrow><annotation encoding="application/x-tex">\mathbf{k}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>k</span></span></span></span> is the row index (aka the 2048-element vector of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>2047</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\begin{bmatrix}0, 1, \cdots, 2047\end{bmatrix}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>[</span></span><span><span><span><span><span><span><span><span></span><span><span>0</span><span>,</span><span></span><span>1</span><span>,</span><span></span><span>⋯</span><span></span><span></span><span>,</span><span></span><span>2047</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span><span><span>]</span></span></span></span></span></span>.</p>
<p>You can compose models as such:</p>
<p><a href="#eq3">3</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mtext>model</mtext><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mtext>model</mtext><mn>2</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>a</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mi mathvariant="bold">x</mi><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><mi mathvariant="bold">k</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub><mi mathvariant="bold">k</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{model}_1 (\text{model}_2 (\mathbf{x})) &amp;= a_1 + b_1(a_2 + b_2 \mathbf{x} + c_2 \mathbf{k}) + c_1 \mathbf{k}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span><span>model</span></span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>(</span><span><span><span>model</span></span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>(</span><span>x</span><span>))</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span><span><span><span><span><span></span><span><span></span><span></span><span>=</span><span></span><span><span>a</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>(</span><span><span>a</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>x</span><span></span><span>+</span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>k</span><span>)</span><span></span><span>+</span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>This gives us a new model <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>model</mtext><mn>12</mn></msub></mrow><annotation encoding="application/x-tex">\text{model}_{12}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>model</span></span><span><span><span><span><span><span></span><span><span><span>12</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> with parameters:</p>
<p><a href="#eq4">4</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>a</mi><mn>12</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>a</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>a</mi><mn>2</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>b</mi><mn>12</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>b</mi><mn>2</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>c</mi><mn>12</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>c</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>c</mi><mn>2</mn></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}a_{12} &amp;= a_1 + b_1 a_2\\
b_{12} &amp;= b_1 b_2\\
c_{12} &amp;= c_1 + b_1 c_2\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span>a</span><span><span><span><span><span><span></span><span><span><span>12</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span><span><span></span><span><span><span>b</span><span><span><span><span><span><span></span><span><span><span>12</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span><span><span></span><span><span><span>c</span><span><span><span><span><span><span></span><span><span><span>12</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span><span><span><span><span><span></span><span><span></span><span></span><span>=</span><span></span><span><span>a</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>a</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span><span><span></span><span><span></span><span></span><span>=</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span><span><span></span><span><span></span><span></span><span>=</span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>The associative property of the composition operator is left as an exercise for the reader.</p>
<p>There is also the identity model, i.e. one that does nothing, which is</p>
<p><a href="#eq5">5</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>a</mi><mo>=</mo><mn>0</mn><mo separator="true">,</mo><mi>b</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi>c</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}a = 0, b = 1, c = 0\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span>a</span><span></span><span>=</span><span></span><span>0</span><span>,</span><span></span><span>b</span><span></span><span>=</span><span></span><span>1</span><span>,</span><span></span><span>c</span><span></span><span>=</span><span></span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>and there’s also the inverse:</p>
<p><a href="#eq6">6</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mtext>model</mtext><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>:</mo><msub><mi>a</mi><mtext>inv</mtext></msub><mo>=</mo><mo>−</mo><mfrac><mi>a</mi><mi>b</mi></mfrac><mo separator="true">,</mo><msub><mi>b</mi><mtext>inv</mtext></msub><mo>=</mo><mfrac><mn>1</mn><mi>b</mi></mfrac><mo separator="true">,</mo><msub><mi>c</mi><mtext>inv</mtext></msub><mo>=</mo><mo>−</mo><mfrac><mi>c</mi><mi>b</mi></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{model}^{-1}: a_{\text{inv}} = -\frac{a}{b}, b_{\text{inv}} = \frac{1}{b}, c_{\text{inv}} = -\frac{c}{b}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span><span>model</span></span><span><span><span><span><span><span></span><span><span><span>−</span><span>1</span></span></span></span></span></span></span></span></span><span></span><span>:</span><span></span><span><span>a</span><span><span><span><span><span><span></span><span><span><span><span>inv</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span><span>−</span><span><span></span><span><span><span><span><span><span></span><span><span>b</span></span></span><span><span></span><span></span></span><span><span></span><span><span>a</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span>,</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span><span><span>inv</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>b</span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span>,</span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span><span><span>inv</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span><span>−</span><span><span></span><span><span><span><span><span><span></span><span><span>b</span></span></span><span><span></span><span></span></span><span><span></span><span><span>c</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>so the set of these models forms a mathematical group.</p>
<p>I fit a model to each consecutive pair of columns using weighted least squares, where we assign each row element a weight based on a Gaussian.
The weight would be:</p>
<p><a href="#eq7">7</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="bold">w</mi><mo>=</mo><mtext>exp</mtext><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mrow><mtext>model</mtext><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi mathvariant="bold">x</mi><mn>2</mn></msub></mrow><msup><mi>σ</mi><mn>2</mn></msup></mfrac><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\mathbf{w} = \text{exp}\left( -\frac{\text{model}(\mathbf{x}_1) - \mathbf{x}_2}{\sigma^2} \right)\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span>w</span><span></span><span>=</span><span></span><span><span>exp</span></span><span></span><span><span><span>(</span></span><span>−</span><span><span></span><span><span><span><span><span><span></span><span><span><span>σ</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>model</span></span><span>(</span><span><span>x</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>−</span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>)</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>In other words, the residual would be</p>
<p><a href="#eq8">8</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>residual</mtext><mo>=</mo><mtext>diag</mtext><mo stretchy="false">(</mo><mi mathvariant="bold">w</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mtext>model</mtext><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi mathvariant="bold">x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{residual} = \text{diag}(\mathbf{w}) (\text{model}(\mathbf{x}_1) - \mathbf{x}_2)\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span>residual</span></span><span></span><span>=</span><span></span><span><span>diag</span></span><span>(</span><span>w</span><span>)</span><span>(</span><span><span>model</span></span><span>(</span><span><span>x</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>−</span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>After fitting this model, we redo the steps again several times, where the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">w</mi></mrow><annotation encoding="application/x-tex">\mathbf{w}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>w</span></span></span></span> vector is recalculated each time.
This is known as <em>iteratively-reweighted least squares</em> and is pretty good at rejecting outliers.</p>
<figure id="fig24"><img src="https://i.dllu.net/jitter_debug_082121e08533fc28-600.png" alt="" width="600" height="338" loading="lazy" decoding="async" srcset="https://i.dllu.net/jitter_debug_082121e08533fc28-600.png 600w, https://i.dllu.net/jitter_debug_082121e08533fc28-1200.png 1200w, https://i.dllu.net/jitter_debug_082121e08533fc28-2400.png 2400w, https://i.dllu.net/jitter_debug_082121e08533fc28-3840.png 3840w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig24">FIGURE 24</a> The first plot shows the current column’s luminance and previous column’s luminance, as well as the previous column corrected by the model. The second plot shows the weight. The third plot shows the weighted initial and final error.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28-600.png">600 × 338</a></li><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28-1200.png">1200 × 675</a></li><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28-2400.png">2400 × 1350</a></li><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28-3840.png">3840 × 2160</a></li><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28-7680.png">7680 × 4320</a></li><li><a href="https://i.dllu.net/jitter_debug_082121e08533fc28.png">original 9600 × 5400</a></li></ul></nav></details></figcaption></figure>
<p>This all gives us <em>relative</em> models between the previous column and the current column, but we want <em>global</em> models that tell us how to correct each column overall.
We could set the global models by just composing them forever, but they would soon start to drift arbitrarily far away from the identity model.</p>
<p>You could prevent them from drifting away by solving a band-diagonal linear system where you have residuals of two types:</p>
<ul><li>prior residual, penalizing the difference between each model from the identity</li><li>relative model residual, penalizing the difference between the delta between adjacent models and the relative model we computed</li></ul>
<p>This can be solved in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>O</span><span>(</span><span>n</span><span>)</span></span></span></span>. However, it is a bit of work to implement. In practice, you can mitigate most high frequency stripes by just doing <a href="https://en.wikipedia.org/wiki/Exponential_smoothing">exponential smoothing</a>, which basically acts as a high-pass filter</p>
<p><a href="#eq9">9</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mtext>global</mtext><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><mtext>compose</mtext><mo stretchy="false">(</mo><msub><mtext>global</mtext><mi>i</mi></msub><mo separator="true">,</mo><msub><mtext>relative</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mtext>identity</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{global}_{i + 1} = (1 - \lambda) \text{compose}(\text{global}_i, \text{relative}_i) + \lambda \text{identity}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span><span>global</span></span><span><span><span><span><span><span></span><span><span><span>i</span><span>+</span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span><span>(</span><span>1</span><span></span><span>−</span><span></span><span>λ</span><span>)</span><span><span>compose</span></span><span>(</span><span><span><span>global</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span><span>relative</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>+</span><span></span><span>λ</span><span><span>identity</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>for some small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>λ</span></span></span></span>, in this case hardcoded to be 0.02.</p>
<figure id="fig25"><img src="https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be-600.png" alt="" width="1200" height="539" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be-600.png 600w, https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be-1200.png 1200w, https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be.png 1469w" sizes="100vw"/><figcaption><p><a href="#fig25">FIGURE 25</a> Before. You can see rather subtle stripes in the dark area.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be-600.png">600 × 270</a></li><li><a href="https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be-1200.png">1200 × 539</a></li><li><a href="https://i.dllu.net/2025-08-21-23-06-05_7f2b75d765c999be.png">original 1469 × 660</a></li></ul></nav></details></figcaption></figure>
<figure id="fig26"><img src="https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1-600.png" alt="" width="1200" height="540" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1-600.png 600w, https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1-1200.png 1200w, https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1.png 1470w" sizes="100vw"/><figcaption><p><a href="#fig26">FIGURE 26</a> After.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1-600.png">600 × 270</a></li><li><a href="https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1-1200.png">1200 × 540</a></li><li><a href="https://i.dllu.net/2025-08-21-23-06-21_d6e64e01704c96d1.png">original 1470 × 661</a></li></ul></nav></details></figcaption></figure>
<p>Previously, I also had some success by directly fitting the model to line up each column with the first column. However, it doesn’t work for captures where the background isn’t static (e.g. rotating line scan panoramas, and pointing the line scan camera out of a moving train).</p>
<p>By the way, I should point out that vertical stripes getting rid of should be done <em>before</em> speed estimation, since it happens in the time domain at capture time.
If a train were speeding up, it would appear stretched out at first, and squished at the end, and the striping would affect the end a lot more than the start.</p>

<p>I implemented a patch-based denoiser, also known as <a href="https://en.wikipedia.org/wiki/Block-matching_and_3D_filtering">block matching</a>.
It works by making the observation that you often have repeated textures in a line scan photo of a train.
Technically, you also have lots of self-similarity in general photos, so patch-based denoising is a common method for denoising in general.
However, one important distinction is that most denoisers only look in a small neighborhood around the current patch, but mine looks along the entire row.</p>
<p>What I do is, for each row, we process it independently.
From each 3×3 pixel patch, we can construct a <em>feature vector</em> of size 27 (9 times 3 channels, RGB).
Then, we collect all these features and sort them by mean value.
Now, for each position along the row, we search in the window of size 128 in the sorted vector.
The sorted vector will have similar-looking patches nearby, but we further weigh them by Gaussian similarity to the current patch.
Then, we compute the weighted average of the center pixel of each of those patches.</p>
<p>Another trick is to realize that the noise is Poisson-distributed which has a standard deviation that scales with the square root of the signal.
But if I just square root the input data first, then we just need to compare it to a constant.</p>
<p>This works decently, but is incredibly slow.
Let me know if you think of any faster ways to do it. A KD tree in feature space would die from the curse of dimensionality. Perhaps a hash table? To keep things lightweight, we can limit the population in each cell.</p>
<figure id="fig27"><img src="https://i.dllu.net/2025-08-20-16-08-55_264411aaba797e0c.png" alt="" width="427" height="373" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-20-16-08-55_264411aaba797e0c.png 427w" sizes="(max-width: 427px) 100vw, 427px"/><figcaption><p><a href="#fig27">FIGURE 27</a> Noisy watch.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-20-16-08-55_264411aaba797e0c.png">original 427 × 373</a></li></ul></nav></details></figcaption></figure>
<figure id="fig28"><img src="https://i.dllu.net/2025-08-20-16-08-30_6c3c0102c46a5803.png" alt="" width="509" height="449" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-20-16-08-30_6c3c0102c46a5803.png 509w" sizes="(max-width: 509px) 100vw, 509px"/><figcaption><p><a href="#fig28">FIGURE 28</a> Denoised watch.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-20-16-08-30_6c3c0102c46a5803.png">original 509 × 449</a></li></ul></nav></details></figcaption></figure>
<figure id="fig29"><img src="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-600.png" alt="" width="600" height="402" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-600.png 600w, https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-1200.png 1200w, https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-2400.png 2400w, https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-3840.png 3840w, https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151.png 3881w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig29">FIGURE 29</a> Noisy passenger.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-600.png">600 × 402</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-1200.png">1200 × 803</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-2400.png">2400 × 1607</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151-3840.png">3840 × 2571</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-34_8be193ad950c4151.png">original 3881 × 2598</a></li></ul></nav></details></figcaption></figure>
<figure id="fig30"><img src="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-600.png" alt="" width="600" height="404" loading="lazy" decoding="async" srcset="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-600.png 600w, https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-1200.png 1200w, https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-2400.png 2400w, https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080.png 3507w" sizes="(max-width: 600px) 100vw, 600px"/><figcaption><p><a href="#fig30">FIGURE 30</a> Denoised passenger.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-600.png">600 × 404</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-1200.png">1200 × 809</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080-2400.png">2400 × 1617</a></li><li><a href="https://i.dllu.net/2025-08-20-16-09-59_dbce64ce63ce8080.png">original 3507 × 2363</a></li></ul></nav></details></figcaption></figure>
<p>The good thing about the patch-based denoiser is that unique features like this passenger remain virtually unchanged.</p>
<p>Previously, I also tried using a <a href="https://en.wikipedia.org/wiki/Total_variation_denoising">total variation denoiser</a>, processing each row and column independently.
It worked decently but would often destroy fine detail in textures.</p>

<p>If the camera isn’t perfectly upright, the resulting image may be slightly skewed.
I’m planning on implementing automatic skew correction.
But here are two caveats:</p>
<ul><li>skew detection must be done after speed estimation</li><li>proper sampling should happen after skew detection, since the skew transformation introduces generation loss and we can sample directly from the raw data instead.</li></ul>
<p>So basically we’d need to generate a quick, poorly sampled version, run skew detection on it, and then sample it properly afterwards.
We can implement skew detection using a <a href="https://daniel.lawrence.lu/blog/2025-09-21-line-scan-camera-image-processing/Hough%20transform">Hough transform</a>.
Generally, I do a decent job of keeping the camera upright, so we just need to correct for very small skews, so a Hough transform is suitable (since the complexity scales with the number of bins of the histogram).
We can also use the energy function from the region of interest detector to primarily care about vertical structures.</p>
<figure id="fig31"><img src="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-600.png" alt="" width="1200" height="300" loading="lazy" decoding="async" srcset="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-600.png 600w, https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-1200.png 1200w, https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-2400.png 2400w, https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-3840.png 3840w, https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa.png 4096w" sizes="100vw"/><figcaption><p><a href="#fig31">FIGURE 31</a> Hough transform lines for skew detection superimposed over the vertical structure energy image.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-600.png">600 × 150</a></li><li><a href="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-1200.png">1200 × 300</a></li><li><a href="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-2400.png">2400 × 600</a></li><li><a href="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa-3840.png">3840 × 960</a></li><li><a href="https://i.dllu.net/skew_energy_00_9e33e9555d22ddfa.png">original 4096 × 1024</a></li></ul></nav></details></figcaption></figure>

<p>I kinda just eyeballed this color calibration matrix.</p>
<p><a href="#eq10">10</a> <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.9</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.8</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1.6</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2.0</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\begin{bmatrix}
    0.9&amp;  -0.3&amp; -0.3 \\
    -0.8 &amp; 1.6 &amp; -0.3 \\ 
    -0.5 &amp; -0.5 &amp; 2.0 \\
    \end{bmatrix}\end{aligned}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span><span><span></span><span><span><span><span><span><span><span><span><span></span><span><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span><span><span><span><span><span><span></span><span><span>0.9</span></span></span><span><span></span><span><span>−</span><span>0.8</span></span></span><span><span></span><span><span>−</span><span>0.5</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span></span><span><span><span><span><span><span></span><span><span>−</span><span>0.3</span></span></span><span><span></span><span><span>1.6</span></span></span><span><span></span><span><span>−</span><span>0.5</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span></span><span><span><span><span><span><span></span><span><span>−</span><span>0.3</span></span></span><span><span></span><span><span>−</span><span>0.3</span></span></span><span><span></span><span><span>2.0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span><span><span><span><span><span><span><span></span><span><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>But to be honest it looks fairly decent.</p>
<figure id="fig32"><img src="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-600.jpg" alt="" width="1200" height="300" loading="lazy" decoding="async" srcset="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-600.jpg 600w, https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-1200.jpg 1200w, https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-2400.jpg 2400w, https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-3840.jpg 3840w" sizes="100vw"/><figcaption><p><a href="#fig32">FIGURE 32</a> People’s skin tones look fine to me.</p><details><summary>Download</summary><nav aria-label="Download sizes"><ul><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-600.jpg">600 × 150</a></li><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-1200.jpg">1200 × 300</a></li><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-2400.jpg">2400 × 600</a></li><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-3840.jpg">3840 × 960</a></li><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15-7680.jpg">7680 × 1920</a></li><li><a href="https://i.dllu.net/rgb_7_prod_no_denoise_2474ac2d89335c15.jpg">original 16384 × 4096</a></li></ul></nav></details></figcaption></figure>
<p>I also implemented DNG output so that I can postprocess the colors in Darktable.</p>

<p>The code is implemented in Python using numpy.</p>
<p><a href="https://github.com/dllu/nectar/blob/master/python/preview.py">the code</a></p>
<p>Due to the large size of the data (4096 rows and hundreds of thousands of columns), it is sometimes impossible to fit all of it in memory, so the code takes several passes and outputs in chunks.
Actually, it is probably okay to fit it in a few gigabytes of RAM, but you’d have to chunk up the storage (there’s no way a contiguous numpy array of 4096 by 100,000 could be allocated).</p>
<h2 id="s11.1"><span id="vibe-coding-experience" aria-hidden="true"></span><a href="#s11.1">11.1</a> <span>Vibe coding experience</span></h2>
<p>I tried using AI to help with a lot of the implementation. However, the results were mixed.</p>
<p>AI would often accidentally make things quadratic for no reason when a linear time algorithm would suffice. For example, when trying to implement spline-based resampling, ChatGPT 5 came up with horribly slow (but vectorized) code that constructed a giant tensor with a mask across the entire width of the image for <em>every single sample</em>. Since there are 100,000 samples, and each mask was 100,000 columns wide, you can imagine it would take millennia to run. I ended up reimplementing it from scratch by hand. Then Grok 4 implemented weighted least squares regression by materializing the entire weight vector with <code>np.diag</code> instead of simply pre-multiplying each row of <code>A</code> and <code>x</code> with the square root of the weight before doing <code>np.linalg.solve(A, x)</code>. Again, with 100,000 elements, making the square matrix with <code>np.diag</code> would have instantly run out of memory.</p>
<p>Both Grok 4 Expert and ChatGPT 5 Thinking also completely failed to implement the band-diagonal least squares to my vertical stripes strategy, but as mentioned, the exponential smoothing trick works okay for now.</p>
<p>However, for some other stuff, AI was quite helpful.
It created a class that dynamically loads chunks from disk but provides the API to index and slice it.
That was neat.
AI was also incredibly good at helping with Matplotlib’s arcane syntax.</p>

<h2 id="s12.1"><span id="adam-magyar" aria-hidden="true"></span><a href="#s12.1">12.1</a> <span>Adam Magyar</span></h2>
<p><a href="https://www.magyaradam.com/wp/">Adam Magyar</a> uses a black and white digital line scan camera for his “Stainless” project, and another derived from a scanner for his “Urban Flow” project.</p>
<p>His camera must have much better sensitivity than mine since he managed to capture fairly clean images even for underground trains (whereas I generally require sunlight for mine).
Apparently, he had to scout out many subway stations to find ones where the lights don’t flicker at 60 Hz.</p>
<h2 id="s12.2"><span id="kr64s-blog" aria-hidden="true"></span><a href="#s12.2">12.2</a> <span>KR64&#39;s blog</span></h2>
<p>At <a href="https://web.archive.org/web/20250715102540/https://kr64.seesaa.net/">kr64.seesaa.net</a> you can find a mind boggling collection of high quality line scan photos of trains from all across Japan.</p>
<p>They probably do this full time as the variety of trains is far greater than I can ever hope to achieve.
I believe they use a film slit scan camera.</p>
<p>Unfortunately, their website has a bunch of technical issues and often goes down. I would be happy to help them out but my Japanese is very poor and I don’t see any way to contact them.</p>


</div></div>
  </body>
</html>
