<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://james.darpinian.com/blog/integer-math-in-javascript">Original</a>
    <h1>Integer math in JavaScript</h1>
    
    <div id="readability-page-1" class="page"><div id="post-content" itemprop="articleBody"><p>You may know that all numbers in JavaScript are 64 bit double-precision floating point values. This is sometimes convenient and it works pretty well as a default for novice programmers, who are often confused by integer math, and rightfully so when <code>1 / 2 = 0</code>. Unfortunately, it makes things slow. Doubles take a lot of memory and floating point math is slower than integer math on CPUs. It&#39;s also inconvenient if you want to port existing code to JavaScript, because existing code usually expects to use integer math.</p><p>Fortunately, there is a way to make JavaScript do integer math, and it works remarkably well!</p><h2 id="tldr">TL;DR<a href="#tldr" title="Direct link to heading">​</a></h2><p>Add <code>| 0</code> after every math operation to get a 32-bit signed integer result, and <code>&gt;&gt;&gt; 0</code> for a 32-bit unsigned integer result. And store all your numbers in typed arrays instead of JavaScript arrays.</p><h2 id="the-background">The background<a href="#the-background" title="Direct link to heading">​</a></h2><p>JavaScript turns out to have a full set of bit manipulation instructions. The bitwise and/or/xor/not/shift operators are just like C, and I have no idea why JavaScript originally had them because they don&#39;t seem very useful for web development. Also that&#39;s weird when all numbers are double precision floating point, right? Nobody does bitwise operations on floating point numbers. And neither does JavaScript. In fact, JavaScript will (conceptually) first round your 64-bit double to a 32-bit signed integer, do the bitwise operation, and then convert it back to a double precision value. Weird!</p><p>All this conversion sounds expensive! And it probably was, back in the days before <a href="https://en.wikipedia.org/wiki/Asm.js" target="_blank" rel="noopener noreferrer">asm.js</a>. The asm.js people were porting C code to JavaScript, and the weird casting performed by JavaScript&#39;s weird bitwise operators was just what they needed to emulate C&#39;s integer arithmetic.</p><h2 id="the-trick">The trick<a href="#the-trick" title="Direct link to heading">​</a></h2><p>In C if <code>x</code> and <code>y</code> are integers then <code>x / y</code> will do integer division, rounding the result down. In JavaScript <code>x / y</code> will always be a floating point division with a floating point result. But if you apply a bitwise operator right afterward, then the result will be rounded down, converted to integer, and you&#39;ll get the same number as C did! With a lot more work. Of course you don&#39;t want your bitwise operator to change the result, so you can do a no-op bitwise operation such as <code>&gt;&gt; 0</code> or <code>| 0</code>. No-op in C, of course, but not in JavaScript, because of the integer conversion.</p><p>Once asm.js started doing <code>| 0</code> everywhere, people started being very interested in optimizing it. Obviously you can easily just skip running the <code>OR</code> instruction since it does nothing. But the real work is in all that slow conversion to and from floating point. It turns out that if you add a <code>| 0</code> after every operation, your JavaScript JIT compiler can skip the redundant conversions too, and just keep your numbers as integers the whole time. When the inputs to a division are known to be integers, and <code>| 0</code> converts it to integer again afterward, then instead of emitting two conversions to floating point, a floating point division instruction, and then a conversion to integer, the JIT can emit a single integer division instruction, just like a C compiler would. This is pretty miraculous!</p><h2 id="the-details">The details<a href="#the-details" title="Direct link to heading">​</a></h2><p>All of JavaScript&#39;s bitwise operators inherited from C convert their operands and results to 32-bit signed integers. But there&#39;s a trick for unsigned integers too. JavaScript has one extra bitwise operator that C doesn&#39;t have: <code>&gt;&gt;&gt;</code>. This is essentially an &#34;unsigned right shift&#34; operator, and it is special because its result is an unsigned 32-bit integer. So when you want a signed integer you append <code>| 0</code> after your arithmetic operations, and for unsigned you use <code>&gt;&gt;&gt; 0</code>. That&#39;s all there is to it!</p><p>So this all works great for 32-bit integer math, both signed and unsigned. What about other sizes? Unfortunately if you want 64-bit integer math, you&#39;re out of luck. These tricks work for 32-bit numbers because double precision floating point can represent every 32-bit integer exactly, and doing a floating-point division of two integers less than 2<sup>32</sup> and then converting the result to an integer gives the exact same result as an integer division instruction in every case. But the full range of 64 bit integers isn&#39;t representable in double precision floating point, and JavaScript numbers always have to behave as if they are represented by double precision floating point values even when that isn&#39;t true. The JIT compiler can&#39;t just do 64-bit integer math under the covers and pretend that it&#39;s floating point, because it would get different results when the integers are large enough.</p><p>OK, 64-bit doesn&#39;t work, how about 16-bit and 8-bit? Well, on the one hand you can&#39;t do those either, all your integer math is going to be 32 bits wide. But on the other hand that isn&#39;t so bad, because CPUs add 32-bit numbers just as fast as 8-bit numbers. Where smaller types <em>really</em> matter is in memory usage. If you want an array of bytes, but you use a JavaScript array to store JavaScript numbers instead, it will use 8 times the memory (and 8 times the memory bandwidth, and 8 times the cache space) because every JavaScript number is 8 bytes. Thankfully JavaScript has a solution for this too: typed arrays. Typed arrays can hold 8-bit, 16-bit, and 32-bit values in both signed and unsigned varieties. As an added benefit, since typed arrays can&#39;t hold object references, the garbage collector doesn&#39;t need to scan their contents, which also helps performance.</p><p>Bonus question: what about 32-bit floating point? It&#39;s faster than 64-bit floating point, and used a lot in 3D graphics. Can we use a similar trick to make the JavaScript JIT emit 32-bit float math instructions? The answer is yes, there&#39;s a function <code>Math.fround</code> used for this purpose by asm.js. I&#39;ve never tried using it myself.</p><h2 id="putting-it-all-together">Putting it all together<a href="#putting-it-all-together" title="Direct link to heading">​</a></h2><p>Asm.js uses these techniques to translate C code to JavaScript and gets impressively close to the performance of native C compilers. But you don&#39;t have to use asm.js to benefit. Anytime you want good performance in JavaScript, you can store your data in typed arrays and use <code>| 0</code> manually to make sure your values stay in integer form. Your code can run fast without resorting to Web Assembly or Emscripten.</p></div></div>
  </body>
</html>
