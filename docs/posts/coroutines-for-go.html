<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.swtch.com/coro">Original</a>
    <h1>Coroutines for Go</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        
        

<p>
This post is about why we need a coroutine package for Go, and what it would look like.
But first, what are coroutines?

</p><p>
Every programmer today is familiar with function calls (subroutines):
F calls G, which stops F and runs G.
G does its work, potentially calling and waiting for other functions, and eventually returns.
When G returns, G is gone and F continues running.
In this pattern, only one function is running at a time,
while its callers wait, all the way up the call stack.

</p><p>
In contrast to subroutines, coroutines run concurrently on different stacks,
but it&#39;s still true that only one is running at a time,
while its caller waits.
F starts G, but G does not run immediately.
Instead, F must explicitly <i>resume</i> G, which then starts running.
At any point, G may turn around and <i>yield</i> back to F.
That pauses G and continues F from its resume operation.
Eventually F calls resume again, which pauses F and continues G from its yield.
On and on they go, back and forth, until G returns, which cleans up G and
continues F from its most recent resume, with some signal to F that G is done
and that F should no longer try to resume G.
In this pattern, only one coroutine is running at a time,
while its caller waits on a different stack.
They take turns in a well-defined, coordinated manner.

</p><p>
This is a bit abstract. Let&#39;s look at real programs.
<a href="#lua"></a></p><h2 id="lua"><a href="#lua">Coroutines in Lua</a></h2>


<p>
To use a <a href="https://research.swtch.com/pcdata#gopher">venerable example</a>, consider comparing two binary trees
to see if they have the same value sequence, even if their structures are different.
For example, here is code in <a href="https://lua.org">Lua 5</a> to generate some binary trees:
</p><pre>function T(l, v, r)
    return {left = l, value = v, right = r}
end

e = nil
t1 = T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))
t2 = T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 5, e)))))
t3 = T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 6, e)))))
</pre>


<p>
The trees <code>t1</code> and <code>t2</code> both contain the values 1, 2, 3, 4, 5; <code>t3</code> contains 1, 2, 3, 4, 6.

</p><p>
We can write a coroutine to walk over a tree and yield each value:
</p><pre>function visit(t)
    if t ~= nil then  -- note: ~= is &#34;not equal&#34;
        visit(t.left)
        coroutine.yield(t.value)
        visit(t.right)
    end
end
</pre>


<p>
Then to compare two trees, we can create two visit coroutines and
alternate between them to read and compare successive values:
</p><pre>function cmp(t1, t2)
    co1 = coroutine.create(visit)
    co2 = coroutine.create(visit)
    while true
    do
        ok1, v1 = coroutine.resume(co1, t1)
        ok2, v2 = coroutine.resume(co2, t2)
        if ok1 ~= ok2 or v1 ~= v2 then
            return false
        end
        if not ok1 and not ok2 then
            return true
        end
    end
end
</pre>


<p>
The <code>t1</code> and <code>t2</code> arguments to <code>coroutine.resume</code> are only used on the first iteration,
as the argument to <code>visit</code>.
Subsequent resumes return that value from <code>coroutine.yield</code>, but the code ignores the value.

</p><p>
A more idiomatic Lua version would use <code>coroutine.wrap</code>, which returns a function
that hides the coroutine object:
</p><pre><span>function cmp(t1, t2)</span>
    next1 = coroutine.wrap(function() visit(t1) end)
    next2 = coroutine.wrap(function() visit(t2) end)
<span>    while true</span>
<span>    do</span>
        v1 = next1()
        v2 = next2()
        if v1 ~= v2 then
<span>            return false</span>
<span>        end</span>
        if v1 == nil and v2 == nil then
<span>            return true</span>
<span>        end</span>
<span>    end</span>
<span>end</span>
</pre>


<p>
When the coroutine has finished, the <code>next</code> function returns <code>nil</code> (<a href="https://gist.github.com/rsc/5908886288b741b847a83c0c6597c690">full code</a>).
<a href="#python"></a></p><h2 id="python"><a href="#python">Generators in Python (Iterators in CLU)</a></h2>


<p>
Python provides generators that look a lot like Lua&#39;s coroutines,
but they are not coroutines, so it&#39;s worth pointing out the differences.
The main difference is that the “obvious” programs don&#39;t work.
For example, here&#39;s a direct translation of our Lua tree and visitor to Python:
</p><pre>def T(l, v, r):
    return {&#39;left&#39;: l, &#39;value&#39;: v, &#39;right&#39;: r}

def visit(t):
    if t is not None:
        visit(t[&#39;left&#39;])
        yield t[&#39;value&#39;]
        visit(t[&#39;right&#39;])
</pre>


<p>
But this obvious translation doesn&#39;t work:
</p><pre>&gt;&gt;&gt; e = None
&gt;&gt;&gt; t1 = T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))
&gt;&gt;&gt; for x in visit(t1):
...     print(x)
...
4
&gt;&gt;&gt;
</pre>


<p>
We lost 1, 2, 3, and 5. What happened?

</p><p>
In Python, that <code>def visit</code> does not define an ordinary function.
Because the body contains a <code>yield</code> statement, the result is a generator instead:
</p><pre>&gt;&gt;&gt; type(visit(t1))
&lt;class &#39;generator&#39;&gt;
&gt;&gt;&gt;
</pre>


<p>
The call <code>visit(t[&#39;left&#39;])</code> doesn&#39;t run the code in <code>visit</code> at all.
It only creates and returns a new generator, which is then discarded.
To avoid discarding those results, you have to loop over the generator and re-yield them:
</p><pre><span></span>
<span>def visit(t):</span>
<span>    if t is not None:</span>
        for x in visit(t[&#39;left&#39;]):
            yield x
<span>        yield t[&#39;value&#39;]</span>
        for x in visit(t[&#39;right&#39;])
            yield x
</pre>


<p>
Python 3.3 introduced <code>yield</code> <code>from</code>, allowing:
</p><pre><span>def visit(t):</span>
<span>    if t is not None:</span>
        yield from visit(t[&#39;left&#39;]):
<span>        yield t[&#39;value&#39;]</span>
        yield from visit(t[&#39;right&#39;])
</pre>


<p>
The generator object contains the state of the single call to <code>visit</code>,
meaning local variable values and which line is executing.
That state is pushed onto the call stack each time the generator is resumed
and then popped back into the generator object at each <code>yield</code>,
which can only occur in the top-most call frame.
In this way, the generator uses the same stack as the original program,
avoiding the need for a full coroutine implementation
but introducing these confusing limitations instead.

</p><p>
Python&#39;s generators appear to be almost exactly copied from CLU,
which pioneered this abstraction (and so many other things),
although CLU calls them iterators, not generators.
A CLU tree iterator looks like:
</p><pre>visit = iter (t: cvt) yields (int):
    tagcase t
        tag empty: ;
        tag non_empty(t: node):
            for x: int
                in tree$visit(t.left) do
                    yield(x);
                    end;
            yield(t.value);
            for x: int
                in tree$visit(t.right) do
                    yield(x);
                    end;
        end;
    end visit;
</pre>


<p>
The syntax is different, especially the <code>tagcase</code> that is examining
a tagged union representation of a tree, but the basic structure,
including the nested <code>for</code> loops, is exactly the same as our first
working Python version.
Also, because CLU was statically typed, <code>visit</code> is clearly marked as an iterator (<code>iter</code>)
not a function (<code>proc</code> in CLU).
Thanks to that type information,
misuse of <code>visit</code> as an ordinary function call,
like in our buggy Python example,
is something that the compiler could (and I assume did) diagnose.

</p><p>
About CLU&#39;s implementation, the original implementers wrote,
“Iterators are a form of coroutine; however, their use is sufficiently constrained
that they are implemented using just the program stack.
Using an iterator is therefore only slightly more expensive than using a
procedure.”
This sounds exactly like the explanation I gave above for the Python generators.
For more, see Barbara Liskov <i>et al.</i>&#39;s 1977 paper
“<a href="https://dl.acm.org/doi/10.1145/359763.359789">Abstraction Mechanisms in CLU</a>”,
specifically sections 4.2, 4.3, and 6.
<a href="#thread"></a></p><h2 id="thread"><a href="#thread">Coroutines, Threads, and Generators</a></h2>


<p>
At first glance, coroutines, threads, and generators look alike.
All three provide <a href="https://research.swtch.com/pcdata">concurrency</a> in one form or another,
but they differ in important ways.
</p><ul>
<li>


<p>
Coroutines provide concurrency without parallelism:
when one coroutine is running, the one that resumed it
or yielded to it is not.

</p><p>
Because coroutines run one at a time and only switch at specific
points in the program, the coroutines can share data among themselves
without races.
The explicit switches (<code>coroutine.resume</code> in the first Lua example
or calling a <code>next</code> function in the second Lua example)
serve as synchronization points, creating <a href="https://research.swtch.com/gomm#gos_memory_model_today">happens-before edges</a>.

</p><p>
Because scheduling is explicit (without any preemption)
and done entirely without the operating system,
a coroutine switch takes at most around ten nanoseconds, usually even less.
Startup and teardown is also much cheaper than threads.
</p></li><li>


<p>
Threads provide more power than coroutines, but with more cost.
The additional power is parallelism, and the cost is
the overhead of scheduling, including more expensive context switches
and the need to add preemption in some form.
Typically the operating system provides threads,
and a thread switch takes a few microseconds.

</p><p>
For this taxonomy, Go&#39;s goroutines are cheap threads:
a goroutine switch is closer to a few hundred nanoseconds,
because the Go runtime takes on some of the scheduling work,
but goroutines still provide the full parallelism and preemption
of threads.
(Java&#39;s new lightweight threads are basically the same as goroutines.)
</p></li><li>


<p>
Generators provide less power than coroutines, because only
the top-most frame in the coroutine is allowed to yield.
That frame is moved back and forth between an object and the call stack
to suspend and resume it.</p></li></ul>


<p>
Coroutines are a useful building block for writing programs that want
concurrency for program structuring
but not for parallelism.
For one detailed example of that, see my previous post,
“<a href="https://research.swtch.com/pcdata">Storing Data in Control Flow</a>”.
For other examples, see Ana Lúcia De Moura and Roberto Ierusalimschy&#39;s 2009 paper
“<a href="https://dl.acm.org/doi/pdf/10.1145/1462166.1462167">Revisiting Coroutines</a>”.
For the original example, see Melvin Conway&#39;s 1963 paper
“<a href="https://dl.acm.org/doi/pdf/10.1145/366663.366704">Design of a Separable Transition-Diagram Compiler</a>”.
<a href="#why"></a></p><h2 id="why"><a href="#why">Why Coroutines in Go?</a></h2>


<p>
Coroutines are a concurrency pattern not directly
served by existing Go concurrency libraries.
Goroutines are often close enough,
but as we saw,
they are not the same, and sometimes that difference matters.

</p><p>
For example,
Rob Pike&#39;s 2011 talk “<a href="https://go.dev/talks/2011/lex.slide">Lexical Scanning in Go</a>”
presents the original lexer and parser for the <a href="https://go.dev/pkg/text/template">text/template package</a>.
They ran in separate goroutines connected by a channel,
imperfectly simulating a pair of coroutines: the
lexer and parser ran in parallel, with the lexer looking ahead to
the next token while the parser processed the most recent one.
Generators would not have been good enough—the lexer yields values from many different functions—but
full goroutines proved to be a bit too much.
The parallelism provided by the goroutines caused races
and eventually led to abandoning the design
in favor of the lexer storing state in an object,
which was a more faithful simulation of a coroutine.
Proper coroutines would have avoided the races
and been more efficient than goroutines.

</p><p>
An anticipated future use case for coroutines in Go
is iteration over generic collections.
We have discussed adding support to Go for
<a href="https://github.com/golang/go/discussions/56413">ranging over functions</a>,
which would encourage authors of collections and other abstractions
to provide CLU-like iterator functions.
Iterators can be implemented today using function values, without any language changes.
For example, a slightly simplified tree iterator in Go could be:
</p><pre>func (t *Tree[V]) All(yield func(v V)) {
    if t != nil {
        t.left.All(yield)
        yield(t.value)
        t.right.All(yield)
    }
}
</pre>


<p>
That iterator can be invoked today as:
</p><pre>t.All(func(v V) {
    fmt.Println(v)
})
</pre>


<p>
and perhaps a variant could be invoked in a future version of Go as:
</p><pre>for v := range t.All {
    fmt.Println(v)
}
</pre>


<p>
Sometimes, however, we want to iterate over a collection
in a way that doesn&#39;t fit a single <code>for</code> loop.
The binary tree comparison is an example of this:
the two iterations need to be interlaced somehow.
As we&#39;ve already seen, coroutines would provide an answer,
letting us turn a function like <code>(*Tree).All</code> (a “push” iterator)
into a function that returns a stream of values, one per call
(a “pull” iterator).
<a href="#how"></a></p><h2 id="how"><a href="#how">How to Implement Coroutines in Go</a></h2>


<p>
If we are to add coroutines to Go, we should aim to do it without language changes.
That means the definition of coroutines should be possible to implement
and understand in terms of ordinary Go code.
Later, I will argue for an optimized implementation provided directly by the runtime,
but that implementation should be indistinguishable from the pure Go definition.

</p><p>
Let&#39;s start with a very simple version that ignores the yield operation entirely.
It just runs a function in another goroutine:
</p><pre>package coro

func New[In, Out any](f func(In) Out) (resume func(In) Out) {
    cin := make(chan In)
    cout := make(chan Out)
    resume = func(in In) Out {
        cin &lt;- in
        return &lt;-cout
    }
    go func() { cout &lt;- f(&lt;-cin) }()
    return resume
}
</pre>


<p>
<code>New</code> takes a function <code>f</code> which must have one argument and one result.
<code>New</code> allocates channels, defines <code>resume</code>,
creates a goroutine to run <code>f</code>,
and returns the <code>resume</code> funtion.
The new goroutine blocks on <code>&lt;-cin</code>,
so there is no opportunity for parallelism.
The <code>resume</code> function unblocks the
new goroutine by sending an <code>in</code> value and then
blocks receiving an <code>out</code> value.
This send-receive pair makes a coroutine switch.
We can use <code>coro.New</code> like this (<a href="https://go.dev/play/p/gLhqAutT9Q4">full code</a>):
</p><pre>func main() {
    resume := coro.New(strings.ToUpper)
    fmt.Println(resume(&#34;hello world&#34;))
}
</pre>


<p>
So far, <code>coro.New</code> is just a clunky way to call a function.
We need to add <code>yield</code>, which we can pass as an argument to <code>f</code>:
</p><pre>func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) Out) {
<span></span>
<span>    cin := make(chan In)</span>
<span>    cout := make(chan Out)</span>
<span>    resume = func(in In) Out {</span>
<span>        cin &lt;- in</span>
<span>        return &lt;-cout</span>
<span>    }</span>
    yield := func(out Out) In {
        cout &lt;- out
        return &lt;-cin
    }
    go func() { cout &lt;- f(&lt;-cin, yield) }()
<span>    return resume</span>
<span>}</span>
</pre>


<p>
Note that there is still no parallelism here: <code>yield</code> is another send-receive pair.
These goroutines are constrained by the communication pattern
to act indistinguishably from coroutines.
<a href="#parser"></a></p><h2 id="parser"><a href="#parser">Example: String Parser</a></h2>


<p>
Before we build up to iterator conversion, let&#39;s look at a few simpler examples.
In “<a href="https://research.swtch.com/pcdata">Storing Data in Control Flow</a>,” we considered the problem of
taking a function
</p><pre>func parseQuoted(read func() byte) bool
</pre>


<p>
and running it in a separate control flow so that bytes can be provided one
at a time to a <code>Write</code> method. Instead of the ad hoc channel-based implementation
in that post, we can use:
</p><pre>type parser struct {
    resume func(byte) Status
}

func (p *parser) Init() {
    coparse := func(_ byte, yield func(Status) byte) Status {
        read := func() byte { return yield(NeedMoreInput) }
        if !parseQuoted(read) {
            return BadInput
        }
        return Success
    }
    p.resume = coro.New(coparse)
    p.resume(0)
}

func (p *parser) Write(c byte) Status {
    return p.resume(c)
}
</pre>


<p>
The <code>Init</code> funtion does all the work, and not much.
It defines a function <code>coparse</code> that has the signature needed by <code>coro.New</code>,
which means adding a throwaway input of type <code>byte</code>.
That function defines a <code>read</code> that yields <code>NeedMoreInput</code>
and then returns the byte provided by the caller.
It then runs <code>parseQuoted(read)</code>, converting the boolean result
to the usual status code.
Having created a coroutine for <code>coparse</code> using <code>coro.New</code>,
<code>Init</code> calls <code>p.resume(0)</code> to allow <code>coparse</code> to advance
to the first read in <code>parseQuoted</code>.
Finally the <code>Write</code> method is a trivial wrapper around <code>p.resume</code> (<a href="https://go.dev/play/p/MNGVPk11exV">full code</a>).

</p><p>
This setup abstracts away the pair of channels that we
maintained by hand in the previous post, allowing us to work
at a higher level as we write the program.
<a href="#sieve"></a></p><h2 id="sieve"><a href="#sieve">Example: Prime Sieve</a></h2>


<p>
As a slightly larger example, consider <a href="https://www.cs.dartmouth.edu/~doug/sieve/sieve.pdf">Doug McIlroy&#39;s concurrent prime sieve</a>.
It consists of a pipeline of coroutines, one for each prime <code>p</code>, each running:
</p><pre>loop:
    n = get a number from left neighbor
    if (p does not divide n)
        pass n to right neighbor
</pre>


<p>
A counting coroutine on the leftmost side of the pipeline feeds the numbers 2, 3, 4, ... into the left end of the pipeline.
A printing coroutines on the rightmost side can read primes out, print them, and create new filtering coroutines.
The first filter in the pipeline removes multiples of 2, the next removes multiples of 3, the next removes multiples of 5, and so on.

</p><p>
The <code>coro.New</code> primitive we&#39;ve created lets us take a straightforward loop that yields values
and convert it into a function that can be called to obtain each value one at a time.
Here is the counter:
</p><pre>func counter() func(bool) int {
    return coro.New(func(more bool, yield func(int) bool) int {
        for i := 2; more; i++ {
            more = yield(i)
        }
        return 0
    })
}
</pre>


<p>
The counter logic is the function literal passed to <code>New</code>.
It takes a yield function of type <code>func(int)</code> <code>bool</code>.
The code yields a value by passing it to <code>yield</code> and then receives back a boolean
saying whether to continue generating more numbers.
When told to stop, either because <code>more</code> was false on entry
or because a <code>yield</code> call returned false,
the loop ends.
It returns a final, ignored value, to satisfy the function
type required by <code>New</code>.

</p><p>
<code>New</code> turns this into loop a function that is the inverse of <code>yield</code>: a <code>func(bool)</code> <code>int</code>
that can be called with true to obtain the next value or with false to shut down
the generator.
The filtering coroutine is only slightly more complex:
</p><pre>func filter(p int, next func(bool) int) (filtered func(bool) int) {
    return coro.New(func(more bool, yield func(int) bool) int {
        for more {
            n := next(true)
            if n%p != 0 {
                more = yield(n)
            }
        }
        return next(false)
    })
}
</pre>


<p>
It takes a prime <code>p</code> and a <code>next</code> func connected to the coroutine on the left
and then returns the filtered output stream to connect to the coroutine on the right.

</p><p>
Finally we have the printing coroutine:
</p><pre>func main() {
    next := counter()
    for i := 0; i &lt; 10; i++ {
        p := next(true)
        fmt.Println(p)
        next = filter(p, next)
    }
    next(false)
}
</pre>


<p>
Starting with the counter, <code>main</code> maintains in <code>next</code> the output
of the pipeline constructed so far.
Then it loops: read a prime <code>p</code>, print <code>p</code>, and then add a new
filter on the right end of the pipeline to remove multiples of <code>p</code> (<a href="https://go.dev/play/p/3OHQ_FHe_Na">full code</a>).

</p><p>
Notice that the calling relationship between coroutines can change over time:
any coroutine C can call another coroutine D&#39;s <code>next</code> function and become the
coroutine that D yields to.
The counter&#39;s first <code>yield</code> goes to <code>main</code>, while its subsequent <code>yield</code>s
go to the 2-filter.
Similarly each <code>p</code>-filter <code>yield</code>s its first output (the next prime) to <code>main</code>
while its subsequent <code>yield</code>s go to the filter for that next prime.
<a href="#goroutines"></a></p><h2 id="goroutines"><a href="#goroutines">Coroutines and Goroutines</a></h2>


<p>
In a certain sense, it is a misnomer to call these control flows coroutines.
They are full goroutines, and they can do everything an ordinary
goroutine can, including block waiting for mutexes, channels,
system calls, and so on.
What <code>coro.New</code> does is create goroutines
with access to coroutine switch operations
inside the <code>yield</code> and <code>resume</code> functions (which the sieve calls <code>next</code>).
The ability to use those operations can even be passed to
different goroutines, which is happening with <code>main</code> handing off
each of its <code>next</code> streams to each successive <code>filter</code> goroutine.
Unlike the <code>go</code> statement, <code>coro.New</code> adds new concurrency to the program
<i>without</i> new parallelism.
The goroutine that <code>coro.New(f)</code> creates can only run
when some other goroutine explicitly loans it the
ability to run using <code>resume</code>; that loan is repaid by <code>yield</code>
or by <code>f</code> returning.
If you have just one main goroutine
and run 10 <code>go</code> statements, then all 11 goroutines can be running at once.
In contrast, if you have one main goroutine
and run 10 <code>coro.New</code> calls, there are now 11 control flows
but the parallelism of the program is what it was before: only one runs at a time.
Exactly which goroutines are paused in coroutine operations
can vary as the program runs, but the parallelism never increases.

</p><p>
In short, <code>go</code> creates a new concurrent, <i>parallel</i> control flow,
while <code>coro.New</code> creates a new concurrent, <i>non-parallel</i> control flow.
It is convenient to continue to talk about the non-parallel control flows
as coroutines, but remember that exactly which goroutines are
“non-parallel” can change over the execution of a program,
exactly the same way that which goroutines are receiving or sending from channels
can change over the execution of a program.
<a href="#resume"></a></p><h2 id="resume"><a href="#resume">Robust Resumes</a></h2>


<p>
There are a few improvements we can make to <code>coro.New</code> so that it works better in real programs.
The first is to allow <code>resume</code> to be called after the function is done: right now it deadlocks.
Let&#39;s add a bool result indicating whether <code>resume</code>&#39;s result came from a yield.
The <code>coro.New</code> implementation we have so far is:
</p><pre>func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) Out) {
    cin := make(chan In)
    cout := make(chan Out)
    resume = func(in In) Out {
        cin &lt;- in
        return &lt;-cout
    }
    yield := func(out Out) In {
        cout &lt;- out
        return &lt;-cin
    }
    go func() {
        cout &lt;- f(&lt;-cin, yield)
    }()
    return resume
}
</pre>


<p>
To add this extra result, we need to track whether <code>f</code> is running
and return that result from <code>resume</code>:
</p><pre>func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool)) {
<span>    cin := make(chan In)</span>
<span>    cout := make(chan Out)</span>
    running := true
    resume = func(in In) (out Out, ok bool) {
        if !running {
            return
        }
<span>        cin &lt;- in</span>
        out = &lt;-cout
        return out, running
<span>    }</span>
<span>    yield := func(out Out) In {</span>
<span>        cout &lt;- out</span>
<span>        return &lt;-cin</span>
<span>    }</span>
<span>    go func() {</span>
        out := f(&lt;-cin, yield)
        running = false
        cout &lt;- out
<span>    }()</span>
<span>    return resume</span>
<span>}</span>
</pre>


<p>
Note that since <code>resume</code> can only run when the calling goroutine is blocked,
and vice versa, sharing the <code>running</code> variable is not a race.
The two are synchronizing by taking turns executing.
If <code>resume</code> is called after the coroutine has exited, <code>resume</code> returns a zero value and false.

</p><p>
Now we can tell when a goroutine is done (<a href="https://go.dev/play/p/Y2tcF-MHeYS">full code</a>):
</p><pre>func main() {
    resume := coro.New(func(_ int, yield func(string) int) string {
        yield(&#34;hello&#34;)
        yield(&#34;world&#34;)
        return &#34;done&#34;
    })
    for i := 0; i &lt; 4; i++ {
        s, ok := resume(0)
        fmt.Printf(&#34;%q %v\n&#34;, s, ok)
    }
}


$ go run cohello.go
&#34;hello&#34; true
&#34;world&#34; true
&#34;done&#34; false
&#34;&#34; false
$
</pre>
<a href="#iterator"><h2 id="iterator">Example: Iterator Conversion</h2></a>


<p>
The prime sieve example showed direct use of <code>coro.New</code>,
but the <code>more bool</code> argument was a bit awkward and does not
match the iterator functions we saw before.
Let&#39;s look at converting any push iterator into a pull iterator
using <code>coro.New</code>.
We will need a way to terminate the coroutine running
the push iterator if we want to stop early, so we will add a boolean
result from <code>yield</code> indicating whether to continue,
just like in the prime sieve:
</p><pre>push func(yield func(V) bool)
</pre>


<p>
The goal of the new function <code>coro.Pull</code> is to turn that push function
into a pull iterator. The iterator will return the next value
and a boolean indicating whether the iteration is over,
just like a channel receive or map lookup:
</p><pre>pull func() (V, bool)
</pre>


<p>
If we want to stop the push iteration early, we need some
way to signal that, so <code>Pull</code> will return not just the pull
function but also a stop function:
</p><pre>stop func()
</pre>


<p>
Putting those together, the full signature of <code>Pull</code> is:
</p><pre>func Pull[V any](push func(yield func(V) bool)) (pull func() (V, bool), stop func()) {
    ...
}
</pre>


<p>
The first thing <code>Pull</code> needs to do is start a coroutine to run the push iterator,
and to do that it needs a wrapper function with the right type,
namely one that takes a <code>more bool</code> to match the bool result from <code>yield</code>,
and that returns a final <code>V</code>.
The <code>pull</code> function can call <code>resume(true)</code>, while the <code>stop</code> function can call <code>resume(false)</code>:
</p><pre>func Pull[V any](push func(yield func(V) bool)) (pull func() (V, bool), stop func()) {
    copush := func(more bool, yield func(V) bool) V {
        if more {
            push(yield)
        }
        var zero V
        return zero
    }
    resume := coro.New(copush)
    pull = func() (V, bool) {
        return resume(true)
    }
    stop = func() {
        resume(false)
    }
    return pull, stop
}
</pre>


<p>
That&#39;s the complete implementation.
With the power of <code>coro.New</code>, it took very little code and effort to build a nice iterator converter.

</p><p>
To use <code>coro.Pull</code>, we need to redefine the tree&#39;s <code>All</code> method
to expect and use the new <code>bool</code> result from <code>yield</code>:
</p><pre>func (t *Tree[V]) All(yield func(v V) bool) {
    t.all(yield)
}

func (t *Tree[V]) all(yield func(v V) bool) bool {
    return t == nil ||
        t.Left.all(yield) &amp;&amp; yield(t.Value) &amp;&amp; t.Right.all(yield)
}
</pre>


<p>
Now we have everything we need to write a tree comparison function in Go (<a href="https://go.dev/play/p/hniFxnbXTgH">full code</a>):
</p><pre>func cmp[V comparable](t1, t2 *Tree[V]) bool {
    next1, stop1 := coro.Pull(t1.All)
    next2, stop2 := coro.Pull(t2.All)
    defer stop1()
    defer stop2()
    for {
        v1, ok1 := next1()
        v2, ok2 := next2()
        if v1 != v2 || ok1 != ok2 {
            return false
        }
        if !ok1 &amp;&amp; !ok2 {
            return true
        }
    }
}
</pre>


<h2 id="panic"><a href="#panic">Propagating Panics</a></h2>


<p>
Another improvement is to pass panics from a coroutine back to its caller,
meaning the coroutine that most recently called <code>resume</code> to run it
(and is therefore sitting blocked in <code>resume</code> waiting for it).
Some mechanism to inform one goroutine when another panics is a very common request,
but in general that can be difficult, because we don&#39;t know which
goroutine to inform and whether it is ready to hear that message.
In the case of coroutines, we have the caller blocked waiting for news,
so it makes sense to deliver news of the panic.

</p><p>
To do that, we can add a <code>defer</code> to catch a panic in the new coroutine
and trigger it again in the <code>resume</code> that is waiting.
</p><pre>type msg[T any] struct {
    panic any
    val   T
}
<span></span>
<span>func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool)) {</span>
<span>    cin := make(chan In)</span>
    cout := make(chan msg[Out])
<span>    running := true</span>
<span>    resume = func(in In) (out Out, ok bool) {</span>
<span>        if !running {</span>
<span>            return</span>
<span>        }</span>
<span>        cin &lt;- in</span>
        m := &lt;-cout
        if m.panic != nil {
            panic(m.panic)
        }
        return m.val, running
<span>    }</span>
<span>    yield := func(out Out) In {</span>
        cout &lt;- msg[Out]{val: out}
<span>        return &lt;-cin</span>
<span>    }</span>
<span>    go func() {</span>
        defer func() {
            if running {
                running = false
                cout &lt;- msg[Out]{panic: recover()}
            }
        }()
<span>        out := f(&lt;-cin, yield)</span>
<span>        running = false</span>
        cout &lt;- msg[Out]{val: out}
<span>    }()</span>
<span>    return resume</span>
<span>}</span>
</pre>


<p>
Let&#39;s test it out (<a href="https://go.dev/play/p/Sihm8KVlTIB">full code</a>):
</p><pre>func main() {
    defer func() {
        if e := recover(); e != nil {
            fmt.Println(&#34;main panic:&#34;, e)
            panic(e)
        }
    }()
    next, _ := coro.Pull(func(yield func(string) bool) {
        yield(&#34;hello&#34;)
        panic(&#34;world&#34;)
    })
    for {
        fmt.Println(next())
    }
}
</pre>


<p>
The new coroutine yields <code>hello</code> and then panics <code>world</code>.
That panic is propagated back to the main goroutine,
which prints the value and repanics.
We can see that the panic appears to originate in the call to <code>resume</code>:
</p><pre>% go run coro.go
hello true
main panic: world
panic: world [recovered]
    panic: world

goroutine 1 [running]:
main.main.func1()
    /tmp/coro.go:9 +0x95
panic({0x108f360?, 0x10c2cf0?})
    /go/src/runtime/panic.go:1003 +0x225
main.coro_New[...].func1()
    /tmp/coro.go.go:55 +0x91
main.Pull[...].func2()
    /tmp/coro.go.go:31 +0x1c
main.main()
    /tmp/coro.go.go:17 +0x52
exit status 2
%
</pre>
<a href="#cancel"><h2 id="cancel">Cancellation</h2></a>


<p>
Panic propagation takes care of telling the caller about an early coroutine exit,
but what about telling a coroutine about an early caller exit?
Analogous to the <code>stop</code> function in the pull iterator,
we need some way to signal to the coroutine that it&#39;s no longer needed,
perhaps because the caller is panicking, or perhaps because the caller
is simply returning.

</p><p>
To do that, we can change <code>coro.New</code> to return not just <code>resume</code> but
also a <code>cancel</code> func.
Calling <code>cancel</code> will be like <code>resume</code>, except that <code>yield</code> panics instead of returning a value.
If a coroutine panics in a different way during cancellation,
we want <code>cancel</code> to propagate that panic, just as <code>resume</code> does.
But of course we don&#39;t want <code>cancel</code> to propagate its own panic,
so we create a unique panic value we can check for.
We also have to handle a cancellation in before <code>f</code> begins.
</p><pre>var ErrCanceled = errors.New(&#34;coroutine canceled&#34;)
<span></span>
func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool), cancel func()) {
    cin := make(chan msg[In])
<span>    cout := make(chan msg[Out])</span>
<span>    running := true</span>
<span>    resume = func(in In) (out Out, ok bool) {</span>
<span>        if !running {</span>
<span>            return</span>
<span>        }</span>
        cin &lt;- msg[In]{val: in}
<span>        m := &lt;-cout</span>
<span>        if m.panic != nil {</span>
<span>            panic(m.panic)</span>
<span>        }</span>
<span>        return m.val, running</span>
<span>    }</span>
    cancel = func() {
        e := fmt.Errorf(&#34;%w&#34;, ErrCanceled) // unique wrapper
        cin &lt;- msg[In]{panic: e}
        m := &lt;-cout
        if m.panic != nil &amp;&amp; m.panic != e {
            panic(m.panic)
        }
    }
    yield := func(out Out) In {
        cout &lt;- msg[Out]{val: out}
        m := &lt;-cin
        if m.panic != nil {
            panic(m.panic)
        }
        return m.val
<span>    }</span>
<span>    go func() {</span>
<span>        defer func() {</span>
<span>            if running {</span>
<span>                running = false</span>
<span>                cout &lt;- msg[Out]{panic: recover()}</span>
<span>            }</span>
<span>        }()</span>
        var out Out
        m := &lt;-cin
        if m.panic == nil {
            out = f(m.val, yield)
        }
        running = false
        cout &lt;- msg[Out]{val: out}
    }()
    return resume, cancel
<span>}</span>
</pre>


<p>
We could change <code>Pull</code> to use panics to cancel iterators as well,
but in that context the explicit <code>bool</code> seems clearer,
especially since stopping an iterator is unexceptional.
<a href="#sieve2"></a></p><h2 id="sieve2"><a href="#sieve2">Example: Prime Sieve Revisited</a></h2>


<p>
Let&#39;s look at how panic propagation and cancellation make cleanup of the prime sieve “just work”.
First let&#39;s update the sieve to use the new API.
The <code>counter</code> and <code>filter</code> functions are already
“one-line” <code>return coro.New(...)</code> calls.
They change signature to include the additional cancel func returned from <code>coro.New</code>:
</p><pre>func counter() (func(bool) (int, bool), func()) {
    return coro.New(...)
}

func filter(p int, next func(bool) (int, bool)) (func(bool) (int, bool), func()) {
    return coro.New(...)
}
</pre>


<p>
Then let&#39;s convert the <code>main</code> function to be a <code>primes</code> function that prints <code>n</code> primes (<a href="https://go.dev/play/p/XWV8ACRKjDS">full code</a>):
</p><pre>func primes(n int) {
    next, cancel := counter()
    defer cancel()
    for i := 0; i &lt; n; i++ {
        p, _ := next(true)
        fmt.Println(p)
        next, cancel = filter(p, next)
        defer cancel()
    }
}
</pre>


<p>
When this function runs, after it has gotten <code>n</code> primes, it returns.
Each of the deferred <code>cancel</code> calls cleans up the
coroutines that were created.
And what if one of the coroutines has a bug and panics?
If the coroutine was resumed by a <code>next</code> call in <code>primes</code>,
then the panic comes back to <code>primes</code>, and <code>primes</code>&#39;s deferred
<code>cancel</code> calls clean up all the other coroutines.
If the coroutine was resumed by a <code>next</code> call in a <code>filter</code> coroutine,
then the panic will propagate up to the waiting <code>filter</code> coroutine
and then the next waiting <code>filter</code> coroutine, and so on, until it
gets to the <code>p</code> <code>:=</code> <code>next(true)</code> in <code>primes</code>, which will
again clean up the remaining coroutines.
<a href="#api"></a></p><h2 id="api"><a href="#api">API</a></h2>


<p>
The API we&#39;ve arrived at is:</p><blockquote>

<p>
New creates a new, paused coroutine ready to run the function f.
The new coroutine is a goroutine that never runs on its own:
it only runs while some other goroutine invokes and waits for it,
by calling resume or cancel.

</p><p>
A goroutine can pause itself and switch to the new coroutine by calling resume(in).
The first call to resume starts f(in, yield).
Resume blocks while f runs, until either f calls yield(out) or returns out.
When f calls yield, yield blocks and resume returns out, true.
When f returns, resume returns out, false.
When resume has returned due to a yield, the next resume(in)
switches back to f, with yield returning in.

</p><p>
Cancel stops the execution of f and shuts down the coroutine.
If resume has not been called,
then f does not run at all.
Otherwise, cancel causes the blocked yield call
to panic with an error satisfying errors.Is(err, ErrCanceled).

</p><p>
If f panics and does not recover the panic,
the panic is stopped in f&#39;s coroutine and restarted in the goroutine
waiting for f, by causing the blocked resume or cancel that is waiting
to re-panic with the same panic value.
Cancel does not re-panic when f&#39;s panic is one that
cancel itself triggered.

</p><p>
Once f has returned or panicked, the coroutine no longer exists.
Subsequent calls to resume return zero, false.
Subsequent calls to cancel simply return.

</p><p>
The functions resume, cancel, and yield can be passed between
and used by different goroutines, in effect dynamically changing
which goroutine is “the coroutine.”
Although New creates a new goroutine, it also establishes an
invariant that one goroutine is always blocked,
either in resume, cancel, yield, or (right after New)
waiting for the resume that will call f.
This invariant holds until f returns, at which point the
new goroutine is shut down.
The net result is that coro.New creates new concurrency in the program
without any new parallelism.

</p><p>
If multiple goroutines call resume or cancel, those calls are serialized.
Similarly, if multiple goroutines call yield, those calls are serialized.</p></blockquote>
<pre>func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool), cancel func())
</pre>
<a href="#efficiency"><h2 id="efficiency">Efficiency</h2></a>


<p>
As I said at the start, while it&#39;s important to have a definition of coroutines
that can be understood by reference to a pure Go implementation,
I believe we should use an optimized runtime implementation.
On my 2019 MacBook Pro, passing values back and
forth using the channel-based <code>coro.New</code> in this post requires
approximately 190ns per switch, or 380ns per value in <code>coro.Pull</code>.
Remember that <code>coro.Pull</code> would not be the standard way
to use an iterator: the standard way would be to invoke the iterator
directly, which has no coroutine overhead at all.
You only need <code>coro.Pull</code> when you want to process
iterated values incrementally, not using a single for loop.
Even so, we want to make <code>coro.Pull</code> as fast as we can.

</p><p>
First I tried having the compiler mark send-receive pairs
and leave hints for the runtime to fuse them into a single operation.
That would let the channel runtime bypass the scheduler
and jump directly to the other coroutine.
This implementation requires
about 118ns per switch, or 236ns per pulled value (38% faster).
That&#39;s better, but it&#39;s still not as fast as I would like.
The full generality of channels is adding too much overhead.

</p><p>
Next I added a direct coroutine switch to the runtime,
avoiding channels entirely.
That cuts the coroutine switch to three atomic compare-and-swaps
(one in the coroutine data structure, one for the scheduler status
of the blocking coroutine, and one for the scheduler status of the resuming coroutine),
which I believe is optimal given the safety invariants that must be maintained.
That implementation takes 20ns per switch, or 40ns per pulled value.
This is about 10X faster than the original channel implementation.
Perhaps more importantly, 40ns per pulled value seems small enough
in absolute terms not to be a bottleneck for code that needs <code>coro.Pull</code>.
      </p></div>
    </div></div>
  </body>
</html>
