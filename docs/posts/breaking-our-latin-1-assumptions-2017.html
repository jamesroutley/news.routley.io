<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/">Original</a>
    <h1>Breaking our Latin-1 assumptions (2017)</h1>
    
    <div id="readability-page-1" class="page"><div><p>So in my <a href="http://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points">previous post</a> I explored a specific (wrong) assumption that programmers
tend to make about the nature of code points and text.</p>

<p>I was asked multiple times about other assumptions we tend to make. There are a lot. Most
Latin-based scripts are simple, but most programmers spend their time dealing with Latin
text so these complexities never come up.</p>

<p>I thought it would be useful to share my personal list of
<a href="https://twitter.com/ManishEarth/status/810582690906931200">scripts that break our Latin-1 assumptions</a>. This is a list I mentally check against
whenever I am attempting to reason about text. I check if Iâ€™m making any assumptions that
break in these scripts. <em>Most</em> of these concepts are independent of Unicode; so any program
would have to deal with this regardless of encoding.</p>

<p>I again recommend going through <a href="https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/">eeveeâ€™s post</a>, since it covers many related issues.
<a href="https://github.com/jagracey/Awesome-Unicode">Awesome-Unicode</a> also has a lot of random tidbits about Unicode.</p>

<p>Anyway, hereâ€™s the list. Note that a lot of the concepts here exist in scripts other than the
ones listed, these are just the scripts <em>I</em> use for comparing.</p>

<h2 id="arabic--hebrew">Arabic / Hebrew</h2>

<p>Both Arabic and Hebrew are RTL scripts; they read right-to-left. This may even affect how
a page is laid out, see the <a href="https://he.wikipedia.org/wiki/%D7%A2%D7%9E%D7%95%D7%93_%D7%A8%D7%90%D7%A9%D7%99">Hebrew Wikipedia</a>.</p>

<p>They both have a concept of letters changing how they look depending on where they are in the word.
Hebrew has the â€œsofitâ€ letters, which use separate code points. For example, Kaf (×›) should be typed
as ×š at the end of a word. Greek has something similar with the sigma.</p>

<p>In Arabic, the letters can have up to four different forms, depending on whether they start a word,
end a word, are inside a word, or are used by themselves. These forms can look very different. They
donâ€™t use separate code points for this; however. You can see a list of these forms <a href="https://en.wikipedia.org/wiki/Arabic_alphabet#Table_of_basic_letters">here</a></p>

<p>Arabic can get pretty tricky â€“ the characters have to join up; and in cursive fonts (like those for Nastaliq),
you get a lot of complex ligatures.</p>

<p>As I mentioned in the last post, U+FDFD (ï·½), a ligature representing the Basamala,
is also a character that breaks a lot of assumptions.</p>

<h2 id="indic-scripts">Indic scripts</h2>

<p>Indic scripts are <em>abugidas</em>, where you have consonants with vowel modifiers. For example, à¤• is
â€œkÉ™â€, where the upside down â€œeâ€ is a schwa, something like an â€œuhâ€ vowel sound. You can change the
vowel by adding a diacritic (e.g <code>à¤¾</code>); getting things like à¤•à¤¾ (â€œkaaâ€) à¤•à¥‹ (â€œkohâ€) à¤•à¥‚ (â€œkooâ€).</p>

<p>You can also mash together consonants to create consonant clusters. The â€œviramaâ€ is a vowel-killer
symbol that removes the inherent schwa vowel. So, <code>à¤•</code> + <code>à¥</code> becomes <code>à¤•à¥</code>. This sound itself is
unpronounceable since à¤• is a stop consonant (vowel-killed consonants can be pronounced for nasal and some other
consonants though), but you can combine it with another consonant, as <code>à¤•à¥</code> + <code>à¤°</code> (â€œrÉ™â€), to get <code>à¤•à¥à¤°</code>
(â€œkrÉ™â€). Consonants can be strung up infinitely, and you can stick one or more vowel diacritics
after that. Usually, you wonâ€™t see more than two consonants in a cluster, but larger ones are not
uncommon in Sanskrit (or when writing down some onomatopoeia). They may not get rendered as single
glyphs, depending on the font.</p>

<p>One thing that crops up is that thereâ€™s no unambiguous concept of a letter here. There
is a concept of an â€œaksharaâ€, which basically includes the vowel diacritics, and
depending on who you talk to may also include consonant clusters. Often things are
clusters an akshara depending on whether theyâ€™re drawn with an explicit virama
or form a single glyph.</p>

<p>In general the nature of the virama as a two-way combining character in Unicode is pretty new.</p>

<h2 id="hangul">Hangul</h2>

<p>Korean does its own fun thing when it comes to conjoining characters. Hangul has a concept
of a â€œsyllable blockâ€, which is basically a letter. Itâ€™s made up of a leading consonant,
medial vowel, and an optional tail consonant. á„€á…¡á†¨ is an example of
such a syllable block, and it can be typed as á„€ + á…¡ + á†¨. It can
also be typed as ê°, which is a â€œprecomposed formâ€ (and a single code point).</p>

<p>These characters are examples of combining characters with very specific combining rules. Unlike
accents or other diacritics, these combining characters will combine with the surrounding characters
only when the surrounding characters form an L-V-T or L-V syllable block.</p>

<p>As I mentioned in my previous post, apparently syllable blocks with more (adjacent) Ls, Vs, and Ts are
also valid and used in Old Korean, so the grapheme segmentation algorithm in Unicode considers
â€œá„€á„€á„€á„€á…¡á†¨á†¨á†¨â€ to be a single grapheme (<a href="http://www.unicode.org/reports/tr29/#Hangul_Syllable_Boundary_Determination">it explicitly mentions this</a>).
Iâ€™m not aware of any fonts which render these as a single syllable block, or if thatâ€™s even
a valid thing to do.</p>

<h2 id="han-scripts">Han scripts</h2>

<p>So Chinese (Hanzi), Japanese (Kanji<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>), Korean (Hanja<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>), and Vietnamese (HÃ¡n tá»±, along with Chá»¯
NÃ´m <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>) all share glyphs, collectively called â€œHan charactersâ€ (or CJK characters<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">4</a></sup>). These
languages at some point in their history borrowed the Chinese writing system, and made their own
changes to it to tailor to their needs.</p>

<p>Now, the Han characters are ideographs. This is not a phonetic script; individual characters
represent words. The word/idea they represent is not always consistent across languages. The
pronounciation is usually different too. Sometimes, the glyph is drawn slightly differently based on
the language used. There are around 80,000 Han ideographs in Unicode right now.</p>

<p>The concept of ideographs itself breaks some of our Latin-1 assumptions. For example, how
do you define Levenshtein edit distance for text using Han ideographs? The straight answer is that
you canâ€™t, though if you step back and decide <em>why</em> you need edit distance you might be able
to find a workaround. For example, if you need it to detect typos, the userâ€™s input method
may help. If itâ€™s based on pinyin or bopomofo, you might be able to reverse-convert to the
phonetic script, apply edit distance in that space, and convert back. Or not. I only maintain
an idle curiosity in these scripts and donâ€™t actually use them, so Iâ€™m not sure how well this would
work.</p>

<p>The concept of halfwidth character is a quirk that breaks some assumptions.</p>

<p>In the space of Unicode in particular, all of these scripts are represented by a single set of
ideographs. This is known as â€œHan unificationâ€. This is a pretty controversial issue, but the
end result is that rendering may sometimes be dependent on the language of the text, which
e.g. in HTML you set with a <code>&lt;span lang=whatever&gt;</code>. <a href="https://en.wikipedia.org/wiki/Han_unification#Examples_of_language-dependent_glyphs">The wiki page</a> has some examples of
encoding-dependent characters.</p>

<p>Unicode also has a concept of variation selector, which is a code point that can be used to
select between variations for a code point that has multiple ways of being drawn. These
do get used in Han scripts.</p>

<p>While this doesnâ€™t affect rendering, Unicode, as a system for <em>describing</em> text,
also has a concept of interlinear annotation characters. These are used to represent
<a href="https://en.wikipedia.org/wiki/Ruby_character">furigana / ruby</a>. Fonts donâ€™t render this, but itâ€™s useful if you want to represent
text that uses ruby. Similarly, there are <a href="https://en.wikipedia.org/wiki/Chinese_character_description_languages#Ideographic_Description_Sequences">ideographic description sequences</a> which
can be used to â€œbuild upâ€ glyphs from smaller ones when the glyph canâ€™t be encoded in
Unicode. These, too, are not to be rendered, but can be used when you want to describe
the existence of a character like <a href="https://en.wikipedia.org/wiki/Biangbiang_noodles#Chinese_character_for_bi.C3.A1ng">biÃ¡ng</a>. These are not things a programmer
needs to worry about; I just find them interesting and couldnâ€™t resist mentioning them :)</p>

<p>Japanese speakers havenâ€™t completely moved to Unicode; there are a lot of things out there
using Shift-JIS, and IIRC there are valid reasons for that (perhaps Han unification?). This
is another thing you may have to consider.</p>

<p>Finally, these scripts are often written <em>vertically</em>, top-down. <a href="https://en.wikipedia.org/wiki/Mongolian_script">Mongolian</a>, while
not being a Han script, is written vertically sideways, which is pretty unique. The
CSS <a href="https://drafts.csswg.org/css-writing-modes/">writing modes</a> spec introduces various concepts related to this, though thatâ€™s mostly in the
context of the Web.</p>

<h2 id="thai--khmer--burmese--lao">Thai / Khmer / Burmese / Lao</h2>

<p>These scripts donâ€™t use spaces to split words. Instead, they have rules for what kinds of sequences
of characters start and end a word. This can be determined programmatically, however IIRC the
Unicode spec does not attempt to deal with this. There are libraries you can use here instead.</p>

<h2 id="latin-scripts-themselves">Latin scripts themselves!</h2>

<p>Turkish is a latin-based script. But it has a quirk: The uppercase of â€œiâ€ is
a dotted â€œÄ°â€, and the lowercase of â€œIâ€ is â€œÄ±â€. If doing case-based operations, try to use
a Unicode-aware library, and try to provide the locale if possible.</p>

<p>Also, not all code points have a single-codepoint uppercase version. The eszett (ÃŸ) capitalizes
to â€œSSâ€. Thereâ€™s also the â€œcapitalâ€ eszett áº, but its usage seems to vary and Iâ€™m not exactly
sure how it interacts here.</p>

<p>While Latin-1 uses precomposed characters, Unicode also introduces ways to specify the same
characters via combining diacritics. Treating these the same involves using the normalization
algorithms (NFC/NFD).</p>

<h2 id="emoji">Emoji</h2>

<p>Well, not a script<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. But emoji is weird enough that it breaks many of our assumptions. The
scripts above cover most of these, but itâ€™s sometimes easier to think of them
in the context of emoji.</p>

<p>The main thing with emoji is that you can use a zero-width-joiner character to glue emoji together.</p>

<p>For example, the family emoji ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ (may not render for you) is made by using the woman/man/girl/boy
emoji and gluing them together with ZWJs. You can see its decomposition in <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%91%A9%E2%80%8D%F0%9F%91%A9%E2%80%8D%F0%9F%91%A7%E2%80%8D%F0%9F%91%A6">uniview</a>.</p>

<p>There are more sequences like this, which you can see in the <a href="http://unicode.org/Public/emoji/4.0/emoji-zwj-sequences.txt">emoji-zwj-sequences</a> file. For
example, MAN + ZWJ + COOK will give a male cook emoji (font support is sketchy).
Similarly, SWIMMER + ZWJ + FEMALE SIGN is a female swimmer. You have both sequences of
the form â€œgendered person + zwj + thingâ€, and â€œemoji containing human + zwj + genderâ€,
IIRC due to legacy issues<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">6</a></sup></p>

<p>There are also <a href="http://www.unicode.org/reports/tr51/#Diversity">modifier characters</a> that let you change the skin tone of an emoji that
contains a human (or human body part, like the hand-gesture emojis) in it.</p>

<p>Finally, the flag emoji are pretty special snowflakes. For example, ğŸ‡ªğŸ‡¸ is the Spanish
flag. Itâ€™s made up of <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%87%AA%F0%9F%87%B8">two regional indicator characters for â€œEâ€ and â€œSâ€</a>.</p>

<p>Unicode didnâ€™t want to deal with adding new flags each time a new country or territory pops up. Nor
did they want to get into the tricky business of determining what a country <em>is</em>, for example
when dealing with disputed territories. So instead, they just defined these regional indicator
symbols. Fonts are supposed to take pairs of RI symbols<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">7</a></sup> and map the country code to a flag.
This mapping is up to them, so itâ€™s totally valid for a font to render a regional indicator
pair â€œEâ€ + â€œSâ€ as something other than the flag of Spain. On some Chinese systems, for example,
the flag for Taiwan (ğŸ‡¹ğŸ‡¼) may not render.</p>

<hr/>

<p>I hightly recommend comparing against this relatively small list of scripts the next time you
are writing code that does heavy manipulation of user-provided strings.</p>


</div></div>
  </body>
</html>
