<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://roxeem.com/2025/09/30/what-net-10-gc-changes-mean-for-developers/">Original</a>
    <h1>What .NET 10 GC Changes Mean for Developers</h1>
    
    <div id="readability-page-1" class="page"><div>
			
<p>What if I told you that starting with .NET 10, several of your fundamental ideas about garbage collection are now outdated? Imagine that there are actual improvements that can sometimes cause two to three times better memory usage and speed. These improvements are available through a series of runtime switches and new optimization behaviors. However, it is important to consider that these improvements come with trade-offs that you need to evaluate instead of simply enabling them on faith.</p>



<p>In this post, I’ll take you through the real story in .NET 10, show you the rationale behind the new GC features, give you actionable patterns, code, and measurement tools, and help you answer: should you rely on these improvements or tune and even disable them for your scenario?</p>



<h2 id="fundamentals-of-net-garbage-collection">Fundamentals of .NET Garbage Collection</h2>



<p>Since the dawn of the CLR, .NET’s memory management model has used a <strong>generational, tracing garbage collector</strong>. This model means all object allocations live on a managed heap, with the GC tracking which objects are still “in use” (reachable from application roots) and which can be reclaimed.</p>



<p>The GC splits heap memory into:</p>



<ul>
<li><strong>Generation 0</strong>: the youngest objects, collected most frequently.</li>



<li><strong>Generation 1</strong>: survivors promoted from Gen 0, acting as a buffer.</li>



<li><strong>Generation 2</strong>: long-lived survivors—think caches, statics, or persistent models.</li>



<li><strong>Large Object Heap (LOH/”Gen 3″)</strong>: for objects &gt;85 KB, managed specially to avoid frequent compaction.</li>
</ul>



<p>Why generations? Because most objects die young. Focusing collections on Gen 0 means low overhead, fewer full-heap pauses, and better cache locality.</p>



<p><strong>GC Collection Phases</strong></p>



<p>Every GC cycle runs in three broad steps:</p>



<ol>
<li><strong>Mark</strong> live objects starting from known roots.</li>



<li><strong>Relocate</strong> references if objects might be moved.</li>



<li><strong>Compact</strong> memory by sliding/live object movement, reducing fragmentation.</li>
</ol>



<h3 id="modes-workstation-vs-server-gc">GC Modes: Workstation vs Server GC</h3>



<ul>
<li><strong>Workstation GC</strong>: Default for desktop apps. Designed for UI responsiveness using minimal threads and background collection.</li>



<li><strong>Server GC</strong>: Designed for front/back-end services. Parallelizes collection across multiple heaps/cores, maximizing throughput.</li>
</ul>



<p>Configuration is a single runtime flag:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>JSON</span></p><pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;runtimeOptions&#34;</span><span>: {</span></span>
<span><span>    </span><span>&#34;configProperties&#34;</span><span>: {</span></span>
<span><span>      </span><span>&#34;System.GC.Server&#34;</span><span>: </span><span>true</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div>



<blockquote>
<p>ℹ️ Always benchmark with the GC mode intended for your deployment. The wrong mode often causes unexpected latency.</p>
</blockquote>



<h3 id="background-and-concurrent-gc">Background and Concurrent GC</h3>



<p>.NET has long supported background collection for Gen 2, allowing most app threads to continue running while the GC performs its work in another thread.</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>JSON</span></p><pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;runtimeOptions&#34;</span><span>: {</span></span>
<span><span>    </span><span>&#34;configProperties&#34;</span><span>: {</span></span>
<span><span>      </span><span>&#34;System.GC.Concurrent&#34;</span><span>: </span><span>true</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div>



<h2 id="why-generational-gc">Why Generational GC?</h2>



<p>Imagine a room with boxes (objects) and a robot cleaner (the GC). Every few minutes, the robot checks which boxes are “still needed,” starting with boxes close to the door (Gen 0: new arrivals), then a shelf behind the door (Gen 1: short-term survivors), and, less often, the back wall (Gen 2: persistent storage). By focusing on the door first, the robot spends less time on each sweep. However, if the back wall fills up, the robot is forced to perform a full sweep, which results in a noticeable pause.</p>



<p>This analogy highlights the <strong>GC’s main tradeoff</strong>: it minimizes work most of the time, but when collections escalate, the cost is non-linear.</p>



<h2 id="the-evolution-of-gc-in-net">The Evolution of GC in .NET</h2>



<p>Before we dissect what’s new in .NET 10, let’s recall the story so far. Each major .NET release has pushed GC performance and developer flexibility forward:</p>



<ul>
<li><strong>.NET Framework Era</strong>: Introduced generational, workstation/server GC models, background collection, and LOH (uncompacted by default).</li>



<li><strong>.NET Core (1-3)</strong>: Modularized runtime, made GC truly cross-platform, and improved per-thread/per-core server scalability.</li>



<li><strong>.NET Core 3.1–6</strong>: LOH compaction on-demand, GCHeapHardLimit for containers/cloud, and support for finer GC configuration.</li>



<li><strong>.NET 7-9</strong>: Region-based heap management and DATAS (Dynamic Adaptation To Application Sizes), auto-tuning heap use based on app behavior (especially in containers).</li>



<li><strong>.NET 10</strong>: Big leaps in escape analysis (for stack allocation), delegate optimization, region sizing, and DATAS now enabled by default.</li>
</ul>



<h2 id="new-gc-features-and-changes-in-net-10-whats-actually-different">New GC Features and Changes in .NET 10: What’s Actually Different?</h2>



<p>You’ll see many exciting headlines in the .NET 10 release notes. Here’s what matters most for your memory profile:</p>



<ol>
<li>Escape analysis for aggressive stack allocation</li>



<li>DATAS is now on by default in most configurations</li>



<li>Region size and range tuning for efficient allocation</li>



<li>Delegate and closure optimization</li>



<li>More intelligent elision of write barriers</li>



<li>Better, more automatic devirtualization and inlining in collection code</li>



<li>Nuanced heap size and threshold controls for large heaps and containers</li>
</ol>



<p>Let’s break down what each change means for real workloads.</p>



<h3 id="1-escape-analysis--stack-allocation--game-changer-for-small-objects">1. Escape Analysis &amp; Stack Allocation – Game Changer for Small Objects</h3>



<p>Traditionally, almost every object or array allocated with the <code>new</code> keyword landed on the heap. The GC must trace all these allocations, mark and compact them, and, for short-lived objects, the cost accumulates.</p>



<p>.NET 10’s JIT compiler deepens <em>escape analysis</em>, the process of detecting allocations that do <strong>not “escape”</strong> (i.e., are not referenced outside the method or lambda where they’re created.) If an allocation is proven not to escape, it’s placed on the stack, not the heap.</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>C#</span></p><pre tabindex="0"><code><span><span>public</span><span> </span><span>int</span><span> </span><span>StackallocOfArrays</span><span>()</span></span>
<span><span>{</span></span>
<span><span>    </span><span>int</span><span>[] </span><span>numbers</span><span> </span><span>=</span><span> [</span><span>1</span><span>, </span><span>2</span><span>, </span><span>3</span><span>, </span><span>4</span><span>, </span><span>5</span><span>, </span><span>6</span><span>, </span><span>7</span><span>];</span></span>
<span><span>    </span><span>var</span><span> </span><span>sum</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    </span><span>for</span><span> (</span><span>var</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>; </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>numbers</span><span>.</span><span>Length</span><span>; </span><span>i</span><span>++</span><span>)</span></span>
<span><span>    {</span></span>
<span><span>        </span><span>sum</span><span> </span><span>+=</span><span> </span><span>numbers</span><span>[</span><span>i</span><span>];</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    </span><span>return</span><span> </span><span>sum</span><span>;</span></span>
<span><span>}</span></span></code></pre></div>



<p>In .NET 9:</p>



<ul>
<li><code>numbers</code> is always heap-allocated.</li>



<li>GC tracks the array, triggers Gen 0/1 collects as soon as it’s unreachable.</li>
</ul>



<p>In .NET 10, if this array is small and its lifetime never escapes the method boundary, the JIT allocates it on the stack. <strong>No GC involvement.</strong> Benchmarks confirm significant speedups and zero allocations (see table).</p>



<figure><table><thead><tr><th>Method</th><th>Mean (ns)</th><th>Allocated</th><th>GC Gen0</th></tr></thead><tbody><tr><td>StackallocOfArrays (.NET 9)</td><td>7.7</td><td>72 B</td><td>0.0086</td></tr><tr><td>StackallocOfArrays (.NET 10)</td><td>3.9</td><td>0</td><td>0</td></tr></tbody></table></figure>



<blockquote>
<p><strong>ℹ️</strong> Lean on stack-alloc-friendly patterns for small, fixed-size arrays or value types. This can reduce GC pressure dramatically.</p>
</blockquote>



<h3 id="2-datas-dynamic-adaptation-to-application-sizes">2. DATAS: Dynamic Adaptation to Application Sizes</h3>



<p><strong>DATAS</strong> is a runtime feature that automatically tunes heap/GC thresholds to better fit real application memory requirements. With the explosion of microservices and containers, many .NET processes run with strict memory caps.</p>



<ul>
<li><strong>Old Model</strong>: Heap grew based on historic allocation patterns, causing over-provisioned memory, and the GC hung onto space in anticipation of bursts.</li>



<li><strong>DATAS</strong>: When workloads are light, GC is more aggressive in releasing memory to OS. However, when app ramps up, heap expands to meet demand.</li>
</ul>



<p>By default, DATAS is <strong>enabled</strong> in .NET 10. To disable:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span># Environment variable</span></span>
<span><span>DOTNET_GCDynamicAdaptationMode</span><span>=</span><span>0</span></span></code></pre></div>



<p>Or in JSON runtime config:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>JSON</span></p><pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;runtimeOptions&#34;</span><span>: {</span></span>
<span><span>    </span><span>&#34;configProperties&#34;</span><span>: {</span></span>
<span><span>      </span><span>&#34;System.GC.DynamicAdaptationMode&#34;</span><span>: </span><span>0</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div>



<blockquote>
<p>⚠️ If your app is highly throughput-sensitive and exhibits unpredictable allocation spikes (e.g., high-load webservers), DATAS may increase p99 worst-case latency. Thorough benchmarking is essential before rolling out.</p>
</blockquote>



<h3 id="3-region-sizerange-configuration">3. Region Size/Range Configuration</h3>



<p>Since .NET 7, GC on 64-bit systems allocates memory using flexible “regions” instead of fixed segments. In .NET 10, you can tune:</p>



<ul>
<li><strong>RegionRange</strong>: How much virtual address space is reserved up front for the managed heap.</li>



<li><strong>RegionSize</strong>: How large each region block is (default 4 MB for SOH, 32 MB for LOH etc).</li>
</ul>



<p>Tuning these can yield:</p>



<ul>
<li>Lower native memory overhead for very small heaps (set region size to 1 MB).</li>



<li>Fewer memory mappings for huge heaps (bump up region size, especially on Linux).</li>
</ul>



<p>Configuration example:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>JSON</span></p><pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;runtimeOptions&#34;</span><span>: {</span></span>
<span><span>    </span><span>&#34;configProperties&#34;</span><span>: {</span></span>
<span><span>      </span><span>&#34;System.GC.RegionRange&#34;</span><span>: </span><span>549755813888</span><span>,  </span><span>// 512GB</span></span>
<span><span>      </span><span>&#34;System.GC.RegionSize&#34;</span><span>: </span><span>4194304</span><span>         </span><span>// 4MB</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div>



<blockquote>
<p>⚠️ Default values suffice for 95% of workloads. Adjust only if you have a detailed understanding of your app’s memory allocation and the operating system’s constraints.</p>
</blockquote>



<h3 id="4-delegate-escape-analysis-and-closure-optimization">4. Delegate Escape Analysis and Closure Optimization</h3>



<p>Delegates often involve hidden allocations (e.g., closures capturing locals). Escaping closures are those that are referenced outside their creation site and must be heap-allocated and tracked by the GC. But most lambdas are inlined or used locally.</p>



<p>.NET 10 spots more “non-escaping” delegates and stack-allocates their closure objects, slashing memory pressure and invocation overhead.</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>C#</span></p><pre tabindex="0"><code><span><span>public</span><span> </span><span>int</span><span> </span><span>DelegateEscapeAnalysis</span><span>()</span></span>
<span><span>{</span></span>
<span><span>    </span><span>var</span><span> </span><span>sum</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span><span>    </span><span>Action</span><span>&lt;</span><span>int</span><span>&gt; </span><span>action</span><span> </span><span>=</span><span> </span><span>i</span><span> </span><span>=&gt;</span><span> </span><span>sum</span><span> </span><span>+=</span><span> </span><span>i</span><span>;</span></span>
<span></span>
<span><span>    </span><span>foreach</span><span> (</span><span>var</span><span> </span><span>number</span><span> </span><span>in</span><span> </span><span>Numbers</span><span>)</span></span>
<span><span>    {</span></span>
<span><span>        </span><span>action</span><span>(</span><span>number</span><span>);</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    </span><span>return</span><span> </span><span>sum</span><span>;</span></span>
<span><span>}</span></span></code></pre></div>



<figure><table><thead><tr><th>Method</th><th>Mean (ns)</th><th>Allocated</th><th>Alloc Ratio</th></tr></thead><tbody><tr><td>.NET 9</td><td>18,983</td><td>88 B</td><td>1</td></tr><tr><td>.NET 10</td><td>6,292</td><td>24 B</td><td>0.27</td></tr></tbody></table></figure>



<blockquote>
<p>ℹ️ In performance-critical code, minimize escapes in your lambdas/delegates. Patterns that are “leaf-level only” (not returned/passed elsewhere) will see major performance benefits automatically in .NET 10.</p>
</blockquote>



<h3 id="5-write-barrier-optimization">5. Write Barrier Optimization</h3>



<p>When manipulating references between generations, the GC uses <em>write barriers</em> to track updates and maintain generational correctness. .NET 10 uses more aggressive analysis to eliminate unnecessary barriers when it can prove the assignment does not cross generational boundaries, especially with byref-like structs and certain ephemeral object patterns.</p>



<p>This translates to lowered CPU usage in high-churn object graphs, especially for server-side/high-throughput workloads.</p>



<h3 id="6-devirtualization-and-inlining-improvements">6. Devirtualization and Inlining Improvements</h3>



<p>Many collection operations in .NET (LINQ, <code>IEnumerable&lt;T&gt;</code>, List, etc) are interface-based, which incurs virtual dispatch and can block optimizations.</p>



<p>.NET 10’s JIT makes even more aggressive devirtualization and inlining decisions for common operations when allocation patterns and types are clear.</p>



<p>For example, iterating over arrays using <code>foreach</code> on <code>IEnumerable&lt;T&gt;</code> can now often be inlined and optimized comparably to direct <code>for</code> loops, even across delegate boundaries.</p>



<h3 id="7-heap-hard-limits-loh-tuning-and-container-awareness">7. Heap Hard Limits, LOH Tuning, and Container Awareness</h3>



<p>Memory-constrained deployments (like containers) need more fine-grained heap control. .NET 10 continues .NET 9’s improvements:</p>



<ul>
<li><strong>HeapHardLimit</strong> and <strong>HeapHardLimitPercent</strong> configs for total heap or per-generation hard upper bounds.</li>



<li><strong>LOHThreshold</strong> to influence when allocations go to the Large Object Heap.</li>
</ul>



<p>These are essential in resource-sensitive microservices, but they <em>must</em> be set with precise knowledge of your workload to avoid OOMs or excessive collections.</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>JSON</span></p><pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;runtimeOptions&#34;</span><span>: {</span></span>
<span><span>    </span><span>&#34;configProperties&#34;</span><span>: {</span></span>
<span><span>      </span><span>&#34;System.GC.HeapHardLimit&#34;</span><span>: </span><span>209715200</span><span>, </span><span>// 200MB</span></span>
<span><span>      </span><span>&#34;System.GC.HeapHardLimitPercent&#34;</span><span>: </span><span>30</span><span>,</span></span>
<span><span>      </span><span>&#34;System.GC.LOHThreshold&#34;</span><span>: </span><span>120000</span><span> </span><span>// 120KB</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div>



<h2 id="why-did-the-net-team-make-these-changes">Why Did the .NET Team Make These Changes?</h2>



<p>The explosion of multi-core servers, containers, cloud-native workloads, and microservices called for smarter, more aggressive, and more <em>automatic</em> memory management strategies:</p>



<ul>
<li><strong>Escape Analysis and Stack Allocation</strong>: To push managed applications toward the raw efficiency of C/C++ for short-lived objects. Eliminating heap allocations lets .NET compete in microservices, gaming, and edge scenarios.</li>



<li><strong>DATAS</strong>: In a world where many containers run idle or with mostly predictable memory use, keeping more heap “just in case” is wasteful. DATAS closes the gap between allocated memory and <em>actually needed</em> memory, saving cloud costs and reducing resource contention.</li>



<li><strong>Region Tuning</strong>: To boost efficiency for both the cloud-scale (massive servers, hundreds of GB of RAM) and the edge (IoT, microservices with MB-level needs), the one-size-fits-all segment model was insufficient.</li>



<li><strong>Delegate/Lambda/Closure Optimizations</strong>: The prevalence of asynchronous programming, LINQ, and functional idioms forced delegates to become as cheap as possible.</li>



<li><strong>Write Barrier Tuning and Devirtualization</strong>: Modern workloads are allocation-heavy and rely on high-performance collections. Trimming even tiny fractions of cost at this scale adds up to significant savings.</li>
</ul>







<p>If you want to prove (or disprove) GC’s impact in your own scenario, you need the right observability toolbox.</p>



<p>Developers and SREs demand tools and hooks to understand where memory bottlenecks occur, not just post-mortem but in live, production scenarios. .NET 10 now emits rich runtime metrics:</p>



<ul>
<li><strong>GC Collections</strong>: Number of Gen0/Gen1/Gen2/LOH/POH collections.</li>



<li><strong>Heap Allocated (B)</strong>: Cumulative bytes allocated on the managed heap.</li>



<li><strong>GC Heap Size &amp; Fragmentation</strong>: Used and unused memory breakdown, per generation.</li>



<li><strong>GC Pause Time</strong>: Cumulative pause time for all collections (can measure “% time in GC”).</li>
</ul>



<p>Example code to listen for runtime metrics:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>C#</span></p><pre tabindex="0"><code><span><span>// Measure total allocations and collections</span></span>
<span><span>GC</span><span>.</span><span>GetTotalAllocatedBytes</span><span>();</span></span>
<span><span>GC</span><span>.</span><span>CollectionCount</span><span>(</span><span>0</span><span>);  </span><span>// Gen0</span></span>
<span><span>GC</span><span>.</span><span>CollectionCount</span><span>(</span><span>1</span><span>);  </span><span>// Gen1</span></span>
<span><span>GC</span><span>.</span><span>CollectionCount</span><span>(</span><span>2</span><span>);  </span><span>// Gen2</span></span></code></pre></div>



<p>Or with <a href="https://docs.microsoft.com/en-us/dotnet/core/diagnostics/dotnet-counters">dotnet-counters</a>:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><p><span>Bash</span></p><pre tabindex="0"><code><span><span>dotnet-counters</span><span> </span><span>monitor</span><span> </span><span>-p</span><span> </span><span>&lt;</span><span>process_i</span><span>d</span><span>&gt;</span><span> </span><span>System.Runtime</span></span></code></pre></div>



<figure><table><thead><tr><th>Metric</th><th>Purpose</th></tr></thead><tbody><tr><td>dotnet.gc.pause.time</td><td>Total time spent in GC since start</td></tr><tr><td>dotnet.gc.collections</td><td>Number of collections per generation</td></tr><tr><td>dotnet.gc.heap.total_allocated</td><td>Total bytes allocated</td></tr><tr><td>dotnet.gc.last_collection.heap.size</td><td>Heap size at last collection</td></tr><tr><td>dotnet.gc.last_collection.heap.fragmentation.size</td><td>Fragmentation stats</td></tr><tr><td>dotnet.process.memory.working_set</td><td>OS-level working set</td></tr></tbody></table></figure>



<p>Analysis of these metrics helps distinguish between <strong>GC pressure</strong>, memory leaks, fragmentation, and overall heap efficiency.</p>



<h2 id="when-to-opt-out-or-retune-gc-behavior">When to Opt Out or Retune GC Behavior</h2>



<p>Despite all these advances, some workloads <em>should</em> consider modifying the defaults or even reverting to older GC modes:</p>



<ul>
<li><strong>Throughput over Memory Conservation</strong>: Batch/analytics jobs and ultra-low-latency APIs may lose p99 performance with DATAS enabled.</li>



<li><strong>Memory Predictability in Real-Time Systems</strong>: If your app cannot tolerate unexpected pauses, consider tuning region sizes, disable DATAS, or pin to older behaviors.</li>



<li><strong>Legacy or Exotic Profiles</strong>: If you run on edge hardware (IoT, embedded) or have a memory model not well-aligned with .NET’s tracing collector, explicit tuning may be needed.</li>
</ul>



<h2 id="conclusion">Conclusion</h2>



<p>For decades, garbage collection in .NET was a background concern. It was mostly invisible to the everyday developer and was regarded as “automatic” unless (or until) something slowed down the application. However, .NET 10 changes this perspective by making garbage collection (GC) a key component of application performance. It offers transparency, configurability, and modern features that meet the demands of today’s scalable and cloud-native workloads.</p>



<p>By embracing these changes, .NET developers can transform their view of GC from an uncontrollable burden into a customizable ally. The telemetry, efficiency, and predictability of GC should be considered as vital to application health as metrics such as HTTP throughput or database latency.</p>





		</div></div>
  </body>
</html>
