<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://infinigen.org/">Original</a>
    <h1>Infinigen</h1>
    
    <div id="readability-page-1" class="page"><div id="docusaurus_skipToContent_fallback"><main><section><div><div><p><img src="https://infinigen.org/img/random_sample.jpeg"/></p><p><img src="https://infinigen.org/img/random_sample_indoors.jpeg"/></p><div><div><p>Infinigen is a procedural generator of 3D scenes, developed by<!-- --> <a href="https://pvl.cs.princeton.edu/">Princeton Vision &amp; Learning Lab</a>. Infinigen is optimized for computer vision research and generates diverse high-quality 3D training data. Infinigen is based on <a href="https://blender.org">Blender</a> and is free and open-source (BSD 3-Clause License). Infinigen is being actively developed to expand its capabilities and coverage. Everyone is welcome to<!-- --> <a href="https://infinigen.org/docs-contributing">contribute</a>.</p></div></div></div></div></section><section><div><div><div><div><div><p><span><a href="http://araistrick.com">Alexander Raistrick*</a>,<!-- --> <a href="https://www.lahavlipson.com">Lahav Lipson*</a>,<!-- --> <a href="https://mazeyu.github.io">Zeyu Ma*</a> Â <a href="https://www.cs.princeton.edu/~lm5483/">Lingjie Mei</a>,<!-- --> <a href="https://www.cs.princeton.edu/~mingzhew">Mingzhe Wang</a>, <a href="https://zuoym15.github.io">Yiming Zuo</a>,<!-- --> <a href="https://kkayan.com">Karhan Kayan</a>,<!-- --> <a href="https://hermera.github.io">Hongyu Wen</a>,<!-- --> <a href="https://pvl.cs.princeton.edu/people.html">Beining Han</a><a href="https://pvl.cs.princeton.edu/people.html">Yihan Wang</a>,<a href="http://www-personal.umich.edu/~alnewell/index.html">Alejandro Newell</a>, <a href="https://heilaw.github.io">Hei Law</a>,<!-- --> <a href="https://imankgoyal.github.io">Ankit Goyal</a>,<!-- --> <a href="https://yangky11.github.io">Kaiyu Yang</a>,<!-- --> <a href="http://www.cs.princeton.edu/~jiadeng">Jia Deng</a></span></p></div></div><pre><code>@inproceedings{infinigen2023infinite,
  title={Infinite Photorealistic Worlds Using Procedural Generation},
  author={Raistrick, Alexander and Lipson, Lahav and Ma, Zeyu and Mei, Lingjie and Wang, Mingzhe and Zuo, Yiming and Kayan, Karhan and Wen, Hongyu and Han, Beining and Wang, Yihan and Newell, Alejandro and Law, Hei and Goyal, Ankit and Yang, Kaiyu and Deng, Jia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12630--12641},
  year={2023}
}</code></pre></div><div><div><div><p><span><a href="http://araistrick.com">Alexander Raistrick*</a>,<!-- --> <a href="https://www.cs.princeton.edu/~lm5483/name.html">Lingjie Mei*</a>, <a href="https://mazeyu.github.io">Karhan Kayan*</a>,<!-- --> <a href="https://david-yan1.github.io/">David Yan</a>,<a href="https://zuoym15.github.io">Yiming Zuo</a>,<!-- --> <a href="https://pvl.cs.princeton.edu/people.html">Beining Han</a>, <a href="https://hermera.github.io">Hongyu Wen</a>,<!-- --> <a href="https://pvl.cs.princeton.edu/people.html">Meenal Parakh</a>,<!-- --> <a href="https://stamatisalex.github.io/">Stamatis Alexandropoulos</a>, <a href="https://www.lahavlipson.com">Lahav Lipson</a>,<!-- --> <a href="https://mazeyu.github.io">Zeyu Ma</a>,<!-- --> <a href="http://www.cs.princeton.edu/~jiadeng">Jia Deng</a></span></p></div></div><div><p><span>Conference on Computer Vision and Pattern Recognition (CVPR) 2024</span></p></div><pre><code>@inproceedings{infinigen2024indoors,
    author={Raistrick, Alexander and Mei, Lingjie and Kayan, Karhan and Yan, David and Zuo, Yiming and Han, Beining and Wen, Hongyu and Parakh, Meenal and Alexandropoulos, Stamatis and Lipson, Lahav and Ma, Zeyu and Deng, Jia},
    title={Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month={June},
    year={2024},
    pages={21783-21794}
}</code></pre></div></div></div></section><section><div><div><div><div><div><div><div><p><img src="https://infinigen.org/img/procedural.png"/></p></div><div><p>Infinigen is a procedural generator that creates everything entirely from randomized mathematical rules, including all shapes and materials, from macro structures to micro details.<span> Infinigen</span> can create unlimited variations. Users have full control the generation of assets by overriding default parameters of randomization.</p></div></div></div></div></div><div><div><div><div><div><p><img src="https://infinigen.org/img/diverse.jpeg"/></p></div><div><p><span>Infinigen </span>provides generators for diverse objects and scenes in the natural world including plants, animals, terrains, and natural phenomena such as fire, cloud, rain, and snow. The current focus on nature is motivated by the observation that mammalian vision evolved in the natural world. However, Infinigen is expected to expand over time to cover built environments and artificial objects.</p></div></div></div></div></div></div><div><div><div><div><div><div><div><div><div><p><img src="https://infinigen.org/img/fake_geo.png"/></p><p><span>Fake Geometry</span></p></div><div><p><img src="https://infinigen.org/img/real_geo.png"/></p><p><span>Real Geometry</span></p></div></div></div></div><div><p>Infinigen is optimized for computer vision research, particularly 3D vision. Infinigen does not use bump/normal-maps, full-transparency, or other techniques which fake geometric detail. All fine details of geometry from<!-- --> <span>Infinigen</span> are real, ensuring accurate 3D ground truth.</p></div></div></div></div></div><div><div><div><div><div><div><div><p><img src="https://infinigen.org/img/quad.png"/></p></div></div></div><div><p><span>Infinigen </span>can automatically generate high-quality annotations for a variety of computer vision tasks, including optical flow, 3D scene flow, depth, surface normals, panoptic segmentation, occlusion boundaries. Because users have full access to the rendering process, the annotations are easily customizable.</p></div></div></div></div></div></div></div></section></main></div></div>
  </body>
</html>
