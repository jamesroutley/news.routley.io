<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://agi-sphere.com/llama-2/">Original</a>
    <h1>What&#39;s new in Llama 2 and how to run it locally</h1>
    
    <div id="readability-page-1" class="page"><div><p><a href="https://about.fb.com/news/2023/07/llama-2/" target="_blank" rel="noopener">Llama 2</a> is a free and open-source large language model that you can run locally on your own machine. It is an improvement to the earlier Llama model.</p><p>In this post, you will learn:</p><ul><li>What the llama 2 model is.</li></ul><ul><li>How to install and run the Llama 2 models in Windows.</li></ul><h2><span id="What_is_Llama_2_model">What is Llama 2 model?</span></h2><p>LLama 2 is a free and open-source large language model released by Meta in July 2023. Two model families are released.</p><ul><li><strong>Llama 2</strong>: 40% more pertaining data than Llama 1. Doubled context length. Good for sentence completion.</li><li><strong>Llama 2-Chat</strong>: Optimized for conversation usage like Chat GPT.</li></ul><p>7B, 13B and 70B models are available for both families.</p><figure><img decoding="async" width="1024" height="683" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://agi-sphere.com/wp-content/uploads/2023/08/image-11-1024x683.png" alt="" data-srcset="https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-11.png?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-11.png?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-11.png?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-11.png?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-11.png?w=1344&amp;ssl=1 1344w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure><h3><span id="What8217s_new_in_Llama_2">What’s new in Llama 2?</span></h3><h4><span id="Model_architecture">Model architecture</span></h4><p>The model architecture is very similar to the Llama model. The improvements in model architecture are</p><ul><li>Increased context length</li><li>Grouped-query attention</li></ul><p>The <strong>context length</strong> is the number of tokens (similar to words or subwords) a language model can consider in the input text when generating a response. The <a href="https://agi-sphere.com/llama-models/" data-type="post" data-id="553">original llama model</a> has a context length of 2,048. Llama 2’s context length is doubled to 4,096.</p><p><strong>Grouped-query attention</strong> (GQA) is a new optimization to tackle high memory usage due to increased context length and model size. It reduces memory usage by sharing the cached keys and values of the previous tokens. GQA is only used in the 34B and 70B Llama 2 models.</p><h3><span id="Pre-training">Pre-training</span></h3><p>The pretraining of Llama 1 and 2 are similar, except that Llama 2 has a larger pretraining dataset. It is increased to 2.0 trillion tokens, up from 1.0 and 1.4 tokens for the Llama 1 model.</p><p>Indeed, the larger pretraining dataset has resulted in higher performance across all metrics evaluated.</p><figure><img decoding="async" width="1024" height="423" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://agi-sphere.com/wp-content/uploads/2023/08/image-8-1024x423.png" alt="" data-srcset="https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-8.png?resize=1024%2C423&amp;ssl=1 1024w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-8.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-8.png?resize=768%2C317&amp;ssl=1 768w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-8.png?resize=1536%2C634&amp;ssl=1 1536w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-8.png?w=1682&amp;ssl=1 1682w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Performance comparison between Llama 1 and Llama 2. (Table from the Llama 2 paper)</figcaption></figure><h3><span id="Supervised_Fine-Tuning_SFT">Supervised Fine-Tuning (SFT)</span></h3><p>Quality is more important than quantity when it comes to fine-tuning the model. The model was fine-tuned with the following techniques.</p><ul><li><strong>SFT Annotations</strong>: High-quality prompt and response pairs.</li><li><strong>Reinforcement Learning with Human Feedback</strong> (RLHF): Let a human tell which answers he or she likes more. Then teach the model to respond with answers that humans prefer.</li><li><strong>Human preference</strong>: The model learns to provide <strong>safe</strong> and <strong>helpful</strong> responses based on human feedback.</li></ul><figure><img decoding="async" width="1024" height="492" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://agi-sphere.com/wp-content/uploads/2023/08/image-10-1024x492.png" alt="" data-srcset="https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-10.png?resize=1024%2C492&amp;ssl=1 1024w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-10.png?resize=300%2C144&amp;ssl=1 300w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-10.png?resize=768%2C369&amp;ssl=1 768w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-10.png?resize=1536%2C737&amp;ssl=1 1536w, https://i0.wp.com/agi-sphere.com/wp-content/uploads/2023/08/image-10.png?w=1850&amp;ssl=1 1850w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Training of Llama 2 (Image from Llama 2 paper.)</figcaption></figure><h2><span id="Running_Llama_2_locally">Running Llama 2 locally</span></h2><h3><span id="Step_1_Install_text-generation-webUI">Step 1: Install text-generation-webUI</span></h3><p>Follow this <a href="https://agi-sphere.com/text-generation-webui-windows/" data-type="post" data-id="566">installation guide for Windows</a>.</p><h3><span id="Step_2_Download_Llama_2_model">Step 2: Download Llama 2 model</span></h3><h4><span id="Option_1_Windows_users_with_Nvidia_GPU">Option 1: Windows users with Nvidia GPU</span></h4><p>In text-generation-webui, navigate to the <strong>Model</strong> page. In <strong>Download custom model or LoRA </strong>section, put in the <strong>Huggingface path</strong> you find below for the model you want to download below. Refresh the Model list and load the newly downloaded model.</p><p>You will want to download the Llama-2-Chat models if you want to use them in a conversation style like ChatGPT.</p><p><a href="https://huggingface.co/localmodels/Llama-2-7B-Chat-GPTQ" target="_blank" rel="noopener">Llama-2-Chat 7B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-7B-Chat-GPTQ</code></pre><p><a href="https://huggingface.co/localmodels/Llama-2-13B-Chat-GPTQ" target="_blank" rel="noopener">Llama-2-Chat 13B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-13B-Chat-GPTQ</code></pre><p><a href="https://huggingface.co/localmodels/Llama-2-70B-Chat-GPTQ" target="_blank" rel="noopener">Llama-2-Chat 70B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-70B-Chat-GPTQ</code></pre><p><a href="https://huggingface.co/localmodels/Llama-2-7B-GPTQ" target="_blank" rel="noopener">Llama-2-7B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-7B-GPTQ</code></pre><p><a href="https://huggingface.co/localmodels/Llama-2-13B-GPTQ" target="_blank" rel="noopener">Llama-2-13B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-13B-GPTQ</code></pre><p><a href="https://huggingface.co/localmodels/Llama-2-70B-GPTQ" target="_blank" rel="noopener">Llama-2-70B</a></p><p>Huggingface path:</p><pre><code>localmodels/Llama-2-70B-GPTQ</code></pre><h4><span id="Option_2_Mac_users_or_Windows_CPU_users">Option 2: Mac users or Windows CPU users</span></h4><p>If you use Mac or Windows without a GPU card, you can download the Llama 2 models from the following pages. There are multiple files on the one model page. You DON’T need to download them all. You only need to download ONE <code>.bin</code> file to run the model. They are different quantizations that aim at reducing the file sizes.</p><p>Download ONE <code>.bin</code> file for a model and put it in <strong>text-generation-webui</strong> &gt; <strong>models</strong> folder. Refresh the <strong>Model</strong> list on the <strong>Models</strong> page. Select and <strong>load</strong> the model to start using.</p><p><a href="https://huggingface.co/localmodels/Llama-2-7B-Chat-ggml" target="_blank" rel="noopener">Llama 2 Chat 7B GGML model</a> – <a href="https://huggingface.co/localmodels/Llama-2-7B-Chat-ggml/blob/main/llama-2-7b-chat.ggmlv3.q4_0.bin" target="_blank" rel="noopener">Download link</a></p><p><a href="https://huggingface.co/localmodels/Llama-2-13B-Chat-ggml" target="_blank" rel="noopener">Llama 2 Chat 13B GGML model</a> – <a href="https://huggingface.co/localmodels/Llama-2-13B-Chat-ggml/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin" target="_blank" rel="noopener">Download link</a></p><p><a href="https://huggingface.co/localmodels/Llama-2-7B-ggml" target="_blank" rel="noopener">Llama 2 7B model</a> – <a href="https://huggingface.co/localmodels/Llama-2-7B-ggml/blob/main/llama-2-7b.ggmlv3.q4_0.bin" target="_blank" rel="noopener">Download link</a></p><p><a href="https://huggingface.co/localmodels/Llama-2-13B-ggml" target="_blank" rel="noopener">Llama 2 13B model</a> – <a href="https://huggingface.co/localmodels/Llama-2-13B-ggml/blob/main/llama-2-13b.ggmlv3.q4_0.bin" target="_blank" rel="noopener">Download link</a></p><h2><span id="Resources">Resources</span></h2><ul><li><a href="https://ai.meta.com/llama/" target="_blank" rel="noopener">Llama 2 official page</a></li><li><a href="https://arxiv.org/abs/2307.09288" target="_blank" rel="noopener">Llama 2 research article</a></li></ul> <!-- Simple Share Buttons Adder (8.4.6) simplesharebuttons.com --></div></div>
  </body>
</html>
