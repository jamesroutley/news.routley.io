<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bignacio.github.io/soc/docs/articles/arm64-x86_64-on-aws/">Original</a>
    <h1>Workloads on Arm-based AWS instances</h1>
    
    <div id="readability-page-1" class="page"><div id="main-content" role="main"><p><em>May 2023</em></p><hr/><p>Not too long ago <a href="https://bignacio.github.io/soc/docs/articles/public-cloud-usage/#can-i-do-anything-to-reduce-my-already-slim-cloud-costs">I suggested</a> using Arm-based EC2 instances on AWS as a way to further cost savings.</p><p>Depending on the applications and types of workloads, that might not be worth the trouble. As usual, one has to measure. And measure the results again.</p><p>However, I went ahead and decided I should check how much of a non-starter that could be. I did that by evaluation one of the most common use cases, a simple REST-based endpoint.</p><p>Here’s what I found.</p><h2 id="test-setup"> <a href="#test-setup" aria-labelledby="test-setup"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Test setup</h2><p>The test service exposes a single endpoint to accept POST requests, with a JSON payload, and respond with the exact same that was received.</p><p>I did that using 4 different and (I believe) commonly used Web frameworks:</p><ul><li>Django (Python)</li><li>Spring Boot (Java)</li><li>Actix-Web (Rust)</li><li>Gin (Go)</li></ul><p>The services were then tested under high request rate using <a href="https://github.com/rakyll/hey">hey</a> with a JSON payload of 6k. Each combination of framework and architecture processed 1M requests.</p><p>The EC2 instances used were</p><p><em>(instance types and their configuration as of May 2023)</em></p><ul><li>for x64, a t3a.micro with 2 vCPUs and 1G of memory</li><li>for Arm. a t4g.micro with 2 vCPUs and 1G of memory</li></ul><p>I chose these instance types based on number of cores and memory size, though the architectures are very different and to for certain applications, these may not be the best attributes for comparison.</p><h2 id="indicators-and-expectations"> <a href="#indicators-and-expectations" aria-labelledby="indicators-and-expectations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Indicators and expectations</h2><p>I am looking for throughput and latency for the same service and framework on both architectures.</p><p>For that I primarily collected service response time (round trip) at various percentiles.</p><p>It’s important to note that network and instance jitter can affect the results and I would sometimes have a single request, in 10M, to take 10x the expected time.</p><p>Repeating the test many times over under different instances was necessary to eliminate the outliers.</p><h3 id="note-on-payload-content"> <a href="#note-on-payload-content" aria-labelledby="note-on-payload-content"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Note on payload content</h3><p>The JSON payload consisted of various data types, long and short arrays of single and complex objects.</p><p>I also tested much smaller payloads and the results were the same, so I decided to use 6k as a large <em>enough</em> payload size.</p><h2 id="the-results"> <a href="#the-results" aria-labelledby="the-results"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The results</h2><p>Before diving into the results, I want to mention this is not a comparison between frameworks (though waiting 10-20x for the python app was a little annoying) rather, I was interested in seeing how the same framework (and language compiler/interpreter) behaves on both architectures.</p><h3 id="python--django"> <a href="#python--django" aria-labelledby="python--django"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Python + Django</h3><p>Response time in milliseconds</p><div><table><thead><tr><th>%</th><th>x86_64</th><th>Arm</th></tr></thead><tbody><tr><td>99.50</td><td>55.6</td><td>51.8</td></tr><tr><td>99.90</td><td>59.7</td><td>57.0</td></tr><tr><td>99.99999</td><td>92.3</td><td>95.8</td></tr><tr><td>Average</td><td>47.2</td><td>47.4</td></tr><tr><td>Min</td><td>5.8</td><td>5.8</td></tr><tr><td>Max</td><td>92.4</td><td>95.0</td></tr></tbody></table></div><p>Distribution x86_64</p><p><img src="https://bignacio.github.io/soc/assets/images/python-x86.png" alt="x86_64" title="x86_64"/></p><p>Distribution arm64</p><p><img src="https://bignacio.github.io/soc/assets/images/python-arm.png" alt="arm64" title="arm64"/></p><p>On the surface it appears that the x86 architecture performed a 2-3% better at the high percentile but up to 99.5, Arm was actually 8% faster.</p><h3 id="java--spring-boot"> <a href="#java--spring-boot" aria-labelledby="java--spring-boot"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Java + Spring Boot</h3><p>Response time in milliseconds</p><div><table><thead><tr><th>%</th><th>x86_64</th><th>Arm</th></tr></thead><tbody><tr><td>99.50</td><td>8.1</td><td>7.3</td></tr><tr><td>99.90</td><td>10.9</td><td>9.0</td></tr><tr><td>99.99999</td><td>17.2</td><td>23.2</td></tr><tr><td>Average</td><td>1.7</td><td>1.6</td></tr><tr><td>Min</td><td>1.3</td><td>1.3</td></tr><tr><td>Max</td><td>17.3</td><td>23.3</td></tr></tbody></table></div><p>Distribution x86_64</p><p><img src="https://bignacio.github.io/soc/assets/images/java-x86.png" alt="x86_64" title="x86_64"/></p><p>Distribution arm64</p><p><img src="https://bignacio.github.io/soc/assets/images/java-arm.png" alt="arm64" title="arm64"/></p><p>Again we see the same pattern, where the Arm test performs better up until the 99.5 percentile but not so much after that.</p><p>The histograms show a higher number of requests in the lower response time bands.</p><h3 id="go--gin"> <a href="#go--gin" aria-labelledby="go--gin"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Go + Gin</h3><p>Response time in milliseconds</p><div><table><thead><tr><th>%</th><th>x86_64</th><th>Arm</th></tr></thead><tbody><tr><td>99.50</td><td>7.2</td><td>7.2</td></tr><tr><td>99.90</td><td>8.9</td><td>8.8</td></tr><tr><td>99.99999</td><td>15.5</td><td>16.9</td></tr><tr><td>Average</td><td>1.6</td><td>1.5</td></tr><tr><td>Min</td><td>1.3</td><td>1.3</td></tr><tr><td>Max</td><td>15.6</td><td>17.0</td></tr></tbody></table></div><p>Distribution x86_64</p><p><img src="https://bignacio.github.io/soc/assets/images/go-x86.png" alt="x86_64" title="x86_64"/></p><p>Distribution arm64</p><p><img src="https://bignacio.github.io/soc/assets/images/go-arm.png" alt="arm64" title="arm64"/></p><p>The same pattern again with a 8% slower response time for Arm at the 99.99998th percentile.</p><h3 id="rust--actix-web"> <a href="#rust--actix-web" aria-labelledby="rust--actix-web"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Rust + Actix-web</h3><p>Response time in milliseconds</p><div><table><thead><tr><th>%</th><th>x86_64</th><th>Arm</th></tr></thead><tbody><tr><td>99.50</td><td>2.7</td><td>3.0</td></tr><tr><td>99.90</td><td>7.2</td><td>7.2</td></tr><tr><td>99.99999</td><td>9.6</td><td>10.9</td></tr><tr><td>Average</td><td>1.4</td><td>1.4</td></tr><tr><td>Min</td><td>1.2</td><td>1.2</td></tr><tr><td>Max</td><td>9.7</td><td>11.0</td></tr></tbody></table></div><p>Distribution x86_64</p><p><img src="https://bignacio.github.io/soc/assets/images/rust-x86.png" alt="x86_64" title="x86_64"/></p><p>Distribution arm64</p><p><img src="https://bignacio.github.io/soc/assets/images/rust-arm.png" alt="arm64" title="arm64"/></p><p>Much like the results for go, thought the histograms suggest a much smaller right tail for Arm.</p><h2 id="final-notes"> <a href="#final-notes" aria-labelledby="final-notes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Final notes</h2><p>It does appear that the Arm-based instances can’t consistently maintain the same performance at high request rates.</p><p>However, I wouldn’t take these results as discouraging, quite the opposite. It’s very possible that most services won’t need to keep those levels of performance at “7 nines” percentiles and the differences these tests show would be immaterial.</p><p>Arm instances on AWS are around 10% cheaper than x86(10.6% to be more precise, at the time of this writing). So even if more instances are needed to keep up with load, it’s possible the total cost would still be lower.</p><p>If the workloads you’re running don’t depend on specific instruction sets, I’d suggest giving Arm a try.</p><hr/></div></div>
  </body>
</html>
