<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.danielcorin.com/posts/2024/fine-tuning-connections/">Original</a>
    <h1>(Unsuccessfully) Fine-tuning GPT to play &#34;Connections&#34;</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>I started playing the NYTimes word game “<a href="https://www.nytimes.com/games/connections" target="_blank">Connections</a>” recently, by the recommendation of a few friends.
It has the type of freshness that <a href="https://www.nytimes.com/games/wordle/index.html" target="_blank">Wordle</a> lost for me a long time ago.
After playing Connections for a few days, I wondered if an OpenAI language model could solve the game (the objective is to group the 16 words into 4 categories of 4 words).
I tried with <code>gpt-4k-32k</code> and <code>gpt-4-1106-preview</code>, tweaking prompts for a few hours and wasn’t able to make much progress.
It’s certainly possible prompt engineering alone could solve this problem, but it wasn’t easy for me for find a path forward.
I imagine it will involve a bit of creativity.
I decided this was as good a time as any to try and fine tune a model to do a thing I couldn’t easily get it to do with prompts.</p><h2 id="getting-the-dataset">Getting the dataset</h2><p>I remembered seeing at some point that Wordle had an API to return the day’s word and it does at <code>https://www.nytimes.com/svc/wordle/v2/yyyy-mm-dd.json</code>.
I figured Connections might have a similar JSON API and it does.
I wrote a script to get all the solutions to past game and put the in the <code>connections_data</code> folder with the naming convention <code>yyyy-mm-dd.json</code>.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> json
</span></span><span><span><span>import</span> httpx
</span></span><span><span><span>from</span> datetime <span>import</span> timedelta, datetime
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>url <span>=</span> <span>&#34;https://www.nytimes.com/svc/connections/v1/</span><span>{date}</span><span>.json&#34;</span>
</span></span><span><span>start_date <span>=</span> datetime<span>.</span>strptime(<span>&#34;2023-06-12&#34;</span>, <span>&#34;%Y-%m-</span><span>%d</span><span>&#34;</span>)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    end_date <span>=</span> datetime<span>.</span>now()
</span></span><span><span>    dates_generated <span>=</span> [
</span></span><span><span>        start_date <span>+</span> timedelta(days<span>=</span>x)
</span></span><span><span>        <span>for</span> x <span>in</span> range((end_date <span>-</span> start_date)<span>.</span>days <span>+</span> <span>1</span>)
</span></span><span><span>    ]
</span></span><span><span>    <span>for</span> date <span>in</span> dates_generated:
</span></span><span><span>        formatted_date <span>=</span> date<span>.</span>strftime(<span>&#34;%Y-%m-</span><span>%d</span><span>&#34;</span>)
</span></span><span><span>        response <span>=</span> httpx<span>.</span>get(url<span>.</span>format(date<span>=</span>formatted_date))
</span></span><span><span>        response_object <span>=</span> response<span>.</span>json()
</span></span><span><span>        <span>with</span> open(<span>f</span><span>&#34;connections_data/</span><span>{</span>formatted_date<span>}</span><span>.json&#34;</span> , <span>&#34;w&#34;</span>) <span>as</span> f:
</span></span><span><span>            f<span>.</span>write(json<span>.</span>dumps(response_object, indent<span>=</span><span>2</span>))
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>It turns out the first game was published on 2023-06-12.
Next, I wrote some not pretty code to create a jsonl file to upload to OpenAI.
They describe the structure of the file to fine-tune the <code>gpt-3.5-turbo</code> model <a href="https://platform.openai.com/docs/guides/fine-tuning/example-format" target="_blank">here</a>.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> os
</span></span><span><span><span>import</span> json
</span></span><span><span>
</span></span><span><span>SYSTEM_PROMPT <span>=</span> <span>&#34;&#34;&#34;The game &#34;Connections&#34; is a word game where you start with 16 words and need to group them into 4 groups of 4. Each grouping has a category that unambiguously groups the four words together. Each puzzle has exactly one solution. Watch out for words that seem to belong to multiple categories. You will be given 16 words. Output 4 groupings of 4 words and the categories to which they belong.&#34;&#34;&#34;</span>
</span></span><span><span>
</span></span><span><span>OUT_FILE <span>=</span> <span>&#34;connections_prompts.jsonl&#34;</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    <span>with</span> open(OUT_FILE, <span>&#34;w&#34;</span>) <span>as</span> writef:
</span></span><span><span>        <span>for</span> file <span>in</span> os<span>.</span>listdir(<span>&#34;connections_data&#34;</span>):
</span></span><span><span>            <span>if</span> file<span>.</span>endswith(<span>&#34;.json&#34;</span>):
</span></span><span><span>                print(file)
</span></span><span><span>                <span>with</span> open(<span>f</span><span>&#34;connections_data/</span><span>{</span>file<span>}</span><span>&#34;</span>, <span>&#34;r&#34;</span>) <span>as</span> f:
</span></span><span><span>                    data <span>=</span> json<span>.</span>load(f)
</span></span><span><span>                categories <span>=</span> [c <span>for</span> c <span>in</span> data[<span>&#34;groups&#34;</span>]<span>.</span>keys()]
</span></span><span><span>                categories_and_members <span>=</span> {c: data[<span>&#34;groups&#34;</span>][c] <span>for</span> c <span>in</span> categories}
</span></span><span><span>                assistant_str <span>=</span> <span>&#34;&#34;</span>
</span></span><span><span>                <span>for</span> c, words <span>in</span> categories_and_members<span>.</span>items():
</span></span><span><span>                    assistant_str <span>+=</span> <span>f</span><span>&#34;category: </span><span>{</span>c<span>.</span>lower()<span>}</span><span>\n</span><span>words: </span><span>{</span><span>&#39; &#39;</span><span>.</span>join(words)<span>}</span><span>\n\n</span><span>&#34;</span>
</span></span><span><span>                all_words <span>=</span> [word<span>.</span>lower() <span>for</span> group <span>in</span> categories_and_members<span>.</span>values() <span>for</span> word <span>in</span> group[<span>&#34;members&#34;</span>]]
</span></span><span><span>                all_words_str <span>=</span>  <span>&#39;, &#39;</span><span>.</span>join(all_words)
</span></span><span><span>                out_obj <span>=</span> {
</span></span><span><span>                    <span>&#34;messages&#34;</span>: [
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: SYSTEM_PROMPT,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: <span>f</span><span>&#34;Here are the 16 words: </span><span>{</span>all_words_str<span>}</span><span>&#34;</span>,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;assistant&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: assistant_str<span>.</span>strip(),
</span></span><span><span>                        },
</span></span><span><span>                    ]
</span></span><span><span>                }
</span></span><span><span>                writef<span>.</span>write(<span>f</span><span>&#34;</span><span>{</span>json<span>.</span>dumps(out_obj)<span>}</span><span>\n</span><span>&#34;</span>)
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><h2 id="estimating-price">Estimating Price</h2><p>I estimated the price of the job by counting the number of tokens in my fine-tune file.
The <a href="https://openai.com/pricing" target="_blank">OpenAI pricing page</a> lists the price of the fine-tune at $0.0080 / 1K tokens.
Additionally, the <a href="https://platform.openai.com/docs/guides/fine-tuning/estimate-costs" target="_blank">fine-tuning guide</a> notes</p><blockquote><p>To estimate the costs for a specific fine-tuning job, use the following formula:</p><pre tabindex="0"><code>base cost per 1k tokens * number of tokens in the input file * number of epochs trained
</code></pre><p>For a training file with 100,000 tokens trained over 3 epochs, the expected cost would be ~$2.40 USD.</p></blockquote><p>Using <code>tiktoken</code> to count tokens</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> tiktoken
</span></span><span><span>
</span></span><span><span><span># gpt-3.5-turbo	$0.0080 / 1K tokens</span>
</span></span><span><span>
</span></span><span><span><span>with</span> open(<span>&#34;connections_prompts.jsonl&#34;</span>, <span>&#34;r&#34;</span>) <span>as</span> file:
</span></span><span><span>    data <span>=</span> file<span>.</span>read()
</span></span><span><span>
</span></span><span><span>encoding <span>=</span> tiktoken<span>.</span>encoding_for_model(<span>&#34;gpt-3.5-turbo&#34;</span>)
</span></span><span><span>tokens <span>=</span> len(encoding<span>.</span>encode(data))
</span></span><span><span>price <span>=</span> (tokens <span>/</span> <span>1000</span>) <span>*</span> <span>0.0080</span>
</span></span><span><span>print(<span>f</span><span>&#34;Number of tokens: </span><span>{</span>tokens<span>}</span><span>.</span><span>\n</span><span>Price: </span><span>{</span>price<span>:</span><span>.2f</span><span>}</span><span>&#34;</span>)
</span></span></code></pre></div><p>which output</p><div><pre tabindex="0"><code data-lang="text"><span><span>Number of tokens: 46814.
</span></span><span><span>Price: 0.37
</span></span></code></pre></div><h2 id="running-the-fine-tune-job">Running the fine-tune job</h2><p>I took 15 of the rows (number chosen pretty randomly) from the result and separated them out into a training file, so that OpenAI can used it to calculate loss for the fine-tuning (I think).
I called these files <code>connections_prompts_train.jsonl</code> and <code>connections_prompts_test.jsonl</code>.
I went to <a href="https://platform.openai.com/finetune" target="_blank">OpenAI</a> and created a new fine-tuning job.
I selected the <code>gpt-3.5-turbo-1106</code> model then uploaded my training and test data, and clicked “create” and off it went.
As the job ran, I could see this dashboard.
Here’s what it looked like when it finished.</p><p><img src="https://www.danielcorin.com/img/posts/2024/fine-tuning-connections.png" alt="Fine-tuning progress. A loss graph with two lines, slowly decreasing starting around 3 and down to around 0.2"/></p><p>And it cost \$0.90.
According to the fine-tune metrics, 3 epochs (given my estimated cost of \$0.37) as mentioned <a href="https://platform.openai.com/docs/guides/fine-tuning/estimate-costs" target="_blank">fine-tune training guide</a> though I don’t recall setting that or seeing it anywhere else.</p><p><img src="https://www.danielcorin.com/img/posts/2024/fine-tuning-cost.png" alt="Fine-tuning cost screenshot"/></p><h2 id="testing-the-fine-tune">Testing the fine-tune</h2><p>With the fine-tuning done, I went to the <a href="https://platform.openai.com/playground?mode=chat&amp;model=ft%253Agpt-3.5-turbo-1106" target="_blank">playground</a> to try it out.
I fetched the words for the next day’s puzzle, which was mercifully already available.
I forgot to make a validation set.
Shame on me.
It would have take a bit longer to fine-tune again, and I had a lot of anticipation to see the results, it being my first fine-tune and not really understanding the loss graph or knowing if it worked.</p><p>I copied the same system prompt from the training</p><div><pre tabindex="0"><code data-lang="text"><span><span>The game &#34;Connections&#34; is a word game where you start with 16 words and need to group them into 4 groups of 4. Each grouping has a category that unambiguously groups the four words together. Each puzzle has exactly one solution. Watch out for words that seem to belong to multiple categories. You will be given 16 words. Output 4 groupings of 4 words and the categories to which they belong.
</span></span></code></pre></div><p>then added the user message with the words</p><div><pre tabindex="0"><code data-lang="text"><span><span>Here are the 16 words: punt, badge, tackle, run, direct, pass, end, table, ticket, stall, chair, center, lead, safety, invite, hold
</span></span></code></pre></div><p>and clicked submit.
The model outputted</p><div><pre tabindex="0"><code data-lang="text"><span><span>category: american football terms
</span></span><span><span>words: level members
</span></span><span><span>
</span></span><span><span>category: football actions
</span></span><span><span>words: level members
</span></span><span><span>
</span></span><span><span>category: things that might be numbered
</span></span><span><span>words: level members
</span></span><span><span>
</span></span><span><span>category: field positions
</span></span><span><span>words: level members
</span></span></code></pre></div><p>A definite bummer.
I did a quick search in my project directory for “words: level members”, and found it <em>everywhere</em>.
Oops!
I built the dataset improperly.</p><h2 id="fixing-a-dataset-bug">Fixing a dataset bug</h2><p>After a bit of a reset, I found some issues in the prompt generation python script and fixed them here</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> os
</span></span><span><span><span>import</span> json
</span></span><span><span>
</span></span><span><span>SYSTEM_PROMPT <span>=</span> <span>&#34;&#34;&#34;The game &#34;Connections&#34; is a word game where you start with 16 words and need to group them into 4 groups of 4. Each grouping has a category that unambiguously groups the four words together. Each puzzle has exactly one solution. Watch out for words that seem to belong to multiple categories. You will be given 16 words. Output 4 groupings of 4 words and the categories to which they belong.&#34;&#34;&#34;</span>
</span></span><span><span>
</span></span><span><span>OUT_FILE <span>=</span> <span>&#34;connections_prompts.jsonl&#34;</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    <span>with</span> open(OUT_FILE, <span>&#34;w&#34;</span>) <span>as</span> writef:
</span></span><span><span>        <span>for</span> file <span>in</span> os<span>.</span>listdir(<span>&#34;connections_data&#34;</span>):
</span></span><span><span>            <span>if</span> file<span>.</span>endswith(<span>&#34;.json&#34;</span>):
</span></span><span><span>                print(file)
</span></span><span><span>                <span>with</span> open(<span>f</span><span>&#34;connections_data/</span><span>{</span>file<span>}</span><span>&#34;</span>, <span>&#34;r&#34;</span>) <span>as</span> f:
</span></span><span><span>                    data <span>=</span> json<span>.</span>load(f)
</span></span><span><span>                categories <span>=</span> [c <span>for</span> c <span>in</span> data[<span>&#34;groups&#34;</span>]<span>.</span>keys()]
</span></span><span><span>                categories_and_members <span>=</span> {c: data[<span>&#34;groups&#34;</span>][c][<span>&#34;members&#34;</span>] <span>for</span> c <span>in</span> categories}
</span></span><span><span>                assistant_str <span>=</span> <span>&#34;&#34;</span>
</span></span><span><span>                <span>for</span> c, words <span>in</span> categories_and_members<span>.</span>items():
</span></span><span><span>                    lower_words <span>=</span> [w<span>.</span>lower() <span>for</span> w <span>in</span> words]
</span></span><span><span>                    assistant_str <span>+=</span> <span>f</span><span>&#34;category: </span><span>{</span>c<span>.</span>lower()<span>}</span><span>\n</span><span>words: </span><span>{</span><span>&#39;, &#39;</span><span>.</span>join(lower_words)<span>}</span><span>\n\n</span><span>&#34;</span>
</span></span><span><span>                all_words <span>=</span> [word<span>.</span>lower() <span>for</span> group <span>in</span> categories_and_members<span>.</span>values() <span>for</span> word <span>in</span> group]
</span></span><span><span>                all_words_str <span>=</span>  <span>&#39;, &#39;</span><span>.</span>join(all_words)
</span></span><span><span>                out_obj <span>=</span> {
</span></span><span><span>                    <span>&#34;messages&#34;</span>: [
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: SYSTEM_PROMPT,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: <span>f</span><span>&#34;Here are the 16 words: </span><span>{</span>all_words_str<span>}</span><span>&#34;</span>,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;assistant&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: assistant_str<span>.</span>strip(),
</span></span><span><span>                        },
</span></span><span><span>                    ]
</span></span><span><span>                }
</span></span><span><span>                writef<span>.</span>write(<span>f</span><span>&#34;</span><span>{</span>json<span>.</span>dumps(out_obj)<span>}</span><span>\n</span><span>&#34;</span>)
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>I checked my data and validated the correct words for each category were in the output jsonl file.
This time around, I remembered to create an external validation set so I had a few cases to run once the fine-tune was ready.
I split the data up 60% to train, 20% to validate for the fine-tune and 20% to use myself to validate after the fine-tune.</p><p>I put up my feet and waited for the fine-tune to run.</p><p>The first run of the fine-tune.</p><p><img src="https://www.danielcorin.com/img/posts/2024/fine-tune-run-model-output.png" alt="fine-tune run model output"/></p><p>I’m very glad I had more validation data because I couldn’t believe it when I saw it work.
I ran several more and each time, it got the word groups correct.
Though occasionally it seemed to struggle to get the category right with <code>x ___</code> or <code>___ x</code> categories.
But honestly, I was a little stunned.
Before this fine-tuning, the model could not come all that close to solving Connections puzzles and now it could generally get the 4 word groups right every time and the categories right most of the time.
It seemed to good to be true.
It <em>was</em>!
Can you spot the problem?
The input words</p><pre tabindex="0"><code>Here are the 16 words: fido, lucky, rover, spot, catch, notice, observe, see, bait, chum, fly, sinker, bone, rex, shirt, storm
</code></pre><p>and the output categories</p><pre tabindex="0"><code>category: common dog names
words: fido, lucky, rover, spot

category: perceive
words: catch, notice, observe, see

category: fishing gear
words: bait, chum, fly, sinker

category: ___ in a teacup
words: bone, rex, shirt, storm
</code></pre><p>are in the same order.</p><p>When I change the input order of the words for this fine-tune</p><div><pre tabindex="0"><code data-lang="text"><span><span>Here are the 16 words: lucky, chum, shirt, storm, spot, catch, rex, fly, observe, rover, see, bait, fido, notice, sinker, bone
</span></span></code></pre></div><p>it all falls apart.</p><div><pre tabindex="0"><code data-lang="text"><span><span>category: pal
</span></span><span><span>words: lucky, chum, shirt, storm
</span></span><span><span>
</span></span><span><span>category: find
</span></span><span><span>words: spot, catch, rex
</span></span><span><span>
</span></span><span><span>category: ways to call
</span></span><span><span>words: fly, observe, rover, see
</span></span><span><span>
</span></span><span><span>category: dog, e.g.
</span></span><span><span>words: bait, fido, notice, sinker
</span></span></code></pre></div><p>The categories stop making sense.
The model hallucinates words.
Some categories don’t even have 4 words in them.
This fine-tune is toast.</p><h2 id="fixing-another-dataset-bug">Fixing another dataset bug</h2><p>Back to the code.
I modified my data set generation code, then split my data into three sets again.
I used a stable random seed, so that the generation would be the same each time.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> os
</span></span><span><span><span>import</span> json
</span></span><span><span><span>import</span> random
</span></span><span><span>
</span></span><span><span>random<span>.</span>seed(<span>42</span>)
</span></span><span><span>
</span></span><span><span>SYSTEM_PROMPT <span>=</span> <span>&#34;&#34;&#34;The game &#34;Connections&#34; is a word game where you start with 16 words and need to group them into 4 groups of 4. Each grouping has a category that unambiguously groups the four words together. Each puzzle has exactly one solution. Watch out for words that seem to belong to multiple categories. You will be given 16 words. Output 4 groupings of 4 words and the categories to which they belong.&#34;&#34;&#34;</span>
</span></span><span><span>
</span></span><span><span>OUT_FILE <span>=</span> <span>&#34;connections_prompts.jsonl&#34;</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    <span>with</span> open(OUT_FILE, <span>&#34;w&#34;</span>) <span>as</span> writef:
</span></span><span><span>        <span>for</span> file <span>in</span> os<span>.</span>listdir(<span>&#34;connections_data&#34;</span>):
</span></span><span><span>            <span>if</span> file<span>.</span>endswith(<span>&#34;.json&#34;</span>):
</span></span><span><span>                <span>with</span> open(<span>f</span><span>&#34;connections_data/</span><span>{</span>file<span>}</span><span>&#34;</span>, <span>&#34;r&#34;</span>) <span>as</span> f:
</span></span><span><span>                    data <span>=</span> json<span>.</span>load(f)
</span></span><span><span>                categories <span>=</span> [c <span>for</span> c <span>in</span> data[<span>&#34;groups&#34;</span>]<span>.</span>keys()]
</span></span><span><span>                categories_and_members <span>=</span> {c: data[<span>&#34;groups&#34;</span>][c][<span>&#34;members&#34;</span>] <span>for</span> c <span>in</span> categories}
</span></span><span><span>                assistant_str <span>=</span> <span>&#34;&#34;</span>
</span></span><span><span>                <span>for</span> c, words <span>in</span> categories_and_members<span>.</span>items():
</span></span><span><span>                    lower_words <span>=</span> [w<span>.</span>lower() <span>for</span> w <span>in</span> words]
</span></span><span><span>                    assistant_str <span>+=</span> <span>f</span><span>&#34;category: </span><span>{</span>c<span>.</span>lower()<span>}</span><span>\n</span><span>words: </span><span>{</span><span>&#39;, &#39;</span><span>.</span>join(lower_words)<span>}</span><span>\n\n</span><span>&#34;</span>
</span></span><span><span>                all_words <span>=</span> [word<span>.</span>lower() <span>for</span> group <span>in</span> categories_and_members<span>.</span>values() <span>for</span> word <span>in</span> group]
</span></span><span><span>                random<span>.</span>shuffle(all_words)
</span></span><span><span>                all_words_str <span>=</span>  <span>&#39;, &#39;</span><span>.</span>join(all_words)
</span></span><span><span>                out_obj <span>=</span> {
</span></span><span><span>                    <span>&#34;messages&#34;</span>: [
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: SYSTEM_PROMPT,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: <span>f</span><span>&#34;Here are the 16 words: </span><span>{</span>all_words_str<span>}</span><span>&#34;</span>,
</span></span><span><span>                        },
</span></span><span><span>                        {
</span></span><span><span>                            <span>&#34;role&#34;</span>: <span>&#34;assistant&#34;</span>,
</span></span><span><span>                            <span>&#34;content&#34;</span>: assistant_str<span>.</span>strip(),
</span></span><span><span>                        },
</span></span><span><span>                    ]
</span></span><span><span>                }
</span></span><span><span>                writef<span>.</span>write(<span>f</span><span>&#34;</span><span>{</span>json<span>.</span>dumps(out_obj)<span>}</span><span>\n</span><span>&#34;</span>)
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>I ran a few tests</p><div><pre tabindex="0"><code data-lang="text"><span><span>Here are the 16 words: adult, height, kiss, top, pair, tease, times, josh, peak, ten, score, gross, kid, dozen, max, rib
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="text"><span><span>category: nudge, as for information
</span></span><span><span>words: hint, josh, rib, tease
</span></span><span><span>
</span></span><span><span>category: mountain ___
</span></span><span><span>words: adult, gross, height, peak
</span></span><span><span>
</span></span><span><span>category: 12
</span></span><span><span>words: dozen, max, score, times
</span></span><span><span>
</span></span><span><span>category: ___ number
</span></span><span><span>words: kid, kiss, pair, top
</span></span></code></pre></div><p>and</p><div><pre tabindex="0"><code data-lang="text"><span><span>Here are the 16 words: get, presto, secure, tada, fire, voila, carpenter, adam, win, behold, surprise, anger, land, fear, happiness, red
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="text"><span><span>category: eureka!
</span></span><span><span>words: behold, presto, tada, voila
</span></span><span><span>
</span></span><span><span>category: “inside out” emotions
</span></span><span><span>words: anger, fear, happiness, sadness
</span></span><span><span>
</span></span><span><span>category: ___ and peace
</span></span><span><span>words: land, order, red, secure
</span></span><span><span>
</span></span><span><span>category: ___’s rib
</span></span><span><span>words: adam, carpenter, get, surprise
</span></span></code></pre></div><p>The results are <em>ok</em>, but not incredible.
It does get some groupings correct.
There are hallucinations, adding words that don’t exist.
Also, most categories and grouping are not correct.</p><h2 id="evaluating-the-results">Evaluating the results</h2><p>To figure out if this fine-tune was worthwhile, I needed benchmark against the performance of <code>gpt-3.5-turbo-1106</code>.</p><p>I wrote some quick and dirty code to read the <code>validation.jsonl</code>, make an OpenAI call, parse the response and compare it to the known, correct answer.
I decided to measure percentage of puzzles correct (all four categories) and percentage of categories correct (4 words correctly grouped).
I also augmented the user prompt a bit to get the un-fine-tuned model to output it’s response the same way the fine-tuned model would for consistent parsing.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> json
</span></span><span><span><span>from</span> openai <span>import</span> OpenAI
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>client <span>=</span> OpenAI()
</span></span><span><span>
</span></span><span><span>data <span>=</span> []
</span></span><span><span>puzzles_correct <span>=</span> <span>0</span>
</span></span><span><span>puzzles_incorrect <span>=</span> <span>0</span>
</span></span><span><span><span>with</span> open(<span>&#34;validation.jsonl&#34;</span>, <span>&#34;r&#34;</span>) <span>as</span> file:
</span></span><span><span>    <span>for</span> row <span>in</span> file:
</span></span><span><span>        data<span>.</span>append(json<span>.</span>loads(row))
</span></span><span><span>
</span></span><span><span>total_puzzles <span>=</span> len(data)
</span></span><span><span>categories_correct <span>=</span> <span>0</span>
</span></span><span><span>total_categories <span>=</span> total_puzzles <span>*</span> <span>4</span>
</span></span><span><span>
</span></span><span><span><span>for</span> da <span>in</span> data:
</span></span><span><span>    system_prompt <span>=</span> da[<span>&#34;messages&#34;</span>][<span>0</span>][<span>&#34;content&#34;</span>]
</span></span><span><span>    user_prompt <span>=</span> da[<span>&#34;messages&#34;</span>][<span>1</span>][<span>&#34;content&#34;</span>] <span>+</span> <span>&#34;&#34;&#34;</span><span>\n</span><span>Output your response in exact adherence to the following form
</span></span></span><span><span><span>
</span></span></span><span><span><span>category: &lt;category&gt;
</span></span></span><span><span><span>words: &lt;word1&gt;, &lt;word2&gt;, &lt;word3&gt;, &lt;word4&gt;
</span></span></span><span><span><span>
</span></span></span><span><span><span>for example:
</span></span></span><span><span><span>
</span></span></span><span><span><span>category: height
</span></span></span><span><span><span>words: height, top, peak, max
</span></span></span><span><span><span>&#34;&#34;&#34;</span>
</span></span><span><span>
</span></span><span><span>    expected_result <span>=</span> da[<span>&#34;messages&#34;</span>][<span>2</span>]
</span></span><span><span>
</span></span><span><span>    completion <span>=</span> client<span>.</span>chat<span>.</span>completions<span>.</span>create(
</span></span><span><span>        model<span>=</span><span>&#34;gpt-3.5-turbo-1106&#34;</span>
</span></span><span><span>        <span># for the fine-tune:</span>
</span></span><span><span>        <span># model=&#34;ft:gpt-3.5-turbo-1106:personal::&lt;my_id&gt;&#34;,</span>
</span></span><span><span>        messages<span>=</span>[
</span></span><span><span>            {<span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>, <span>&#34;content&#34;</span>: system_prompt},
</span></span><span><span>            {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: user_prompt},
</span></span><span><span>        ]
</span></span><span><span>    )
</span></span><span><span>    <span># parse response</span>
</span></span><span><span>    result <span>=</span> completion<span>.</span>choices[<span>0</span>]<span>.</span>message<span>.</span>content
</span></span><span><span>    categories_with_words <span>=</span> {}
</span></span><span><span>    <span>for</span> line <span>in</span> result<span>.</span>strip()<span>.</span>split(<span>&#34;</span><span>\n\n</span><span>&#34;</span>):
</span></span><span><span>        category, words_str <span>=</span> line<span>.</span>lower()<span>.</span>split(<span>&#34;</span><span>\n</span><span>words: &#34;</span>)
</span></span><span><span>        category_name <span>=</span> category<span>.</span>split(<span>&#34;: &#34;</span>)[<span>1</span>]<span>.</span>strip()
</span></span><span><span>        words <span>=</span> [word<span>.</span>strip() <span>for</span> word <span>in</span> words_str<span>.</span>split(<span>&#34;, &#34;</span>)]
</span></span><span><span>        categories_with_words[category_name] <span>=</span> tuple(sorted(words))
</span></span><span><span>
</span></span><span><span>    <span># compare to correct answer</span>
</span></span><span><span>    correct_categories_with_words <span>=</span> {}
</span></span><span><span>    correct_str <span>=</span>  da[<span>&#34;messages&#34;</span>][<span>2</span>][<span>&#34;content&#34;</span>]
</span></span><span><span>    <span>for</span> line <span>in</span> correct_str<span>.</span>strip()<span>.</span>split(<span>&#34;</span><span>\n\n</span><span>&#34;</span>):
</span></span><span><span>        category, words_str <span>=</span> line<span>.</span>split(<span>&#34;</span><span>\n</span><span>words: &#34;</span>)
</span></span><span><span>        category_name <span>=</span> category<span>.</span>split(<span>&#34;: &#34;</span>)[<span>1</span>]<span>.</span>strip()
</span></span><span><span>        words <span>=</span> [word<span>.</span>strip() <span>for</span> word <span>in</span> words_str<span>.</span>split(<span>&#34;, &#34;</span>)]
</span></span><span><span>        correct_categories_with_words[category_name] <span>=</span> tuple(sorted(words))
</span></span><span><span>
</span></span><span><span>    num_correct <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> word_list <span>in</span> categories_with_words<span>.</span>values():
</span></span><span><span>        <span>if</span> (word_list <span>in</span> list(correct_categories_with_words<span>.</span>values())):
</span></span><span><span>            print(word_list)
</span></span><span><span>            num_correct <span>+=</span> <span>1</span>
</span></span><span><span>    categories_correct <span>+=</span> num_correct
</span></span><span><span>    <span>if</span> num_correct <span>==</span> <span>4</span>:
</span></span><span><span>        puzzles_correct <span>+=</span> <span>1</span>
</span></span><span><span>    <span>else</span>:
</span></span><span><span>        puzzles_incorrect <span>+=</span> <span>1</span>
</span></span><span><span>
</span></span><span><span>    <span># Calculate and print the percentages</span>
</span></span><span><span>    percent_correct <span>=</span> (puzzles_correct <span>/</span> total_puzzles) <span>*</span> <span>100</span>
</span></span><span><span>    percent_incorrect <span>=</span> (puzzles_incorrect <span>/</span> total_puzzles) <span>*</span> <span>100</span>
</span></span><span><span>    print(<span>f</span><span>&#34;Correct: </span><span>{</span>percent_correct<span>:</span><span>.2f</span><span>}</span><span>%&#34;</span>)
</span></span><span><span>    print(<span>f</span><span>&#34;Incorrect: </span><span>{</span>percent_incorrect<span>:</span><span>.2f</span><span>}</span><span>%&#34;</span>)
</span></span><span><span>
</span></span><span><span>    percent_categories_correct <span>=</span> (categories_correct <span>/</span> total_categories) <span>*</span> <span>100</span>
</span></span><span><span>    print(<span>f</span><span>&#34;Total Categories Correct: </span><span>{</span>percent_categories_correct<span>:</span><span>.2f</span><span>}</span><span>%&#34;</span>)
</span></span></code></pre></div><p>I started by running the code against <code>gpt-3.5-turbo-1106</code>.</p><div><pre tabindex="0"><code data-lang="text"><span><span>Correct: 0.00%
</span></span><span><span>Incorrect: 100.00%
</span></span><span><span>Total Categories Correct: 20.24%
</span></span></code></pre></div><p>Next, I ran it against my fine-tuned model.</p><div><pre tabindex="0"><code data-lang="text"><span><span>Correct: 4.76%
</span></span><span><span>Incorrect: 95.24%
</span></span><span><span>Total Categories Correct: 23.81%
</span></span></code></pre></div><p>Not a huge difference.
I did a few more runs and none of the results we’re too out of the ordinary.
Other than consistent formatting, it’s not clear the model got all that much better at the game after fine-tuning.</p><h2 id="wrap-up">Wrap up</h2><p>This experience was an interesting introduction to model fine-tuning.
The results weren’t that amazing, but I learned a lot about easy pitfalls and mistakes one can make and had some fun.</p><h2 id="future-work">Future work</h2><p>To see if there might be more to explore for this project, I ran the validation set through <code>gpt-4</code> with the following results</p><div><pre tabindex="0"><code data-lang="text"><span><span>Correct: 9.52%
</span></span><span><span>Incorrect: 90.48%
</span></span><span><span>Total Categories Correct: 39.29%
</span></span></code></pre></div><p>This improvement is notable over gpt-3.5’s ~20-25%.
I requested access to fine-tune <code>gpt-4</code>, so we’ll see if that comes through and I can try it out.</p><hr/></div></div></div>
  </body>
</html>
