<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.collabora.com/news-and-blog/blog/2022/02/08/landing-a-new-syscall-part-what-is-futex/">Original</a>
    <h1>Landing a new syscall, part 1: What is futex?</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Over the past 18 months, we have been on a roller-coaster ride developing futex2, a new set of system calls. As part of this prolonged effort, the futex_waitv() syscall has now successfully <a href="https://www.collabora.com/news-and-blog/blog/2022/02/08/landing-a-new-syscall-part-what-is-futex/news-and-blog/news-and-events/kernel-5.16.html" target="_blank" rel="noopener noreferrer">landed in Linux 5.16</a>.</p>
<p>A followup of the initial futex syscall, this new interface aims to overcome long term issues that have been limiting the way applications use the Linux kernel. But what exactly is futex? This series of blog posts will help answer that and other questions around this tricky function.</p>
<p>If you&#39;ve ever run <code>strace</code> in a multithread program, chances are that the trace was filled with <code>futex()</code> calls. If you are a Linux gamer trying to increase the performance of your setup, you have probably heard of futex as well.</p>
<p>Read on as I take a deep dive into this important system call and how it is used to process synchronization functions.</p>
<h3>Data racing</h3>
<p>Before getting into futex, we need to know which problem it solves: race condition. Since the arrival of multitasking operating systems, different tasks can now work at the same time and compete for the same resources. Using the same data at the same moment can lead to serious bugs as we will see next.</p>
<p>Imagine that your bank has a multithreading software to manage your account running in a single core, but failed to correctly use synchronization mechanisms. Let&#39;s say that you have 500 moneys in the bank. You want to withdraw 300 moneys and at the same time your friend wants to send you 200 moneys. Then, in the fast multithread bank system, this happens:</p>
<h4>Thread 1</h4>
<pre>aux = account_balance 	//  500
aux += receive_money   	//  500 + 200
account_balance = aux 	//  700
</pre>
<h4>Thread 2</h4>
<pre>aux = account_balance 	//  700
aux -= withdraw_money	//  700 - 300
account_balance = aux	//  400
</pre>
<p>All good! Everything went as expected. The kernel can order the threads in different manners. In this case, if <strong>Thread 2</strong> went before <strong>Thread 1</strong> the final result would be the same anyway:</p>
<h4>Thread 2</h4>
<pre>aux = account_balance 	//  500
aux -= withdraw_money	//  500 - 300
account_balance = aux	//  200
</pre>
<h4>Thread 1</h4>
<pre>aux = account_balance 	//  200
aux += receive_money   	//  200 + 200
account_balance = aux 	//  400
</pre>
<p>However, the scheduler preemption can interleave the execution of both threads, resulting in something like this:</p>
<h4>Thread 1</h4>
<pre>aux = account_balance 	//  500
aux += receive_money   	//  500 + 200
</pre>
<h4>Thread 2</h4>
<pre>aux = account_balance 	//  500
aux -= withdraw_money	//  500 - 300
account_balance = aux	//  200
</pre>
<h4>And back to Thread 1</h4>
<pre>account_balance = aux 	//  700
</pre>
<p>Given that both threads were sharing the same resource (<code>account_balance</code>) and aren&#39;t using synchronization mechanisms, they failed to keep data consistence. <strong>Thread 2</strong> writes 200 to <code>account_balance</code>, but just after <strong>Thread 1</strong> overwrote it with 700.</p>
<p>If we were in a multiprocessor machine, this issue would be even worse given that these threads can run in concurrency.</p>
<p>But it&#39;s not that bad, right? You got more moneys! However, the opposite scheduling could happen as well, keeping you with only 200 moneys in the bank. So how do we solve this?</p>
<h3>Mutual exclusion: Mutex</h3>
<p>Mutex is a sync primitive that helps you make sure only one thread can access a critical section (hence the name, mutual exclusion).</p>
<p>Imagine that there&#39;s a room that can only be accessed by one person at a time. You get the key for the room, access it, and lock the door. When exiting, you leave the key for the next person. This is how a mutex works: you lock to use access the critical section and then unlock after using it. If when you want to lock it&#39;s already locked, then you need to patiently wait for another thread to open the door and give you the key.</p>
<p>In our bank example, the code could be fixed like this:</p>
<pre>mutex_lock()
aux = account_balance 
[...]
account_balance = aux
mutex_unlock()
</pre>
<p>This would then make any thread changing the account balance do so exclusively, without racing to other threads. Even if the thread gets scheduled with the lock, any other thread that tries to change the <code>account_balance</code> would face the <code>mutex_lock()</code> and would have to wait until someone calls <code>mutex_unlock()</code>.</p>
<p>There are several other sync mechanisms out there, like spinlocks, semaphores and barriers, but in this article we are going to focus just on mutexes.</p>
<h3>&#34;Never write your own locks&#34;</h3>
<p>The goal of a mutex is to enable multiple threads to do their work, so ideally we should not impose high overheads with our mutexes. They should be super fast when the lock is not taken and ensure that tasks waiting to get the lock don&#39;t waste CPU time.</p>
<p>So how is a userspace mutex implemented? There are different approaches to it, as operating systems and programming libraries can take different directions. But if I would implement my own, I would make sure to use the kernel. After all, only the kernel can put a thread to sleep and awaken it when asked.</p>
<p>If we use the kernel, we can figure out a nice interface that takes care of a value for us. That would then allow us to:</p>
<ul>
<li>Check if the lock is taken. If it is, sleep;</li>
<li>If it is not taken, take it;</li>
<li>And when releasing the lock, wake anyone waiting for it.</li>
</ul>
<p>And just like that, I have described something similar to the &#34;System V semaphore&#34; mechanism, implemented in Linux via semop() syscall.</p>
<p>However, doing syscalls requires expensive context switches (and costs even more in the face of Spectre and Meltdown). Don&#39;t forget that our goal is to be as fast as possible in the common case, which is when the lock is not taken. This is where futex design comes in.</p>
<h3>Futex: fast userspace mutex</h3>
<p>Instead of asking for the kernel to take care of the mutex value for us, we can keep track of it in userspace. Then, depending on the value, we can use the kernel only if we need to sleep or to wake other threads.</p>
<p>This is the main design feature of the futex. Most of the time, it doesn&#39;t need the kernel, so we have less context switch and can have a lightweight mutex implementation. However, to make this work we need to have a platform that supports atomic operations so we can ensure that the mutex value is being manipulated by a single thread at once. Let&#39;s see what the code would look like for such a situation.</p>
<p>First, let&#39;s define values for our mutex state. Futex can only operate with unsigned int of 32bits:</p>
<pre>#define UNLOCKED 0
#define LOCKED 1
</pre>
<p>Now, here&#39;s an implementation for the <code>mutex_lock()</code>. Note, however, that a correct mutex is slightly more complex than this example. A complete mutex would enable us to avoid going into the kernel if needed, and would be able to prevent mutual starvation between two threads acquiring the lock. The example below is therefore only for didactic purposes, to help demonstrate how a mutex works.</p>
<pre>mutex_lock(unsigned int *mutex)
{
	while (!cmpxchg(mutex, UNLOCKED, LOCKED))
		futex(mutex, FUTEX_WAIT, LOCKED);
}
</pre>
<p>Breaking down the code:</p>
<p>Here, our mutex is just a simple <code>uint</code>. <code>cmpxchg()</code> is an atomic compare-and-exchange operation, where if the mutex value is UNLOCKED, it replaces it by LOCKED. It returns true if the operation succeeded or false otherwise. If it returns true, it means that the lock was free and we took it. Otherwise, the lock was already taken by someone else and we need to wait for it to get freed. Now we call the futex() syscall. We use <code>&amp;mutex</code> as the first argument, since the memory address of our value is the identifier.</p>
<p>The second argument is <code>FUTEX_WAIT</code>, that&#39;s the opcode to wait on this address until something wakes us (you can optionally use a timeout argument as well). The third argument is the value that we expect to find as the value of the mutex variable. If the value at mutex is different from that, the syscall returns immediately with an <code>-EAGAIN</code> error. We need to set that because between the <code>cmpxchg()</code> and <code>futex()</code> the lock could be freed and if we wait in a free lock, we will probably wait forever.</p>
<p>We need to do this in a &#34;while loop&#34; because when waking up we might race with another thread trying to acquire the lock, and might need to wait again.</p>
<p>On the unlock side, we have this:</p>
<pre>mutex_unlock(unsigned int *mutex)
{
	atomic_set(mutex, UNLOCKED);
	futex(mutex, FUTEX_WAKE, 1);
}
</pre>
<p>We atomically set the value as <code>UNLOCKED</code>, making it free to anyone that wants to take it and issue a <code>futex()</code> call; using the <code>FUTEX_WAKE</code> operation with 1 as an argument. That means that we will wake someone that is waiting in the <code>&amp;mutex</code> address. We could optimize this code to have more than two states and have a way to specify that the mutex is locked and that there is someone waiting for it. If there is no one waiting for it, then we don&#39;t need to call <code>futex()</code> in the unlock function. That way we achieve a very fast mutex with no syscalls needed for the common case, that&#39;s where the lock is not taken.</p>
<h3>Conclusion</h3>
<p>As you can see, <a href="https://www.akkadia.org/drepper/futex.pdf" target="_blank" rel="noopener noreferrer">futexes are tricky</a>. Hopefully, if everything works as expected, software developers won&#39;t need to know that it exists, even if it&#39;s constantly being used by multithread applications.</p>
<p>At a high level, we can describe that futex syscall provides a kernel side wait queue indexed by a userspace address. That userspace can add or remove new threads to it.</p>
<p>In the next post, we are going to dive into the internal implementation of the futex syscall, its limitations, and why a new interface is being proposed.</p>


</div></div>
  </body>
</html>
