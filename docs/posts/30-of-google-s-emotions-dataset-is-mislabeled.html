<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.surgehq.ai//blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled">Original</a>
    <h1>30% of Google&#39;s Emotions Dataset Is Mislabeled</h1>
    
    <div id="readability-page-1" class="page"><div><div><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb708dd809bc5b02e8af16_3z1oyrmmd7m41.png" loading="lazy" alt=""/></p><figcaption><em>When you mislabel LOVE, cue heartbreak all around.</em></figcaption></figure><p>Last year, Google released their <a href="https://ai.googleblog.com/2021/10/goemotions-dataset-for-fine-grained.html">“GoEmotions” dataset</a>: a human-labeled dataset of 58K Reddit comments categorized according to 27 emotions.</p><p>The problem? <strong>A whopping 30% of the dataset is severely mislabeled!</strong> (We tried training a model on the dataset ourselves, but noticed deep quality issues. So we took 1000 random comments, asked Surgers whether the original emotion was reasonably accurate, and found strong errors in 308 of them.) How are you supposed to train and evaluate machine learning models when your data is so wrong?</p><p>For example, here are 25 mislabeled emotions in Google’s dataset.</p><p><strong>Comments mislabeled as NEGATIVE emotions</strong></p><ul role="list"><li><strong>LETS FUCKING GOOOOO</strong> – mislabeled as <strong>ANGER</strong>, likely because Google&#39;s low-quality labelers don’t understand English slang and mislabel any profanity as a negative emotion</li><li><strong>*aggressively tells friend I love them*</strong> – mislabeled as <strong>ANGER</strong></li><li><strong>you almost blew my fucking mind there.</strong> – mislabeled as <strong>ANNOYANCE</strong></li><li><strong>daaaaaamn girl!</strong> – mislabeled as <strong>ANGER</strong></li><li><strong>[NAME] wept.</strong> – mislabeled as <strong>SADNESS</strong>, likely because Google’s non-fluent labelers don’t understand the <a href="https://www.urbandictionary.com/define.php?term=Jesus%20wept">idiomatic meaning of “Jesus wept”</a>, and thought someone was truly crying</li><li><strong>I try my damndest. Hard to be sad these days when I got this guy with me</strong> – mislabeled as <strong>SADNESS</strong></li><li><strong>hell yeah my brother</strong> – mislabeled as <strong>ANNOYANCE</strong></li><li><strong>[NAME] is bae, how dare you.</strong> – mislabeled as <strong>ANGER</strong>, likely because the labelers don’t know what <a href="https://www.urbandictionary.com/define.php?term=Bae">“bae”</a> means, and aren’t fluent enough in online English usage to realize that “how dare you” is written in a mock anger tone</li></ul><p><strong>Comments mislabeled as NEUTRAL emotions</strong></p><ul role="list"><li><strong>But muh narrative! Orange man caused this!!!!!</strong> – mislabeled as <strong>NEUTRAL</strong>, likely because labelers don’t understand who “orange man” refers to, or the mockery behind writing “muh” instead of “my”</li><li><strong>My man!</strong> – mislabeled as <strong>NEUTRAL</strong>, likely because labelers don’t know what this phrase means</li><li><strong>KAMALA 2020!!!!!!</strong> – mislabeled as <strong>NEUTRAL</strong>, likely because the non-US labelers don’t know who Kamala Harris is or didn&#39;t have enough context</li><li><strong>Hi dying, I&#39;m dad!</strong> – mislabeled as <strong>NEUTRAL</strong>, likely because labelers don’t understand dad jokes</li></ul><p>‍<strong>Comments mislabeled as POSITIVE emotions</strong></p><ul role="list"><li><strong>I love when they send in the wrong meat, it’s only happened to me once</strong> – mislabeled as <strong>LOVE</strong></li><li><strong>Nobody has the money to. What a joke</strong> – mislabeled as <strong>JOY</strong></li><li><strong>Yay, cold McDonald&#39;s. My favorite.</strong> – mislabeled as <strong>LOVE</strong></li><li><strong>Really? Wow. You’re either hopelessly ignorant or you’re trolling. For your sake, I hope you’re trolling.</strong> – mislabeled as <strong>OPTIMISM</strong></li><li><strong>These 2 are repulsive little kids</strong> – mislabeled as <strong>APPROVAL</strong> (I don’t have any explanation, other than this in the kind of quality you get when you throw warm bodies at the problem of data labeling instead of building robust infrastructure)</li><li><strong>Yeah, because not paying a bill on time is equal to murdering children.</strong> – mislabeled as <strong>APPROVAL</strong>, likely because of the “Yeah”</li><li><strong>I wished my mom protected me from my grandma. She was a horrible person who was so mean to me and my mom.</strong> – mislabeled as <strong>OPTIMISM</strong></li></ul><p>In other words, when Google can’t even label <strong><em>daaaaaamn girl!</em></strong> or <strong><em>These 2 are repulsive little kids</em></strong> correctly, is it any surprise that <a href="https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors">Google’s Toxic Speech API is merely a profanity detector</a>?</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb75ddd809bc1ef7e902bb_CleanShot%202022-07-10%20at%2017.57.47%402x.png" loading="lazy" alt=""/></p><figcaption>Is it a surprise that Google&#39;s Toxicity API misclassifies this comment as TOXIC, given the errors in its datasets?</figcaption></figure><p>Or that <a href="https://www.surgehq.ai/blog/are-the-spammers-winning-failures-in-gmail-spam-detection">Gmail’s spam detector is deteriorating</a>?</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb74cd2f1b07a5dfb607e5_CleanShot%202022-07-10%20at%2017.53.31%402x.png" loading="lazy" alt=""/></p><figcaption>This email may seem like obvious spam... But then again, <strong><em>daaaaaamn girl!</em></strong> seems obviously <em>not</em> ANGER!</figcaption></figure><p>When good data is crucial for good models – in a research paper <em>specifically designed to create a dataset</em>, no less! – can we really trust Google to create unbiased real-world AI? </p><h2>Google’s Flawed Data Labeling Methodology</h2><p>To summarize the types of errors in Google’s dataset, many come from:</p><ul role="list"><li>Profanity – mislabeling <strong>hell yeah my brother </strong>as ANNOYANCE instead of APPROVAL or EXCITEMENT. </li><li>English idioms – mislabeling <strong>Jesus wept</strong> as SADNESS and <strong>What a joke</strong> as JOY.</li><li>Sarcasm – mislabeling <strong>Yay, cold McDonald’s. My favorite.</strong> as LOVE</li><li>Basic English – mislabeling <strong>These 2 are repulsive little kids</strong> as APPROVAL</li><li>Reddit memes – mislabeling <strong>Hi dying, I’m dad!</strong> as NEUTRAL instead of AMUSEMENT</li><li>US politics and culture – mislabeling <strong>KAMALA 2020!!!!!!</strong> as NEUTRAL instead of EXCITEMENT or sarcasm, depending on the context</li></ul><p>What’s causing these issues? A big part of the problem is Google treating data labeling as an afterthought to throw warm bodies at, instead of as a nuanced problem that requires sophisticated technical infrastructure and research attention of its own.</p><p>For  example, let’s look at the labeling methodology described in the paper. To quote Section 3.3:</p><ol role="list"><li>“Reddit comments were presented [to labelers] with no additional metadata (such as the author or subreddit).”</li><li>“All raters are native English speakers from India.”</li></ol><h3>Problem #1: “Reddit comments were presented with no additional metadata”</h3><p>First of all, language doesn’t live in a vacuum! Why would you present a comment with no additional metadata? The subreddit and parent post it’s replying to are especially important context.</p><p>For example, <a href="https://www.reddit.com/r/worldbuilding/comments/afeoyz/we_seriously_need_have_jail_time_based_on_a/?context=0"><strong>“We SERIOUSLY NEED to have Jail Time based on a person&#39;s race”</strong></a> means one thing in a subreddit about law, and something completely different in a subreddit about fantasy worldbuilding.</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb6cdde8198458a8c10bb5_Na7Fy1da_yJCoXf4noIMZ_fI1H2uqEVmeeSMCnxU04wFx78uFDw4KxpObwCgPsvURkaTg67nCtUCaUtABP3OtjM6IcJS-HiClzdcVaKfVeVhpYwx68O8IdWHzqJZvT5rk0ULvBkOdcwsYr9vfDc.png" alt=""/></p><figcaption>“We SERIOUSLY NEED to have Jail Time based on a person&#39;s race” means very different things in subreddits about law vs. fantasy worldbuilding</figcaption></figure><p>As another example, imagine you see the comment <strong>“his traps hide the fucking sun”</strong> by itself. Would you have any idea what it means? Probably not – maybe that&#39;s why Google mislabeled it.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb6cddbd099a05caf9d0b1_MTE7K4Gxrdk55L9dzpnZXwET43mSbDtAxAcvfln0qJ2C9Ty_usRyl3wvJJXS4OpOBwxzrlW3OzLeBgh4k_Ki2X1bioQbIXPq8qq3uEzQPPgNk5ckXz9vOLVAE1UmaNifVXEpCLCqo95rDCeBbd4.png" alt=""/></p><figcaption>What does “his traps hide the fucking sun” mean with no context?</figcaption></figure><p>But what if you were told it came from the <a href="https://www.reddit.com/r/nattyorjuice/">/r/nattyorjuice</a> subreddit dedicated to bodybuilding? Would you realize, then, that traps refers to someone’s trapezoid muscles?</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb6cdde00ff81040ae47c5_e6KXpo2tOvLlNk854elcZwxjW1US5iuTjWD-1SUgle_Ivy2FAgm5oXrT3slSCbrI__O4MkZXH9ISB_bjv-AwgOy4-lpnOwp5L2MBvWK9ziYyQdurxhN5U5gOm3Er6vZg1UUoAoroKuJykQr8IJ8.png" alt=""/></p><figcaption>“his traps hide the fucking sun” in the context of a bodybuilding subreddit</figcaption></figure><p>What, moreover, if you were given <a href="https://www.reddit.com/r/nattyorjuice/comments/aee3wx/olympic_drug_tested_wrestler_revaz_nadareishvili/ee8jd5h/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">the actual link to the comment</a>, and saw the picture it was replying to? Would you realize, then, that the comment is pointing out the size of the man’s muscles?</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><p><img src="https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62cb6cdeaeebe907f3660d96_sqcUuiT9CPubrjG2MzzxqB1f4G-5uIdT5X4CUpvGNXF1yR6amXqgZ7kyPr6qGg3wBD-bXIAk4HPqPRmg_FbaMkNG0MK8vcIE-_27nauJSR4IRuHPGuek2RkOANYJLNKmFXwd7cY0OdNdcVfpo9Q.png" alt=""/></p><figcaption>Ah... Those big, beautiful traps do indeed hide the sun!</figcaption></figure><p>With this extra context, a good data labeling platform wouldn&#39;t have mislabeled the comment as NEUTRAL and ANGER like this dataset did.</p><h3>Problem #2: “All raters are native English speakers from India”</h3><p>Second, Google used data labelers unfamiliar with US English and US culture – despite Reddit being a US-centric site with particularly specialized memes and jargon. </p><p>Is it a surprise that these labelers don’t understand sarcasm, profanity, and common English idioms in the texts that they’re labeling?</p><p>That they can’t correctly label comments like <strong>KAMALA 2020!!!!!!</strong> where you need familiarity with US politics? Or that they mislabel comments like <strong>Hi dying, I&#39;m dad! </strong>where you need to understand Reddit culture and memes?</p><p>That’s why when we relabeled the dataset, our technical infrastructure and human-AI algorithms allowed us to:</p><ul role="list"><li>Leverage our labeling marketplace to build a team of Surgers who aren&#39;t only native US English speakers, but also heavy Reddit and social media users who understand all of Reddit&#39;s in-jokes, the nuances in US politics (important for social media labeling, given its trickiness and prevalence!), and the cultural zeitgeist. (Who said you can&#39;t be a professional memelord?)</li></ul><ul role="list"><li>Test labelers to make sure they were labeling sarcasm, idioms, profanity, and memes correctly – e.g., dynamically giving them exams to make sure only labelers who understood <strong>But muh narrative! Orange man caused this!!!!!</strong> could work on the project.</li><li>Double-check cases where our AI prediction infrastructure differed from human judgments.</li></ul><h2>The Importance of High-Quality Data</h2><p>If you want to deploy ML models that work in the real world, it’s time for a focus on <strong>high-quality datasets</strong> over bigger models – just listen, after all, to Andrew Ng&#39;s focus on <a href="https://mitsloan.mit.edu/ideas-made-to-matter/why-its-time-data-centric-artificial-intelligence">data-centric AI</a>. </p><p>Hopefully Google learns this too!</p><p>Otherwise those big, beautiful traps may get censored into oblivion, and all the rich nuances of language and humor with it...</p><p>–</p><p><em>Have you experienced frustrations getting good data? Want to work with a data labeling platform that treats data as a first-class citizen, and gives it the loving attention and care it deserves? Check out our other posts on data-centric AI, and follow us on Twitter at </em><a href="https://twitter.com/hellosurgeai"><em>@HelloSurgeAI</em></a><em>!<br/></em></p><ul role="list"><li><a href="https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors">Holy $#!t: Are popular toxicity models simply profanity detectors?</a></li><li><a href="https://www.surgehq.ai/blog/why-context-aware-datasets-are-crucial-for-data-centric-ai">The importance of context-sensitivity in data-centric AI</a></li><li><a href="https://www.surgehq.ai/blog/are-the-spammers-winning-failures-in-gmail-spam-detection">10 Failures in Gmail Spam Detection</a></li></ul></div></div><div><p><img src="https://assets.website-files.com/60fe135d32619450ac38f676/624186de687b3586d87257ca_CS%20logo%20image.png" loading="lazy" width="80" alt="surge ai logo"/></p><div><h3>Data Labeling 2.0 for Rich, Creative AI</h3><p>Superintelligent AI, meet your human teachers. Our data labeling platform is designed from the ground up to train the next generation of AI — whether it’s systems that can code in Python, summarize poetry, or detect the subtleties of toxic speech. Use our powerful data labeling workforce and tools to build the rich, human-powered datasets you need today.</p></div></div></div>
  </body>
</html>
