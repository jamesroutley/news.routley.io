<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.techdirt.com/2026/02/12/ice-cbp-knew-facial-recognition-app-couldnt-do-what-dhs-says-it-could-deployed-it-anyway/">Original</a>
    <h1>ICE, CBP Knew Facial Recognition App Couldn&#39;t Do What DHS Says It Could</h1>
    
    <div id="readability-page-1" class="page"><div id="storywrap-532176">

		<div>

			<div>

				


				


				<h3>from the <i>fuck-everyone-but-us-policy-still-in-play</i> dept</h3>
				


				<p>The DHS and its components want to find non-white people to deport by any means necessary. Of course, “necessary” is something that’s on a continually sliding scale with Trump back in office, which means everything (legal or not) is “necessary” if it can help White House advisor Stephen Miller hit his self-imposed <a href="https://www.techdirt.com/2025/08/08/courts-start-asking-about-the-ice-arrest-quota-the-administration-is-now-pretending-isnt-a-quota/" data-type="link" data-id="https://www.techdirt.com/2025/08/08/courts-start-asking-about-the-ice-arrest-quota-the-administration-is-now-pretending-isnt-a-quota/">3,000 arrests per day</a> goal.</p>
<p>As was reported last week, DHS components (ICE, CBP) are using a web app that supposedly can identify people and link them with citizenship documents. As has always been the case with DHS components (dating back to the Obama era), the rule of thumb is “deploy first, compile legally-required paperwork later.” The pattern has never changed. ICE, CBP, etc. acquire new tech, hand it out to agents, and much later — if <em>ever</em> — the agencies compile and publish their legally-required Privacy Impact Assessments (PIAs). </p>
<p>PIAs are supposed to <em>precede</em> deployments of new tech that might have an impact on privacy rights and other civil liberties. In almost every case, the tech has been deployed far ahead of the precedential paperwork. </p>
<p>As one would expect, the Trump administration was never going to be the one to ensure the paperwork arrived ahead of the deployment. <a href="https://www.techdirt.com/2026/02/06/facial-recognition-tech-used-to-hunt-migrants-was-deployed-without-required-privacy-paperwork/" data-type="link" data-id="https://www.techdirt.com/2026/02/06/facial-recognition-tech-used-to-hunt-migrants-was-deployed-without-required-privacy-paperwork/">As we covered recently</a>, both ICE and CBP are using tech provided by NEC called “Mobile Fortify” to identify migrants who are possibly subject to removal, even though neither agency has bothered to publish a Privacy Impact Assessment.</p>
<p><a href="https://www.wired.com/story/mobile-fortify-face-recognition-nec-ice-cbp/" data-type="link" data-id="https://www.wired.com/story/mobile-fortify-face-recognition-nec-ice-cbp/">As Wired reported</a>, the app is being used widely by officers working with both agencies, despite both agencies making it clear they don’t have the proper paperwork in place to justify these deployments. </p>
<blockquote>
<p><em>While CBP says there are “sufficient monitoring protocols” in place for the app, ICE says that the development of monitoring protocols is in progress, and that it will identify potential impacts during an AI impact assessment. According to <a href="https://archive.ph/o/j89xB/https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf" target="_blank" rel="noreferrer noopener">guidance</a> from the Office of Management and Budget, which was issued before the inventory says the app was deployed for either CBP or ICE, agencies are supposed to complete an AI impact assessment before deploying any high-impact use case. Both CBP and ICE say the app is “high-impact” and “deployed.”</em></p>
</blockquote>
<p>While this is obviously concerning, it would be far less concerning if we weren’t dealing with an administration that has told immigration officers that they don’t need warrants to <a href="https://www.techdirt.com/2026/01/22/since-last-may-ice-officers-have-been-told-they-dont-need-warrants-to-enter-homes/" data-type="link" data-id="https://www.techdirt.com/2026/01/22/since-last-may-ice-officers-have-been-told-they-dont-need-warrants-to-enter-homes/">enter houses</a> or <a href="https://www.techdirt.com/2026/02/03/ice-director-says-officers-are-now-allowed-to-make-arrests-without-warrants/" data-type="link" data-id="https://www.techdirt.com/2026/02/03/ice-director-says-officers-are-now-allowed-to-make-arrests-without-warrants/">effect arrests</a>. And it would be insanely less concerning if we weren’t dealing with an administration that has claimed that simply observing or reporting on immigration enforcement efforts is an act of terrorism.</p>
<p>Officers working for the combined forces of bigotry d/b/a/ “immigration enforcement” know they’re safe. The Supreme Court has ensured they’re safe by <a href="https://www.techdirt.com/2022/06/14/supreme-court-makes-it-all-but-impossible-to-sue-federal-officers-for-rights-violations/" data-type="link" data-id="https://www.techdirt.com/2022/06/14/supreme-court-makes-it-all-but-impossible-to-sue-federal-officers-for-rights-violations/">making it impossible</a> to sue federal officers. And the people running immigration-related agencies have made it clear they don’t even care if the ends justify the means. </p>
<p><a href="https://www.wired.com/story/cbp-ice-dhs-mobile-fortify-face-recognition-verify-identity/" data-type="link" data-id="https://www.wired.com/story/cbp-ice-dhs-mobile-fortify-face-recognition-verify-identity/">These facts make what’s reported here even worse</a>, especially when officers are using the app to “identify” pretty much anyone they can point a smartphone at. </p>
<blockquote>
<p><em>Despite DHS repeatedly framing Mobile Fortify as a tool for identifying people through facial recognition, however, the app does not actually “verify” the identities of people stopped by federal immigration agents—a well-known limitation of the technology and a function of how Mobile Fortify is designed and used.</em></p>
<p><em>[…]</em></p>
<p><em>Records reviewed by WIRED also show that DHS’s hasty approval of Fortify last May was enabled by dismantling centralized privacy reviews and quietly removing department-wide limits on facial recognition—changes overseen by a former Heritage Foundation lawyer and Project 2025 contributor, who now serves in a senior DHS privacy role.</em></p>
</blockquote>
<p>Even if you’re the sort of prick who thinks whatever happens to non-citizens is deserved due to their alleged violation of civil statutes, one would hope you’d actually care what happens to your fellow citizens. I mean, one would hope, but even the federal government doesn’t care what happens to US citizens if they happen to be unsupportive of Trump’s migrant-targeting crime wave. </p>
<blockquote>
<p><em>DHS—which has declined to detail the methods and tools that agents are using, despite repeated calls from <a href="https://documents.pclob.gov/prod/Documents/OversightReport/90964138-44eb-483d-990e-057ce4c31db7/Use%20of%20FRT%20by%20TSA%2C%20PCLOB%20Report%20%285-12-25%29%2C%20Completed%20508%2C%20May%2019%2C%202025.pdf" target="_blank" rel="noreferrer noopener">oversight officials</a> and <a href="https://epic.org/wp-content/uploads/2025/11/Coalition-Letter-on-ICE-Mobile-Fortify-FRT-Nov2025.pdf" target="_blank" rel="noreferrer noopener">nonprofit privacy watchdogs</a>—has used Mobile Fortify to scan the faces not only of “targeted individuals,” but also people later <a href="https://www.nytimes.com/2026/01/30/technology/tech-ice-facial-recognition-palantir.html" target="_blank" rel="noreferrer noopener">confirmed to be US citizens</a> and others who were observing or protesting enforcement activity.</em></p>
</blockquote>
<p>TLDR and all that: DHS knows this tool performs worst in the situations where it’s used most. DHS and its components also knew they were supposed to produce PIAs before deploying privacy-impacting tech. And DHS knows its agencies are not only misusing the tech to convert AI shrugs into probable cause, but are using it to identify people protesting or observing their efforts, which means this tech is also a potential tool of unlawful retribution.</p>
<p>There’s nothing left to be discussed. This tech will continue to be used because it can turn bad photos into migrant arrests. And its off-label use is just as effective: it allows ICE and CBP agents to identify protesters and observers, even as DHS officials continue to claim doxing should be a federal offense if they’re not the ones doing it. Everything about this is bullshit. But bullshit is all this administration has. </p>

				
<p>

	Filed Under: <a href="https://www.techdirt.com/tag/border-patrol/" rel="tag">border patrol</a>, <a href="https://www.techdirt.com/tag/cbp/" rel="tag">cbp</a>, <a href="https://www.techdirt.com/tag/dhs/" rel="tag">dhs</a>, <a href="https://www.techdirt.com/tag/facial-recognition-tech/" rel="tag">facial recognition tech</a>, <a href="https://www.techdirt.com/tag/ice/" rel="tag">ice</a>, <a href="https://www.techdirt.com/tag/privacy-impact-assessment/" rel="tag">privacy impact assessment</a>, <a href="https://www.techdirt.com/tag/surveillance/" rel="tag">surveillance</a>, <a href="https://www.techdirt.com/tag/trump-administration/" rel="tag">trump administration</a>
	</p>

			</div>

		</div>

		
	</div></div>
  </body>
</html>
