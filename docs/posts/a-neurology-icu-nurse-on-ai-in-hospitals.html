<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.codastory.com/stayonthestory/nursing-ai-hospitals-robots-capture/">Original</a>
    <h1>A neurology ICU nurse on AI in hospitals</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>The healthcare landscape is changing fast thanks to the introduction of artificial intelligence. These technologies have shifted decision-making power away from nurses and on to the robots. Michael Kennedy, who works as a neuro-intensive care nurse in San Diego, believes AI could destroy nurses’ intuition, skills, and training. The result being that patients are left watched by more machines and fewer pairs of eyes. Here is Michael’s  story, as told to Coda’s Isobel Cockerell. This conversation has been edited and condensed for clarity.  </p>



<p>Every morning at about 6:30am I catch the trolley car from my home in downtown San Diego up to the hospital where I work — a place called La Jolla. Southern California isn’t known for its public transportation, but I’m the weirdo that takes it — and I like it. It’s quick, it’s easy, I don’t have to pay for parking, it’s wonderful. A typical shift is 12 hours and it ends up being 13 by the time you do your report and get all your charting done, so you’re there for a very long time. </p>



<p>Most of the time, I don’t go to work expecting catastrophe — of course it happens once in a while, but usually I’m just going into a normal job, where you do routine stuff.</p>


    <div>
        <div id="mc_embed_signup">
            <div>
                <p>Stay on the story</p>
                <p>Coda produces journalism that digs into the roots of major global trends. Sign up to receive stories and insights straight to your inbox.</p>
            </div>
            <!-- Mailchimp for WordPress v4.9.18 - https://wordpress.org/plugins/mailchimp-for-wp/ --><!-- / Mailchimp for WordPress Plugin -->        </div>
    </div>


<p>I work in the neuro-intensive care unit. The majority of our patients have just had neurosurgery for tumors or strokes. It’s not a happy place most of the time. I see a lot of people with long recoveries ahead of them who need to relearn basic skills — how to hold a pencil, how to walk. After a brain injury, you lose those abilities, and it’s a long process to get them back. It’s not like we do a procedure, fix them, and they go home the next day. We see patients at their worst, but we don’t get to see the progress. If we’re lucky, we might hear months later that they’ve made a full recovery. It’s an environment where there’s not much instant gratification. </p>



<p>As a nurse, you end up relying on intuition a lot. It’s in the way a patient says something, or just a feeling you get from how they look. It’s not something I think machines can do — and yet, in recent years, we’ve seen more and more artificial intelligence creep into our hospitals. </p>



<p>I get to work at 7am. The hospital I work at looks futuristic from the outside — it’s this high-rise building, all glass and curved lines. It’s won a bunch of architectural awards. The building was financed by Irwin Jacobs, who’s the billionaire owner of Qualcomm, a big San Diego tech company. I think the hospital being owned by a tech billionaire really has a huge amount to do with the way they see technology and the way they dive headfirst into it.</p>



<p>They always want to be on the cutting edge of everything. And so when something new comes out, they’re going to jump right on it. I think that’s part of why they dive headfirst into this AI thing.  </p>



<p>We didn’t call it AI at first. The first thing that happened was these new innovations just crept into our electronic medical record system. They were tools that monitored whether specific steps in patient treatment were being followed. If something was missed or hadn’t been done, the AI would send an alert. It was very primitive, and it was there to stop patients falling through the cracks. </p>



<p>Then in 2018, the hospital bought a new program from Epic, the electronic medical record company. It predicted something called “patient acuity” — basically the workload each patient requires from their nursing care. It’s a really important measurement we have in nursing, to determine how sick a person is and how many resources they will need. At its most basic level, we just classify patients as low, medium or high need. Before the AI came in, we basically filled in this questionnaire — which would ask things like how many meds a patient needed. Are they IV meds? Are they crushed? Do you have a central line versus a peripheral? That sort of thing. </p>



<p>This determines whether a patient was low, medium or high-need. And we’d figure out staffing based on that. If you had lots of high-need patients, you needed more staffing. If you had mostly low-need patients, you could get away with fewer. </p>



<p>We used to answer the questions ourselves and we felt like we had control over it. We felt like we had agency. But one day, it was taken away from us. Instead, they bought this AI-powered program without notifying the unions, nurses, or representatives. They just started using it and sent out an email saying, ‘Hey, we’re using this now.’</p>



<p>The new program used AI to pull from a patient’s notes, from the charts, and then gave them a special score. It was suddenly just running in the background at the hospital.</p>



<p>The problem was, we had no idea where these numbers were coming from. It felt like magic, but not in a good way. It would spit out a score, like 240, but we didn’t know what that meant. There was no clear cutoff for low, medium, or high need, making it functionally useless.</p>



<p>The upshot was, it took away our ability to advocate for patients. We couldn’t point to a score and say, ‘This patient is too sick, I need to focus on them alone,’ because the numbers didn’t help us make that case anymore. They didn’t tell us if a patient was low, medium, or high need. They just gave patients a seemingly random score that nobody understood, on a scale of one to infinity.</p>



<p>We felt the system was designed to take decision-making power away from nurses at the bedside. Deny us the power to have a say in how much staffing we need. </p>



<figure><img decoding="async" width="1800" height="1013" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABwgAAAP1AQMAAABPHikRAAAAA1BMVEVHcEyC+tLSAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAPVJREFUeNrtwTEBAAAAwqD1T20KP6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAICfAX53AAHnsGqkAAAAAElFTkSuQmCC" alt="" data-src="https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-1800x1013.jpg" data-srcset="https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-1800x1013.jpg 1800w, https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-600x338.jpg 600w, https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-768x432.jpg 768w, https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-1536x864.jpg 1536w, https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork-1600x900.jpg 1600w, https://www.codastory.com/wp-content/uploads/2024/10/Untitled_Artwork.jpg 1920w" data-sizes="auto" data-eio-rwidth="1800" data-eio-rheight="1013"/></figure>



<p>That was the first thing.</p>



<p>Then, earlier this year, the hospital got a huge donation from the Jacobs family, and they hired a chief AI officer. When we heard that, alarm bells went off — “they’re going all in on AI,” we said to each other. We found out about this Scribe technology that they were rolling out. It’s called Ambient Documentation. They announced they were going to pilot this program with the physicians at our hospital. </p>



<p>It basically records your encounter with your patient. And then it’s like chat GPT or a large language model — it takes everything and just auto populates a note. Or your “documentation.”</p>



<p>There were obvious concerns with this, and the number one thing that people said was, “Oh my god — it’s like mass surveillance. They’re gonna listen to everything our patients say, everything we do. They’re gonna track us.”</p>



<p>This isn’t the first time they’ve tried to track nurses. My hospital hasn’t done this, but there are hospitals around the US that use tracking tags to monitor how many times you go into a room to make sure you’re meeting these metrics. It’s as if they don’t trust us to actually care for our patients. </p>



<p>We leafletted our colleagues to try to educate them on what “Ambient Documentation” actually means. We demanded to meet with the chief AI officer. He downplayed a lot of it, saying, ‘No, no, no, we hear you. We’re right there with you. We’re starting; it’s just a pilot.’ A lot of us rolled our eyes.</p>



<p>He said they were adopting the program because of physician burnout. It’s true, documentation is one of the most mundane aspects of a physician’s job, and they hate doing it.</p>



<p>The reasoning for bringing in AI tools to monitor patients is always that it will make life easier for us, but in my experience, technology in healthcare rarely makes things better. It usually just speeds up the factory floor, squeezing more out of us, so they can ultimately hire fewer of us. </p>



<p>“Efficiency” is a buzzword in Silicon Valley, but get it out of your mind when it comes to healthcare. When you’re optimizing for efficiency, you’re getting rid of redundancies. But when patients’ lives are at stake, you actually want redundancy. You want extra slack in the system. You want multiple sets of eyes on a patient in a hospital. </p>



<p>When you try to reduce everything down to a machine that one person relies on to carry out decisions, then there’s only one set of eyes on that patient. That may be efficient, but by creating efficiency, you’re also creating a lot of potential points of failure. So, efficiency isn’t as efficient as tech bros think it is.</p>



<p>In an ideal world, they believe technology would take away mundane tasks, allowing us to focus on patient encounters instead of spending our time typing behind a computer. </p>






<p>But who thinks recording everything a patient says and storing it on a third-party server is a good idea? That’s crazy. I’d need assurance that the system is 100 percent secure — though nothing ever is. We’d all love to be freed from documentation requirements and be more present with our patients.</p>



<p>There’s a proper way to do this. AI isn’t inevitable, but it’s come at us fast. One day, ChatGPT was a novelty, and now everything is AI. We’re being bombarded with it.</p>



<p>The other thing that’s burst into our hospitals in recent years is an AI-powered alert system. They’re these alerts that ping us to make sure we’ve done certain things — like checked for sepsis, for example. They’re usually not that helpful, or not timed very well. The goal is to stop patients falling through the cracks — that’s obviously a nightmare scenario in healthcare. But I don’t think the system is working as intended.</p>



<p>I don’t think the goal is really to provide a safety net for everyone — I think it’s actually to speed us up, so we can see more patients, reduce visits down from 15 minutes to 12 minutes to 10. Efficiency, again.</p>



<p>I believe the goal is for these alerts to eventually take over healthcare. To tell us how to do our jobs rather than have hospitals spend money training nurses and have them develop critical thinking skills, experience, and intuition. So we basically just become operators of the machines.</p>



<p>As a seasoned nurse, I’ve learned to recognize patterns and anticipate potential outcomes based on what I see. New nurses don’t have that intuition or forethought yet; developing critical thinking is part of their training. When they experience different situations, they start to understand that instinctively.</p>



<p>In the future, with AI, and alerts pinging them all day reminding them how to do their job, new cohorts of nurses might not develop that same intuition. Critical thinking is being shifted elsewhere — to the machine. I believe the tech leaders envision a world where they can crack the code of human illness and automate everything based on algorithms. They just see us as machines that can be figured out.</p>



<p><em>The artwork for this piece was developed during a Rhode Island School of Design course taught by Marisa Mazria Katz, in collaboration with the <a href="https://artisticinquiry.org/">Center for Artistic Inquiry and </a><a href="https://artisticinquiry.org/" target="_blank" rel="noreferrer noopener">Reporting</a>.</em></p>
</div></div>
  </body>
</html>
