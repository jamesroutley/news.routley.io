<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.quarkslab.com/./nvidia_gpu_kernel_vmalloc_exploit.html">Original</a>
    <h1>A kernel stack use-after-free: Exploiting Nvidia&#39;s GPU Linux drivers</h1>
    
    <div id="readability-page-1" class="page"><div>
                <div>
                    <div>
<div>
    <p><span>Posted</span>
    <span title="2025-10-14T00:00:00+02:00">Tue 14 October 2025</span></p></div>                    </div>
                </div>
                <hr/>
                <p>This article details two bugs discovered in the <a href="https://github.com/NVIDIA/open-gpu-kernel-modules">NVIDIA Linux Open GPU Kernel Modules</a> and demonstrates how they can be exploited. The bugs can be triggered by an attacker controlling a local unprivileged process. Their security implications were confirmed via a proof of concept that achieves kernel read and write primitives.</p>
                <hr/>
                
<p>Back in 2022, NVIDIA started distributing the Linux Open GPU Kernel Modules. Since 2024, using these modules is officially <a href="https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/">&#34;the right move&#34;</a> for both consumer and server hardware. The driver provides multiple kernel modules, the bugs being found in <code>nvidia.ko</code> and <code>nvidia-uvm.ko</code>. They expose ioctls on device files, most of them being accessible to unprivileged users. These ioctls are meant to be used by NVIDIA&#39;s proprietary userland binaries and libraries. However, using the header files provided in the kernel modules repository as a basis, it&#39;s possible to make direct ioctl calls.</p>
<p>While manually probing the attack surface related to memory allocation and management we found two vulnerabilities. They were reported to NVIDIA and the vendor issued fixes in their <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5703">NVIDIA GPU Display Drivers update of October 2025</a> </p>

<p>The <code>UVM_MAP_EXTERNAL_ALLOCATION</code> ioctl of the <code>nvidia-uvm</code> module allows mapping memory allocated from the main <code>nvidia</code> module into the Unified Virtual Memory framework. This includes memory allocations of type <code>NV01_MEMORY_DEVICELESS</code> which are not associated with any device and therefore have the <code>pGpu</code> field of their corresponding <code>MEMORY_DESCRIPTOR</code> structure set to null. The ioctl call leads to an unchecked use of this field, resulting in a kernel null-pointer dereference. An example stack trace is provided below:</p>
<div><pre><span></span><code>// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

osIovaMap+0x11e/0x630 [nvidia]
iovaspaceAcquireMapping_IMPL+0x232/0x470 [nvidia]
memdescMapIommu+0x90/0x300 [nvidia]
dupMemory+0x2d9/0x830 [nvidia]
nvUvmInterfaceDupMemory+0x44/0xe0 [nvidia]
uvm_map_external_allocation_on_gpu+0x298/0x500 [nvidia_uvm]
uvm_api_map_external_allocation+0x5dd/0x860 [nvidia_uvm]
uvm_ioctl+0x1aad/0x1e70 [nvidia_uvm]
uvm_unlocked_ioctl_entry.part.0+0x7b/0xf0 [nvidia_uvm]
uvm_unlocked_ioctl_entry+0x6a/0x90 [nvidia_uvm]
__x64_sys_ioctl+0xa3/0xf0
x64_sys_call+0x11ad/0x25f0
do_syscall_64+0x7e/0x170
</code></pre></div>
<blockquote>
<p>üõ†Ô∏è‚úÖ NVIDIA Fix</p>
<p>A <a href="https://github.com/NVIDIA/open-gpu-kernel-modules/blame/2b436058a616676ec888ef3814d1db6b2220f2eb/src/nvidia/src/kernel/rmapi/nv_gpu_ops.c#L8053">new check</a> was added to the function <code>dupMemory</code> so that operations that require valid GPU contexts are skipped for deviceless memory.</p>
</blockquote>

<p>The <code>threadStateInit()</code> and <code>threadStateFree()</code> functions are used in multiple locations of the <code>open-gpu-kernel-modules</code> codebase. They are always used as a pair to encapsulate specific operations, as seen in the following example:</p>
<div><pre><span></span><code><span>// src/nvidia/src/kernel/rmapi/mapping.c (line 433)</span>

<span>NV_STATUS</span>
<span>rmapiMapWithSecInfoTls</span>
<span>(</span>
<span>    </span><span>RM_API</span><span>            </span><span>*</span><span>pRmApi</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hClient</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hDevice</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hMemCtx</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hMemory</span><span>,</span>
<span>    </span><span>NvU64</span><span>              </span><span>offset</span><span>,</span>
<span>    </span><span>NvU64</span><span>              </span><span>length</span><span>,</span>
<span>    </span><span>NvU32</span><span>              </span><span>flags</span><span>,</span>
<span>    </span><span>NvU64</span><span>             </span><span>*</span><span>pDmaOffset</span><span>,</span>
<span>    </span><span>API_SECURITY_INFO</span><span> </span><span>*</span><span>pSecInfo</span>
<span>)</span>
<span>{</span>
<span>    </span><span>THREAD_STATE_NODE</span><span> </span><span>threadState</span><span>;</span>
<span>    </span><span>NV_STATUS</span><span>         </span><span>status</span><span>;</span>

<span>    </span><span>threadStateInit</span><span>(</span><span>&amp;</span><span>threadState</span><span>,</span><span> </span><span>THREAD_STATE_FLAGS_NONE</span><span>);</span>

<span>    </span><span>status</span><span> </span><span>=</span><span> </span><span>rmapiMapWithSecInfo</span><span>(</span><span>pRmApi</span><span>,</span><span> </span><span>hClient</span><span>,</span><span> </span><span>hDevice</span><span>,</span><span> </span><span>hMemCtx</span><span>,</span><span> </span><span>hMemory</span><span>,</span><span> </span><span>offset</span><span>,</span>
<span>                                 </span><span>length</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>pDmaOffset</span><span>,</span><span> </span><span>pSecInfo</span><span>);</span>

<span>    </span><span>threadStateFree</span><span>(</span><span>&amp;</span><span>threadState</span><span>,</span><span> </span><span>THREAD_STATE_FLAGS_NONE</span><span>);</span>

<span>    </span><span>return</span><span> </span><span>status</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>The <code>threadState</code> structure will be inserted into a global red-black tree (<code>threadStateDatabase.dbRoot</code>) during <code>threadStateInit()</code> and removed during <code>threadStateFree()</code>. The fact that this structure is always stack-allocated is dangerous if a <a href="https://en.wikipedia.org/wiki/Linux_kernel_oops">kernel oops</a> occurs between the two function calls. The oops will lead to the kernel stack for this task being freed on modern Linux kernels, which use virtual stacks allocated through <code>vmalloc</code>. As a result, an invalid pointer to the now freed stack would remain in the global tree structure. This is exactly what happens when bug #1 is triggered: <code>threadStateInit()</code> is called during <code>dupMemory()</code> (in <code>src/nvidia/src/kernel/rmapi/nv_gpu_ops.c</code>) and the null-pointer dereference happens before the call to <code>threadStateFree()</code>. The following stack trace shows the use-after-free being triggered by a call to <code>open</code> on <code>/dev/nvidia0</code> after the oops caused by bug #1:</p>
<div><pre><span></span><code>// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

_mapInsertBase+0x3c/0x320 [nvidia]
threadStateInit+0xd5/0x1b0 [nvidia]
rm_is_device_sequestered+0x28/0x60 [nvidia]
nv_open_device+0x2ef/0x9e0 [nvidia]
nvidia_open+0x22a/0x4b0 [nvidia]
chrdev_open+0xd2/0x250
do_dentry_open+0x218/0x4c0
vfs_open+0x30/0x100
do_open+0x2ba/0x440
path_openat+0x132/0x2c0
do_filp_open+0xc0/0x170
do_sys_openat2+0xb3/0xe0
__x64_sys_openat+0x55/0xa0
x64_sys_call+0x230a/0x25f0
do_syscall_64+0x7e/0x170
</code></pre></div>
<blockquote>
<p>üõ†Ô∏è‚úÖ NVIDIA Fix</p>
<p>The heap based <a href="https://github.com/NVIDIA/open-gpu-kernel-modules/blame/2b436058a616676ec888ef3814d1db6b2220f2eb/src/nvidia/src/kernel/core/thread_state.c#L607"><code>threadStateAlloc</code></a> function was added as a &#34;new UAF-safe API&#34;. However, it seems it is currently used as a replacement for the stack based <code>threadStateInit</code> only in the <code>dupMemory</code> function. This has not been tested, but, other functions still using <code>threadStateInit</code> may continue to be vulnerable to a UAF in the case of a oops.</p>
</blockquote>

<p>Proof of concept exploitation was carried out in the following environment:</p>
<ul>
<li>ThinkPad P14s Gen 3 (Intel) with NVIDIA T550 Laptop GPU</li>
<li>Ubuntu Noble with the following packages:<ul>
<li>linux-image-6.11.0-24-generic (6.11.0-24.24~24.04.1 amd64)</li>
<li>nvidia-driver-570-server-open (570.86.15-0ubuntu0.24.04.4 amd64)</li>
</ul>
</li>
</ul>
<p>Since bug #1 is only used to trigger bug #2, we will focus on the latter. This bug is quite unusual since the UAF address is part of a kernel stack, and as such it belongs to a <code>vmalloc</code> area. Most resources available on UAF exploitation are related to <code>kmalloc</code> as it&#39;s used way more broadly for kernel allocations. The only reference for exploitation related to <code>vmalloc</code> seems to be <a href="https://googleprojectzero.blogspot.com/2020/12/an-ios-hacker-tries-android.html">&#34;An iOS hacker tries Android&#34;</a> from Brandon Azad. However, things changed since then, for example the introduction of <a href="https://lwn.net/Articles/849888/"><code>random_kstack_offset</code></a>. This feature introduces a randomly generated stack offset at each syscall entry, effectively cancelling its mostly deterministic layout. By randomising the position of key stack values, it makes exploitation more difficult.</p>
<h2 id="vmalloc">Vmalloc</h2>
<p><code>vmalloc</code> is a kernel function for allocating virtually contiguous memory with a page granularity. It&#39;s notably used for allocating kernel stacks, as well as other large kernel allocations. On a running system, the allocations can be inspected using <code>/proc/vmallocinfo</code>. This section will discuss the behavior of the allocator, focusing on address space management, without addressing how backing pages are selected. Here is a very simplified representation of an area managed by <code>vmalloc</code>:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-1.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-1.png" width="100%"/>
</a></p>
<p>When a new allocation is made, it&#39;s placed in the first free area that can accommodate its size. Here is an example for a small allocation that takes the first empty slot:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-2.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-2.png" width="100%"/>
</a></p>
<p>Here is an example for a bigger allocation that didn&#39;t fit in the first available slot and so is being allocated further away:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-3.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-3.png" width="100%"/>
</a></p>
<p>When allocations are released, they are not immediately freed but instead marked as unpurged. While they are not used by the kernel anymore, they still live in the <code>vmalloc</code> area and the address cannot be reused directly. Here is an example if we free three of the allocations:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-4.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-4.png" width="100%"/>
</a></p>
<p>To be effectively freed, the unpurged allocations must be purged. This is done when the number of pages contained in the unpurged allocations crosses the value returned by <code>lazy_max_pages</code>, which can easily be computed from userland and is defined as follows:</p>
<div><pre><span></span><code><span>// linux/mm/vmalloc.c</span>

<span>static</span><span> </span><span>unsigned</span><span> </span><span>long</span><span> </span><span>lazy_max_pages</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
<span>    </span><span>unsigned</span><span> </span><span>int</span><span> </span><span>log</span><span>;</span>

<span>    </span><span>log</span><span> </span><span>=</span><span> </span><span>fls</span><span>(</span><span>num_online_cpus</span><span>());</span>

<span>    </span><span>return</span><span> </span><span>log</span><span> </span><span>*</span><span> </span><span>(</span><span>32UL</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>/</span><span> </span><span>PAGE_SIZE</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>After the purge, all released areas are typically ready to be used again for allocations:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-5.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-5.png" width="100%"/>
</a></p>
<p>However, due to <a href="https://lwn.net/Articles/956590/">recent optimisations</a>, the kernel will now add freed allocations back into size-based pools. While they are in these pools, they will be reused in priority for allocations of the same size and the corresponding areas cannot be used for allocations of other sizes. This is a bit annoying in the context of the exploitation of a UAF, but the pools have a &#34;decay&#34; feature where ~25% of their contents will be released during a purge. By triggering a lot of purges instead of one, we can completely empty out the pools and get a similar result to the old behavior.</p>
<h2 id="shaping primitives">Shaping primitives</h2>
<p>To act on the <code>vmalloc</code> area from an unprivileged process we will use the three following primitives.</p>
<h3 id="forking">Forking</h3>
<p>As previously mentioned, kernel stacks are allocated in the <code>vmalloc</code> area. As each userland process has its own dedicated kernel thread stack, forking will lead to a new 0x5000 bytes allocation. This corresponds to four pages for the stack itself and one guard page. Freed kernel stacks are cached to be possibly reused later without the need for new allocations. However, when a stack is released, the operation is usually delayed meaning that if we write very aggressive code like this:</p>
<div><pre><span></span><code><span>while</span><span> </span><span>(</span><span>1</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>fork</span><span>()</span><span> </span><span>==</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>exit</span><span>(</span><span>0</span><span>);</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>
<p>It will lead to the stack cache not being used properly, triggering numerous allocations and deallocations, ultimately leading to a lot of unpurged areas.</p>
<h3 id="video4linux2 buffers">Video4linux2 buffers</h3>
<p>The v4l2 (video4linux2) framework is used for interacting with video devices from userland. It has nothing to do with the NVIDIA driver but it can provide some powerful <code>vmalloc</code> capabilities. Indeed, it has a <code>vmalloc</code> backend for allocating buffers shared with the user (<code>drivers/media/common/videobuf2/videobuf2-vmalloc.c</code>). The use of this backend is not systematic but seems to be common for internal and external USB-based webcams. The target system being a laptop, it&#39;s of course fit with one such device. However, some systems may restrict the use of video devices to the <code>video</code> group.</p>
<p>By opening a video device using the <code>vmalloc</code> backend we get access to the following capabilities:</p>
<ul>
<li>Allocate between 1 and 16 buffers at once</li>
<li>Control the size by asking for different resolutions</li>
<li><code>mmap</code> the buffers in userland while they are also mapped in kernel</li>
</ul>
<p>Only one set of buffers can be allocated per video device. However, the <code>mmap</code> capability is extremely powerful and the fact that we can allocate large buffers is also very useful to generate a lot of unpurged pages to trigger purges.</p>
<h3 id="side effect purge">Side effect purge</h3>
<p>We know that we can trigger purges by allocating and freeing a large number of buffers using either forking or v4l2 buffers. Still, it&#39;s not possible to know precisely when the purge will happen. However, exceeding <code>lazy_max_pages</code> unpurged pages is in fact not the only way to cause a purge. And, by sheer chance, the allocation of a deviceless memory inside the NVIDIA driver (i.e. the type of memory used to trigger bug #1) will cause <code>nv_alloc_contig_pages()</code> to be called with the <code>NV_MEMORY_UNCACHED</code> flag. This will cause an attribute change using the <code>change_page_attr_set_clr()</code> kernel function which will explicitly call <code>vm_unmap_aliases()</code> leading to a purge. This is extremely useful for improving reliability by starting from a known clean state.</p>
<h2 id="reclaiming the uaf_1">Reclaiming the UAF</h2>
<p>The first step in the exploitation is to gain control of the UAF. The goal is to trigger it, provoke a large number of purges so that the affected kernel stack is actually freed and finally allocate a v4l2 buffer that overlaps the UAF address. By memory mapping (via <code>mmap</code>) this buffer, we can get full control over the UAF area. First, we begin by allocating deviceless memory in the NVIDIA driver until there is no unpurged area left and the pools are empty. Then, we can use the forking primitive to fill all the holes in the <code>vmalloc</code> area. This will ensure a clean state where future allocations will be made one right after the other even if they are of different sizes. When forking, we will make most of the processes terminate immediately. However, some of them will be kept alive at regular intervals, to create gaps that are smaller than the v4l2 buffers we will allocate later. This way, even after the unpurged stacks are freed (red allocations in the next figure), any v4l2 buffer allocated will end up in the clean area, while smaller allocations on the system that could disrupt the exploitation will end up in these holes. We will refer to the kept alive stacks as guards.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-6.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-6.png" width="100%"/>
</a></p>
<p>Once we reach the clean state, we do the final setup by:</p>
<ol>
<li>Forking and keeping alive a &#34;beacon&#34; process (used later)</li>
<li>Allocating and freeing a medium-sized v4l2 buffer</li>
<li>Forking a new process and triggering bug #1 with it</li>
<li>Allocating and freeing a medium-sized v4l2 buffer again</li>
<li>Allocating and keeping alive a final guard process</li>
</ol>
<p>These steps are very time sensitive as any other allocation on the system may get in between, most probably leading to a failure of the exploitation. </p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-7.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-7.png" width="100%"/>
</a></p>
<p>After that, it&#39;s possible to monitor the oops happening by waiting for the triggering process to get killed. Once it happened, the driver will be in a reduced state. Indeed, the kernel thread that hit the bug was killed while holding locks, so, most new calls to the drivers will just hang indefinitely. This means we can&#39;t use the side effect purge method and instead have to use large v4l2 buffers. These large allocations will not interfere with the area of the UAF as they will be allocated further away because of the guard stacks.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-8.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-8.png" width="100%"/>
</a></p>
<p>Once we allocated and freed enough of these large allocations so that the pools are empty, we can just allocate a set of two medium-sized v4l2 buffers. These buffers will be backed by only one <code>vmalloc</code> allocation and so they will be one after the other. If everything went right, they should end up being allocated just after the beacon process because of guards. The second buffer will contain the UAF. The reason we used two buffers is because Buffer0 will be used later in the exploitation for data storage.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-9.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-9.png" width="100%"/>
</a></p>
<h2 id="the tree data structure">The tree data structure</h2>
<p>The UAF we now control somewhere in Buffer1 is the node of a <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree">binary Red/Black tree</a>. It serves as the underlying data storage for a map container, the global <code>threadStateDatabase.dbRoot</code>. This map is used to store structures of type <code>THREAD_STATE_NODE</code> in the time frame between <code>threadStateInit()</code> and <code>threadStateFree()</code>. The implementation is intrusive so every <code>THREAD_STATE_NODE</code> structure contains a <code>struct MapNode</code> defined as follows:</p>
<div><pre><span></span><code><span>// src/nvidia/inc/libraries/containers/map.h</span>

<span>struct</span><span> </span><span>MapNode</span><span> </span><span>{</span>
<span>    </span><span>NvU64</span><span>       </span><span>key</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pParent</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pLeft</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pRight</span><span>;</span>
<span>    </span><span>NvBool</span><span>      </span><span>bIsRed</span><span>;</span>
<span>};</span>
</code></pre></div>
<p>This data structure will be our primary focus. The <code>THREAD_STATE_NODE</code> structure also contains interesting fields such as function pointers. However, the <code>threadStateInit()</code> and <code>threadStateFree()</code> functions only perform operations on the structure found in their own stack, so that it&#39; not possible to trick them into calling these function pointers on a node coming from the tree.</p>
<h2 id="revealing kernel memory addresses">Revealing kernel memory addresses</h2>
<p>Even if the driver is in a reduced state, one operation still working is opening a GPU device (e.g. <code>/dev/nvidia0</code>). Fortunately, this triggers a call to <code>rm_is_device_sequestered()</code> which uses the <code>threadStateInit()</code> and <code>threadStateFree()</code> combo. This means a new node will be inserted and removed from the tree each time we open the device file. As the nodes have a very short life span, we can expect the UAF node to be the only one in the tree. As such, the UAF node will be the root and we can expand the tree by creating our own node linked to it. Before doing that, we need to solve two problems:</p>
<ul>
<li>Where is the UAF node located in Buffer1 to be able to modify it </li>
<li>What is the address of Buffer0 so we can create our own nodes inside it and link them together</li>
</ul>
<p>Because of <code>random_kstack_offset</code>, we can&#39;t predict the offset of the UAF node in the stack and so its offset in Buffer1. Fortunately, a zeroed out <code>struct MapNode</code> is a valid node (a black node with no children). Therefore, if the whole Buffer1 is zeroed out, insertions in the tree can happen without any issue. Because the key will also be 0, new nodes will be inserted as the right child of the UAF node. So, when calling <code>open</code> on the GPU device, <code>node.pRight</code> will very briefly be filled with a pointer to a child. To find the offset of the node in Buffer1, a possibility is to call <code>open</code> repeatedly from another process and scan Buffer1 until we find a non-zero value.</p>
<p>Furthermore, because <code>node.pRight</code> will point to the <code>struct MapNode</code> stored in the stack of the process calling <code>open</code>, it&#39;s effectively leaking an address inside its kernel stack. We set up a beacon process for this reason, ensuring its stack is positioned just before Buffer0.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-10.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-10.png" width="100%"/>
</a></p>
<p>Once the beacon stack address is leaked, we can guess an address that should be part of Buffer0. If we set <code>node.pRight</code> of the UAF node to this guessed address, new nodes will be inserted as the right child of the guessed node. By calling <code>open</code> repeatedly again and scanning Buffer0 for a nonzero value, we can find the offset of the guessed node. By subtracting the found offset to the guess address we ultimately find the exact kernel address of Buffer0.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-11.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-11.png" width="100%"/>
</a></p>
<p>The guess address technique may seem superfluous, but it&#39;s essential as we cannot ascertain the exact beacon stack base address from the leak. This ambiguity is due to the <code>random_kstack_offset</code> feature and the possibility that a kernel stack allocation can begin at any page boundary.</p>
<h2 id="a first write primitive">A first write primitive</h2>
<p>Now that we have everything needed to create arbitrary trees, we need to find arrangements that could lead to interesting primitives during either insertion or deletion of a node. These operations always comprise the actual addition or removal of the node in the tree followed by a fixup phase (<code>_mapInsertFixup()</code> or <code>_mapDeleteFixup()</code>). These fixup functions will usually recolor and perform rotations in the tree. They are interesting as they loop up through it allowing us to have at least a bit of control on the execution. The goal is then to trick them into reading or writing at an arbitrary address. To do so we can use part of the rotation code:</p>
<div><pre><span></span><code><span>static</span><span> </span><span>void</span><span> </span><span>_mapRotateRight</span>
<span>(</span>
<span>    </span><span>MapNode</span><span> </span><span>**</span><span>pPRoot</span><span>,</span>
<span>    </span><span>MapNode</span><span> </span><span>*</span><span>x</span>
<span>)</span>
<span>{</span>
<span>    </span><span>// rotate node x to right</span>
<span>    </span><span>MapNode</span><span> </span><span>*</span><span>y</span><span> </span><span>=</span><span> </span><span>x</span><span>-&gt;</span><span>pLeft</span><span>;</span>
<span>    </span><span>// establish x-&gt;pLeft link</span>
<span>    </span><span>x</span><span>-&gt;</span><span>pLeft</span><span> </span><span>=</span><span> </span><span>y</span><span>-&gt;</span><span>pRight</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>y</span><span>-&gt;</span><span>pRight</span><span>)</span>
<span>        </span><span>y</span><span>-&gt;</span><span>pRight</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>x</span><span>;</span><span> </span><span>// &lt;= Here is the only use of y-&gt;pRight</span>

<span>    </span><span>// establish y-&gt;pParent link</span>
<span>    </span><span>y</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>x</span><span>-&gt;</span><span>pParent</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>x</span><span>-&gt;</span><span>pParent</span><span>)</span>
<span>    </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>x</span><span> </span><span>==</span><span> </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pRight</span><span>)</span>
<span>            </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pRight</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>        </span><span>else</span>
<span>            </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pLeft</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>else</span>
<span>        </span><span>(</span><span>*</span><span>pPRoot</span><span>)</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>

<span>    </span><span>// link x and y</span>
<span>    </span><span>y</span><span>-&gt;</span><span>pRight</span><span> </span><span>=</span><span> </span><span>x</span><span>;</span>
<span>    </span><span>x</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>There is a mirror version of this code (<code>_mapRotateLeft</code>) that could also be used, but we will focus on the right one. When executed this function will set <code>pParent</code> in the node pointed to by <code>y-&gt;pRight</code> if it&#39;s not null without ever using it again. Visually the rotation looks like this:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-1.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-1.png" width="55%"/>
</a></p>
<p>If we set <code>y-&gt;pRight</code> to an arbitrary address, we can obtain a constrained arbitrary write primitive because a pointer to <code>x</code> will be written to <code>y-&gt;pRight + offsetof(MapNode, pParent)</code>.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-2.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-2.png" width="55%"/>
</a></p>
<p>Assuming <code>x</code> is one of our nodes in Buffer0, we can consider that we are writing a pointer to a controlled address. The right rotation can be attained from <code>_mapInsertFixup()</code> without the value of <code>y-&gt;pRight</code> being used by building the right tree structure. There might be better primitives available directly from the tree but this one have the advantage of being straightforward and reliable.</p>
<h2 id="selecting a target">Selecting a target</h2>
<p>Next step is to find what exactly to overwrite. Without relying on other bugs, we are only aware of a few addresses allocated by <code>vmalloc</code>. One solution would be to shape the <code>vmalloc</code> area so that an interesting allocation is found close to our beacon and buffers in order to guess its address. That should be doable, but after searching for a bit, I didn&#39;t find any interesting structure. As a matter of fact, <code>vmalloc</code> is not used that much in the kernel and mostly for big buffers because of its page granularity. Also, there are in fact multiple separated <code>vmalloc</code> areas, limiting the possibilities.</p>
<p>Instead, targeting kernel stacks seemed easier as we already know we can leak their addresses. We used this capability before to guess the address of Buffer0. However, we can also leak the address of other interesting values in the stack during the execution of <code>open</code> (the syscall that triggers the insertion in the tree). Indeed, offsets in the stack should be constant for a given kernel and driver binaries, we can just calculate beforehand the distance between the node and a specific value we want to target in the stack. The use of <code>kstack_random_offset</code> changes nothing, as the offset is added before the syscall is executed.</p>
<p>However, in order to use this method combined with the write primitive, the target address needs to be computed in the very small time frame between the insertion of the node and the rotation of the tree that will trigger the write. This is due to the address changing every syscall because of <code>kstack_random_offset</code>. By default, there is not enough time for the userland process to modify the mapped memory in time. However, we can artificially increase the time taken by the tree iteration before the rotation is executed. The <code>_mapInsertFixup()</code> function has a recolor-only path which will perform the following:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-3.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-3.png" width="55%"/>
</a></p>
<p>For our purposes, recoloring has no side effects and can be used to waste time, by building a tree using the pattern found in the previous figure. We can then build a three-staged tree:</p>
<ul>
<li>Setup: Welcomes the new node insertion and make the iteration jump into an alternate part of the tree (i.e. that is not under the root) using a flawed <code>pParent</code> pointer</li>
<li>Dummy: Combination of an arbitrary number of recolor patterns used to waste time (256 patterns were used for the proof of concept)</li>
<li>Write: Perform a write using a rotation, the address will be computed and filled in dynamically by userland</li>
</ul>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-4.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-4.png" width="80%"/>
</a></p>
<p>The node is made to be inserted as a left child using very large keys to facilitate the jump into the dummy phase. This tree allows to reliably write a pointer to controlled data over any chosen value in the kernel thread stack during the handling of the <code>open</code> syscall. The written data will effectively be a pointer to the node labeled <code>END</code>. After the rotation, we are free to write any data at this address.</p>
<h2 id="escalating with stack corruption">Escalating with stack corruption</h2>
<p>Now, we just need to find a good candidate pointer to overwrite. A very interesting one is the <code>file</code> pointer in <code>path_openat()</code>:</p>
<div><pre><span></span><code><span>// fs/namei.c</span>

<span>static</span><span> </span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>path_openat</span><span>(</span><span>struct</span><span> </span><span>nameidata</span><span> </span><span>*</span><span>nd</span><span>,</span>
<span>            </span><span>const</span><span> </span><span>struct</span><span> </span><span>open_flags</span><span> </span><span>*</span><span>op</span><span>,</span><span> </span><span>unsigned</span><span> </span><span>flags</span><span>)</span>
<span>{</span>
<span>    </span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>file</span><span>;</span>
<span>    </span><span>int</span><span> </span><span>error</span><span>;</span>

<span>    </span><span>file</span><span> </span><span>=</span><span> </span><span>alloc_empty_file</span><span>(</span><span>op</span><span>-&gt;</span><span>open_flag</span><span>,</span><span> </span><span>current_cred</span><span>());</span><span> </span><span>// struct file allocation</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>IS_ERR</span><span>(</span><span>file</span><span>))</span>
<span>        </span><span>return</span><span> </span><span>file</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>unlikely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_flags</span><span> </span><span>&amp;</span><span> </span><span>__O_TMPFILE</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>do_tmpfile</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>op</span><span>,</span><span> </span><span>file</span><span>);</span>
<span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>unlikely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_flags</span><span> </span><span>&amp;</span><span> </span><span>O_PATH</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>do_o_path</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>file</span><span>);</span>
<span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span>
<span>        </span><span>const</span><span> </span><span>char</span><span> </span><span>*</span><span>s</span><span> </span><span>=</span><span> </span><span>path_init</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>);</span>
<span>        </span><span>while</span><span> </span><span>(</span><span>!</span><span>(</span><span>error</span><span> </span><span>=</span><span> </span><span>link_path_walk</span><span>(</span><span>s</span><span>,</span><span> </span><span>nd</span><span>))</span><span> </span><span>&amp;&amp;</span>
<span>               </span><span>(</span><span>s</span><span> </span><span>=</span><span> </span><span>open_last_lookups</span><span>(</span><span>nd</span><span>,</span><span> </span><span>file</span><span>,</span><span> </span><span>op</span><span>))</span><span> </span><span>!=</span><span> </span><span>NULL</span><span>)</span>
<span>            </span><span>;</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>!</span><span>error</span><span>)</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>do_open</span><span>(</span><span>nd</span><span>,</span><span> </span><span>file</span><span>,</span><span> </span><span>op</span><span>);</span><span> </span><span>// function that will lead to the write</span>
<span>        </span><span>terminate_walk</span><span>(</span><span>nd</span><span>);</span>
<span>    </span><span>}</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>!</span><span>error</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_mode</span><span> </span><span>&amp;</span><span> </span><span>FMODE_OPENED</span><span>))</span>
<span>            </span><span>return</span><span> </span><span>file</span><span>;</span>
<span>        </span><span>WARN_ON</span><span>(</span><span>1</span><span>);</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>EINVAL</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>fput_close</span><span>(</span><span>file</span><span>);</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>error</span><span> </span><span>==</span><span> </span><span>-</span><span>EOPENSTALE</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>flags</span><span> </span><span>&amp;</span><span> </span><span>LOOKUP_RCU</span><span>)</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>ECHILD</span><span>;</span>
<span>        </span><span>else</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>ESTALE</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>return</span><span> </span><span>ERR_PTR</span><span>(</span><span>error</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>When looking at the compiled binary for the target version, we can see that the <code>file</code> pointer is stored in <code>r12</code>. The <code>do_open()</code> function spills <code>r12</code> on the stack and at the same time will lead to the call that triggers our write. Meaning that we can ultimately overwrite the <code>file</code> pointer to make it point into our memory mapped Buffer0 by precomputing the offset between <code>struct MapNode</code> and the spilled <code>r12</code> register in the stack. This modified file pointer will be returned by <code>path_openat()</code> and associated with a file descriptor in the calling process by <code>fd_install()</code> in <code>do_sys_openat2()</code>. There are a few checks and dereferences that may cause issues, but by creating a fake <code>struct file</code> with somewhat sensible values it&#39;s possible to overcome them easily.</p>
<p>It&#39;s to be noted that the <code>file</code> structure is defined with the <code>__randomize_layout</code> macro. This will lead to the fields being out of order and that we have to find the offsets for the specific target kernel. Fortunately, in our case, these can be easily extracted from the Ubuntu debug packages.</p>
<h2 id="leaking kaslr">Leaking KASLR</h2>
<p>The control over a <code>struct file</code> is extremely powerful. This structure notably contains several function pointers due to the Virtual File System layer. However, our last barrier to a full exploitation is KASLR (Kernel Address Space Layout Randomization). To break it, we can leverage some syscalls that check the type of a file by comparing the <code>f_op</code> pointer to the expected <code>struct file_operations</code>. For example, <code>recvfrom</code> uses <code>sock_from_file()</code> to get access to private data specific to sockets and checks the file type using the <code>f_op</code> pointer:</p>
<div><pre><span></span><code><span>// linux/net/socket.c</span>

<span>struct</span><span> </span><span>socket</span><span> </span><span>*</span><span>sock_from_file</span><span>(</span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>file</span><span>)</span>
<span>{</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_op</span><span> </span><span>==</span><span> </span><span>&amp;</span><span>socket_file_ops</span><span>))</span>
<span>        </span><span>return</span><span> </span><span>file</span><span>-&gt;</span><span>private_data</span><span>;</span><span>  </span><span>/* set in sock_alloc_file */</span>

<span>    </span><span>return</span><span> </span><span>NULL</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>If the pointers don&#39;t match and <code>sock_from_file()</code> returns null, <code>recvfrom</code> will simply return <code>-ENOTSOCK</code>. So, we can call this syscall repeatedly on the file descriptor linked with our controlled <code>struct file</code>, starting with <code>f_op</code> set to the static address of <code>socket_file_ops</code> and then incrementing it to test all the possible slided values. KASLR is leaked when the syscall returns something other than <code>-ENOTSOCK</code>. This is a somewhat fast process due to KASLR entropy only being 9 bits.</p>
<h2 id="wrapping up">Wrapping up</h2>
<p>After that, we can just create our own file operations table. I decided to use the <code>llseek</code> handler to perform arbitrary functions calls in the kernel. It&#39;s defined as follows:</p>
<div><pre><span></span><code><span>loff_t</span><span> </span><span>(</span><span>*</span><span>llseek</span><span>)</span><span> </span><span>(</span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span> </span><span>file</span><span>,</span><span> </span><span>loff_t</span><span> </span><span>offset</span><span>,</span><span> </span><span>int</span><span> </span><span>whence</span><span>);</span>
</code></pre></div>
<p>It&#39;s interesting because the syscall handler does not perform any check on the file before calling the handler. Also, we have control and access to all the parameters and the return value directly from userland. The limitations are as follows:</p>
<ul>
<li>The <code>whence</code> parameter should be less than five</li>
<li>The first parameter is a pointer to our controlled <code>struct file</code> meaning we must input or output arbitrary data from the start of the structure. That&#39;s not a problem on the target version because all the fields in the start are unused, but it could be if we are very unlucky with the randomized order of the fields.</li>
</ul>
<p>By setting the handler to point to selected kernel functions and then calling the <code>llseek</code> syscall, we can build a basic set of primitives:</p>
<ul>
<li>Kernel symbolication with <code>unsigned long kallsyms_lookup_name(const char *name)</code></li>
<li>Kernel arbitrary read with <code>void *memcpy(void *dest, const void *src, size_t count)</code></li>
<li>Kernel arbitrary write with <code>int debugfs_u64_get(void *data, u64 *val)</code></li>
</ul>
<p>For testing them, we can escalate the privileges of our userland process. We just need to symbolicate <code>init_task</code> and iterate the tasks until we find the one corresponding to our process. Then, we can overwrite the creds to become root and open a shell. Below is the full proof of concept running in real time:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/demo.gif">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/demo.gif" width="75%"/>
</a></p>

<p>To conclude, a couple of key points to consider. First, the exploit is sensitive to system activity, particularly forking and calls to the NVIDIA driver during specific time frames. This poses a challenge on systems under constant heavy load where the exploitation will most likely fail.</p>
<p>Second, as previously mentioned the kernel oops triggered by bug #1 causes multiple locks to be held, rendering most of the NVIDIA driver unusable. It should be possible to manually unlock the driver using the kernel read and write primitives, but this has not been tested.</p>
<p>The complete proof-of-concept exploit described in this blog post is available <a href="https://blog.quarkslab.com/resources/2025-10-14_oops/nvidia-open-gpu-cve-2025-23330-poc.tgz">here</a></p>
<h2 id="disclosure timeline">Disclosure timeline</h2>
<p>Below we include a timeline of all the relevant events during the coordinated vulnerability disclosure process with the intent of providing transparency to the whole process and our actions.</p>
<ul>
<li><strong>2025-06-18</strong> Quarkslab reported the vulnerabilities to NVIDIA PSIRT.</li>
<li><strong>2025-06-18</strong> NVIDIA acknowledged the report and asked if we planned to disclose the bugs.</li>
<li><strong>2025-06-25</strong> Quarkslab replied that we planned to publish a blog post or conference talk but there was no specific plan and it would be determined along the coordination process.</li>
<li><strong>2025-06-26</strong> NVIDIA acknowledged last email and promised to keep us updated as the process evolves.</li>
<li><strong>2025-07-14</strong> NVIDIA indicated it couldnt reproduce the bugs.</li>
<li><strong>2025-07-21</strong> Quarkslab sent a reply to NVIDIA noting that the report had specific comments about triggering the bugs and exploitability.</li>
<li><strong>2025-07-22</strong> NVIDIA acknowledged the last communication and said it was passed to the dev team.</li>
<li><strong>2025-07-24</strong> Quarkslab sent further details about how to reproduce the bugs and asked what runtime environment was NVIDIA using to try to repro them.</li>
<li><strong>2025-07-28</strong> Quarkslab re-sent the prior email with a minimized PoC.</li>
<li><strong>2025-08-08</strong> NVIDIA provided information about their runtime environment, the internal case numbers, and said they will implement the fixes by mid-january 2026, and asked if Quarkslab could delay disclosure until then.</li>
<li><strong>2025-08-11</strong> NVIDIA reiterated the request to postpone disclosure until mid-January 2026.</li>
<li><strong>2025-08-12</strong> Quarkslab replied that the bugs were first reported in June 18th and mid-January was well past the standard 90 day normally agreed for coordinated disclosure and that we did not see a rationale for postponing publication by, at a minimum, 3 months. Therefore Quarkslab continued with the publication deadline set to September 23rd 2025 and offered to extend the deadline an additional 30 days provided NVIDIA gave us some insights about the full scope of affected products and if the fixes are to be released as a stand alone security fix, as opposed to rolled into a version bump that includes other code changes.</li>
<li><strong>2025-08-12</strong> NVIDIA acknowledged our email and said it will communicate the deadline to the product team.</li>
<li><strong>2025-08-14</strong> NVIDIA provided an update and requested the 30-day extension offered. Indicated the fix for the null pointer dereferrence bug, which would make the UAF not reachable, was under review. The team was determining whether the fix would be a standalone update or included in a regular version update release. NVIDIA said it would be happy to share the final disclosure security bulletin language before releasing it to partners and the public.</li>
<li><strong>2025-08-18</strong> NVIDIA requested confirmation of the 30 day extension to the disclosure deadline.</li>
<li><strong>2025-08-18</strong> Quarkslab agreed to extend the disclosure deadline to October 23rd 2025.</li>
<li><strong>2025-10-09</strong> NVIDIA published <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5703">Security Bulletin: NVIDIA GPU Display Drivers - October 2025</a> crediting CVE-2025-2330 to Quarkslab.</li>
<li><strong>2025-10-09</strong> Quarkslab asked NVIDIA when they planned to fix the UAF bug or if it was the fix for CVE-2025-23280 in the October update, which was not credited to anyone.</li>
<li><strong>2025-10-09</strong> NVIDIA apologized for not having notified Quarkslab of the security bulletin release and said it would correct the attribution of CVE-2025-23280, which was indeed the Kernel UAF bug.</li>
<li><strong>2025-10-14</strong> This blog post is published.</li>
</ul>
            </div><p>If you would like to learn more about our security audits and explore how we can help you, <a href="https://content.quarkslab.com/talk-to-our-experts-blog">get in touch with us</a>!</p></div>
  </body>
</html>
