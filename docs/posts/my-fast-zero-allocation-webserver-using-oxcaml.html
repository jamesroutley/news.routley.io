<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://anil.recoil.org/notes/oxcaml-httpz">Original</a>
    <h1>My fast zero-allocation webserver using OxCaml</h1>
    
    <div id="readability-page-1" class="page"><div><h2><a href="https://hamy.xyz/notes/oxcaml-httpz">My (very) fast zero-allocation webserver using OxCaml</a> <span> / Feb 2026</span><span> / <a href="https://doi.org/10.59350/9c6bz-kb659">DOI</a></span></h2><p>Since helping with the <side-note type="note" data-slug="icfp25-oxcaml" data-title="Holding an OxCaml tutorial at ICFP/SPLASH 2025" data-year="2025" data-month="10" data-day="6" data-words="1485" data-link="/notes/icfp25-oxcaml" data-image="/images/oxcaml-codespace.640.webp">OxCaml tutorial</side-note> last year at ICFP,
I&#39;ve been chomping at the bit to use it for real in our research infrastructure
for <side-note type="project" data-slug="plancomp" data-title="Planetary Computing" data-start="2022" data-ideas="The efforts here center around constructing system interfaces for hermetic large-scale data processing, with careful support for versioning and spotting sources of non-determinism that lead to non-reproducibility." data-link="/projects/plancomp">planetary computing</side-note> to manage the petabytes of <side-note type="note" data-slug="geotessera-python" data-title="GeoTessera Python library released for geospatial embeddings" data-year="2025" data-month="8" data-day="31" data-words="1044" data-link="/notes/geotessera-python" data-image="/images/tessera-f1.640.webp">TESSERA embeddings</side-note> we&#39;ve been generating.</p>
<p>The reason for my eagerness is that OxCaml has a number of language extensions
that give giant leaps in performance for systems-oriented programs, while
retaining the familiar OCaml functional style of programming. And unlike Rust,
there&#39;s a garbage collector available for &#39;normal&#39; code. I am also deeply sick
and tired of maintaining large Python scripts recently, and crave the modularity and
type safety of OCaml.</p>
<p>The traditional way I learn a new technology is by replacing my <side-note type="note" data-slug="bushel-lives" data-title="Arise Bushel, my sixth generation oxidised website" data-year="2025" data-month="1" data-day="29" data-words="848" data-link="/notes/bushel-lives">website infrastructure</side-note> with the latest hotness. I switched my live site
over to building with OxCaml last year, but never got around to deeply
integrating the new extensions. Therefore, what I&#39;ll talk about next is a new
webserver I&#39;ve been building called
<strong><a href="https://github.com/avsm/oxmono/tree/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz">httpz</a></strong>
which goes all in on performance in OCaml!</p>
<p><em>(Many thanks to <side-note type="contact" data-slug="cc" data-handle="cc" data-name="Chris Casinghino" data-link="https://tyconmismatch.com/code.html" data-url="https://tyconmismatch.com/code.html">Chris Casinghino</side-note>, <side-note type="contact" data-slug="mslater" data-handle="mslater" data-name="Max Slater" data-link="https://thenumb.at/" data-url="https://thenumb.at/">Max Slater</side-note>, <side-note type="contact" data-slug="reisenberg" data-handle="reisenberg" data-name="Richard Eisenberg" data-link="https://richarde.dev/" data-image="/images/faces/reisenberg.webp" data-url="https://richarde.dev/">Richard Eisenberg</side-note>, <side-note type="contact" data-slug="yminsky" data-handle="yminsky" data-name="Yaron Minsky" data-link="https://github.com/yminsky" data-image="/images/faces/yminsky.webp" data-github="yminsky">Yaron Minsky</side-note>, <side-note type="contact" data-slug="mshinwell" data-handle="mshinwell" data-name="Mark Shinwell" data-link="https://github.com/mshinwell" data-image="/images/faces/mshinwell.webp" data-github="mshinwell">Mark Shinwell</side-note>, <side-note type="contact" data-slug="dra27" data-handle="dra27" data-name="David Allsopp" data-link="https://github.com/dra27" data-image="/images/faces/dra27.webp" data-github="dra27">David Allsopp</side-note> and the rest of the Jane Street
tools and compilers team for answering many questions while I got started on all this!)</em></p>
<h2>Why Zero Allocation for HTTP/1.1?</h2>
<p><a href="https://github.com/avsm/oxmono/tree/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz">httpz</a> is a high-performance HTTP/1.1 parser that aims to have no major heap allocation, and very minimal minor heap allocation, by using OxCaml&#39;s <a href="https://oxcaml.org/documentation/unboxed-types/01-intro/">unboxed types</a> and <a href="https://oxcaml.org/documentation/stack-allocation/intro/">local allocations</a>.</p>
<p>Why is this useful?  It means that the entire lifetime of an HTTP connection
can be handled in the callstack alone, so freeing up a connection is just a
matter of returning from the function that handles it. In the steady state, a
webserver would have almost no garbage collector activity. When combined with
<side-note type="paper" data-slug="2021-pldi-retroeff" data-title="Retrofitting effect handlers onto OCaml" data-authors="Sivaramakrishnan et al" data-year="2021" data-link="/papers/2021-pldi-retroeff" data-doi="10.1145/3453483.3454039">direct style effects</side-note>, it can also be written without
looking like callback soup!</p>
<p>I decided to specialise this library for HTTP/1.1 for now, and so settled on
the input being a simple 32KB bytes value. This represents an HTTP request with
the header portion (HTTP body handling is relatively straightforward for POST
requests, and not covered in this post).</p>
<p>Given an input buffer like this, what can we do with OxCaml <em>vs</em> vanilla OCaml
to make this go fast?</p>
<h3>Unboxed Types and Records</h3>
<p>The first port of call is to figure out the core types we&#39;re going to use for our
parser. If you need to get familiar with OCaml&#39;s upstream memory representation then
<a href="https://dev.realworldocaml.org/runtime-memory-layout.html">head over to Real World OCaml</a>.</p>
<p>In my usual OCaml code, I use libraries like <a href="https://github.com/mirage/ocaml-cstruct">cstruct</a>
that I <side-note type="project" data-slug="unikernels" data-title="Unikernels" data-start="2010" data-ideas="Developing unikernels means turning every part of the software stack into a library rather than a wrapper, and so an interest in software architectures and functional programming comes in useful here." data-link="/projects/unikernels" data-finish="2019">originally</side-note> wrote back in 2012 to manage non-copying views into bytes buffers. Cstruct
defines a record that has four words (the box, and three words for the fields):</p>
<pre><code>type buffer = (char, Bigarray.int8_unsigned_elt, Bigarray.c_layout) Bigarray.Array1.t
type Cstruct.t = private {
  buffer: buffer;
  off   : int;
  len   : int;
}
</code></pre>
<p>The idea is to use the record to get narrow views into a larger buffer, and that these
small views can just live on the minor heap of the runtime which is fast to collect.
OxCaml advances this by providing unboxed versions of <a href="https://oxcaml.org/documentation/miscellaneous-extensions/small-numbers/">small
numbers</a>
that live in registers or on the stack, via a new syntax <code>int16#</code>.</p>
<p>Instead of Bigarrays, we&#39;re now going to switch to use <code>bytes</code> instead, but the
basic idea is the same.  Since httpz&#39;s buffer is a max of 32KB, 16-bit integers
also suffice for all positions and lengths!</p>
<pre><code>type Httpz.t = #{ off : int16# ; len : int16# }
</code></pre>
<p>There are actually two new features here: the first is that records can be unboxed with the <code>#{}</code>
syntax, and the contents themselves are of a smaller width.  Let&#39;s have a closer look
at the difference between the Cstruct boxed version and this new OxCaml one:</p>
<h4>Inspect unboxing in utop</h4>
<p>My first port-of-call is usually to use utop interactively to poke around
using the <code>Obj</code> module.  This isn&#39;t quite so easy in OxCaml since the unboxed
records use a special <a href="https://oxcaml.org/documentation/unboxed-types/01-intro/">layout</a>:</p>
<pre><code># type t = #{ off : int16# ; len : int16# };;
type t = #{ off : int16#; len : int16#; }

# let x = #{ off=#1S; len=#2S };;
val x : t = #{off = &lt;abstr&gt;; len = &lt;abstr&gt;}

# Obj.repr x;;
Error: This expression has type t but an expression was expected of type
         (&#39;a : value)
       The layout of t is bits16 &amp; bits16
         because of the definition of t at line 1, characters 0-41.
       But the layout of t must be a sublayout of value.

</code></pre>
<p>That failed, but it did reveal that we have this intriguing int16 pair layout
instead of the normal OCaml flat value representation!  Let&#39;s use the compiler
to figure this out...</p>
<h4>Inspect unboxing in lambda</h4>
<p>I next built a small
test program and inspected the <a href="https://dev.realworldocaml.org/compiler-backend.html">lambda intermediate language</a> from the compiler. To avoid dependencies, I just bound the raw compiler internals directly by checking out the oxcaml source code.</p>
<pre><code>external add_int16 : int16# -&gt; int16# -&gt; int16# = &#34;%int16#_add&#34;
external int16_to_int : int16# -&gt; int = &#34;%int_of_int16#&#34;

type span = #{ off : int16#; len : int16# }

let[@inline never] add_spans (x : span) (y : span) : span =
  #{ off = add_int16 x.#off y.#off; len = add_int16 x.#len y.#len }

let () =
  let x = Sys.opaque_identity #{ off = #1S; len = #2S } in
  let y = Sys.opaque_identity #{ off = #100S; len = #200S } in
  let z = add_spans x y in
  Printf.printf &#34;off=%d len=%d\n&#34; (int16_to_int z.#off) (int16_to_int z.#len)
</code></pre>
<p>This introduces enough compiler optimisation barriers such that
the addition is not optimised away at compile time. We can compile this
with <code>ocaml -dlambda src.ml</code> and see the intermediate form after type checking:</p>
<pre><code>(let
  (add_spans/290 =
     (function {nlocal = 0} x/292[#(int16, int16)] y/293[#(int16, int16)]
       never_inline : #(int16, int16)
       (funct-body add_spans ./x.ml(6)&lt;ghost&gt;:196-294
         (before add_spans ./x.ml(7):229-294
           (make_unboxed_product #(int16, int16)
             (%int16#_add (unboxed_product_field 0 #(int16, int16) x/292)
               (unboxed_product_field 0 #(int16, int16) y/293))
             (%int16#_add (unboxed_product_field 1 #(int16, int16) x/292)
               (unboxed_product_field 1 #(int16, int16) y/293)))))))
</code></pre>
<p>You can see the unboxing propagating nicely here through the intermediate code!</p>
<h4>Inspect unboxing in native code</h4>
<p>The next step is to verify what this looks like when compiled as optimised native
code. I used <code>ocamlopt -O3 -S</code> on my arm64 machine which emits the assembly code
after all the compiler passes, and found:</p>
<pre><code>In the entry point:
  orr   x0, xzr, #1      ; x.#off = 1
  orr   x1, xzr, #2      ; x.#len = 2
  movz  x2, #100, lsl #0 ; y.#off = 100
  movz  x3, #200, lsl #0 ; y.#len = 200
  bl    _camlX__add_spans_0_1_code

_camlX__add_spans_0_1_code:
  add   x1, x1, x3       ; len: x.#len + y.#len
  sbfm  x1, x1, #0, #15  ; sign-extend to 16 bits (int16# semantics)
  add   x0, x0, x2       ; off: x.#off + y.#off
  sbfm  x0, x0, #0, #15  ; sign-extend to 16 bits
  ret

</code></pre>
<p>We can see from the assembly that there&#39;s no boxing, and no heap allocations,
and the <a href="https://finkmartin.com/aarch64-morello/sbfm.html">sbfm instruction</a> maintains
the 16-bit semantics via sign extension.</p>
<p>Let&#39;s double check that the normal boxed OCaml does do more work and that isn&#39;t
just the flambda2 compiler doing its magic.  Here&#39;s a boxed version of the benchmark using
plain OCaml:</p>
<pre><code>type span = { off : int; len : int }

let[@inline never] add_spans (x : span) (y : span) : span =
  { off = x.off + y.off; len = x.len + y.len }

let () =
  let x = Sys.opaque_identity { off = 1; len = 2 } in
  let y = Sys.opaque_identity { off = 100; len = 200 } in
  let z = add_spans x y in
  Printf.printf &#34;off=%d len=%d\n&#34; z.off z.len
</code></pre>
<p>Compiling this boxed version with <code>ocamlopt -O3 -S</code> and looking at the assembly shows
much more minor heap activity:</p>
<pre><code>_camlY__add_spans_0_1_code:
      sub   sp, sp, #16
      str   x30, [sp, #8]
      mov   x2, x0
      ldr   x16, [x28, #0]        ; load young_limit
      sub   x27, x27, #24         ; bump allocator: reserve 24 bytes (3 words)
      cmp   x27, x16              ; check if GC needed
      b.cc  L114                  ; branch to GC if out of space
  L113:
      add   x0, x27, #8           ; x0 = pointer to new block
      orr   x3, xzr, #2048        ; header word (tag 0, size 2)
      str   x3, [x0, #-8]         ; write header
      ldr   x3, [x1, #0]          ; load y.off from heap
      ldr   x4, [x2, #0]          ; load x.off from heap
      add   x3, x4, x3            ; add them
      sub   x3, x3, #1            ; adjust for tagged int
      str   x3, [x0, #0]          ; store result.off to heap
      ldr   x1, [x1, #8]          ; load y.len from heap
      ldr   x2, [x2, #8]          ; load x.len from heap
      add   x1, x2, x1            ; add them
      sub   x1, x1, #1            ; adjust for tagged int
      str   x1, [x0, #8]          ; store result.len to heap
      ...
      ret
  L114:
      bl    _caml_call_gc         ; GC call if needed
</code></pre>
<p>The OCaml minor heap is really fast, but it&#39;s nowhere near as
fast as just passing values around in registers and doing
direct operations, which the unboxed version lets us do!</p>
<p>My benchmark above used direct external calls to compiler primitives,
but OxCaml exposes normal modules for all these special types so
we can just open them and gain access to the usual integer operations:</p>
<pre><code>module I16 = Stdlib_stable.Int16_u

let[@inline always] i16 x = I16.of_int x
let[@inline always] to_int x = I16.to_int x

let pos : int16# = i16 0
let next : int16# = I16.add pos #1S
</code></pre>
<h3>Unboxed characters</h3>
<p>There&#39;s more than just integer operations in OxCaml. Hot off the press in the
past few weeks have been unboxed character operations as well, so we don&#39;t need
to use an OCaml int (this is unboxed as well, but I presume the compiler can
optimise and pack 8-bit operations much more effectively if it knows that we&#39;re
operating on a char instead of a full word).</p>
<p>The httpz parser tries to use these, but the support for untagged ints <a href="https://github.com/oxcaml/oxcaml/pull/4779">isn&#39;t fully
complete yet</a> (thanks <side-note type="contact" data-slug="mslater" data-handle="mslater" data-name="Max Slater" data-link="https://thenumb.at/" data-url="https://thenumb.at/">Max Slater</side-note> for
the <a href="https://bsky.app/profile/thenumb.at/post/3mdevcomw2k2d">pointer</a>).</p>
<p>HTTP <a href="https://github.com/avsm/oxmono/blob/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz/core/date.ml#L107-L137">date timestamps</a> use unboxed floats as well.</p>
<h3>Returning unboxed records and tuples</h3>
<p>Once we&#39;ve declared these unboxed records, they&#39;re fully nestable within other unboxed records.
For example, <a href="https://github.com/avsm/oxmono/blob/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz/core/req.ml#L12-L21">HTTP requests with multiple fields</a> remain unboxed:</p>
<pre><code>type request =
  #{ meth : method_
   ; target : span           (* Nested unboxed record *)
   ; version : version
   ; body_off : int16#
   ; content_length : int64#
   ; is_chunked : bool
   ; keep_alive : bool
   ; expect_continue: bool
   }
</code></pre>
<p>Functions can therefore naturally return multiple values without allocation by using unboxed tuples in the return value of a function:</p>
<pre><code>let take_while predicate buf ~(pos : int16#) ~(len : int16#)
    : #(span * int16#) =
  let start = pos in
  let mutable p = pos in
  while (* ... *) do p &lt;- I16.add p #1S done;
  #(#{ off = start; len = I16.sub p start }, p)

let #(result_span, new_pos) = take_while is_token buf ~pos ~len
</code></pre>
<p>Vanilla OCaml did some unboxing of this use of tuples, but not with
records (which would land up on the minor heap).  With this OxCaml code,
it&#39;s all just passed directly on the stack through function call traces.</p>
<h3>Local allocations and exclaves</h3>
<p>We can then also mark parameters to demand that they won&#39;t escape a function, enabling stack
allocation more explicitly:</p>
<pre><code>(* Buffer is borrowed, won&#39;t be stored anywhere *)
let[@inline] equal (local_ buf) (sp : span) (s : string) : bool =
  let sp_len = I16.to_int sp.#len in
  if sp_len &lt;&gt; String.length s then false
  else Bigstring.memcmp_string buf ~pos:(I16.to_int sp.#off) s = 0
</code></pre>
<p>If a function needs to return a local value, then it uses a new <code>exclave_</code> keyword. For example, in the <a href="https://github.com/avsm/oxmono/blob/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz/core/header.mli">HTTP request parsing</a> we look up a stack allocated list of headers:</p>
<pre><code>val find : t list @ local -&gt; Name.t -&gt; t option @ local

let rec find_string (buf : bytes) (headers : t list @ local) name = exclave_
  match headers with
  | [] -&gt; None
  | hdr :: rest -&gt;
    let matches =
      match hdr.name with
      | Name.Other -&gt; Span.equal_caseless buf hdr.name_span name
      | known -&gt;
        let canonical = Name.lowercase known in
        String.( = ) (String.lowercase name) canonical
    in
    if matches then Some hdr else find_string buf rest name
;;
</code></pre>
<p>Notice that it&#39;s a recursive function as well, so this is a fairly natural way
to write something that remains heap allocated.  You can learn more about this
from <side-note type="contact" data-slug="gleroy" data-handle="gleroy" data-name="Gavin Gray" data-link="https://gavinleroy.com/" data-url="https://gavinleroy.com/">Gavin Gray</side-note>&#39;s <a href="https://gavinleroy.com/oxcaml-tutorial-icfp25/">OxCaml tutorial slides</a>.</p>
<h2>Mutable Local Variables with &#34;let mutable&#34;</h2>
<p>A nice quality of life improvement is that OxCaml allows stack-allocated
mutable variables in loops, eliminating the need to allocate <code>ref</code> values. This
allows parsing code to have local mutability:</p>
<pre><code>let parse_int64 (local_ buf) (sp : span) : int64# =
  let mutable acc : int64# = #0L in
  let mutable i = 0 in
  let mutable valid = true in
  while valid &amp;&amp; i &lt; I16.to_int sp.#len do
    let c = Bytes.get buf (I16.to_int sp.#off + i) in
    match c with
    | &#39;0&#39; .. &#39;9&#39; -&gt;
      acc &lt;- I64.add (I64.mul acc #10L) (I64.of_int (Char.code c - 48));
      i &lt;- i + 1
    | _ -&gt; valid &lt;- false
  done;
  acc
</code></pre>
<p>Whereas in conventional OCaml there might be a minor heap allocation for the
reference:</p>
<pre><code>let parse_int64 buf sp =
  let acc = ref 0L in           (* Heap-allocated ref *)
  let i = ref 0 in              (* Heap-allocated ref *)
  let valid = ref true in       (* Heap-allocated ref *)
  while !valid &amp;&amp; !i &lt; sp.len do
    let c = Bytes.get buf (sp.off + !i) in
    match c with
    | &#39;0&#39; .. &#39;9&#39; -&gt;
      acc := Int64.add (Int64.mul !acc 10L) (Int64.of_int (Char.code c - 48));
      i := !i + 1
    | _ -&gt; valid := false
  done;
  !acc
</code></pre>
<h3>Putting the parser together</h3>
<p>The toplevel <a href="https://github.com/avsm/oxmono/blob/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz/core/httpz.mli#L182">Httpz.parse function</a> has a pretty simple signature from a user&#39;s perspective:</p>
<pre><code>val parse : bytes -&gt; len:int16# -&gt; limits:limits -&gt;
  #(Buf_read.status * Req.t * Header.t list) @ local
</code></pre>
<p>This function receives some a bytebuffer and resource limits and returns an unboxed local tuple of the connection status, parsed (unboxed) request and a stack-local list of header spans that represent the offsets within the input buffer of what was passed.</p>
<p>I should probably make the input buffer local too; one nice aspect of OxCaml is how easy it is to incrementally add type and kind annotations and lean on the compiler type inference to help guide where to fixup callsites.</p>
<h3>Caveats and limitations</h3>
<p>There are lots and lots of other new features in OxCaml which I&#39;ve started integrating, but require careful planning of layouts.
For example, I wanted to use <a href="https://oxcaml.org/documentation/unboxed-types/02-or-null/">or_null</a> to have a non-allocating
version of option, but you often end up with long compiler errors about value inference failures, so I ended up just allocating
a local type instead. Something to investigate more in the future as I get familiar with OxCaml.</p>
<p>I also ran into issues using mutable fields in unboxed records and found this is <a href="https://oxcaml.org/documentation/unboxed-types/01-intro/">documented</a>:</p>
<blockquote>
<p>We plan to allow mutating unboxed records within boxed records (the design
will differ from boxed record mutability, as unboxed types donâ€™t have the
same notion of identity).</p>
</blockquote>
<p>It&#39;s also difficult right now to strip away the OxCaml extensions and go back
to normal OCaml syntax. <side-note type="contact" data-slug="cc" data-handle="cc" data-name="Chris Casinghino" data-link="https://tyconmismatch.com/code.html" data-url="https://tyconmismatch.com/code.html">Chris Casinghino</side-note> pointed me to the OxCaml ocamlformat fork which
has a <code>--erase-jane-syntax</code>, but it requires some build system work to
integrate and seems to lag a little behind the new features (like unboxed small
literals). For now, I&#39;ve decided to just focus on using OxCaml exclusively and
see how it goes for a while.</p>
<p>Finally, the tooling is still a fluid story. <side-note type="contact" data-slug="artw" data-handle="artw" data-name="Arthur Wendling" data-link="https://github.com/art-w" data-github="art-w">Arthur Wendling</side-note> and <side-note type="contact" data-slug="jonludlam" data-handle="jonludlam" data-name="Jon Ludlam" data-link="https://jon.recoil.org" data-image="/images/faces/jonludlam.webp" data-github="jonludlam" data-url="https://jon.recoil.org">Jon Ludlam</side-note> are making
fast progress on getting <a href="https://github.com/ocaml/odoc/pull/1399">odoc working</a> in the
mainline tool, but it&#39;s not quite there today.</p>
<h3>Claude skills for OxCaml</h3>
<p>While I built small scale examples to test out the architecture, I leaned heavily
on Claude code to build out the majority of the parser so I could rapidly experiment.
To do this, I synthesised a set of <a href="https://github.com/avsm/ocaml-claude-marketplace/tree/main/plugins/ocaml-dev/skills/oxcaml">OxCaml specific Claude skills</a>
in my <side-note type="note" data-slug="aoah-2025-25" data-title="AoAH Day 25: Claude OCaml Marketplace for all your festive coding needs" data-year="2025" data-month="12" data-day="25" data-words="283" data-link="/notes/aoah-2025-25" data-image="/images/aoah-plugin-ss-1.640.webp">Claude OCaml marketplace</side-note> which you can add to your own projects as well. Browsing the skills is a pretty nice way of getting familiar with the different features.</p>
<p>I generated those skills via a combination of summarising the OxCaml source trees and cribbing from the <side-note type="note" data-slug="icfp25-oxcaml" data-title="Holding an OxCaml tutorial at ICFP/SPLASH 2025" data-year="2025" data-month="10" data-day="6" data-words="1485" data-link="/notes/icfp25-oxcaml" data-image="/images/oxcaml-codespace.640.webp">ICFP 2025 tutorial</side-note>, and then getting CC to verify that the example code actually compiled. All automated and very easy to refresh every time a new compiler drops from Jane Street.</p>
<figure><img src="https://hamy.xyz/images/claude-oxlocal-1.webp" alt="The OxCaml compiler errors are really descriptive in the latest drop, which greatly helps coding agents figure out the new types" title="The OxCaml compiler errors are really descriptive in the latest drop, which greatly helps coding agents figure out the new types" loading="lazy" srcset="/images/claude-oxlocal-1.1024.webp 1024w,/images/claude-oxlocal-1.1280.webp 1280w,/images/claude-oxlocal-1.1440.webp 1440w,/images/claude-oxlocal-1.1600.webp 1600w,/images/claude-oxlocal-1.1920.webp 1920w,/images/claude-oxlocal-1.320.webp 320w,/images/claude-oxlocal-1.480.webp 480w,/images/claude-oxlocal-1.640.webp 640w,/images/claude-oxlocal-1.768.webp 768w" sizes="(max-width: 768px) 100vw, 33vw"/><figcaption>The OxCaml compiler errors are really descriptive in the latest drop, which greatly helps coding agents figure out the new types</figcaption></figure>
<h2>Performance Results</h2>
<p>Ultimately, none of this matters if the  runtime performance isn&#39;t there!
Luckily, the HTTPz parser is incredible in a synthetic benchmark (just passing
buffers around) as opposed to a network benchmark, using Core_bench to measure
performance. What&#39;s impressive isn&#39;t the straightline throughput, but the
massive drop in heap activity which greatly increased the predictability and
tail latency of the service. And with all the extra typing information, I
expect that straightline performance will only increase (and this is before
I&#39;ve looked at the <a href="https://oxcaml.org/documentation/simd/intro/">SIMD
support</a>).</p>
<div role="region"><table>
<tbody><tr>
<th>Metric</th>
<th>httpz (OxCaml)</th>
<th>Traditional Parser</th>
</tr>
<tr>
<td>Small request (35B)</td>
<td>154 ns</td>
<td>300+ ns</td>
</tr>
<tr>
<td>Medium request (439B)</td>
<td>1,150 ns</td>
<td>2,000+ ns</td>
</tr>
<tr>
<td>Heap allocations</td>
<td>0</td>
<td>100-800 words</td>
</tr>
<tr>
<td>Throughput</td>
<td>6.5M req/sec</td>
<td>3M req/sec</td>
</tr>
</tbody></table></div><h2>Putting my new site live</h2>
<p>I then glued this together using Eio into a <a href="https://github.com/avsm/oxmono/blob/e0b061c0f6621c80e3a990d02867e3302fd7ce16/avsm/httpz/eio/httpz_eio.mli">full
webserver</a>.
It works, and serves traffic just fine and in fact you are reading this web page via it right now!</p>
<h3>What next: caml_alloc_local for C bindings</h3>
<p>The current Eio/OxCaml does a data copy right now since Eio uses Bigarray, but I had a catchup coffee
with <side-note type="contact" data-slug="talex5" data-handle="talex5" data-name="Thomas Leonard" data-link="https://github.com/https://roscidus.com" data-image="/images/faces/talex5.webp" data-github="https://roscidus.com">Thomas Leonard</side-note> and <side-note type="contact" data-slug="pf341" data-handle="pf341" data-name="Patrick Ferris" data-link="https://patrick.sirref.org" data-image="/images/faces/pf341.webp" data-url="https://patrick.sirref.org">Patrick Ferris</side-note> where I agreed to treesmash my local eio into
switching entirely to bytes from the io-uring layer up. <side-note type="contact" data-slug="sadiqj" data-handle="sadiqj" data-name="Sadiq Jaffer" data-link="https://toao.com" data-image="/images/faces/sadiqj.webp" data-email="sj514@cam.ac.uk" data-github="sadiqj" data-orcid="0009-0006-4120-3244" data-url="https://toao.com">Sadiq Jaffer</side-note> informs me
that his compactor doesn&#39;t trigger automatically, so any bytes above a 4KB
threshold are allocated using mmap and so are fine to pass to the kernel for
zero copy receive.</p>
<p>The key OxCaml feature to make this <code>io_uring</code> integration awesome is a new FFI
function that allocates an OCaml value directly into the caller&#39;s OxCaml stack
rather than the heap. This means that we <em>should</em> be able to come up with a scheme
by which io_uring requests are routed directly to an OCaml continuation that&#39;s woken
up directly with a buffer available to it on the stack. True zero-copy to the kernel
awaits, which should also help speed up <side-note type="paper" data-slug="2025-docker-icfp" data-title="Functional Networking for Millions of Docker Desktops" data-authors="Madhavapeddy et al" data-year="2025" data-link="/papers/2025-docker-icfp" data-doi="10.1145/3747525">Docker&#39;s VPNKit</side-note> hugely
as well.</p>
<h3>Making it easier to develop in OxCaml in the open</h3>
<p>Keen readers may note that my OxCaml repo links here go to a new <a href="https://github.com/avsm/oxmono">monorepo</a> I&#39;ve
setup for the purpose of hacking on real code in production outside of Jane Street&#39;s
walls.</p>
<p>I&#39;ll blog more about this next week, but for now I hope you&#39;ve enjoyed a little
taste of what the OxCaml extensions offer in real world code.  Stay tuned also for
even more performance improvements, and for native TLS with an OxCaml port of
<a href="https://github.com/mirleft/ocaml-tls">ocaml-tls</a> from <side-note type="contact" data-slug="hannesm" data-handle="hannesm" data-name="Hannes Mehnert" data-link="https://github.com/hannesm" data-image="/images/faces/hannesm.webp" data-github="hannesm">Hannes Mehnert</side-note> soon!</p>
</div></div>
  </body>
</html>
