<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cat-solstice.github.io/test-pqueue/">Original</a>
    <h1>When O3 is 2x slower than O2</h1>
    
    <div id="readability-page-1" class="page"><div id="content" role="main">
      <p>While trying to optimize a custom bounded priority queue, I ran into a pathological case and I digged deeper and deeper to try to
understand the issue. At one point I decided to collect the data and write this article to share my journey. You can find the repo
<a href="https://github.com/CAT-Solstice/test-pqueue">here</a>.</p>

<hr/>

<p>Here are the results of two benchmarks using <a href="https://crates.io/crates/criterion"><code>criterion</code></a> to justify the click-bait-y title.
Running the benchmark using <code>opt-level=3</code> introduces a performance penalty of +123% vs <code>opt-level=2</code>. Though you should probably not
use <code>opt-level</code> like this with <code>criterion</code>, it is an easy way to make the point.</p>

<div><div><pre><code>RUSTFLAGS=&#34;-C target-cpu=haswell -C opt-level=2&#34; cargo bench
[...]
pqueue-insert/Priority Queue Insert
  time:   [963.15 ns 963.36 ns 963.56 ns]
Found 253 outliers among 10000 measurements (2.53%)
  7 (0.07%) low mild
  229 (2.29%) high mild
  17 (0.17%) high severe
</code></pre></div></div>

<div><div><pre><code>RUSTFLAGS=&#34;-C target-cpu=haswell -C opt-level=3&#34; cargo bench
[...]
pqueue-insert/Priority Queue Insert
  time:   [2.1536 µs 2.1540 µs 2.1545 µs]
  change: [+123.53% +123.60% +123.66%] (p = 0.00 &lt; 0.05)
  Performance has regressed.
Found 203 outliers among 10000 measurements (2.03%)
  11 (0.11%) low mild
  185 (1.85%) high mild
  7 (0.07%) high severe
</code></pre></div></div>

<p>I’m targeting <a href="https://en.wikipedia.org/wiki/Haswell_(microarchitecture)">Haswell</a> architecture because it’s wildly available and
support AVX2, FMA3 and BMI2. I ran this benchmark on an AMD Zen 3 5800X and an Intel 4790 (non-K) - an actual Haswell CPU - with the
same behavior.</p>



<p>The <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/examples/ex-pqueue.rs">example</a> and the <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/benches/pqueue_bench.rs">bench</a>
are building a top-k of distinct pair-like <code>(id, dist)</code> elements from a collection of random elements. The constraint of unicity over
<code>id</code> make the use of a binary heap unefficient, so instead I maintain a sorted <code>Vec</code> inserting new element at the correct position.</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Clone,</span> <span>Copy)]</span>
<span>pub</span> <span>struct</span> <span>Neighbor</span> <span>{</span>
  <span>pub</span> <span>id</span><span>:</span> <span>u32</span><span>,</span>
  <span>pub</span> <span>dist</span><span>:</span> <span>f32</span><span>,</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>Queue</span> <span>{</span>
  <span>neighbors</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Neighbor</span><span>&gt;</span><span>,</span>
  <span>capacity</span><span>:</span> <span>NonZeroUsize</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>The queue is using a <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.binary_search_by">binary search</a> on the vec tofind
the position to insert new element. They should be ordered by <code>dist</code> then by <code>id</code> and <a href="https://floating-point-gui.de/errors/comparison/">as you may know</a>,
floats are a bit tricky to compare. Here is the full code of the <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/src/queue.rs#L32-L56"><code>insert</code></a>
method of the queue:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>insert</span><span>(</span> <span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>neighbor</span><span>:</span> <span>Neighbor</span> <span>)</span> <span>{</span>
  <span>// this compare function trigger the pathological behavior, we will come back to it later</span>
  <span>let</span> <span>cmp</span> <span>=</span> <span>|</span><span>other</span><span>:</span> <span>&amp;</span><span>Neighbor</span><span>|</span> <span>-&gt;</span> <span>Ordering</span> <span>{</span>
    <span>if</span> <span>other</span><span>.dist</span> <span>&lt;</span> <span>neighbor</span><span>.dist</span> <span>{</span> <span>Ordering</span><span>::</span><span>Less</span> <span>}</span>
    <span>else</span> <span>if</span> <span>other</span><span>.dist</span> <span>==</span> <span>neighbor</span><span>.dist</span> <span>{</span> <span>other</span><span>.id</span><span>.cmp</span><span>(</span><span>&amp;</span><span>neighbor</span><span>.id</span><span>)</span> <span>}</span>
    <span>else</span> <span>{</span> <span>Ordering</span><span>::</span><span>Greater</span> <span>}</span>
  <span>};</span>

  <span>if</span> <span>let</span> <span>Err</span><span>(</span> <span>pos</span> <span>)</span> <span>=</span> <span>self</span><span>.neighbors</span><span>.binary_search_by</span><span>(</span> <span>cmp</span> <span>)</span> <span>&amp;&amp;</span> <span>pos</span> <span>&lt;</span> <span>self</span><span>.capacity</span><span>.get</span><span>()</span> <span>{</span>
    <span>if</span> <span>self</span><span>.neighbors</span><span>.len</span><span>()</span> <span>==</span> <span>self</span><span>.capacity</span><span>.get</span><span>()</span> <span>{</span>
      <span>_</span> <span>=</span> <span>self</span><span>.neighbors</span><span>.pop</span><span>();</span>
    <span>}</span>
    <span>unsafe</span> <span>{</span> <span>std</span><span>::</span><span>hint</span><span>::</span><span>assert_unchecked</span><span>(</span> <span>self</span><span>.neighbors</span><span>.len</span><span>()</span> <span>&lt;</span> <span>self</span><span>.neighbors</span><span>.capacity</span><span>()</span> <span>)</span> <span>};</span>
    <span>self</span><span>.neighbors</span><span>.insert</span><span>(</span> <span>pos</span><span>,</span> <span>neighbor</span> <span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>



<p>This section is a bit of a disclaimer. It is hard to be sure what you actually measure with a synthetic benchmark and even harder to
draw clear conclusion from it. Maybe I’m wrong here and there, maybe I’m wrong from start to finish.</p>

<p>Here is the <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/benches/pqueue_bench.rs#L13-L23">benchmark loop</a>:</p>

<div><div><pre><code>  <span>let</span> <span>neighbors</span> <span>=</span> <span>generate_random_neighbors</span><span>();</span>
  <span>let</span> <span>mut</span> <span>queue</span> <span>=</span> <span>Queue</span><span>::</span><span>with_capacity</span><span>(</span> <span>NonZeroUsize</span><span>::</span><span>new</span><span>(</span><span>64</span><span>)</span><span>.unwrap</span><span>()</span> <span>);</span>
  <span>bencher</span><span>.iter</span><span>(</span> <span>||</span> <span>{</span>
    <span>queue</span><span>.clear</span><span>();</span>
    <span>for</span> <span>neighbor</span> <span>in</span> <span>neighbors</span><span>.iter</span><span>()</span> <span>{</span>
      <span>queue</span><span>.insert</span><span>(</span><span>black_box</span><span>(</span> <span>*</span><span>neighbor</span> <span>));</span>
    <span>}</span>
    <span>black_box</span><span>(</span> <span>&amp;</span><span>queue</span> <span>);</span>
  <span>});</span>
</code></pre></div></div>

<p>The data to be inserted <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/benches/pqueue_bench.rs#L33-L45">are generated</a> from
a seeded random uniform distribution for the <code>dist</code> and a randomized range for the <code>id</code>s. We can change the size of the dataset
and/or the capacity of the queue to test different workloads.</p>



<p>We will start going deeper using <a href="https://github.com/flamegraph-rs/flamegraph"><code>flamegraph</code></a> to try to spot the issue. For this, we
will use the <a href="https://github.com/CAT-Solstice/test-pqueue/blob/main/examples/ex-pqueue.rs"><code>ex-pqueue</code></a> example and we should set
<code>debug = 1</code> in the <code>[profile.release]</code> section to help the profiler to match assembly code with Rust code.</p>

<div><div><pre><code><span>[profile.release]</span>
<span>debug</span> <span>=</span> <span>1</span>
<span>codegen-units</span> <span>=</span> <span>1</span>
<span>lto</span> <span>=</span> <span>&#34;thin&#34;</span>
</code></pre></div></div>

<p>You may have to install <code>linux-tools</code> and hint where to find <code>perf</code> to be able run <code>cargo flamegraph</code> like this:</p>

<ul>
  <li><code>opt-level=2</code> <a href="https://cat-solstice.github.io/test-pqueue/assets/ex-pqueue-opt-level-2.svg">full graph</a></li>
</ul>

<div><div><pre><code>PERF=/usr/lib/linux-tools-5.15.0-160/perf \
RUSTFLAGS=&#34;-C target-cpu=haswell -C opt-level=2&#34; \
cargo flamegraph -o ex-pqueue-opt-level-2.svg --example ex-pqueue
[...]
done in 2921ms
[ perf record: Woken up 714 times to write data ]
[ perf record: Captured and wrote 178.494 MB perf.data (2913 samples) ]
Running perf script [0s]: writing flamegraph to &#34;ex-pqueue-opt-level-2.svg&#34;
</code></pre></div></div>

<p><img src="https://cat-solstice.github.io/test-pqueue/assets/ex-pqueue-opt-level-2.svg" alt="flamegraph opt-leve=2"/></p>

<ul>
  <li><code>opt-level=3</code> <a href="https://cat-solstice.github.io/test-pqueue/assets/ex-pqueue-opt-level-3.svg">full graph</a></li>
</ul>

<div><div><pre><code>PERF=/usr/lib/linux-tools-5.15.0-160/perf \
RUSTFLAGS=&#34;-C target-cpu=haswell -C opt-level=3&#34; \
cargo flamegraph -o ex-pqueue-opt-level-3.svg --example ex-pqueue
[...]
done in 6521ms
[ perf record: Woken up 1594 times to write data ]
[ perf record: Captured and wrote 398.344 MB perf.data (6501 samples) ]
Running perf script [0s]: writing flamegraph to &#34;ex-pqueue-opt-level-3.svg&#34;
</code></pre></div></div>

<p><img src="https://cat-solstice.github.io/test-pqueue/assets/ex-pqueue-opt-level-3.svg" alt="flamegraph opt-leve=3"/></p>

<p>Here we can see the percentage of samples in <code>binary_search_by</code> is going from 44.15% to 79.62%. That’s a +80%. The compare function
goes from 25.88% to 63.57%, which is +145%. Compiler optimizations may (and will) merge or split assembly fragments, so it’s not
always obvious which fragment comes from which function in the Rust source code, even with the help of debug informations.</p>

<p>Having a look at the <a href="https://github.com/rust-lang/rust/blob/1.90.0/library/core/src/slice/mod.rs#L2942-L2969"><code>binary_search_by</code></a>
method from <code>core::slice</code>:</p>

<div><div><pre><code>  <span>// This loop intentionally doesn&#39;t have an early exit if the comparison</span>
  <span>// returns Equal. We want the number of loop iterations to depend *only*</span>
  <span>// on the size of the input slice so that the CPU can reliably predict</span>
  <span>// the loop count.</span>
  <span>while</span> <span>size</span> <span>&gt;</span> <span>1</span> <span>{</span>
    <span>let</span> <span>half</span> <span>=</span> <span>size</span> <span>/</span> <span>2</span><span>;</span>
    <span>let</span> <span>mid</span> <span>=</span> <span>base</span> <span>+</span> <span>half</span><span>;</span>

    <span>// SAFETY: the call is made safe by the following invariants:</span>
    <span>// - `mid &gt;= 0`: by definition</span>
    <span>// - `mid &lt; size`: `mid = size / 2 + size / 4 + size / 8 ...`</span>
    <span>let</span> <span>cmp</span> <span>=</span> <span>f</span><span>(</span><span>unsafe</span> <span>{</span> <span>self</span><span>.get_unchecked</span><span>(</span><span>mid</span><span>)</span> <span>});</span>

    <span>// Binary search interacts poorly with branch prediction, so force</span>
    <span>// the compiler to use conditional moves if supported by the target</span>
    <span>// architecture.</span>
    <span>base</span> <span>=</span> <span>hint</span><span>::</span><span>select_unpredictable</span><span>(</span><span>cmp</span> <span>==</span> <span>Greater</span><span>,</span> <span>base</span><span>,</span> <span>mid</span><span>);</span>

    <span>// This is imprecise in the case where `size` is odd and the</span>
    <span>// comparison returns Greater: the mid element still gets included</span>
    <span>// by `size` even though it&#39;s known to be larger than the element</span>
    <span>// being searched for.</span>
    <span>//</span>
    <span>// This is fine though: we gain more performance by keeping the</span>
    <span>// loop iteration count invariant (and thus predictable) than we</span>
    <span>// lose from considering one additional element.</span>
    <span>size</span> <span>-=</span> <span>half</span><span>;</span>
  <span>}</span>
</code></pre></div></div>

<p>The comment about branch prediction and conditional moves should ring a bell. Time for disassembly!</p>



<p>We will now use Compiler Explorer (<a href="https://godbolt.org/">godbolt</a>) to have a look at the assembly emitted by the compiler.
Here is a link to <a href="https://godbolt.org/z/jxEK933sr">a currated version</a> of the queue and the assembly for the <code>Queue::insert()</code>
method (search for <code>insert:</code> in the assembly). The first pane is compiled with <code>opt-level=2</code> and the second with <code>opt-level=3</code>.</p>

<p>We are looking for the generated code of the search loop. I annotated some operations to help, but you better know some assembly to
follow. Here is the relevant snippet using <code>opt-level=2</code>:</p>

<div><div><pre><code><span>.LBB3_11:</span>
    <span>mov</span>       <span>rax</span><span>,</span> <span>r8</span>
<span>.LBB3_12:</span>
    <span>sub</span>       <span>rdx</span><span>,</span> <span>r9</span>                            <span>; size -= half</span>
    <span>mov</span>       <span>r8</span><span>,</span> <span>rax</span>
    <span>cmp</span>       <span>rdx</span><span>,</span> <span>1</span>                             <span>; while size &gt; 1</span>
    <span>jbe</span>       <span>.LBB3_3</span>                            <span>; exit loop</span>
<span>.LBB3_8:</span>
    <span>mov</span>       <span>r9</span><span>,</span> <span>rdx</span>
    <span>shr</span>       <span>r9</span>                                 <span>; half = size / 2</span>
    <span>lea</span>       <span>rax</span><span>,</span> <span>[</span><span>r9</span> <span>+</span> <span>r8</span><span>]</span>                     <span>; mid = half + base</span>
    <span>vmovss</span>    <span>xmm1</span><span>,</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>rax</span> <span>+</span> <span>4</span><span>]</span>
    <span>vucomiss</span>  <span>xmm0</span><span>,</span> <span>xmm1</span>                         <span>; cmp neighbor.dist other.dist</span>
    <span>ja</span>        <span>.LBB3_12</span>
    <span>vucomiss</span>  <span>xmm1</span><span>,</span> <span>xmm0</span>                         <span>; cmp other.dist neighbor.dist</span>
    <span>jne</span>       <span>.LBB3_11</span>
    <span>jp</span>        <span>.LBB3_11</span>
    <span>cmp</span>       <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>rax</span><span>],</span> <span>esi</span>       <span>; cmp other.id neighbor.id</span>
    <span>ja</span>        <span>.LBB3_11</span>
    <span>jmp</span>       <span>.LBB3_12</span>
</code></pre></div></div>

<p>Straight forward implementation with two comparison on the float and a total of 5 conditional jumps, one of them to exit the loop.
Nothing fancy here. Note the use of <code>jp</code> (bit parity) to check for <code>NaN</code>s.</p>

<p>Now the snippet for <code>opt-level=3</code>:</p>

<div><div><pre><code><span>.LBB3_8:</span>
    <span>mov</span>       <span>r9</span><span>,</span> <span>rdx</span>
    <span>shr</span>       <span>r9</span>                                 <span>; half = size / 2</span>
    <span>lea</span>       <span>r10</span><span>,</span> <span>[</span><span>r9</span> <span>+</span> <span>r8</span><span>]</span>                     <span>; mid = half + base</span>
    <span>cmp</span>       <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>r10</span><span>],</span> <span>esi</span>       <span>; cmp other.id neighbor.id</span>
    <span>mov</span>       <span>rax</span><span>,</span> <span>r10</span>
    <span>cmova</span>     <span>rax</span><span>,</span> <span>r8</span>
    <span>vucomiss</span>  <span>xmm0</span><span>,</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>r10</span> <span>+</span> <span>4</span><span>]</span>  <span>; cmp neighbor.dist other.dist</span>
    <span>cmovne</span>    <span>rax</span><span>,</span> <span>r8</span>
    <span>cmovp</span>     <span>rax</span><span>,</span> <span>r8</span>
    <span>cmova</span>     <span>rax</span><span>,</span> <span>r10</span>
    <span>sub</span>       <span>rdx</span><span>,</span> <span>r9</span>                            <span>; size -= half</span>
    <span>mov</span>       <span>r8</span><span>,</span> <span>rax</span>
    <span>cmp</span>       <span>rdx</span><span>,</span> <span>1</span>                             <span>; while size &gt; 1</span>
    <span>ja</span>        <span>.LBB3_8</span>                            <span>; exit loop</span>
</code></pre></div></div>

<p>As you can see, the code is rearranged from one version to the other. This version is shorter and there is only one conditional jump
to exit the loop. The 4 conditional jumps are replaced by 4 conditional moves. That’s pretty cool te be honest.</p>

<p>But oh the irony: when the compiler successfully emit a compare function that actually produce conditional moves instead of conditional
jumps, the performance plummet.</p>



<p>Modern CPUs are <a href="https://en.wikichip.org/w/images/c/c7/haswell_block_diagram.svg">very complex</a> beasts and they try their best to run
our code as fast as possible. They may <a href="https://en.wikipedia.org/wiki/Out-of-order_execution">reorder</a> operations, introduce
<a href="https://en.wikipedia.org/wiki/Instruction-level_parallelism">instruct level parallelism</a> do <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch prediction</a>
and <a href="https://en.wikipedia.org/wiki/Speculative_execution">speculative exeuction</a> to squeeze out the maximum work from each CPU cycle.</p>

<p>Each instruction has a latency (number of cycles to perform the instruction) and can be executed by only a selected set of
<a href="https://en.wikipedia.org/wiki/Execution_unit">execution units</a> routed by dedicated ports, which will eventually dictate their
(maximum) throughput. At the same time, our code logic will introduce <a href="https://en.wikipedia.org/wiki/Data_dependency">dependencies</a>
between operations.</p>

<p>We can try to see how our assembly code may perform at the CPU level using <a href="https://uica.uops.info/">uiCA</a> which allows us to simulate
the execution of a snippet of assembly and doing iterations on it. We are doing theorical nano-benchmark here!</p>

<ul>
  <li><a href="https://uica.uops.info/?code=.LBB3_11%3A%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20rax%2C%20r8%0D%0A.LBB3_12%3A%0D%0A%20%20%20%20sub%20%20%20%20%20%20%20rdx%2C%20r9%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r8%2C%20rax%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20rdx%2C%201%0D%0A%20%20%20%20jbe%20%20%20%20%20%20%20.LBB3_3%0D%0A.LBB3_8%3A%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r9%2C%20rdx%0D%0A%20%20%20%20shr%20%20%20%20%20%20%20r9%0D%0A%20%20%20%20lea%20%20%20%20%20%20%20rax%2C%20%5Br9%20%2B%20r8%5D%0D%0A%20%20%20%20vmovss%20%20%20%20xmm1%2C%20dword%20ptr%20%5Brcx%20%2B%208*rax%20%2B%204%5D%0D%0A%20%20%20%20vucomiss%20%20xmm0%2C%20xmm1%0D%0A%20%20%20%20ja%20%20%20%20%20%20%20%20.LBB3_12%0D%0A%20%20%20%20vucomiss%20%20xmm1%2C%20xmm0%0D%0A%20%20%20%20jne%20%20%20%20%20%20%20.LBB3_11%0D%0A%20%20%20%20jp%20%20%20%20%20%20%20%20.LBB3_11%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20dword%20ptr%20%5Brcx%20%2B%208*rax%5D%2C%20esi%0D%0A%20%20%20%20ja%20%20%20%20%20%20%20%20.LBB3_11%0D%0A%20%20%20%20jmp%20%20%20%20%20%20%20.LBB3_12%0D%0A.LBB3_3%3A%0D%0A&amp;syntax=asIntel&amp;uArchs=HSW&amp;tools=uiCA&amp;alignment=0&amp;uiCAHtmlOptions=traceTable&amp;uiCAHtmlOptions=dependencies">uiCA, opt-level=2</a></li>
</ul>

<p>You can then <code>Run!</code> the simulation and <code>uiCA</code> will produce a predicted throughput along with a detailed output. Beware, the throughput
is given in cycles per iteration, so the higher the slower!</p>

<div><div><pre><code>Throughput (in cycles per iteration): 5.00
Bottleneck: Ports

The following throughputs could be achieved if the given property were the only bottleneck:

  - LSD: 4.00
  - Issue: 4.00
  - Ports: 5.00
  - Dependencies: 2.00
</code></pre></div></div>

<p>There are detailed information for each assembly operation in the table (not reported here). You can also see the execution trace
over several iterations following the <code>Open Trace</code> link. They may be a bit overwhelming to add in this article but I encourage you
to check them out!</p>

<ul>
  <li><a href="https://uica.uops.info/?code=.LBB3_8%3A%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r9%2C%20rdx%0D%0A%20%20%20%20shr%20%20%20%20%20%20%20r9%0D%0A%20%20%20%20lea%20%20%20%20%20%20%20r10%2C%20%5Br9%20%2B%20r8%5D%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20dword%20ptr%20%5Brcx%20%2B%208*r10%5D%2C%20esi%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20rax%2C%20r10%0D%0A%20%20%20%20cmova%20%20%20%20%20rax%2C%20r8%0D%0A%20%20%20%20vucomiss%20%20xmm0%2C%20dword%20ptr%20%5Brcx%20%2B%208*r10%20%2B%204%5D%0D%0A%20%20%20%20cmovne%20%20%20%20rax%2C%20r8%0D%0A%20%20%20%20cmovp%20%20%20%20%20rax%2C%20r8%0D%0A%20%20%20%20cmova%20%20%20%20%20rax%2C%20r10%0D%0A%20%20%20%20sub%20%20%20%20%20%20%20rdx%2C%20r9%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r8%2C%20rax%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20rdx%2C%201%0D%0A%20%20%20%20ja%20%20%20%20%20%20%20%20.LBB3_8%0D%0A&amp;syntax=asIntel&amp;uArchs=HSW&amp;tools=uiCA&amp;alignment=0&amp;uiCAHtmlOptions=traceTable&amp;uiCAHtmlOptions=dependencies">uiCA, opt-level=3</a></li>
</ul>

<div><div><pre><code>Throughput (in cycles per iteration): 13.81
Bottleneck: Dependencies

The following throughputs could be achieved if the given property were the only bottleneck:

  - LSD: 5.00
  - Issue: 5.25
  - Ports: 4.13
  - Dependencies: 14.00
</code></pre></div></div>

<p>The assembly using conditional moves has a predicted throughput 2.7x lower! <code>uiCA</code> hint us about dependencies as a potential
bottleneck. This should not come at a surprise, conditional moves are known to be a double-edged sword <a href="https://yarchive.net/comp/linux/cmov.html">for a long time</a>.</p>



<p>At this point, you may think: <em>“So many cmoves! Your compare function is odd!”</em> While one could argue about this implementation, I
used it here because the optimization level changes the emitted assembly for this particular one. I tested other implementations,
and they consistently produce either jumps (fast) or moves (slow), regardless of <code>opt-level</code>.</p>

<p>We can try with this one which uses <a href="https://doc.rust-lang.org/std/primitive.f32.html#method.total_cmp"><code>f32::total_cmp</code></a>:</p>

<div><div><pre><code><span>let</span> <span>cmp</span> <span>=</span> <span>|</span><span>other</span><span>:</span> <span>&amp;</span><span>Neighbor</span><span>|</span> <span>-&gt;</span> <span>Ordering</span> <span>{</span>
  <span>match</span> <span>other</span><span>.dist</span><span>.total_cmp</span><span>(</span> <span>&amp;</span><span>neighbor</span><span>.dist</span> <span>)</span> <span>{</span>
    <span>Ordering</span><span>::</span><span>Equal</span> <span>=&gt;</span> <span>other</span><span>.id</span><span>.cmp</span><span>(</span> <span>&amp;</span><span>neighbor</span><span>.id</span> <span>),</span>
    <span>ordering</span> <span>=&gt;</span> <span>ordering</span><span>,</span>
  <span>}</span>
<span>};</span>
</code></pre></div></div>

<p><code>total_cmp</code> works with the <a href="https://github.com/rust-lang/rust/blob/1.90.0/library/core/src/num/f32.rs#L1348-L1378">bit representation</a>
of the <code>f32</code>, which should add some bit twiddling operations but should remove the special case for <code>NaN</code>s. Using <code>opt-level=3</code>, here
is the emitted assembly:</p>

<div><div><pre><code><span>.LBB3_14:</span>
    <span>cmp</span>       <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>rax</span><span>],</span> <span>esi</span>       <span>; cmp other.id neighbor.id</span>
    <span>seta</span>      <span>r11b</span>
<span>.LBB3_16:</span>
    <span>test</span>      <span>r11b</span><span>,</span> <span>r11b</span>
    <span>cmovne</span>    <span>rax</span><span>,</span> <span>r9</span>
    <span>sub</span>       <span>r8</span><span>,</span> <span>r10</span>                            <span>; size -= half</span>
    <span>mov</span>       <span>r9</span><span>,</span> <span>rax</span>
    <span>cmp</span>       <span>r8</span><span>,</span> <span>1</span>                              <span>; while size &gt; 1</span>
    <span>jbe</span>       <span>.LBB3_4</span>                            <span>; exit loop</span>
<span>.LBB3_13:</span>
    <span>mov</span>       <span>r10</span><span>,</span> <span>r8</span>
    <span>shr</span>       <span>r10</span>                                <span>; half = size / 2</span>
    <span>lea</span>       <span>rax</span><span>,</span> <span>[</span><span>r10</span> <span>+</span> <span>r9</span><span>]</span>                    <span>; mid = half + base</span>
    <span>mov</span>       <span>r11d</span><span>,</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rcx</span> <span>+</span> <span>8</span><span>*</span><span>rax</span> <span>+</span> <span>4</span><span>]</span>
    <span>mov</span>       <span>ebp</span><span>,</span> <span>r11d</span>
    <span>sar</span>       <span>ebp</span><span>,</span> <span>31</span>                            <span>; bit twiddling</span>
    <span>shr</span>       <span>ebp</span>                                <span>; bit twiddling</span>
    <span>xor</span>       <span>ebp</span><span>,</span> <span>r11d</span>                          <span>; bit twiddling</span>
    <span>cmp</span>       <span>ebp</span><span>,</span> <span>edx</span>                           <span>; cmp other.dist neighbor.dist</span>
    <span>je</span>        <span>.LBB3_14</span>
    <span>setg</span>      <span>r11b</span>
    <span>jmp</span>       <span>.LBB3_16</span>
</code></pre></div></div>

<p>Nice code again, only one conditional jump and one conditional move. Surely a single <code>cmovne</code> is faster, right?</p>

<div><div><pre><code>RUSTFLAGS=&#34;-C target-cpu=haswell -C opt-level=3&#34; cargo bench
[...]
pqueue-insert/Priority Queue Insert
  time:   [2.0744 µs 2.0750 µs 2.0756 µs]
  change: [−3.7051% −3.6691% −3.6344%] (p = 0.00 &lt; 0.05)
  Performance has improved.
Found 69 outliers among 10000 measurements (0.69%)
  18 (0.18%) low mild
  51 (0.51%) high mild
</code></pre></div></div>

<p>Actually it is barely faster than with 4 conditional moves and still 2x slower that with conditional jumps (<a href="https://cat-solstice.github.io/test-pqueue/assets/ex-pqueue-total-cmp.svg">flamegraph</a>
for completeness).</p>

<p>Let’s check what uiCA predict for this piece of assembly: <a href="https://uica.uops.info/?code=.LBB3_14%3A%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20dword%20ptr%20%5Brcx%20%2B%208*rax%5D%2C%20esi%0D%0A%20%20%20%20seta%20%20%20%20%20%20r11b%0D%0A.LBB3_16%3A%0D%0A%20%20%20%20test%20%20%20%20%20%20r11b%2C%20r11b%0D%0A%20%20%20%20cmovne%20%20%20%20rax%2C%20r9%0D%0A%20%20%20%20sub%20%20%20%20%20%20%20r8%2C%20r10%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r9%2C%20rax%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20r8%2C%201%0D%0A%20%20%20%20jbe%20%20%20%20%20%20%20.LBB3_4%0D%0A.LBB3_13%3A%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r10%2C%20r8%0D%0A%20%20%20%20shr%20%20%20%20%20%20%20r10%0D%0A%20%20%20%20lea%20%20%20%20%20%20%20rax%2C%20%5Br10%20%2B%20r9%5D%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20r11d%2C%20dword%20ptr%20%5Brcx%20%2B%208*rax%20%2B%204%5D%0D%0A%20%20%20%20mov%20%20%20%20%20%20%20ebp%2C%20r11d%0D%0A%20%20%20%20sar%20%20%20%20%20%20%20ebp%2C%2031%0D%0A%20%20%20%20shr%20%20%20%20%20%20%20ebp%0D%0A%20%20%20%20xor%20%20%20%20%20%20%20ebp%2C%20r11d%0D%0A%20%20%20%20cmp%20%20%20%20%20%20%20ebp%2C%20edx%0D%0A%20%20%20%20je%20%20%20%20%20%20%20%20.LBB3_14%0D%0A%20%20%20%20setg%20%20%20%20%20%20r11b%0D%0A%20%20%20%20jmp%20%20%20%20%20%20%20.LBB3_16%0D%0A.LBB3_4%3A%0D%0A&amp;syntax=asIntel&amp;uArchs=HSW&amp;tools=uiCA&amp;alignment=0&amp;uiCAHtmlOptions=traceTable&amp;uiCAHtmlOptions=dependencies">uiCA, total_cmp</a></p>

<div><div><pre><code>Throughput (in cycles per iteration): 15.50
Bottleneck: unknown

The following throughputs could be achieved if the given property were the only bottleneck:

  - LSD: 5.00
  - Issue: 5.25
  - Ports: 5.00
  - Dependencies: 15.00
</code></pre></div></div>

<p>Same story. If we trust <code>uiCA</code>, the dependencies are killing it.</p>



<p>You may wonder what we could do about this. I copy-pasted the code of <code>binary_search_by</code> and tried some tweaks:</p>

<ul>
  <li>add a <code>hint::black_box</code> around the call to the compare function</li>
</ul>

<p>Using the first compare function, it degrades the O2 perf by +10% while improving the O3 by -50%, so they are now neck and neck. The
generated assembly is different in O3, though. There is a mix of one conditional move and 3 conditional jumps. Meanwhile, with the
compare function which uses <code>total_cmp</code>, the performance plummets event more and is now 3x slower. That’s wild!</p>

<ul>
  <li>replace the <code>hint::select_unpredictable</code> with the worst <code>match</code> statement possible:</li>
</ul>

<div><div><pre><code><span>match</span> <span>f</span><span>(</span> <span>unsafe</span> <span>{</span> <span>slice</span><span>.get_unchecked</span><span>(</span><span>mid</span><span>)</span> <span>}</span> <span>)</span> <span>{</span>
  <span>Ordering</span><span>::</span><span>Less</span> <span>|</span> <span>Ordering</span><span>::</span><span>Equal</span> <span>=&gt;</span> <span>base</span> <span>=</span> <span>mid</span><span>,</span>
  <span>Ordering</span><span>::</span><span>Greater</span> <span>=&gt;</span> <span>{},</span>
<span>}</span>
</code></pre></div></div>

<p>The performance of all tested cases are now similar to each other (and good) but there is no more conditional moves in the generated
assembly.</p>

<hr/>

<p>I digged into the history of the implementation of <code>binary_search_by</code> and here are the most relevant links I found:</p>

<ul>
  <li>Improve <code>SliceExt::binary_search</code> performance <a href="https://github.com/rust-lang/rust/pull/45333">#45333</a></li>
  <li>Binary search performance regressed in 1.25 <a href="https://github.com/rust-lang/rust/issues/53823">#53823</a></li>
  <li>Add <code>select_unpredictable</code> to force LLVM to use CMOV <a href="https://github.com/rust-lang/rust/pull/128250">#128250</a></li>
</ul>

<p>The performance regression tells us there are benchmarks where conditional moves are faster than conditional jumps, and I bet they
were conducted by people who know better than I do. In my tests, the results varied between -10% and +200%. According to <code>uiCA</code>, the
bottleneck appears to be dependency-related but I’m not entirely sure the simulation is accurate, and it may represent a worst-case
scenario.</p>

<p>Benchmarking is hard, and I might be stretching myself a bit too much here. I hope you enjoyed the ride and learned something in the
meantime!</p>


      
    </div></div>
  </body>
</html>
