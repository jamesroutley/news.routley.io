<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1">Original</a>
    <h1>Social learning: Collaborative learning with large language models</h1>
    
    <div id="readability-page-1" class="page"><div>
<div id="post-body-1765359719068432739">
<p><span>Posted by Amirkeivan Mohtashami, Research Intern, and Florian Hartmann, Software Engineer, Google Research</span>

</p><p>
Large language models (LLMs) have significantly improved the state of the art for solving tasks specified using natural language, often reaching performance close to that of people. As these models increasingly enable assistive agents, it could be beneficial for them to learn effectively from each other, much like people do in social settings, which would allow LLM-based agents to improve each other’s performance. 
</p>
<p>
To discuss the learning processes of humans, Bandura and Walters <a href="https://books.google.ch/books/about/Social_Learning_Theory.html?id=IXvuAAAAMAAJ&amp;redir_esc=y">described</a> the concept of <em>social learning</em> in 1977, outlining different models of observational learning used by people. One common method of learning from others is through a <em>verbal instruction</em> (e.g., from a teacher) that describes how to engage in a particular behavior. Alternatively, learning can happen through a <em>live model</em> by mimicking a live example of the behavior.
</p>
<p>
Given the success of LLMs mimicking human communication, in our paper “<a href="https://arxiv.org/abs/2312.11441">Social Learning: Towards Collaborative Learning with Large Language Models</a>”, we investigate whether LLMs are able to learn from each other using social learning. To this end, we outline a framework for social learning in which LLMs share knowledge with each other in a privacy-aware manner using natural language. We evaluate the effectiveness of our framework on various datasets, and propose quantitative methods that measure privacy in this setting. In contrast to previous approaches to collaborative learning, such as common <a href="https://blog.research.google/2017/04/federated-learning-collaborative.html">federated learning</a> approaches that often rely on gradients, in our framework, agents teach each other purely using natural language.
</p>
</div>
</div></div>
  </body>
</html>
