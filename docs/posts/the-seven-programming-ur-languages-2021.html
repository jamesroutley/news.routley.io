<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://madhadron.com/programming/seven_ur_languages.html">Original</a>
    <h1>The seven programming ur-languages (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
	    
            
            
            

            
            <p id="epistemics">
                Status: Done</p>
            

	    
	    
            <p>I regularly hear people asking which programming language to learn,
and then reeling off a list of very similar languages (“Should I learn
Java, C#, C++, Python, or Ruby?”). In response I usually tell them that
it doesn’t really matter, as long as they get started. There are
fundamentals behind them.</p>
<p>What do I mean when I say fundamentals? If you have an array or list
of items and you’re going to loop over it, that is the same in any
imperative language. There is straightforward iteration</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span>int</span><span>[</span><span>10</span><span>]</span> arr<span>;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++)</span> <span>{</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span>// do something with arr[i]</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>and there is iterating over all unordered combinations</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span>int</span><span>[</span><span>10</span><span>]</span> arr<span>;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++)</span> <span>{</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span>for</span> <span>(</span><span>int</span> j <span>=</span> i<span>+</span><span>1</span><span>;</span> j <span>&lt;</span> <span>10</span><span>;</span> j<span>++)</span> <span>{</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span>// do something with arr[i] and arr[j]</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span>}</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>and a few other patterns, but those patterns are basically the same
in C, Java, Python, or Fortran. Having neural pathways that fluently
express intention in these patterns, the same way you express thoughts
in sentence structures in English, are fundamentals.</p>
<p>But not all languages have the same set of patterns. The patterns for
looping in C or Python are very different from the patterns of recursion
in Standard ML or Prolog. The way you organize a program in Lisp, where
you name new language constructs, is very different from how you
organize it in APL, where fragments of symbol sequences are both the
definitions of behavior and become the label for that behavior in your
mind.</p>
<p>These distinct collections of fundamentals form various
<em>ur</em>-languages. Learning a new language that traces to the same
<em>ur</em>-language is an easy shift. Learning one that traces to an
unfamiliar <em>ur</em>-language requires significant time and effort and
new neural pathways.</p>
<p>I am aware of seven <em>ur</em>-languages in software today. I’ll
name them for a <em>type specimen</em>, the way a species in
paleontology is named for a particular fossil that defines it and then
other fossils are compared to the type specimen to determine their
identity. The <em>ur</em>-languages are:</p>
<ul>
<li>ALGOL</li>
<li>Lisp</li>
<li>ML</li>
<li>Self</li>
<li>Forth</li>
<li>APL</li>
<li>Prolog</li>
</ul>
<h2 id="algol">ALGOL</h2>
<p><strong>Characteristics</strong>. Programs consist of sequences of
assignments, conditionals, and loops, organized into functions. Many
languages add module systems, ways of defining new data types,
polymorphism, or alternate control flow constructs like exceptions or
coroutines.</p>
<p><strong>Examples</strong>. Most common programming languages trace to
this <em>ur</em>-language. ALGOL itself included ALGOL 58, ALGOL 60,
ALGOL W, and ALGOL 68. Assembly languages for mainstream processors,
Fortran, C, C++, Python, Java, C#, Ruby, Pascal, JavaScript and Ada all
trace to this <em>ur</em>-language.</p>
<p><strong>History</strong>. This is the oldest <em>ur</em>-language,
going back to Ada Lovelace formulating programs for Babbage’s analytical
engine. The machine and assembly languages for all Eckert-Mauchly
architecture computers, going back to EDVAC and the first Univacs were
of this form, as were all early attempts at higher level languages,
starting with Grace Hopper’s A-0 and going through Fortran and COBOL. In
the 1960’s the academic computer science community developed structured
programming to make programming in these languages more manageable,
which led to ALGOL 60, which basically all members of the class derive
from.</p>
<p>Over time, members of this family accrete features taken from other
<em>ur</em>-languages. In the 1980’s, notions from the Self
<em>ur</em>-language were grafted onto many of these language in the
form of classes as a way to define data types and do polymorphism. Since
2010, ideas from the ML <em>ur</em>-language have been appearing.</p>
<h2 id="lisp">Lisp</h2>
<p><strong>Characteristics</strong>. Lisp consists of prefix expressions
enclosed in parentheses, for example</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>(<span>+</span> <span>2</span> <span>3</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>(<span>defun</span><span> square </span>(x)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  (<span>*</span> x x))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>(<span>*</span> (square <span>3</span>) <span>3</span>)</span></code></pre></div>
<p>This syntax seems bizarre, but the language also has a built-in
representation of lists as a data structure as parentheses around the
space separated items (e.g., <code>(1 2 3 4)</code>). Thus the code is
in the form of a list, and Lisp systems let you define macros that take
a list, modify it, and pass that modified code to the compiler.</p>
<p>Lisps tend to behave like some other <em>ur</em>-language when
writing most code (usually ALGOL or ML), but are distinguished by the
macro system that lets the programmer redefine the semantics of the
language. Common Lisp, for example, has a <code>loop</code> syntax, but
it is defined as a macro, not built into the language.</p>
<p><strong>Examples</strong>. There were many early Lisps, but the
community achieved a consensus in Common Lisp. Meanwhile, Sussman and
Steele explored how much could be done with functions and produced
Scheme. Several other special purpose Lisps such as Lush (for numerical
computing), AutoLISP (the scripting language for AutoCAD), and Emacs
Lisp (the language used to implement editing behavior in the Emacs
editor) have been used. In recent years Clojure has emerged as a third
major branch of the Lisp family.</p>
<p><strong>History</strong>. Lisp is about a year younger than Fortran,
which makes it the second oldest language still in use today. Its
origins were in a purely mathematical question: how do you write down a
mathematical structure you can define that can evaluate its own
expressions? John McCarthy provided an answer in 1958, which then got
implemented on a computer. That mathematical background made early Lisps
awkward fits for the machines they were on. Questions about memory and
CPU cycles were irrelevant to the mathematics, and things like garbage
collection had to be invented to make it work.</p>
<p>There was a period in the late 1970’s and early 1980’s when machines
were specially built to run Lisp from the ground up. Much of today’s
integrated development environments was invented on those machines. Lisp
itself was the vehicle of choice for most artificial intelligence
research in that period, and when artifical intelligence’s hype in the
1980’s failed to deliver, the field, and Lisp with it, crashed into what
is called the “AI Winter.” Lisps remain stubbornly alive to this day,
especially as computers gained power and other languages adopted many of
the features that originally made them awkward to implement.</p>
<h2 id="ml-functional-languages">ML (functional languages)</h2>
<p><strong>Characteristics</strong>. ML languages are defined by
functions being first class values and a type system in the
Hindley-Milner family that is adequate to represent different kinds of
functions and tagged unions. All iteration is done by recursion, as
in</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>sum : <span>list</span> <span>of</span> <span>int</span> -&gt; <span>int</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>sum [] = <span>0</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sum (x:xs) = x + sum xs</span></code></pre></div>
<p>or by defining functions that encapsulate the iteration pattern and
take another function to implement the behavior.</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>map : (&#39;a -&gt; &#39;a) -&gt; <span>list</span> <span>of</span> &#39;a -&gt; <span>list</span> <span>of</span> &#39;a</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>map _ [] = []</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>map f (x:xs) = (f x) : (map f xs)</span></code></pre></div>
<p>Some languages in the family (Miranda and Haskell) are lazy by
default, that is, they do not evaluate anything until it is actually
needed. Others explore extensions of the type system in various
directions. OCaml attempts to merge notions from the Self
<em>ur</em>-language. Agda and Idris mix values and types (what is
called dependent type systems) and 1ML mixes modules and types.</p>
<p><strong>Examples</strong>. ML spawned CaML (Cambridge ML), Standard
ML, OCaml, and a whole related family such as Miranda, Haskell, and
today the dependently typed languages like Agda and Idris.</p>
<p><strong>History</strong>. ML was the metalanguage (thus the name) for
a theorem proving program developed in Cambridge, England. The language
escaped from that context and was popular in Europe, particularly in
England and France.</p>
<h2 id="self-object-oriented-languages">Self (object oriented
languages)</h2>
<p><strong>Characteristics</strong>. A program consists of a set of
objects that can receive and send messages to each other. All behavior
is implemented in this way. You create a new object by sending a message
to an existing object. You do conditionals by having a variable which
refers to either the true object or the false object. Both take a
message with two parameters, a function to run on true, and a function
to run on false. The true object runs the first function. The false
object runs the second. The calling code does not know which it is
sending to, only that it is sending a message. Loops are the same.
Indeed, by creating and inserting appropriate objects into the right
places you can entirely redefine the semantics of the language.</p>
<p>These languages usually have their source stored in a live
environment rather than text files. The programmer modifies the live
system and saves its new state rather than compile files to produce a
system.</p>
<p><strong>Examples</strong>. The two important examples are Smalltalk
and Self. A whole range of languages implement message passing to
objects in some subset of the language. This kind of partial import is
usually referred to as “object oriented programming.” Most of these are
modeled on Smalltalk. JavaScript is the exception, and derives from
Self’s classless object system.</p>
<p>The ideas were taken in two other important directions.</p>
<p>First, Common Lisp’s object system generalized the idea of choosing
what code is run based on what object receives a message. It disconnects
behavior from the objects and instead the runtime chooses which behavior
to run based on all the parameters involved, not just one.</p>
<p>Second, Erlang switched the notion of a thread of execution jumping
from object to object to run various code and instead had parallel
threads of execution that explicitly listen for and send messages.</p>
<p><strong>History</strong>. Smalltalk was the original language,
developed at Xerox Parc in the late 1970’s and 1980’s. There were a
variety of commercial Smalltalk systems in the 1980’s, and IBM used
Smalltalk to develop its programming tools for other languages (the
collection of tools known as VisualAge). Today Smalltalk largely
survives as the open source Pharo Smalltalk.</p>
<p>A lot of work was done on how to make Smalltalk run fast and
efficiently, culminating in the Strongtalk project. Strongtalk is
historically important because its discoveries became the basis of the
HotSpot just-in-time compiler for Java.</p>
<p>Smalltalk inherited the notion of a value and its type from earlier
languages, and implemented the idea of a class. All objects had a class
that gave their type, and the class was used to construct objects of
that type. Self disposed of the notion of class and worked solely with
objects. As this is a purer form, I have chosen Self as the type
specimen for this <em>ur</em>-language.</p>
<h2 id="forth-stack-languages">Forth (stack languages)</h2>
<p><strong>Characteristics</strong>. Stack languages are an inverse of
Lisp, and share the grammar of Hewlett Packard reverse Polish notation
calculators. They have a data stack. When you write a literal like the
number <code>42</code>, it is pushed to the stack. When you write the
name of a function, it takes no explicit parameters. Instead it operates
on the stack. Simple arithmetic looks quite backwards</p>
<pre><code>2 3 + 5 *</code></pre>
<p>and function definitions are equally terse. In most Forth variants,
<code>:</code> defines a new word, in this case <code>square</code>.
When <code>square</code> is called it is the same as calling
<code>dup</code>, which duplicates the top element of the stack,
followed by <code>*</code>, which multiplies the top two elements.</p>
<pre><code>: square dup * ;

3 square</code></pre>
<p>Forth allows programmers to intercept the parser and replace it with
their own code, so the grammar is entirely replaceable. It is common to
see Forth programs that define small languages, such as a Fortran subset
or a way to directly ASCII parse diagrams giving packet layouts or the
transitions of state machines.</p>
<p><strong>Examples</strong>. Forth in all its many variants,
PostScript, Factor, Joy (a purely functional language that uses a
mathematical formulation of composition in place of the stack).</p>
<p><strong>History</strong>. Forth was originally written in 1970 to
control radio telescopes, but then spread broadly in embedded systems.
It is sufficiently easy to bootstrap a Forth system that there are
dozens of variations created by different programmers for thir own
purposes.</p>
<p>PostScript emerged in the 1980’s as a flexible means to describe
documents to printers. It is much more limited in many ways than Forth,
but defines primitives related to graphical layouts in the language.</p>
<h2 id="apl-array-languages">APL (array languages)</h2>
<p><strong>Characteristics</strong>. Everything in the language is an (n
dimensional) array. Operators are one or two symbols long, and implement
high level operations over these arrays. The result is so terse that the
sequences of symbols become the label for an operation rather than
giving it another name. For example, to calculate the average of an
array in variable <code>x</code>, you would write</p>

<p><strong>Examples</strong>. APL, J, K. The higher order operations
over arrays have been partially exported into many environments, such as
MATLAB, NumPy, and R.</p>
<p><strong>History</strong>. APL began as a mathematical notation
created by Kenneth Iverson in the 1960’s. He then implemented it on a
computer. It has enjoyed a niche following ever since among people doing
heavy calculations. Its descendant, K, was very popular in financial
settings.</p>
<h2 id="prolog-logic-languages">Prolog (logic languages)</h2>
<p><strong>Characteristics</strong>. Programs consist of facts, either
“ground” facts such as Bob is Ed and Jane’s father,</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>father(bob<span>,</span> ed)<span>.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>father(bob<span>,</span> jane)<span>.</span></span></code></pre></div>
<p>or non-ground facts which define how to derive a fact from other
facts by putting in variables (which are capitalized)</p>
<div id="cb10"><pre><code><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>grandfather(<span>X</span><span>,</span> <span>Y</span>) <span>:-</span> father(<span>X</span><span>,</span> <span>Z</span>)<span>,</span> father(<span>Z</span><span>,</span> <span>Y</span>)<span>.</span></span></code></pre></div>
<p>Prolog runtimes take these facts and a query on them and searches for
a result for the query. And it turns out that if you choose the right
structure for defining facts, this is Turing complete.</p>
<p>The terms that form facts in Prolog are a native data type in their
own right that can be created and then fed to the runtime, the same way
that Lisp’s macros or Forth’s parser replacement work.</p>
<p>Because Prolog programs are basically searches, they are tuned rather
the way database queries are, adjusting the order in which things are
searched and cutting off paths that will not yield anything as early as
possible.</p>
<p><strong>Examples</strong>. Prolog, Mercury, Kanren. The vast majority
of programming around this <em>ur</em>-language takes place in Prolog
itself — the community is impressively unified.</p>
<p><strong>History</strong>. In the 1970’s, logicians in France realized
that they could express programs in terms of first order logic, and
began trying to implement this. In the 1980’s the Japanese fifth
generation computer project bet heavily on Prolog, and when that project
failed, Prolog went down in reputation with it.</p>
<p>Meanwhile, decades of research continued into how to make Prolog
runtimes smart enough to be efficient in most cases and how to add new
capabilities, such as numerical constraints (yielding constraint logic
programming).</p>
<p>Prolog tends to show up in niches. Type checking for Java was for
many years implemented in Prolog, as was Facebook’s original source code
search tool.</p>
<h2 id="what-to-do-with-this">What to do with this</h2>
<p>For most programmers some or all of these will seem very exotic. It
is worth spending some time with each of them for the neural pathways
they will make you grow and the possibilities they introduce. Very often
two things that seems completely different when viewed through an ALGOL
lens turn into a trivial comparison seen through a different lens.</p>
<p>Every programmer needs to know a language in the ALGOL family well.
Once you do, then it’s worth branching out. Learning a new language that
traces to an unfamiliar <em>ur</em>-language each year will pay
dividends. The languages I would suggest today in each of these
families, and maybe in this order, are:</p>
<ul>
<li><strong>Lisp</strong>: PLT Racket</li>
<li><strong>ML</strong>: Haskell</li>
<li><strong>Self</strong>: Self</li>
<li><strong>Prolog</strong>: Prolog</li>
<li><strong>Forth</strong>: gForth<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
<li><strong>APL</strong>: K (via <a href="https://github.com/johnearnest/ok">ok</a>)</li>
</ul>
<p>If you do a lot of numerical work, learn J earlier. If you do lots of
embedded programming, learn gForth earlier. But the order is not
important, nor is the exact language. You could learn Standard ML or
OCaml instead of Haskell, Common Lisp instead of PLT Racket, and Factor
instead of gForth with absolute impunity.</p>


	  
	  <p>« Back to <a href="https://madhadron.com/programming/index.html">Programming</a> | <a href="https://madhadron.com/">Home</a></p>
	  	    
        </div></div>
  </body>
</html>
