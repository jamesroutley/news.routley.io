<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://broot.ca/kafka-at-the-low-end.html">Original</a>
    <h1>Kafka at the low end: how bad can it get?</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>There is oft-quoted advice that Kafka does poorly as a job queue. I’ve experienced
this myself, and I wanted to formalize it a bit.</p>

<p>I’ll use the common architecture of a Web application submitting
background jobs to workers via Kafka (for example, to generate a PDF of some
report).  Except for the use of Kafka in this role, this is common in Web
applications, and (speaking from experience!) when Kafka is already deployed,
there is an impulse to use it instead of deploying yet-another queue system.</p>

<p>Note: when <a href="https://www.confluent.io/blog/queues-on-kafka/">Queues for Kafka (KIP-932)</a> becomes
a thing, a lot of these concerns go away. I look forward to it!</p>

<p>What I want to characterize here is the worst-case “unfairness” of jobs being
assigned to workers. There are many other reasons to not use Kafka as a job
queue, but this unfairness is (in my view) the strongest reason. In most
queues, you put work into the queue and every worker… well, <em>works</em> until all
the work is done. It sound obvious, but that’s the raison d’être for these
things! When (mis-)using Kafka as a queue, this is not the case: work can get
unfairly assigned to one worker, even if other workers have nothing to do. So,
how many jobs can <em>one</em> worker be assigned, before <em>any other</em> worker is
given work? This can be worked out with this formula:</p>

<div><div><pre><code>WorstCaseJobsPerConsumer = (Partitions / Consumers) * Producers
</code></pre></div></div>

<p>To work an example, say you have a topic with 16 partitions, because you would like to
be able to scale up to 16 consumers at peak times, but, at your current load you only
predict you need 4 consumers processing jobs. Further, say you have 5 producers
(Web application servers, here - Gunicorn processes, Kubernetes pods, whatever)
that receive an API call and put a job onto this Kafka topic. Imagine these Web
workers are behind a load balancer which routes API calls in a round-robin
fashion to each of those 5 Web workers. Pretty typical architecture right?</p>

<p><img src="https://broot.ca/img/kafka.png"/></p>

<p>Plugging these numbers in, we get <code>(16 / 4) * 5 == 20</code>: that means, if you’re unlucky, the
next <em>20 jobs</em> coming along could <em>all</em> be routed to a single consumer, and that
consumer has to churn away at those 20 jobs while its 3 counterparts will sit idle. How this would
happen is by the following somewhat unlucky sequence of events:</p>

<ul>
  <li>Before any API calls are made, the 4 worker processes start up, and each take 4 of the 16 topic’s partitions, so that
the partitions are fairly shared.</li>
  <li>20 API calls are made by clients.</li>
  <li>The load balancer round-robins these 20 requests, giving 4 requests each to the 5 Web workers</li>
  <li>Each of these Web workers puts those 4 records onto 4 of the topic’s partitions in a round-robin fashion. And, because they
do not coordinate this, they might choose the same 4 partitions, which happen to all land on a single consumer.</li>
</ul>

<p>This exact sequence of events is rare, but milder variations of this happen
constantly when Kafka is used this way, at a low volume - such as only half, or
three-quarters of your workers being busy, while the remainder are idle <em>and
there’s work queued, just sitting there</em>.</p>

<p>To decide if this matters to your application, think about your peak periods
and how many jobs might be created in that period, and what the latency
expectations are for those jobs. If it’s a small internal application used by,
say, 15 users, and they all (in the same instant) request 1 job that takes 5
minutes to run, then those 15 jobs can land on the same consumer and the queue
takes 75 minutes to clear, leading to some of those users being very unhappy.
This doesn’t <em>always</em> happen, but it <em>can</em>.
On the other hand, if you have 200 users each requesting 1 job and those jobs
take 1 second to run, these 200 jobs will be much more fairly distributed and
all workers will be contributing to clearing that queue.  So where, exactly, is
this cutoff? As a rule of thumb, if you have <em>at least</em>
<code>WorstCaseJobsPerConsumer * Consumers</code> jobs in-flight in your peak period (in
the above example, this is <code>20 * 4 == 80 jobs</code>), then you can be sure that all
your workers are doing <em>some</em> work, because there are enough jobs to overcome
the aforementioned worst-case behaviour. If there are fewer jobs than this,
you run the risk that some workers will not be pulling their weight.</p>

<p>Please note that I’m completely ignoring varying job run times. That makes this
problem significantly worse, because again, work is assigned to workers on a
record-by-record basis, irrespective of how long those jobs take. A long job
will block a short job and there’s nothing you can do about it.</p>

<p>I am <em>not</em> trying to say Kafka is a bad tool - what I am saying is <em>it was not
designed for such a low volume</em>. It was designed for exactly the opposite
(millions or billions of records) where a conventional single-node message
broker <em>simply cannot keep up</em>. It strips away a lot of the <em>very useful</em>
features of these conventional brokers in order to go faster. If you don’t
<em>need</em> that speed, you are losing a lot in that trade-off!</p>

<p>In conclusion: the oft-quoted wisdom is right; Kafka is not a good job queue,
especially not at particularly low volumes, at least until <a href="https://www.confluent.io/blog/queues-on-kafka/">Queues for Kafka
(KIP-932)</a> comes along.</p>

</div></div>
  </body>
</html>
