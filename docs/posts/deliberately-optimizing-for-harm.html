<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.science.org/content/blog-post/deliberately-optimizing-harm">Original</a>
    <h1>Deliberately optimizing for harm</h1>
    
    <div id="readability-page-1" class="page"><article>
								<section>
									<p><a href="https://www.nature.com/articles/s42256-022-00465-9?fbclid=IwAR11_V1cd9SUxEvUfwrWMA7TUcroyYIY1nBDUL3KaS-8B4rG5MIqZCmjm0M">This new paper</a> is worrying but not surprising. It describes a recent effort to (mis)use computational drug design software (especially as applied to avoid compounds with predicted toxicity), flipping the signs to have the model generate the most toxic molecules it could come up with. This was part of a biannual conference in Switzerland that looks at the implication of new technologies on chemical and biological weapons threats, and the authors (from Collaboration Pharmaceuticals) were invited to present on how AI/ML approaches could be weaponized in these areas. They were clearly shaken by the experience:</p>
<p><em>The thought had never previously struck us. We were vaguely aware of security concerns around work with pathogens or toxic chemicals, but that did not relate to us; we primarily operate in a virtual setting. Our work is rooted in building machine learning models for therapeutic and toxic targets to better assist in the design of new molecules for drug discovery. We have spent decades using computers and AI to improve human health—not to degrade it. We were naive in thinking about the potential misuse of our trade, as our aim had always been to avoid molecular features that could interfere with the many different classes of proteins essential to human life. Even our projects on Ebola and neurotoxins, which could have sparked thoughts about the potential negative implications of our machine learning models, had not set our alarm bells ringing.</em></p>
<p><span>The effort used known LD<sub>50</sub> data to drive the modeling in the known &#34;nerve gas&#34; space, and it sppears to have worked very well. Relatively speaking, that is:</span></p>
<p><em>In less than 6 hours after starting on our in-house server, our model generated 40,000 molecules that scored within our desired threshold. In the process, the AI designed not only VX, but also many other known chemical warfare agents that we identified through visual confirmation with structures in public chemistry databases. Many new molecules were also designed that looked equally plausible. These new molecules were predicted to be more toxic, based on the predicted LD<sub>50</sub> values, than publicly known chemical warfare agents (Fig. <a href="https://www.nature.com/articles/s42256-022-00465-9#Fig1" data-track="click" data-track-label="link" data-track-action="figure anchor">1</a>). This was unexpected because the datasets we used for training the AI did not include these nerve agents. The virtual molecules even occupied a region of molecular property space that was entirely separate from the many thousands of molecules in the organism-specific LD<sub>50 </sub>model, which comprises mainly pesticides, environmental toxins and drugs (Fig. <a href="https://www.nature.com/articles/s42256-022-00465-9#Fig1" data-track="click" data-track-label="link" data-track-action="figure anchor">1</a>). By inverting the use of our machine learning models, we had transformed our innocuous generative model from a helpful tool of medicine to a generator of likely deadly molecules.</em></p>
<p><span>It would not surprise me if this modeling work uncovered a number of nondisclosed structures that have been quietly looked at in the past. It seems clear that there&#39;s a lot more structure-activity space in this area than has ever been declassified (the appearance of the &#34;Novichok&#34; compounds is one example of this). Now, keep in mind that we can&#39;t deliberately design our way to drugs so easily, so we won&#39;t be able to design horrible compounds in one shot, either. Just as there are considerations in drug discovery that narrow down these sorts of lead-generation efforts, there are such factors for chemical weapons: stability on storage, volatility (or lack of it), persistance in the environment, manufacturing concerns, etc. So it&#39;s not like all of these predicted highly toxic compounds would be militarily useful - but note that we&#39;re not just talking about state actors here. A big worry has always been homebrew types (as witness <a href="https://en.wikipedia.org/wiki/Aum_Shinrikyo">Aum Shinrikyo</a> and their 1995 nerve-gas release in the Tokyo subway system). As it happened, Aum was not particularly competent, but that shouldn&#39;t make any of us feel better, because someone else might be. That goes for the various <a href="https://www.science.org/content/blog-post/pipeline-222">garage-ricin incidents</a> over the years as well - ricin is (fortunately) not all that easy to turn into a weapon, and the people who try to do it are generally somewhat disconnected from reality (and also from technical proficiency).</span></p>
<p><span>But there&#39;s always that worrisome part of the Venn diagram where competence and evil intent overlap. It hit me in the aftermath of 9/11 (during that anthrax period) that I could personally think of a whole list of horrible possibilities for chemical and biological terrorism threats. I&#39;d never thought of such things, but a bit of sustained thought brought all sorts of stuff to mind. That must have been a similar feeling to what the authors of this paper experienced. And while I&#39;m fairly imaginative, I don&#39;t think I&#39;m particularly diabolical. What, I wondered, about people who are a bit of both?</span></p>
<p><span>As mentioned, I&#39;m not surprised at all that computational methods can point the way to such things, although I can see how the authors of this work found demonstrating this to be an unsettling experience. To be honest, I&#39;m not all that worried about new nerve agents, at least not compared to my level of worry about the existing ones for which there is already a wide base of knowledge. That is, I&#39;m not sure that anyone <em>needs</em> to deploy a new compound in order to wreak havoc - they can save themselves a lot of trouble by just making Sarin or VX, God help us. One factor (mentioned in the paper) is that new compounds and new routes might be able to circumvent chemical controls and watch lists, though. The paper discusses ethics training, international agreements and guidelines, pledges of responsibility and so on. That&#39;s all fine, but history demonstrates that anyone truly interested in using such things will care nothing for these constraints. I feel about these the way that I felt about the &#34;No First Use&#34; pledge on nuclear weapons - that it guaranteed that the world could only be blown up by a liar. Thin comfort.</span></p>
<p><span>So we should be vigilant about potential misuse of these technologies, but at the same time we shouldn&#39;t imagine that this will be enough. </span></p>
								</section>
							</article></div>
  </body>
</html>
