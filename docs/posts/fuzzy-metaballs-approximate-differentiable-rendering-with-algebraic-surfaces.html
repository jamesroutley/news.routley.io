<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://leonidk.github.io/fuzzy-metaballs/">Original</a>
    <h1>Fuzzy Metaballs: Approximate Differentiable Rendering with Algebraic Surfaces</h1>
    
    <div id="readability-page-1" class="page"><div>

		<!-- The Grid -->
		<div>

			<!-- paper container -->
			<div>
				

				

				<hr/>
				<div>
					<!--<img src="images/fig1.png" style="width:100%">-->

					<video controls="" autoplay="" loop="" playsinline="" muted="">
						<source src="videos/media1.mp4" type="video/mp4"/>
						Sorry, your browser doesn&#39;t support embedded videos.
					</video>
					<p><strong>Shape From Silhouette Reconstruction</strong> from a short cell phone video, showing reconstructed masks.</p>

				</div>
				<hr/>
				<p>
					<h2>Abstract</h2>
				</p>
				<p>Differentiable renderers provide a direct mathematical link between an object&#39;s 3D representation and images of that object. In this work, we develop an approximate differentiable renderer for a compact, interpretable representation, which we call Fuzzy Metaballs. Our approximate renderer focuses on rendering shapes via depth maps and silhouettes. It sacrifices fidelity for utility, producing fast runtimes and high-quality gradient information that can be used to solve vision tasks. Compared to mesh-based differentiable renderers, our method has forward passes that are 5x faster and backwards passes that are 30x faster. The depth maps and silhouette images generated by our method are smooth and defined everywhere. In our evaluation of differentiable renderers for pose estimation, we show that our method is the only one comparable to classic techniques. In shape from silhouette, our method performs well using only gradient descent and a per-pixel loss, without any surrogate losses or regularization. These reconstructions work well even on natural video sequences with segmentation artifacts.</p>
				<hr/>



				<p>
					<h2>Demo</h2>
				</p>
				<p><strong>Shape from Silhouette</strong>: using 32 random views and gradient descent optimization over a 400 parameter model. </p>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/sfs1.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/sfs2.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/sfs3.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>

				<hr/>
				<p><strong>Shape from Silhouette</strong>: <a href="https://ai.facebook.com/datasets/CO3D-dataset/">CO3D</a> sequences with noisy input masks. Optimization is about a minute on laptop CPU. </p>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/media8.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/media9.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>
				<video controls="" autoplay="" loop="" playsinline="" muted="">
					<source src="videos/media10.mp4" type="video/mp4"/>
					Sorry, your browser doesn&#39;t support embedded videos.
				</video>
				<hr/>
				<div>
					<h2>Pose Estimation Results</h2><p>
					Reported as the geometric mean of rotation and translation error. Results are mean ± interquartile range.
				</p></div>
				<table>
					<tbody><tr>
						<th></th>
						<th><b>Parameters</b></th>
						<th><b>Noise-Free Error</b></th>
						<th><b>Noisy Error</b></th>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td>Initialization</td>
						<td></td>
						<td>20.2 ± 18</td>
						<td>20.2 ± 18</td>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td>Pulsar</td>
						<td>1,200</td>
						<td>20.2 ± 18</td>
						<td>20.2 ± 18</td>
					</tr>
					<tr>
						<td>PyTorch3D Point Cloud</td>
						<td>1,200</td>
						<td>18.5 ± 16</td>
						<td>18.4 ± 16</td>
					</tr>
					<tr>
						<td>PyTorch3D SoftRas Mesh</td>
						<td>750</td>
						<td>14.9 ± 15</td>
						<td>17.0 ± 17</td>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td>Equal Fidelity ICP (Plane)</td>
						<td>1,200</td>
						<td>10.8 ± 12</td>
						<td>8.2 ± 3.3</td>
					</tr>
					<tr>
						<td>Equal Fidelity ICP (Point)</td>
						<td>1,200</td>
						<td>7.6 ± 9.9</td>
						<td>8.7 ± 6.6</td>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td>High Fidelity ICP (Plane)</td>
						<td>120,000</td>
						<td>8.2 ± 0.8</td>
						<td>8.0 ± 3.6</td>
					</tr>
					<tr>
						<td>High Fidelity ICP (Point)</td>
						<td>120,000</td>
						<td>6.2 ± 3.7</td>
						<td>6.8 ± 3.3</td>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td><b>Fuzzy Metaballs</b></td>
						<td><b>400</b></td>
						<td><b>4.0 ± 1.5</b></td>
						<td><b>4.2 ± 2.1</b></td>
					</tr>
				</tbody></table>

				<hr/>
				<div>
					<h2>Shape From Silhouette (SFS) Results</h2><p>
					Cross-entropy silhouette loss on 32 novel viwes for 10 sample models. Runtimes were the average per model on CPU. Results show μ ± σ.
				</p></div>
				<table>
					<tbody><tr>
						<th></th>
						<th><b>Time (s)</b></th>
						<th><b>Noise-Free Error</b></th>
						<th><b>Noisy Error</b></th>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td>Voxel Carving</td>
						<td>82</td>
						<td>0.31 ± 0.10</td>
						<td>1.12 ± 0.37</td>
					</tr>
					<tr>
						<td>PyTorch3D Point Cloud</td>
						<td>185</td>
						<td>0.08 ± 0.08</td>
						<td>0.10 ± 0.08</td>
					</tr>
					<tr>
						<td>PyTorch3D SoftRas Mesh</td>
						<td>3,008</td>
						<td>0.06 ± 0.05</td>
						<td>0.07 ± 0.05</td>
					</tr>


					<tr>
						<td>NeRF</td>
						<td>7,406</td>
						<td><b>0.03 ± 0.02</b></td>
						<td>0.062 ± 0.06</td>
					</tr>
					<tr>
						<td colspan="4"></td>
					</tr>
					<tr>
						<td><b>Fuzzy Metaballs</b></td>
						<td><b>68</b></td>
						<td>0.04 ± 0.02</td>
						<td><b>0.055 ± 0.02</b></td>
					</tr>
				</tbody></table>

				<hr/>
				<div>
					<p>
						<h2>Paper</h2>
					</p>
					
					<p><img src="https://leonidk.github.io/fuzzy-metaballs/images/page1.png"/>
					</p>
					<div>
						<p>
							Leonid Keselman and Martial Hebert
							<i>Approximate Differentiable Rendering with Algebraic Surfaces</i>
							ECCV 2022.
						</p>
						<h3>[<a href="https://arxiv.org/pdf/2207.10606.pdf">pdf</a>] [<a href="https://leonidk.github.io/fuzzy-metaballs/bib.txt">bibtex</a>] [<a href="https://www.youtube.com/watch?v=Ec7cxEc9eOU">video</a>]</h3>
					</div>
					
				</div>
				<hr/>
			</div>
			<!-- end paper container -->

		</div><!-- End Grid -->
	</div></div>
  </body>
</html>
