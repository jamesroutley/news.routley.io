<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/huggingface/text-generation-inference/issues/726">Original</a>
    <h1>HuggingFace Text Generation License No Longer Open-Source</h1>
    
    <div id="readability-page-1" class="page"><div disabled="" sortable="">
<div>
          <p dir="auto"><a href="https://github.com/huggingface/text-generation-inference">Text-Generation-Inference</a>, aka TGI, is a project we started earlier this year to power optimized inference of Large Language Models, as an internal tool to power LLM inference on the <a href="https://huggingface.co/docs/api-inference/index" rel="nofollow">Hugging Face Inference API</a> and later <a href="https://huggingface.co/chat/" rel="nofollow">Hugging Chat</a>. Since then it has become a crucial component of our commercial products (like <a href="https://huggingface.co/blog/inference-endpoints-llm" rel="nofollow">Inference Endpoints</a>) and that of our commercial partners, like <a href="https://www.philschmid.de/sagemaker-falcon-llm" rel="nofollow">Amazon SageMaker</a>,<a href="https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/falcon-llms-in-azure-machine-learning/ba-p/3876847" rel="nofollow"> Azure Machine Learning</a> and <a href="https://huggingface.co/blog/huggingface-and-ibm" rel="nofollow">IBM watsonx</a>. At the same time, the project quickly grew in popularity and was adopted by other open source projects like <a href="https://open-assistant.io/" rel="nofollow">Open-Assistant</a> and nat.dev.</p>
<h2 dir="auto">TGI v1.0 new license: HFOIL 1.0</h2>
<p dir="auto">We are releasing TGI v1.0 under a new license: HFOIL 1.0.</p>
<p dir="auto">HFOIL stands for Hugging Face Optimized Inference License, and it has been specifically designed for our optimized inference solutions. While the source code remains accessible, HFOIL is not a true open source license because we added a restriction: to sell a hosted or managed service built on top of TGI, we now require a separate agreement.</p>
<h2 dir="auto">What does this mean for you?</h2>
<p dir="auto">This change in source code licensing <strong>has no impact on the overwhelming majority of our user community</strong> who use TGI for free. Additionally, both our Inference Endpoint customers and those of our commercial partners will also remain unaffected.</p>
<p dir="auto">However, it will restrict non-partnered cloud service providers from offering TGI v1.0+ as a service without requesting a license.</p>
<p dir="auto">To elaborate further:</p>
<ul dir="auto">
<li>
<p dir="auto">If you are an existing user of TGI prior to v1.0, your current version is still <strong>Apache 2.0</strong> and <strong>you can use it commercially without restrictions</strong>.</p>
</li>
<li>
<p dir="auto">If you are using TGI for personal use or research purposes, <strong>the HFOIL 1.0 restrictions do not apply to you.</strong></p>
</li>
<li>
<p dir="auto">If you are using TGI for commercial purposes as part of an internal company project (that will not be sold to third parties as a hosted or managed service), <strong>the HFOIL 1.0 restrictions do not apply to you.</strong></p>
</li>
<li>
<p dir="auto">If you integrate TGI into a hosted or managed service that you sell to customers, then consider requesting a license to upgrade to v1.0 and later versions - you can email us at <a href="mailto:api-enterprise@huggingface.co">api-enterprise@huggingface.co</a> with information about your service.</p>
</li>
</ul>
<h2 dir="auto">Why the new license?</h2>
<p dir="auto">TGI started as a project to power our internal products, and we see it as a critical component of our commercial solutions. TGI is not meant as a community-driven project, but as a production solution thatâ€™s widely accessible to the community. We want to continue building TGI in the open, and will continue to welcome contributions. But unlike community-driven projects like <a href="https://github.com/huggingface/transformers">Transformers</a> and <a href="https://github.com/huggingface/diffusers">Diffusers</a> focused on making machine learning accessible, TGI is focused on performance and robustness in production contexts, with the goal of building commercial products.</p>
<h2 dir="auto">What about Hugging Face contributions to open source?</h2>
<p dir="auto">Our mission as a company is to democratize good machine learning. An important component of democratization is making good machine learning more accessible. We achieve this through community-driven open source projects like Transformers, Diffusers, Datasets, our free courses (Transformers, Diffusers Audio, RL), and <a href="https://github.com/huggingface/">many more libraries</a> collectively garnering about <a href="https://gitstar-ranking.com/organizations" rel="nofollow">240k GitHub stars as of this writing</a>. Our long term commitment to open source has not changed.</p>
      </div>
</div></div>
  </body>
</html>
