<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/amakelov/mandala">Original</a>
    <h1>Show HN: Mandala â€“ Automatically save, query and version Python computations</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto"><code>mandala</code> eliminates the effort and code overhead of ML experiment tracking (and
beyond) with two generic tools:</p>
<ol dir="auto">
<li>The <code>@op</code> decorator:
<ul dir="auto">
<li><strong>captures inputs, outputs and code (+dependencies)</strong> of Python
function calls</li>
<li>automatically reuses past results &amp; <strong>never computes the same call twice</strong></li>
<li><strong>designed to be composed</strong> into end-to-end persisted programs, enabling
efficient iterative development in plain-Python, without thinking about the
storage backend.</li>
</ul>
</li>
</ol>
<markdown-accessiblity-table><table>
  <tbody><tr>
    <td>
      <ol start="2" dir="auto">
    <li>
        The <a href="https://amakelov.github.io/mandala/blog/01_cf/" rel="nofollow">ComputationFrame</a> data structure:
        <ul dir="auto">
        <li>
            <strong>automatically organizes executions of imperative
            code</strong> into a high-level computation graph of variables and
            operations. Detects patterns like feedback loops, branching/merging
            and aggregation/indexing
        </li>
        <li>
            <strong>queries relationships between variables</strong> by extracting a dataframe where columns are variables and operations in the graph, and each row contains values/calls of a (possibly partial) execution of the graph
        </li>
        <li>
            <strong>automates exploration and high-level operations</strong> over heterogeneous &#34;webs&#34; of <code>@op</code> calls
        </li>
        </ul>
    </li>
    </ol>
    </td>
    <td><a target="_blank" rel="noopener noreferrer" href="https://github.com/amakelov/mandala/blob/master/output.svg"><img src="https://github.com/amakelov/mandala/raw/master/output.svg" alt="Description" width="2000"/></a></td>
  </tr>
</tbody></table></markdown-accessiblity-table>

<p dir="auto">A quick demo of running computations in <code>mandala</code> and simultaneously updating a view of the corresponding <code>ComputationFrame</code> and the dataframe extracted from it (code can
be found <a href="https://github.com/amakelov/mandala/blob/master/_demos/cf_vid.ipynb">here</a>):</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description output.mp4">output.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1467702/347620677-85185599-10fb-479e-bf02-442873732906.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA4MDQ3NTMsIm5iZiI6MTcyMDgwNDQ1MywicGF0aCI6Ii8xNDY3NzAyLzM0NzYyMDY3Ny04NTE4NTU5OS0xMGZiLTQ3OWUtYmYwMi00NDI4NzM3MzI5MDYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDcxMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA3MTJUMTcxNDEzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWE4MDE2Zjc3MjI3ZGJhZTMzZTgyOTA4OGUxODg2Njk0ZWY2ZDUxZTc5NzFmMGYzZWE4ZWJmNGIzYTU5MTBhNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.JYe7YaKLmEPjjkNDKsA4IgtyTC5L_Tsw3fOrB2FGDeA" data-canonical-src="https://private-user-images.githubusercontent.com/1467702/347620677-85185599-10fb-479e-bf02-442873732906.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA4MDQ3NTMsIm5iZiI6MTcyMDgwNDQ1MywicGF0aCI6Ii8xNDY3NzAyLzM0NzYyMDY3Ny04NTE4NTU5OS0xMGZiLTQ3OWUtYmYwMi00NDI4NzM3MzI5MDYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDcxMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA3MTJUMTcxNDEzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWE4MDE2Zjc3MjI3ZGJhZTMzZTgyOTA4OGUxODg2Njk0ZWY2ZDUxZTc5NzFmMGYzZWE4ZWJmNGIzYTU5MTBhNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.JYe7YaKLmEPjjkNDKsA4IgtyTC5L_Tsw3fOrB2FGDeA" controls="controls" muted="muted">

  </video>
</details>


<div data-snippet-clipboard-copy-content="pip install git+https://github.com/amakelov/mandala"><pre><code>pip install git+https://github.com/amakelov/mandala
</code></pre></div>



<ul dir="auto">
<li><a href="https://amakelov.github.io/mandala/blog/01_cf/" rel="nofollow">Tidy Computations</a>: introduces
the <code>ComputationFrame</code> data structure and its applications</li>
<li><a href="https://amakelov.github.io/blog/deps/" rel="nofollow">Practical Dependency Tracking for Python Function
Calls</a>: describes the motivations and designs behind <code>mandala</code>&#39;s dependency tracking system</li>
<li>The <a href="https://amakelov.github.io/scipy-mandala.pdf" rel="nofollow">paper</a>, which is to
appear in the SciPy 2024 proceedings.</li>
</ul>

<div dir="auto"><h2 tabindex="-1" dir="auto">How is this different from other experiment tracking frameworks?</h2><a id="user-content-how-is-this-different-from-other-experiment-tracking-frameworks" aria-label="Permalink: How is this different from other experiment tracking frameworks?" href="#how-is-this-different-from-other-experiment-tracking-frameworks"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Compared to popular tools like W&amp;B, MLFlow or Comet, <code>mandala</code>:</p>
<ul dir="auto">
<li><strong>is integrated with the actual Python code execution on a more granular
level</strong>
<ul dir="auto">
<li>the function call is the synchronized unit of persistence, versioning and
querying, as opposed to an entire script or notebook, leading to more
efficient reuse and incremental development.</li>
<li>going even further, Python collections (e.g. <code>list, dict</code>) can be made
transparent to the storage system, so that individual elements are stored
and tracked separately and can be reused across collections and calls.</li>
<li>since it&#39;s memoization-based as opposed to logging-based, you don&#39;t have
to think about how to name any of the things you log.</li>
</ul>
</li>
<li><strong>provides the <code>ComputationFrame</code> data structure</strong>, a powerful &amp; simple way to
represent, query and manipulate complex saved computations.</li>
<li><strong>automatically resolves the version of every <code>@op</code> call</strong> from the current
state of the codebase and the inputs to the call.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">How is the <code>@op</code> cache invalidated?</h2><a id="user-content-how-is-the-op-cache-invalidated" aria-label="Permalink: How is the @op cache invalidated?" href="#how-is-the-op-cache-invalidated"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>given inputs for a call to an <code>@op</code>, e.g. <code>f</code>, it searches for a past call
to <code>f</code> on inputs with the same contents (as determined by a hash function) where the dependencies accessed by this call (including <code>f</code>
itself) have versions compatible with their current state.</li>
<li>compatibility between versions of a function is decided by the user: you
have the freedom to mark certain changes as compatible with past results, though
see the <a href="#limitations">limitations</a> about marking changes as compatible.</li>
<li>internally, <code>mandala</code> uses slightly modified <code>joblib</code> hashing to compute a
content hash for Python objects. This is practical for many use cases, but
not perfect, as discussed in the <a href="#limitations">limitations</a> section.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">Can I change the code of <code>@op</code>s, and what happens if I do?</h2><a id="user-content-can-i-change-the-code-of-ops-and-what-happens-if-i-do" aria-label="Permalink: Can I change the code of @ops, and what happens if I do?" href="#can-i-change-the-code-of-ops-and-what-happens-if-i-do"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>a frequent use case: you have some <code>@op</code> you&#39;ve been using, then want to
extend its functionality in a way that doesn&#39;t invalidate the past results.
The recommended way is to add a new argument <code>a</code>, and provide a default
value for it wrapped with <code>NewArgDefault(x)</code>. When a value equal to <code>x</code> is
passed for this argument, the storage falls back on calls before</li>
</ul>

<ul dir="auto">
<li><code>mandala</code> is in alpha, and the API is subject to change.</li>
<li>moreover, there are known performance bottlenecks that may make working with
storages of 10k+ calls slow.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">How self-contained is it?</h2><a id="user-content-how-self-contained-is-it" aria-label="Permalink: How self-contained is it?" href="#how-self-contained-is-it"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><code>mandala</code>&#39;s core is a few kLoCs and only depends on <code>pandas</code> and <code>joblib</code>.</li>
<li>for visualization of <code>ComputationFrame</code>s, you should have <code>dot</code> installed
on the system level, and/or the Python <code>graphviz</code> library installed.</li>
</ul>

<ul dir="auto">
<li>When using versioning and you mark a change as compatible with past results,
you should be careful if the change introduced new dependencies that are not
tracked by <code>mandala</code>. Changes to such &#34;invisible&#34; dependencies may remain
unnoticed by the storage system, leading you to believe that certain results
are up to date when they are not.</li>
<li>See the &#34;gotchas&#34; notebook for some limitations of the hashing used to invalidate the cache: <a href="https://colab.research.google.com/github/amakelov/mandala/blob/master/docs_source/tutorials/gotchas.ipynb" rel="nofollow">
<img src="https://camo.githubusercontent.com/f5e0d0538a9c2972b5d413e0ace04cecd8efd828d133133933dfffec282a4e1b/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"/> </a></li>
</ul>

<p dir="auto"><strong>Overall</strong></p>
<ul>
<li> support for named outputs in <code>@op</code>s</li>
<li> support for renaming <code>@op</code>s and their inputs/outputs</li>
</ul>
<p dir="auto"><strong>Memoization</strong></p>
<ul>
<li> add custom serialization for chosen objects</li>
<li> figure out a solution that ignores small numerical error in content hashing</li>
<li> improve the documentation on collections</li>
<li> support parallelization of <code>@op</code> execution via e.g. <code>dask</code> or <code>ray</code></li>
<li> support for inputs/outputs to exclude from the storage</li>
</ul>
<p dir="auto"><strong>Computation frames</strong></p>
<ul>
<li> add support for cycles in the computation graph</li>
<li> improve heuristics for the <code>expand_...</code> methods</li>
<li> add tools for restricting a CF to specific subsets of variable values via predicates</li>
<li> improve support &amp; examples for using collections</li>
<li> add support for merging or splitting nodes in the CF and similar simplifications</li>
</ul>
<p dir="auto"><strong>Versioning</strong></p>
<ul>
<li> support restricting CFs by function versions</li>
<li> support ways to manually add dependencies to versions in order to avoid the &#34;invisible dependency&#34; problem</li>
</ul>
<p dir="auto"><strong>Performance</strong></p>
<ul>
<li> improve performance of the in-memory cache</li>
<li> improve performance of <code>ComputationFrame</code> operations</li>
</ul>

<p dir="auto">Aspirationally, <code>mandala</code> is about much more than ML experiment tracking. The
main goal is to <strong>make persistence logic &amp; best practices a natural extension of Python</strong>.
Once this is achieved, the purely &#34;computational&#34; code you must write anyway
doubles as a storage interface. It&#39;s hard to think of a simpler and more
reliable way to manage computational artifacts.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">A first-principles approach to managing computational artifacts</h2><a id="user-content-a-first-principles-approach-to-managing-computational-artifacts" aria-label="Permalink: A first-principles approach to managing computational artifacts" href="#a-first-principles-approach-to-managing-computational-artifacts"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">What we want from our storage are ways to</p>
<ul dir="auto">
<li>refer to artifacts with short, unambiguous descriptions: &#34;here&#39;s [big messy Python object] I computed, which to me
means [human-readable description]&#34;</li>
<li>save artifacts: &#34;save [big messy Python object]&#34;</li>
<li>refer to artifacts and load them at a later time: &#34;give me [human-readable description] that I computed before&#34;</li>
<li>know when you&#39;ve already computed something: &#34;have I computed [human-readable description]?&#34;</li>
<li>query results in more complicated ways: &#34;give me all the things that satisfy
[higher-level human-readable description]&#34;, which in practice means some
predicate over combinations of artifacts.</li>
<li>get a report of how artifacts were generated: &#34;what code went into [human-readable description]?&#34;</li>
</ul>
<p dir="auto">The key observation is that <strong>execution traces</strong> can already answer ~all of
these questions.</p>

<p dir="auto"><code>mandala</code> combines ideas from, and shares similarities with, many technologies.
Here are some useful points of comparison:</p>
<ul dir="auto">
<li><strong>memoization</strong>:
<ul dir="auto">
<li>standard Python memoization solutions are <a href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html" rel="nofollow"><code>joblib.Memory</code></a>
and
<a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow"><code>functools.lru_cache</code></a>.
<code>mandala</code> uses <code>joblib</code> serialization and hashing under the hood.</li>
<li><a href="https://github.com/pajju/IncPy"><code>incpy</code></a> is a project that integrates
memoization with the python interpreter itself.</li>
<li><a href="https://github.com/aspuru-guzik-group/funsies"><code>funsies</code></a> is a
memoization-based distributed workflow executor that uses an analogous notion
of hashing to <code>mandala</code> to keep track of which computations have already been done. It
works on the level of scripts (not functions), and lacks queriability and
versioning.</li>
<li><a href="https://arxiv.org/abs/1901.01908" rel="nofollow"><code>koji</code></a> is a design for an incremental
computation data processing framework that unifies over different resource
types (files or services). It also uses an analogous notion of hashing to
keep track of computations.</li>
</ul>
</li>
<li><strong>computation frames</strong>:
<ul dir="auto">
<li>computation frames are special cases of <a href="https://en.wikipedia.org/wiki/Relational_database" rel="nofollow">relational
databases</a>: each function
node in the computation graph has a table of calls, where columns are all the
input/output edge labels connected to the function. Similarly, each variable
node is a single-column table of all the <code>Ref</code>s in the variable. Foreign key
constraints relate the functions&#39; columns to the variables, and various joins
over the tables express various notions of joint computational history of
variables.</li>
<li>computation frames are also related to <a href="https://en.wikipedia.org/wiki/Graph_database" rel="nofollow">graph
databases</a>, in the sense that
some of the relevant queries over computation frames, e.g. ones having to do
with reachability along <code>@op</code>s, are special cases of queries over graph
databases. The internal representation of the <code>Storage</code> is also closer to
a graph database than a relational one.</li>
<li>computation frames are also related to some ideas from applied <a href="https://en.wikipedia.org/wiki/Category_theory" rel="nofollow">category
theory</a>, such as using functors
from a finite category to the category of sets (<em>copresheaves</em>) as a blueprint
for a &#34;universal&#34; in-memory data structure that is (again) equivalent to a
relational database; see e.g.  <a href="https://compositionality-journal.org/papers/compositionality-4-5/" rel="nofollow">this
paper</a>,
which describes this categorical construction.</li>
</ul>
</li>
<li><strong>versioning</strong>:
<ul dir="auto">
<li>the revision history of each function in the codebase is organized in a &#34;mini-<a href="https://git-scm.com/" rel="nofollow"><code>git</code></a> repository&#34; that shares only the most basic
features with <code>git</code>: it is a
<a href="https://en.wikipedia.org/wiki/Content-addressable_storage" rel="nofollow">content-addressable</a>
tree, where each edge tracks a diff from the content at one endpoint to that
at the other. Additional metadata indicates equivalence classes of
semantically equivalent contents.</li>
<li><a href="https://semver.org/" rel="nofollow">semantic versioning</a> is another popular code
versioning system. <code>mandala</code> is similar to <code>semver</code> in that it allows you to
make backward-compatible changes to the interface and logic of dependencies.
It is different in that versions are still labeled by content, instead of by
&#34;non-canonical&#34; numbers.</li>
<li>the <a href="https://www.unison-lang.org/learn/the-big-idea/" rel="nofollow">unison programming language</a> represents
functions by the hash of their content (syntax tree, to be exact).</li>
</ul>
</li>
</ul>
</article></div></div>
  </body>
</html>
