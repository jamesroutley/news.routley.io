<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://words.filippo.io/dispatches/kyber-math/">Original</a>
    <h1>Enough polynomials and linear algebra to implement Kyber</h1>
    
    <div id="readability-page-1" class="page"><article>
        <span>
            <time datetime="2023-11-07">07 Nov 2023</time>
        </span>
        
        <section>
            <p>I was once talking with a mathematician and trying to explain elliptic curve cryptography. Eventually, something clicked and they went &#34;oh, that! I think there was a chapter about it in the book. You made a whole field out of it?&#34;</p>
<p>Yes, in cryptography we end up focusing on a very narrow slice of the general math we use. I think that&#39;s good, and makes for good engineering, because we need to make computer programs that are <em>very good</em> at the thing they do, and it being narrow enough lets us get decently good at it.</p>
<p>Anyway, over the years of implementing RSA and elliptic curves, we collectively learned quite a bit about modular arithmetic, large finite fields, and group logic. We did it wrong for many years, and now I think we mostly know how to do it right.</p>
<p>Except now the post-quantum algorithms are coming, and they use lattices and matrices and polynomials. So, how much linear algebra and polynomial algebra do you need to know to implement these post-quantum cryptography primitives? Turns out, surprisingly little! The word “lattice” doesn’t even show up in the spec except in the name.</p>
<p>If you want to learn math, this is not the article for you. If you want to implement ML-KEM (FIPS 203, formerly known as Kyber), you&#39;re about to be all set.</p>
<p>Note that all this is explained pretty clearly and in more detail in Section 2.4 of FIPS 203 (DRAFT). The FIPS spec actually does a great job of avoiding formalisms and speaking to engineers. Consider this a friendlier, even more pragmatic summary.</p>
<h2 id="polynomials">Polynomials</h2>
<p>A polynomial is an element of the ring <math><semantics><msub><mi>R</mi><mi>q</mi></msub><annotation encoding="application/x-tex">R_q</annotation></semantics></math> and looks like this</p>
<p><math display="block"><semantics><mrow><mi>f</mi><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><mo>+</mo><msub><mi>f</mi><mn>1</mn></msub><mi>X</mi><mo>+</mo><msub><mi>f</mi><mn>2</mn></msub><msup><mi>X</mi><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>f</mi><mn>255</mn></msub><msup><mi>X</mi><mn>255</mn></msup></mrow><annotation encoding="application/x-tex">f = f_0 + f_1X + f_2X^2 + \dots + f_{255}X^{255}</annotation></semantics></math></p>
<p>but you don’t even need to know that. As far as you’re concerned as an implementor, an ML-KEM polynomial is an array of 256 coefficients. Each coefficient is an integer modulo <math><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>, where <math><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> is 3329. An array of coefficients is said to be in <math><semantics><msubsup><mi>ℤ</mi><mi>q</mi><mn>256</mn></msubsup><annotation encoding="application/x-tex">\mathbb{Z}^{256}_q</annotation></semantics></math> because it’s made of 256 coefficients, each in <math><semantics><msub><mi>ℤ</mi><mi>q</mi></msub><annotation encoding="application/x-tex">\mathbb{Z}_q</annotation></semantics></math>, the integers modulo <math><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>.</p>
<p><math display="block"><semantics><mtable displaystyle="true" columnalign="left center right"><mtr><mtd></mtd><mtd><mrow><mrow></mrow><msub><mi>f</mi><mn>0</mn></msub><mo>+</mo><msub><mi>f</mi><mn>1</mn></msub><mi>X</mi><mo>+</mo><msub><mi>f</mi><mn>2</mn></msub><msup><mi>X</mi><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>f</mi><mn>255</mn></msub><msup><mi>X</mi><mn>255</mn></msup><mo>∈</mo><msub><mi>R</mi><mi>q</mi></msub></mrow></mtd><mtd><mtext></mtext></mtd></mtr><mtr><mtd></mtd><mtd><mrow><mrow></mrow><mo stretchy="false">↓</mo></mrow></mtd><mtd><mtext></mtext></mtd></mtr><mtr><mtd></mtd><mtd><mrow><mrow></mrow><mo form="prefix" stretchy="false">(</mo><msub><mi>f</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>f</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>f</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>f</mi><mn>255</mn></msub><mo form="postfix" stretchy="false">)</mo><mo>∈</mo><msubsup><mi>ℤ</mi><mi>q</mi><mn>256</mn></msubsup></mrow></mtd><mtd><mtext></mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{gather}
\nonumber f_0 + f_1X + f_2X^2 + \dots + f_{255}X^{255} \in R_q
\\
\nonumber \downarrow
\\
\nonumber (f_0, f_1, f_2, \dots, f_{255}) \in \mathbb{Z}^{256}_q
\end{gather}</annotation></semantics></math></p>
<p>Each coefficient fits in a uint16, so you can write a type for a polynomial like <code>[256]uint16</code>.</p>
<p>To add or subtract two polynomials (or ring elements) you go coefficient by coefficient (<code>c[0] = a[0] + b[0]</code>, and so on). You never multiply ring elements directly in ML-KEM.</p>
<h3 id="modular-arithmetic">Modular arithmetic</h3>
<p>As we said, each coefficient is an integer modulo 3329, so while it fits in a uint16, you do need to apply the right constant-time modular arithmetic to it.</p>
<p>You might be used to doing limb-based modular arithmetic for very large moduli. This is analogous but much easier because the field size is just 12 bits.</p>
<p>For addition and subtraction, you do a classic conditional subtraction. You will find the conditional subtraction useful for ByteDecode₁₂, too.</p>
<p>Multiplication fits in a uint32. Then you have a choice of Montgomery or <a href="https://www.nayuki.io/page/barrett-reduction-algorithm?ref=words.filippo.io">Barrett reduction</a>. I find Barrett simpler and fast enough. (Note that the inner product of the Barrett reduction is 37 bits, so you need a uint64 intermediate value. Ask me how I know!) You can’t use <code>%</code> because division is not always constant time in hardware.</p>
<p>The field is so small that you can exhaustively test your add, subtract, and multiply implementations in a fraction of a second. Do that.</p>
<h3 id="ntt">NTT</h3>
<p>One of the scariest-sounding parts of the ML-KEM specification is the <em>Number-Theoretic Transform</em>. Good news, you don’t need to understand this one either.</p>
<p>What you need to know is that it’s a different way to represent a polynomial. Each polynomial, or element of <math><semantics><msub><mi>R</mi><mi>q</mi></msub><annotation encoding="application/x-tex">R_q</annotation></semantics></math>, can be mapped to an element of <math><semantics><msub><mi>T</mi><mi>q</mi></msub><annotation encoding="application/x-tex">T_q</annotation></semantics></math> (the NTT domain) and back. The function doing the mapping is called the NTT, and the one mapping back is the inverse NTT (or NTT⁻¹). An element of <math><semantics><msub><mi>T</mi><mi>q</mi></msub><annotation encoding="application/x-tex">T_q</annotation></semantics></math> is called an “NTT representative”, is denoted by a letter with a hat like <math><semantics><mover><mi>f</mi><mo stretchy="false">^</mo></mover><annotation encoding="application/x-tex">\hat{f}</annotation></semantics></math>, and is stored just like a polynomial: as 256 integers modulo <math><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>.</p>
<p>Technically, an NTT representative is a sequence of 128 polynomials each of them with two coefficients, but you don’t need to think about that and you can represent both elements in <math><semantics><msub><mi>R</mi><mi>q</mi></msub><annotation encoding="application/x-tex">R_q</annotation></semantics></math> and in <math><semantics><msub><mi>T</mi><mi>q</mi></msub><annotation encoding="application/x-tex">T_q</annotation></semantics></math> with the same data structure, such as <code>[256]uint16</code>. Still, it would be a good idea to assign them separate types in your type system so you don’t mix them up.</p>
<p>If you used Montgomery reduction and the Montgomery domain before, you’re already familiar with the concept of mapping values to a different domain where some operation (again multiplication) is faster. Just like with the Montgomery domain, the data structure you use to represent elements is the same in and out of the domain, but they have semantically different types.</p>
<p>You can implement both NTT and NTT⁻¹ without understanding the math behind them. Note that there is a complicated term in NTT and NTT⁻¹ called <em>zeta</em>. You’re expected to precompute that for its 128 possible values.</p>
<p>Addition and subtraction of NTT representatives works the same as with polynomials. You just can’t mix and match them. (If you have a weak type system or generics, you can literally use the same functions.)</p>
<p>The whole reason to have the NTT is that multiplication is faster in the NTT domain. Indeed, there’s a MultiplyNTTs algorithm that you can blindly implement. It has a <math><semantics><mi>γ</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math> term that you’re expected to precompute like the <em>zeta</em> of NTT.</p>
<p>ML-KEM is special in that the NTT is part of the wire format, not just a behind-the-scenes optimization, because encryption and decryption keys are serialized and deserialized directly in their NTT representation.</p>
<h2 id="matrices-and-vectors">Matrices and vectors</h2>
<p>Aside from coefficients, polynomials, and NTT representatives, the other main types you need to deal with are vectors and matrices.</p>
<p>A vector is, for our purposes, an array of <math><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> elements of <math><semantics><msub><mi>R</mi><mi>q</mi></msub><annotation encoding="application/x-tex">R_q</annotation></semantics></math> or <math><semantics><msub><mi>T</mi><mi>q</mi></msub><annotation encoding="application/x-tex">T_q</annotation></semantics></math>. <math><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> is 2, 3, or 4 depending on the parameter set. You can represent a vector as a <code>[k][256]uint16</code>. Vectors are denoted by bold lowercase letters like <math><semantics><mi>𝐯</mi><annotation encoding="application/x-tex">\mathbf{v}</annotation></semantics></math> or <math><semantics><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover><annotation encoding="application/x-tex">\mathbf{\hat{v}}</annotation></semantics></math>.</p>
<p><math display="block"><semantics><mrow><mi>𝐯</mi><mo>=</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center"><mtr><mtd><msub><mi>v</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><msub><mi>v</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><mrow><mi>⋮</mi><mspace width="0pt" height="14.944pt"></mspace></mrow></mtd></mtr><mtr><mtd><msub><mi>v</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{v} = \begin{bmatrix}
    v_0 \\
    v_1 \\
    \vdots \\
    v_{k-1}
\end{bmatrix}</annotation></semantics></math></p>
<p>Vectors are a special case of a <math><semantics><mrow><mi>k</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k \times 1</annotation></semantics></math> matrix. That’s <math><semantics><mrow><mtext>rows</mtext><mo>×</mo><mtext>columns</mtext></mrow><annotation encoding="application/x-tex">\text{rows} \times \text{columns}</annotation></semantics></math>, so a vector is a matrix with <math><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> rows and one column. The only other matrix we encounter is <math><semantics><mi>𝐀</mi><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math>, which is a <math><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k \times k</annotation></semantics></math> matrix. I recommend storing it in a <code>[k*k][256]uint16</code> array, rather than <code>[k][k][256]uint16</code>, because the latter leads to indexing like <code>A[column][row]</code> to be consistent with the vector type, which is backwards compared to the notation <math><semantics><mrow><mi>𝐀</mi><mo form="prefix" stretchy="false">[</mo><mtext>row</mtext><mo separator="true">,</mo><mtext>column</mtext><mo form="postfix" stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{A}[\text{row}, \text{column}]</annotation></semantics></math>.</p>
<p><math display="block"><semantics><mrow><mi>𝐀</mi><mo>=</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center center center center"><mtr><mtd><msub><mi>a</mi><mn>0,0</mn></msub></mtd><mtd><msub><mi>a</mi><mn>0,1</mn></msub></mtd><mtd><mo lspace="0em" rspace="0em">…</mo></mtd><mtd><msub><mi>a</mi><mrow><mn>0</mn><mo separator="true">,</mo><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>a</mi><mn>1,0</mn></msub></mtd><mtd><msub><mi>a</mi><mn>1,1</mn></msub></mtd><mtd><mo lspace="0em" rspace="0em">…</mo></mtd><mtd><msub><mi>a</mi><mrow><mn>1</mn><mo separator="true">,</mo><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mrow><mi>⋮</mi><mspace width="0pt" height="14.944pt"></mspace></mrow></mtd><mtd><mrow><mi>⋮</mi><mspace width="0pt" height="14.944pt"></mspace></mrow></mtd><mtd><mo lspace="0em" rspace="0em">⋱</mo></mtd><mtd><mrow><mi>⋮</mi><mspace width="0pt" height="14.944pt"></mspace></mrow></mtd></mtr><mtr><mtd><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>1,0</mn></mrow></msub></mtd><mtd><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>1,1</mn></mrow></msub></mtd><mtd><mo lspace="0em" rspace="0em">…</mo></mtd><mtd><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{A} = \begin{bmatrix}
    a_{0,0} &amp; a_{0,1} &amp; \dots &amp; a_{0,k-1} \\
    a_{1,0} &amp; a_{1,1} &amp; \dots &amp; a_{1,k-1} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    a_{k-1,0} &amp; a_{k-1,1} &amp; \dots &amp; a_{k-1,k-1} \\
\end{bmatrix}</annotation></semantics></math></p>
<p>Applying a function like NTT or ByteEncode to a vector or a matrix just applies it to every element.</p>
<p>Vector addition is coordinate-wise (<code>c[0] = a[0] + b[0]</code>, and so on).</p>
<p>There are only two kinds of matrix multiplications in ML-KEM: matrix by vector (<math><semantics><mrow><mover><mi>𝐀</mi><mo stretchy="false">^</mo></mover><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{\hat{A}} \circ \mathbf{\hat{v}}</annotation></semantics></math>), and transposed vector by vector (<math><semantics><mrow><msup><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover><mo>⊺</mo></msup><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{\hat{v}^\intercal} \circ \mathbf{\hat{v}}</annotation></semantics></math>). They might look intimidating but they are both very simple. (They all have hats because as mentioned in the NTT section, we only do multiplications in the NTT domain.)</p>
<p>I’m not going to do a better job of explaining the general concept of matrix multiplication and dot product than <a href="https://www.mathsisfun.com/algebra/matrix-multiplying.html?ref=words.filippo.io">other online resources</a>, but I’ll tell you how it works in the two cases you’ll encounter. The rule to keep in mind is that the result of multiplying two matricies is another matrix. More specifically, the result of multiplication of a matrix <math><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math> by a matrix <math><semantics><mrow><mi>n</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">n \times p</annotation></semantics></math> is a matrix of dimensions <math><semantics><mrow><mi>m</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">m \times p</annotation></semantics></math>.</p>
<p>Matrix by vector multiplication (<math><semantics><mrow><mover><mi>𝐀</mi><mo stretchy="false">^</mo></mover><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{\hat{A}} \circ \mathbf{\hat{v}}</annotation></semantics></math>, also known as transforming a vector by a matrix) is <math><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi><mo>∘</mo><mi>k</mi><mo>×</mo><mn>1</mn><mo>=</mo><mi>k</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k \times k \circ k \times 1 = k \times 1</annotation></semantics></math>, so it produces a vector. To do a matrix by vector multiplication, you go row-by-row in the matrix, and for each row you multiply every element by the corresponding vector element, and add all those products together. Each result vector element is the “dot product” (sum of corresponding products) of one matrix row by the vector.</p>
<p>Here’s an example for <math><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k = 3</annotation></semantics></math>, as in ML-KEM-768.</p>
<p><math display="block"><semantics><mrow><mover><mi>𝐀</mi><mo stretchy="false">^</mo></mover><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover><mo>=</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center center center"><mtr><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,0</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,1</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,2</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,0</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,1</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,2</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,0</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,1</mn></msub></mtd><mtd><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,2</mn></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow><mo>∘</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center"><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow><mo>=</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center"><mtr><mtd><mrow><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,0</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,1</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>0,2</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,0</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,1</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>1,2</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,0</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,1</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>+</mo><msub><mover><mi>a</mi><mo stretchy="false">^</mo></mover><mn>2,2</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mrow></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{\hat{A}} \circ \mathbf{\hat{v}} = 
\begin{bmatrix}
    \hat{a}_{0,0} &amp; \hat{a}_{0,1} &amp; \hat{a}_{0,2} \\
    \hat{a}_{1,0} &amp; \hat{a}_{1,1} &amp; \hat{a}_{1,2} \\
    \hat{a}_{2,0} &amp; \hat{a}_{2,1} &amp; \hat{a}_{2,2} \\
\end{bmatrix}
\circ
\begin{bmatrix}
    \hat{v}_{0} \\
    \hat{v}_{1} \\
    \hat{v}_{2} \\
\end{bmatrix}
=
\begin{bmatrix}
    \hat{a}_{0,0}\hat{v}_{0} + \hat{a}_{0,1}\hat{v}_{1} + \hat{a}_{0,2}\hat{v}_{2} \\
    \hat{a}_{1,0}\hat{v}_{0} + \hat{a}_{1,1}\hat{v}_{1} + \hat{a}_{1,2}\hat{v}_{2} \\
    \hat{a}_{2,0}\hat{v}_{0} + \hat{a}_{2,1}\hat{v}_{1} + \hat{a}_{2,2}\hat{v}_{2} \\
\end{bmatrix}</annotation></semantics></math></p>
<p>Transposed vector by vector (<math><semantics><mrow><msup><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover><mo>⊺</mo></msup><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{\hat{v}^\intercal} \circ \mathbf{\hat{v}}</annotation></semantics></math>, also known as inner product) is <math><semantics><mrow><mn>1</mn><mo>×</mo><mi>k</mi><mo>∘</mo><mi>k</mi><mo>×</mo><mn>1</mn><mo>=</mo><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 \times k \circ k \times 1 = 1 \times 1</annotation></semantics></math>, so in practice it’s just a fancy way to say it’s a single dot product, and it produces a “scalar” (a single element). You just multiply elements coordinate-wise and add them all together.</p>
<p>Here’s an example, again for <math><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k = 3</annotation></semantics></math>.</p>
<p><math display="block"><semantics><mrow><msup><mover><mi>𝐮</mi><mo stretchy="false">^</mo></mover><mo>⊺</mo></msup><mo>∘</mo><mover><mi>𝐯</mi><mo stretchy="false">^</mo></mover><mo>=</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center center center"><mtr><mtd><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub></mtd><mtd><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub></mtd><mtd><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow><mo>∘</mo><mrow><mo fence="true" form="prefix">[</mo><mtable columnalign="center"><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub></mtd></mtr><mtr><mtd><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mtd></mtr></mtable><mo fence="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>0</mn></msub><mo>+</mo><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>+</mo><msub><mover><mi>u</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub><msub><mover><mi>v</mi><mo stretchy="false">^</mo></mover><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{\hat{u}^\intercal} \circ \mathbf{\hat{v}} = 
\begin{bmatrix}
    \hat{u}_{0} &amp; \hat{u}_{1} &amp; \hat{u}_{2} \\
\end{bmatrix}
\circ
\begin{bmatrix}
    \hat{v}_{0} \\
    \hat{v}_{1} \\
    \hat{v}_{2} \\
\end{bmatrix}
=
\hat{u}_{0}\hat{v}_{0} + \hat{u}_{1}\hat{v}_{1} + \hat{u}_{2}\hat{v}_{2}</annotation></semantics></math></p>
<p>Note that you never actually apply a transposition to a vector or a matrix in memory. Transposed vectors are only used on the left hand side of a dot product as explained above, and the transposed matrix <math><semantics><msup><mover><mi>𝐀</mi><mo stretchy="false">^</mo></mover><mo>⊺</mo></msup><annotation encoding="application/x-tex">\mathbf{\hat{A}^\intercal}</annotation></semantics></math> in K-PKE.Encrypt can just be generated pre-transposed by inverting column and matrix in the XOF input to SampleNTT. (There is actually <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/s-C-zIAeKfE/m/eZJmXYsSAQAJ?ref=words.filippo.io">a bug in the first ML-KEM draft</a> around this, which will probably be resolved by denoting <math><semantics><msup><mover><mi>𝐀</mi><mo stretchy="false">^</mo></mover><mo>⊺</mo></msup><annotation encoding="application/x-tex">\mathbf{\hat{A}^\intercal}</annotation></semantics></math> as <math><semantics><mover><mi>𝐁</mi><mo stretchy="false">^</mo></mover><annotation encoding="application/x-tex">\mathbf{\hat{B}}</annotation></semantics></math>, which will make it clear you’re not actually doing any transposition.)</p>
<p>That’s it, this is all the linear algebra you need to implement ML-KEM! If you got this far, you might want to follow me on Bluesky at <a href="https://bsky.app/profile/filippo.abyssdomain.expert?ref=words.filippo.io">@filippo.abyssdomain.expert</a> or on Mastodon at <a href="https://abyssdomain.expert/@filippo?ref=words.filippo.io">@filippo@abyssdomain.expert</a>.</p>
<h2 id="the-picture">The picture</h2>
<p>Walking around Trastevere, thinking about Certificate Transparency, I stopped to listen to an excellent jazz street performance. Great city. 🎷</p>
<p><img src="https://words.filippo.io/content/images/2023/11/news---1--1-.jpeg" alt="A jazz band at night on a cobblestone road, against a wall with a large orange mural with drawn faces and the text &#34;ALL&#39;AMOR SI STA IN SILENZIO&#34;, below a street light. There&#39;s tenor sax, trumpet, bass, drums, and keyboard." loading="lazy"/></p>
<p>My awesome clients—<a href="https://www.sigsum.org/?ref=words.filippo.io">Sigsum</a>, <a href="https://protocol.ai/?ref=words.filippo.io">Protocol Labs</a>, <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a>, <a href="https://interchain.io/?ref=words.filippo.io">Interchain</a>, <a href="https://smallstep.com/?ref=words.filippo.io">Smallstep</a>, <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, <a href="https://goteleport.com/?ref=words.filippo.io">Teleport</a>, and <a href="https://tailscale.com/?ref=words.filippo.io">Tailscale</a>—are funding all my work for the community and through our retainer contracts they get face time and unlimited access to advice on Go and cryptography.</p>
<p>Here are a few words from some of them!</p>
<p>Latacora — <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a> bootstraps security practices for startups. Instead of wasting your time trying to hire a security person who is good at everything from Android security to AWS IAM strategies to SOC2 and apparently has the time to answer all your security questionnaires plus never gets sick or takes a day off, you hire us. We provide a crack team of professionals prepped with processes and power tools, coupling individual security capabilities with strategic program management and tactical project management.</p>
<p>Protocol Labs — In case you&#39;re around Istanbul next week, for DevConnect or other purposes, make sure to check our <a href="https://23.labweek.io/?ref=words.filippo.io">LabWeek</a>, which is packed with events. Among the notable ones, we have a <a href="https://23.labweek.io/libp2p-day?ref=words.filippo.io">libp2p day</a> in case you&#39;re interested in powering your peer to peer communication using the same technology as most decentralized networks in the world. If you&#39;re more into Zero Knowledge proofs or decentralized storage, we have you covered too, and don&#39;t miss the <a href="https://lu.ma/loe-summit-2023?ref=words.filippo.io">League of Entropy summit</a> in case you&#39;re into randomness!</p>
<p>Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. <a href="https://goteleport.com/identity-governance-security/?utm=filippo&amp;ref=words.filippo.io">Teleport Identity Governance &amp; Security</a> is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.</p>
<p>Ava Labs — We at <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, maintainer of <a href="https://github.com/ava-labs/avalanchego?ref=words.filippo.io">AvalancheGo</a> (the most widely used client for interacting with the <a href="https://www.avax.network/?ref=words.filippo.io">Avalanche Network</a>), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.</p>



        </section>
    </article></div>
  </body>
</html>
