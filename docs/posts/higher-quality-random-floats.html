<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.corsix.org/content/higher-quality-random-floats">Original</a>
    <h1>Higher quality random floats</h1>
    
    <div id="readability-page-1" class="page"><div>

<div>
<p data-sourcepos="1:1-1:429">Much has been written about how to generate random 64-bit integers; people might argue over which <em>particular</em> (CS)PRNG is best suited for a given task, but there is agreement on the general shape of the solution: keep some state around, and then extract 64 bits of randomness at a time, where each bit is equally likely to be either zero or one. This gives nice uniformly-distributed integers over the range [0, 2<sup>64</sup>).</p>
<p data-sourcepos="3:1-3:349">There is less agreement on how to generate random floating-point values. It is tempting to aim for what looks like a simple transformation of an integer generator: uniformly-distributed floats over the range [0, 1). There are various ways of doing such a transformation; <a href="https://dotat.at/@/2023-06-23-random-double.html">one exposition does it</a> as:</p>
<pre><code><span><span>double</span> <span>pcg64_random_double</span><span>(pcg64_t *rng)</span> </span>{
    <span>return</span> (<span>double</span>)(pcg64_random(rng) &gt;&gt; <span>11</span>) * <span>0x1</span><span>.0</span>p-<span>53</span>;
}
</code></pre>
<p data-sourcepos="9:1-9:130">Whereas <a href="https://github.com/LuaJIT/LuaJIT/blob/656ecbcf8f669feb94e0d0ec4b4f59190bcd2e48/src/lj_prng.c#L54-L61">LuaJIT does it</a> as:</p>
<pre><code><span>uint64_t <span>lj_prng_u64d</span><span>(PRNGState *rs)</span> </span>{
    uint64_t z, r = <span>0</span>;
    TW223_STEP(rs, z, r)
    
    <span>return</span> (r &amp; <span>0x000fffffffffffff</span>ull) | <span>0x3ff0000000000000</span>ull;
}

U64double u;
<span>double</span> d;
u.u64 = lj_prng_u64d(rs);
d = u.d - <span>1.0</span>;
</code></pre>
<p data-sourcepos="23:1-23:122">And a <a href="https://lemire.me/blog/2023/10/17/randomness-in-programming-with-go-code/#floats">Go version by Lemire does it</a> as:</p>
<pre><code>
<span>func</span> toFloat64(seed *<span>uint64</span>) <span>float64</span> {
    x := splitmix64(seed)
    x &amp;= <span>0x1fffffffffffff</span> 
    <span>return</span> <span>float64</span>(x) / <span>float64</span>(<span>0x1fffffffffffff</span>)
}
</code></pre>
<p data-sourcepos="33:1-33:693">The [0, 1) output range is less useful than it might initially appear. It is often stated that [0, 1) can be transformed to [A, B) by multiplying by <code>B-A</code> then adding <code>A</code>, <a href="https://hal.science/hal-03282794">but this is only true for <em>some</em> values of A and B</a>; for other values, a number just less than 1 can be transformed and end up <em>equal</em> to B due to floating-point rounding, i.e. [0, 1) is transformed to [A, B]. The possibility of a zero output is also unhelpful if the result is going to be log-transformed (for example as part of a <a href="https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform">Box-Muller transform</a>), as <a href="https://github.com/tinygrad/tinygrad/pull/1192">log(0) explodes</a>.</p>
<p data-sourcepos="35:1-35:403">An output range of [0, 1] would be better behaved under most additive and multiplicative transforms. After such a transform, a range like [A, B] can be easily turned into [A, B) via rejection sampling, should the half-open range be desired. It will also turn out to be very easy (on either theoretical or practical grounds) to exclude 0 as a possible output, giving the log-friendly output range (0, 1].</p>
<p data-sourcepos="37:1-37:1038">Before trying to generate a random float in the range [0, 1], we should instead consider the easier problem of generating a random float in the range [0.5, 1]. There are 2<sup>52</sup>+1 different IEEE-754 doubles in this range. The &#34;rounding basin&#34; of some double <code>d</code> in that range can be defined as the range of infinite-precision real numbers in the range [0.5, 1] that would round to <code>d</code> (assuming round-to-nearest). Taking ε=2<sup>-54</sup>, most of these doubles have a basin of <code>d-ε</code> through <code>d+ε</code>. The exceptions are the extremes of the range; 0.5 has a basin of <code>0.5</code> through <code>0.5+ε</code>, and 1 has a basin of <code>1-ε</code> through <code>1</code>. In other words, there are 2<sup>52</sup>-1 values in the range whose basin is <code>2ε</code> wide, and 2 values in the range whose basin is only <code>ε</code> wide. For a uniform distribution, the probability of seeing <code>d</code> should equal the width of the rounding basin of <code>d</code>. Given all this, there is a fairly simple monotonic transform from the uniform integer range [0, 2<sup>53</sup>) to the uniform float range [0.5, 1]:</p>
<table><tbody><tr><th>Integer(s)</th><th>Resultant floating-point double (ε=2<sup>-54</sup>)</th></tr>
<tr><td>0</td><td>0.5</td></tr>
<tr><td>1, 2</td><td>0.5 + 2ε</td></tr>
<tr><td>3, 4</td><td>0.5 + 4ε</td></tr>
<tr><td>5, 6</td><td>0.5 + 6ε</td></tr>
<tr><td>⋮</td><td>⋮</td></tr>
<tr><td>2<sup>53</sup>-7, 2<sup>53</sup>-6</td><td>1 - 6ε</td></tr>
<tr><td>2<sup>53</sup>-5, 2<sup>53</sup>-4</td><td>1 - 4ε</td></tr>
<tr><td>2<sup>53</sup>-3, 2<sup>53</sup>-2</td><td>1 - 2ε</td></tr>
<tr><td>2<sup>53</sup>-1</td><td>1</td></tr>
</tbody></table>
<p data-sourcepos="51:1-51:48">This transform can be expressed in code like so:</p>
<pre><code><span><span>double</span> <span>rand_between_half_and_one</span><span>()</span> </span>{
    <span>double</span> d;
    uint64_t x = rand_u64() &gt;&gt; <span>11</span>; 
    x = ((x + <span>1</span>) &gt;&gt; <span>1</span>) + (<span>1022u</span>ll &lt;&lt; <span>52</span>);
    <span>memcpy</span>(&amp;d, &amp;x, <span>sizeof</span>(d));
    <span>return</span> d;
}
</code></pre>
<p data-sourcepos="63:1-63:245">The range [0.25, 0.5] looks a lot like the range [0.5, 1], except that ε reduces to 2<sup>-55</sup>. That is, there is a fairly simple monotonic transform from the uniform integer range [0, 2<sup>53</sup>) to the uniform float range [0.25, 0.5]:</p>
<table><tbody><tr><th>Integer(s)</th><th>Resultant floating-point double (ε=2<sup>-55</sup>)</th></tr>
<tr><td>0</td><td>0.25</td></tr>
<tr><td>1, 2</td><td>0.25 + 2ε</td></tr>
<tr><td>3, 4</td><td>0.25 + 4ε</td></tr>
<tr><td>5, 6</td><td>0.25 + 6ε</td></tr>
<tr><td>⋮</td><td>⋮</td></tr>
<tr><td>2<sup>53</sup>-7, 2<sup>53</sup>-6</td><td>0.5 - 6ε</td></tr>
<tr><td>2<sup>53</sup>-5, 2<sup>53</sup>-4</td><td>0.5 - 4ε</td></tr>
<tr><td>2<sup>53</sup>-3, 2<sup>53</sup>-2</td><td>0.5 - 2ε</td></tr>
<tr><td>2<sup>53</sup>-1</td><td>0.5</td></tr>
</tbody></table>
<p data-sourcepos="77:1-77:11">Or in code:</p>
<pre><code><span><span>double</span> <span>rand_between_quarter_and_half</span><span>()</span> </span>{
    <span>double</span> d;
    uint64_t x = rand_u64() &gt;&gt; <span>11</span>; 
    x = ((x + <span>1</span>) &gt;&gt; <span>1</span>) + (<span>1021u</span>ll &lt;&lt; <span>52</span>);
    <span>memcpy</span>(&amp;d, &amp;x, <span>sizeof</span>(d));
    <span>return</span> d;
}
</code></pre>
<p data-sourcepos="89:1-89:355">In turn, the range [0.125, 0.25] looks a lot like [0.25, 0.5], and [0.0625, 0.125] looks a lot like [0.125, 0.25], and so on. To generate a float in [0, 1], we need to choose one of these ranges, and then choose a value within that range. For a uniform distribution, the probability of a range should be proportional to the width of the range, so we have:</p>
<table><tbody><tr><th>Output range</th><th>Width</th><th>Probability</th></tr>
<tr><td>[0.5, 1]</td><td>2<sup>-1</sup></td><td>50%</td></tr>
<tr><td>[0.25, 0.5]</td><td>2<sup>-2</sup></td><td>25%</td></tr>
<tr><td>[0.125, 0.25]</td><td>2<sup>-3</sup></td><td>12.5%</td></tr>
<tr><td>[0.0625, 0.125]</td><td>2<sup>-4</sup></td><td>6.25%</td></tr>
<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>
</tbody></table>
<p data-sourcepos="99:1-99:436">As the width of the range approaches zero, so does the probability of the range. Once the width is less than 2<sup>-75</sup>, the probabilities are so small as to be effectively impossible for most practical purposes. By making them <em>actually</em> impossible, we gain a nice guarantee of algorithm termination, and avoid having to think about denormals, and get the log-friendly output range (0, 1]. One way of implementing this in code is:</p>
<pre><code><span><span>double</span> <span>rand_between_zero_and_one</span><span>()</span> </span>{
    <span>double</span> d;
    uint64_t x = rand_u64() &gt;&gt; <span>11</span>; 
    uint64_t e = <span>1022</span>;
    <span>do</span> {
      <span>if</span> (rand_u64() &amp; <span>1</span>) <span>break</span>; 
      e -= <span>1</span>;
    } <span>while</span> (e &gt; <span>1022</span>-<span>75</span>);
    x = ((x + <span>1</span>) &gt;&gt; <span>1</span>) + (e &lt;&lt; <span>52</span>);
    <span>memcpy</span>(&amp;d, &amp;x, <span>sizeof</span>(d));
    <span>return</span> d;
}
</code></pre>
<p data-sourcepos="116:1-116:110">The above throws away lots of random bits, whereas it would be more economical to remember and use them later:</p>
<pre><code><span><span>double</span> <span>rand_between_zero_and_one</span><span>()</span> </span>{
    <span>double</span> d;
    uint64_t x = rand_u64(); 
    uint64_t bits = x &amp; <span>0x7ff</span>, nbits = <span>11</span>;
    uint64_t e = <span>1022</span>;
    <span>do</span> {
      <span>if</span> (bits &amp; <span>1</span>) <span>break</span>; 
      bits &gt;&gt;= <span>1</span>;
      <span>if</span> (--nbits == <span>0</span>) bits = rand_u64(), nbits = <span>64</span>;
      e -= <span>1</span>;
    } <span>while</span> (e &gt; <span>1022</span>-<span>75</span>);
    x = (((x &gt;&gt; <span>11</span>) + <span>1</span>) &gt;&gt; <span>1</span>) + (e &lt;&lt; <span>52</span>);
    <span>memcpy</span>(&amp;d, &amp;x, <span>sizeof</span>(d));
    <span>return</span> d;
}
</code></pre>
<p data-sourcepos="136:1-136:66">Finally, the loop can be eliminated using bit-counting intrinsics:</p>
<pre><code><span><span>double</span> <span>rand_between_zero_and_one</span><span>()</span> </span>{
    <span>double</span> d;
    uint64_t x = rand_u64();
    uint64_t e = __builtin_ctzll(x) - <span>11u</span>ll;
    <span>if</span> ((<span>int64_t</span>)e &gt;= <span>0</span>) e = __builtin_ctzll(rand_u64());
    x = (((x &gt;&gt; <span>11</span>) + <span>1</span>) &gt;&gt; <span>1</span>) - ((e - <span>1011u</span>ll) &lt;&lt; <span>52</span>);
    <span>memcpy</span>(&amp;d, &amp;x, <span>sizeof</span>(d));
    <span>return</span> d;
}
</code></pre>
<p data-sourcepos="150:1-150:23">Or in Go rather than C:</p>
<pre><code>
<span>func</span> toFloat64(seed *<span>uint64</span>) <span>float64</span> {
    x := splitmix64(seed)
    e := bits.TrailingZeros64(x) - <span>11</span>
    <span>if</span> e &gt;= <span>0</span> {
        e = bits.TrailingZeros64(splitmix64(seed))
    }
    x = (((x &gt;&gt; <span>11</span>) + <span>1</span>) &gt;&gt; <span>1</span>) - ((<span>uint64</span>(<span>int64</span>(e)) - <span>1011</span>) &lt;&lt; <span>52</span>)
    <span>return</span> math.Float64frombits(x)
}
</code></pre>
<p data-sourcepos="164:1-164:221">With that exposition done, I can now present my criteria for assessing the quality of functions that claim to generate uniformly-distributed IEEE-754 double-precision floating-point values over (0, 1] or [0, 1] or [0, 1):</p>
<ul data-sourcepos="165:3-169:0">
<li data-sourcepos="165:3-165:241">What is the probability of seeing exactly zero? The rounding basin of 0 is only 2<sup>-1075</sup> wide, so the probability should be as close as possible to this. Note that probability zero (i.e. impossible) is <em>extremely</em> close to this.</li>
<li data-sourcepos="166:3-166:76">What is the smallest non-zero value that can be seen? Smaller is better.</li>
<li data-sourcepos="167:3-167:123">What is the largest double-precision value less than 1 that <em>cannot</em> be seen? Smaller is better (and negative is best).</li>
<li data-sourcepos="168:3-169:0">How many distinct double-precision values can be seen? Larger is better.</li>
</ul>
<table><tbody><tr><th>Criteria</th><th>Most functions</th><th>Presented here</th><th>Ideal</th></tr>
<tr><td>Probability of zero</td><td>2<sup>-52</sup> or 2<sup>-53</sup></td><td>0</td><td>2<sup>-1075</sup></td></tr>
<tr><td>Smallest non-zero</td><td>2<sup>-52</sup> or 2<sup>-53</sup></td><td>2<sup>-76</sup></td><td>2<sup>-1074</sup></td></tr>
<tr><td>Largest non-seeable</td><td>1 - 2<sup>-53</sup> or 0.5 - 2<sup>-54</sup></td><td>2<sup>-76</sup> - 2<sup>-129</sup></td><td>-0</td></tr>
<tr><td>Distinct values</td><td>2<sup>52</sup> or 2<sup>53</sup></td><td>2<sup>58.2</sup></td><td>2<sup>62</sup>±1</td></tr>
</tbody></table>
<p data-sourcepos="177:1-177:344">If you&#39;ve reached this far, then you might be interested in similar commentary from <a href="https://mumble.net/~campbell/2014/04/28/uniform-random-float">Taylor R. Campbell</a> or <a href="https://allendowney.com/research/rand/downey07randfloat.pdf">Allen B. Downey</a> or <a href="https://outerproduct.net/trivial/2023-06-24_number-whose-point-floats.html">@moon_chilled</a>.</p>
</div>
</div></div>
  </body>
</html>
