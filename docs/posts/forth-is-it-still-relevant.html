<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/chochain/eforth">Original</a>
    <h1>Forth – Is it still relevant?</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: <em>due to C&#39;s broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing</em>.</p>
<p dir="auto">So, the question is, how to encourage today&#39;s world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won&#39;t get us anywhere.</p>
<p dir="auto">Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth <a href="https://chochain.github.io/eforth/docs/eForthAndZen.pdf" rel="nofollow">genesis</a> and <a href="https://chochain.github.io/eforth/docs/eForthOverviewv5.pdf" rel="nofollow">overview</a>. I like the idea and decided to pick it up.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">eForth now - What did I change!</h2><a id="user-content-eforth-now---what-did-i-change" aria-label="Permalink: eForth now - What did I change!" href="#eforth-now---what-did-i-change"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><b>100% C/C++ with multi-platform support</b>. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.</p>
</li>
<li>
<p dir="auto"><b>Dictionary is just an array</b>. It&#39;s remodeled from linear memory linked-list to an array (or a vector in C++&#39;s term) of words.</p>
<ul dir="auto">
<li>To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.</li>
<li>To execute become just a walk of the word pointers in the array. This is our inner interpreter.</li>
<li>Hashtables might go even faster but we&#39;ll try that later.</li>
</ul>
</li>
<li>
<p dir="auto"><b>Data and Return Stacks are also arrays</b>. With push, pop and [] methods to clarify intentions.</p>
</li>
<li>
<p dir="auto"><b>Parameter fields are all arrays</b>. Why not!</p>
</li>
<li>
<p dir="auto"><b>No vocabulary, or meta-compilation</b>. Except CREATE..DOES&gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.</p>
</li>
<li>
<p dir="auto"><b>Multi-threading and message passing are available</b> From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details</p>
<ul dir="auto">
<li>A thread pool is built-in. Size is defaults to number of cores.</li>
<li>Message Passing send/recv with pthread mutex waiting.</li>
<li>IO and memory update can be synchronized with lock/unlock.</li>
</ul>
</li>
</ol>
<div dir="auto"><h2 tabindex="-1" dir="auto">Rolling your own C-based Forth?</h2><a id="user-content-rolling-your-own-c-based-forth" aria-label="Permalink: Rolling your own C-based Forth?" href="#rolling-your-own-c-based-forth"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download <a href="https://github.com/chochain/eforth/releases/tag/v4.2.2">release v4.2</a> and work from there.</p>
<p dir="auto">In the release, a heavily commented <em>ceforth.cpp</em>, the companion <em>ceforth.h</em>, and a <em>config.h</em>. Altogether, about 800 lines. Check them out!</p>

<p dir="auto">The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.</p>
<ol dir="auto">
<li>
<p dir="auto"><b>Code</b> - the heart of eForth, depends on the constructor called, the following fields are populated accordingly</p>
 <pre> + name - a string that holds primitive word&#39;s name, i.e. NFA in classic FORTH,
          can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory
 + xt   - pointer to a lambda function for primitive words i.e. XT in classic FORTH
 + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH
 + q    - holds the literal value which classic FORTH keep on parameter memory
 </pre>
</li>
<li>
<p dir="auto"><b>Lit, Var, Str, Bran, Tmp</b> - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.</p>
 <pre> + Lit  - numeric literals
 + Var  - variable or constant
 + Str  - string for dostr or dotstr
 + Bran - Branching opcode
 + Tmp  - temp storage for branching word
 </pre>
</li>
<li>
<p dir="auto"><b>Dictionary</b> - an array of <em>Code</em> objects</p>
 <pre> + build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt
     dict[0].xt ------&gt; lambda[0]         &lt;== These function pointers can be converted
     dict[1].xt ------&gt; lambda[1]             into indices to a jump table
     ...                                      which is exactly what WASM does
     dict[N-1].xt ----&gt; lambda[N-1]       &lt;== N is number of built-in words
     
 + colon (user defined) words - collection of word pointers during compile time
     dict[N].pf   = [ *Code, *Code, ... ] &lt;== These are called the &#39;threads&#39; in Forth&#39;s term
     dict[N+1].pf = [ *Code, *Code, ... ]     So, instead of subroutine threading
     ...                                      this is &#39;object&#39; threading.
     dict[-1].pf  = [ *Code, *Code, ... ]     It can be further compacted into
                                              token (i.e. dict index) threading if desired
 </pre>
</li>
<li>
<p dir="auto"><b>Inner Interpreter</b> - <em>Code.exec()</em> is self-explanatory</p>
<div dir="auto" data-snippet-clipboard-copy-content="if (xt) { xt(this); return; }         // run primitive word
for (Code *w : pf) {                  // run colon word
    try { w-&gt;exec(); }                // execute recursively
    catch (...) { break; }            // handle exception if any
}"><pre><span>if</span> (<span>xt</span>) { <span>xt</span>(<span>this</span>); <span>return</span>; }         <span>// run primitive word</span>
<span>for</span> (<span>Code</span> <span>*</span><span>w</span> : <span>pf</span>) {                  <span>// run colon word</span>
    <span>try</span> { <span>w</span><span>-&gt;</span><span>exec</span>(); }                <span>// execute recursively</span>
    <span>catch</span> (...) { <span>break</span>; }            <span>// handle exception if any</span>
}</pre></div>
<p dir="auto">i.e. either we call a built-in word&#39;s lambda function or walk the Code.pf array recursively like a depth-first tree search.</p>
</li>
<li>
<p dir="auto"><b>Outer Interpreter</b> - <em>forth_core()</em> is self-explanatory</p>
<div dir="auto" data-snippet-clipboard-copy-content="Code *c = find(idiom);                // search dictionary
if (c) {                              // word found?
    if (compile &amp;&amp; !c-&gt;immd)          // are we compiling a new word?
        dict[-1]-&gt;add(c);             // then append found code to it
    else c-&gt;exec();                   // or, execute the code
    return;
}
DU n = parse_number(idiom);           // word not found, try as a number
if (compile)                          // are we compiling a new word?
    dict[-1]-&gt;add(new Lit(n));        // append numeric literal to it
else PUSH(n);                         // push onto data stack"><pre><span>Code</span> <span>*</span><span>c</span> <span>=</span> <span>find</span>(<span>idiom</span>);                <span>// search dictionary</span>
<span>if</span> (<span>c</span>) {                              <span>// word found?</span>
    <span>if</span> (<span>compile</span> <span>&amp;&amp;</span> !<span>c</span><span>-&gt;</span><span>immd</span>)          <span>// are we compiling a new word?</span>
        <span>dict</span>[<span>-1</span>]<span>-&gt;</span><span>add</span>(<span>c</span>);             <span>// then append found code to it</span>
    <span>else</span> <span>c</span><span>-&gt;</span><span>exec</span>();                   <span>// or, execute the code</span>
    <span>return</span>;
}
<span>DU</span> <span>n</span> <span>=</span> <span>parse_number</span>(<span>idiom</span>);           <span>// word not found, try as a number</span>
<span>if</span> (<span>compile</span>)                          <span>// are we compiling a new word?</span>
    <span>dict</span>[<span>-1</span>]<span>-&gt;</span><span>add</span>(<span>new</span> <span>Lit</span>(<span>n</span>));        <span>// append numeric literal to it</span>
<span>else</span> <span>PUSH</span>(<span>n</span>);                         <span>// push onto data stack</span></pre></div>
</li>
</ol>
<p dir="auto">With the array implementation, the first difference is in array variable read/write.</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt; create narr 10 cells allot
&gt; see narr
&gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +"><pre>&gt; <span>create</span> narr <span>10</span> cells allot
&gt; <span>see</span> narr
&gt; : narr
    <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> <span>0</span> ;
<span>\       ^----------------- narr 2 cells +</span></pre></div>
<p dir="auto">While traditional Forths uses <code>narr 2 cells +</code> to get the memory address of <code>narr[2]</code>, eforth <code>narr</code> returns its index (or defining order) in the dictionary. So, <code>narr 2 cells +</code> will actually get you the index of the second word defined after <code>narr</code>. You&#39;ll be storing the value into that word&#39;s empty qf field.
To access the n<em>th</em> element of <code>narr</code>, use <code>th</code> instead</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&gt; fill-arr
&gt; see narr
&gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;"><pre>&gt; : fill-arr
    <span>10</span> <span>0</span> <span>do</span>
      <span>i</span> 2* narr <span>i</span> th !
    <span>loop</span> ;
&gt; fill-arr
&gt; <span>see</span> narr
&gt; : narr
    <span>0</span> <span>2</span> <span>4</span> <span>6</span> <span>8</span> <span>10</span> <span>12</span> <span>14</span> <span>16</span> <span>18</span> ;</pre></div>
<p dir="auto">With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the &#34;scary&#34; features for Forths to come.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">ceForth - Where we came from</h2><a id="user-content-ceforth---where-we-came-from" aria-label="Permalink: ceForth - Where we came from" href="#ceforth---where-we-came-from"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See <a href="https://www.forth.org/OffeteStore/OffeteStore.html" rel="nofollow">here</a> for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.</p>
<p dir="auto">Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight <strong>Forth without Forth</strong>.</p>
<p dir="auto">In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see <a href="https://chochain.github.io/eforth/docs/ceforth_403.pdf" rel="nofollow">ceForth_403</a> and <a href="https://github.com/chochain/eJsv32">eJsv32</a> for details.</p>
<p dir="auto">We hope it can serve as a stepping stone for learning Forth to even building their own, one day.</p>

<div dir="auto" data-snippet-clipboard-copy-content="    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth"><pre>    $ git clone https://github.com/chochain/eforth to your <span>local</span> machine
    $ <span>cd</span> eforth</pre></div>
<p dir="auto">There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.</p>
<p dir="auto">Checkout the version you are interested in.</p>
<div dir="auto" data-snippet-clipboard-copy-content="    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on"><pre>    $ git checkout v42           <span><span>#</span> for version 4.2 (latest), or</span>
    $ git checkout master        <span><span>#</span> for version 5 and on</span></pre></div>
<p dir="auto">To enable multi-threading, of v5, update the followings in ~/src/config.h</p>
<div dir="auto" data-snippet-clipboard-copy-content="    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8"><pre>    <span>#define</span> <span>DO_MULTITASK</span>   1
    <span>#define</span> <span>E4_VM_POOL_SZ</span>  8</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Linux, MacOS, Cygwin, Raspberry Pi, or Android with Termux</h3><a id="user-content-linux-macos-cygwin-raspberry-pi-or-android-with-termux" aria-label="Permalink: Linux, MacOS, Cygwin, Raspberry Pi, or Android with Termux" href="#linux-macos-cygwin-raspberry-pi-or-android-with-termux"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter"><pre>    $ make
    $ ./tests/eforth             <span><span>#</span> to bring up the Forth interpreter</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="    &gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &gt; words⏎               \ to see available Forth words
    &gt; 1 2 +⏎               \ see Forth in action
    &gt; bye⏎  or Ctrl-C      \ to exit eForth"><pre>    &gt; eForth v5.0, RAM 16.5% free (1300 / <span>7880</span> MB)
    &gt; words⏎               <span>\ to see available Forth words</span>
    &gt; <span>1</span> <span>2</span> +⏎               <span>\ see Forth in action</span>
    &gt; bye⏎  or Ctrl-C      <span>\ to exit eForth</span></pre></div>
<div data-snippet-clipboard-copy-content="Once you get pass the above, try the lessons by Dr. Ting."><pre><code>Once you get pass the above, try the lessons by Dr. Ting.
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="    $ ./tests/eforth &lt; ./tests/demo.fs"><pre>    $ ./tests/eforth <span>&lt;</span> ./tests/demo.fs</pre></div>
<p dir="auto">Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.</p>
<p dir="auto">Note: MacOS added, thanks to Kristopher Johnson&#39;s work.</p>

<p dir="auto">I haven&#39;t develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I&#39;m hoping someone can make it more streamlined.</p>
<div data-snippet-clipboard-copy-content="* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&gt; Build -&gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory"><pre><code>* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&gt; Build -&gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="    &gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &gt; words⏎               \ to see available Forth words
    &gt; 1 2 +⏎               \ see Forth in action
    &gt; bye⏎  or Ctrl-C      \ to exit eForth"><pre>    &gt; eForth v5.0, RAM 16.5% free (1300 / <span>7880</span> MB)
    &gt; words⏎               <span>\ to see available Forth words</span>
    &gt; <span>1</span> <span>2</span> +⏎               <span>\ see Forth in action</span>
    &gt; bye⏎  or Ctrl-C      <span>\ to exit eForth</span></pre></div>
<div data-snippet-clipboard-copy-content="Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files."><pre><code>Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
</code></pre></div>

<div data-snippet-clipboard-copy-content="* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk"><pre><code>* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="    $ make wasm
    $ python3 tests/cors.py        # supports COOP"><pre>    $ make wasm
    $ python3 tests/cors.py        <span><span>#</span> supports COOP</span></pre></div>
<div data-snippet-clipboard-copy-content="* from your browser, open http://localhost:8000/tests/eforth.html"><pre><code>* from your browser, open http://localhost:8000/tests/eforth.html
</code></pre></div>
<p dir="auto">Note: For multi-threading to work, browser needs to receive Cross-Origin policies <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cross-Origin-Opener-Policy" rel="nofollow">here for detail</a> in the response header. A Python script <em>~/tests/cors.py</em> is provided to solve the issue. The same needed to be provided if you use other web server.</p>

<div data-snippet-clipboard-copy-content="* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to &#39;Both NL &amp; CR&#39;
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server"><pre><code>* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to &#39;Both NL &amp; CR&#39;
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
</code></pre></div>
<p dir="auto">Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Multi-threading - for release v5.0 and after</h2><a id="user-content-multi-threading---for-release-v50-and-after" aria-label="Permalink: Multi-threading - for release v5.0 and after" href="#multi-threading---for-release-v50-and-after"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Forth has been supporting multi-tasking since the 70&#39;s. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.</p>

<div data-snippet-clipboard-copy-content="* each VM has it&#39;s own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication."><pre><code>* each VM has it&#39;s own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
</code></pre></div>

<div data-snippet-clipboard-copy-content="1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in &#34;ready to run&#34; tasks.
4. Lastly, event_loop picks up &#34;ready to run&#34; tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task"><pre><code>1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in &#34;ready to run&#34; tasks.
4. Lastly, event_loop picks up &#34;ready to run&#34; tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
</code></pre></div>
<p dir="auto">Before we go too far, make sure the following are updated before your build</p>
<div data-snippet-clipboard-copy-content="* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h"><pre><code>* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Built-in words (available only when DO_MULTITASK is enabled)</h3><a id="user-content-built-in-words-available-only-when-do_multitask-is-enabled" aria-label="Permalink: Built-in words (available only when DO_MULTITASK is enabled)" href="#built-in-words-available-only-when-do_multitask-is-enabled"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>word</th>
<th>stack</th>
<th>desc</th>
<th>state</th>
</tr>
</thead>
<tbody>
<tr>
<td>task</td>
<td>( xt -- t )</td>
<td>create a task (tid is index to thread pool entry)</td>
<td>STOP=&gt;HOLD</td>
</tr>
<tr>
<td>rank</td>
<td>( -- t )</td>
<td>fetch current task id</td>
<td>NEST</td>
</tr>
<tr>
<td>start</td>
<td>( t -- )</td>
<td>start a task</td>
<td>HOLD=&gt;NEST</td>
</tr>
<tr>
<td>join</td>
<td>( t -- )</td>
<td>wait until the given task is completed</td>
<td>NEST=&gt;STOP</td>
</tr>
<tr>
<td>lock</td>
<td>( -- )</td>
<td>lock (semaphore) IO or memory</td>
<td>NEST</td>
</tr>
<tr>
<td>unlock</td>
<td>( -- )</td>
<td>release IO or memory lock</td>
<td>NEST</td>
</tr>
<tr>
<td>send</td>
<td>( v1 v2 .. vn n t -- )</td>
<td>send n elements on current stack to designated task&#39;s stack (use stack as message queue)</td>
<td>sender NEST</td>
</tr>
<tr>
<td>recv</td>
<td>( -- v1 v2 .. vn )</td>
<td>wait, until message to arrive</td>
<td>HOLD=&gt;NEST</td>
</tr>
<tr>
<td>pull</td>
<td>( n t -- )</td>
<td>forced fetch stack elements from a completed task</td>
<td>current NEST</td>
</tr>
<tr>
<td>bcast</td>
<td>( n -- )</td>
<td>not implemented yet, TODO</td>
<td>sender NEST</td>
</tr>
<tr>
<td>clock</td>
<td>( -- n )</td>
<td>fetch microsecond since Epoch, useful for timing</td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example1 - parallel jobs (~/tests/demo/mtask.fs)</h4><a id="user-content-example1---parallel-jobs-testsdemomtaskfs" aria-label="Permalink: Example1 - parallel jobs (~/tests/demo/mtask.fs)" href="#example1---parallel-jobs-testsdemomtaskfs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="    &gt; : once 999999 for rank drop next ;            \ 1M cycles
    &gt; : run clock negate once clock + . .&#34; ms&#34; cr ; \ benchmark
    &gt; &#39; run constant xt                             \ keep the xt
    &gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &gt; 4 jobs"><pre>    &gt; : once <span>999999</span> <span>for</span> rank drop <span>next</span> ;            <span>\ 1M cycles</span>
    &gt; : run clock negate once clock + . .&#34; <span>ms&#34;</span> cr ; <span>\ benchmark</span>
    &gt; <span>&#39;</span> run <span>constant</span> xt                             <span>\ keep the xt</span>
    &gt; : jobs 1- <span>for</span> xt task start <span>next</span> ;            <span>\ tasks in parallel</span>
    &gt; <span>4</span> jobs</pre></div>
<pre>[06.1]&gt;&gt; started on T2
[05.1]&gt;&gt; started on T4
[04.1]&gt;&gt; started on T6
[07.1]&gt;&gt; started on T0
18 ms
[06.3]&gt;&gt; finished on T2
18 ms
[05.3]&gt;&gt; finished on T4
18 ms
[04.3]&gt;&gt; finished on T6
18 ms
[07.3]&gt;&gt; finished on T0
</pre>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example2 - producer-consumer (~/tests/demo/mpi.fs)</h4><a id="user-content-example2---producer-consumer-testsdemompifs" aria-label="Permalink: Example2 - producer-consumer (~/tests/demo/mpi.fs)" href="#example2---producer-consumer-testsdemompifs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="    &gt; 0 constant pp                           \ producer task id
    &gt; 0 constant cc                           \ consumer task id
    &gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock .&#34; sent &#34; cr unlock ;            \ locked IO before write
    &gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock .&#34; sum=&#34; . cr unlock ;           \ locked IO before write
    &gt; &#39; sndr task to pp
    &gt; &#39; rcvr task to cc
    &gt; cc start                                \ start receiver task
    &gt; pp start                                \ start sender task
    &gt; pp join cc join                         \ wait for completion"><pre>    &gt; <span>0</span> <span>constant</span> pp                           <span>\ producer task id</span>
    &gt; <span>0</span> <span>constant</span> cc                           <span>\ consumer task id</span>
    &gt; : sndr
        <span>1000</span> ms                               <span>\ delay to simulate some processing</span>
        <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>4</span> cc send                     <span>\ send 4 items from stack</span>
        lock .&#34; <span>sent &#34;</span> cr unlock ;            <span>\ locked IO before write</span>
    &gt; : rcvr
        recv                                  <span>\ wait for sender</span>
        + + +                                 <span>\ sum received 4 items</span>
        lock .&#34; <span>sum=&#34;</span> . cr unlock ;           <span>\ locked IO before write</span>
    &gt; <span>&#39;</span> sndr task <span>to</span> pp
    &gt; <span>&#39;</span> rcvr task <span>to</span> cc
    &gt; cc start                                <span>\ start receiver task</span>
    &gt; pp start                                <span>\ start sender task</span>
    &gt; pp join cc join                         <span>\ wait for completion</span></pre></div>
<pre>[06.1]&gt;&gt; started on T1
[06.1]&gt;&gt; waiting
[07.1]&gt;&gt; started on T2
[06.1]&gt;&gt; sending 4 items to VM6.1
sent 
[07.3]&gt;&gt; finished on T2
[00.3]&gt;&gt; VM7 joint
[06.3]&gt;&gt; received =&gt; state=3
sum=10
[06.3]&gt;&gt; finished on T1
[00.3]&gt;&gt; VM6 joint
</pre>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example3 - fetch result(s) from completed task (~/tests/demo/mpi_pull.fs)</h4><a id="user-content-example3---fetch-results-from-completed-task-testsdemompi_pullfs" aria-label="Permalink: Example3 - fetch result(s) from completed task (~/tests/demo/mpi_pull.fs)" href="#example3---fetch-results-from-completed-task-testsdemompi_pullfs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="    &gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &gt; &#39; sum task constant tt                  \ create the task
    &gt; tt start tt join                        \ run and wait for completion
    &gt; 1 tt pull .&#34; total=&#34; .                  \ pull the sum"><pre>    &gt; : sum <span>0</span> <span>1000000</span> <span>for</span> <span>i</span> + <span>next</span> ;          <span>\ add 0 to 1M</span>
    &gt; <span>&#39;</span> sum task <span>constant</span> tt                  <span>\ create the task</span>
    &gt; tt start tt join                        <span>\ run and wait for completion</span>
    &gt; <span>1</span> tt pull .&#34; <span>total=&#34;</span> .                  <span>\ pull the sum</span></pre></div>
<pre>[00.3]&gt;&gt; joining VM7
[07.1]&gt;&gt; started on T1
[07.3]&gt;&gt; finished on T1
[00.3]&gt;&gt; VM7 joint
pulled 1 items from VM7.0
total= 1784293664 -1 -&gt; ok
</pre>

<div data-snippet-clipboard-copy-content="+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40"><pre><code>+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
</code></pre></div>

<div dir="auto"><h3 tabindex="-1" dir="auto">Desktop PC - 10K*10K cycles on 3.2GHz AMD**</h3><a id="user-content-desktop-pc---10k10k-cycles-on-32ghz-amd" aria-label="Permalink: Desktop PC - 10K*10K cycles on 3.2GHz AMD**" href="#desktop-pc---10k10k-cycles-on-32ghz-amd"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<div data-snippet-clipboard-copy-content="+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)"><pre><code>+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
</code></pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">v5.x ~/src/ceforth, multi-threading capable, dynamic vector, object threading</h4><a id="user-content-v5x-srcceforth-multi-threading-capable-dynamic-vector-object-threading" aria-label="Permalink: v5.x ~/src/ceforth, multi-threading capable, dynamic vector, object threading" href="#v5x-srcceforth-multi-threading-capable-dynamic-vector-object-threading"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&gt; not much overhead with MT"><pre><code>+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&gt; not much overhead with MT
</code></pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">experimental ~/orig/50x/ceforth multi-threading capable, linear-memory, 32-bit IU</h4><a id="user-content-experimental-orig50xceforth-multi-threading-capable-linear-memory-32-bit-iu" aria-label="Permalink: experimental ~/orig/50x/ceforth multi-threading capable, linear-memory, 32-bit IU" href="#experimental-orig50xceforth-multi-threading-capable-linear-memory-32-bit-iu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn&#39;t seem to bother WASM."><pre><code>+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn&#39;t seem to bother WASM.
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">ESP32 - 1K*1K cycles on 240MHz NodeMCU**</h3><a id="user-content-esp32---1k1k-cycles-on-240mhz-nodemcu" aria-label="Permalink: ESP32 - 1K*1K cycles on 240MHz NodeMCU**" href="#esp32---1k1k-cycles-on-240mhz-nodemcu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="+ 1440ms: Dr. Ting&#39;s ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)"><pre><code>+ 1440ms: Dr. Ting&#39;s ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Dictionary of Pointers vs Objects</h3><a id="user-content-dictionary-of-pointers-vs-objects" aria-label="Permalink: Dictionary of Pointers vs Objects" href="#dictionary-of-pointers-vs-objects"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">What is the performance difference?</p>
<ol dir="auto">
<li>Code *dict[] - where words are dynamically allocated as a collection of pointers, or</li>
<li>Code dict[]  - where words are statically created as an array of objects.</li>
</ol>
<p dir="auto">I have created a git branch &#39;static&#39; to compare to the &#39;master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn&#39;t been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Big switch statement vs lambda pointers</h3><a id="user-content-big-switch-statement-vs-lambda-pointers" aria-label="Permalink: Big switch statement vs lambda pointers" href="#big-switch-statement-vs-lambda-pointers"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">An array of lambdas vs the classic switch statement, i.e.</p>
<div data-snippet-clipboard-copy-content="const Code dict[] {               ///&lt; Forth dictionary
    CODE(&#34;+&#34;,      TOS += SS.pop()),
    CODE(&#34;-&#34;,      TOS =  SS.pop() - TOS),
    CODE(&#34;*&#34;,      TOS *= SS.pop()),
    CODE(&#34;/&#34;,      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ..."><pre><code>const Code dict[] {               ///&lt; Forth dictionary
    CODE(&#34;+&#34;,      TOS += SS.pop()),
    CODE(&#34;-&#34;,      TOS =  SS.pop() - TOS),
    CODE(&#34;*&#34;,      TOS *= SS.pop()),
    CODE(&#34;/&#34;,      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
</code></pre></div>
<p dir="auto">Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops.
However, with the advance of compilers,</p>
<ol dir="auto">
<li>It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync</li>
<li>It is possible to prebuild lambda array as a ROM image or static library that can be transported.</li>
<li>A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.</li>
</ol>
<div dir="auto"><h3 tabindex="-1" dir="auto">Memory Consumption Consideration</h3><a id="user-content-memory-consumption-consideration" aria-label="Permalink: Memory Consumption Consideration" href="#memory-consumption-consideration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.</p>
<div data-snippet-clipboard-copy-content="+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes"><pre><code>+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
</code></pre></div>
<p dir="auto">The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes <a href="https://chochain.github.com/eforth/orig/40x/ceforth.h">here</a>. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.</p>
<p dir="auto">I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Multiple or Unified Parameter Field Consideration</h3><a id="user-content-multiple-or-unified-parameter-field-consideration" aria-label="Permalink: Multiple or Unified Parameter Field Consideration" href="#multiple-or-unified-parameter-field-consideration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch <strong>one_pf</strong> doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?</p>
<div data-snippet-clipboard-copy-content="+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup."><pre><code>+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
</code></pre></div>
<p dir="auto">So, what <strong>cachegrind</strong> said for <strong>100M loop</strong> tight loops and <strong>chacha.fs</strong> a CPU intensive?</p>
<div data-snippet-clipboard-copy-content="| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |"><pre><code>| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
</code></pre></div>
<p dir="auto">Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. <strong>_if/_else/_then</strong>, <strong>for/next</strong>, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn&#39;t be so dramatic especially with the recursive nest(). More research on this...</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">50x, 50x32 - back to classic linear-memory model</h3><a id="user-content-50x-50x32---back-to-classic-linear-memory-model" aria-label="Permalink: 50x, 50x32 - back to classic linear-memory model" href="#50x-50x32---back-to-classic-linear-memory-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth&#39;s model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).</p>
<p dir="auto">It works better with WASM&#39;s memory model. It is used as the foundation for <a href="https://github.com/chochain/weForth">weForth</a>. So far, it is stable but tweaked from time to time and</p>
<div data-snippet-clipboard-copy-content="&gt; make 50x
&gt; ./tests/eforth50x"><pre><code>&gt; make 50x
&gt; ./tests/eforth50x
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">eForthX - an effort to modernize Forth</h3><a id="user-content-eforthx---an-effort-to-modernize-forth" aria-label="Permalink: eForthX - an effort to modernize Forth" href="#eforthx---an-effort-to-modernize-forth"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Hinted by Sean Pringle&#39;s <a href="https://github.com/seanpringle/reforth">Rethinking Forth</a> and Travis Bemann&#39;s wornderful <a href="https://github.com/tabemann/zeptoforth">zeptoforth</a>. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX</p>

<div data-snippet-clipboard-copy-content="+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)"><pre><code>+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
</code></pre></div>

<ul dir="auto">
<li>
<p dir="auto">Dr. Ting&#39;s work on eForth between 1995~2011
<a href="http://forth.org/library/eforth_SOC" rel="nofollow">eForth references</a> and their <a href="http://forth.org/library/eforth_SOC/eforth_SOC_source" rel="nofollow">Source Code Repo</a></p>
</li>
<li>
<p dir="auto">CC 20210314: Initial</p>
<ul dir="auto">
<li>Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.</li>
</ul>
</li>
<li>
<p dir="auto">CC 20210707: Refactor</p>
<ul dir="auto">
<li>Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.</li>
</ul>
</li>
<li>
<p dir="auto">CC 20210816: Code Merge</p>
<ul dir="auto">
<li>Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0</li>
</ul>
</li>
<li>
<p dir="auto">CC 20220512: Refactor</p>
<ul dir="auto">
<li>Though the goal of Dr. Ting&#39;s is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&gt;dict, dict-&gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!</li>
<li>Refactor to subroutine indirect threading. It&#39;s not portable but does speed up 25% (see benchmark above).</li>
<li>Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.</li>
<li>Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.</li>
</ul>
</li>
<li>
<p dir="auto">CC 20221118: Refactor</p>
<ul dir="auto">
<li>WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt &#34;function pointer&#34; in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.</li>
</ul>
</li>
<li>
<p dir="auto">CC 20231011: Review</p>
<ul dir="auto">
<li>Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.</li>
<li>LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.</li>
</ul>
</li>
<li>
<p dir="auto">CC 20240308: Refactor for multi-platform, accept dynamic vectors</p>
<ul dir="auto">
<li>Experiment various threading and memory pointer models, archive into ~/orig/40x</li>
<li>To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done
<ul dir="auto">
<li>Separate cross-platform and configuration into ~/src/config.h</li>
<li>Separate platform specific code into ~/platform</li>
<li>add included opcode for Forth script loading</li>
<li>rename &#39;next_idiom&#39; to &#39;word&#39;, per Forth standard</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">CC 20241001: Add multi-threading support</p>
<ul dir="auto">
<li>Shared dictionary and code space amount threads.</li>
<li>Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.</li>
<li>Introduce VM, states
<ul dir="auto">
<li>local ss, rs, tos, and user area</li>
<li>align to cache-line width</li>
<li>pass VM&amp; to all lambda and static functions</li>
</ul>
</li>
<li>Add thread pool and event_loop with affinity to physical cores.
<ul dir="auto">
<li>task, start, stop, join for thread life-cycle management</li>
<li>add general multi-threading demo</li>
</ul>
</li>
<li>Add Inter-task communication
<ul dir="auto">
<li>pthread mutex and condition variables are used for synchronization</li>
<li>rank for task id</li>
<li>send, recv, and pull. Use local stack, as queue, for message passing.</li>
<li>add producer/consumer demo</li>
</ul>
</li>
<li>Add IO sequencing
<ul dir="auto">
<li>ANSI-Color trace/logging for different cores</li>
<li>mutex guard used</li>
<li>lock, unlock for output stream synchronization</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">CC: 20250610: maintenance and memory leak check</p>
<ul dir="auto">
<li>Refactor
<ul dir="auto">
<li>Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT</li>
<li>Group IO functions to forth_sys module</li>
<li>Macros to clarify intention, i.e. NEST, BASE, ADD_W</li>
<li>Code references replace Code pointers</li>
<li>Rename ms=&gt;clock, delay=&gt;ms (adhere to Forth Standard)</li>
<li>Add destructors to deallocate (reduce valgrind&#39;s complaints)</li>
</ul>
</li>
<li>Enhance multi-threading
<ul dir="auto">
<li>Use std::thread instead of pthread (except device specific CPU affinity)</li>
<li>Handle recursive include - Save/Restore WP</li>
<li>Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)</li>
</ul>
</li>
<li>Enhance debugging
<ul dir="auto">
<li>Add dict() to detail dictionary entries</li>
<li>Add dump() to show memory/parameter field&#39;s content</li>
</ul>
</li>
</ul>
</li>
</ul>
</article></div></div>
  </body>
</html>
