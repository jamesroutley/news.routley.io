<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theguardian.com/technology/2025/feb/06/google-edits-super-bowl-ad-for-ai-that-featured-false-information">Original</a>
    <h1>Google edits Super Bowl ad for AI that featured false information</h1>
    
    <div id="readability-page-1" class="page"><div id="maincontent"><div><p>Google has edited an advert for its leading artificial intelligence (AI) tool, Gemini, before its broadcast during the <a href="https://www.theguardian.com/sport/super-bowl" data-link-name="in body link" data-component="auto-linked-tag">Super Bowl</a> after it was found to contain false information about gouda cheese.</p><p>The local commercial, which advertises how people can use “AI for every business”, showcases Gemini’s abilities by depicting the tool helping a cheesemonger in Wisconsin to write a product description, including the erroneous line that gouda accounts for “50% to 60% of global cheese consumption”.</p><figure id="a4e1bbb2-6871-4226-bd47-6b911a74278d" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&#34;richLinkIndex&#34;:2,&#34;element&#34;:{&#34;_type&#34;:&#34;model.dotcomrendering.pageElements.RichLinkBlockElement&#34;,&#34;prefix&#34;:&#34;Related: &#34;,&#34;text&#34;:&#34;Google owner drops promise not to use AI for weapons&#34;,&#34;elementId&#34;:&#34;a4e1bbb2-6871-4226-bd47-6b911a74278d&#34;,&#34;role&#34;:&#34;richLink&#34;,&#34;url&#34;:&#34;https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons&#34;},&#34;ajaxUrl&#34;:&#34;https://api.nextgen.guardianapps.co.uk&#34;,&#34;format&#34;:{&#34;design&#34;:0,&#34;display&#34;:0,&#34;theme&#34;:0}}"><div data-print-layout="hide" data-link-name="rich-link-2 | 2" data-component="rich-link" data-name="placeholder"></div></gu-island></figure><p>However, a blogger posted on X that the stat was an “AI hallucination” that is “unequivocally false”, as more reliable data suggests the Dutch cheese is probably less popular than cheddar or mozzarella.</p><p>The blogger Nate Hake <a href="https://x.com/natejhake/status/1885137070936478011" data-link-name="in body link">added</a>: “I found the above AI slop example in 20 minutes, and on the first Super Bowl ad I tried factchecking.”</p><p><a href="https://x.com/jdischler/status/1885806962605957555" data-link-name="in body link">Replying to him</a><strong><a href="https://x.com/jdischler/status/1885806962605957555" data-link-name="in body link">,</a> </strong>the Google executive Jerry Dischler said this was not a “hallucination” – where AI systems invent untrue information – but rather a reflection of the fact the untrue information is contained in the websites that Gemini scrapes.</p><p>He wrote: “Gemini is grounded in the web – and users can always check the results and references. In this case, multiple sites across the web include the 50-60% stat.”</p><p>In a statement, <a href="https://www.theguardian.com/technology/google" data-link-name="in body link" data-component="auto-linked-tag">Google</a> said it remade the ad to remove the error after speaking to the cheesemonger featured in the clip and asking him what he would have done.</p><p>“Following his suggestion to have Gemini rewrite the product description without the stat, we updated the user interface to reflect what the business would do,” the statement added.</p><p>Google’s AI tools have previously come under fire for containing errors or unhelpful advice. In May last year, its AI overviews search feature was criticised <a href="https://www.theguardian.com/technology/article/2024/may/31/google-ai-summaries-sge-changes" data-link-name="in body link">after it told some users to use “non-toxic glue”</a> when they searched for “how to make cheese stick to pizza better”, while AI-generated responses said geologists recommended humans eat one rock a day.</p><p>Last year, Gemini was “paused” after Google <a href="https://www.theguardian.com/technology/2024/mar/08/we-definitely-messed-up-why-did-google-ai-tool-make-offensive-historical-images" data-link-name="in body link">conceded</a> it “definitely messed up” after a slew of social media posts exposed how Gemini’s image generation tool depicting a variety of historical figures – including popes, founding fathers of the US and, most excruciatingly, German second world war soldiers – <a href="https://www.theguardian.com/technology/2024/feb/22/google-pauses-ai-generated-images-of-people-after-ethnicity-criticism" data-link-name="in body link">as people of colour</a>.</p><p>The images, along with Gemini chatbot responses that vacillated over whether libertarians or Stalin had caused the greater harm, prompted negative commentary from figures including <a href="https://www.theguardian.com/technology/elon-musk" data-link-name="in body link" data-component="auto-linked-tag">Elon Musk</a>.</p></div></div></div>
  </body>
</html>
