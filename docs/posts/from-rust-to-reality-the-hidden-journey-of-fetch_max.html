<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://questdb.com/blog/rust-fetch-max-compiler-journey/">Original</a>
    <h1>From Rust to reality: The hidden journey of fetch_max</h1>
    
    <div id="readability-page-1" class="page"><article><div><p>
  QuestDB is the open-source time-series database for demanding workloads—from trading floors to mission control
  It delivers ultra-low latency, high ingestion throughput, and a multi-tier storage engine.
  Native support for Parquet and SQL keeps your data portable, AI-ready—no vendor lock-in.</p>
<hr/>
<h2 id="how-a-job-interview-sent-me-down-a-compiler-rabbit-hole"><a href="#how-a-job-interview-sent-me-down-a-compiler-rabbit-hole">How a Job Interview Sent Me Down a Compiler Rabbit Hole</a></h2>
<p>I occasionally interview candidates for engineering roles. We need people who understand
concurrent programming. One of our favorite questions involves keeping track of a
maximum value across multiple producer threads - a classic pattern that appears in many
real-world systems.</p>
<p>Candidates can use any language they want.
In Java (the language I know best), you might write a <a href="https://en.wikipedia.org/wiki/Compare-and-swap">CAS loop</a>,
or if you&#39;re feeling functional, use <code>updateAndGet()</code> with a lambda:</p>
<div><div><div><pre><p><span>AtomicLong highScore = new AtomicLong(100);</span></p><p><span>[...]</span></p><p><span>highScore.updateAndGet(current -&gt; Math.max(current, newScore));</span></p></pre></div></div></div>
<p>But that lambda is doing work - it&#39;s still looping under the hood, retrying if
another thread interferes. You can see the loop right in <a href="https://github.com/openjdk/jdk/blob/5271448b3a013b2e3edcd619a4a3b975b292dae1/src/java.base/share/classes/java/util/concurrent/atomic/AtomicLong.java#L268-L288">AtomicLong&#39;s source code</a>.</p>
<p>Then one candidate chose Rust.</p>
<p>I was following along as he started typing, expecting to see either an explicit
CAS loop or some functional wrapper around one. But instead, he just wrote:</p>
<div><div><div><pre><p><span>high_score.fetch_max(new_score, Ordering::Relaxed);</span></p></pre></div></div></div>
<p><em>&#34;Rust has fetch_max built in,&#34;</em> he explained casually, moving on to the next
part of the problem.</p>
<p>Hold on. This wasn&#39;t a wrapper around a loop pattern - this was a first-class
atomic operation, sitting right there next to <code>fetch_add</code> and <code>fetch_or</code>. Java
doesn&#39;t have this. C++ doesn&#39;t have this. How could Rust just... have this?</p>
<p>After the interview, curiosity got the better of me. Why would Rust provide
<code>fetch_max</code> as a built-in intrinsic? Intrinsics usually exist to leverage
specific hardware instructions. But x86-64 doesn&#39;t have an <code>atomic max</code>
instruction. So there had to be a CAS loop somewhere in the pipeline. Unless...
maybe some architectures <em>do</em> have this instruction natively? And if so, how
does the same Rust code work on both?</p>
<p>I had to find out. Was the loop in Rust&#39;s standard library? Was it in LLVM?
Was it generated during code generation for x86-64?</p>
<p>So I started digging. What I found was a fascinating journey through five
distinct layers of compiler transformations, each one peeling back another level
of abstraction, until I found exactly where that loop materialized. Let me share
what I discovered.</p>
<h2 id="layer-1:-the-rust-code"><a href="#layer-1:-the-rust-code">Layer 1: The Rust Code</a></h2>
<p>Let&#39;s start with what that candidate wrote - a simple high score tracker that can
be safely updated from multiple threads:</p>
<div><div><div><pre><p><span>use std::sync::atomic::{AtomicU64, Ordering};</span></p><p><span>fn main() {</span></p><p><span>    let high_score = AtomicU64::new(100);</span></p><p><span>    // [...]</span></p><p><span>    // Another thread reports a new score of 200</span></p><p><span>    let _old_score = high_score.fetch_max(200, Ordering::Relaxed);</span></p><p><span>    // [...]</span></p><p><span>}</span></p><p><span>// Save this snippet as `main.rs` we are going to use it later.</span></p></pre></div></div></div>
<p>This single line does exactly what it promises: atomically fetches the current
value, compares it with the new one, updates it if the new value is greater, and
returns the old value. It&#39;s safe, concise, and impossible to mess up. No
explicit loops, no retry logic visible anywhere. But how does it actually work under
the hood?</p>
<h2 id="layer-2:-the-macro-expansion"><a href="#layer-2:-the-macro-expansion">Layer 2: The Macro Expansion</a></h2>
<p>Before our <code>fetch_max</code> call even reaches anywhere close to machine code generation,
there&#39;s another layer of abstraction at work. The <code>fetch_max</code> method isn&#39;t hand-written
for each atomic type - it&#39;s generated by a Rust macro called <code>atomic_int!</code>.</p>
<p>If we peek into Rust&#39;s standard library source code, we find that <code>AtomicU64</code>
and all its methods are actually created by
<a href="https://github.com/rust-lang/rust/blob/f4b946a14788df30b693a28e96aa18c9bee618ad/library/core/src/sync/atomic.rs#L3788-L3806">this macro</a>:</p>
<div><div><div><pre><p><span>atomic_int! {</span></p><p><span>    cfg(target_has_atomic = &#34;64&#34;),</span></p><p><span>    // ... various configuration attributes ...</span></p><p><span>    atomic_umin, atomic_umax,  // The intrinsics to use</span></p><p><span>    8,                          // Alignment</span></p><p><span>    u64 AtomicU64              // The type to generate</span></p><p><span>}</span></p></pre></div></div></div>
<p>Inside this macro, <code>fetch_max</code> is defined as a
<a href="https://github.com/rust-lang/rust/blob/f4b946a14788df30b693a28e96aa18c9bee618ad/library/core/src/sync/atomic.rs#L3557-L3564">template</a>
that works for any integer type:</p>
<div><div><div><pre><p><span>pub fn fetch_max(&amp;self, val: $int_type, order: Ordering) -&gt; $int_type {</span></p><p><span>    // SAFETY: data races are prevented by atomic intrinsics.</span></p><p><span>    unsafe { $max_fn(self.v.get(), val, order) }</span></p><p><span>}</span></p></pre></div></div></div>
<p>The <code>$max_fn</code> placeholder gets replaced with <code>atomic_umax</code> for unsigned types
and <code>atomic_max</code> for signed types. This single macro definition generates
<code>fetch_max</code> methods for <code>AtomicI8</code>, <code>AtomicU8</code>, <code>AtomicI16</code>, <code>AtomicU16</code>, and so
on - all the way up to <code>AtomicU128</code>.</p>
<p>So our simple <code>fetch_max</code> call is actually invoking generated code. But what
does the <code>atomic_umax</code> function actually do? To answer that, we need
to see what the Rust compiler produces next.</p>
<h2 id="layer-3:-llvm-ir"><a href="#layer-3:-llvm-ir">Layer 3: LLVM IR</a></h2>
<p>Now that we know <code>fetch_max</code> is macro-generated code calling <code>atomic_umax</code>,
let&#39;s see what happens when the Rust compiler processes it. The compiler
doesn&#39;t go straight to assembly. First, it translates the code into an
intermediate representation. Rust uses the LLVM compiler project, so it
generates <strong>LLVM Intermediate Representation (IR)</strong>.</p>
<p>If we peek at the LLVM IR for our <code>fetch_max</code> call, we see something like this:</p>
<div><div><div><pre><p><span>; Before the transformation</span></p><p><span>bb7:</span></p><p><span>  %0 = atomicrmw umax ptr %self, i64 %val monotonic, align 8</span></p><p><span>  ...</span></p></pre></div></div></div>
<p>This is LLVM&#39;s language for saying: <em>&#34;I need an atomic read-modify-write
operation. The modification I want to perform is an unsigned maximum.&#34;</em></p>
<p>This is a powerful, high-level instruction within the compiler itself. But it
poses a critical question: does the CPU actually have a single instruction
called <code>umax</code>? For most architectures, the answer is no. So <em>how</em> does the
compiler bridge this gap?</p>
<h3 id="how-to-see-this-yourself"><a href="#how-to-see-this-yourself">How to See This Yourself</a></h3>
<p>My goal is not to merely describe what is happening, but to give you the tools to
see it for yourself. You can trace this transformation step-by-step on your own
machine.</p>
<p>First, tell the Rust compiler to stop after generating the LLVM IR:</p>
<div><div><div><pre><p><span>rustc --emit=llvm-ir main.rs</span></p></pre></div></div></div>
<p>This creates a <code>main.ll</code> file. This file contains the LLVM IR
representation of your Rust code, including our <code>atomicrmw umax</code> instruction.
Keep the file around; we&#39;ll use it in the next steps.</p>
<h2 id="interlude:-compiler-intrinsics"><a href="#interlude:-compiler-intrinsics">Interlude: Compiler Intrinsics</a></h2>
<p>We&#39;re missing something important. How does the Rust function <code>atomic_umax</code>
actually become the LLVM instruction <code>atomicrmw umax</code>? This is where compiler
intrinsics come into play.</p>
<p>If you dig into Rust&#39;s source code, you&#39;ll find that <code>atomic_umax</code> is
<a href="https://github.com/rust-lang/rust/blob/f4b946a14788df30b693a28e96aa18c9bee618ad/library/core/src/sync/atomic.rs#L4244-L4255">defined like this</a>:</p>
<div><div><div><pre><p><span>/// Updates `*dst` to the max value of `val` and the old value (unsigned comparison)</span></p><p><span>#[inline]</span></p><p><span>#[cfg(target_has_atomic)]</span></p><p><span>#[cfg_attr(miri, track_caller)] // even without panics, this helps for Miri backtraces</span></p><p><span>unsafe fn atomic_umax&lt;T: Copy&gt;(dst: *mut T, val: T, order: Ordering) -&gt; T {</span></p><p><span>    // SAFETY: the caller must uphold the safety contract for `atomic_umax`</span></p><p><span>    unsafe {</span></p><p><span>        match order {</span></p><p><span>            Relaxed =&gt; intrinsics::atomic_umax::&lt;T, { AO::Relaxed }&gt;(dst, val),</span></p><p><span>            Acquire =&gt; intrinsics::atomic_umax::&lt;T, { AO::Acquire }&gt;(dst, val),</span></p><p><span>            Release =&gt; intrinsics::atomic_umax::&lt;T, { AO::Release }&gt;(dst, val),</span></p><p><span>            AcqRel =&gt; intrinsics::atomic_umax::&lt;T, { AO::AcqRel }&gt;(dst, val),</span></p><p><span>            SeqCst =&gt; intrinsics::atomic_umax::&lt;T, { AO::SeqCst }&gt;(dst, val),</span></p><p><span>        }</span></p><p><span>    }</span></p><p><span>}</span></p></pre></div></div></div>
<p>But what is this <code>intrinsics::atomic_umax</code> function? If you <a href="https://github.com/rust-lang/rust/blob/62b4347e80cc86314bd98749e95eff8cdf8ef005/library/core/src/intrinsics/mod.rs#L238-L245">look at its
definition</a>,
you find something slightly unusual:</p>
<div><div><div><pre><p><span>/// Maximum with the current value using an unsigned comparison.</span></p><p><span>/// `T` must be an unsigned integer type.</span></p><p><span>///</span></p><p><span>/// The stabilized version of this intrinsic is available on the</span></p><p><span>/// [`atomic`] unsigned integer types via the `fetch_max` method. For example, [`AtomicU32::fetch_max`].</span></p><p><span>#[rustc_intrinsic]</span></p><p><span>#[rustc_nounwind]</span></p><p><span>pub unsafe fn atomic_umax&lt;T: Copy, const ORD: AtomicOrdering&gt;(dst: *mut T, src: T) -&gt; T;</span></p></pre></div></div></div>
<p>There is no body. This is a declaration, not a definition. The
<code>#[rustc_intrinsic]</code> attribute tells the Rust compiler that this function
maps directly to a low-level operation understood by the compiler
itself. When the Rust compiler sees a call to <code>intrinsics::atomic_umax</code>, it
knows to
<a href="https://github.com/rust-lang/rust/blob/de1b999ff6c981475e4491ea2fff1851655587e5/compiler/rustc_codegen_ssa/src/mir/intrinsic.rs#L442-L465">replace it</a>
with the corresponding
<a href="https://github.com/rust-lang/rust/blob/bcfc9b5073a92bbb4b1e4db2eab535357d8973ad/compiler/rustc_codegen_llvm/src/builder.rs#L1331-L1356">LLVM intrinsic function</a>.</p>
<p>So our journey actually looks like this:</p>
<ol>
<li><code>fetch_max</code> method (user-facing API)</li>
<li>Macro expands to call <code>atomic_umax</code> function</li>
<li><code>atomic_umax</code> is a compiler intrinsic</li>
<li>Rustc replaces the intrinsic with LLVM&#39;s <code>atomicrmw umax</code> ← <strong>We are here</strong></li>
<li>LLVM processes this instruction...</li>
</ol>
<h2 id="layer-4:-the-transformation"><a href="#layer-4:-the-transformation">Layer 4: The Transformation</a></h2>
<p>LLVM runs a series of &#34;passes&#34; that analyze and transform the code. The one we&#39;re interested in is called the
<a href="https://github.com/llvm/llvm-project/blob/4abcbb053f8adaf48dbfff677e8ccda1f6d52b33/llvm/lib/CodeGen/AtomicExpandPass.cpp"><code>AtomicExpandPass</code></a>.</p>
<p>Its job is to look at high-level atomic operations like <code>atomicrmw umax</code> and ask
the target architecture, <em>&#34;Can you do this natively?&#34;</em></p>
<p>When the <code>x86-64</code> backend says <em>&#34;No, I can&#39;t,&#34;</em> this pass expands the single
instruction into a sequence of more fundamental ones that the CPU <em>does</em>
understand. The result is a
<a href="https://github.com/llvm/llvm-project/blob/4abcbb053f8adaf48dbfff677e8ccda1f6d52b33/llvm/lib/CodeGen/AtomicExpandPass.cpp#L1628-L1687">compare-and-swap (CAS) loop</a>.</p>
<p>We can see this transformation in action by asking LLVM to emit the
intermediate representation before and after this pass. To see the IR <em>before</em>
the <code>AtomicExpandPass</code>, run:</p>
<div><div><div><pre><p><span>llc -print-before=atomic-expand main.ll -o /dev/null</span></p></pre></div></div></div>
<blockquote>
<p><em>Tip: If you do not have <code>llc</code> installed, you can ask <code>rustc</code> to run the pass for you directly.</em>
<code>rustc -C llvm-args=&#34;-print-before=atomic-expand -print-after=atomic-expand&#34; main.rs</code></p>
</blockquote>
<p>The code will be printed to your terminal. The function containing our atomic max
looks like this:</p>
<div><div><div><pre><p><span>*** IR Dump Before Expand Atomic instructions (atomic-expand) ***</span></p><p><span>; Function Attrs: inlinehint nonlazybind uwtable</span></p><p><span>define internal i64 @_ZN4core4sync6atomic9AtomicU649fetch_max17h6c42d6f2fc1a6124E(ptr align 8 %self, i64 %val, i8 %0) unnamed_addr #1 {</span></p><p><span>start:</span></p><p><span>  %_0 = alloca [8 x i8], align 8</span></p><p><span>  %order = alloca [1 x i8], align 1</span></p><p><span>  store i8 %0, ptr %order, align 1</span></p><p><span>  %1 = load i8, ptr %order, align 1</span></p><p><span>  %_7 = zext i8 %1 to i64</span></p><p><span>  switch i64 %_7, label %bb2 [</span></p><p><span>    i64 0, label %bb7</span></p><p><span>    i64 1, label %bb5</span></p><p><span>    i64 2, label %bb6</span></p><p><span>    i64 3, label %bb4</span></p><p><span>    i64 4, label %bb3</span></p><p><span>  ]</span></p><p><span>bb2:                                              ; preds = %start</span></p><p><span>  unreachable</span></p><p><span>bb7:                                              ; preds = %start</span></p><p><span>  %2 = atomicrmw umax ptr %self, i64 %val monotonic, align 8</span></p><p><span>  store i64 %2, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>bb5:                                              ; preds = %start</span></p><p><span>  %3 = atomicrmw umax ptr %self, i64 %val release, align 8</span></p><p><span>  store i64 %3, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>bb6:                                              ; preds = %start</span></p><p><span>  %4 = atomicrmw umax ptr %self, i64 %val acquire, align 8</span></p><p><span>  store i64 %4, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>bb4:                                              ; preds = %start</span></p><p><span>  %5 = atomicrmw umax ptr %self, i64 %val acq_rel, align 8</span></p><p><span>  store i64 %5, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>bb3:                                              ; preds = %start</span></p><p><span>  %6 = atomicrmw umax ptr %self, i64 %val seq_cst, align 8</span></p><p><span>  store i64 %6, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>bb1:                                              ; preds = %bb3, %bb4, %bb6, %bb5, %bb7</span></p><p><span>  %7 = load i64, ptr %_0, align 8</span></p><p><span>  ret i64 %7</span></p><p><span>}</span></p></pre></div></div></div>
<p>You can see the <code>atomicrmw umax</code> instruction in multiple places, depending on
the memory ordering specified. This is the high-level atomic operation that the
compiler backend understands, but the CPU does not.</p>
<div><div><div><pre><p><span>llc -print-after=atomic-expand main.ll -o /dev/null</span></p></pre></div></div></div>
<p>This is the relevant part of the output:</p>
<div><div><div><pre><p><span>*** IR Dump After Expand Atomic instructions (atomic-expand) ***</span></p><p><span>; Function Attrs: inlinehint nonlazybind uwtable</span></p><p><span>define internal i64 @_ZN4core4sync6atomic9AtomicU649fetch_max17h6c42d6f2fc1a6124E(ptr align 8 %self, i64 %val, i8 %0) unnamed_addr #1 {</span></p><p><span>start:</span></p><p><span>  %_0 = alloca [8 x i8], align 8</span></p><p><span>  %order = alloca [1 x i8], align 1</span></p><p><span>  store i8 %0, ptr %order, align 1</span></p><p><span>  %1 = load i8, ptr %order, align 1</span></p><p><span>  %_7 = zext i8 %1 to i64</span></p><p><span>  switch i64 %_7, label %bb2 [</span></p><p><span>    i64 0, label %bb7</span></p><p><span>    i64 1, label %bb5</span></p><p><span>    i64 2, label %bb6</span></p><p><span>    i64 3, label %bb4</span></p><p><span>    i64 4, label %bb3</span></p><p><span>  ]</span></p><p><span>bb2:                                              ; preds = %start</span></p><p><span>  unreachable</span></p><p><span>bb7:                                              ; preds = %start</span></p><p><span>  %2 = load i64, ptr %self, align 8               ; seed expected value</span></p><p><span>  br label %atomicrmw.start                       ; enter CAS loop</span></p><p><span>atomicrmw.start:                                  ; preds = %atomicrmw.start, %bb7</span></p><p><span>  %loaded = phi i64 [ %2, %bb7 ], [ %newloaded, %atomicrmw.start ] ; on first iteration: use %2, on retries: use value observed by last cmpxchg</span></p><p><span>  %3 = icmp ugt i64 %loaded, %val                 ; unsigned compare (umax semantics)</span></p><p><span>  %new = select i1 %3, i64 %loaded, i64 %val      ; desired = max(loaded, val)</span></p><p><span>  %4 = cmpxchg ptr %self, i64 %loaded, i64 %new monotonic monotonic, align 8 ; CAS: if *self==loaded, store new</span></p><p><span>  %success = extractvalue { i64, i1 } %4, 1       ; boolean: whether the swap happened</span></p><p><span>  %newloaded = extractvalue { i64, i1 } %4, 0     ; value seen in memory before the CAS</span></p><p><span>  br i1 %success, label %atomicrmw.end, label %atomicrmw.start ; loop until CAS succeeds</span></p><p><span>atomicrmw.end:                                    ; preds = %atomicrmw.start</span></p><p><span>  store i64 %newloaded, ptr %_0, align 8</span></p><p><span>  br label %bb1</span></p><p><span>[... MORE OF THE SAME, JUST FOR DIFFERENT ORDERING..]</span></p><p><span>bb1:                                              ; preds = %bb3, %bb4, %bb6, %bb5, %bb7</span></p><p><span>  %7 = load i64, ptr %_0, align 8</span></p><p><span>  ret i64 %7</span></p><p><span>}</span></p></pre></div></div></div>
<p>We can see the pass did not change the first part - it still has the code to dispatch based
on the memory ordering. But in the <code>bb7</code> block, where we originally had the
<code>atomicrmw umax</code> LLVM instruction, we now see a full compare-and-swap loop.
A compiler engineer would say that the <code>atomicrmw umax</code> instruction has been
&#34;lowered&#34; into a sequence of more primitive operations, that are closer to what
the hardware can actually execute.</p>
<p>Here&#39;s the simplified logic:</p>
<ol>
<li>Read (seed): grab the current value (<code>expected</code>).</li>
<li>Compute: <code>desired = umax(expected, val)</code>.</li>
<li>Attempt: <code>observed, success = cmpxchg(ptr, expected, desired, [...])</code>.</li>
<li>If success, return <code>observed</code> (the old value). Otherwise <code>set expected = observed</code> and loop.</li>
</ol>
<p>This CAS loop is a fundamental pattern in lock-free programming. The compiler
just built it for us automatically.</p>
<h2 id="layer-5:-the-final-product-(x86-64-assembly)"><a href="#layer-5:-the-final-product-(x86-64-assembly)">Layer 5: The Final Product (x86-64 Assembly)</a></h2>
<p>We&#39;re at the final step. To see the final machine code, you can tell <code>rustc</code> to
emit the assembly directly:</p>

<p>This will produce a <code>main.s</code> file containing the final assembly code.
Inside, you&#39;ll find the result of the <code>cmpxchg</code> loop:</p>
<div><div><div><pre><p><span>.LBB8_2:</span></p><p><span>	movq  -32(%rsp), %rax       # rax = &amp;self</span></p><p><span>	movq	(%rax), %rax        # rax = *self (seed &#39;expected&#39;)</span></p><p><span>	movq	%rax, -48(%rsp)     # spill expected to stack</span></p><p><span>.LBB8_3:                    # loop head</span></p><p><span>	movq	-48(%rsp), %rax     # rax = expected</span></p><p><span>	movq	-32(%rsp), %rcx     # rcx = &amp;self</span></p><p><span>	movq	-40(%rsp), %rdx     # rdx = val</span></p><p><span>	movq	%rax, %rsi          # rsi = expected (scratch)</span></p><p><span>	subq	%rdx, %rsi          # set flags for unsigned compare: expected - val</span></p><p><span>	cmovaq	%rax, %rdx          # if (expected &gt; val) rdx = expected; else rdx = val (compute max)</span></p><p><span>	lock cmpxchgq	%rdx, (%rcx)# CAS: if *rcx==rax then *rcx=rdx; rax &lt;- old *rcx; ZF=success</span></p><p><span>	sete	%cl                 # cl = success</span></p><p><span>	movq	%rax, -56(%rsp)     # spill observed to stack</span></p><p><span>	testb	$1, %cl             # branch on success</span></p><p><span>	movq	%rax, -48(%rsp)     # expected = observed (for retry)</span></p><p><span>	jne	.LBB8_4             # success -&gt; exit</span></p><p><span>	jmp	.LBB8_3             # failure → retry</span></p></pre></div></div></div>
<p><em>The syntax might look a bit different from what you&#39;re used to, that&#39;s because it&#39;s
in AT&amp;T syntax, which is the default for <code>rustc</code>. If you prefer Intel syntax, you can
use <code>rustc --emit=asm main.rs -C &#34;llvm-args=-x86-asm-syntax=intel&#34;</code> to get that.</em></p>
<p>I&#39;m not an assembly expert, but you can see the key parts of the CAS loop here:</p>
<ul>
<li><strong>Seed read (first iteration)</strong>: Load <code>*self</code> once to initialize the expected value.</li>
<li><strong>Compute umax without branching</strong>: The pair <code>sub</code> + <code>cmova</code> implements <code>desired = max_u(expected, val)</code>.</li>
<li><strong>CAS operation</strong>: On x86-64, <code>cmpxchg</code> uses <code>RAX</code> as the expected value and returns the observed value in <code>RAX</code>; <code>ZF</code>
encodes success.</li>
<li><strong>Retry or finish</strong>: If <code>ZF</code> is clear, we failed and need to retry. Otherwise, we are done.</li>
</ul>
<blockquote>
<p>Note we did not ask <code>rustc</code> to optimize the code. If we did, the compiler would
generate more efficient assembly: No spills to the stack, fewer jumps, no
dispatch on memory ordering, etc. But I wanted to keep the output as close
to the original IR as possible to make it easier to follow.</p>
</blockquote>
<h2 id="the-beauty-of-abstraction"><a href="#the-beauty-of-abstraction">The Beauty of Abstraction</a></h2>
<p>And there we have it. Our journey is complete. We started with a safe, clear,
single line of Rust and ended with a CAS loop written in assembly language.</p>
<p><strong>Rust <code>fetch_max</code></strong> → <strong>Macro-generated <code>atomic_umax</code></strong> → <strong>LLVM
<code>atomicrmw umax</code></strong> → <strong>LLVM <code>cmpxchg</code> loop</strong> → <strong>Assembly <code>lock cmpxchg</code> loop</strong></p>
<p>This journey is a perfect example of the power of modern compilers. We get to
work at a high level of abstraction, focusing on safety and logic, while the
compiler handles the messy, error-prone, and incredibly complex task of
generating correct and efficient code for the hardware.</p>
<p>So, next time you use an atomic, take a moment to appreciate the incredible,
hidden journey your code is about to take.</p>
<p>PS: After conducting this journey I learned that
<a href="https://en.cppreference.com/w/cpp/atomic/atomic/fetch_max.html">C++26 adds <code>fetch_max</code></a>
too!</p>
<p>PPS: We are <a href="https://questdb.com/careers/core-database-engineer/">hiring</a>!</p>
<h2 id="bonus:-apple-silicon-(aarch64)"><a href="#bonus:-apple-silicon-(aarch64)">Bonus: Apple Silicon (AArch64)</a></h2>
<p>Out of curiosity, I also checked how this looks on Apple Silicon (AArch64).
This architecture does have a native <code>atomic max</code> instruction, so the
<code>AtomicExpandPass</code> does not need to lower it into a CAS loop. The LLVM code before and after
the pass is identical, still containing the <code>atomicrmw umax</code> instruction.</p>
<p>The final assembly contains a variant of the <code>LDUMAX</code> instruction. This is the relevant part of the assembly:</p>
<div><div><div><pre><p><span>ldr    x8, [sp, #16]     # x8 = value to compare with</span></p><p><span>ldr    x9, [sp, #8]      # x9 = pointer to the atomic variable</span></p><p><span>ldumax x8, x8, [x9]      # atomic unsigned max (relaxed), [x9] = max(x8, [x9]), x8 = old value</span></p><p><span>str    x8, [sp, #40]     # Store old value</span></p><p><span>b      LBB8_11</span></p></pre></div></div></div>
<blockquote>
<p>Note that AArch64 uses <a href="https://developer.arm.com/documentation/dui0473/m/dom1359731145130">Unified Assembler Language</a>,
when reading the snippet above, it&#39;s important to remember that the destination register comes first.</p>
</blockquote>
<p>And that&#39;s really it. We could continue to dig into the microarchitecture, to see how instructions are executed
at the hardware level, what are the effects of the <code>LOCK</code> prefix, dive into differences in memory ordering, etc.
But we&#39;ll leave that for another day.</p>
<blockquote>
<p><strong>Alice:</strong> <em>&#34;Would you tell me, please, which way I ought to go from here?&#34;</em></p>
<p>- Lewis Carroll, Alice&#39;s Adventures in Wonderland</p>
</blockquote></div></article></div>
  </body>
</html>
