<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html">Original</a>
    <h1>On the foolishness of “natural language programming” (1979)</h1>
    
    <div id="readability-page-1" class="page"><div id="content">
				<p><u>On the foolishness of &#34;natural language programming&#34;</u>.</p>
				<p>Since the early days of automatic computing we have had people that have felt it as a shortcoming that programming required the care and accuracy that is characteristic for the use of any formal symbolism. They blamed the mechanical slave for its strict obedience with which it carried out its given instructions, even if a moment&#39;s thought would have revealed that those instructions contained an obvious mistake. &#34;But a moment is a long time, and thought is a painful process.&#34; (A.E.Houseman). They eagerly hoped and waited for more sensible machinery that would refuse to embark on such nonsensical activities as a trivial clerical error evoked at the time.</p>
				<p>Machine code, with its absence of almost any form of redundancy, was soon identified as a needlessly risky interface between man and machine. Partly in response to this recognition so-called &#34;high-level programming languages&#34; were developed, and, as time went by, we learned to a certain extent how to enhance the protection against silly mistakes. It was a significant improvement that now many a silly mistake did result in an error message instead of in an erroneous answer. (And even this improvement wasn&#39;t universally appreciated: some people found error messages they couldn&#39;t ignore more annoying than wrong results, and, when judging the relative merits of programming languages, some still seem to equate &#34;the ease of programming&#34; with the ease of making undetected mistakes.) The (abstract) machine corresponding to a programming language remained, however, a faithful slave, i.e. the nonsensible automaton perfectly capable of carrying out nonsensical instructions. Programming remained the use of a formal symbolism and, as such, continued to require the care and accuracy required before.</p>
				<p>In order to make machines significantly easier to use, it has been proposed (to try) to design machines that we could instruct in our native tongues. this would, admittedly, make the machines much more complicated, but, it was argued, by letting the machine carry a larger share of the burden, life would become easier for us. It sounds sensible provided you blame the obligation to use a formal symbolism as the source of your difficulties. But is the argument valid? I doubt.</p>
				<p>We know in the meantime that the choice of an interface is not just a division of (a fixed amount of) labour, because the work involved in co-operating and communicating across the interface has to be added. We know in the meantime —from sobering experience, I may add— that a change of interface can easily increase at both sides of the fence the amount of work to be done (even drastically so). Hence the increased preference for what are now called &#34;narrow interfaces&#34;. Therefore, although changing to communication between machine and man conducted in the latter&#39;s native tongue would greatly increase the machine&#39;s burden, we have to challenge the assumption that this would simplify man&#39;s life.</p>
				<p>A short look at the history of mathematics shows how justified this challenge is. Greek mathematics got stuck because it remained a verbal, pictorial activity, Moslem &#34;algebra&#34;, after a timid attempt at symbolism, died when it returned to the rhetoric style, and the modern civilized world could only emerge —for better or for worse— when Western Europe could free itself from the fetters of medieval scholasticism —a vain attempt at verbal precision!— thanks to the carefully, or at least consciously designed formal symbolisms that we owe to people like Vieta, Descartes, Leibniz, and (later) Boole.</p>
				<p>The virtue of formal texts is that their manipulations, in order to be legitimate, need to satisfy only a few simple rules; they are, when you come to think of it, an amazingly effective tool for ruling out all sorts of nonsense that, when we use our native tongues, are almost impossible to avoid.</p>
				<p>Instead of regarding the obligation to use formal symbols as a burden, we should regard the convenience of using them as a privilege: thanks to them, school children can learn to do what in earlier days only genius could achieve. (This was evidently not understood by the author that wrote —in 1977— in the preface of a technical report that &#34;even the standard symbols used for logical connectives have been avoided for the sake of clarity&#34;. The occurrence of that sentence suggests that the author&#39;s misunderstanding is not confined to him alone.) When all is said and told, the &#34;naturalness&#34; with which we use our native tongues boils down to the ease with which we can use them for making statements the nonsense of which is not obvious.</p>
				<p>It may be illuminating to try to imagine what would have happened if, right from the start our native tongue would have been the only vehicle for the input into and the output from our information processing equipment. My considered guess is that history would, in a sense, have repeated itself, and that computer science would consist mainly of the indeed black art how to bootstrap from there to a sufficiently well-defined formal system. We would need all the intellect in the world to get the interface narrow enough to be usable, and, in view of the history of mankind, it may not be overly pessimistic to guess that to do the job well enough would require again a few thousand years.</p>
				<p><u>Remark</u>. As a result of the educational trend away from intellectual discipline, the last decades have shown in the Western world a sharp decline of people&#39;s mastery of their own language: many people that by the standards of a previous generation should know better, are no longer able to use their native tongue effectively, even for purposes for which it is pretty adequate. (You have only to look at the indeed alarming amount of on close reading meaningless verbiage in scientific articles, technical reports, government publications etc.) This phenomenon —known as &#34;The New Illiteracy&#34;— should discourage those believers in natural language programming that lack the technical insight needed to predict its failure. (End of remark.)</p>
				<p>From one gut feeling I derive much consolation: I suspect that machines to be programmed in our native tongues —be it Dutch, English, American, French, German, or Swahili— are as damned difficult to make as they would be to use.</p>
				
			</div></div>
  </body>
</html>
