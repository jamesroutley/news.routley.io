<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://qwenlm.github.io/blog/qvq-max-preview/">Original</a>
    <h1>QVQ-Max: Think with Evidence</h1>
    
    <div id="readability-page-1" class="page"><div><article><div><figure><video loop="" src="http://qianwen-res.oss-cn-beijing.aliyuncs.com/QVQ-Max/head.mov" autoplay=""></video></figure><p><a href="https://chat.qwenlm.ai" target="_blank">QWEN CHAT</a>
<a href="https://github.com/QwenLM/Qwen2.5-VL" target="_blank">GITHUB</a>
<a href="https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5" target="_blank">HUGGING FACE</a>
<a href="https://modelscope.cn/collections/Qwen25-VL-58fbb5d31f1d47" target="_blank">MODELSCOPE</a>
<a href="https://discord.gg/yPEP2vHTu4" target="_blank">DISCORD</a></p><h2 id="introduction"><strong>Introduction</strong></h2><p>Last December, we launched QVQ-72B-Preview as an exploratory model, but it had many issues. Today, we are officially releasing the first version of QVQ-Max, our visual reasoning model. This model can not only “understand” the content in images and videos but also analyze and reason with this information to provide solutions. From math problems to everyday questions, from programming code to artistic creation, QVQ-Max has demonstrated impressive capabilities. Though this is just our first version, its potential is already eye-catching.</p><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/QVQ-Max/test_time.png#center" width="80%"/></figure><p>MathVision is a benchmark that aggregates various challenging multimodal mathematical problems, and we evaluate a model’s ability to solve complex math problems based on its performance on this benchmark. As shown in the figure, by adjusting the maximum length of the model’s thinking process, we observe a continuous improvement in the model’s accuracy on MathVision, demonstrating the immense potential of the model.</p><p>In the following sections, we will discuss the design philosophy behind QVQ-Max, its actual capabilities, and what it can do for you.</p><hr/><h3 id="why-do-we-need-visual-reasoning"><strong>Why Do We Need Visual Reasoning?</strong></h3><p>Traditional AI models mostly rely on text input, such as answering questions, writing articles, or generating code. However, in real life, much of the information isn’t expressed through words but rather through images, charts, or even videos. A single image can contain rich details like colors, shapes, spatial relationships, and more. These elements are often more intuitive, but also more complex than text.</p><p>For example, if you want to determine whether an architectural blueprint is reasonable, a description alone might not be enough. But if you could see the blueprint and analyze it using professional knowledge, the task becomes much easier. This is the significance of visual reasoning—it allows AI to not just “see,” but also “understand” and “think.”</p><p>Our goal in designing QVQ-Max was simple: to create an assistant that is both “sharp-eyed” and “quick-thinking,” capable of solving various practical problems for users.</p><hr/><h3 id="core-capabilities-from-observation-to-reasoning"><strong>Core Capabilities: From Observation to Reasoning</strong></h3><p>The capabilities of QVQ-Max can be summarized into three areas: detailed observation, deep reasoning, and flexible application. Let’s break down how it performs in each area.</p><ol><li><p><strong>Detailed Observation: Capturing Every Detail</strong></p></li><li><p><strong>Deep Reasoning: Not Just “Seeing,” But Also “Thinking”</strong></p></li><li><p><strong>Flexible Application: From Problem-Solving to Creation</strong></p></li></ol><hr/><h2 id="demo-cases"><strong>Demo Cases</strong></h2><p>QVQ-Max has a wide range of applications, whether in learning, work, or daily life—it can come in handy in many scenarios.</p><ul><li><p><strong>Workplace Tool</strong>: At work, QVQ-Max can assist in completing data analysis, organizing information, and even writing code</p></li><li><p><strong>Learning Assistant</strong>: For students, QVQ-Max can help solve difficult problems in subjects like math and physics, especially those accompanied by diagrams. It can also explain complex concepts in an intuitive way, making learning easier.</p></li><li><p><strong>Life Helper</strong>: In daily life, QVQ-Max can offer practical advice. For instance, it can recommend outfit combinations based on photos of your wardrobe, or guide you through cooking a new dish based on recipe images.</p></li></ul><div><div><p><span>Multi-image Recognition</span>
<a>Next</a></p></div></div><hr/><h2 id="next-step"><strong>Next Step</strong></h2><p>The current version of QVQ-Max is just the first iteration, and there’s still much room for improvement. Moving forward, we will focus on several key areas:</p><ol><li><strong>More Accurate Observations</strong>: Enhance recognition accuracy through grounding techniques, which validate observations made from visual content.</li><li><strong>Visual Agent</strong>: Improve the model’s ability to handle multi-step and more complex tasks, such as operating smartphones or computers, and even playing games.</li><li><strong>Better Interaction</strong>: Expand beyond text-based interaction to include more modalities, such as tool verification and visual generation, allowing for richer user experiences.</li></ol><p>Overall, QVQ-Max is a visual reasoning model that possesses both “vision” and “intellect.” It doesn’t just recognize the content in images; it combines this information to analyze, reason, and even complete creative tasks. Although it’s still in its growth phase, it has already shown great potential. Through continuous optimization, we aim to make QVQ-Max a truly practical visual agent that helps everyone solve real-world problems.</p></div></article></div></div>
  </body>
</html>
