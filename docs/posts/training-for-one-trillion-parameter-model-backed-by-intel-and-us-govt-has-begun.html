<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.techradar.com/pro/the-gpt-to-rule-them-all-training-for-one-trillion-parameter-model-backed-by-intel-and-us-government-has-just-begun">Original</a>
    <h1>Training for one trillion parameter model backed by Intel and US govt has begun</h1>
    
    <div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<div>

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<div>
<div>
<picture><source type="image/webp" alt="The Aurora supercomputer" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg"/><source type="image/jpeg" alt="The Aurora supercomputer" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg"/><img src="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-320-80.jpg" alt="The Aurora supercomputer" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg"/></picture>
</div>
</div>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/RNfefVMmkhiXYwnWif3tVD.jpg"/>
<meta itemprop="height" content="600"/>
<meta itemprop="width" content="338"/>
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Intel)</span>
</figcaption>
</div>

<div id="article-body">
<p>Scientists are training a gargantuan one-trillion-parameter generative AI system dubbed &#39;ScienceGPT&#39; based on scientific data from the newly established <a data-analytics-id="inline-link" href="https://www.techradar.com/pro/intels-most-powerful-supercomputer-is-ready-to-be-switched-on" data-before-rewrite-localise="https://www.techradar.com/pro/intels-most-powerful-supercomputer-is-ready-to-be-switched-on">Aurora supercomputer</a>.</p><p>The AuroraGPT AI model, which is being trained by researchers at the Argonne National Lab (ALN) in Illinois, USA, is powered by <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/intel" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/intel">Intel</a>&#39;s Ponte Vecchio GPUs which provide the main computing power, and is being backed by the US government.</p><p>Training could take months to complete, according to HPC Wire, with training currently limited to 256 of the roughly 10,000 nodes of the Aurora supercomputer, before this is scaled up over time. Even given this limitation, Intel and ANL are only testing the model training on a string of 64 nodes, with caution due to Aurora&#39;s unique design as a supercomputer.</p><h2 id="inside-apos-sciencegpt-apos-3">Inside &#39;ScienceGPT&#39;</h2><p>At one trillion parameters, ScienceGPT will be one of the largest LLMs out there. While it won&#39;t quite hit the size of the reported 1.7-trillion-parameter <a data-analytics-id="inline-link" href="https://www.techradar.com/news/gpt-4" data-before-rewrite-localise="https://www.techradar.com/news/gpt-4">GPT-4</a>, developed by <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/openai" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/openai">OpenAI</a>, it&#39;ll be almost twice as large as the 560-billion-parameter Pathways Language Model, which powers <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/google" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/google">Google</a>&#39;s Bard.</p><p>“It combines all the text, codes, specific scientific results, papers, into the model that science can use to speed up research,” said Ogi Brkic, vice president and general manager for data center and HPC solutions, in a press briefing.</p><p>It&#39;ll operate like <a data-analytics-id="inline-link" href="https://www.techradar.com/news/chatgpt-explained" data-before-rewrite-localise="https://www.techradar.com/news/chatgpt-explained">ChatGPT</a>, but it&#39;s yet unclear at the moment whether it will be multimodal, in that it will generate different kinds of media like text, images, and video. </p><p>Aurora  – which will be the second exascale supercomputer in US history – has just established itself on the Top500 list of the most powerful supercomputers after years of being developed. </p><p>It&#39;s the second-most powerful supercomputer after Froniter, and is powered by 60,000 Intel GPUs while boating 10,000 computing nodes over 166 racks, alongside more than 80,000 networking nodes. </p><p>It is still being finished, however, and will likely exceed Frontier&#39;s performance when it&#39;s fully up to speed, and all testing and finetuning is complete, <a data-analytics-id="inline-link" href="https://www.top500.org/news/frontier-remains-no-1-in-the-top500-but-aurora-with-intels-sapphire-rapids-chips-enters-with-a-half-scale-system-at-no-2/" data-url="https://www.top500.org/news/frontier-remains-no-1-in-the-top500-but-aurora-with-intels-sapphire-rapids-chips-enters-with-a-half-scale-system-at-no-2/">said Top500</a>.</p><h3 id="section-more-from-techradar-pro"><span>More from TechRadar Pro</span></h3><ul><li><a href="https://www.techradar.com/pro/nvidia-is-powering-a-mega-tesla-supercomputer-powered-by-10000-h100-gpus" data-before-rewrite-localise="https://www.techradar.com/pro/nvidia-is-powering-a-mega-tesla-supercomputer-powered-by-10000-h100-gpus">Nvidia is powering a mega Tesla supercomputer powered by 10,000 H100 GPUs</a></li><li>Here&#39;s the <a href="https://www.techradar.com/news/heres-the-smallest-aiml-supercomputer-ever" data-before-rewrite-localise="https://www.techradar.com/news/heres-the-smallest-aiml-supercomputer-ever">smallest AI/ML supercomputer</a> ever</li><li>These are the <a href="https://www.techradar.com/best/best-ai-tools" data-before-rewrite-localise="https://www.techradar.com/best/best-ai-tools">best AI tools</a> you can try today</li></ul>
</div>
<div id="slice-container-newsletterForm-articleInbodyContent-AhvpnTSSefmBa4kGyesKRo"><div data-hydrate="true"><div><section></section><section><p>Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed!</p></section></div></div></div>
<div id="slice-container-authorBio-AhvpnTSSefmBa4kGyesKRo"><div><p>Keumars Afifi-Sabet is the Features Editor for ITPro, CloudPro and ChannelPro. He oversees the commissioning and publication of in-depth and long-form features, including case studies and op-eds, across a breadth of topics in the B2B technology space. He also contributes to a vareity of other publications including The Week Digital and TechRadar Pro. Keumars joined ITPro as a staff writer in 2018, and has expertise in a variety of areas including  AI, cyber security, cloud computing and digital transformation, as well as public policy and legislation.</p></div></div>



</section>












</div>
</div></div>
  </body>
</html>
