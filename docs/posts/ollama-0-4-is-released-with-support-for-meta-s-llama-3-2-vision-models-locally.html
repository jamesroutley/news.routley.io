<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ollama.com/blog/llama3.2-vision">Original</a>
    <h1>Ollama 0.4 is released with support for Meta&#39;s Llama 3.2 Vision models locally</h1>
    
    <div id="readability-page-1" class="page"><div>
      
  <article>
    
    <h2>November 6, 2024</h2>
    <section>
      <p><a href="https://ollama.com/library/llama3.2-vision">Llama 3.2 Vision</a> is now available to run in Ollama, in both 11B and 90B sizes.</p>

<video controls="" autoplay="">
    <source src="https://github.com/user-attachments/assets/82e25d0d-921c-4900-b78f-589c1bb86968"/>
</video>

<h2>Get started</h2>

<p><a href="https://ollama.com/download">Download Ollama 0.4</a>, then run:</p>

<pre><code>ollama run llama3.2-vision
</code></pre>

<p>To run the larger 90B model:</p>

<pre><code>ollama run llama3.2-vision:90b
</code></pre>

<p>To add an image to the prompt, drag and drop it into the terminal, or add a path to the image to the prompt on Linux.</p>

<blockquote>
<p>Note: Llama 3.2 Vision 11B requires least 8GB of VRAM, and the 90B model requires at least 64 GB of VRAM.</p>
</blockquote>

<h2>Examples</h2>

<h3>Handwriting</h3>

<p><img src="https://ollama.com/public/blog/llama3.2-vision-handwriting.png" alt="handwriting example"/></p>

<h3>Optical Character Recognition (OCR)</h3>

<p><img src="https://ollama.com/public/blog/llama3.2-vision-ocr.png" alt="OCR example"/></p>

<h3>Charts &amp; tables</h3>

<p><img src="https://ollama.com/public/blog/llama3.2-vision-charts.png" alt="charts and tables example"/></p>

<h3>Image Q&amp;A</h3>

<p><img src="https://ollama.com/public/blog/llama3.2-vision-imageqa.png" alt="image Q&amp;A example"/></p>

<h2>Usage</h2>

<p>First, pull the model:</p>

<pre><code>ollama pull llama3.2-vision
</code></pre>

<h3>Python Library</h3>

<p>To use Llama 3.2 Vision with the Ollama <a href="https://github.com/ollama/ollama-python">Python library</a>:</p>

<pre><code>import ollama

response = ollama.chat(
    model=&#39;llama3.2-vision&#39;,
    messages=[{
        &#39;role&#39;: &#39;user&#39;,
        &#39;content&#39;: &#39;What is in this image?&#39;,
        &#39;images&#39;: [&#39;image.jpg&#39;]
    }]
)

print(response)
</code></pre>

<h3>JavaScript Library</h3>

<p>To use Llama 3.2 Vision with the Ollama <a href="https://github.com/ollama/ollama-js">JavaScript library</a>:</p>

<pre><code>import ollama from &#39;ollama&#39;

const response = await ollama.chat({
  model: &#39;llama3.2-vision&#39;,
  messages: [{
    role: &#39;user&#39;,
    content: &#39;What is in this image?&#39;,
    images: [&#39;image.jpg&#39;]
  }]
})

console.log(response)
</code></pre>

<h3>cURL</h3>

<pre><code>curl http://localhost:11434/api/chat -d &#39;{
  &#34;model&#34;: &#34;llama3.2-vision&#34;,
  &#34;messages&#34;: [
    {
      &#34;role&#34;: &#34;user&#34;,
      &#34;content&#34;: &#34;what is in this image?&#34;,
      &#34;images&#34;: [&#34;&lt;base64-encoded image data&gt;&#34;]
    }
  ]
}&#39;
</code></pre>

<p><a href="https://ollama.com/download"><img src="https://ollama.com/public/blog/ollama-vision.png" alt="Ollama Vision logo" title="Download Ollama"/></a></p>

    </section>
  </article>

    </div></div>
  </body>
</html>
