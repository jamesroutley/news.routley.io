<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.gnu.org/software/parallel/parallel_design.html">Original</a>
    <h1>Design of GNU Parallel (2015)</h1>
    
    <div id="readability-page-1" class="page"><section id="design-of-gnu-parallel">

<p>This document describes design decisions made in the development of GNU <strong>parallel</strong> and the reasoning behind them. It will give an overview of why some of the code looks the way it does, and will help new maintainers understand the code better.</p>
<section id="one-file-program">
<h2>One file program<a href="#one-file-program" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> is a Perl script in a single file. It is object oriented, but contrary to normal Perl scripts each class is not in its own file. This is due to user experience: The goal is that in a pinch the user will be able to get GNU <strong>parallel</strong> working simply by copying a single file: No need to mess around with environment variables like PERL5LIB.</p>
</section>
<section id="choice-of-programming-language">
<h2>Choice of programming language<a href="#choice-of-programming-language" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> is designed to be able to run on old systems. That means that it cannot depend on a compiler being installed - and especially not a compiler for a language that is younger than 20 years old.</p>
<p>The goal is that you can use GNU <strong>parallel</strong> on any system, even if you are not allowed to install additional software.</p>
<p>Of all the systems I have experienced, I have yet to see a system that had GCC installed that did not have Perl. The same goes for Rust, Go, Haskell, and other younger languages. I have, however, seen systems with Perl without any of the mentioned compilers.</p>
<p>Most modern systems also have either Python2 or Python3 installed, but you still cannot be certain which version, and since Python2 cannot run under Python3, Python is not an option.</p>
<p>Perl has the added benefit that implementing the {= perlexpr =} replacement string was fairly easy.</p>
<p>The primary drawback is that Perl is slow. So there is an overhead of 3-10 ms/job and 1 ms/MB output (and even more if you use <strong>--tag</strong>).</p>
</section>
<section id="old-perl-style">
<h2>Old Perl style<a href="#old-perl-style" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> uses some old, deprecated constructs. This is due to a goal of being able to run on old installations. Currently the target is CentOS 3.9 and Perl 5.8.0.</p>
</section>
<section id="scalability-up-and-down">
<h2>Scalability up and down<a href="#scalability-up-and-down" title="Permalink to this headline"></a></h2>
<p>The smallest system GNU <strong>parallel</strong> is tested on is a 32 MB ASUS WL500gP. The largest is a 2 TB 128-core machine. It scales up to around 100 machines - depending on the duration of each job.</p>
</section>
<section id="exponentially-back-off">
<h2>Exponentially back off<a href="#exponentially-back-off" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> busy waits. This is because the reason why a job is not started may be due to load average (when using <strong>--load</strong>), and thus it will not make sense to just wait for a job to finish. Instead the load average must be rechecked regularly. Load average is not the only reason: <strong>--timeout</strong> has a similar problem.</p>
<p>To not burn up too much CPU GNU <strong>parallel</strong> sleeps exponentially longer and longer if nothing happens, maxing out at 1 second.</p>
</section>
<section id="shell-compatibility">
<h2>Shell compatibility<a href="#shell-compatibility" title="Permalink to this headline"></a></h2>
<p>It is a goal to have GNU <strong>parallel</strong> work equally well in any shell. However, in practice GNU <strong>parallel</strong> is being developed in <strong>bash</strong> and thus testing in other shells is limited to reported bugs.</p>
<p>When an incompatibility is found there is often not an easy fix: Fixing the problem in <strong>csh</strong> often breaks it in <strong>bash</strong>. In these cases the fix is often to use a small Perl script and call that.</p>
</section>
<section id="env-parallel">
<h2>env_parallel<a href="#env-parallel" title="Permalink to this headline"></a></h2>
<p><strong>env_parallel</strong> is a dummy shell script that will run if <strong>env_parallel</strong> is not an alias or a function and tell the user how to activate the alias/function for the supported shells.</p>
<p>The alias or function will copy the current environment and run the command with GNU <strong>parallel</strong> in the copy of the environment.</p>
<p>The problem is that you cannot access all of the current environment inside Perl. E.g. aliases, functions and unexported shell variables.</p>
<p>The idea is therefore to take the environment and put it in <strong>$PARALLEL_ENV</strong> which GNU <strong>parallel</strong> prepends to every command.</p>
<p>The only way to have access to the environment is directly from the shell, so the program must be written in a shell script that will be sourced and there has to deal with the dialect of the relevant shell.</p>
<section id="id1">
<h3>env_parallel.*<a href="#id1" title="Permalink to this headline"></a></h3>
<p>These are the files that implements the alias or function <strong>env_parallel</strong> for a given shell. It could be argued that these should be put in some obscure place under /usr/lib, but by putting them in your path it becomes trivial to find the path to them and <strong>source</strong> them:</p>
<div><div><pre><span></span><span>source</span> <span>`which env_parallel.foo`</span>
</pre></div>
</div>
<p>The beauty is that they can be put anywhere in the path without the user having to know the location. So if the user&#39;s path includes /afs/bin/i386_fc5 or /usr/pkg/parallel/bin or /usr/local/parallel/20161222/sunos5.6/bin the files can be put in the dir that makes most sense for the sysadmin.</p>
</section>
<section id="env-parallel-bash-env-parallel-sh-env-parallel-ash-env-parallel-dash-env-parallel-zsh-env-parallel-ksh-env-parallel-mksh">
<h3>env_parallel.bash / env_parallel.sh / env_parallel.ash / env_parallel.dash / env_parallel.zsh / env_parallel.ksh / env_parallel.mksh<a href="#env-parallel-bash-env-parallel-sh-env-parallel-ash-env-parallel-dash-env-parallel-zsh-env-parallel-ksh-env-parallel-mksh" title="Permalink to this headline"></a></h3>
<p><strong>env_parallel.(bash|sh|ash|dash|ksh|mksh|zsh)</strong> defines the function <strong>env_parallel</strong>. It uses <strong>alias</strong> and <strong>typeset</strong> to dump the configuration (with a few exceptions) into <strong>$PARALLEL_ENV</strong> before running GNU <strong>parallel</strong>.</p>
<p>After GNU <strong>parallel</strong> is finished, <strong>$PARALLEL_ENV</strong> is deleted.</p>
</section>
<section id="env-parallel-csh">
<h3>env_parallel.csh<a href="#env-parallel-csh" title="Permalink to this headline"></a></h3>
<p><strong>env_parallel.csh</strong> has two purposes: If <strong>env_parallel</strong> is not an alias: make it into an alias that sets <strong>$PARALLEL</strong> with arguments and calls <strong>env_parallel.csh</strong>.</p>
<p>If <strong>env_parallel</strong> is an alias, then <strong>env_parallel.csh</strong> uses <strong>$PARALLEL</strong> as the arguments for GNU <strong>parallel</strong>.</p>
<p>It exports the environment by writing a variable definition to a file for each variable.  The definitions of aliases are appended to this file. Finally the file is put into <strong>$PARALLEL_ENV</strong>.</p>
<p>GNU <strong>parallel</strong> is then run and <strong>$PARALLEL_ENV</strong> is deleted.</p>
</section>
<section id="env-parallel-fish">
<h3>env_parallel.fish<a href="#env-parallel-fish" title="Permalink to this headline"></a></h3>
<p>First all functions definitions are generated using a loop and <strong>functions</strong>.</p>
<p>Dumping the scalar variable definitions is harder.</p>
<p><strong>fish</strong> can represent non-printable characters in (at least) 2 ways. To avoid problems all scalars are converted to \XX quoting.</p>
<p>Then commands to generate the definitions are made and separated by NUL.</p>
<p>This is then piped into a Perl script that quotes all values. List elements will be appended using two spaces.</p>
<p>Finally \n is converted into \1 because <strong>fish</strong> variables cannot contain \n. GNU <strong>parallel</strong> will later convert all \1 from <strong>$PARALLEL_ENV</strong> into \n.</p>
<p>This is then all saved in <strong>$PARALLEL_ENV</strong>.</p>
<p>GNU <strong>parallel</strong> is called, and <strong>$PARALLEL_ENV</strong> is deleted.</p>
</section>
</section>
<section id="parset-supported-in-sh-ash-dash-bash-zsh-ksh-mksh">
<h2>parset (supported in sh, ash, dash, bash, zsh, ksh, mksh)<a href="#parset-supported-in-sh-ash-dash-bash-zsh-ksh-mksh" title="Permalink to this headline"></a></h2>
<p><strong>parset</strong> is a shell function. This is the reason why <strong>parset</strong> can set variables: It runs in the shell which is calling it.</p>
<p>It is also the reason why <strong>parset</strong> does not work, when data is piped into it: <strong>... | parset ...</strong> makes <strong>parset</strong> start in a subshell, and any changes in environment can therefore not make it back to the calling shell.</p>
</section>
<section id="job-slots">
<h2>Job slots<a href="#job-slots" title="Permalink to this headline"></a></h2>
<p>The easiest way to explain what GNU <strong>parallel</strong> does is to assume that there are a number of job slots, and when a slot becomes available a job from the queue will be run in that slot. But originally GNU <strong>parallel</strong> did not model job slots in the code. Job slots have been added to make it possible to use <strong>{%}</strong> as a replacement string.</p>
<p>While the job sequence number can be computed in advance, the job slot can only be computed the moment a slot becomes available. So it has been implemented as a stack with lazy evaluation: Draw one from an empty stack and the stack is extended by one. When a job is done, push the available job slot back on the stack.</p>
<p>This implementation also means that if you re-run the same jobs, you cannot assume jobs will get the same slots. And if you use remote executions, you cannot assume that a given job slot will remain on the same remote server. This goes double since number of job slots can be adjusted on the fly (by giving <strong>--jobs</strong> a file name).</p>
</section>
<section id="rsync-protocol-version">
<h2>Rsync protocol version<a href="#rsync-protocol-version" title="Permalink to this headline"></a></h2>
<p><strong>rsync</strong> 3.1.x uses protocol 31 which is unsupported by version 2.5.7. That means that you cannot push a file to a remote system using <strong>rsync</strong> protocol 31, if the remote system uses 2.5.7. <strong>rsync</strong> does not automatically downgrade to protocol 30.</p>
<p>GNU <strong>parallel</strong> does not require protocol 31, so if the <strong>rsync</strong> version is &gt;= 3.1.0 then <strong>--protocol 30</strong> is added to force newer <strong>rsync</strong>s to talk to version 2.5.7.</p>
</section>
<section id="compression">
<h2>Compression<a href="#compression" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> buffers output in temporary files.  <strong>--compress</strong> compresses the buffered data.  This is a bit tricky because there should be no files to clean up if GNU <strong>parallel</strong> is killed by a power outage.</p>
<p>GNU <strong>parallel</strong> first selects a compression program. If the user has not selected one, the first of these that is in $PATH is used: <strong>pzstd lbzip2 pbzip2 zstd pixz lz4 pigz lzop plzip lzip gzip lrz pxz bzip2 lzma xz clzip</strong>. They are sorted by speed on a 128 core machine.</p>
<p>Schematically the setup is as follows:</p>
<div><div><pre><span></span><span>command</span> <span>started</span> <span>by</span> <span>parallel</span> <span>|</span> <span>compress</span> <span>&gt;</span> <span>tmpfile</span>
<span>cattail</span> <span>tmpfile</span> <span>|</span> <span>uncompress</span> <span>|</span> <span>parallel</span> <span>which</span> <span>reads</span> <span>the</span> <span>output</span>
</pre></div>
</div>
<p>The setup is duplicated for both standard output (stdout) and standard error (stderr).</p>
<p>GNU <strong>parallel</strong> pipes output from the command run into the compression program which saves to a tmpfile. GNU <strong>parallel</strong> records the pid of the compress program.  At the same time a small Perl script (called <strong>cattail</strong> above) is started: It basically does <strong>cat</strong> followed by <strong>tail -f</strong>, but it also removes the tmpfile as soon as the first byte is read, and it continuously checks if the pid of the compression program is dead. If the compress program is dead, <strong>cattail</strong> reads the rest of tmpfile and exits.</p>
<p>As most compression programs write out a header when they start, the tmpfile in practice is removed by <strong>cattail</strong> after around 40 ms.</p>
<p>More detailed it works like this:</p>
<div><div><pre><span></span><span>bash</span> <span>(</span> <span>command</span> <span>)</span> <span>|</span>
  <span>sh</span> <span>(</span> <span>emptywrapper</span> <span>(</span> <span>bash</span> <span>(</span> <span>compound</span> <span>compress</span> <span>)</span> <span>)</span> <span>&gt;</span><span>tmpfile</span> <span>)</span>
<span>cattail</span> <span>(</span> <span>rm</span> <span>tmpfile</span><span>;</span> <span>compound</span> <span>decompress</span> <span>)</span> <span>&lt;</span> <span>tmpfile</span>
</pre></div>
</div>
<p>This complex setup is to make sure compress program is only started if there is input. This means each job will cause 8 processes to run. If combined with <strong>--keep-order</strong> these processes will run until the job has been printed.</p>
</section>
<section id="wrapping">
<h2>Wrapping<a href="#wrapping" title="Permalink to this headline"></a></h2>
<p>The command given by the user can be wrapped in multiple templates. Templates can be wrapped in other templates.</p>
<ul>
<li><p><strong>$COMMAND</strong></p></li>
</ul>
<blockquote>
<p>the command to run.</p></blockquote>
<ul>
<li><p><strong>$INPUT</strong></p></li>
</ul>
<blockquote>
<p>the input to run.</p></blockquote>
<ul>
<li><p><strong>$SHELL</strong></p></li>
</ul>
<blockquote>
<p>the shell that started GNU Parallel.</p></blockquote>
<ul>
<li><p><strong>$SSHLOGIN</strong></p></li>
</ul>
<blockquote>
<p>the sshlogin.</p></blockquote>
<ul>
<li><p><strong>$WORKDIR</strong></p></li>
</ul>
<blockquote>
<p>the working dir.</p></blockquote>
<ul>
<li><p><strong>$FILE</strong></p></li>
</ul>
<blockquote>
<p>the file to read parts from.</p></blockquote>
<ul>
<li><p><strong>$STARTPOS</strong></p></li>
</ul>
<blockquote>
<p>the first byte position to read from <strong>$FILE</strong>.</p></blockquote>
<ul>
<li><p><strong>$LENGTH</strong></p></li>
</ul>
<blockquote>
<p>the number of bytes to read from <strong>$FILE</strong>.</p></blockquote>
<ul>
<li><p>--shellquote</p></li>
</ul>
<blockquote>
<p>echo <em>Double quoted $INPUT</em></p></blockquote>
<ul>
<li><p>--nice <em>pri</em></p></li>
</ul>
<blockquote>
<div><p>Remote: See <strong>The remote system wrapper</strong>.</p>
<p>Local: <strong>setpriority(0,0,$nice)</strong></p>
</div></blockquote>
<ul>
<li><p>--cat</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>cat</span> <span>&gt;</span> <span>{};</span> <span>$COMMAND</span> <span>{};</span>
<span>perl</span> <span>-</span><span>e</span> <span>&#39;$bash = shift;</span>
<span>  $csh = shift;</span>
<span>  for(@ARGV) { unlink;rmdir; }</span>
<span>  if($bash =~ s/h//) { exit $bash;  }</span>
<span>  exit $csh;&#39;</span> <span>&#34;$?h&#34;</span> <span>&#34;$status&#34;</span> <span>{};</span>
</pre></div>
</div>
<p>{} is set to <strong>$PARALLEL_TMP</strong> which is a tmpfile. The Perl script saves the exit value, unlinks the tmpfile, and returns the exit value - no matter if the shell is <strong>bash</strong>/<strong>ksh</strong>/<strong>zsh</strong> (using $?) or <strong>*csh</strong>/<strong>fish</strong> (using $status).</p>
</div></blockquote>
<ul>
<li><p>--fifo</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>perl</span> <span>-</span><span>e</span> <span>&#39;($s,$c,$f) = @ARGV;</span>
<span>  # mkfifo $PARALLEL_TMP</span>
<span>  system &#34;mkfifo&#34;, $f;</span>
<span>  # spawn $shell -c $command &amp;</span>
<span>  $pid = fork || exec $s, &#34;-c&#34;, $c;</span>
<span>  open($o,&#34;&gt;&#34;,$f) || die $!;</span>
<span>  # cat &gt; $PARALLEL_TMP</span>
<span>  while(sysread(STDIN,$buf,131072)){</span>
<span>     syswrite $o, $buf;</span>
<span>  }</span>
<span>  close $o;</span>
<span>  # waitpid to get the exit code from $command</span>
<span>  waitpid $pid,0;</span>
<span>  # Cleanup</span>
<span>  unlink $f;</span>
<span>  exit $?/256;&#39;</span> <span>$SHELL</span> <span>-</span><span>c</span> <span>$COMMAND</span> <span>$PARALLEL_TMP</span>
</pre></div>
</div>
<p>This is an elaborate way of: mkfifo {}; run <strong>$COMMAND</strong> in the background using <strong>$SHELL</strong>; copying STDIN to {}; waiting for background to complete; remove {} and exit with the exit code from <strong>$COMMAND</strong>.</p>
<p>It is made this way to be compatible with <strong>*csh</strong>/<strong>fish</strong>.</p>
</div></blockquote>
<ul>
<li><p>--pipepart</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>&lt;</span> <span>$FILE</span> <span>perl</span> <span>-</span><span>e</span> <span>&#39;while(@ARGV) {</span>
<span>    sysseek(STDIN,shift,0) || die;</span>
<span>    $left = shift;</span>
<span>    while($read =</span>
<span>          sysread(STDIN,$buf,</span>
<span>                  ($left &gt; 131072 ? 131072 : $left))){</span>
<span>      $left -= $read;</span>
<span>      syswrite(STDOUT,$buf);</span>
<span>    }</span>
<span>  }&#39;</span> <span>$STARTPOS</span> <span>$LENGTH</span>
</pre></div>
</div>
<p>This will read <strong>$LENGTH</strong> bytes from <strong>$FILE</strong> starting at <strong>$STARTPOS</strong> and send it to STDOUT.</p>
</div></blockquote>
<ul>
<li><p>--sshlogin $SSHLOGIN</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>ssh</span> <span>$SSHLOGIN</span> <span>&#34;$COMMAND&#34;</span>
</pre></div>
</div>
</div></blockquote>
<ul>
<li><p>--transfer</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>ssh</span> <span>$SSHLOGIN</span> <span>mkdir</span> <span>-</span><span>p</span> <span>./</span><span>$WORKDIR</span><span>;</span>
<span>rsync</span> <span>--</span><span>protocol</span> <span>30</span> <span>-</span><span>rlDzR</span> <span>\</span>
      <span>-</span><span>essh</span> <span>.</span><span>/{} $SSHLOGIN:./</span><span>$WORKDIR</span><span>;</span>
<span>ssh</span> <span>$SSHLOGIN</span> <span>&#34;$COMMAND&#34;</span>
</pre></div>
</div>
<p>Read about <strong>--protocol 30</strong> in the section <strong>Rsync protocol version</strong>.</p>
</div></blockquote>
<ul>
<li><p>--transferfile <em>file</em></p></li>
</ul>
<blockquote>
<p>&lt;&lt;todo&gt;&gt;</p></blockquote>
<ul>
<li><p>--basefile</p></li>
</ul>
<blockquote>
<p>&lt;&lt;todo&gt;&gt;</p></blockquote>
<ul>
<li><p>--return <em>file</em></p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>$COMMAND</span><span>;</span> <span>_EXIT_status</span><span>=</span><span>$?</span><span>;</span> <span>mkdir</span> <span>-</span><span>p</span> <span>$WORKDIR</span><span>;</span>
<span>rsync</span> <span>--</span><span>protocol</span> <span>30</span> <span>\</span>
  <span>--</span><span>rsync</span><span>-</span><span>path</span><span>=</span><span>cd</span><span>\</span> <span>.</span><span>/$WORKDIR\;\ rsync \</span>
<span>  -rlDzR -essh $SSHLOGIN:./</span><span>$FILE</span> <span>./</span><span>$WORKDIR</span><span>;</span>
<span>exit</span> <span>$_EXIT_status</span><span>;</span>
</pre></div>
</div>
<p>The <strong>--rsync-path=cd ...</strong> is needed because old versions of <strong>rsync</strong> do not support <strong>--no-implied-dirs</strong>.</p>
<p>The <strong>$_EXIT_status</strong> trick is to postpone the exit value. This makes it incompatible with <strong>*csh</strong> and should be fixed in the future. Maybe a wrapping &#39;sh -c&#39; is enough?</p>
</div></blockquote>
<ul>
<li><p>--cleanup</p></li>
</ul>
<blockquote>
<div><p>$RETURN is the wrapper from <strong>--return</strong></p>
<div><div><pre><span></span><span>$COMMAND</span><span>;</span> <span>_EXIT_status</span><span>=</span><span>$?</span><span>;</span> <span>$RETURN</span><span>;</span>
<span>ssh</span> <span>$SSHLOGIN</span> <span>\</span><span>(</span><span>rm</span><span>\</span> <span>-</span><span>f</span><span>\</span> <span>.</span><span>/$WORKDIR/</span><span>{}</span><span>\</span><span>;</span><span>\</span>
                <span>rmdir</span><span>\</span> <span>.</span><span>/$WORKDIR\ \&gt;\&amp;/</span><span>dev</span><span>/</span><span>null</span><span>\</span><span>;</span><span>\</span><span>);</span>
<span>exit</span> <span>$_EXIT_status</span><span>;</span>
</pre></div>
</div>
<p><strong>$_EXIT_status</strong>: see <strong>--return</strong> above.</p>
</div></blockquote>
<ul>
<li><p>--pipe</p></li>
</ul>
<blockquote>
<div><div><div><pre><span></span><span>perl</span> <span>-</span><span>e</span> <span>&#39;if(sysread(STDIN, $buf, 1)) {</span>
<span>    open($fh, &#34;|-&#34;, &#34;@ARGV&#34;) || die;</span>
<span>    syswrite($fh, $buf);</span>
<span>    # Align up to 128k block</span>
<span>    if($read = sysread(STDIN, $buf, 131071)) {</span>
<span>        syswrite($fh, $buf);</span>
<span>    }</span>
<span>    while($read = sysread(STDIN, $buf, 131072)) {</span>
<span>        syswrite($fh, $buf);</span>
<span>    }</span>
<span>    close $fh;</span>
<span>    exit ($?&amp;127 ? 128+($?&amp;127) : 1+$?&gt;&gt;8)</span>
<span>  }&#39;</span> <span>$SHELL</span> <span>-</span><span>c</span> <span>$COMMAND</span>
</pre></div>
</div>
<p>This small wrapper makes sure that <strong>$COMMAND</strong> will never be run if there is no data.</p>
</div></blockquote>
<ul>
<li><p>--tmux</p></li>
</ul>
<blockquote>
<div><dl>
<dt>&lt;&lt;TODO Fixup with &#39;-quoting&gt;&gt; mkfifo /tmp/tmx3cMEV &amp;&amp;</dt><dd><p>sh -c &#39;tmux -S /tmp/tmsaKpv1 new-session -s p334310 -d &#34;sleep .2&#34; &gt;/dev/null 2&gt;&amp;1&#39;; tmux -S /tmp/tmsaKpv1 new-window -t p334310 -n wc\ 10 \(wc\ 10\)\;\ perl\ -e\ \&#39;while\(\$t++\&lt;3\)\{\ print\ \$ARGV\[0\],\&#34;\\n\&#34;\ \}\&#39;\ \$\?h/\$status\ \&gt;\&gt;\ /tmp/tmx3cMEV\&amp;echo\ wc\\\ 10\;\ echo\ \Job\ finished\ at:\ \`date\`\;sleep\ 10; exec perl -e &#39;$/=&#34;/&#34;;$_=&lt;&gt;;$c=&lt;&gt;;unlink $ARGV; /(\d+)h/ and exit($1);exit$c&#39; /tmp/tmx3cMEV</p>
</dd>
</dl>
<p>mkfifo <em>tmpfile.tmx</em>; tmux -S &lt;tmpfile.tms&gt; new-session -s p<em>PID</em> -d &#39;sleep .2&#39; &gt;&amp;/dev/null; tmux -S &lt;tmpfile.tms&gt; new-window -t p<em>PID</em> -n &lt;&lt;shell quoted input&gt;&gt; \(&lt;&lt;shell quoted input&gt;&gt;\)\;\ perl\ -e\ \&#39;while\(\$t++\&lt;3\)\{\ print\ \$ARGV\[0\],\&#34;\\n\&#34;\ \}\&#39;\ \$\?h/\$status\ \&gt;\&gt;\ <em>tmpfile.tmx</em>\&amp;echo\ &lt;&lt;shell double quoted input&gt;&gt;\;echo\ \Job\ finished\ at:\ \`date\`\;sleep\ 10; exec perl -e &#39;$/=&#34;/&#34;;$_=&lt;&gt;;$c=&lt;&gt;;unlink $ARGV; /(\d+)h/ and exit($1);exit$c&#39; <em>tmpfile.tmx</em></p>
<p>First a FIFO is made (.tmx). It is used for communicating exit value. Next a new tmux session is made. This may fail if there is already a session, so the output is ignored. If all job slots finish at the same time, then <strong>tmux</strong> will close the session. A temporary socket is made (.tms) to avoid a race condition in <strong>tmux</strong>. It is cleaned up when GNU <strong>parallel</strong> finishes.</p>
<p>The input is used as the name of the windows in <strong>tmux</strong>. When the job inside <strong>tmux</strong> finishes, the exit value is printed to the FIFO (.tmx). This FIFO is opened by <strong>perl</strong> outside <strong>tmux</strong>, and <strong>perl</strong> then removes the FIFO. <strong>Perl</strong> blocks until the first value is read from the FIFO, and this value is used as exit value.</p>
<p>To make it compatible with <strong>csh</strong> and <strong>bash</strong> the exit value is printed as: $?h/$status and this is parsed by <strong>perl</strong>.</p>
<p>There is a bug that makes it necessary to print the exit value 3 times.</p>
<p>Another bug in <strong>tmux</strong> requires the length of the tmux title and command to not have certain limits.  When inside these limits, 75 &#39;\ &#39; are added to the title to force it to be outside the limits.</p>
<p>You can map the bad limits using:</p>
<div><div><pre><span></span>perl -e &#39;sub r { int(rand(shift)).($_[0] &amp;&amp; &#34;\t&#34;.r(@_)) } print map { r(@ARGV).&#34;\n&#34; } 1..10000&#39; 1600 1500 90 |
  perl -ane &#39;$F[0]+$F[1]+$F[2] &lt; 2037 and print &#39; |
  parallel --colsep &#39;\t&#39; --tagstring &#39;{1}\t{2}\t{3}&#39; tmux -S /tmp/p{%}-&#39;{=3 $_=&#34;O&#34;x$_ =}&#39; \
    new-session -d -n &#39;{=1 $_=&#34;O&#34;x$_ =}&#39; true&#39;\ {=2 $_=&#34;O&#34;x$_ =};echo $?;rm -f /tmp/p{%}-O*&#39;

perl -e &#39;sub r { int(rand(shift)).($_[0] &amp;&amp; &#34;\t&#34;.r(@_)) } print map { r(@ARGV).&#34;\n&#34; } 1..10000&#39; 17000 17000 90 |
  parallel --colsep &#39;\t&#39; --tagstring &#39;{1}\t{2}\t{3}&#39; \
tmux -S /tmp/p{%}-&#39;{=3 $_=&#34;O&#34;x$_ =}&#39; new-session -d -n &#39;{=1 $_=&#34;O&#34;x$_ =}&#39; true&#39;\ {=2 $_=&#34;O&#34;x$_ =};echo $?;rm /tmp/p{%}-O*&#39;
&gt; value.csv 2&gt;/dev/null

R -e &#39;a&lt;-read.table(&#34;value.csv&#34;);X11();plot(a[,1],a[,2],col=a[,4]+5,cex=0.1);Sys.sleep(1000)&#39;
</pre></div>
</div>
<p>For <strong>tmux 1.8</strong> 17000 can be lowered to 2100.</p>
<p>The interesting areas are title 0..1000 with (title + whole command) in 996..1127 and 9331..9636.</p>
</div></blockquote>
<p>The ordering of the wrapping is important:</p>
<ul>
<li><p>$PARALLEL_ENV which is set in env_parallel.* must be prepended to the command first, as the command may contain exported variables or functions.</p></li>
<li><p><strong>--nice</strong>/<strong>--cat</strong>/<strong>--fifo</strong> should be done on the remote machine</p></li>
<li><p><strong>--pipepart</strong>/<strong>--pipe</strong> should be done on the local machine inside <strong>--tmux</strong></p></li>
</ul>
</section>
<section id="convenience-options-nice-basefile-transfer-return-cleanup-tmux-group-compress-cat-fifo-workdir-tag-tagstring">
<h2>Convenience options --nice --basefile --transfer --return --cleanup --tmux --group --compress --cat --fifo --workdir --tag --tagstring<a href="#convenience-options-nice-basefile-transfer-return-cleanup-tmux-group-compress-cat-fifo-workdir-tag-tagstring" title="Permalink to this headline"></a></h2>
<p>These are all convenience options that make it easier to do a task. But more importantly: They are tested to work on corner cases, too. Take <strong>--nice</strong> as an example:</p>
<div><div><pre><span></span><span>nice</span> <span>parallel</span> <span>command</span> <span>...</span>
</pre></div>
</div>
<p>will work just fine. But when run remotely, you need to move the nice command so it is being run on the server:</p>
<div><div><pre><span></span><span>parallel</span> <span>-</span><span>S</span> <span>server</span> <span>nice</span> <span>command</span> <span>...</span>
</pre></div>
</div>
<p>And this will again work just fine, as long as you are running a single command. When you are running a composed command you need nice to apply to the whole command, and it gets harder still:</p>
<div><div><pre><span></span><span>parallel</span> <span>-</span><span>S</span> <span>server</span> <span>-</span><span>q nice </span><span>bash</span> <span>-</span><span>c</span> <span>&#39;command1 ...; cmd2 | cmd3&#39;</span>
</pre></div>
</div>
<p>It is not impossible, but by using <strong>--nice</strong> GNU <strong>parallel</strong> will do the right thing for you. Similarly when transferring files: It starts to get hard when the file names contain space, :, `, *, or other special characters.</p>
<p>To run the commands in a <strong>tmux</strong> session you basically just need to quote the command. For simple commands that is easy, but when commands contain special characters, it gets much harder to get right.</p>
<p><strong>--compress</strong> not only compresses standard output (stdout) but also standard error (stderr); and it does so into files, that are open but deleted, so a crash will not leave these files around.</p>
<p><strong>--cat</strong> and <strong>--fifo</strong> are easy to do by hand, until you want to clean up the tmpfile and keep the exit code of the command.</p>
<p>The real killer comes when you try to combine several of these: Doing that correctly for all corner cases is next to impossible to do by hand.</p>
</section>
<section id="shard">
<h2>--shard<a href="#shard" title="Permalink to this headline"></a></h2>
<p>The simple way to implement sharding would be to:</p>
<ul>
<li><p>1</p></li>
</ul>
<blockquote>
<p>start n jobs,</p></blockquote>
<ul>
<li><p>2</p></li>
</ul>
<blockquote>
<p>split each line into columns,</p></blockquote>
<ul>
<li><p>3</p></li>
</ul>
<blockquote>
<p>select the data from the relevant column</p></blockquote>
<ul>
<li><p>4</p></li>
</ul>
<blockquote>
<p>compute a hash value from the data</p></blockquote>
<ul>
<li><p>5</p></li>
</ul>
<blockquote>
<p>take the modulo n of the hash value</p></blockquote>
<ul>
<li><p>6</p></li>
</ul>
<blockquote>
<p>pass the full line to the jobslot that has the computed value</p></blockquote>
<p>Unfortunately Perl is rather slow at computing the hash value (and somewhat slow at splitting into columns).</p>
<p>One solution is to use a compiled language for the splitting and hashing, but that would go against the design criteria of not depending on a compiler.</p>
<p>Luckily those tasks can be parallelized. So GNU <strong>parallel</strong> starts n sharders that do step 2-6, and passes blocks of 100k to each of those in a round robin manner. To make sure these sharders compute the hash the same way, $PERL_HASH_SEED is set to the same value for all sharders.</p>
<p>Running n sharders poses a new problem: Instead of having n outputs (one for each computed value) you now have n outputs for each of the n values, so in total n*n outputs; and you need to merge these n*n outputs together into n outputs.</p>
<p>This can be done by simply running &#39;parallel -j0 --lb cat ::: outputs_for_one_value&#39;, but that is rather inefficient, as it spawns a process for each file. Instead the core code from &#39;parcat&#39; is run, which is also a bit faster.</p>
<p>All the sharders and parcats communicate through named pipes that are unlinked as soon as they are opened.</p>
</section>
<section id="shell-shock">
<h2>Shell shock<a href="#shell-shock" title="Permalink to this headline"></a></h2>
<p>The shell shock bug in <strong>bash</strong> did not affect GNU <strong>parallel</strong>, but the solutions did. <strong>bash</strong> first introduced functions in variables named: <em>BASH_FUNC_myfunc()</em> and later changed that to <em>BASH_FUNC_myfunc%%</em>. When transferring functions GNU <strong>parallel</strong> reads off the function and changes that into a function definition, which is copied to the remote system and executed before the actual command is executed. Therefore GNU <strong>parallel</strong> needs to know how to read the function.</p>
<p>From version 20150122 GNU <strong>parallel</strong> tries both the ()-version and the %%-version, and the function definition works on both pre- and post-shell shock versions of <strong>bash</strong>.</p>
</section>
<section id="the-remote-system-wrapper">
<h2>The remote system wrapper<a href="#the-remote-system-wrapper" title="Permalink to this headline"></a></h2>
<p>The remote system wrapper does some initialization before starting the command on the remote system.</p>
<section id="make-quoting-unnecessary-by-hex-encoding-everything">
<h3>Make quoting unnecessary by hex encoding everything<a href="#make-quoting-unnecessary-by-hex-encoding-everything" title="Permalink to this headline"></a></h3>
<p>When you run <strong>ssh server foo</strong> then <strong>foo</strong> has to be quoted once:</p>
<div><div><pre><span></span><span>ssh</span> <span>server</span> <span>&#34;echo foo; echo bar&#34;</span>
</pre></div>
</div>
<p>If you run <strong>ssh server1 ssh server2 foo</strong> then <strong>foo</strong> has to be quoted twice:</p>
<div><div><pre><span></span>ssh server1 ssh server2 \&#39;&#34;echo foo; echo bar&#34;\&#39;
</pre></div>
</div>
<p>GNU <strong>parallel</strong> avoids this by packing everyting into hex values and running a command that does not need quoting:</p>
<div><div><pre><span></span><span>perl</span> <span>-</span><span>X</span> <span>-</span><span>e</span> <span>GNU_Parallel_worker</span><span>,</span><span>eval</span><span>+</span><span>pack</span><span>+</span><span>q/H10000000/</span><span>,</span><span>join</span><span>+</span><span>q//</span><span>,</span><span>@ARGV</span>
</pre></div>
</div>
<p>This command reads hex from the command line and converts that to bytes that are then eval&#39;ed as a Perl expression.</p>
<p>The string <strong>GNU_Parallel_worker</strong> is not needed. It is simply there to let the user know, that this process is GNU <strong>parallel</strong> working.</p>
</section>
<section id="ctrl-c-and-standard-error-stderr">
<h3>Ctrl-C and standard error (stderr)<a href="#ctrl-c-and-standard-error-stderr" title="Permalink to this headline"></a></h3>
<p>If the user presses Ctrl-C the user expects jobs to stop. This works out of the box if the jobs are run locally. Unfortunately it is not so simple if the jobs are run remotely.</p>
<p>If remote jobs are run in a tty using <strong>ssh -tt</strong>, then Ctrl-C works, but all output to standard error (stderr) is sent to standard output (stdout). This is not what the user expects.</p>
<p>If remote jobs are run without a tty using <strong>ssh</strong> (without <strong>-tt</strong>), then output to standard error (stderr) is kept on stderr, but Ctrl-C does not kill remote jobs. This is not what the user expects.</p>
<p>So what is needed is a way to have both. It seems the reason why Ctrl-C does not kill the remote jobs is because the shell does not propagate the hang-up signal from <strong>sshd</strong>. But when <strong>sshd</strong> dies, the parent of the login shell becomes <strong>init</strong> (process id 1). So by exec&#39;ing a Perl wrapper to monitor the parent pid and kill the child if the parent pid becomes 1, then Ctrl-C works and stderr is kept on stderr.</p>
<p>Ctrl-C does, however, kill the ssh connection, so any output from a remote dying process is lost.</p>
<p>To be able to kill all (grand)*children a new process group is started.</p>
</section>
<section id="nice">
<h3>--nice<a href="#nice" title="Permalink to this headline"></a></h3>
<p><strong>nice</strong>ing the remote process is done by <strong>setpriority(0,0,$nice)</strong>. A few old systems do not implement this and <strong>--nice</strong> is unsupported on those.</p>
</section>
<section id="setting-parallel-tmp">
<h3>Setting $PARALLEL_TMP<a href="#setting-parallel-tmp" title="Permalink to this headline"></a></h3>
<p><strong>$PARALLEL_TMP</strong> is used by <strong>--fifo</strong> and <strong>--cat</strong> and must point to a non-exitent file in <strong>$TMPDIR</strong>. This file name is computed on the remote system.</p>
</section>
<section id="the-wrapper">
<h3>The wrapper<a href="#the-wrapper" title="Permalink to this headline"></a></h3>
<p>The wrapper looks like this:</p>
<div><div><pre><span></span><span>$shell</span> <span>=</span> <span>$PARALLEL_SHELL</span> <span>||</span> <span>$SHELL</span><span>;</span>
<span>$tmpdir</span> <span>=</span> <span>$TMPDIR</span> <span>||</span> <span>$PARALLEL_REMOTE_TMPDIR</span><span>;</span>
<span>$nice</span> <span>=</span> <span>$</span><span>opt::</span><span>nice</span><span>;</span>
<span>$termseq</span> <span>=</span> <span>$</span><span>opt::</span><span>termseq</span><span>;</span>

<span># Check that $tmpdir is writable</span>
<span>-</span><span>w</span> <span>$tmpdir</span> <span>||</span>
    <span>die</span><span>(</span><span>&#34;$tmpdir is not writable.&#34;</span><span>.</span>
     <span>&#34; Set PARALLEL_REMOTE_TMPDIR&#34;</span><span>);</span>
<span># Set $PARALLEL_TMP to a non-existent file name in $TMPDIR</span>
<span>do</span> <span>{</span>
    <span>$ENV</span><span>{</span><span>PARALLEL_TMP</span><span>}</span> <span>=</span> <span>$tmpdir</span><span>.</span><span>&#34;/par&#34;</span><span>.</span>
     <span>join</span><span>&#34;&#34;</span><span>,</span> <span>map</span> <span>{</span> <span>(</span><span>0</span><span>..</span><span>9</span><span>,</span><span>&#34;a&#34;</span><span>..</span><span>&#34;z&#34;</span><span>,</span><span>&#34;A&#34;</span><span>..</span><span>&#34;Z&#34;</span><span>)[</span><span>rand</span><span>(</span><span>62</span><span>)]</span> <span>}</span> <span>(</span><span>1</span><span>..</span><span>5</span><span>);</span>
<span>}</span> <span>while</span><span>(</span><span>-</span><span>e</span> <span>$ENV</span><span>{</span><span>PARALLEL_TMP</span><span>});</span>
<span># Set $script to a non-existent file name in $TMPDIR</span>
<span>do</span> <span>{</span>
    <span>$script</span> <span>=</span> <span>$tmpdir</span><span>.</span><span>&#34;/par&#34;</span><span>.</span>
     <span>join</span><span>&#34;&#34;</span><span>,</span> <span>map</span> <span>{</span> <span>(</span><span>0</span><span>..</span><span>9</span><span>,</span><span>&#34;a&#34;</span><span>..</span><span>&#34;z&#34;</span><span>,</span><span>&#34;A&#34;</span><span>..</span><span>&#34;Z&#34;</span><span>)[</span><span>rand</span><span>(</span><span>62</span><span>)]</span> <span>}</span> <span>(</span><span>1</span><span>..</span><span>5</span><span>);</span>
<span>}</span> <span>while</span><span>(</span><span>-</span><span>e</span> <span>$script</span><span>);</span>
<span># Create a script from the hex code</span>
<span># that removes itself and runs the commands</span>
<span>open</span><span>(</span><span>$fh</span><span>,</span><span>&#34;&gt;&#34;</span><span>,</span><span>$script</span><span>)</span> <span>||</span> <span>die</span><span>;</span>
<span># &#39; needed due to rc-shell</span>
<span>print</span><span>(</span><span>$fh</span><span>(</span><span>&#34;rm \&#39;$script\&#39;\n&#34;</span><span>,</span><span>$bashfunc</span><span>.</span><span>$cmd</span><span>));</span>
<span>close</span> <span>$fh</span><span>;</span>
<span>my</span> <span>$parent</span> <span>=</span> <span>getppid</span><span>;</span>
<span>my</span> <span>$done</span> <span>=</span> <span>0</span><span>;</span>
<span>$SIG</span><span>{</span><span>CHLD</span><span>}</span> <span>=</span> <span>sub</span> <span>{</span> <span>$done</span> <span>=</span> <span>1</span><span>;</span> <span>};</span>
<span>$pid</span> <span>=</span> <span>fork</span><span>;</span>
<span>unless</span><span>(</span><span>$pid</span><span>)</span> <span>{</span>
    <span># Make own process group to be able to kill HUP it later</span>
    <span>eval</span> <span>{</span> <span>setpgrp</span> <span>};</span>
    <span># Set nice value</span>
    <span>eval</span> <span>{</span> <span>setpriority</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>$nice</span><span>)</span> <span>};</span>
    <span># Run the script</span>
    <span>exec</span><span>(</span><span>$shell</span><span>,</span><span>$script</span><span>);</span>
    <span>die</span><span>(</span><span>&#34;exec failed: $!&#34;</span><span>);</span>
<span>}</span>
<span>while</span><span>((</span><span>not</span> <span>$done</span><span>)</span> <span>and</span> <span>(</span><span>getppid</span> <span>==</span> <span>$parent</span><span>))</span> <span>{</span>
    <span># Parent pid is not changed, so sshd is alive</span>
    <span># Exponential sleep up to 1 sec</span>
    <span>$s</span> <span>=</span> <span>$s</span> <span>&lt;</span> <span>1</span> <span>?</span> <span>0.001</span> <span>+</span> <span>$s</span> <span>*</span> <span>1.03</span> <span>:</span> <span>$s</span><span>;</span>
    <span>select</span><span>(</span><span>undef</span><span>,</span> <span>undef</span><span>,</span> <span>undef</span><span>,</span> <span>$s</span><span>);</span>
<span>}</span>
<span>if</span><span>(</span><span>not</span> <span>$done</span><span>)</span> <span>{</span>
    <span># sshd is dead: User pressed Ctrl-C</span>
    <span># Kill as per --termseq</span>
    <span>my</span> <span>@term_seq</span> <span>=</span> <span>split</span><span>/,/</span><span>,</span><span>$termseq</span><span>;</span>
    <span>if</span><span>(</span><span>not</span> <span>@term_seq</span><span>)</span> <span>{</span>
     <span>@term_seq</span> <span>=</span> <span>(</span><span>&#34;TERM&#34;</span><span>,</span><span>200</span><span>,</span><span>&#34;TERM&#34;</span><span>,</span><span>100</span><span>,</span><span>&#34;TERM&#34;</span><span>,</span><span>50</span><span>,</span><span>&#34;KILL&#34;</span><span>,</span><span>25</span><span>);</span>
    <span>}</span>
    <span>while</span><span>(</span><span>@term_seq</span> <span>&amp;&amp;</span> <span>kill</span><span>(</span><span>0</span><span>,</span><span>-</span><span>$pid</span><span>))</span> <span>{</span>
     <span>kill</span><span>(</span><span>shift</span> <span>@term_seq</span><span>,</span> <span>-</span><span>$pid</span><span>);</span>
     <span>select</span><span>(</span><span>undef</span><span>,</span> <span>undef</span><span>,</span> <span>undef</span><span>,</span> <span>(</span><span>shift</span> <span>@term_seq</span><span>)</span><span>/</span><span>1000</span><span>);</span>
    <span>}</span>
<span>}</span>
<span>wait</span><span>;</span>
<span>exit</span> <span>(</span><span>$?</span><span>&amp;</span><span>127</span> <span>?</span> <span>128</span><span>+</span><span>(</span><span>$?</span><span>&amp;</span><span>127</span><span>)</span> <span>:</span> <span>1</span><span>+</span><span>$?</span><span>&gt;&gt;</span><span>8</span><span>)</span>
</pre></div>
</div>
</section>
</section>
<section id="transferring-of-variables-and-functions">
<h2>Transferring of variables and functions<a href="#transferring-of-variables-and-functions" title="Permalink to this headline"></a></h2>
<p>Transferring of variables and functions given by <strong>--env</strong> is done by running a Perl script remotely that calls the actual command. The Perl script sets <strong>$ENV{</strong><em>variable</em><strong>}</strong> to the correct value before exec&#39;ing a shell that runs the function definition followed by the actual command.</p>
<p>The function <strong>env_parallel</strong> copies the full current environment into the environment variable <strong>PARALLEL_ENV</strong>. This variable is picked up by GNU <strong>parallel</strong> and used to create the Perl script mentioned above.</p>
</section>
<section id="base64-encoded-bzip2">
<h2>Base64 encoded bzip2<a href="#base64-encoded-bzip2" title="Permalink to this headline"></a></h2>
<p><strong>csh</strong> limits words of commands to 1024 chars. This is often too little when GNU <strong>parallel</strong> encodes environment variables and wraps the command with different templates. All of these are combined and quoted into one single word, which often is longer than 1024 chars.</p>
<p>When the line to run is &gt; 1000 chars, GNU <strong>parallel</strong> therefore encodes the line to run. The encoding <strong>bzip2</strong>s the line to run, converts this to base64, splits the base64 into 1000 char blocks (so <strong>csh</strong> does not fail), and prepends it with this Perl script that decodes, decompresses and <strong>eval</strong>s the line.</p>
<div><div><pre><span></span><span>@GNU_Parallel</span><span>=</span><span>(</span><span>&#34;use&#34;</span><span>,</span><span>&#34;IPC::Open3;&#34;</span><span>,</span><span>&#34;use&#34;</span><span>,</span><span>&#34;MIME::Base64&#34;</span><span>);</span>
<span>eval</span> <span>&#34;@GNU_Parallel&#34;</span><span>;</span>

<span>$SIG</span><span>{</span><span>CHLD</span><span>}</span><span>=</span><span>&#34;IGNORE&#34;</span><span>;</span>
<span># Search for bzip2. Not found =&gt; use default path</span>
<span>my</span> <span>$zip</span> <span>=</span> <span>(</span><span>grep</span> <span>{</span> <span>-</span><span>x</span> <span>$_</span> <span>}</span> <span>&#34;/usr/local/bin/bzip2&#34;</span><span>)[</span><span>0</span><span>]</span> <span>||</span> <span>&#34;bzip2&#34;</span><span>;</span>
<span># $in = stdin on $zip, $out = stdout from $zip</span>
<span>my</span><span>(</span><span>$in</span><span>,</span> <span>$out</span><span>,</span><span>$eval</span><span>);</span>
<span>open3</span><span>(</span><span>$in</span><span>,</span><span>$out</span><span>,</span><span>&#34;&gt;&amp;STDERR&#34;</span><span>,</span><span>$zip</span><span>,</span><span>&#34;-dc&#34;</span><span>);</span>
<span>if</span><span>(</span><span>my</span> <span>$perlpid</span> <span>=</span> <span>fork</span><span>)</span> <span>{</span>
    <span>close</span> <span>$in</span><span>;</span>
    <span>$eval</span> <span>=</span> <span>join</span> <span>&#34;&#34;</span><span>,</span> <span>&lt;$out&gt;</span><span>;</span>
    <span>close</span> <span>$out</span><span>;</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>close</span> <span>$out</span><span>;</span>
    <span># Pipe decoded base64 into &#39;bzip2 -dc&#39;</span>
    <span>print</span> <span>$in</span> <span>(</span><span>decode_base64</span><span>(</span><span>join</span><span>&#34;&#34;</span><span>,</span><span>@ARGV</span><span>));</span>
    <span>close</span> <span>$in</span><span>;</span>
    <span>exit</span><span>;</span>
<span>}</span>
<span>wait</span><span>;</span>
<span>eval</span> <span>$eval</span><span>;</span>
</pre></div>
</div>
<p>Perl and <strong>bzip2</strong> must be installed on the remote system, but a small test showed that <strong>bzip2</strong> is installed by default on all platforms that runs GNU <strong>parallel</strong>, so this is not a big problem.</p>
<p>The added bonus of this is that much bigger environments can now be transferred as they will be below <strong>bash</strong>&#39;s limit of 131072 chars.</p>
</section>
<section id="which-shell-to-use">
<h2>Which shell to use<a href="#which-shell-to-use" title="Permalink to this headline"></a></h2>
<p>Different shells behave differently. A command that works in <strong>tcsh</strong> may not work in <strong>bash</strong>.  It is therefore important that the correct shell is used when GNU <strong>parallel</strong> executes commands.</p>
<p>GNU <strong>parallel</strong> tries hard to use the right shell. If GNU <strong>parallel</strong> is called from <strong>tcsh</strong> it will use <strong>tcsh</strong>.  If it is called from <strong>bash</strong> it will use <strong>bash</strong>. It does this by looking at the (grand)*parent process: If the (grand)*parent process is a shell, use this shell; otherwise look at the parent of this (grand)*parent. If none of the (grand)*parents are shells, then $SHELL is used.</p>
<p>This will do the right thing if called from:</p>
<ul>
<li><p>an interactive shell</p></li>
<li><p>a shell script</p></li>
<li><p>a Perl script in `` or using <strong>system</strong> if called as a single string.</p></li>
</ul>
<p>While these cover most cases, there are situations where it will fail:</p>
<ul>
<li><p>When run using <strong>exec</strong>.</p></li>
<li><p>When run as the last command using <strong>-c</strong> from another shell (because some shells use <strong>exec</strong>):</p>
<div><div><pre><span></span><span>zsh</span><span>%</span> <span>bash</span> <span>-</span><span>c</span> <span>&#34;parallel &#39;echo {} is not run in bash; \</span>
<span>     set | grep BASH_VERSION&#39; ::: This&#34;</span>
</pre></div>
</div>
<p>You can work around that by appending &#39;&amp;&amp; true&#39;:</p>
<div><div><pre><span></span><span>zsh</span><span>%</span> <span>bash</span> <span>-</span><span>c</span> <span>&#34;parallel &#39;echo {} is run in bash; \</span>
<span>     set | grep BASH_VERSION&#39; ::: This &amp;&amp; true&#34;</span>
</pre></div>
</div>
</li>
<li><p>When run in a Perl script using <strong>system</strong> with parallel as the first string:</p>
<div><div><pre><span></span><span>#!/usr/bin/perl</span>

<span>system</span><span>(</span><span>&#34;parallel&#34;</span><span>,</span><span>&#39;setenv a {}; echo $a&#39;</span><span>,</span><span>&#34;:::&#34;</span><span>,</span><span>2</span><span>);</span>
</pre></div>
</div>
<p>Here it depends on which shell is used to call the Perl script. If the Perl script is called from <strong>tcsh</strong> it will work just fine, but if it is called from <strong>bash</strong> it will fail, because the command <strong>setenv</strong> is not known to <strong>bash</strong>.</p>
</li>
</ul>
<p>If GNU <strong>parallel</strong> guesses wrong in these situation, set the shell using <strong>$PARALLEL_SHELL</strong>.</p>
</section>
<section id="always-running-commands-in-a-shell">
<h2>Always running commands in a shell<a href="#always-running-commands-in-a-shell" title="Permalink to this headline"></a></h2>
<p>If the command is a simple command with no redirection and setting of variables, the command <em>could</em> be run without spawning a shell. E.g. this simple <strong>grep</strong> matching either &#39;ls &#39; or &#39; wc &gt;&gt; c&#39;:</p>
<div><div><pre><span></span><span>parallel</span> <span>&#34;grep -E &#39;ls | wc &gt;&gt; c&#39; {}&#34;</span> <span>::</span><span>:</span> <span>foo</span>
</pre></div>
</div>
<p>could be run as:</p>
<div><div><pre><span></span><span>system</span><span>(</span><span>&#34;grep&#34;</span><span>,</span><span>&#34;-E&#34;</span><span>,</span><span>&#34;ls | wc &gt;&gt; c&#34;</span><span>,</span><span>&#34;foo&#34;</span><span>);</span>
</pre></div>
</div>
<p>However, as soon as the command is a bit more complex a shell <em>must</em> be spawned:</p>
<div><div><pre><span></span><span>parallel</span> <span>&#34;grep -E &#39;ls | wc &gt;&gt; c&#39; {} | wc &gt;&gt; c&#34;</span> <span>::</span><span>:</span> <span>foo</span>
<span>parallel</span> <span>&#34;LANG=C grep -E &#39;ls | wc &gt;&gt; c&#39; {}&#34;</span> <span>::</span><span>:</span> <span>foo</span>
</pre></div>
</div>
<p>It is impossible to tell how <strong>| wc &gt;&gt; c</strong> should be interpreted without parsing the string (is the <strong>|</strong> a pipe in shell or an alternation in a <strong>grep</strong> regexp?  Is <strong>LANG=C</strong> a command in <strong>csh</strong> or setting a variable in <strong>bash</strong>? Is <strong>&gt;&gt;</strong> redirection or part of a regexp?).</p>
<p>On top of this, wrapper scripts will often require a shell to be spawned.</p>
<p>The downside is that you need to quote special shell chars twice:</p>
<div><div><pre><span></span>parallel echo &#39;*&#39; ::: This will expand the asterisk
parallel echo &#34;&#39;*&#39;&#34; ::: This will not
parallel &#34;echo &#39;*&#39;&#34; ::: This will not
parallel echo &#39;\*&#39; ::: This will not
parallel echo \&#39;&#39;*&#39;\&#39; ::: This will not
parallel -q echo &#39;*&#39; ::: This will not
</pre></div>
</div>
<p><strong>-q</strong> will quote all special chars, thus redirection will not work: this prints &#39;* &gt; out.1&#39; and <em>does not</em> save &#39;*&#39; into the file out.1:</p>
<div><div><pre><span></span><span>parallel</span> <span>-</span><span>q echo </span><span>&#34;*&#34;</span> <span>&#34;&gt;&#34;</span> <span>out</span><span>.</span><span>{}</span> <span>::</span><span>:</span> <span>1</span>
</pre></div>
</div>
<p>GNU <strong>parallel</strong> tries to live up to Principle Of Least Astonishment (POLA), and the requirement of using <strong>-q</strong> is hard to understand, when you do not see the whole picture.</p>
</section>
<section id="quoting">
<h2>Quoting<a href="#quoting" title="Permalink to this headline"></a></h2>
<p>Quoting depends on the shell. For most shells &#39;-quoting is used for strings containing special characters.</p>
<p>For <strong>tcsh</strong>/<strong>csh</strong> newline is quoted as \ followed by newline. Other special characters are also \-quoted.</p>
<p>For <strong>rc</strong> everything is quoted using &#39;.</p>
</section>
<section id="pipepart-vs-pipe">
<h2>--pipepart vs. --pipe<a href="#pipepart-vs-pipe" title="Permalink to this headline"></a></h2>
<p>While <strong>--pipe</strong> and <strong>--pipepart</strong> look much the same to the user, they are implemented very differently.</p>
<p>With <strong>--pipe</strong> GNU <strong>parallel</strong> reads the blocks from standard input (stdin), which is then given to the command on standard input (stdin); so every block is being processed by GNU <strong>parallel</strong> itself. This is the reason why <strong>--pipe</strong> maxes out at around 500 MB/sec.</p>
<p><strong>--pipepart</strong>, on the other hand, first identifies at which byte positions blocks start and how long they are. It does that by seeking into the file by the size of a block and then reading until it meets end of a block. The seeking explains why GNU <strong>parallel</strong> does not know the line number and why <strong>-L/-l</strong> and <strong>-N</strong> do not work.</p>
<p>With a reasonable block and file size this seeking is more than 1000 time faster than reading the full file. The byte positions are then given to a small script that reads from position X to Y and sends output to standard output (stdout). This small script is prepended to the command and the full command is executed just as if GNU <strong>parallel</strong> had been in its normal mode. The script looks like this:</p>
<div><div><pre><span></span><span>&lt;</span> <span>file</span> <span>perl</span> <span>-</span><span>e</span> <span>&#39;while(@ARGV) {</span>
<span>   sysseek(STDIN,shift,0) || die;</span>
<span>   $left = shift;</span>
<span>   while($read = sysread(STDIN,$buf,</span>
<span>                         ($left &gt; 131072 ? 131072 : $left))){</span>
<span>     $left -= $read; syswrite(STDOUT,$buf);</span>
<span>   }</span>
<span>}&#39;</span> <span>startbyte</span> <span>length_in_bytes</span>
</pre></div>
</div>
<p>It delivers 1 GB/s per core.</p>
<p>Instead of the script <strong>dd</strong> was tried, but many versions of <strong>dd</strong> do not support reading from one byte to another and might cause partial data. See this for a surprising example:</p>
<div><div><pre><span></span><span>yes</span> <span>|</span> <span>dd</span> <span>bs</span><span>=</span><span>1024</span><span>k</span> <span>count</span><span>=</span><span>10</span> <span>|</span> <span>wc</span>
</pre></div>
</div>
</section>
<section id="block-size-adjustment">
<h2>--block-size adjustment<a href="#block-size-adjustment" title="Permalink to this headline"></a></h2>
<p>Every time GNU <strong>parallel</strong> detects a record bigger than <strong>--block-size</strong> it increases the block size by 30%. A small <strong>--block-size</strong> gives very poor performance; by exponentially increasing the block size performance will not suffer.</p>
<p>GNU <strong>parallel</strong> will waste CPU power if <strong>--block-size</strong> does not contain a full record, because it tries to find a full record and will fail to do so. The recommendation is therefore to use a <strong>--block-size</strong> &gt; 2 records, so you always get at least one full record when you read one block.</p>
<p>If you use <strong>-N</strong> then <strong>--block-size</strong> should be big enough to contain N+1 records.</p>
</section>
<section id="automatic-block-size-computation">
<h2>Automatic --block-size computation<a href="#automatic-block-size-computation" title="Permalink to this headline"></a></h2>
<p>With <strong>--pipepart</strong> GNU <strong>parallel</strong> can compute the <strong>--block-size</strong> automatically. A <strong>--block-size</strong> of <strong>-1</strong> will use a block size so that each jobslot will receive approximately 1 block.  <strong>--block -2</strong> will pass 2 blocks to each jobslot and <strong>-</strong><em>n</em> will pass <em>n</em> blocks to each jobslot.</p>
<p>This can be done because <strong>--pipepart</strong> reads from files, and we can compute the total size of the input.</p>
</section>
<section id="jobs-and-onall">
<h2>--jobs and --onall<a href="#jobs-and-onall" title="Permalink to this headline"></a></h2>
<p>When running the same commands on many servers what should <strong>--jobs</strong> signify? Is it the number of servers to run on in parallel?  Is it the number of jobs run in parallel on each server?</p>
<p>GNU <strong>parallel</strong> lets <strong>--jobs</strong> represent the number of servers to run on in parallel. This is to make it possible to run a sequence of commands (that cannot be parallelized) on each server, but run the same sequence on multiple servers.</p>
</section>
<section id="shuf">
<h2>--shuf<a href="#shuf" title="Permalink to this headline"></a></h2>
<p>When using <strong>--shuf</strong> to shuffle the jobs, all jobs are read, then they are shuffled, and finally executed. When using SQL this makes the <strong>--sqlmaster</strong> be the part that shuffles the jobs. The <strong>--sqlworker</strong>s simply executes according to Seq number.</p>
</section>
<section id="csv">
<h2>--csv<a href="#csv" title="Permalink to this headline"></a></h2>
<p><strong>--pipepart</strong> is incompatible with <strong>--csv</strong> because you can have records like:</p>
<div><div><pre><span></span><span>a</span><span>,</span><span>b</span><span>,</span><span>c</span>
<span>a</span><span>,</span><span>&#34;</span>
<span>a,b,c</span>
<span>a,b,c</span>
<span>a,b,c</span>
<span>&#34;</span><span>,</span><span>c</span>
<span>a</span><span>,</span><span>b</span><span>,</span><span>c</span>
</pre></div>
</div>
<p>Here the second record contains a multi-line field that looks like records. Since <strong>--pipepart</strong> does not read then whole file when searching for record endings, it may start reading in this multi-line field, which would be wrong.</p>
</section>
<section id="buffering-on-disk">
<h2>Buffering on disk<a href="#buffering-on-disk" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> buffers output, because if output is not buffered you have to be ridiculously careful on sizes to avoid mixing of outputs (see excellent example on <a href="https://catern.com/posts/pipes.html">https://catern.com/posts/pipes.html</a>).</p>
<p>GNU <strong>parallel</strong> buffers on disk in $TMPDIR using files, that are removed as soon as they are created, but which are kept open. So even if GNU <strong>parallel</strong> is killed by a power outage, there will be no files to clean up afterwards. Another advantage is that the file system is aware that these files will be lost in case of a crash, so it does not need to sync them to disk.</p>
<p>It gives the odd situation that a disk can be fully used, but there are no visible files on it.</p>
<section id="partly-buffering-in-memory">
<h3>Partly buffering in memory<a href="#partly-buffering-in-memory" title="Permalink to this headline"></a></h3>
<p>When using output formats SQL and CSV then GNU Parallel has to read the whole output into memory. When run normally it will only read the output from a single job. But when using <strong>--linebuffer</strong> every line printed will also be buffered in memory - for all jobs currently running.</p>
<p>If memory is tight, then do not use the output format SQL/CSV with <strong>--linebuffer</strong>.</p>
</section>
<section id="comparing-to-buffering-in-memory">
<h3>Comparing to buffering in memory<a href="#comparing-to-buffering-in-memory" title="Permalink to this headline"></a></h3>
<p><strong>gargs</strong> is a parallelizing tool that buffers in memory. It is therefore a useful way of comparing the advantages and disadvantages of buffering in memory to buffering on disk.</p>
<p>On an system with 6 GB RAM free and 6 GB free swap these were tested with different sizes:</p>
<div><div><pre><span></span><span>echo</span> <span>/dev/</span><span>zero</span> <span>|</span> <span>gargs</span> <span>&#34;head -c $size {}&#34;</span> <span>&gt;</span><span>/dev/</span><span>null</span>
<span>echo</span> <span>/dev/</span><span>zero</span> <span>|</span> <span>parallel</span> <span>&#34;head -c $size {}&#34;</span> <span>&gt;</span><span>/dev/</span><span>null</span>
</pre></div>
</div>
<p>The results are here:</p>
<div><div><pre><span></span><span>JobRuntime</span>      <span>Command</span>
     <span>0.344</span>      <span>parallel_test</span> <span>1</span><span>M</span>
     <span>0.362</span>      <span>parallel_test</span> <span>10</span><span>M</span>
     <span>0.640</span>      <span>parallel_test</span> <span>100</span><span>M</span>
     <span>9.818</span>      <span>parallel_test</span> <span>1000</span><span>M</span>
    <span>23.888</span>      <span>parallel_test</span> <span>2000</span><span>M</span>
    <span>30.217</span>      <span>parallel_test</span> <span>2500</span><span>M</span>
    <span>30.963</span>      <span>parallel_test</span> <span>2750</span><span>M</span>
    <span>34.648</span>      <span>parallel_test</span> <span>3000</span><span>M</span>
    <span>43.302</span>      <span>parallel_test</span> <span>4000</span><span>M</span>
    <span>55.167</span>      <span>parallel_test</span> <span>5000</span><span>M</span>
    <span>67.493</span>      <span>parallel_test</span> <span>6000</span><span>M</span>
   <span>178.654</span>      <span>parallel_test</span> <span>7000</span><span>M</span>
   <span>204.138</span>      <span>parallel_test</span> <span>8000</span><span>M</span>
   <span>230.052</span>      <span>parallel_test</span> <span>9000</span><span>M</span>
   <span>255.639</span>      <span>parallel_test</span> <span>10000</span><span>M</span>
   <span>757.981</span>      <span>parallel_test</span> <span>30000</span><span>M</span>
     <span>0.537</span>      <span>gargs_test</span> <span>1</span><span>M</span>
     <span>0.292</span>      <span>gargs_test</span> <span>10</span><span>M</span>
     <span>0.398</span>      <span>gargs_test</span> <span>100</span><span>M</span>
     <span>3.456</span>      <span>gargs_test</span> <span>1000</span><span>M</span>
     <span>8.577</span>      <span>gargs_test</span> <span>2000</span><span>M</span>
    <span>22.705</span>      <span>gargs_test</span> <span>2500</span><span>M</span>
   <span>123.076</span>      <span>gargs_test</span> <span>2750</span><span>M</span>
    <span>89.866</span>      <span>gargs_test</span> <span>3000</span><span>M</span>
   <span>291.798</span>      <span>gargs_test</span> <span>4000</span><span>M</span>
</pre></div>
</div>
<p>GNU <strong>parallel</strong> is pretty much limited by the speed of the disk: Up to 6 GB data is written to disk but cached, so reading is fast. Above 6 GB data are both written and read from disk. When the 30000MB job is running, the disk system is slow, but usable: If you are not using the disk, you almost do not feel it.</p>
<p><strong>gargs</strong> has a speed advantage up until 2500M where it hits a wall. Then the system starts swapping like crazy and is completely unusable. At 5000M it goes out of memory.</p>
<p>You can make GNU <strong>parallel</strong> behave similar to <strong>gargs</strong> if you point $TMPDIR to a tmpfs-filesystem: It will be faster for small outputs, but may kill your system for larger outputs and cause you to lose output.</p>
</section>
</section>
<section id="disk-full">
<h2>Disk full<a href="#disk-full" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> buffers on disk. If the disk is full, data may be lost. To check if the disk is full GNU <strong>parallel</strong> writes a 8193 byte file every second. If this file is written successfully, it is removed immediately. If it is not written successfully, the disk is full. The size 8193 was chosen because 8192 gave wrong result on some file systems, whereas 8193 did the correct thing on all tested filesystems.</p>
</section>
<section id="memory-usage">
<h2>Memory usage<a href="#memory-usage" title="Permalink to this headline"></a></h2>
<p>Normally GNU <strong>parallel</strong> will use around 17 MB RAM constantly - no matter how many jobs or how much output there is. There are a few things that cause the memory usage to rise:</p>
<ul>
<li><p>Multiple input sources. GNU <strong>parallel</strong> reads an input source only once. This is by design, as an input source can be a stream (e.g. FIFO, pipe, standard input (stdin)) which cannot be rewound and read again. When reading a single input source, the memory is freed as soon as the job is done - thus keeping the memory usage constant.</p>
<p>But when reading multiple input sources GNU <strong>parallel</strong> keeps the already read values for generating all combinations with other input sources.</p>
</li>
<li><p>Computing the number of jobs. <strong>--bar</strong>, <strong>--eta</strong>, and <strong>--halt xx%</strong> use <strong>total_jobs()</strong> to compute the total number of jobs. It does this by generating the data structures for all jobs. All these job data structures will be stored in memory and take up around 400 bytes/job.</p></li>
<li><p>Buffering a full line. <strong>--linebuffer</strong> will read a full line per running job. A very long output line (say 1 GB without \n) will increase RAM usage temporarily: From when the beginning of the line is read till the line is printed.</p></li>
<li><p>Buffering the full output of a single job. This happens when using <strong>--results *.csv/*.tsv</strong> or <strong>--sql*</strong>. Here GNU <strong>parallel</strong> will read the whole output of a single job and save it as csv/tsv or SQL.</p></li>
</ul>
</section>
<section id="argument-separators">
<h2>Argument separators ::: :::: :::+ ::::+<a href="#argument-separators" title="Permalink to this headline"></a></h2>
<p>The argument separator <strong>:::</strong> was chosen because I have never seen <strong>:::</strong> used in any command. The natural choice <strong>--</strong> would be a bad idea since it is not unlikely that the template command will contain <strong>--</strong>. I have seen <strong>::</strong> used in programming languanges to separate classes, and I did not want the user to be confused that the separator had anything to do with classes.</p>
<p><strong>:::</strong> also makes a visual separation, which is good if there are multiple <strong>:::</strong>.</p>
<p>When <strong>:::</strong> was chosen, <strong>::::</strong> came as a fairly natural extension.</p>
<p>Linking input sources meant having to decide for some way to indicate linking of <strong>:::</strong> and <strong>::::</strong>. <strong>:::+</strong> and <strong>::::+</strong> were chosen, so that they were similar to <strong>:::</strong> and <strong>::::</strong>.</p>
<p>In 2022 I realized that <strong>///</strong> would have been an even better choice, because you cannot have an file named <strong>///</strong> whereas you <em>can</em> have a file named <strong>:::</strong>.</p>
</section>
<section id="perl-replacement-strings-and-rpl">
<h2>Perl replacement strings, {= =}, and --rpl<a href="#perl-replacement-strings-and-rpl" title="Permalink to this headline"></a></h2>
<p>The shorthands for replacement strings make a command look more cryptic. Different users will need different replacement strings. Instead of inventing more shorthands you get more flexible replacement strings if they can be programmed by the user.</p>
<p>The language Perl was chosen because GNU <strong>parallel</strong> is written in Perl and it was easy and reasonably fast to run the code given by the user.</p>
<p>If a user needs the same programmed replacement string again and again, the user may want to make his own shorthand for it. This is what <strong>--rpl</strong> is for. It works so well, that even GNU <strong>parallel</strong>&#39;s own shorthands are implemented using <strong>--rpl</strong>.</p>
<p>In Perl code the bigrams <strong>{=</strong> and <strong>=}</strong> rarely exist. They look like a matching pair and can be entered on all keyboards. This made them good candidates for enclosing the Perl expression in the replacement strings. Another candidate ,, and ,, was rejected because they do not look like a matching pair. <strong>--parens</strong> was made, so that the users can still use ,, and ,, if they like: <strong>--parens ,,,,</strong></p>
<p>Internally, however, the <strong>{=</strong> and <strong>=}</strong> are replaced by \257&lt; and \257&gt;. This is to make it simpler to make regular expressions. You only need to look one character ahead, and never have to look behind.</p>
</section>
<section id="test-suite">
<h2>Test suite<a href="#test-suite" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> uses its own testing framework. This is mostly due to historical reasons. It deals reasonably well with tests that are dependent on how long a given test runs (e.g. more than 10 secs is a pass, but less is a fail). It parallelizes most tests, but it is easy to force a test to run as the single test (which may be important for timing issues). It deals reasonably well with tests that fail intermittently. It detects which tests failed and pushes these to the top, so when running the test suite again, the tests that failed most recently are run first.</p>
<p>If GNU <strong>parallel</strong> should adopt a real testing framework then those elements would be important.</p>
<p>Since many tests are dependent on which hardware it is running on, these tests break when run on a different hardware than what the test was written for.</p>
<p>When most bugs are fixed a test is added, so this bug will not reappear. It is, however, sometimes hard to create the environment in which the bug shows up - especially if the bug only shows up sometimes. One of the harder problems was to make a machine start swapping without forcing it to its knees.</p>
</section>
<section id="median-run-time">
<h2>Median run time<a href="#median-run-time" title="Permalink to this headline"></a></h2>
<p>Using a percentage for <strong>--timeout</strong> causes GNU <strong>parallel</strong> to compute the median run time of a job. The median is a better indicator of the expected run time than average, because there will often be outliers taking way longer than the normal run time.</p>
<p>To avoid keeping all run times in memory, an implementation of remedian was made (Rousseeuw et al).</p>
</section>
<section id="error-messages-and-warnings">
<h2>Error messages and warnings<a href="#error-messages-and-warnings" title="Permalink to this headline"></a></h2>
<p>Error messages like: ERROR, Not found, and 42 are not very helpful. GNU <strong>parallel</strong> strives to inform the user:</p>
<ul>
<li><p>What went wrong?</p></li>
<li><p>Why did it go wrong?</p></li>
<li><p>What can be done about it?</p></li>
</ul>
<p>Unfortunately it is not always possible to predict the root cause of the error.</p>
</section>
<section id="determine-number-of-cpus">
<h2>Determine number of CPUs<a href="#determine-number-of-cpus" title="Permalink to this headline"></a></h2>
<p>CPUs is an ambiguous term. It can mean the number of socket filled (i.e. the number of physical chips). It can mean the number of cores (i.e. the number of physical compute cores). It can mean the number of hyperthreaded cores (i.e. the number of virtual cores - with some of them possibly being hyperthreaded).</p>
<p>On ark.intel.com Intel uses the terms <em>cores</em> and <em>threads</em> for number of physical cores and the number of hyperthreaded cores respectively.</p>
<p>GNU <strong>parallel</strong> uses uses <em>CPUs</em> as the number of compute units and the terms <em>sockets</em>, <em>cores</em>, and <em>threads</em> to specify how the number of compute units is calculated.</p>
</section>
<section id="computation-of-load">
<h2>Computation of load<a href="#computation-of-load" title="Permalink to this headline"></a></h2>
<p>Contrary to the obvious <strong>--load</strong> does not use load average. This is due to load average rising too slowly. Instead it uses <strong>ps</strong> to list the number of threads in running or blocked state (state D, O or R). This gives an instant load.</p>
<p>As remote calculation of load can be slow, a process is spawned to run <strong>ps</strong> and put the result in a file, which is then used next time.</p>
</section>
<section id="killing-jobs">
<h2>Killing jobs<a href="#killing-jobs" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> kills jobs. It can be due to <strong>--memfree</strong>, <strong>--halt</strong>, or when GNU <strong>parallel</strong> meets a condition from which it cannot recover. Every job is started as its own process group. This way any (grand)*children will get killed, too. The process group is killed with the specification mentioned in <strong>--termseq</strong>.</p>
</section>
<section id="sql-interface">
<h2>SQL interface<a href="#sql-interface" title="Permalink to this headline"></a></h2>
<p>GNU <strong>parallel</strong> uses the DBURL from GNU <strong>sql</strong> to give database software, username, password, host, port, database, and table in a single string.</p>
<p>The DBURL must point to a table name. The table will be dropped and created. The reason for not reusing an existing table is that the user may have added more input sources which would require more columns in the table. By prepending &#39;+&#39; to the DBURL the table will not be dropped.</p>
<p>The table columns are similar to joblog with the addition of <strong>V1</strong> .. <strong>Vn</strong> which are values from the input sources, and Stdout and Stderr which are the output from standard output and standard error, respectively.</p>
<p>The Signal column has been renamed to _Signal due to Signal being a reserved word in MySQL.</p>
</section>
<section id="logo">
<h2>Logo<a href="#logo" title="Permalink to this headline"></a></h2>
<p>The logo is inspired by the Cafe Wall illusion. The font is DejaVu Sans.</p>
</section>
<section id="citation-notice">
<h2>Citation notice<a href="#citation-notice" title="Permalink to this headline"></a></h2>
<p>Funding a free software project is hard. GNU <strong>parallel</strong> is no exception. On top of that it seems the less visible a project is, the harder it is to get funding. And the nature of GNU <strong>parallel</strong> is that it will never be seen by &#34;the guy with the checkbook&#34;, but only by the people doing the actual work.</p>
<p>This problem has been covered by others - though no solution has been found: <a href="https://www.slideshare.net/NadiaEghbal/consider-the-maintainer">https://www.slideshare.net/NadiaEghbal/consider-the-maintainer</a> <a href="https://www.numfocus.org/blog/why-is-numpy-only-now-getting-funded/">https://www.numfocus.org/blog/why-is-numpy-only-now-getting-funded/</a></p>
<p>Before implementing the citation notice it was discussed with the users: <a href="https://lists.gnu.org/archive/html/parallel/2013-11/msg00006.html">https://lists.gnu.org/archive/html/parallel/2013-11/msg00006.html</a></p>
<p>Having to spend 10 seconds on running <strong>parallel --citation</strong> once is no doubt not an ideal solution, but no one has so far come up with an ideal solution - neither for funding GNU <strong>parallel</strong> nor other free software.</p>
<p>If you believe you have the perfect solution, you should try it out, and if it works, you should post it on the email list. Ideas that will cost work and which have not been tested are, however, unlikely to be prioritized.</p>
<p>Running <strong>parallel --citation</strong> one single time takes less than 10 seconds, and will silence the citation notice for future runs. This is comparable to graphical tools where you have to click a checkbox saying &#34;Do not show this again&#34;. But if that is too much trouble for you, why not use one of the alternatives instead?  See a list in: <strong>man parallel_alternatives</strong>.</p>
<p>As the request for citation is not a legal requirement this is acceptable under GPLv3 and cleared with Richard M. Stallman himself. Thus it does not fall under this: <a href="https://www.gnu.org/licenses/gpl-faq.en.html#RequireCitation">https://www.gnu.org/licenses/gpl-faq.en.html#RequireCitation</a></p>
</section>
</section></div>
  </body>
</html>
