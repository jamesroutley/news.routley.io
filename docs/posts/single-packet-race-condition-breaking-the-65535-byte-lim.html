<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://flatt.tech/research/posts/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/">Original</a>
    <h1>Single-packet race condition breaking the 65535 byte lim</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    
    <h5>
      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <rect x="4" y="5" width="16" height="16" rx="2"></rect>
        <line x1="16" y1="3" x2="16" y2="7"></line>
        <line x1="8" y1="3" x2="8" y2="7"></line>
        <line x1="4" y1="11" x2="20" y2="11"></line>
        <rect x="8" y="15" width="2" height="2"></rect>
      </svg>
      Posted on 
  
    August 2, 2024
  


      
         • 
      
      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <circle cx="12" cy="12" r="9"></circle>
        <polyline points="12 7 12 12 15 15"></polyline>
      </svg>
      12 minutes
       •
      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0"></path>
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0"></path>
        <line x1="3" y1="6" x2="3" y2="19"></line>
        <line x1="12" y1="6" x2="12" y2="19"></line>
        <line x1="21" y1="6" x2="21" y2="19"></line>
      </svg>
      2429 words
      
    </h5>
    

    <details id="TableOfContents">
    <summary>
      <span>Table of contents</span>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <polyline points="6 9 12 15 18 9"></polyline>
     </svg>
    </summary>

    <ul>
        

        
        <li>
        <a href="#introduction">Introduction</a>
        

        
        </li><li>
        <a href="#tldr">TL;DR</a>
        

        
        </li><li>
        <a href="#limitation-of-single-packet-attack">Limitation of single-packet attack</a>
        

        
        </li><li>
        <a href="#fragmentation-of-ip-packet">Fragmentation of IP packet</a>
        

        
        </li><li>
        <a href="#tcp-and-sequence-number">TCP and Sequence Number</a>
        

        
        </li><li>
        <a href="#first-sequence-sync">First Sequence Sync</a>
        

        
        </li><li>
        <a href="#combining-ip-fragmentation-and-first-sequence-sync">Combining IP fragmentation and First Sequence Sync</a>
        

        
        </li><li>
        <a href="#limiting-factors">Limiting factors</a>
        

        
        </li><li>
        <a href="#demonstration">Demonstration</a>
        

        
        </li><li>
        <a href="#further-improvements">Further Improvements</a>
        

        
        </li><li>
        <a href="#conclusion">Conclusion</a>
        

        
        </li><li>
        <a href="#shameless-plug">Shameless plug</a>
        </li></ul>
  </details>

    <h2 id="introduction">Introduction</h2>
<p>Hello, I’m RyotaK (<a href="https://twitter.com/ryotkak" target="_blank" rel="noopener">@ryotkak</a>
), a security engineer at Flatt Security Inc.</p>
<p>In 2023, <a href="https://twitter.com/albinowax" target="_blank" rel="noopener">James Kettle</a>
 of PortSwigger published <a href="https://portswigger.net/research/smashing-the-state-machine" target="_blank" rel="noopener">an excellent paper</a>
 titled <code>Smashing the state machine: the true potential of web race conditions</code>.</p>
<figure>
  <img src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/01.png" alt="An image that indicates single-packet bypasses the network jitter"/>
  <center><figcaption>Quoted from <a href="https://portswigger.net/research/smashing-the-state-machine" target="_blank" rel="noopener">Smashing the state machine: the true potential of web race conditions</a></figcaption></center>
</figure>
<p>Recently, I encountered a limit-overrun type of race condition that requires sending approximately 10,000 requests simultaneously to exploit reliably, so I attempted to apply the single packet attack to it.</p>
<p>Therefore, I began exploring ways to overcome this limitation and discovered a method to extend the 1,500-byte limitation of the single packet attack and even the 65,535-byte limitation of TCP.</p>
<h2 id="tldr">TL;DR</h2>
<p>To overcome the limitation of a single packet attack, I used IP fragmentation and TCP sequence number reordering.</p>
<p>Using IP layer fragmentation, a single TCP packet can be split into multiple IP packets, which allows the full utilization of the TCP window size.</p>
<p>Thanks to these techniques, we can significantly exploit a minor limit-overrun vulnerability, potentially leading to severe vulnerabilities like the authentication bypass of one-time token authentication.</p>

<p>
  <iframe src="https://www.youtube.com/embed/-lYxbYKxYTg" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h2 id="limitation-of-single-packet-attack">Limitation of single-packet attack</h2>
<p>As James mentioned in the <a href="https://portswigger.net/research/the-single-packet-attack-making-remote-race-conditions-local" target="_blank" rel="noopener">The single-packet attack: making remote race-conditions ’local’</a>
, the single-packet attack limits the number of requests that can be synchronized to 20-30 requests:</p>
<pre tabindex="0"><code>TCP has a soft limit of 1,500 bytes as well and I never explored how to push beyond this because 20-30 requests is sufficient for most race conditions.
</code></pre><p>Due to this limitation, it’s hard to exploit the scenario where you can bypass the rate-limiting of, for example, one-time token authentication even if the one-time token only contains the numbers. This is because you’re likely to be able to send only 20-30 requests even if you bypassed the rate limiting.  </p>
<h2 id="fragmentation-of-ip-packet">Fragmentation of IP packet</h2>
<p>To explain the 1,500-byte limitation of the single packet attack, we need to understand the relation between the Ethernet frame, IP packet, and TCP packet.  </p>
<p>When you send a TCP packet over the Ethernet, the TCP packet is encapsulated in the IP packet, and the IP packet is encapsulated in the Ethernet frame:</p>
<p><img alt="An image that shows how TCP packet is encapsulated" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/02.png"/></p>
<p>The maximum size of the Ethernet frame is 1,518 bytes including the Ethernet header (14 bytes) and the frame check sequence (4 bytes), so the maximum size of the IP packet that can be encapsulated in a single Ethernet frame is 1,500 bytes.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>  
<img alt="An image that shows the IP packet is limited to 1,500 bytes" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/03.png"/></p>
<p>This is why James mentioned 1,500 bytes as a soft limit of the TCP. But, why the TCP allows the maximum size of 65,535 bytes for the TCP packet even though the IP packet has a limit of 1,500 bytes?  </p>
<p>Actually, the IP packet supports fragmentation, as defined in the RFC 791.  </p>
<p><a href="https://datatracker.ietf.org/doc/html/rfc791" target="_blank" rel="noopener">https://datatracker.ietf.org/doc/html/rfc791</a>
</p>
<pre tabindex="0"><code> Fragmentation of an internet datagram is necessary when it
 originates in a local net that allows a large packet size and must
 traverse a local net that limits packets to a smaller size to reach
 its destination.
</code></pre><p>When the IP packet is fragmented, the original IP packet is divided into multiple smaller IP packets, and each of the smaller IP packets is encapsulated in different Ethernet frames.  </p>
<p><img alt="An image that shows IP packet is fragmented into multiple frames" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/04.png"/></p>
<p>Since the fragmented IP packet won’t be passed to the TCP layer until all the fragments are received, we can synchronize a large TCP packet even if we split the TCP packet into multiple IP packets.  </p>
<p><img alt="An image that multiple IP fragments are reassembled into a single IP packet" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/05.png"/></p>
<h2 id="tcp-and-sequence-number">TCP and Sequence Number</h2>
<p>We can now send a TCP packet up to 65,535 bytes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by using IP fragmentation, but it’s still not enough when we want to send a large number of requests simultaneously.  </p>
<p>Since we are now using the TCP window size fully, we can’t expand the limit further with a single TCP packet, so we need to figure out how to synchronize the multiple TCP packets.  </p>
<p>Fortunately for us, TCP guarantees the order of the packets via the sequence number.</p>
<p><img alt="An image that shows the TCP packets are reordered based on the sequence number" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/06.png"/></p>
<p><a href="https://datatracker.ietf.org/doc/html/rfc9293#section-3.10-8" target="_blank" rel="noopener">https://datatracker.ietf.org/doc/html/rfc9293#section-3.10-8</a>
</p>
<pre tabindex="0"><code> A natural way to think about processing incoming segments is to imagine that they are first tested for proper sequence number (i.e., that their contents lie in the range of the expected &#34;receive window&#34; in the sequence number space) and then that they are generally queued and processed in sequence number order.
</code></pre><h2 id="first-sequence-sync">First Sequence Sync</h2>
<p>Since TCP guarantees the order of the packets, we can use the sequence number to synchronize the multiple TCP packets.</p>
<table>
<thead>
<tr>
<th>Packet</th>
<th>Sequence Number</th>
</tr>
</thead>
<tbody>
<tr>
<td>A      </td>
<td>1    </td>
</tr>
<tr>
<td>B      </td>
<td>2    </td>
</tr>
<tr>
<td>C      </td>
<td>3    </td>
</tr>
</tbody>
</table>
<p>If the server receives the packets in the order of B, C, and A, the server will not be able to process the packets until it receives packet A, because the server needs to process the packets in the order of the sequence number.  </p>
<p><img alt="An image that shows how the server can’t process the packet" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/07.png"/></p>
<p>By using this behavior, we can prevent the server from processing the packets until we send the final packet, that contains the first sequence number.</p>
<h2 id="combining-ip-fragmentation-and-first-sequence-sync">Combining IP fragmentation and First Sequence Sync</h2>
<p>By using the IP fragmentation and the first sequence sync, we can now send a lot of large requests simultaneously without worrying about the request size.</p>
<p>First, the client establishes a TCP connection with the server and opens HTTP/2 streams, then sends request data except for the last byte of each request.  
At this point, the application waits for the client to send the remaining bytes of the requests, so requests are not processed yet.  </p>
<p><img alt="An image that shows the client sends the requests except for the last byte" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/08.png"/></p>
<p>Then, the client creates large TCP packets that contain multiple HTTP/2 frames with the last byte of requests and sends the packets to the server using IP fragmentation<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, except for the TCP packet with the first sequence number.</p>
<p><img alt="An image that shows the client sends TCP packets with the last byte of requests, but except for the first TCP packet" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/09.png"/></p>
<p>Finally, once the server receives all the packets sent above, the client sends the TCP packet with the first sequence number, and the server processes all the requests simultaneously.</p>
<p><img alt="An image that shows the client sends the first TCP packet" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/10.png"/></p>
<h2 id="limiting-factors">Limiting factors</h2>
<p>While the above technique seems to work well, several factors can affect the number of requests that can be sent simultaneously.  </p>
<p>One obvious factor is the TCP buffer size of the server. Since the server needs to store the packets in the buffer until it reassembles the packets, the server needs to have a large enough buffer to store the packets that are sent out-of-order.  </p>
<p>Thankfully, modern servers usually have a large RAM, and most OS-es have enough buffer to store the packets by default, so the buffer size is not a big issue in most cases.  </p>
<p>However, there is another factor that can affect the number of requests that can be sent simultaneously.  </p>
<p>In HTTP/2, the number of streams that can be opened simultaneously is limited by the <code>SETTINGS_MAX_CONCURRENT_STREAMS</code> setting.</p>
<p>This is a critical issue when we try to use the techniques described in this article because we need to send the requests in one TCP connection to use the first sequence sync.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>  </p>
<p><img alt="An image that indicates that the client can’t open the streams above the limit" src="https://elijer.github.io/research/beyond-the-limit-expanding-single-packet-race-condition-with-first-sequence-sync/11.png"/></p>
<p>Unfortunately, popular HTTP servers like Apache and Nginx have a strict <code>SETTINGS_MAX_CONCURRENT_STREAMS</code> setting:</p>
<table>
<thead>
<tr>
<th>Implementation</th>
<th>Default <code>SETTINGS_MAX_CONCURRENT_STREAMS</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Apache httpd</td>
<td><a href="https://httpd.apache.org/docs/2.4/mod/mod_http2.html#h2maxsessionstreams" target="_blank" rel="noopener">100</a>
                                      </td>
</tr>
<tr>
<td>Nginx  </td>
<td><a href="http://nginx.org/en/docs/http/ngx_http_v2_module.html#http2_max_concurrent_streams" target="_blank" rel="noopener">128</a>
                                      </td>
</tr>
<tr>
<td>Go    </td>
<td><a href="https://cs.opensource.google/go/x/net/+/master:http2/server.go;l=58;drc=6249541f2a6c4cff317a4502d93dd287c5fb0c51" target="_blank" rel="noopener">250</a>
                                      </td>
</tr>
</tbody>
</table>
<p>That being said, <a href="https://datatracker.ietf.org/doc/html/rfc9113#section-6.5.2-2.6.1" target="_blank" rel="noopener">RFC 9113 defines</a>
 the initial value of the <code>SETTINGS_MAX_CONCURRENT_STREAMS</code> as unlimited, and some implementation have a generous limit:</p>
<table>
<thead>
<tr>
<th>Implementation</th>
<th>Default <code>SETTINGS_MAX_CONCURRENT_STREAMS</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>nghttp2</td>
<td><a href="https://github.com/nghttp2/nghttp2/blob/35a245554ba8df0941b7e8a940eb13ff15eed978/lib/nghttp2_session.h#L107" target="_blank" rel="noopener">4294967295</a>
</td>
</tr>
<tr>
<td>Node.js</td>
<td><a href="https://nodejs.org/api/http2.html#settings-object" target="_blank" rel="noopener">4294967295</a>
<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></td>
</tr>
</tbody>
</table>
<p>So, the techniques described in this article could be really powerful depending on the HTTP/2 implementation used by the server.  </p>
<h2 id="demonstration">Demonstration</h2>
<p>In this section, I will benchmark the performance of the first sequence sync, and demonstrate how the exploitation of the limit-overrun vulnerability with it looks like.  </p>
<p>I’ve used the following environment for the demonstration:</p>
<table>
<thead>
<tr>
<th></th>
<th>Server</th>
<th>Client</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Platform</strong></td>
<td>AWS EC2</td>
<td>AWS EC2</td>
</tr>
<tr>
<td><strong>OS</strong></td>
<td>Amazon Linux 2023</td>
<td>Amazon Linux 2023</td>
</tr>
<tr>
<td><strong>Kernel Version</strong></td>
<td>6.1.91</td>
<td>6.1.91</td>
</tr>
<tr>
<td><strong>Instance Type</strong></td>
<td>c5a.4xlarge</td>
<td>t2.micro</td>
</tr>
<tr>
<td><strong>Region</strong></td>
<td>sa-east-1</td>
<td>ap-northeast-1</td>
</tr>
</tbody>
</table>
<p>These servers are located on almost the opposite side of the world, and the network latency between the servers is around 250ms.  </p>
<p>I configured the iptables of the client machine to prevent the RST packet from being sent to the server:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>iptables -A OUTPUT -p tcp --tcp-flags RST RST -s <span>[</span>IP<span>]</span> -j DROP
</span></span></code></pre></div><p>Firstly, I will synchronize the 10,000 requests using the first sequence sync, and measure the time it takes to send the requests.</p>

<p>
  <iframe src="https://www.youtube.com/embed/-lYxbYKxYTg" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Here is the result of the benchmark:</p>
<table>
<thead>
<tr>
<th>Metrics</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Total time</td>
<td>166460500ns</td>
</tr>
<tr>
<td>Average time between requests</td>
<td>16647ns</td>
</tr>
<tr>
<td>Max time between requests</td>
<td>553627ns</td>
</tr>
<tr>
<td>Median time between requests</td>
<td>14221ns</td>
</tr>
<tr>
<td>Min time between requests</td>
<td>220ns</td>
</tr>
</tbody>
</table>
<p>As you can see, I was able to send 10,000 requests in about 166ms.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup> This is equivalent to 0.0166ms per request, which is significantly fast considering the network latency between the servers is around 250ms.  </p>
<p>Next, I will demonstrate the exploitation of the limit-overrun vulnerability in the rate-limiting of the one-time token authentication.</p>

<p>
  <iframe src="https://www.youtube.com/embed/2cUUER1e1OE" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>While the target server software limits the maximum authentication attempts to 5 times, the client machine was able to perform 1,000 attempts, bypassing the rate limiting.</p>
<h2 id="further-improvements">Further Improvements</h2>
<p>While the demonstration worked well, there are still some improvements that can be made to make the attack more reliable and efficient.</p>
<ol>
<li><strong>Support for HTTPS</strong>: The current PoC requires the support of HTTP/2 over the plaintext connection, which some implementations don’t support because the browser only supports HTTP/2 over TLS. By implementing the PoC with TLS support, we can apply these techniques to a wider range of targets.</li>
<li><strong>Support for the case where the target server updates the TCP window</strong>: The current implementation doesn’t support the case where the target server updates the TCP window while sending requests. With the current PoC, the attack will likely fail if the target server updates the TCP window.  </li>
<li><strong>Integrate with the existing proxy tools</strong>: The current PoC doesn’t have flexibility, and requires changes to the code to add headers or modify the request body. By integrating with the existing proxy tools like Burp Suite or Caido, we can easily modify the request and headers.
<ul>
<li>Please note that this might not be possible because these techniques rely on layers 3 and 4 of the OSI model and the proxy tools are designed to work on layer 7.</li>
</ul>
</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>In this article, I explained the technique that I named <code>First Sequence Sync</code> to expand the limitation of the single packet attack.</p>
<p>While the technique could certainly benefit from further refinement, I already find it quite valuable for exploiting vulnerabilities that would otherwise be unexploitable. In fact, I successfully exploited the vulnerability introduced earlier, and I hope you can achieve similar success. Furthermore, I’m looking forward to seeing the new toolings implementing these techniques, too.</p>
<h2 id="shameless-plug">Shameless plug</h2>
<p>At Flatt Security, we specialize in providing top-notch security assessment and penetration testing services. To celebrate the update of our brand new English web pages, you can currently receive a month-long investigation by our elite engineers for just $40,000!</p>
<p>We also offer a powerful security assessment tool called Shisho Cloud, which combines Cloud Security Posture Management (CSPM) and Cloud Infrastructure Entitlement Management (CIEM) capabilities with Dynamic Application Security Testing (DAST) for web applications.</p>
<p>If you’re interested in learning more, feel free to reach out to us at <a href="https://flatt.tech/en" target="_blank" rel="noopener">https://flatt.tech/en</a>
.</p>


  </article></div>
  </body>
</html>
