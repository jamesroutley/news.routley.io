<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bitbashing.io/haskell-concurrency.html">Original</a>
    <h1>Concurrency in Haskell: Fast, Simple, Correct</h1>
    
    <div id="readability-page-1" class="page"><article>
    <p>After nearly a decade of building embedded systems in C, C++, and Rust,
I’ve somehow ended up writing Haskell for a living.
If you’d asked me about functional programming a few years ago,
I would have told you it was self-indulgent academic baloney—and then I stumbled into
people using it for real-time systems where microseconds can mean literal life or death.</p>

<p>I’m too old to try to convince people what tools they <em>should</em> use,
but Haskell has some features that might interest anyone who cares about fast, correct code.
Let’s talk about them.</p>

<p>We’ll start with concurrency.</p>

<hr/>

<p><em>Some people, when confronted with a problem, think,</em></p>

<p><em>Some people, when confronted with a problem, think,</em></p>

<hr/>

<p>Like <a href="https://bitbashing.io/async-rust.html">we’ve previously discussed,</a> <!-- four years ago? Fuck. -->
we have two main concerns when going fast:</p>

<ul>
  <li>
    <p>Your computer (even the one in your pocket) has many cores.
To use the whole computer, you need to distribute work across them.</p>
  </li>
  <li>
    <p>The outside world is slow—networking and disk IO are many thousands of times slower
than computing. Keep computing while you wait!</p>
  </li>
</ul>

<p><img src="https://assets.bitbashing.io/images/latency-numbers.png"/></p>

<p>And so, we need to break work into independent tasks, usually one of two ways:<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">1</a></sup></p>
<ol>
  <li>Compose the program into several <em>threads</em> of execution,
traditionally scheduled and ran by the operating system.</li>
  <li>Compose the program as a series of callbacks, or <em>continuations</em>,
that run once some other action (e.g., IO) completes.</li>
</ol>

<p>Option 2 has some nice performance benefits, especially when paired with event-driven IO.
Watch
<a href="https://www.youtube.com/watch?v=EeYvFl7li9E">Ryan Dhall introduce Node.js to the world</a>—he
doesn’t especially care about Javascript;
he’s just trying to make this sort of concurrency more accessible.
But continuation passing has its own problems.
Even when syntactic sugar like <code>async/await</code> makes it <em>appear</em> to run sequentially,
debugging can be a frustrating experience.
Traditional stack traces go out the window,
and you may ask yourself, “well, how did I get here?”</p>

<h2 id="threads-and-you">Threads and You</h2>

<p>Haskell tries to have the best of both worlds: threads are its concurrency primitive,
but they’re <em>green</em> threads, scheduled by the runtime on an (OS) thread pool,
and fed by event-driven IO.</p>

<p>Let’s crunch through the basics so that we can get to the cool stuff.
We can spawn threads with
<a href="https://hackage.haskell.org/package/base/docs/Control-Concurrent.html#v:forkIO"><code>forkIO</code></a>,
which runs the given action in a new thread and returns a thread ID:</p>
<div><div><pre><code><span>import</span> <span>Control.Concurrent</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
    <span>_tid</span> <span>&lt;-</span> <span>forkIO</span> <span>$</span> <span>putStrLn</span> <span>&#34;Hello from thread 2!&#34;</span>
    <span>putStrLn</span> <span>&#34;Look ma, concurrent prints!&#34;</span>

</code></pre></div></div>
<p>That’s a start, but how do we wait for the thread to complete, or see what it returned?
There’s not much we can do with a thread’s ID, besides
<a href="https://hackage.haskell.org/package/base/docs/Control-Concurrent.html#v:killThread">killing it</a>.
We find answers in the
<a href="https://hackage.haskell.org/package/async/docs/Control-Concurrent-Async.html">async</a>
package, which gives us a <em>promise</em> for our new thread:</p>
<div><div><pre><code><span>async</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Async</span> <span>a</span><span>)</span>
</code></pre></div></div>
<p>…which we can <code>wait</code> for! Or cancel, if we’re in a bad mood:</p>
<div><div><pre><code><span>wait</span> <span>::</span> <span>Async</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>a</span>

<span>cancel</span> <span>::</span> <span>Async</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
</code></pre></div></div>
<p>And so,</p>
<div><div><pre><code><span>import</span> <span>Control.Concurrent.Async</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
    <span>hFut</span> <span>&lt;-</span> <span>async</span> <span>$</span> <span>readFile</span> <span>&#34;hello.txt&#34;</span>
    <span>putStrLn</span> <span>&#34;Reading file...&#34;</span>
    <span>helloContents</span> <span>&lt;-</span> <span>wait</span> <span>hFut</span>
    <span>putStrLn</span> <span>helloContents</span>
</code></pre></div></div>

<p>Sometimes we don’t want to wait for the threads we spawn, though.
Consider a server that spins one off for each client that connects.
It might
<a href="https://hackage.haskell.org/package/async/docs/Control-Concurrent-Async.html#v:link"><em>link</em></a>
these new threads to itself so failures<sup id="fnref:3"><a href="#fn:3" rel="footnote" role="doc-noteref">2</a></sup> propagate back up.</p>
<div><div><pre><code><span>serveLoop</span> <span>::</span> <span>Socket</span> <span>-&gt;</span> <span>(</span><span>Socket</span> <span>-&gt;</span> <span>SockAddr</span> <span>-&gt;</span> <span>IO</span> <span>()</span><span>)</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>serveLoop</span> <span>listener</span> <span>clientHandler</span> <span>=</span> <span>do</span>
    <span>(</span><span>clientSock</span><span>,</span> <span>clientAddr</span><span>)</span> <span>&lt;-</span> <span>accept</span> <span>listener</span>
    <span>-- Handle each client in their own thread</span>
    <span>clientThread</span> <span>&lt;-</span> <span>async</span> <span>$</span> <span>clientHandler</span> <span>clientSock</span> <span>clientAddr</span>
    <span>-- Silently swallowing errors is bad, mmk?</span>
    <span>link</span> <span>clientThread</span>
    <span>serveLoop</span> <span>listener</span> <span>clientHandler</span>
</code></pre></div></div>

<h2 id="no-threads-only-concurrently">No Threads, Only Concurrently</h2>

<p>We still have lots to figure out.
How should we wait for several threads?
If one fails, can we cancel the others?
What happens if <em>we</em> (the caller) are cancelled?<sup id="fnref:4"><a href="#fn:4" rel="footnote" role="doc-noteref">3</a></sup></p>

<p>With the right tools, the correct answer is, “don’t worry about it.”</p>
<div><div><pre><code><span>-- Runs each action in its own thread and returns the results</span>
<span>concurrently</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>

<span>-- Runs each action in its own thread,</span>
<span>-- returning whichever finishes first.</span>
<span>race</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Either</span> <span>a</span> <span>b</span><span>)</span>

<span>-- Run a function (mapping a to b) in a separate thread</span>
<span>-- for each element of a data structure</span>
<span>mapConcurrently</span> <span>::</span> <span>Traversable</span> <span>t</span> <span>=&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>t</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>t</span> <span>b</span><span>)</span>

<span>-- And much more...</span>
</code></pre></div></div>
<p>In each of these, if one thread fails, the rest are cancelled.
And if the parent thread fails, all children are cancelled.
This is wonderfully declarative—work happens concurrently,
stops as soon as it should,
and we don’t concern ourselves with spawning and joining individual threads.</p>

<p>There’s also a <code>Concurrently</code> type we can apply to our own abstractions.
Want a concurrently-evaluated tuple?</p>
<div><div><pre><code><span>(</span><span>page1</span><span>,</span> <span>page2</span><span>,</span> <span>page3</span><span>)</span> <span>&lt;-</span> <span>runConcurrently</span> <span>$</span> <span>(,,)</span>
    <span>&lt;$&gt;</span> <span>Concurrently</span> <span>(</span><span>getURL</span> <span>&#34;url1&#34;</span><span>)</span>
    <span>&lt;*&gt;</span> <span>Concurrently</span> <span>(</span><span>getURL</span> <span>&#34;url2&#34;</span><span>)</span>
    <span>&lt;*&gt;</span> <span>Concurrently</span> <span>(</span><span>getURL</span> <span>&#34;url3&#34;</span><span>)</span>
</code></pre></div></div>
<p>Or to run a whole collection of actions all at once and collect the results?</p>
<div><div><pre><code><span>runAll</span> <span>::</span> <span>(</span><span>Foldable</span> <span>f</span><span>,</span> <span>Monoid</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>f</span> <span>(</span><span>IO</span> <span>m</span><span>)</span> <span>-&gt;</span> <span>IO</span> <span>m</span>
<span>runAll</span> <span>=</span> <span>runConcurrently</span> <span>.</span> <span>foldMap</span> <span>Concurrently</span>
</code></pre></div></div>
<p>(Haskell’s ability to build generalize code over “anything foldable” or “anything traversable”
is another superpower
<a href="https://blog.jle.im/entry/inside-my-world-ode-to-functor-and-monad.html">worth talking about</a>,
but let’s gloss over FP jargon today.)</p>

<h2 id="stm-and-the-art-of-waiting">STM and the art of waiting</h2>

<p><em>For he who gets hurt will be he who has stalled.</em></p>

<hr/>

<p>Great, we have threads! Next, we need them to talk to each other—this is the part
folks think of when they say concurrency is hard.
Enter the real magic of Haskell: <em>STM</em>.</p>

<p>Short for “software transactional memory”,
STM defines a few special types.
The foundational one is
<a href="https://hackage.haskell.org/package/stm/docs/Control-Concurrent-STM-TVar.html#t:TVar"><code>TVar</code></a>:</p>
<div><div><pre><code><span>-- A &#34;transactional variable&#34;</span>
<span>data</span> <span>TVar</span> <span>a</span>

<span>-- Create a TVar holding any type at all, then...</span>
<span>newTVarIO</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>TVar</span> <span>a</span><span>)</span>

<span>-- ...atomically read...</span>
<span>readTVar</span> <span>::</span> <span>TVar</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>a</span>

<span>-- ...and atomically write.</span>
<span>writeTVar</span> <span>::</span> <span>TVar</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>()</span>
</code></pre></div></div>
<p>The library uses that to build other useful types, like a bounded queue:</p>
<div><div><pre><code><span>data</span> <span>TBQueue</span> <span>a</span>

<span>-- Create one of the given length</span>
<span>newTBQueueIO</span> <span>::</span> <span>Natural</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>TBQueue</span> <span>a</span><span>)</span>

<span>-- Write to the queue, blocking if full</span>
<span>writeTBQueue</span> <span>::</span> <span>TBQueue</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>()</span>

<span>-- Read from the queue, blocking if empty</span>
<span>readTBQueue</span> <span>::</span> <span>TBQueue</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>a</span>

<span>-- Read from the queue, returning Nothing if empty</span>
<span>tryReadTBQueue</span> <span>::</span> <span>TBQueue</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>(</span><span>Maybe</span> <span>a</span><span>)</span>

<span>-- And so on...</span>
</code></pre></div></div>

<p>You’ll notice that reads and writes aren’t IO actions—they’re <em>STM actions</em>.
How do we use those? As parts of an atomic transaction, of course.</p>
<div><div><pre><code><span>atomically</span> <span>::</span> <span>STM</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>a</span>
</code></pre></div></div>
<p>As the name implies, <code>atomically</code> acts as a critical section—everything inside
happens all at once.
At its most boring, we can use this to read and write our STM types:</p>
<div><div><pre><code><span>-- A silly concurrent cat:</span>
<span>-- read stdin in one thread, write to stdout in the other.</span>
<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
    <span>q</span> <span>&lt;-</span> <span>newTBQueueIO</span> <span>1024</span>
    <span>let</span> <span>reader</span> <span>=</span> <span>do</span>
            <span>l</span> <span>&lt;-</span> <span>getLine</span>
            <span>atomically</span> <span>$</span> <span>writeTBQueue</span> <span>q</span> <span>l</span>
            <span>reader</span> <span>-- loop!</span>
    <span>let</span> <span>printer</span> <span>=</span> <span>do</span>
            <span>l</span> <span>&lt;-</span> <span>atomically</span> <span>$</span> <span>readTBQueue</span> <span>q</span>
            <span>putStrLn</span> <span>l</span>
            <span>printer</span> <span>-- loop!</span>
    <span>-- Run each in their own thread:</span>
    <span>concurrently_</span> <span>reader</span> <span>printer</span>
</code></pre></div></div>
<p>But the real power is how STM functions compose.</p>

<p>Let’s say we want a queue that can be <em>closed</em>.
Our little program only works well until data stops—pipe it a file or hit Ctrl+D and:</p>
<div><div><pre><code>cat.hs: &lt;stdin&gt;: hGetLine: end of file
</code></pre></div></div>
<p>Let’s fix that.</p>
<div><div><pre><code><span>-- The C is for Closeable!</span>
<span>data</span> <span>TBCQueue</span> <span>a</span> <span>=</span> <span>TBCQueue</span> <span>{</span>
    <span>queue</span> <span>::</span> <span>TBQueue</span> <span>a</span><span>,</span>
    <span>open</span> <span>::</span> <span>TVar</span> <span>Bool</span>
<span>}</span>

<span>-- Make a new closeable queue with the given capacity.</span>
<span>newTBCQueueIO</span> <span>::</span> <span>Natural</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>TBCQueue</span> <span>a</span><span>)</span>
<span>newTBCQueueIO</span> <span>n</span> <span>=</span> <span>TBCQueue</span> <span>&lt;$&gt;</span> <span>newTBQueueIO</span> <span>n</span> <span>&lt;*&gt;</span> <span>newTVarIO</span> <span>True</span>

<span>-- Closing means it&#39;s no longer open.</span>
<span>closeTBCQueue</span> <span>::</span> <span>TBCQueue</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>()</span>
<span>closeTBCQueue</span> <span>q</span> <span>=</span> <span>writeTVar</span> <span>q</span><span>.</span><span>open</span> <span>False</span>
</code></pre></div></div>
<p>We’ll make writing a no-op if the channel is closed.
(Returning <code>open</code> would be another viable option.)</p>
<div><div><pre><code><span>writeTBCQueue</span> <span>::</span> <span>TBCQueue</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>()</span>
<span>writeTBCQueue</span> <span>q</span> <span>v</span> <span>=</span> <span>do</span>
    <span>stillOpen</span> <span>&lt;-</span> <span>readTVar</span> <span>q</span><span>.</span><span>open</span>
    <span>when</span> <span>stillOpen</span> <span>$</span> <span>writeTBQueue</span> <span>q</span><span>.</span><span>queue</span> <span>v</span>
</code></pre></div></div>
<p>Reading is a little more interesting—we want to wait for a value when the queue is open,
and then once it’s closed <em>(and empty!)</em>, return <code>Nothing</code>.</p>
<div><div><pre><code><span>readTBCQueue</span> <span>::</span> <span>TBCQueue</span> <span>a</span> <span>-&gt;</span> <span>STM</span> <span>(</span><span>Maybe</span> <span>a</span><span>)</span>
<span>readTBCQueue</span> <span>q</span> <span>=</span> <span>do</span>
    <span>-- Try to read from the queue</span>
    <span>maybeV</span> <span>&lt;-</span> <span>tryReadTBQueue</span> <span>q</span><span>.</span><span>queue</span>
    <span>case</span> <span>maybeV</span> <span>of</span>
        <span>-- If there was a value in the queue, just return it.</span>
        <span>Just</span> <span>v</span> <span>-&gt;</span> <span>pure</span> <span>$</span> <span>Just</span> <span>v</span>
        <span>-- If the queue was empty...</span>
        <span>Nothing</span> <span>-&gt;</span> <span>do</span>
            <span>-- ...Is the queue still open?</span>
            <span>-- If so we need to wait,</span>
            <span>-- otherwise return Nothing to indicate it&#39;s closed.</span>
            <span>stillOpen</span> <span>&lt;-</span> <span>readTVar</span> <span>q</span><span>.</span><span>open</span>
            <span>if</span> <span>stillOpen</span>
                <span>then</span> <span>retry</span>
                <span>else</span> <span>pure</span> <span>Nothing</span>
</code></pre></div></div>
<p>What’s <code>retry</code>, you might ask? It aborts the entire transaction and tries again.</p>

<p>Add some logic to check when the party ends,
and we can gracefully handle EOF:</p>
<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
    <span>q</span> <span>&lt;-</span> <span>newTBCQueueIO</span> <span>1024</span>
    <span>let</span> <span>reader</span> <span>=</span> <span>do</span>
            <span>eof</span> <span>&lt;-</span> <span>isEOF</span>
            <span>if</span> <span>eof</span>
                <span>then</span> <span>atomically</span> <span>$</span> <span>closeTBCQueue</span> <span>q</span>
                <span>else</span> <span>do</span>
                    <span>l</span> <span>&lt;-</span> <span>getLine</span>
                    <span>atomically</span> <span>$</span> <span>writeTBCQueue</span> <span>q</span> <span>l</span>
                    <span>reader</span> <span>-- loop!</span>

    <span>let</span> <span>printer</span> <span>=</span> <span>do</span>
            <span>maybeL</span> <span>&lt;-</span> <span>atomically</span> <span>$</span> <span>readTBCQueue</span> <span>q</span>
            <span>case</span> <span>maybeL</span> <span>of</span>
                <span>Nothing</span> <span>-&gt;</span> <span>pure</span> <span>()</span>
                <span>Just</span> <span>l</span> <span>-&gt;</span> <span>do</span>
                    <span>putStrLn</span> <span>l</span>
                    <span>printer</span> <span>-- loop!</span>

    <span>concurrently_</span> <span>reader</span> <span>printer</span>
</code></pre></div></div>
<p>If you’d like to play with this yourself,
<code>TBCQueue</code> and some related goodies are available
<a href="https://hackage.haskell.org/package/hoare-0.1.0.0">here</a>.</p>

<p>But first, stop and appreciate the magic.
We’re atomically manipulating both the queue <em>and</em> the <code>open</code>
flag, and there’s no mutexes in sight.
What’s more, <code>readTBCQueue</code> looks like it busy-loops by calling <code>retry</code>,
but no cores are harmed when we run the program!
The Haskell runtime tracks the TVars involved in each transaction,
and only wakes <code>retry</code>ing threads when a writer changes one.</p>

<p>Imagine how you’d implement this wait/wake behavior with condition variables,
CASes and futexes, event groups, or whatever other primitives you know and love.
It would be tricky, to say the least.
Here there’s no spurious wakeups or deadlock to worry about.
And, because only <code>STM</code> actions can go in <code>atomically</code>,
we can’t accidentally pull arbitrary IO into these critical sections.
In the same way Rust makes most memory bugs impossible<sup id="fnref:5"><a href="#fn:5" rel="footnote" role="doc-noteref">4</a></sup> on the type level,
STM wipes out entire categories of concurrency problems.</p>

<p>I think that’s pretty neat.</p>

<hr/>



  </article></div>
  </body>
</html>
