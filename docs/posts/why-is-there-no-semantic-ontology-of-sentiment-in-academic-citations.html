<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://shkspr.mobi/blog/2022/07/why-is-there-no-semantic-ontology-of-sentiment-in-academic-citations/">Original</a>
    <h1>Why is there no semantic ontology of sentiment in academic citations?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="https://schema.org/articleBody">
<p>About a million years ago, I was discussing the <a href="http://xmlns.com/foaf/spec/">FOAF</a> (Friend of a Friend) ontology with its early proponents. It allowed you to define a machine-readable semantic relationship like &#34;Alice is married to Bill&#34; and &#34;Bill is Carol&#39;s child&#34; and &#34;Carol works for David&#34;. That sort of thing.</p><p>At the time, all the FOAF relationships were defined in terms of positive sentiment. There wasn&#39;t (and still isn&#39;t) a FOAF representation for &#34;divorced&#34; or &#34;estranged&#34; or &#34;fired by&#34;. I thought this was a failing. I understand <em>why</em> we all might want to play nice on the Internet. But sometimes it is <em>useful</em> to know about &#34;negative&#34; relationships.</p><p>For example, I want to organise a seating plan for my wedding - it&#39;s helpful to know that Alice and Bill divorced and can&#39;t be on the same table, Carol doesn&#39;t talk to David. Bill is in a relationship with David and wants to keep it secret. Ellen would like to know Alice better. That sort of thing.</p><p>More modern versions of FOAF have properties like <a href="https://vocab.org/relationship/#enemyOf"><code>enemyOf</code></a> and <code>wouldLikeToKnow</code>. Which I think makes a great deal of sense.</p><p>And so we come to Academic Citations.</p><p>Using Google Scholar (or any other knowledge graph) I can find just about any academic paper. More importantly, it lets me see every paper which <em>references</em> that paper.</p><p><img src="https://shkspr.mobi/blog/wp-content/uploads/2022/06/Screenshot-2022-06-12-at-09-12-24-farting-Google-Scholar.png" alt="Screenshot from Google Scholar. The book On farting: Language and laughter in the middle ages by V Allen has been cited by 106 other authors." width="696" height="146"/></p><p>Great! I can see if something has been cited lots of times, or very few times. That gives me a <em>weak</em> signal about its &#34;importance&#34;.</p><p>But it tells me nothing about the <em>sentiment</em> of those citations.</p><p>Suppose I&#39;ve just read (Smith, 2015) and I want to know whether the consensus is that the paper is a work of genius or absolute horseshit. What are my options? I can find all the citations of it, then manually read each one to determine whether the author thinks Smith is off their rocker or not.</p><p>Wikidata has support for this. The <a href="https://www.wikidata.org/wiki/Q112286535#P2860">Cites Work</a> property can have roles like &#34;<a href="https://www.wikidata.org/wiki/Q2090618">objection</a>&#34; and &#34;<a href="https://www.wikidata.org/wiki/Q265871">endorsement</a>&#34;</p><p><img loading="lazy" src="https://shkspr.mobi/blog/wp-content/uploads/2022/06/Screenshot-2022-06-12-at-09-23-14-â€˜Conversion-Therapy-and-the-University-of-Birmingham-c.1966-1983.png" alt="Screenshot of a Wikidata page which lists papers which express an objection to the cited work." width="823" height="496"/></p><p>This means, in theory, someone could build a knowledge graph which says &#34;Smith&#39;s argument rests on Jones&#39; paper, but Xi&#39;s paper and Zhang&#39;s paper both object to Jones.  Hook disagrees with Zhang&#39;s analysis, but these 500 papers disagree with Hook.&#34;</p><h2 id="why-is-this-important"><a href="#why-is-this-important">Why is this important</a></h2><p>One problem that modern social media has is that its algorithms have no knowledge of sentiment.  Whether you share a cute kitten video to make your friends smile or share a hateful message by a bigot in order to whip up a frenzy against them - the algorithm sees the <em>same</em> signal; <code>+1</code>.</p><p>This means the outrage economy grows quickly. All &#34;shares&#34; are seen as positive sentiment.  The algorithm sees lots of shares, interprets that a positive signal, and then further promotes the content - or similar content.  There is very little way that a social network can filter content by &#34;agrees with&#34; or &#34;disagrees with&#34;.</p><p>Things like Facebook attempt to map sentiment with a series of emoji.</p><p><img loading="lazy" src="https://shkspr.mobi/blog/wp-content/uploads/2022/06/Screenshot-from-2022-06-12-09-41-50.png" alt="Facebook sentiment emoji include, love, support, laughter, shock, sadness, and anger." width="422" height="73"/></p><p>In theory, you could tell Facebook not to show you posts which have more than 10% of anger reactions. Or only show you posts with positive sentiment. I say &#34;in theory&#34; because Facebook profits off your rage, so has no interest in helping you moderate your emotions.</p><p>Popping back to academia for a moment. I recently read a paper that I disagreed with. I wanted to know if I was alone in my objection.  This is currently <strong>no way</strong> for me to find all the citations which also disagree with the paper.</p><h2 id="why-this-will-never-happen"><a href="#why-this-will-never-happen">Why this will never happen</a></h2><p>The first thing that stops this is that it is a <em>lot</em> of extra work for a human to perform.  With hundreds of citations per paper, it would be a massive burden to categorise every single paper mentioned in passing. Most academics can&#39;t even be bothered to write alt-text for their images, so any extra labour is likely to be resisted.</p><p>The second problem is that sentiment is <em>hard!</em>  Can it be boiled down to just &#34;agrees with&#34; and &#34;disagrees with&#34;? What about &#34;Agrees with methodology but not conclusion&#34; or &#34;Disagrees with some definitions but supports others&#34;? There are hundreds of different sentiments. Even just positive and negative probably need degrees of strength associated with them.</p><p>In the glorious future where DEEP AI and MACHINE CLEVERNESS rules, it <em>might</em> be possible for a computer to read an academic paper and determine whether it concurs with the papers referenced therein.</p><p>Perhaps we need an army of (paid?) dogsbodies to manually go through every paper ever published and assess the sentiment behind each citation?</p><p>But, for now, we have to make do with weak signals and uncertain sentiment.</p></div></div>
  </body>
</html>
