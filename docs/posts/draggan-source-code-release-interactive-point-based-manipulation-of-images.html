<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/XingangPan/DragGAN">Original</a>
    <h1>DragGAN source code release: Interactive Point-Based Manipulation of Images</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://www.wildlondon.org.uk/XingangPan/DragGAN/blob/main/DragGAN.gif"><img src="https://www.wildlondon.org.uk/XingangPan/DragGAN/raw/main/DragGAN.gif" width="700" data-animated-image=""/></a>
</p>
<p dir="auto"><strong>Figure:</strong> <em>Drag your GAN.</em></p>
<blockquote>
<p dir="auto"><strong>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</strong> </p>
</blockquote>
<h2 tabindex="-1" dir="auto"><a id="user-content-requirements" aria-hidden="true" href="#requirements"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Requirements</h2>
<p dir="auto">Please follow the requirements of <a href="https://github.com/NVlabs/stylegan3">https://github.com/NVlabs/stylegan3</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-download-pre-trained-stylegan2-weights" aria-hidden="true" href="#download-pre-trained-stylegan2-weights"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Download pre-trained StyleGAN2 weights</h2>
<p dir="auto">To download pre-trained weights, simply run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sh scripts/download_model.sh"><pre>sh scripts/download_model.sh</pre></div>
<p dir="auto">If you want to try StyleGAN-Human and the Landscapes HQ (LHQ) dataset, please download weights from these links: <a href="https://drive.google.com/file/d/1dlFEHbu-WzQWJl7nBBZYcTyo000H9hVm/view?usp=sharing" rel="nofollow">StyleGAN-Human</a>, <a href="https://drive.google.com/file/d/16twEf0T9QINAEoMsWefoWiyhcTd-aiWc/view?usp=sharing" rel="nofollow">LHQ</a>, and put them under <code>./checkpoints</code>.</p>
<p dir="auto">Feel free to try other pretrained StyleGAN.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-run-draggan-gui" aria-hidden="true" href="#run-draggan-gui"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Run DragGAN GUI</h2>
<p dir="auto">To start the DragGAN GUI, simply run:</p>

<p dir="auto">This GUI supports editing GAN-generated images. To edit a real image, you need to first perform GAN inversion using tools like <a href="https://github.com/danielroich/PTI">PTI</a>. Then load the new latent code and model weights to the GUI.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-acknowledgement" aria-hidden="true" href="#acknowledgement"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgement</h2>
<p dir="auto">This code is developed based on <a href="https://github.com/NVlabs/stylegan3">StyleGAN3</a>. Part of the code is borrowed from <a href="https://github.com/stylegan-human/StyleGAN-Human">StyleGAN-Human</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-license" aria-hidden="true" href="#license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h2>
<p dir="auto">The code related to the DragGAN algorithm is licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="nofollow">CC-BY-NC</a>.
However, most of this project are available under a separate license terms: all codes used or modified from <a href="https://github.com/NVlabs/stylegan3">StyleGAN3</a> is under the <a href="https://github.com/NVlabs/stylegan3/blob/main/LICENSE.txt">Nvidia Source Code License</a>.</p>
<p dir="auto">Any form of use and derivative of this code must preserve the watermarking functionality.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-bibtex" aria-hidden="true" href="#bibtex"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BibTeX</h2>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{pan2023draggan,
    title={Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold}, 
    author={Pan, Xingang and Tewari, Ayush, and Leimk{\&#34;u}hler, Thomas and Liu, Lingjie and Meka, Abhimitra and Theobalt, Christian},
    booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
    year={2023}
}"><pre><span>@inproceedings</span>{<span>pan2023draggan</span>,
    <span>title</span>=<span><span>{</span>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold<span>}</span></span>, 
    <span>author</span>=<span><span>{</span>Pan, Xingang and Tewari, Ayush, and Leimk{\&#34;u}hler, Thomas and Liu, Lingjie and Meka, Abhimitra and Theobalt, Christian<span>}</span></span>,
    <span>booktitle</span> = <span><span>{</span>ACM SIGGRAPH 2023 Conference Proceedings<span>}</span></span>,
    <span>year</span>=<span><span>{</span>2023<span>}</span></span>
}</pre></div>
</article>
          </div></div>
  </body>
</html>
