<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://thomascountz.com/2023/07/30/low-poly-image-generation">Original</a>
    <h1>Low-poly image generation using evolutionary algorithms in Ruby (2023)</h1>
    
    <div id="readability-page-1" class="page"><div>

	    <header aria-hidden="true">
    
    <nav role="navigation" aria-hidden="true">
        
        <a href="https://thomascountz.com/">
            Writing
        </a>
        
        <a href="https://thomascountz.com/about">
            About
        </a>
        
        <a href="https://thomascountz.com/search">
            Search
        </a>
        
        <a href="https://thomascountz.com/atom.xml">
            Rss
        </a>
        
    </nav>
</header>


        <section>
  

  <p>Inspired by biological systems, evolutionary algorithms model the patterns of multi-generational evolution in order to unearth unique ideas. They work by generating a vast number of potential solutions to a particular problem and then pitting them against each other in a process akin natural selection: only the fittest survive. In this way, evolutionary algorithms are able to navigate large ambiguous search spaces in order to find solutions to problems that may be difficult or inefficient to solve using other methods.</p>

<p>These algorithms are used for a wide variety of tasks: from optimizing neural network parameters, evolving mechanical structures, simulating protein folding, and even generating art!</p>

<p>Today, we will use one such algorithm to create a low-poly version of the Ruby logo, using Ruby<sup id="fnref:why_ruby" role="doc-noteref"><a href="#fn:why_ruby" rel="footnote">1</a></sup>.</p>



<div>
  <div>
    <p><span>Generation:</span>
      <span>0000</span>
    </p>
    <p><span>Max Fitness:</span>
      <span>0078.1640</span>
    </p>
    <p><span>Time (seconds):</span>
      <span>0001.03</span>
    </p>
  </div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/out/gen-0000.png"/>
  </p>
  </div>



<p>In this post, we‚Äôre going to be using the <a href="https://github.com/thomascountz/petri_dish">petri_dish_lab</a> gem for the task of <em>image reconstruction</em>. Image reconstruction is a great example to use because we‚Äôll be able to visualize the evolutionary process working over time.</p>

<p>We‚Äôll begin by going over what an evolutionary algorithm is and how it works. Then, we‚Äôll take a look at the Petri Dish framework and how we can use it to implement an evolutionary algorithm. Next, we‚Äôll define the objective of our image reconstruction problem and how we can represent it in code. Then, we‚Äôll define the genetic operators that we‚Äôll use to evolve the population. Finally, we‚Äôll put it all together and see the results!</p>

<blockquote>
  <p>üßë‚Äçüíª <a href="https://github.com/thomascountz/petri_dish"><strong>Code Here</strong></a></p>
</blockquote>

<blockquote>
  <p>üî∑ <strong>What is a Low-Poly Image?</strong></p>
</blockquote>





<ul>
  <li><a href="#evolutionary-algorithm-overview">Evolutionary Algorithm Overview</a>
    <ul>
      <li><a href="#the-petri-dish-framework">The Petri Dish Framework</a></li>
    </ul>
  </li>
  <li><a href="#understanding-the-objective">Understanding the Objective</a></li>
  <li><a href="#member-representation">Member Representation</a>
    <ul>
      <li><a href="#input-target-image">Input <em>Target</em> Image</a></li>
      <li><a href="#member-genes">Member Genes</a></li>
      <li><a href="#reconstructed-output-image"><em>Reconstructed</em> Output Image</a></li>
    </ul>
  </li>
  <li><a href="#population-initialization">Population Initialization</a></li>
  <li><a href="#fitness-function">Fitness Function</a></li>
  <li><a href="#genetic-operators">Genetic Operators</a>
    <ul>
      <li><a href="#parent-selection-function">Parent Selection Function</a></li>
      <li><a href="#crossover-function">Crossover Function</a></li>
      <li><a href="#mutation-function">Mutation Function</a></li>
      <li><a href="#replacement">Replacement</a></li>
      <li><a href="#end-condition">End Condition</a></li>
    </ul>
  </li>
  <li><a href="#putting-it-together">Putting it Together</a>
    <ul>
      <li><a href="#final-configuration">Final Configuration</a></li>
    </ul>
  </li>
  <li><a href="#results">Results</a>
    <ul>
      <li><a href="#subjective-analysis">Subjective Analysis</a></li>
      <li><a href="#data-analysis-and-interpretation">Data Analysis and Interpretation</a>
        <ul>
          <li><a href="#log-data">Log Data</a></li>
          <li><a href="#image-data">Image Data</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#footnotes">Footnotes</a></li>
</ul>





<p>Evolutionary algorithms are optimization algorithms that ‚Äúsearch‚Äù through an expansive space of potential solutions. The goal of a search algorithm is to find a solution that satisfies some criteria, or <em>objective</em>. Evolutionary algorithms are particularly good in cases where we want a solution that is ‚Äúgood enough,‚Äù rather than an absolute optimum. In our case, we want to find a set of polygon vertices and grayscale values that, when combined, approximate a given image. For this usecase, there‚Äôs no one ‚Äúbest‚Äù solution, so evolutionary algorithms are a good fit.</p>

<p>The image reconstruction process begins by creating a bunch of images with random polygons. We‚Äôre going to use triangles, but we could technically use any shape, and we‚Äôll stick to grayscale colors in order to make the problem a bit simpler. This collection of images is called the <em>population</em>, and each image is called a <em>member</em> of the population.</p>

<p>Once we have a bunch of random guesses, we compare each member to the target image, pixel-by-pixel, to determine their likeness to the target. This <em>measure of likeness</em> is what we refer to as their <em>fitness</em>, and will be determined by how close each pixel is to the correct grayscale value.</p>

<p>Based on their fitness, <em>parent</em> members are then chosen and combined to create a new <em>child</em> member in a process called <em>crossover</em>. The way we select and crossover parent members is by using <em>selection</em> and <em>crossover</em> functions, and we cover these function (along with <em>mutation</em> functions, which mirror the biological process of genetic mutation by injecting random changes into the child member) later. Together, these functions are called the <em>genetic operators</em>. The exact implementation of these operators is perhaps the most important part of developing an evolutionary algorithm, and we‚Äôll spend a lot of time on them later. If you‚Äôre familiar with machine learning, you can think of the genetic operators as <em>hyperparameters</em>.</p>

<p>And, just like in biological systems, the process of parent selection, child creation, and mutation repeats and repeats until we have enough new members to fill a new <em>population</em>. If any of the new members meet our objective, we‚Äôre done! Otherwise, we‚Äôll repeat this entire process, known as a <em>generation</em>, until we find a member that meets the objective, or we otherwise get close enough.</p>

<p>An evolutionary algorithm configured in this way is called a <em>genetic algorithm</em>. There are other types of evolutionary algorithms, but they all share a similar recursive structure, shown here in Ruby-esque code:</p>

<div><div><pre><code><span>def</span> <span>run</span><span>(</span><span>population</span> <span>=</span> <span>[])</span>
  <span># If population is empty or not provided, create a new population</span>
  <span>population</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>POPULATION_SIZE</span><span>)</span> <span>{</span> <span>create_random_member</span> <span>}</span> <span>if</span> <span>population</span><span>.</span><span>empty?</span>

  <span># Try to find a member of the population that meets the objective</span>
  <span>best_member</span> <span>=</span> <span>population</span><span>.</span><span>find</span> <span>{</span> <span>|</span><span>member</span><span>|</span> <span>objective_met?</span><span>(</span><span>member</span><span>)</span> <span>}</span>

  <span># If a member meeting the objective is found, return it</span>
  <span>return</span> <span>best_member</span> <span>if</span> <span>best_member</span>

  <span># Otherwise, create a new generation and recursively search again</span>
  <span>new_population</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>POPULATION_SIZE</span><span>)</span> <span>do</span>
    <span>parents</span> <span>=</span> <span>select_parents</span><span>(</span><span>population</span><span>)</span>
    <span>child</span> <span>=</span> <span>crossover</span><span>(</span><span>parents</span><span>)</span>
    <span>mutate</span><span>(</span><span>child</span><span>)</span>
  <span>end</span>

  <span>run</span><span>(</span><span>new_population</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<blockquote>
  <p>üîÑ <strong>Tail Call Recursion</strong></p>
  <div><div><pre><code><span>RubyVM</span><span>::</span><span>InstructionSequence</span><span>.</span><span>compile_option</span> <span>=</span> <span>{</span>
  <span>tailcall_optimization: </span><span>true</span><span>,</span>
  <span>trace_instruction: </span><span>false</span>
<span>}</span>
</code></pre></div>  </div>
  <p>This prevents the stack from growing indefinitely by reusing the same stack frame for each recursive call, rather than creating a new one.<sup id="fnref:ruby_tail_call_optimization" role="doc-noteref"><a href="#fn:ruby_tail_call_optimization" rel="footnote">2</a></sup></p>
</blockquote>

<h2 id="the-petri-dish-framework">The Petri Dish Framework</h2>

<p>The <a href="https://github.com/thomascountz/petri_dish">Petri Dish</a> framework is a Ruby gem that implements the evolutionary algorithm structure for us in the <code>PetriDish::World.run</code> method. We need to supply the members of the population, how to evaluate their fitness, the genetic operators, and when to stop. These specifics of an evolutionary algorithm are highly dependent on the problem we‚Äôre trying to solve, but the underlying structure is always the same.</p>

<p>Here‚Äôs what a stripped down version of what the <code>PetriDish::World.run</code> method looks like. See if you can spot the similarities to the pseudocode above:</p>

<div><div><pre><code><span>module</span> <span>PetriDish</span>
  <span>class</span> <span>World</span>
    <span>class</span> <span>&lt;&lt;</span> <span>self</span>
      <span>attr_accessor</span> <span>:metadata</span>
      <span>attr_reader</span> <span>:configuration</span><span>,</span> <span>:end_condition_reached</span>

      <span>def</span> <span>run</span><span>(</span>
        <span>members</span><span>:,</span>
        <span>configuration: </span><span>Configuration</span><span>.</span><span>new</span><span>,</span>
        <span>metadata: </span><span>Metadata</span><span>.</span><span>new</span>
      <span>)</span>
        <span>end_condition_reached</span> <span>=</span> <span>false</span>
        <span>max_generation_reached</span> <span>=</span> <span>false</span>

        <span>max_generation_reached</span> <span>=</span> <span>metadata</span><span>.</span><span>generation_count</span> <span>&gt;=</span> <span>configuration</span><span>.</span><span>max_generations</span>

        <span>new_members</span> <span>=</span> <span>(</span><span>configuration</span><span>.</span><span>population_size</span><span>).</span><span>times</span><span>.</span><span>map</span> <span>do</span>
          <span>parents</span> <span>=</span> <span>configuration</span><span>.</span><span>parents_selection_function</span><span>.</span><span>call</span><span>(</span><span>members</span><span>)</span>
          <span>child_member</span> <span>=</span> <span>configuration</span><span>.</span><span>crossover_function</span><span>.</span><span>call</span><span>(</span><span>parents</span><span>)</span>
          <span>configuration</span><span>.</span><span>mutation_function</span><span>.</span><span>call</span><span>(</span><span>child_member</span><span>).</span><span>tap</span> <span>do</span> <span>|</span><span>mutated_child</span><span>|</span>
            <span>end_condition_reached</span> <span>=</span> <span>configuration</span><span>.</span><span>end_condition_function</span><span>.</span><span>call</span><span>(</span><span>mutated_child</span><span>)</span>
          <span>end</span>
        <span>end</span>

        <span>metadata</span><span>.</span><span>increment_generation</span>

        <span>unless</span> <span>end_condition_reached</span> <span>||</span> <span>max_generation_reached</span>
          <span>run</span><span>(</span><span>members: </span><span>new_members</span><span>,</span> <span>configuration: </span><span>configuration</span><span>,</span> <span>metadata: </span><span>metadata</span><span>)</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The <code>PetriDish::World.run</code> method accepts a <code>members</code> Array, which contains the evolving population; a <code>configuration</code> object, which holds the user-defined genetic operators and other configuration options; and an internally used <code>metadata</code> object, which holds information about the current state of the algorithm, like the current generation number.</p>

<p>The Petri Dish framework exposes the <a href="https://github.com/Thomascountz/petri_dish/blob/133be9efea42e7e3f62e01cd92a77ba03425afa4/lib/petri_dish/configuration.rb#L18-L22"><code>PetriDish::Configuration#configure</code></a> method which takes a block of configuration options.</p>

<p>The core configuration options that we‚Äôre interested in for this post are:</p>

<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>fitness_function</code></td>
      <td>A function used to calculate the fitness of an individual</td>
    </tr>
    <tr>
      <td><code>parents_selection_function</code></td>
      <td>A function used to select parents for crossover</td>
    </tr>
    <tr>
      <td><code>crossover_function</code></td>
      <td>A function used to perform crossover between two parents</td>
    </tr>
    <tr>
      <td><code>mutation_function</code></td>
      <td>A function used to mutate the genes of an individual</td>
    </tr>
    <tr>
      <td><code>mutation_rate</code></td>
      <td>The chance that a gene will change during mutation</td>
    </tr>
    <tr>
      <td><code>max_generations</code></td>
      <td>The maximum number of generations to run the evolution for</td>
    </tr>
    <tr>
      <td><code>end_condition_function</code></td>
      <td>A function that determines whether the evolution process should stop premature of <code>max_generations</code></td>
    </tr>
  </tbody>
</table>

<p>We‚Äôll take a look at each of these functions in detail later, but for now, let‚Äôs take a step back and define the objective of our problem.</p>



<p>As mentioned earlier, evolutionary algorithms work best when we define a criteria to aim towards, versus a discrete target. In our case, we are trying to replicate a given grayscale image using triangles. If we break this down in terms of drawing polygons, we want to <strong>find a set of triangles that, when drawn together, approximate the given image</strong>. That is our <em>objective</em>.</p>

<p>We‚Äôll define the triangles by their three vertices. <strong>Each vertex can be encoded as an <code>(x,y)</code> coordinate and a grayscale value.</strong> These are our <em>decision variables</em>.</p>

<p>A series of these three-vertices-and-a-grayscale-value groupings is all the information we need create a low-poly image. We‚Äôll call these groupings ‚Äúpoints‚Äù and an Array of them will represent each members‚Äô <em>genes</em>. Each member of the population will have a distinct set of these points and the algorithm will optimize for a member whose points, or genes, are more <em>fit</em>.</p>

<blockquote>
  <p>‚òùÔ∏è <strong>Why Points instead of Triangles?</strong></p>
</blockquote>

<p>Lastly, we need to define our <em>constraints</em>, or the boundaries of the search space. In our case (mostly due to the arbitrary limit of my laptop‚Äôs processing power), <strong>we will limit the height and width of the image to 100x100 pixels and the color space to 8-bit grayscale</strong>. Independently, <strong>we will also limit each members‚Äô genes to be 100 points</strong>.</p>

<blockquote>
  <p>üó∫Ô∏è <strong>Quantifying the Search Space</strong></p>
</blockquote>

<p>Now that we‚Äôve taken a look at the objective, decision variables, and constraints at a high level, let‚Äôs take a look at how we can represent them in code.</p>

<p>To recap:</p>
<ul>
  <li><strong>Objective</strong>: Find a set of non-overlapping triangles that approximate the given image</li>
  <li><strong>Decision Variables</strong>: Each vertex can be encoded as an <code>(x,y)</code> coordinate and a grayscale value</li>
  <li><strong>Constraints</strong>: 100x100 pixel image, 8-bit grayscale, 100 points</li>
</ul>



<p>Evolutionary algorithms are generic in the sense that they can be applied to a wide variety of problems. Therefore, just as we would for a neural network, we must engineer, or encode, our problem into a format that can be understood by the algorithm‚Äôs architecture.</p>

<p>We need to encode:</p>
<ol>
  <li><a href="#input-target-image">The input <em>target</em> image</a>,</li>
  <li><a href="#member-genes">The <em>genes</em> of each member of the population</a>, and</li>
  <li><a href="#reconstructed-output-image">The <em>reconstructed</em> output image</a>.</li>
</ol>

<h2 id="input-target-image">Input <em>Target</em> Image</h2>

<p>For both the input and output images, we‚Äôll use the <a href="https://github.com/rmagick/rmagick"><code>Magick</code></a> gem which provides a Ruby interface to the <a href="https://imagemagick.org/">ImageMagick</a> image processing library.</p>

<p>Starting with an input image path, we can read the image into memory, center crop it to a 100x100 pixel square, and then convert it to grayscale. We‚Äôll save the image to a file for later comparison.</p>

<div><div><pre><code><span>require</span> <span>&#39;rmagick&#39;</span>

<span>def</span> <span>import_target_image</span><span>(</span><span>input_path</span><span>,</span> <span>output_path</span><span>)</span>
  <span>image</span> <span>=</span> <span>Magick</span><span>::</span><span>Image</span><span>.</span><span>read</span><span>(</span><span>input_path</span><span>).</span><span>first</span>

  <span># Calculate crop size and coordinates for center crop</span>
  <span>crop_size</span> <span>=</span> <span>[</span><span>image</span><span>.</span><span>columns</span><span>,</span> <span>image</span><span>.</span><span>rows</span><span>].</span><span>min</span>
  <span>crop_x</span> <span>=</span> <span>(</span><span>image</span><span>.</span><span>columns</span> <span>-</span> <span>crop_size</span><span>)</span> <span>/</span> <span>2</span>
  <span>crop_y</span> <span>=</span> <span>(</span><span>image</span><span>.</span><span>rows</span> <span>-</span> <span>crop_size</span><span>)</span> <span>/</span> <span>2</span>

  <span>image</span>
    <span>.</span><span>crop</span><span>(</span><span>crop_x</span><span>,</span> <span>crop_y</span><span>,</span> <span>crop_size</span><span>,</span> <span>crop_size</span><span>)</span>
    <span>.</span><span>resize</span><span>(</span><span>IMAGE_HEIGHT_PX</span><span>,</span> <span>IMAGE_WIDTH_PX</span><span>)</span>
    <span>.</span><span>quantize</span><span>(</span><span>256</span><span>,</span> <span>Magick</span><span>::</span><span>GRAYColorspace</span><span>)</span>
    <span>.</span><span>write</span><span>(</span><span>output_path</span><span>)</span>

  <span>image</span>
<span>end</span>
</code></pre></div></div>

<p>Let‚Äôs import the Ruby logo and see what it looks like:</p>

<div><div><pre><code><span>IMAGE_WIDTH_PX</span> <span>=</span> <span>100</span>
<span>IMAGE_HEIGHT_PX</span> <span>=</span> <span>100</span>

<span>target_image</span> <span>=</span> <span>import_target_image</span><span>(</span><span>&#34;ruby_logo.png&#34;</span><span>,</span> <span>&#34;ruby_logo_grayscale.png&#34;</span><span>)</span>
</code></pre></div></div>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/ruby_logo_grayscale.png"/></p><figcaption>100x100 pixel grayscale version of the Ruby logo: our target image.</figcaption>
</div>

<p>Using the <code>Magick::Image</code> class to represent our target image is arbitrary, but the <code>rmagick</code> library provides a convenient interface for reading, writing, and importantly, comparing images pixel-by-pixel. (We‚Äôll use this later to calculate the fitness of each member).</p>

<h2 id="member-genes">Member Genes</h2>

<p>When defining of our objective, we identified that the genes of each member can be represented as an Array of 100 points, each with an <code>(x,y)</code> coordinate and a grayscale value that defines the vertices of triangles. We can encode this using a <code>Point</code> Struct with <code>x</code>, <code>y</code>, and <code>grayscale</code> attributes.</p>

<div><div><pre><code><span>Point</span> <span>=</span> <span>Struct</span><span>.</span><span>new</span><span>(</span><span>:x</span><span>,</span> <span>:y</span><span>,</span> <span>:grayscale</span><span>)</span>
</code></pre></div></div>

<blockquote>
  <p>üìê <strong>Why a Struct?</strong></p>
</blockquote>

<!-- TODO: Add benchmarks -->

<blockquote>
  <p>üåà <strong>Why does a Point have color?</strong></p>
</blockquote>

<p>Now that we have a <code>Point</code>, we can create an Array of them to form a member‚Äôs genes.</p>

<p>The Petri Dish framework provides a <code>PetriDish::Member</code> class, which acts as an interface to the library. The <code>PetriDish::Member</code> class holds onto the <code>genes</code> Array, which is then directly exposed via the <code>PetriDish::Member#genes</code> method.</p>

<p>Here is the entire definition of the <code>PetriDish::Member</code> class:</p>

<div><div><pre><code><span>module</span> <span>PetriDish</span>
  <span>class</span> <span>Member</span>
    <span>attr_reader</span> <span>:genes</span>

    <span>def</span> <span>initialize</span><span>(</span><span>genes</span><span>:,</span> <span>fitness_function</span><span>:)</span>
      <span>@fitness_function</span> <span>=</span> <span>fitness_function</span>
      <span>@genes</span> <span>=</span> <span>genes</span>
    <span>end</span>

    <span>def</span> <span>fitness</span>
      <span>@fitness</span> <span>||=</span> <span>@fitness_function</span><span>.</span><span>call</span><span>(</span><span>self</span><span>)</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The initializer also accepts a <code>fitness_function</code> which is used to evaluate the fitness of a member. (We‚Äôll define the fitness function later, but for now, it only needs to respond to <code>#call</code> and take a <code>PetriDish::Member</code> as its only argument).</p>

<p>To create a <code>PetriDish::Member</code> with an Array of 100 random <code>Point</code>-s as its genes, we do the following:</p>

<div><div><pre><code><span>GRAYSCALE_RANGE</span> <span>=</span> <span>0</span><span>..</span><span>255</span>

<span>def</span> <span>random_member</span>
  <span>genes</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>100</span><span>)</span> <span>do</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>rand</span><span>(</span><span>0</span><span>..</span><span>IMAGE_WIDTH_PX</span><span>),</span> <span>rand</span><span>(</span><span>0</span><span>..</span><span>IMAGE_HEIGHT_PX</span><span>),</span> <span>rand</span><span>(</span><span>GRAYSCALE_RANGE</span><span>))</span>
  <span>end</span>

  <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>genes</span><span>,</span> <span>fitness_function: </span><span>-&gt;</span><span>(</span><span>_member</span><span>)</span> <span>{</span> <span>})</span>
<span>end</span>

<span>puts</span> <span>random_member</span><span>.</span><span>genes</span><span>.</span><span>sample</span><span>(</span><span>3</span><span>)</span>
<span>#&lt;struct Point x=57, y=21, grayscale=235&gt;</span>
<span>#&lt;struct Point x=16, y=49, grayscale=64&gt;</span>
<span>#&lt;struct Point x=68, y=6, grayscale=210&gt;</span>
</code></pre></div></div>

<h2 id="reconstructed-output-image"><em>Reconstructed</em> Output Image</h2>

<p>To turn a <code>PetriDish::Member</code> into a low-poly image, we‚Äôll create triangles using its <code>#genes</code> in a process called <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation"><em>Delaunay triangulation</em></a>. This technique takes a set of points and creates a set of triangles such that no point is inside the circumcircle of any triangle, i.e. no triangle overlaps another. The¬†<a href="https://github.com/hendrixfan/delaunator-ruby/tree/master"><code>delaunator</code></a>¬†gem is a Ruby library that performs Delaunay triangulation, and we‚Äôll use it here instead of implementing it ourselves.</p>

<p>Let‚Äôs define a function called <code>member_to_image</code> that takes a <code>PetriDish::Member</code> and returns an <code>Magick::Image</code> object based on the member‚Äôs genes (while also grossly violating the single-responsibility principle).</p>

<ol>
  <li>We begin by initializing a new <code>Magick::Image</code> object, which is the same object type as our input image.</li>
  <li>We then perform the Delaunay triangulation using the <code>Delaunator.triangulate</code> method and passing in the <code>x</code> and <code>y</code> values from the <code>Point</code>-s returned from the <code>PetriDish::Member#genes</code> method.</li>
  <li>To determine the grayscale fill value, we use the <code>grayscale</code> value from <code>PetriDish::Member#genes</code>, and average them, as we discussed earlier.</li>
  <li>Finally, we draw each triangle onto the image using the <code>Magick::Draw#polygon</code> method.</li>
</ol>

<div><div><pre><code><span>require</span> <span>&#39;petri_dish&#39;</span>
<span>require</span> <span>&#39;delaunator&#39;</span>

<span>def</span> <span>member_to_image</span><span>(</span><span>member</span><span>)</span>
  <span># Create a new image with a white background</span>
  <span>image</span> <span>=</span> <span>Magick</span><span>::</span><span>Image</span><span>.</span><span>new</span><span>(</span><span>IMAGE_WIDTH_PX</span><span>,</span> <span>IMAGE_HEIGHT_PX</span><span>)</span> <span>{</span> <span>|</span><span>options</span><span>|</span> <span>options</span><span>.</span><span>background_color</span> <span>=</span> <span>&#34;white&#34;</span> <span>}</span>

  <span># Create a new draw object to draw onto the image</span>
  <span>draw</span> <span>=</span> <span>Magick</span><span>::</span><span>Draw</span><span>.</span><span>new</span>

  <span># Perform Delaunay triangulation on the points</span>
  <span>#</span>
  <span># Delaunator.triangulate accepts a nested array of [[x1, y1], [xN, yN]]</span>
  <span># coordinates and returns an array of triangle vertex indices where each</span>
  <span># group of three numbers forms a triangle</span>
  <span>triangles</span> <span>=</span> <span>Delaunator</span><span>.</span><span>triangulate</span><span>(</span><span>member</span><span>.</span><span>genes</span><span>.</span><span>map</span> <span>{</span> <span>|</span><span>point</span><span>|</span> <span>[</span><span>point</span><span>.</span><span>x</span><span>,</span> <span>point</span><span>.</span><span>y</span><span>]</span> <span>})</span>

  <span>triangles</span><span>.</span><span>each_slice</span><span>(</span><span>3</span><span>)</span> <span>do</span> <span>|</span><span>i</span><span>,</span> <span>j</span><span>,</span> <span>k</span><span>|</span>
    <span># Get the vertices of the triangle</span>
    <span>triangle_points</span> <span>=</span> <span>member</span><span>.</span><span>genes</span><span>.</span><span>values_at</span><span>(</span><span>i</span><span>,</span> <span>j</span><span>,</span> <span>k</span><span>)</span>

    <span># Use the average color from all three points as the fill color</span>
    <span>color</span> <span>=</span> <span>triangle_points</span><span>.</span><span>map</span><span>(</span><span>&amp;</span><span>:grayscale</span><span>).</span><span>sum</span> <span>/</span> <span>3</span>

    <span># The `Magick::Draw#fill` method accepts a string representing a color in the form &#34;rgb(r, g, b)&#34;</span>
    <span>draw</span><span>.</span><span>fill</span><span>(</span><span>&#34;rgb(</span><span>#{</span><span>color</span><span>}</span><span>, </span><span>#{</span><span>color</span><span>}</span><span>, </span><span>#{</span><span>color</span><span>}</span><span>)&#34;</span><span>)</span>

    <span># Magick::Image#draw takes an array of vertices in the form [x1, y1,..., xN, yN]</span>
    <span>vertices</span> <span>=</span> <span>triangle_points</span><span>.</span><span>map</span> <span>{</span> <span>|</span><span>point</span><span>|</span> <span>[</span><span>point</span><span>.</span><span>x</span><span>,</span> <span>point</span><span>.</span><span>y</span><span>]</span> <span>}</span>
    <span>draw</span><span>.</span><span>polygon</span><span>(</span><span>*</span><span>vertices</span><span>.</span><span>flatten</span><span>)</span>
  <span>end</span>

  <span>draw</span><span>.</span><span>draw</span><span>(</span><span>image</span><span>)</span>
  <span>image</span>
<span>end</span>
</code></pre></div></div>

<p>Let‚Äôs see what the result looks like if we run it a few times:</p>

<div><div><pre><code><span>5</span><span>.</span><span>times</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>member_to_image</span><span>(</span><span>random_member</span><span>).</span><span>write</span><span>(</span><span>&#34;member</span><span>#{</span><span>i</span><span>}</span><span>.png&#34;</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/random_members.png"/></p><figcaption>Five random members of the population.</figcaption>
</div>

<p>Here, we can see the Delaunay triangulation in action. Each member has a different set of points, and therefore a different set of triangles. We can also see that the grayscale values are being averaged together to determine the fill color of each triangle.</p>

<p>When we use an <code>Magick::Image</code> object to represent a member of the population, we do so to easily compare it to the <code>Magick::Image</code> target object and visualize the results from the algorithm.</p>

<p>When we use the <code>Petridish::Member</code> object to represent the same member, we do so to enable the algorithm to easily calculate and evolve new members.</p>

<p>This type of data engineering, akin to <em>feature engineering</em> in machine learning, is a critical step in the process of developing an evolutionary algorithm. The way we encode the problem and represent potential solutions has a large impact on the performance of the algorithm and our ability to interpret its output.</p>

<blockquote>
  <p>‚¨úÔ∏è <strong>Why the White Background?</strong></p>
</blockquote>



<p>Often it is the case that completely random population initialization is a good place to start, but we can sometimes quickly see faster results if seed the population with some prior knowledge; similar to choosing a good initial set of weights for a neural network.</p>

<p>In the case of image reconstruction, I found that random initialization lead to a lot of waste in the early generations on distributing the points across the image dimensions. To avoid this, we can instead evenly distribute the points across the <code>x</code> and <code>y</code> dimensions of the image and then randomly assign a grayscale value to each point.</p>

<div><div><pre><code><span>def</span> <span>init_member</span>
  <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span>
    <span>genes: </span><span>(</span><span>0</span><span>..</span><span>IMAGE_WIDTH_PX</span><span>).</span><span>step</span><span>(</span><span>10</span><span>).</span><span>map</span> <span>do</span> <span>|</span><span>x</span><span>|</span>
              <span>(</span><span>0</span><span>..</span><span>IMAGE_HEIGHT_PX</span><span>).</span><span>step</span><span>(</span><span>10</span><span>).</span><span>map</span> <span>do</span> <span>|</span><span>y</span><span>|</span>
                <span>Point</span><span>.</span><span>new</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>GRAYSCALE_VALUES</span><span>.</span><span>sample</span><span>)</span>
              <span>end</span>
            <span>end</span><span>.</span><span>flatten</span><span>,</span>
    <span>fitness_function: </span><span>-&gt;</span><span>(</span><span>_member</span><span>)</span> <span>{</span> <span>}</span>
  <span>)</span>
<span>end</span>
</code></pre></div></div>
<p>Let‚Äôs see what the result looks like if we run this method a few times:</p>

<div><div><pre><code><span>5</span><span>.</span><span>times</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>member_to_image</span><span>(</span><span>init_member</span><span>).</span><span>write</span><span>(</span><span>&#34;member</span><span>#{</span><span>i</span><span>}</span><span>.png&#34;</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/init_members.png"/></p><figcaption>Five non-random members of the population.</figcaption>
</div>

<p>We can see that the points are evenly distributed across the image dimensions, and that the grayscale values are randomly assigned. Whether or not this is a better starting point than a completely random initialization is a question of experimentation. In the case of image reconstruction and other generative tasks, a random initialization may be better because it allows the algorithm to explore the search space more creatively, though it may take longer to converge on a solution.</p>



<p>The fitness function is a function that takes a <code>Member</code> and returns a number that represents how well that member solves the problem. In our case, we want to know how well a member approximates the target image.</p>

<p>Modeling a fitness function to map to the search space is often the most difficult part of developing an evolutionary algorithm. It‚Äôs also the most important part because it‚Äôs what the algorithm uses to determine which members are better than others. Two key qualities of a fitness function are <em>determinism</em> and <em>discrimination</em>.</p>

<p>Deterministic means that given the same <code>Member</code>, the fitness function should always return the same fitness score. This is because the fitness of a member may be evaluated multiple times during the evolutionary process, and inconsistent results could lead to unpredictable behavior.</p>

<p>Discriminative means that the fitness function should be able to discriminate between different members of the population. That is, members with different genes should have different fitness scores. Although fitness function do not have to be strictly discriminative, if many members have the same fitness score, the evolutionary algorithm may have a harder time deciding which members are better.</p>

<p>Lucky for us, the <code>rmagick</code> library provides an <a href="https://rmagick.github.io/image1.html#difference"><code>Image#difference</code></a> method that fits the bill. <code>Image#difference</code> compares two images and returns three numbers that represent how different they are: <code>mean_erorr_per_pixel</code>, <code>normalized_mean_error</code>, and <code>normalized_maximum_error</code>. We‚Äôll use the <code>normalized_mean_error</code> to calculate our fitness score.<sup id="fnref:normalized_mean_error" role="doc-noteref"><a href="#fn:normalized_mean_error" rel="footnote">4</a></sup></p>

<div><div><pre><code><span>require</span> <span>&#39;petri_dish&#39;</span>
<span>require</span> <span>&#39;rmagick&#39;</span>

  <span>def</span> <span>calculate_fitness</span><span>(</span><span>target_image</span><span>)</span>
    <span>-&gt;</span><span>(</span><span>member</span><span>)</span> <span>do</span>
      <span>member_image</span> <span>=</span> <span>member_to_image</span><span>(</span><span>member</span><span>,</span> <span>IMAGE_WIDTH_PX</span><span>,</span> <span>IMAGE_HEIGHT_PX</span><span>)</span>
      <span># Magick::Image#difference returns a tuple of:</span>
      <span># [mean error per pixel, normalized mean error, normalized maximum error]</span>
      <span>(</span><span>1.0</span> <span>/</span> <span>target_image</span><span>.</span><span>difference</span><span>(</span><span>member_image</span><span>)[</span><span>1</span><span>])</span><span>**</span><span>2</span> <span># Use normalized mean error</span>
    <span>end</span>
  <span>end</span>
</code></pre></div></div>

<p>The fitness function is a lambda that takes a <code>Member</code> and returns a fitness score. The number is the inverse of the normalized mean error between the target image and the image generated from the member, squared. This means that the higher the fitness score, the better the member approximates the target image.</p>

<blockquote>
  <p>üéõÔ∏è <strong>Why normalized?</strong></p>
</blockquote>

<blockquote>
  <p>üôÉ <strong>Why the inverse?</strong></p>
</blockquote>

<blockquote>
  <p>2Ô∏è‚É£ <strong>Why squared?</strong></p>
</blockquote>

<p>Lastly, we define <code>#calculate_fitness</code> as a lambda because the Petri Dish framework requires the <code>fitness_function</code> to respond to <code>#call</code>. The framework will call this lambda via the <code>#fitness</code> method on <code>Member</code> in order to memoize and return the fitness score. We use a closure here so that the <code>target_image</code> is available to the lambda when it‚Äôs called.</p>

<blockquote>
  <p>üì´ <strong>Closures</strong></p>
</blockquote>

<p>Now that we have a way to represent a member of the population and a way to evaluate the fitness of a member, we can start to evolve the population by defining the evolutionary operators.</p>



<p>The genetic operators are the functions that we use to evolve the population generation after generation‚Äîthey are what allow the algorithm to navigate the vast search space of potential solutions.</p>

<p>The operators we‚Äôll take a look at are grouped by <em>selection</em>, <em>crossover</em>, <em>mutation</em>, and <em>replacement</em>.</p>

<h2 id="parent-selection-function">Parent Selection Function</h2>

<p>Selection is the process of choosing which members of the population are the most fit and therefore should be used as <em>parents</em> to create the next generation of <em>children</em>. There are many different selection strategies, but for our task, we‚Äôll use one called <em>fitness proportionate selection</em>.</p>

<p>Also called <em>roulette wheel selection</em> or <em>stochastic acceptance</em>, fitness proportionate selection works by assigning each member a weighted probability of being selected as a parent, and then randomly selects parents based on those probabilities.</p>

<p>The weighted probability assigned to each member is proportional to that member‚Äôs fitness score, which means that members with higher fitness scores are more likely to be selected.</p>

<p>For example, let‚Äôs say we have the following <code>Member</code>-s with the following fitness scores:</p>

<div><div><pre><code><span>population</span> <span>=</span> <span>[</span>
  <span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>],</span> <span>fitness_function: </span><span>-&gt;</span><span>(</span><span>_member</span><span>)</span> <span>{</span> <span>2</span> <span>}),</span>
  <span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>[</span><span>4</span><span>,</span> <span>5</span><span>,</span> <span>6</span><span>],</span> <span>fitness_function: </span><span>-&gt;</span><span>(</span><span>_member</span><span>)</span> <span>{</span> <span>3</span> <span>}),</span>
  <span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>[</span><span>7</span><span>,</span> <span>8</span><span>,</span> <span>9</span><span>],</span> <span>fitness_function: </span><span>-&gt;</span><span>(</span><span>_member</span><span>)</span> <span>{</span> <span>5</span> <span>}),</span>
<span>]</span>
</code></pre></div></div>

<p>To calculate the proportional fitness for each member, we divide the member‚Äôs fitness by the total fitness of the population. In our case, the total fitness is <code>2 + 3 + 5 = 10</code>. Dividing each members‚Äô fitness by this number gives us the proportion of the total fitness that that member contributes.</p>

<p>If we calculate a proportional fitness for each member from our example, we get the following results:</p>

<div><div><pre><code><span>weights</span> <span>=</span> <span>population</span><span>.</span><span>map</span> <span>{</span> <span>|</span><span>member</span><span>|</span> <span>member</span><span>.</span><span>fitness</span> <span>/</span> <span>population</span><span>.</span><span>sum</span><span>(</span><span>&amp;</span><span>:fitness</span><span>).</span><span>to_f</span> <span>}</span>
<span># =&gt; [0.2, 0.3, 0.5]</span>
</code></pre></div></div>

<p>In our example, if we were to select multiple members using these weighted probabilities, we would expect to get the first member (<code>population[0]</code>) 20% of the time, the second member (<code>population[1]</code>) 30% of the time, and the third member (<code>population[2]</code>) 50% of the time.</p>

<p>We can then use these proportional fitnesses, to <em>weigh</em>, or <em>bias</em> the otherwise equally random probability of each member being selected.</p>

<p>Here‚Äôs what that looks like:</p>

<div><div><pre><code>  <span>def</span> <span>roulette_wheel_parent_selection_function</span>
    <span>-&gt;</span><span>(</span><span>members</span><span>)</span> <span>do</span>
      <span>population_fitness</span> <span>=</span> <span>members</span><span>.</span><span>sum</span><span>(</span><span>&amp;</span><span>:fitness</span><span>)</span>
      <span>members</span><span>.</span><span>max_by</span><span>(</span><span>2</span><span>)</span> <span>do</span> <span>|</span><span>member</span><span>|</span>
        <span>weighted_fitness</span> <span>=</span> <span>member</span><span>.</span><span>fitness</span> <span>/</span> <span>population_fitness</span><span>.</span><span>to_f</span>
        <span>rand</span><span>**</span><span>(</span><span>1.0</span> <span>/</span> <span>weighted_fitness</span><span>)</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
</code></pre></div></div>

<p>The proportional fitness is calculated by dividing the member‚Äôs fitness by the total population fitness, like before. Then, we raise a random number between 0 and 1 to the inverse of the proportional fitness in order to bias the selection towards members with higher fitness scores. The <code>Enumberable#max_by</code> method is used to select two members with the highest result from the block.</p>

<p>The maths are a bit annoying to me personally, but nevertheless, the result of all of this is like spinning a roulette wheel where the size of each slice is proportional to the member‚Äôs fitness. The higher the fitness, the larger the slice, and the more likely the member is to be selected.</p>

<p>Notice how the parent selection function makes no mention of <code>Point</code>-s or <code>Magick::Image</code>-s. This is because the selection function is generic and can be used for any problem. It only needs to know how to select members based on their fitness scores.</p>

<p>There are many other selection methods, like simply selecting the fittest members (elite selection) or by first choosing a random subset of the population and then choosing the fittest amongst those (tournament selection).</p>

<p>The benefit of fitness proportional selection is that it allows for a balance between <em>exploration</em> (trying new things) and <em>exploitation</em> (using what we know works). This is because members with lower fitness scores still have a chance of being selected, but members with higher fitness scores are more likely to be selected.</p>

<p>This is the selection method we‚Äôll use for our task, but it may be worth experimenting with other selection methods to see if they work better for our problem.</p>

<blockquote>
  <p>üë®‚Äçüë®‚Äçüë¶ <strong>Multiple Parents</strong></p>
</blockquote>

<h2 id="crossover-function">Crossover Function</h2>

<p>In biology, crossover is when paired chromosomes from each parent swap segments of their DNA. This creates new combinations of genes, leading to genetic diversity in offspring. In evolutionary algorithms, crossover is the process of combining the genes of parents members to create a new child member.</p>

<p>After selecting parents, their genes, an Array of <code>Point</code>-s in our case, are combined to create a new <code>Petridish::Member</code>. There are many different ways to combine the genes of parents, but for our task, we‚Äôll use a method called <em>random midpoint crossover</em> to crossover two parents.</p>

<p>Random midpoint crossover works by randomly selecting a midpoint in the genes of each parent and then combining the genes before and after that midpoint to create a new child. Specifically, we‚Äôll randomly select a midpoint between <code>0</code> and the length of the genes Array, and then take the genes before that midpoint from the first parent and the genes after that midpoint from the second parent.</p>

<p>For example, say we have two parents with the following genes:</p>

<div><div><pre><code><span>parent_1</span> <span>=</span> <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span>
  <span>genes: </span><span>[</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>25</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>3</span><span>,</span> <span>4</span><span>,</span> <span>50</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>5</span><span>,</span> <span>6</span><span>,</span> <span>100</span><span>),</span>
  <span>],</span>
  <span># fitness_function: ...</span>
<span>)</span>
<span>parent_2</span> <span>=</span> <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span>
  <span>genes: </span><span>[</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>7</span><span>,</span> <span>9</span><span>,</span> <span>125</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>9</span><span>,</span> <span>10</span><span>,</span> <span>150</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>11</span><span>,</span> <span>12</span><span>,</span> <span>200</span><span>),</span>
  <span>],</span>
  <span># fitness_function: ...</span>
<span>)</span>
</code></pre></div></div>

<p>If we were to perform random midpoint crossover on these parents, and the <code>midpoint = 1</code>, we would get the following child:</p>

<div><div><pre><code><span>child</span> <span>=</span> <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span>
  <span>genes: </span><span>[</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>25</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>9</span><span>,</span> <span>10</span><span>,</span> <span>50</span><span>),</span>
    <span>Point</span><span>.</span><span>new</span><span>(</span><span>11</span><span>,</span> <span>12</span><span>,</span> <span>200</span><span>),</span>
  <span>],</span>
  <span># fitness_function: ...</span>
<span>)</span>
</code></pre></div></div>

<p>Here‚Äôs our <code>random_midpoint_crossover_function</code> implementation for combining two parents:</p>

<div><div><pre><code>  <span>def</span> <span>random_midpoint_crossover_function</span><span>(</span><span>configuration</span><span>)</span>
    <span>-&gt;</span><span>(</span><span>parents</span><span>)</span> <span>do</span>
      <span>midpoint</span> <span>=</span> <span>rand</span><span>(</span><span>parents</span><span>[</span><span>0</span><span>].</span><span>genes</span><span>.</span><span>length</span><span>)</span>
      <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>parents</span><span>[</span><span>0</span><span>].</span><span>genes</span><span>[</span><span>0</span><span>...</span><span>midpoint</span><span>]</span> <span>+</span> <span>parents</span><span>[</span><span>1</span><span>].</span><span>genes</span><span>[</span><span>midpoint</span><span>..</span><span>],</span> <span>fitness_function: </span><span>configuration</span><span>.</span><span>fitness_function</span><span>)</span>
    <span>end</span>
  <span>end</span>
</code></pre></div></div>

<p>Note again, our function returns a lambda, as required by the Petri Dish framework. The lambda takes an Array of parents and returns a new <code>PetriDish::Member</code> with the combined genes of the parents, while also passing along the <code>fitness_function</code> from the configuration object captured by the closure. As before, the fitness function works generically and does not need to know about <code>Point</code>-s or <code>Magick::Image</code>-s.</p>

<p>Other crossover methods include <em>uniform crossover</em>, where each gene is randomly selected from either parent, and <em>majority rule crossover</em>, which works well for instances of selecting more than two parents. It works by having each gene of the offspring determined by a majority vote among the parents. If the parents have equal votes, one parent is chosen randomly to determine the gene.</p>

<p>Random midpoint crossover is a good choice for starting out for its simplicity, but again, it‚Äôs worth experimenting with other crossover methods to see if they work better for a particular problem. (In fact, its possible to use one genetic algorithm to optimize the genetic operators of another genetic algorithm, but that‚Äôs a topic for another day‚Ä¶).</p>

<blockquote>
  <p>üë©‚Äçüî¨ <strong>Meta Experimentation</strong></p>
</blockquote>

<p>That said, for our task, random midpoint crossover works well enough, so we‚Äôll stick with it for now.</p>

<h2 id="mutation-function">Mutation Function</h2>

<p>Mutation is the process of randomly changing the genes of a child member after crossover. Combining well-fit parents can get us a long way towards a great solution, but mutation is done to introduce new genetic material into the population.</p>

<p>There are many different ways to mutate a member, but for our task, we‚Äôll use a domain-specific implementation that I call <em>nudge mutation</em>.</p>

<blockquote>
  <p>üß¨ <strong>Why mutate at all?</strong></p>
</blockquote>

<p>If we think back to our genes as an Array of <code>Point</code>-s, then nudge mutation is the process of randomly moving each point‚Äôs position and grayscale value by a small amount.</p>

<p>This is done by adding a random number between <code>-10</code> and <code>10</code> to the <code>x</code> and <code>y</code> coordinates of each point <code>clamp</code>-ed between the image dimensions. And, adding a random number between <code>-25</code> and <code>+25</code> to the grayscale value <code>clamp</code>-ed between <code>0..255</code> (i.e. valid grayscale values).</p>

<p>If we implemented this as a lambda for the Petri Dish <code>mutation_function</code> configuration (RBS type <code>Proc[Member, Member]</code>), it might look something like this:</p>

<div><div><pre><code>  <span>def</span> <span>nudge_mutation_function</span><span>(</span><span>configuration</span><span>)</span>
    <span>-&gt;</span><span>(</span><span>member</span><span>)</span> <span>do</span>
      <span>mutated_genes</span> <span>=</span> <span>member</span><span>.</span><span>genes</span><span>.</span><span>dup</span><span>.</span><span>map</span> <span>do</span> <span>|</span><span>gene</span><span>|</span>
        <span>Point</span><span>.</span><span>new</span><span>(</span>
          <span>(</span><span>gene</span><span>.</span><span>x</span> <span>+</span> <span>rand</span><span>(</span><span>-</span><span>10</span><span>..</span><span>10</span><span>)).</span><span>clamp</span><span>(</span><span>0</span><span>,</span> <span>IMAGE_WIDTH_PX</span><span>),</span>
          <span>(</span><span>gene</span><span>.</span><span>y</span> <span>+</span> <span>rand</span><span>(</span><span>-</span><span>10</span><span>..</span><span>10</span><span>)).</span><span>clamp</span><span>(</span><span>0</span><span>,</span> <span>IMAGE_HEIGHT_PX</span><span>),</span>
          <span>(</span><span>gene</span><span>.</span><span>grayscale</span> <span>+</span> <span>rand</span><span>(</span><span>-</span><span>25</span><span>..</span><span>25</span><span>)).</span><span>clamp</span><span>(</span><span>GRAYSCALE</span><span>.</span><span>min</span><span>,</span> <span>GRAYSCALE_RANGE</span><span>.</span><span>max</span><span>)</span>
        <span>)</span>
        <span>end</span>
      <span>PetriDish</span><span>::</span><span>Member</span><span>.</span><span>new</span><span>(</span><span>genes: </span><span>mutated_genes</span><span>,</span> <span>fitness_function: </span><span>configuration</span><span>.</span><span>fitness_function</span><span>)</span>
    <span>end</span>
  <span>end</span>
</code></pre></div></div>
<p>However, we don‚Äôt want to mutate every gene of a child; we want to preserve qualities from the parents and strike a balance between exploration and exploitation. Therefore, we use a <em>mutation rate</em> to determine the probability that any particular gene will be mutated.</p>

<p>For example, if the mutation rate is <code>0.1</code>, then there is a 10% chance that a gene will be mutated.</p>

<p>If we add the concept of a mutation rate to our mutation function, we get this:</p>

<div><div><pre><code><span>def nudge_mutation_function(configuration)
</span>  -&gt;(member) do
    mutated_genes = member.genes.dup.map do |gene|
<span>+      if rand &lt; configuration.mutation_rate
</span>        Point.new(
          (gene.x + rand(-10..10)).clamp(0, IMAGE_WIDTH_PX),
          (gene.y + rand(-10..10)).clamp(0, IMAGE_HEIGHT_PX),
          (gene.grayscale + rand(-25..25)).clamp(GRAYSCALE.min, GRAYSCALE_RANGE.max)
        )
<span>+      else
+        gene
+      end
</span>    end
    PetriDish::Member.new(genes: mutated_genes, fitness_function: configuration.fitness_function)
  end
<span>end
</span></code></pre></div></div>

<p>Here, we use the <code>configuration.mutation_rate</code> to determine whether or not to mutate each gene. If the random number is less than the mutation rate, we mutate the gene, otherwise, copy it over to the new <code>PetriDish::Member</code> as-is.</p>

<blockquote>
  <p>üìà <strong>Determining the mutation rate</strong></p>
</blockquote>

<p>Other common types of mutation strategies include <em>swap mutation</em>, where two genes‚Äô positions are randomly swapped, and <em>scramble mutation</em>, where a random subset of genes are randomly shuffled. Like all other genetic operators, the best strategy for the problem at hand is highly dependent on the problem itself and is often worth experimenting with.</p>

<p>In our case, the mutation function implementation was developed to represent the idea of nudging around the points of a polygon until the resulting image looks like the target image.</p>

<blockquote>
  <p>ü™≤ <strong>Point jitter??</strong></p>
</blockquote>

<p>Now that we have a way to select parents, combine their genes, and mutate the resulting child, we can start to evolve the population. The last step is to define how we‚Äôll replace the old population with the new population.</p>

<h2 id="replacement">Replacement</h2>

<p>In the most simple case, we can replace the entire population with the new population, sometimes called <em>generational replacement</em>. This often works well, but it can sometimes cause <em>too much</em> diversity, which can cause the algorithm to take longer to converge as some of the most-fit members are lost. To prevent this, we can use a technique called <em>elitism</em>.</p>

<p>Elitism, which I personally like to call <em>grandparenting</em>, is the process of preserving the fittest members of the population from one generation to the next. This is done by taking the top <code>n</code> members of the population and adding them to the new population. The rest of the new population is filled with the children of the parents.</p>

<p>In the Petri Dish framework, we tune this parameter using the <code>elitism_rate</code> configuration value. This is the proportion of the population that is preserved through elitism. For example, if the elitism rate is <code>0.1</code>, then the top 10% of the population will be preserved through to the next generation.</p>

<p>Other replacement strategies include <em>steady-state replacement</em>, where only a single member of the population is replaced with a child, and <em>age-based replacement</em>, where the oldest members of the population are replaced with children.</p>

<p>For our image reconstruction task, we‚Äôll use generational replacement with grandparenting set to <code>0.05</code>, or 5%.</p>

<h2 id="end-condition">End Condition</h2>

<p>Lastly, we need to define when the algorithm should stop. The two most common end conditions are 1) when a member of the population meets the criteria, or 2) when a certain number of generations have passed. We‚Äôll use the latter.</p>

<p>An <code>end_condition_function</code> can otherwise be used to determine if any of the members of the population meets a particular criteria. For example, if we were trying to find a member of the population that had a fitness score of <code>1.0</code>, we could use an <code>end_condition_function</code>. Alternatively, we could run the algorithm for a given amount of wall time, or until the rate of improvement drops below a certain threshold.</p>

<p>In our case, we‚Äôll use the <code>max_generations</code> configuration value to determine when the algorithm should stop. This is the maximum number of generations that the algorithm will run for, regardless of the fitness of the members of the population. I have found that <code>5000</code> generations is enough to get a good approximation of the target image, but not so many that it takes too long to run.</p>

<p>We now have all of the pieces we need to put together our evolutionary algorithm. Let‚Äôs see how it all works!</p>



<p>Before we look at the results, let‚Äôs recap everything we‚Äôve gone over.</p>

<ol>
  <li>A genetic algorithm is a type of evolutionary algorithm that uses genetic operators to evolve a population of members towards a solution to a problem.</li>
  <li>We start the algorithm design by identifying our objective, defining our decision variables and search space, and defining our constraints.</li>
  <li>We then define a way to represent a member of the population and a way to evaluate the fitness of a member.
    <ol>
      <li>In our case, we represent a member of the population as an <code>Magick::Image</code> object, and we evaluate the fitness of a member by comparing it to the target image using the <code>Magick::Image#difference</code> method.</li>
      <li>We also represent a member of the population as a <code>PetriDish::Member</code> object with an Array of <code>Point</code>-s as genes, which is used by the Petri Dish framework to evolve the population.</li>
    </ol>
  </li>
  <li>The genetic operators are selection, crossover, mutation, and replacement.
    <ol>
      <li>Selection is the process of choosing which members of the population are the most fit and therefore should be used as <em>parents</em> to create the next generation of <em>children</em>.</li>
      <li>Crossover is the process of combining the genes of parents members to create a new child member.</li>
      <li>Mutation is the process of randomly changing the genes of a child member after crossover.</li>
      <li>Replacement is the process of replacing the old population with the new population.</li>
    </ol>
  </li>
  <li>The end condition is the criteria that determines when the algorithm should stop.
    <ol>
      <li>In our case, we‚Äôll use the <code>max_generations</code> configuration value to determine when the algorithm should stop. This is the maximum number of generations that the algorithm will run for, regardless of the fitness of the members of the population.</li>
    </ol>
  </li>
</ol>

<h2 id="final-configuration">Final Configuration</h2>

<p>The following is the configuration from the <a href="https://github.com/Thomascountz/petri_dish/blob/133be9efea42e7e3f62e01cd92a77ba03425afa4/examples/low_poly_reconstruction/low_poly_reconstruction.rb#L42-L56">actual implementation</a> and contains all of the pieces we‚Äôve discussed so far, with the addition of a few callbacks that the framework provides.</p>

<div><div><pre><code><span>def</span> <span>configuration</span>
  <span>PetriDish</span><span>::</span><span>Configuration</span><span>.</span><span>configure</span> <span>do</span> <span>|</span><span>config</span><span>|</span>
    <span>config</span><span>.</span><span>population_size</span> <span>=</span> <span>50</span>
    <span>config</span><span>.</span><span>mutation_rate</span> <span>=</span> <span>0.05</span>
    <span>config</span><span>.</span><span>elitism_rate</span> <span>=</span> <span>0.05</span>
    <span>config</span><span>.</span><span>max_generations</span> <span>=</span> <span>10_000</span>
    <span>config</span><span>.</span><span>fitness_function</span> <span>=</span> <span>calculate_fitness</span><span>(</span><span>target_image</span><span>)</span>
    <span>config</span><span>.</span><span>parents_selection_function</span> <span>=</span> <span>roulette_wheel_parent_selection_function</span>
    <span>config</span><span>.</span><span>crossover_function</span> <span>=</span> <span>random_midpoint_crossover_function</span><span>(</span><span>config</span><span>)</span>
    <span>config</span><span>.</span><span>mutation_function</span> <span>=</span> <span>nudge_mutation_function</span><span>(</span><span>config</span><span>)</span>
    <span># TODO: Don&#39;t pass in image dimensions, use constants instead</span>
    <span>config</span><span>.</span><span>highest_fitness_callback</span> <span>=</span> <span>-&gt;</span><span>(</span><span>member</span><span>)</span> <span>{</span> <span>save_image</span><span>(</span><span>member_to_image</span><span>(</span><span>member</span><span>,</span> <span>IMAGE_WIDTH_PX</span><span>,</span> <span>IMAGE_HEIGHT_PX</span><span>))</span> <span>}</span>
    <span>config</span><span>.</span><span>generation_start_callback</span> <span>=</span> <span>-&gt;</span><span>(</span><span>current_generation</span><span>)</span> <span>{</span> <span>generation_start_callback</span><span>(</span><span>current_generation</span><span>)</span> <span>}</span>
    <span>config</span><span>.</span><span>end_condition_function</span> <span>=</span> <span>nil</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The <code>highest_fitness_callback</code> is invoked when a member with the highest fitness seen so far is found. When that happens, we save the image to a file so that we can see the progress of the algorithm.</p>

<p>The <code>generation_start_callback</code> is invoked at the start of each generation. We use this to keep track of the progress of the algorithm to do things like name the output images.</p>

<p>The last piece of the configuration we haven‚Äôt discussed yet is the <code>population_size</code>. This is the number of members in the population per generation, and like all other pieces of configuration, is a hyperparameter that should be tuned to improve the performance of the algorithm. A larger population size can increase diversity, but it may also cause the algorithm to take longer to converge. A smaller population size can decrease diversity, but can be aided with a higher mutation rate and maximum number of generations, as we‚Äôve done here.</p>



<p>Finally, it‚Äôs time to run the algorithm and see what happens! Let‚Äôs take a subjective look at the results before we get into the numbers.</p>



<div>
  <div>
    <p><span>Generation:</span>
      <span>0000</span>
    </p>
    <p><span>Max Fitness:</span>
      <span>0078.1640</span>
    </p>
    <p><span>Time (seconds):</span>
      <span>0001.03</span>
    </p>
  </div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/out/gen-0000.png"/>
  </p>
  </div>



<h2 id="subjective-analysis">Subjective Analysis</h2>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/ruby_logo_result.png"/></p><figcaption>Target image and result</figcaption>
</div>

<p>After running the algorithm for over 6000 generations over the course of an hour, I‚Äôm really please with the results!</p>

<p>I‚Äôm surprised by the details the algorithm was able to replicate. For example, the curvature of the top of the ruby is really well defined, given that we‚Äôre working with only straight lines. Also, the highlights along the gem‚Äôs facets were captured well. If I squint hard enough, I have a hard time distinguishing the target image from the result!</p>

<p>With that said, there are some points stuck in the upper left corner that are shading part of the background the wrong color, but I think it‚Äôs those points are actually contributing to the gem‚Äôs curvature that I mentioned earlier.</p>

<p>It looks like algorithm had a lot of early success: by generation 120, we can already begin to see vast improvements! However, as the algorithm continued to run, the gains each generation appeared to diminish, which is to be expected from an evolutionary algorithm and an exponential fitness function. After about generation 2000, the algorithm was making smaller and smaller tweaks to the image.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/skip_montage.png"/></p><figcaption>Output of the <code>highest_fitness_callback</code> calls show a progressively more refined low-poly representation</figcaption>
</div>

<p>The biggest improvements to the image after the early generations appear to be in the grayscale values, rather than the positions of the points. This makes sense because the position of the points only really matter in that the resulting triangle contributes to the grayscale value of the pixels it covers.</p>

<p>By looking only at the images, it‚Äôs hard for me to tell how much the algorithm improved after generation 2000 and wether or not we could have stopped it there.</p>

<p>I‚Äôm curious to see if the numbers tell a different story.<sup id="fnref:subjectivity" role="doc-noteref"><a href="#fn:subjectivity" rel="footnote">7</a></sup></p>

<h2 id="data-analysis-and-interpretation">Data Analysis and Interpretation</h2>

<p>Now that we‚Äôve taken a subjective look at the results, let‚Äôs take an objective look at the algorithm‚Äôs performance. We‚Äôre going to take these numbers with a grain of salt: since we‚Äôve only ran the algorithm once and with one set of configurations, there is nothing to characterize the performance against.<sup id="fnref:additional_runs" role="doc-noteref"><a href="#fn:additional_runs" rel="footnote">8</a></sup> Additionally, we‚Äôre going to look at the numbers from the perspective of the <em>algorithm‚Äôs</em> performance only, rather than the performance of the Ruby code itself<sup id="fnref:time_t" role="doc-noteref"><a href="#fn:time_t" rel="footnote">9</a></sup> <sup id="fnref:ruby-performance" role="doc-noteref"><a href="#fn:ruby-performance" rel="footnote">10</a></sup></p>

<h3 id="log-data">Log Data</h3>

<div><div><pre><code><span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>28.744335</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:0,&#34;highest_fitness&#34;:0,&#34;elapsed_time&#34;:0.0,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>29.393945</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:0,&#34;highest_fitness&#34;:45.43454105775939,&#34;elapsed_time&#34;:0.65,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>29.422413</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:0,&#34;highest_fitness&#34;:73.14234456163621,&#34;elapsed_time&#34;:0.68,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>29.702998</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:0,&#34;highest_fitness&#34;:75.73263190998411,&#34;elapsed_time&#34;:0.96,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>29.775709</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:0,&#34;highest_fitness&#34;:78.16397715764293,&#34;elapsed_time&#34;:1.03,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>29.990462</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:1,&#34;highest_fitness&#34;:78.16397715764293,&#34;elapsed_time&#34;:1.25,&#34;last_fitness_increase&#34;:0}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>30.146199</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:1,&#34;highest_fitness&#34;:85.22354925417734,&#34;elapsed_time&#34;:1.4,&#34;last_fitness_increase&#34;:1}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>30.543062</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:2,&#34;highest_fitness&#34;:85.22354925417734,&#34;elapsed_time&#34;:1.8,&#34;last_fitness_increase&#34;:1}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>30.711047</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:2,&#34;highest_fitness&#34;:95.88177285281498,&#34;elapsed_time&#34;:1.97,&#34;last_fitness_increase&#34;:2}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>31.090201</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:3,&#34;highest_fitness&#34;:95.88177285281498,&#34;elapsed_time&#34;:2.35,&#34;last_fitness_increase&#34;:2}</span>
<span>I</span><span>,</span> <span>[</span><span>2023</span><span>-</span><span>08</span><span>-</span><span>04</span><span>T19</span><span>:</span><span>48</span><span>:</span><span>31.405858</span> <span>#83090]  INFO -- : {&#34;id&#34;:&#34;869b3cc4-b37b-47ff-8beb-602aaa52c48f&#34;,&#34;generation_count&#34;:3,&#34;highest_fitness&#34;:100.92915163430119,&#34;elapsed_time&#34;:2.66,&#34;last_fitness_increase&#34;:3}</span>
</code></pre></div></div>

<p>Using the logs as a data source, let‚Äôs start by looking at a plot of the highest fitness score of any population over time. The fitness was determined by the inverse of the normalized mean error between the target image and the image generated from the member, squared. The higher the fitness, the better the member approximates the target image.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/highest_fitness_over_time.png"/></p><figcaption>Fitness of the fittest member of the population over time.</figcaption>
</div>

<p>We can see that the fitness of the fittest member of each population trends heavily positive over time; somewhat linearly but with a steeper slope at the beginning. This is to be expected because the algorithm starts with a lot to gain from its initial, somewhat random, initial state, and then spends time improving on better and better results.</p>

<p>We can also see that the the trend is not monotonically increasing, i.e. it does not always increase from one time step (generation) to the next. This is because the algorithm is not guaranteed to find a better solution in each generation.</p>

<p>We can visualize this by plotting the change in highest fitness over time, which I called <em>velocity</em>, but can also be considered <em>efficiency</em>.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/highest_fitness_and_fitness_growth_over_generations.png"/></p><figcaption>Velocity of the fittest member of the population over time.</figcaption>
</div>

<p>Here, we can see a lot of zero-efficiency/zero-velocity generations, where the fitness of the fittest member of the population did not change from the previous generation, specifically after about the 1000th generation. This shows us in another way that the algorithm is converging on a solution.</p>

<p>In fact, we could this metric to improve our end condition function, i.e. stop the algorithm when the efficiency drops below a certain threshold, rather than blindly after a certain number generations or a particular fitness score. We can also use efficiency to compare the performance of different configurations.</p>

<p>That said, convergence on a solution doesn‚Äôt always mean that the solution is the best solution to be found, just that it‚Äôs the best so far. We should be careful not to prematurely stop the algorithm. For example, at around generation 4500, we see another significant spike in efficiency even after many hundreds of generations with little-or-no improvement.</p>

<h3 id="image-data">Image Data</h3>

<p>Subjectively, I thought that there was little to be gained after generation 2000, but based on the data from the logs, we know that the algorithm continued to find fitter members, almost linearly! Is generation 6198, with a fitness score of <code>2857.08</code>, really <em><code>68%</code> better</em> than generation 2194 with a fitness score of <code>1700.74</code>?</p>

<p>What does ‚Äú68% better‚Äù <em>look</em> like?</p>

<p>Let‚Äôs start by taking a look at the error across individual pixels. If we remember back to our fitness function, we know that the fitness score was determined by the mean error of each pixel, i.e. how far off the grayscale value of each pixel was from the target image. We can visualize this by plotting the grayscale value of a few random pixel over time.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/grayscale_value_of_random_pixels.png"/></p><figcaption>Five random pixels&#39; grayscale values over time</figcaption>
</div>

<p>Here, we‚Äôre plotting the same five pixels from each member as they journey towards their target (indicated by the dashed lines) over each generation. We can observe that these pixels remain relatively stable after just a few hundred generations, and even more so after about 2500 generations. We can also notice that while some pixels hit their target dead on, others get farther away over time.</p>

<p>Interestingly, we can see some pixels correlate to the global trends we saw in the log data earlier: pixel 4 makes a significant improvement around generation 2500, and pixel 1 makes a significant improvement around generation 4500.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/grayscale_value_of_random_neighboring_pixels.png"/></p><figcaption>10 random neighboring pixels&#39; grayscale values over time moving towards grayscale 46</figcaption>
</div>

<p>We see a similar story when we look at 10 pixels near the center of the image that are all moving towards the same grayscale value. Looking at neighboring pixels is interesting because the algorithm is evolving the population by moving the vertices of triangles around, and therefore, the grayscale values of neighboring pixels are likely to be correlated.</p>

<p>Again, we can see that the pixels stabilize after about 250 generations, even more so after around after 2500. And, we also clearly see the correlation to the large spike around generation 4500 that we saw in the log data. It appears that these pixels were somewhat stuck for over 1000 generations, and then suddenly jumped to their target grayscale value. Curiously, we can also see a divergence after 5500 generations, even though the overall fitness score continued to increase‚Ä¶</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/member_differences.png"/></p><figcaption>The differences between the target image and generations 0000, 0120, 2194, and 6198. Black pixels mean they&#39;re equal.</figcaption>
</div>

<p>If we render the differences between the target image and a sample of generations, we get the images above. In these images, the darker the pixel, the closer the grayscale value of the pixel is to the target image.</p>

<p>This is a good way to visualize our fitness function as the algorithm is essentially trying to increase the number of black pixels and decrease the number of white pixels. We can see that the differences are, in fact, decreasing over time, but it‚Äôs still hard to see the 68% difference between generations 2194 and 6198.</p>

<div>
  <p><img src="https://thomascountz.com/assets/images/low_poly_image_generation/diff_gen-6198_gen-2194.png"/></p><figcaption>The difference between generations 2194 and 6198.</figcaption>
</div>

<p>If we look at the <em>difference of the differences</em> between generations 2194 and 6198, we see mostly dark colored pixels, indicating that the differences are small, and perhaps nearly imperceptible.</p>

<p>This is what ‚Äú68% better‚Äù looks like!</p>

<p>Despite all the math and theory, throughout this exploration, we have aimed the power of evolutionary algorithms towards scratching the subjective search space surface of creativity and art. Algorithmic processes can produce results that are not only fascinating from a technical standpoint but also visually (and philosophically) compelling. At the end of analyzing our algorithm‚Äôs ability to near its target, we are left to contemplate how well the resulting image captures our aesthics and creative vision.</p>



<p>Crafting a low-poly image representation is but one example of the myriad applications of evolutionary algorithms. The <a href="https://github.com/Thomascountz/petri_dish/tree/main/examples"><code>/examples</code> directory within the Petri Dish repository</a> showcases additional uses, including tackling the <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Travelling Salesperson Problem</a> and a more straightforward task of text generation.</p>

<p>Despite the diverse applications, evolutionary algorithms generally follow a uniform framework, as discussed in <a href="#putting-it-together">Putting it Together</a>. Interestingly, many of the design considerations we covered in this blog post are even more broadly applicable to the field of data engineering.</p>

<p>If you‚Äôre intersted in exploring the use of genetic algorithms for creative purposes, I can recommend:</p>

<ul>
  <li>‚ÄúThe Nature of Code‚Äù by Daniel Shiffman, particularly the chapters on evolutionary algorithms.</li>
  <li>‚ÄúGenerative Art‚Äù by Matt Pearson, which discusses the principles of algorithmic art creation.</li>
  <li>The <a href="https://processing.org/">Processing</a> community, which is rich with examples of generative art and creative coding.</li>
</ul>

<p>And of course, feel free to checkout the code for <a href="https://github.com/Thomascountz/petri_dish/">Petri Dish</a> on Github.</p>




  <span>
    <time datetime="2023-07-30T00:00:00+00:00">July 30, 2023</time> ¬∑ 
    <a href="https://thomascountz.com/tag/ruby">ruby</a>, 
    <a href="https://thomascountz.com/tag/generative%20ai">generative ai</a>, 
    <a href="https://thomascountz.com/tag/machine%20learning">machine learning</a>
  </span>
</section>


    </div></div>
  </body>
</html>
