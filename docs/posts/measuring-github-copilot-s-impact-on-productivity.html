<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cacm.acm.org/research/measuring-github-copilots-impact-on-productivity/">Original</a>
    <h1>Measuring GitHub Copilot&#39;s impact on productivity</h1>
    
    <div id="readability-page-1" class="page"><div lang="en"><section id="sec1"><p id="p-1">Code-completion systems offering suggestions to a developer in their integrated development environment (IDE) have become the most frequently used kind of programmer assistance.<sup><a href="#bib1" data-jats-ref-type="bibr" data-jats-rid="bib1">1</a></sup> When generating whole snippets of code, they typically use a large language model (LLM) to predict what the user might type next (the completion) from the context of what they are working on at the moment (the prompt).<sup><a href="#bib2" data-jats-ref-type="bibr" data-jats-rid="bib2">2</a></sup> This system allows for completions at any position in the code, often spanning multiple lines at once.</p><div><h2>Key Insights</h2><ul data-jats-list-type="bullet"><li><p id="p-2">AI pair-programming tools such as GitHub Copilot have a big impact on developer productivity. This holds for developers of all skill levels, with junior developers seeing the largest gains.</p></li><li><p id="p-3">The reported benefits of receiving AI suggestions while coding span the full range of typically investigated aspects of productivity, such as task time, product quality, cognitive load, enjoyment, and learning.</p></li><li><p id="p-4">Perceived productivity gains are reflected in objective measurements of developer activity.</p></li><li><p id="p-5">While suggestion correctness is important, the driving factor for these improvements appears to be not correctness as such, but whether the suggestions are useful as a starting point for further development.</p></li></ul></div><p id="p-6">Potential benefits of generating large sections of code automatically are huge, but evaluating these systems is challenging. Offline evaluation, where the system is shown a partial snippet of code and then asked to complete it, is difficult not least because for longer completions there are many acceptable alternatives and no straightforward mechanism for labeling them automatically.<sup><a href="#bib5" data-jats-ref-type="bibr" data-jats-rid="bib5">5</a></sup> An additional step taken by some researchers<sup><a href="#bib3" data-jats-ref-type="bibr" data-jats-rid="bib3">3</a></sup><sup>,</sup><sup><a href="#bib21" data-jats-ref-type="bibr" data-jats-rid="bib21">21</a></sup><sup>,</sup><sup><a href="#bib29" data-jats-ref-type="bibr" data-jats-rid="bib29">29</a></sup> is to use online evaluation and track the frequency of real users accepting suggestions, assuming that the more contributions a system makes to the developer’s code, the higher its benefit. The validity of this assumption is not obvious when considering issues such as whether two short completions are more valuable than one long one, or whether reviewing suggestions can be detrimental to programming flow.</p><p id="p-7">Code completion in IDEs using language models was first proposed in Hindle et al.,<sup><a href="#bib9" data-jats-ref-type="bibr" data-jats-rid="bib9">9</a></sup> and today neural synthesis tools such as <a href="https://www.copilot.com/" data-jats-ext-link-type="uri">GitHub Copilot</a>, <a href="https://aws.amazon.com/codewhisperer/" data-jats-ext-link-type="uri">CodeWhisperer</a>, and <a href="https://tabnine.com/" data-jats-ext-link-type="uri">TabNine</a> suggest code snippets within an IDE with the explicitly stated intention to increase a user’s productivity. Developer productivity has many aspects, and a recent study has shown that tools like these are helpful in ways that are only partially reflected by measures such as completion times for standardized tasks.<sup><a href="#bib23" data-jats-ref-type="bibr" data-jats-rid="bib23">23</a></sup><sup>,</sup><sup><a href="#FNa" data-jats-rid="FNa" data-jats-ref-type="fn">a</a></sup> Alternatively, we can leverage the developers themselves as expert assessors of their own productivity. This meshes well with current thinking in software engineering research suggesting measuring productivity on multiple dimensions and using self-reported data.<sup><a href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6">6</a></sup> Thus we focus on studying <i>perceived</i> productivity.</p><p id="p-8">Here, we investigate whether usage measurements of developer interactions with GitHub Copilot can predict perceived productivity as reported by developers. We analyze <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>2</mn><mo>,</mo><mn>631</mn></mrow></math></span> survey responses from developers using GitHub Copilot and match their responses to measurements collected from the IDE. We consider acceptance counts and more detailed measures of contribution, such as the amount of code contributed by GitHub Copilot and persistence of accepted completions in the code. <b>We find that acceptance rate of shown suggestions is a better predictor of perceived productivity than the alternative measures</b>. We also find that acceptance rate varies significantly over our developer population as well as over time, and present a deeper dive into some of these variations.</p><p id="p-9">Our results support the principle that acceptance rate can be used for coarse-grained monitoring of the performance of a neural code synthesis system. This ratio of shown suggestions being accepted correlates better than more detailed measures of contribution. However, other approaches remain necessary for fine-grained investigation due to the many human factors involved.</p></section><section id="sec2"><h2>Background</h2><p id="p-10">Offline evaluation of code completion can have shortcomings even in tractable circumstances where completions can be labeled for correctness. For example, a study of <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>15</mn><mo>,</mo><mn>000</mn></mrow></math></span> completions by 66 developers in Visual Studio found significant differences between synthetic benchmarks used for model evaluation and real-world usage.<sup><a href="#bib7" data-jats-ref-type="bibr" data-jats-rid="bib7">7</a></sup> The evaluation of context-aware API completion for Visual Studio IntelliCode considered Recall@5—the proportion of completions for which the correct method call was in the top five suggestions. This metric fell from <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>90</mn><mo>%</mo></mrow></math></span> in offline evaluation to <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>70</mn><mo>%</mo></mrow></math></span> when used online.<sup><a href="#bib21" data-jats-ref-type="bibr" data-jats-rid="bib21">21</a></sup></p><figure id="F1" data-jats-position="float"><figcaption><figure id="attachment_751231" aria-describedby="caption-attachment-751231"><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/02/funnel_white.png" data-type="image" data-caption="" href="https://cacm.acm.org/wp-content/uploads/2024/02/funnel_white.png">
				<img fetchpriority="high" decoding="async" src="https://cacm.acm.org/wp-content/uploads/2024/02/funnel_white.png?w=720" alt="GitHub Copilot’s code completion funnel." width="720" height="480" srcset="https://cacm.acm.org/wp-content/uploads/2024/02/funnel_white.png 720w, https://cacm.acm.org/wp-content/uploads/2024/02/funnel_white.png?resize=300,200 300w" sizes="(max-width: 720px) 100vw, 720px"/>
			</a><figcaption id="caption-attachment-751231"><strong>Figure 1.  GitHub Copilot’s code completion funnel.</strong></figcaption></figure></figcaption></figure><blockquote data-jats-content-type="pull-quote"><p id="p-12">Offline evaluation of code completion can have shortcomings even in tractable circumstances.</p></blockquote><p id="p-13">Due to the diversity of potential solutions to a multi-line completion task, researchers have used software testing to evaluate the behavior of completions. Competitive programming sites have been used as a source of such data<sup><a href="#bib8" data-jats-ref-type="bibr" data-jats-rid="bib8">8</a></sup><sup>,</sup><sup><a href="#bib11" data-jats-ref-type="bibr" data-jats-rid="bib11">11</a></sup> as well as handwritten programming problems.<sup><a href="#bib5" data-jats-ref-type="bibr" data-jats-rid="bib5">5</a></sup> Yet, it is unclear how well performance on programming competition data generalizes to interactive development in an IDE.</p><blockquote data-jats-content-type="pull-quote"><p id="p-14">It is unclear how well performance on programming competition data generalizes to interactive development in an IDE.</p></blockquote><p id="p-15">In this work, we define acceptance rate as the fraction of completions shown to the developer that are subsequently accepted for inclusion in the source file. The IntelliCode Compose system uses the term <i>click through rate</i> (CTR) for this and reports a value of <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>10</mn><mo>%</mo></mrow></math></span> in online trials.<sup><a href="#bib20" data-jats-ref-type="bibr" data-jats-rid="bib20">20</a></sup> An alternative measure is that of <i>daily completions accepted per user</i> (DCPU) for which a value of around 20 has been reported.<sup><a href="#bib3" data-jats-ref-type="bibr" data-jats-rid="bib3">3</a></sup><sup>,</sup><sup><a href="#bib29" data-jats-ref-type="bibr" data-jats-rid="bib29">29</a></sup> To calculate acceptance rate one must, of course, normalize DCPU by the time spent coding each day. For context, in our study GitHub Copilot has an acceptance rate of <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>27</mn><mo>%</mo></mrow></math></span> and a mean DCPU in excess of 312 (See Figure 1).<sup><a href="#FNb" data-jats-rid="FNb" data-jats-ref-type="fn">b</a></sup> These differences are presumably due to differences in the kinds of completion offered, or perhaps to user-interface choices. We discuss later how developer objectives, choice of programming language, and even time of day seem to affect our data. Such discrepancies highlight the difficulty in using acceptance rate to understand the value of a system.</p><p id="p-16">There is some evidence that acceptance rate (and indeed correctness) might not tell the whole story. One survey of developers considered the use of AI to support translation between programming languages and found indications that developers tolerated, and in some cases valued, erroneous suggestions from the model.<sup><a href="#bib26" data-jats-ref-type="bibr" data-jats-rid="bib26">26</a></sup></p><blockquote data-jats-content-type="pull-quote"><p id="p-17">There is some evidence that acceptance rate (and indeed correctness) might not tell the whole story.</p></blockquote><p id="p-18">Measuring developer productivity through activity counts over time (a typical definition of productivity borrowed from economics) disregards the complexity of software development as they account for only a subset of developer outputs. A more holistic picture is formed by measuring <i>perceived</i> productivity through self-reported data across various dimensions<sup><a href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6">6</a></sup> and supplementing it with automatically measured data.<sup><a href="#bib4" data-jats-ref-type="bibr" data-jats-rid="bib4">4</a></sup> We used the SPACE framework<sup><a href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6">6</a></sup> to design a survey that captures self-reported productivity and paired the self-reported data with usage telemetry.</p><p id="p-19">To the best of our knowledge, this is the first study of code suggestion tools establishing a clear link between usage measurements and developer productivity or happiness. A previous study comparing GitHub Copilot against IntelliCode with 25 participants found no significant correlation between task completion times and survey responses.<sup><a href="#bib22" data-jats-ref-type="bibr" data-jats-rid="bib22">22</a></sup></p><figure id="F2" data-jats-position="float"><div><figure id="attachment_751234" aria-describedby="caption-attachment-751234"><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/02/survey_demographics_white.png" data-type="image" data-caption="" href="https://cacm.acm.org/wp-content/uploads/2024/02/survey_demographics_white.png">
				<img decoding="async" src="https://cacm.acm.org/wp-content/uploads/2024/02/survey_demographics_white.png?w=720" alt="Demographic composition of survey respondents." width="720" height="560" srcset="https://cacm.acm.org/wp-content/uploads/2024/02/survey_demographics_white.png 720w, https://cacm.acm.org/wp-content/uploads/2024/02/survey_demographics_white.png?resize=300,233 300w" sizes="(max-width: 720px) 100vw, 720px"/>
			</a><figcaption id="caption-attachment-751234"><strong>Figure 2.  Demographic composition of survey respondents.</strong></figcaption></figure></div><figcaption></figcaption></figure></section><section id="sec3"><h2>Data and Methodology</h2><section id="sec4"><h3>Usage measurements.</h3><p id="p-21" data-jats-content-type="inline-heading">GitHub Copilot provides code completions using OpenAI language models. It runs within the IDE and at appropriate points sends a completion request to a cloud-hosted instance of the neural model. GitHub Copilot can generate completions at arbitrary points in code rather than, for example, only being triggered when a developer types a period for invoking a method on an object. A variety of rules determine when to request a completion, when to abandon requests if the developer has moved on before the model is ready with a completion, and how much of the response from the model to surface as a completion.</p><p id="p-22">As stated in our terms of usage,<sup><a href="#FNc" data-jats-rid="FNc" data-jats-ref-type="fn">c</a></sup> the GitHub Copilot IDE extension records the events shown in Table <a href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a> for all users. We make usage measurements for each developer by counting those events.</p><figure id="T1" data-jats-position="float"><p><strong><span>Table 1. </span> <span>Developer usage events collected by GitHub Copilot.</span></strong></p><div><table data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col/> <col/> </colgroup><tbody><tr><td><code>opportunity</code></td><td>A heuristic-based determination by the IDE and the plug-in that a completion might be appropriate at this point in the code (for example, the cursor is not in the middle of a word)</td></tr><tr><td><code>shown</code></td><td>Completion shown to the developer</td></tr><tr><td><code>accepted</code></td><td>Completion accepted by the developer for inclusion in the source file</td></tr><tr><td><code>accepted_char</code></td><td>The number of characters in an accepted completion</td></tr><tr><td><code>mostly_unchanged_X</code></td><td>Completion persisting in source code with limited modifications (Levenshtein distance less than 33%) after X seconds, where we consider durations of 30, 120, 300, and 600 seconds</td></tr><tr><td><code>unchanged_X</code></td><td>Completion persisting in source code unmodified after X seconds.</td></tr><tr><td>(active) <code>hour</code></td><td>An hour during which the developer was using their IDE with the plug-in active</td></tr></tbody></table></div></figure><p id="p-24">Our measures of persistence go further than existing work, which stops at acceptance. The intuition here is that a completion which is accepted into the source file but then subsequently turns out to be incorrect can be considered to have wasted developer time both in reviewing it and then having to go back and delete it. We also record <i>mostly</i> unchanged completions: A large completion requiring a few edits might still be a positive contribution. It is not clear how long after acceptance one should confirm persistence, so we consider a range of options.</p><p id="p-25">The events pertaining to completions form a funnel which we show quantitatively in Table <a href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a>. We include a summary of all data in Appendix A.<sup><a href="#FNd" data-jats-rid="FNd" data-jats-ref-type="fn">d</a></sup> (<i>All appendices for this article can be found online at</i> <a href="https://dl.acm.org/doi/10.1145/3633453" data-jats-ext-link-type="uri"><i>https://dl.acm.org/doi/10.1145/3633453</i></a>).</p><p id="p-26">We normalize these measures against each other and write <code>X_per_Y</code> to indicate we have normalized metric <code>X</code> by metric <code>Y</code>. For example: <code>accepted_per_hour</code> is calculated as the total number of <code>accepted</code> events divided by the total number of (active) <code>hour</code> events.</p><p id="p-27">Table <a href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a> defines the core set of metrics which we feel have a natural interpretation in this context. We note that there are other alternatives and we incorporate these in our discussion where relevant.</p><figure id="T2" data-jats-position="float"><p><strong><span>Table 2. </span> <span>The core set of measurements considered in this paper.</span></strong></p><div><table data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col/> <col/> </colgroup><thead><tr><th>Natural name</th><th>Explanation</th></tr></thead><tbody><tr><td>Shown rate</td><td>Ratio of completion opportunities that resulted in a completion being shown to the user</td></tr><tr><td>Acceptance rate</td><td>Ratio of shown completions accepted by the user</td></tr><tr><td>Persistence rate</td><td>Ratio of accepted completions unchanged after 30, 120, 300, and 600 seconds</td></tr><tr><td>Fuzzy persistence rate</td><td>Ratio of accepted completions mostly unchanged after 30, 120, 300, and 600 seconds</td></tr><tr><td>Efficiency</td><td>Ratio of completion opportunities that resulted in a completion accepted and unchanged after 30, 120, 300, and 600 seconds</td></tr><tr><td>Contribution speed</td><td>Number of characters in accepted completions per distinct, active hour</td></tr><tr><td>Acceptance frequency</td><td>Number of accepted completions per distinct, active hour</td></tr><tr><td>Persistence frequency</td><td>Number of unchanged completions per distinct, active hour</td></tr><tr><td>Total volume</td><td>Total number of completions shown to the user</td></tr><tr><td>Loquaciousness</td><td>Number of shown completions per distinct, active hour</td></tr><tr><td>Eagerness</td><td>Number of shown completions per opportunity</td></tr></tbody></table></div></figure></section><section id="sec5"><h3>Productivity survey.</h3><p id="p-29" data-jats-content-type="inline-heading">To understand users’ experience with GitHub Copilot, we emailed a link to an online survey to <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>17</mn><mo>,</mo><mn>420</mn></mrow></math></span> users. These were participants of the unpaid technical preview using GitHub Copilot with their everyday programming tasks. The only selection criterion was having previously opted in to receive communications. A vast majority of survey users (more than 80%) filled out the survey within the first two days, on or before February 12, 2022. We therefore focus on data from the four-week period leading up to this point (“the study period”). We received a total of 2,047 responses we could match to usage data from the study period, the earliest on Feb. 10, 2022 and the latest on Mar. 6, 2022.</p><p id="p-30">The survey contained multiple-choice questions regarding demographic information (see Figure <a href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>) and Likert-style questions about different aspects of productivity, which were randomized in their order of appearance to the user. Figure <a href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a> shows the demographic composition of our respondents. We note the significant proportion of professional programmers who responded.</p><p id="p-31">The SPACE framework<sup><a href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6">6</a></sup> defines 5 dimensions of productivity: <b>S</b>atisfaction and well-being, <b>P</b>erformance, <b>A</b>ctivity, <b>C</b>ommunication and collaboration, and <b>E</b>fficiency and flow. We use four of these (S,P,C,E) since self reporting on (A) is generally considered inferior to direct measurement. We included 11 statements covering these four dimensions in addition to a single statement: “I am more productive when using GitHub Copilot.” For each self-reported productivity measure, we encoded its five ordinal response values to numeric labels (1 = Strongly Disagree, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>…</mo></math></span>, 5 = Strongly Agree). We include the full list of questions and their coding to the SPACE framework in Appendix C. For more information on the SPACE framework and how the empirical software engineering community has been discussing developer productivity, please see the following section.</p><p id="p-32">Early in our analysis, we found that the usage metrics we describe in the Usage Measurements section corresponded similarly to each of the measured dimensions of productivity, and in turn these dimensions were highly correlated to each other (Figure <a href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>). We therefore added an aggregate productivity score calculated as the mean of all 12 individual measures (excluding skipped questions). This serves as a rough proxy for the much more complex concept of productivity, facilitating recognition of overall trends, which may be less discernible on individual variables due to higher statistical variation.</p><figure id="F3" data-jats-position="float"><div><figure id="attachment_751232" aria-describedby="caption-attachment-751232"><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png" data-type="image" data-caption="" href="https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png">
				<img decoding="async" src="https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png?w=1020" alt="Correlation between metrics. Metrics are ordered by similarity based on distance in the correlation matrix, except for manually fixing the aggregate productivity and acceptance rate at the end for visibility." width="1020" height="960" srcset="https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png 1020w, https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png?resize=300,282 300w, https://cacm.acm.org/wp-content/uploads/2024/02/heatmap_white.png?resize=768,723 768w" sizes="(max-width: 1020px) 100vw, 1020px"/>
			</a><figcaption id="caption-attachment-751232"><strong>Figure 3.  Correlation between metrics. Metrics are ordered by similarity based on distance in the correlation matrix, except for manually fixing the aggregate productivity and acceptance rate at the end for visibility.</strong></figcaption></figure></div><figcaption></figcaption></figure><p id="p-34">The full dataset of these aggregate productivity scores together with the usage measurements considered in this article is available at <a href="https://github.com/wunderalbert/prod-neural-materials" data-jats-ext-link-type="uri">https://github.com/wunderalbert/prod-neural-materials</a>.</p><p id="p-35">Given it has been impossible to produce a unified definition or metric(s) for developer productivity, there have been attempts to synthesize the factors that impact productivity to describe it holistically, include various relevant factors, and treat developer productivity as a composite measure<sup><a href="#bib17" data-jats-ref-type="bibr" data-jats-rid="bib17">17</a></sup><sup>,</sup><sup><a href="#bib19" data-jats-ref-type="bibr" data-jats-rid="bib19">19</a></sup><sup>,</sup><sup><a href="#bib24" data-jats-ref-type="bibr" data-jats-rid="bib24">24</a></sup> In addition, organizations often use their own multidimensional frameworks to operationalize productivity, which reflects their engineering goals—for example, Google uses the QUANTS framework, with 5 components of productivity.<sup><a href="#bib27" data-jats-ref-type="bibr" data-jats-rid="bib27">27</a></sup> In this article, we use the SPACE framework,<sup><a href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6">6</a></sup> which builds on synthesis of extensive and diverse literature by expert researchers and practitioners in the area of developer productivity.</p><p id="p-36">SPACE is an acronym of the five dimensions of productivity:</p><ul data-jats-list-type="bullet"><li><p id="p-37"><b>S (Satisfaction and well being)</b>: This dimension is meant to reflect developers’ fulfillment with the work they do and the tools they use, as well as how healthy and happy they are with the work they do. This dimension reflects some of the easy-to-overlook trade-offs involved when looking exclusively at velocity acceleration (for example, when we target faster turnaround of code reviews without considering workload impact or burnout for developers).</p></li><li><p id="p-38"><b>P (Performance)</b>: This dimension aims to quantify outcomes rather than output. Example metrics that capture performance relate to quality and reliability, as well as further-removed metrics such as customer adoption or satisfaction.</p></li><li><p id="p-39"><b>A (Activity)</b>: This is the count of outputs—for example, the number of pull requests closed by a developer. As a result this is a dimension that is best quantified via system data. Given the variety of developers’ activities as part of their work, it is important that the activity dimension accounts for more than coding activity—for instance, writing documentation, creating design specs, and so on.</p></li><li><p id="p-40"><b>C (Communication and collaboration)</b>: This dimension aims to capture that modern software development happens in teams and is, therefore, impacted by the discoverability of documentation or the speed of answering questions, or the onboarding time and process of new team members.</p></li><li><p id="p-41"><b>E (Efficiency and flow)</b>: This dimension reflects the ability to complete work or make progress with little interruption or delay. It is important to note that delays and interruptions can be caused either by systems or humans, and it is best to monitor both self-reported and observed measurements—for example, use self-reports of the ability to do uninterrupted work, as well as measure wait time in engineering systems).</p></li></ul></section></section><section id="sec6"><h2>What Drives Perceived Productivity?</h2><p id="p-47">To examine the relationship between objective measurements of user behavior and self-reported perceptions of productivity, we used our set of core usage measurements (Table <a href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a>). We then calculated Pearson’s R correlation coefficient and the corresponding p-value of the F-statistic between each pair of usage measurement and perceived productivity metric. We also computed a PLS regression from all usage measurements jointly.</p><p id="p-48">We summarize these results in Figure <a href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>, showing the correlation coefficients between all measures and survey questions. The full table of all results is included in Appendix B, available online.</p><p id="p-49"><b>We find acceptance rate (</b>accepted_per_shown<b>) most positively predicts users’ perception of productivity, although, given the confounding and human factors, there is still notable unexplained variance.</b></p><p id="p-50">Of all usage measurements, acceptance rate correlates best with aggregate productivity (<span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>24</mn></mrow></math></span>, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>0001</mn></mrow></math></span>). This measurement is also the best performing for at least one survey question in each of the SPACE dimensions. This correlation is high confidence but leaves considerable unexplained variance. Later, we explore improvements from combining multiple usage measurements together.</p><p id="p-51">Looking at the more detailed metrics around persistence, we see that it is generally better over shorter time periods than over longer periods. This is intuitive in the sense that shorter periods move the measure closer to acceptance rate. We also expect that at some point after accepting the completion it becomes simply part of the code and so any changes (or not) after that point will not be attributed to GitHub Copilot. All persistence measures were less well correlated than acceptance rate.</p><p id="p-52">To assess the different metrics in a single model, we ran a regression using projection on latent structures (PLS). The choice of PLS, which captures the common variation of these variables as is linearly connected to the aggregate productivity,<sup><a href="#bib28" data-jats-ref-type="bibr" data-jats-rid="bib28">28</a></sup> is due to the high collinearity of the single metrics. The first component, to which every metric under consideration contributes positively, explains <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>43</mn><mo>.</mo><mn>2</mn><mo>%</mo></mrow></math></span> of the variance. The second component captures the acceptance rate/change rate dichotomy; it explains a further <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>13</mn><mo>.</mo><mn>1</mn><mo>%</mo></mrow></math></span>. Both draw most strongly from acceptance rate.</p><p id="p-53">This strongly points to acceptance rate being the most immediate indicator of perceived productivity, although it is beneficial to combine with others to get a fuller picture.</p></section><section id="sec7"><h2>Experience</h2><p id="p-54">To understand how different types of developers interact with Copilot, our survey asked respondents to self-report their level of experience in two ways:</p><ul data-jats-list-type="bullet"><li><p id="p-55">“Think of the language you have used the most with Copilot. How proficient are you in that language?” with options “Beginner”, “Intermediate”, and “Advanced”.</p></li><li><p id="p-56">“Which best describes your programming experience?” with options starting with “Student” and ranging from “0-2 years” to “16+ years” in two year intervals.</p></li></ul><p id="p-57">We compute correlations with productivity metrics for both experience variables and include these two variables as covariates in a multivariate regression analysis. We find that both are negatively correlated with our aggregate productivity measure (proficiency: <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><mo>–</mo><mn>0</mn><mo>.</mo><mn>095</mn></mrow></math></span>, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>0001</mn></mrow></math></span>; years of experience: <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><mo>–</mo><mn>0</mn><mo>.</mo><mn>161</mn></mrow></math></span>, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>0001</mn></mrow></math></span>). However, in multivariate regressions predicting productivity from usage metrics while controlling for demographics, proficiency had a non-significant positive effect (<span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>c</mi><mi>o</mi><mi>e</mi><mi>f</mi><mi>f</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>021</mn></mrow></math></span>, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>213</mn></mrow></math></span>), while years of experience had a non-significant negative effect (<span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>c</mi><mi>o</mi><mi>e</mi><mi>f</mi><mi>f</mi><mo>=</mo><mo>–</mo><mn>0</mn><mo>.</mo><mn>032</mn></mrow></math></span>, <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>P</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>122</mn></mrow></math></span>).</p><p id="p-58">Looking further at individual measures of productivity, (Table <a href="#T3" data-jats-ref-type="table" data-jats-rid="T3">3</a>) we find that both language proficiency and years of experience negatively predict developers agreeing that Copilot helps them write better code. However, proficiency positively predicts developers agreeing that Copilot helps them stay in the flow, focus on more satisfying work, spend less effort on repetitive tasks, and perform repetitive tasks faster. Years of experience negatively predicts developers feeling less frustrated in coding sessions and perform repetitive tasks faster while using Copilot, but positively predicts developers making progress faster when working in an unfamiliar language. These findings suggest that experienced developers who are already highly skilled are less likely to write better code with Copilot, but Copilot can assist their productivity in other ways particularly when engaging with new areas and automating routine work.</p><blockquote data-jats-content-type="pull-quote"><p id="p-59">Experienced developers who are already highly skilled are less likely to write better code with Copilot, but Copilot can assist their productivity in other ways.</p></blockquote><figure id="T3" data-jats-position="float"><p><strong><span><span>Table 3.</span> Effects of experience on facets of productivity where result of linear regression was a statistically significant covariate.</span></strong></p><div><table data-jats-frame="hsides" data-jats-rules="rows"><thead><tr><th> </th><th><b>productivity measure</b></th><th><b>coeff</b></th></tr></thead><tbody><tr><td>proficiency</td><td><code>better_code</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mo>–</mo> <mn>0</mn> <mo>.</mo> <msup> <mn>061</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr><tr><td>proficiency</td><td><code>stay_in_flow</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>069</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr><tr><td>proficiency</td><td><code>focus_satisfying</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>067</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr><tr><td>proficiency</td><td><code>less_effort_repetitive</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>072</mn> <mrow> <mo>**</mo> </mrow> </msup> </mrow> </math> </span></td></tr><tr><td>proficiency</td><td><code>repetitive_faster</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>055</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td></tr><tr><td>years</td><td><code>better_code</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mo>–</mo> <mn>0</mn> <mo>.</mo> <msup> <mn>087</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr><tr><td>years</td><td><code>less_frustrated</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mo>–</mo> <mn>0</mn> <mo>.</mo> <msup> <mn>103</mn> <mrow> <mo>**</mo> </mrow> </msup> </mrow> </math> </span></td></tr><tr><td>years</td><td><code>repetitive_faster</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mo>–</mo> <mn>0</mn> <mo>.</mo> <msup> <mn>054</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr><tr><td>years</td><td><code>unfamiliar_progress</code></td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>081</mn> <mo>*</mo> </msup> </mrow> </math> </span></td></tr></tbody></table></div></figure><figure id="T4" data-jats-position="float"><p><strong><span>Table 4. </span> <span>Correlations of acceptance rate with aggregate productivity broken down by subgroup.</span></strong></p><div><table data-jats-frame="hsides" data-jats-rules="rows"><thead><tr><th><b>subgroup</b></th><th><b>coeff</b></th><th><b>n</b></th></tr></thead><tbody><tr><td>none</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>135</mn> <mo>*</mo> </msup> </mrow> </math> </span></td><td>344</td></tr><tr><td><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span> 2y</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>178</mn> <mrow> <mo>**</mo> </mrow> </msup> </mrow> </math> </span></td><td>451</td></tr><tr><td>3 – 5 y</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>255</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>358</td></tr><tr><td>6 – 10 y</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>265</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>251</td></tr><tr><td>11 – 15 y</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>171</mn> <mo>*</mo> </msup> </mrow> </math> </span></td><td>162</td></tr><tr><td><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≥</mo></math></span> 16 y</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>153</mn> <mo>*</mo> </msup> </mrow> </math> </span></td><td>214</td></tr><tr><td>JavaScript</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>227</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>1184</td></tr><tr><td>TypeScript</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>165</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>654</td></tr><tr><td>Python</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>172</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>716</td></tr><tr><td>other</td><td><span> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mn>0</mn> <mo>.</mo> <msup> <mn>178</mn> <mrow> <mo>***</mo> </mrow> </msup> </mrow> </math> </span></td><td>1829</td></tr></tbody></table></div></figure><p id="p-63">Junior developers not only report higher productivity gains; they also tend to accept more suggestions. However, the connection observed in section “What Drives Perceived Productivity” is not solely due to differing experience levels. In fact, the connection persists in every single experience group, as shown in Figure <a href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5</a>.</p><figure id="F4" data-jats-position="float"><figcaption></figcaption></figure></section><section id="sec8"><h2>Variation over Time</h2><p id="p-66">Its connection to perceived productivity motivates a closer look at the acceptance rate and what factors influence it. Acceptance rate typically increases over the board when the model or underlying prompt-crafting techniques are improved. But even if these conditions are held constant (the study period did not see changes to either), there are more fine-grained temporal patterns emerging.</p><p id="p-67">For coherence of the cultural implications of time of day and weekdays, all data in this section was restricted to users from the U.S. (whether in the survey or not). We used the same time frame as for the investigation in the previous section. In the absence of more fine-grained geolocation, we used the same time zone to interpret timestamps and for day boundaries (Pacific Standard Time), recognizing that this will introduce some level of noise due to the inhomogeneity of U.S. time zones.</p><p id="p-68">Nevertheless, we observe strong regular patterns in overall acceptance rate (Figure <a href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6</a>). These lead us to distinguish three different time regimes, all of which are statistically significantly distinct at <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>p</mi><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>001</mn><mo>%</mo></mrow></math></span> (using bootstrap resampling):</p><figure id="F6" data-jats-position="float"><div><figure id="attachment_751236" aria-describedby="caption-attachment-751236"><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/02/patterns_white_2.png" data-type="image" data-caption="" href="https://cacm.acm.org/wp-content/uploads/2024/02/patterns_white_2.png">
				<img loading="lazy" decoding="async" src="https://cacm.acm.org/wp-content/uploads/2024/02/patterns_white_2.png?w=720" alt="Average acceptance rate during the week. Each point represents the average for a one-hour period, whereas the shaded ribbon shows the min-max variation during the observed four-week period." width="720" height="480" srcset="https://cacm.acm.org/wp-content/uploads/2024/02/patterns_white_2.png 720w, https://cacm.acm.org/wp-content/uploads/2024/02/patterns_white_2.png?resize=300,200 300w" sizes="(max-width: 720px) 100vw, 720px"/>
			</a><figcaption id="caption-attachment-751236"><strong>Figure 6.  Average acceptance rate during the week. Each point represents the average for a one-hour period, whereas the shaded ribbon shows the min-max variation during the observed four-week period.</strong></figcaption></figure></div></figure><ul data-jats-list-type="bullet"><li><p id="p-70">The weekend: Saturdays and Sundays, where the average acceptance rate is comparatively high at <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>23</mn><mo>.</mo><mn>5</mn><mo>%</mo></mrow></math></span>.</p></li><li><p id="p-71">Typical non-working hours during the week: evenings after 4:00 pm PST until mornings 7:00 am PST, where the average acceptance rate is also rather high at <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>23</mn><mo>%</mo></mrow></math></span>.</p></li><li><p id="p-72">Typical working hours during the week from 7:00 am PST to 4:00 pm PST, where the average acceptance rate is much lower at <span><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>21</mn><mo>.</mo><mn>2</mn><mo>%</mo></mrow></math></span>.</p></li></ul></section><section id="sec9"><h2>Conclusions</h2><p id="p-73">When we set out to connect the productivity benefit of GitHub Copilot to usage measurements from developer activity, we collected measurements about acceptance of completions in line with prior work, but also developed persistence metrics, which arguably capture sustained and direct impact on the resulting code. We were surprised to find acceptance rate (number of acceptances normalized by the number of shown completions) to be better correlated with reported productivity than our measures of persistence.</p><p id="p-74">In hindsight, this makes sense. Coding is not typing, and GitHub Copilot’s central value lies not in being the way the user enters most of their code. Instead, it lies in helping the user to make the best progress toward their goals. A suggestion that serves as a useful template to tinker with may be as good or better than a perfectly correct (but obvious) line of code that only saves the user a few keystrokes.</p><p id="p-75">This suggests that a narrow focus on the correctness of suggestions would not tell the whole story for these kinds of tooling. Instead one could view code suggestions inside an IDE to be more akin to a conversation. While chatbots such as ChatGPT are already used for programming tasks, they are explicitly structured as conversations. Here, we hypothesize that interactions with Copilot, which is not a chatbot, share many characteristics with natural-language conversations.</p><p id="p-76">We see anecdotal evidence of this in comments posted about GitHub Copilot online (see Appendix E for examples) in which users talk about sequences of interactions. A conversation turn in this context consists of the prompt in the completion request and the reply as the completion itself. The developer’s response to the completion arises from the subsequent changes which are incorporated in the next prompt to the model. There are clear programming parallels to factors such as specificity and repetition that have been identified to affect human judgements of conversation quality.<sup><a href="#bib18" data-jats-ref-type="bibr" data-jats-rid="bib18">18</a></sup> Researchers have already investigated the benefits of natural-language feedback to guide program synthesis,<sup><a href="#bib2" data-jats-ref-type="bibr" data-jats-rid="bib2">2</a></sup> so the conversational framing of coding completions is not a radical proposal. But neither is it one we have seen followed yet.</p></section></div></div>
  </body>
</html>
