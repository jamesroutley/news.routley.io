<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://royeisen.github.io/OverclockingLLMReasoning-paper/">Original</a>
    <h1>Overclocking LLM Reasoning: Monitoring and Controlling LLM Thinking Path Lengths</h1>
    
    <div id="readability-page-1" class="page"><div>
                <p>
                    This work investigates how large reasoning models internally track their thinking progress and how such processes can be monitored and controlled. We focus on reasoning models that explicitly segment their computations using <code>&lt;think&gt;</code> and <code>&lt;/think&gt;</code> tokens (e.g., DeepSeek-R1), allowing us to study the internal dynamics of the &#34;thinking phase.&#34;
                </p>

                <h3>1. Monitoring the Thinking Phase</h3>
                <p>
                    We hypothesize that hidden states encode a token&#39;s relative position within the thinking phase. To test this, we collect hidden representations from the final layer of the model for each token in a thinking trajectory $T = w_1w_2...w_N$. Each token is paired with a normalized position:
                </p>
                <p>
                    $$p_j^{(k)} = j / N_k$$
                </p>
                <p>
                    This creates a dataset $D = \{ (h_j^{(k)}, p_j^{(k)}) \}$, where $h \in \mathbb{R}^d$ is the hidden state and $p \in (0, 1]$ is the relative position. We learn a regression function:
                </p>
                <p>
                    $$\theta^* = \arg\min_\theta \sum (f_\theta(h) - p)^2$$
                </p>

                <p>
                    We compare a linear regressor (TPV: Thinking Progress Vector) with a 2-layer FFN and find no improvement from the latter, favoring the simpler TPV model. For improved temporal modeling, we also train a single-layer GRU on full token sequences:
                </p>
                <p>
                    $$D&#39; = \{ (h_1, ..., h_N), (p_1, ..., p_N) \}$$
                </p>
                <p>
                    The GRU outperforms TPV, especially in generalizing from MATH-500 to GSM8K in both fine-tuned and zero-shot setups.
                </p>

                <h3>2. Controlling the Thinking Phase</h3>
                <p>
                    To explore whether TPVs are causally involved in reasoning, we intervene on hidden states during decoding:
                </p>
                <p>
                    $$h^\alpha = h + \alpha\theta \quad \rightarrow \quad \theta^T h^\alpha = \theta^T h + \alpha||\theta||^2$$
                </p>
                <p>
                    This intervention occurs after attention layers to isolate its effect to a single token step. We refer to this manipulation as &#34;<strong>overclocking</strong>&#34; when $\alpha &gt; 0$. Empirically, overclocking results in more concise and decisive reasoning while maintaining correctness.
                </p>

                <h4>Findings</h4>
                <ul>
                    <li>Original trajectories often exhibit repetition and hesitation.</li>
                    <li>Overclocked outputs are shorter and more linear in progress prediction.</li>
                    <li>In some cases, the token count reduces by up to 6Ã— while yielding the same correct answer.</li>
                </ul>

                <h4>Conclusion</h4>
                <p>
                    These findings suggest that models internally track thinking progress and that this representation can be extracted and modified, opening doors for dynamic reasoning control and real-time interpretability.
                </p>
            </div></div>
  </body>
</html>
