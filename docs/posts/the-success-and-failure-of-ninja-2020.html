<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://neugierig.org/software/blog/2020/05/ninja.html">Original</a>
    <h1>The success and failure of Ninja (2020)</h1>
    
    <div id="readability-page-1" class="page"><div>



<p>Around nine years ago I published Ninja, a build system that is
mostly comparable to Make.  At the time <a href="https://neugierig.org/software/chromium/notes/2011/02/ninja.html">I was a bit embarrassed to
share my side
project</a>
but since then it has become widely popular.</p>
<p>I can&#39;t list all of the users off the top of my head anymore, but some
of the &#34;big&#34; projects that use Ninja include:</p>
<ul>
<li>Chrome, which eventually removed all of its non-Ninja builds;</li>
<li>Android, which uses it for some large component of the system that
I&#39;ve never quite understood;</li>
<li>all <a href="https://mesonbuild.com/">Meson</a> projects, which appears to
increasingly be the build system used in the free software world;</li>
<li>many other projects that that use Ninja with CMake (for one
random example, the <a href="https://github.com/apple/swift#system-requirements">build instructions for the Swift programming
language</a> tell you
to install Ninja).</li>
</ul>
<p>Ninja has been by far my most successful open source project,
depending on how you quantify success.  (Other projects of mine like
Chrome have more users, but I was responsible for only parts of
Chrome; Ninja also has had important contributions by collaborators
but it feels more like &#34;mine&#34;.)  I released Ninja in 2011, gave
ownership of the Ninja project away in 2014, and it has since been
passed on again to a third maintainer, so now that my part in the
story is pretty much over I here would like to reflect on what I
learned.</p>
<p>If I were to summarize what I learned in a single sentence, it would
be this: we talk about programming like it is about writing code, but
the code ends up being less important than the architecture, and the
architecture ends up being less important than social issues.</p>
<p>That is, as programmers we like to talk about problems as if they are
primarily technical — &#34;how do I optimize this loop to squeeze more
qps out of this service?&#34; — when in my experience the tech almost
always ends up secondary to bigger picture factors.  I have since seen
that same observation in other words stated by many others as
describing the journey from a &#34;junior&#34; to &#34;senior&#34; engineer which also
rings very true against my career, so I also hope in this
retrospective to give some insight into what that means.</p>
<h2>The tech</h2>
<p>Let&#39;s start by getting some technical details out of the way.</p>
<p>What Ninja specifically does is pretty simple; given a description of
the requirements, I&#39;d expect a competent undergrad, perhaps in a
systems course, to be able to bang out a basic version of it without
much help.  To summarize, the user gives Ninja a <code>ninja.build</code> file
which (omitting some details) contains all the commands you&#39;d like
Ninja to run, along with which files each command consumes and
produces.  Ninja loads this file, checks the modification timestamps
of the various files, and executes in parallel the commands needed to
bring everything up to date.  As compared to Make (which does pretty
much the same thing) Ninja provides <em>fewer</em> features in its input
build language, and is primarily structured around making the few
things it does very fast.</p>
<p>The few things Ninja does are: (1) parse and interpret that build
file; (2) check the modification times of its inputs; (3) execute the
needed commands.  The goal is to get to step 3 as fast as possible
even on huge (&gt;100k input files) projects, and doing so is a
collection of careful but small optimizations. For one small example,
Ninja is careful to map each input file path to a unique in-memory
object as early as possible, and then on it uses pointer comparisons
between those objects for testing path equality (interned strings,
effectively).  I wrote a chapter for the book &#34;The Performance of Open
Source Software&#34; about Ninja that tells some of the stories of the
lower level technical details of making that fast which <a href="https://www.aosabook.org/en/posa/ninja.html">you can read
online</a>.</p>
<p>Many people have done rewrites of Ninja over the years.  It&#39;s a small
enough project that it&#39;s fun to try implementing in your favorite
language.  For some examples,
<a href="https://github.com/apple/swift-llbuild">llbuild</a> and
<a href="https://shakebuild.com/">Shake</a> both support Ninja files as inputs,
and <a href="https://github.com/michaelforney/samurai">samurai</a> is a nearly
file-by-file reimplementation (with less code, but with fewer features
and no tests(!)). Ninja is pretty easy to implement for the fun 20% of
it and the remaining 80% is &#34;just&#34; some fiddly details.  To my
knowledge nobody has ever made a faster implementation.</p>
<h2>Some architecture notes</h2>
<p>Some pieces of Ninja took struggle to get to and then are obvious in
retrospect.  I think this is true of much of math, that once you have
distilled the ideas to their essence they seem obvious. The power
comes from having the right way of thinking about the problem.  I
mostly stumbled through Ninja&#39;s design but once I was on the other
side of it I came to see I accidentally hit some good points in the
design space.  Here are a few examples.</p>
<p><strong>The graph representation</strong>.  Make doesn&#39;t well handle the case when
build rules produce multiple files.  I don&#39;t know how Make is
structured internally, but I would guess that it represents the build
structure as a graph between files since that is what the input syntax
looks like and that structure would generate that behavior.  Ninja
instead uses a bipartite graph between files and commands, where file
nodes are edges into command nodes which have edges back out to files.
This representation better captures the structure of builds: the
command is out of date if any of its inputs change, and it updates all
its outputs when it runs.  (The one graph invariant is that a given
file may have at most one input edge.)  For another consequence of
this, note that the command line itself can be thought of as an input
to command nodes, in that the command is out of date (and consequently
so are its outputs) if the command-line flags change.</p>
<p><strong>The deps log</strong>.  To get C header dependencies right you need to
consume additional dependency data produced by the C compiler.  It&#39;s
described more in <a href="https://www.aosabook.org/en/posa/ninja.html">the book chapter</a>. I recall struggling with
whether to bring in a database and how to reconcile that with my
aspirations of simplicity until I finally hit upon a <a href="https://github.com/ninja-build/ninja/blob/master/src/deps_log.h#L29">representation
format</a>
that ended up pretty tight.  (It&#39;s unfortunately still wrong in some
important ways but oh well.)</p>
<p><strong>End-to-end / crash-only</strong>.  Ninja is not a persistent daemon process
but instead does all its work from scratch on each execution.  This
is intentional and a mixture of the insights of <a href="https://en.wikipedia.org/wiki/End-to-end_principle">the end-to-end
principle</a> and
<a href="https://en.wikipedia.org/wiki/Crash-only_software">crash only
software</a>, which
is to say: given that you need to run Ninja from scratch sometimes,
if you make that fast, then you don&#39;t need to build a second &#34;online&#34;
codepath.  Projects that can stay memory-resident tend to eventually
let their startup performance languish.</p>
<p><strong>File status</strong>.  The reason programmers sometimes expect build tools to
be memory resident is so they can cache status about files on disk.
But in practice, the kernel is already caching this information in
memory and caching it again in userland doesn&#39;t save you much;
fetching file status from Linux is extremely fast.  Ninja does it all
from a single thread even.  On a machine that was &#34;fast&#34; ten years
ago you can <a href="https://github.com/ninja-build/ninja/wiki/Timing-Numbers">stat 30k files in 10s of
milliseconds</a>.
(A programming joke: half of performance problems are fixed by
introducing a cache; the other half are fixed by removing one.)</p>
<p><strong>Orders of magnitude</strong>.  A rule of thumb is that you can get scale by
2x with optimization, but to scale by 10x you need to rearchitecture.
Ninja was designed around Chrome&#39;s build which at the time had around
30k build steps.  These days it&#39;s used in much smaller settings where
it&#39;s likely not needed (see below discussion on speed) and in larger
settings like the Android build where it is failing to scale and will
likely need an alternative approach.</p>
<p><strong>Underspecifying and overspecifying</strong>.  Ninja executes commands in
parallel, so it requires the user to provide enough information to get
that correct. But at the other extreme, it also doesn&#39;t mandate that
it has a complete picture of the build. You can see one discussion of
this dynamic <a href="https://github.com/ninja-build/ninja/issues/1303">in this bug in
particular</a> (search
for &#34;evmar&#34; to see my comments).  You must often compromise between
correctness and convenience or performance and you should be
intentional when you choose a point along that continuum.  I find some
programmers are inflexible when considering this dynamic, where it&#39;s
somehow obvious that one of those concerns dominates, but in my
experience the interplay is pretty subtle; for example, a tool that
trades off correctness for convenience might overall produce a more
correct ecosystem than a more correct but less convenient alternative,
if programmers end up avoiding the latter.  (That could be <a href="https://neugierig.org/software/blog/2011/10/why-not-haskell.html">one reason
Haskell isn&#39;t more
successful</a>.
Now that I work in programming languages I see this dynamic play out
regularly.)</p>
<p>And finally, the biggest architectural insight is:</p>
<h2>The &#39;assembler&#39; metaphor</h2>
<p>When people think of build systems they think of a broad range of
features, so broad that often the way build systems talk about
themselves sometimes aren&#39;t even comparable across different tools.
The marketing text for these tools often talks about how user-friendly
the input syntax is.</p>
<p>Ninja&#39;s insight (discovered in retrospect) is that all of these tools,
no matter the high-level features, ultimately eventually must
construct some sort of graph of the <em>actions</em>: the files they intend
to keep up to date and which commands to execute.  Ninja only
implements that action graph and leaves it to the user to choose
another &#34;generator&#34; program on top.</p>
<p>I originally invented this two program split just because it neatly
fit into the project (Chrome) I was working on at the time, but I have
since come to see it as Ninja&#39;s primary contribution.</p>
<p>On one side, it allowed me to make Ninja stupid but quick, because
anything costly (such as &#34;glob for *.c&#34;) is forced into the generator.
Compared to other build systems that do all the work in one pass,
Ninja&#39;s design effectively forces you to &#34;snapshot&#34; the action graph
to disk once you&#39;ve computed it.  Another way to look at this is that
it effectively has you cache the action graph across builds.</p>
<p>On the other side, it also meant Ninja was useful in very flexible
ways, because the generator could be as high level as the user wanted
(&#34;tests are found by globbing the entire source tree for files with
&#39;test&#39; in their name&#34;).  Importantly, it forced the developer who used
Ninja to decide what they were going to pay for.  If their generator
program wanted to glob all over the disk looking for files, it was
welcome to, but then it would be more obvious to them why their builds
were slow.</p>
<p>(I should note here that a clean separation between a generator and
the resulting action graph is not as easy as I make it out to be.
Ninja ultimately has a lot of fiddly details that are all struggling
around which layer the work belongs in, but it&#39;s hard to write up the
lessons learned.)</p>
<p>The irony of this aspect of Ninja&#39;s design is that there is nothing
preventing anyone else from doing this.  Xcode or Visual Studio&#39;s
build systems (for example) could just as well do the same thing: do a
bunch of work up front, then snapshot the result for quick
reexecution.  I think the reason so few succeed at this is that it&#39;s
just too tempting to mix the layers.</p>
<p>Ninja&#39;s closest relative is Make, which attempts to encompass all of
this programmer-facing functionality (with globbing, variable
expansions, substringing, functions, etc.) that resulted in a
programming language that was too weak to express all the needed
features (witness autotools) but still strong enough to let people
write slow Makefiles.  This is vaguely <a href="https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule">Greenspun&#39;s tenth
rule</a>, which
I strongly attempted to avoid in Ninja.</p>
<h2>Defaults dominate</h2>
<p>By default, Ninja executes the desired commands in parallel.  Make is
capable of this too; Ninja borrows the same flag name for this
capability (<code>-j</code>) and just uses a different default value.  However,
because Make defaulted to running commands serially, it is relatively
easy to write a Makefile that underspecifies dependencies such that it
is unsafe to execute it in parallel.  In fact, there&#39;s even some
commercial vendor that offers some sort of &#34;Makefile accelerator&#34; tool
that helps people discover and repair underspecified dependencies.</p>
<p>In contrast, because Ninja always executes commands in parallel (even
on a single-core system) it ends up revealing mistakes like these
earlier.  This means that programs that build with Ninja typically end
up safe to build in parallel.  (Ninja has no fancy system for
detecting when you&#39;ve gotten things wrong, it just causes wrong builds
more often.)  In contrast, users often forget or are unaware of the
flag to Make that makes it also run in parallel.  It is embarrassing
to take credit for this because it&#39;s just a flag, but just because of
its default value, Ninja in practice will end up being &#34;twice as fast
as Make&#34; or more for users who aren&#39;t careful.  The lesson is that all
the optimization in the world doesn&#39;t matter if your users don&#39;t
actually see it.</p>
<h2>Speed</h2>
<p>In this post I have talked about performance a few times, and it&#39;s
important to note that there are lots of different kinds of
performance metrics to care about in a build system.  For example, one
might care &#34;how long does the build take when I start from scratch?&#34;
Ninja was solely focused on the edit-compile cycle of <em>incremental</em>
builds in large codebases, which is to say you&#39;ve run a build, you&#39;ve
edited one file, and you run the next build.</p>
<p>When I wrote Ninja, I had a memory of blaze (aka
<a href="https://bazel.build/">bazel</a>) being very fast, but it had been years
since I had last used it.  Because of this memory, I kept trying to
make Ninja even faster, to try to catch up with my memory of blaze.
Ironically it turns out blaze is not particularly fast on the speed
metric I cared about; because blaze is a Java program, even having
blaze print its &#34;help&#34; output is pretty slow.</p>
<p>It is maybe silly of me to fixate on incremental builds, but I
strongly believe that iteration time has a huge impact on programmer
satisfaction, and Ninja is used exactly in the edit-compile loop where
the difference of 1 second and 4 seconds is critical.  I think I am
personally more latency-sensitive than the average programmer, but I
also believe that programmers <em>feel</em> latency and it affects their mood
even if they don&#39;t notice it.  (Google has recently done some research
in this area that kinda confirmed my belief, here&#39;s hoping they&#39;ll
publish it publicly!)</p>
<p>It is very difficult to communicate to users the many possible
meanings of &#34;fast&#34;.  The Ninja manual tries to warn people away from
using it on small programs. Literally the <a href="https://ninja-build.org/manual.html#_using_ninja_for_your_project">second paragraph after the
introduction</a>
says &#34;If your project is small, Ninja&#39;s speed impact is likely
unnoticeable&#34; and recommends using a different build system.
Unfortunately &#34;fast&#34; sells, and the Ninja list often had users trying
to use it for their miniature apps and getting frustrated by its lack
of features.</p>
<p>Though Ninja focused on incremental rebuild performance, some users
reported that Ninja improved their end-to-end build performance too.
This was unintentional, but is because Ninja (again by virtue of doing
nearly nothing) consumes very little CPU while running those builds,
while comparable programs for whatever reason consume more CPU while
running and that takes CPU away from the underlying build.</p>
<p>In my post <a href="https://neugierig.org/software/chromium/notes/2010/05/fast.html">&#34;What does it mean for a browser to be
fast&#34;</a>
I go into how there are many aspects to speed, and that ultimately
what&#39;s important is the user&#39;s <em>perception</em> of speed.  Ninja is very
terse in its output: for most successful builds, it prints a single
line.  In contrast, other build systems tend to print a bunch of
(often gratuitously colored) output with timing numbers about the
various stages of the build it&#39;s going through, which makes them feel
heavy.  Ninja, by virtue of saying little, makes it feel even more
like it&#39;s not there.</p>
<h2>CMake</h2>
<p>I originally built Ninja to work with Chrome&#39;s wacky one-off build
system and left it at that.  Somehow a kind stranger named Peter
Collingbourne found Ninja and did the work to plug it into the much
more popular CMake build system.  Ninja&#39;s design fits well into CMake,
but there were (as always) a lot of details to work out and Peter did
most of this, initially to use Ninja to work on LLVM.  This was more
than just CMake, but also required building new semantics into Ninja.
If anyone is responsible for making Ninja succeed out there in the
real world, Peter is due the credit.</p>
<p>The CMake authors eventually took over this integration and I feel bad
about how poorly I supported them; they were very kind and patient
with me but I never really had the time to answer their requests or
concerns.  Brad, if you read this, I am very sorry!  To this day I&#39;ve
never actually used CMake and I never could find the time to worry
about it.</p>
<h2>Windows</h2>
<p>Because the motivating project for Ninja was Chrome and Chrome targets
Windows too, we got it working on Windows.  (This was another part of
Ninja that was primarily written by <a href="http://h4ck3r.net/">a
contributor</a>.)</p>
<p>At a technical level, supporting Windows is mostly a big hassle.  In
the places where the Linux code doesn&#39;t work as is, it requires either
uninteresting abstractions or major redesigns.  For an example of the
former, spawning processes and capturing their output is very
different between the platforms, but mostly in that you need to learn
a totally different API.  For an example of the latter, Ninja&#39;s design
centrally relies on the property that you can get a kernel-cached
file&#39;s last modification time quickly, and that is <a href="https://github.com/ninja-build/ninja/wiki/Timing-Numbers">just not true on
Windows</a>.</p>
<p>But Windows is still a huge platform in terms of developers, and those
developers are starved for tools.  The underlying dynamic is that when
someone makes a neat tool for Linux, the impulse is to share it, but
when they do so for Windows, the impulse is to sell it, and so because
of that there aren&#39;t as many tools freely available on Windows.</p>
<p>It was a surprise to me how many of the early Ninja users were Windows
users, but in retrospect it is kind of obvious: even if only one in a
hundred Windows developers cared about Ninja, there are so many people
on Windows that they would eventually show up.  (Sometimes in the
Linux Chrome early days we talked about it this way: even if we got
~all desktop Linux users using Chrome, in terms of total humans that&#39;s
only like getting an additional 5% of Windows users.  You can disagree
with the specific value of that number but hopefully you get my
point.)</p>
<h2>Related work</h2>
<p>I mentioned that I stumbled through Ninja&#39;s design.  I regret not
spending more time researching before building, but I intended the
whole project as just a weekend demo hack, not a serious thing.
(Relatedly, please forgive me for the embarrassing name.)  Since then
I have come to appreciate how important it is to actually understand
the design space when building a thing.  I now find myself noticing
how rare it is for programmers to discuss related work and it now
drives me mad.</p>
<p>The term I used above (&#34;action graph&#34;) is not how I thought about it
in Ninja, but is instead taken from Google&#39;s build system
(&#34;blaze&#34;/&#34;bazel&#34;).  In bazel, they explicitly talk about how there&#39;s a
graph of targets (higher-level user concepts like &#34;library&#34; and
&#34;binary&#34;) and how that generates a <a href="https://docs.bazel.build/versions/master/bazel-overview.html#how-does-bazel-work">graph of actions
(commands)</a>.</p>
<p>I wrote above a bit about how the command-line text can be viewed as
an &#39;input&#39; to commands in the same way that files are.  This is a
specific instance of the broader concept of incremental computation,
which covers not only build systems but also incrementality in UI.  My
friend <a href="https://twitter.com/radokirov">Rado</a> has been reading the
research in this area for the past year or so(!) and is working on a
series of blog posts that attempt to summarize it; watch for it.  The
Jane Street blog has had <a href="https://blog.janestreet.com/introducing-incremental/">some work on summarizing this area
too</a>; as you can
see there, there&#39;s even a connection to our recent renaissance in UI
construction as found in React.</p>
<p>The fantastic paper <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems-final.pdf">&#34;Build Systems à la
Carte&#34;</a>
discusses incremental computation in the context of build systems.  I
wish this paper had existed before I wrote Ninja.</p>
<h2>Open source</h2>
<p>I&#39;d like to wrap this up by talking a bit about being an open source
maintainer.  As you might have read elsewhere, it ends up not being
especially fun.  (<a href="https://www.youtube.com/watch?v=o_4EX4dPppA">This talk &#34;The Hard Parts of Open
Source&#34;</a> is worth your
time.)</p>
<p>When I try to take stock of my overall feelings about the project, it
is a mixture of the occasional pride when I see someone on proggit or
HN say something nice about it and a larger overall sense of
disappointment.</p>
<p>I made this thing that I thought was cool and I gave it away, and what
I got back were occasionally friendly people who nicely requested
things from me, but more often angry users who demanded things of me,
and rarely anyone saying thanks.  People repeatedly threatened to fork
the project when I didn&#39;t agree to their demands, never once
considering the possibility that I had more context on the design
space than they did.</p>
<p>A different source of sadness were the friendly and intelligent people
who made reasonable-seeming contributions that conflicted with my
design goals, where I wanted to repay their effort with a thorough
explanation about why I was turning them down, and doing that was
itself exhausting.</p>
<p>I got into programming via free software, and I wrote code with the
desire to give back to the people who gave me so much.  (If you are
reading this post then I predict you are benefiting from one or more
one of my free software contributions.)  But today I see
that free software is not really about sharing between equals anymore;
people instead think of themselves as customers and treat authors as
if they can go complain to the manager.</p>
<p>Another way of saying this is that today I am motivated by just trying
to impress or live up to the ~ten hackers that I admire, people like
apenwarr or agl or bradfitz or graydon, and while it&#39;s occasionally
cool to meet someone and have the reputation of my software precede
me, I think a lot of &#34;succeeding&#34; was mostly just kind of a burden.  I
think I could have learned about as much with a much smaller fraction
of the success.</p>
<h2>Final acknowledgements</h2>
<p>I mentioned a few people already in this post, but I&#39;d like to also
specifically thank Nico Weber, both for being a careful collaborator
and for taking on maintainership of Ninja for years, and also Jan
Niklas Hasse, who took over after Nico and whom I don&#39;t know at all
but who seems to be doing a fine job.  And finally, thanks to the many
other <a href="https://github.com/ninja-build/ninja/graphs/contributors">authors of
Ninja</a>.</p>

</div></div>
  </body>
</html>
