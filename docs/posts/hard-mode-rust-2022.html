<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://matklad.github.io/2022/10/06/hard-mode-rust.html">Original</a>
    <h1>Hard Mode Rust (2022)</h1>
    
    <div id="readability-page-1" class="page"><div>
  <article>


<p><span>This post is a case study of writing a Rust application using only minimal, artificially constrained API (eg, no dynamic memory allocation).</span>
<span>It assumes a fair bit of familiarity with the language.</span></p>
<section id="Hard-Mode-Rust-1">

    <h2>
    <a href="#Hard-Mode-Rust-1"><span>Hard Mode Rust</span> </a>
    </h2>
<p><span>The back story here is a particular criticism of Rust and C++ from hard-core C programmers.</span>
<span>This criticism is aimed at </span><a href="https://en.cppreference.com/w/cpp/language/raii"><span>RAII</span></a><span> </span>—<span> the language-defining feature of C++, which was wholesale imported to Rust as well.</span>
<span>RAII makes using various resources requiring cleanups (file descriptors, memory, locks) easy </span>—<span> any place in the program can create a resource, and the cleanup code will be invoked automatically when needed.</span>
<span>And herein lies the problem </span>—<span> because allocating resources becomes easy, RAII encourages a sloppy attitude to resources, where they are allocated and destroyed all over the place.</span>
<span>In particular, this leads to:</span></p>
<ul>
<li>
<span>Decrease in reliability. Resources are usually limited in principle, but actual resource exhaustion happens rarely.</span>
<span>If resources are allocated throughout the program, there are many virtually untested codepaths.</span>
</li>
<li>
<span>Lack of predictability. It usually is impossible to predict up-front how much resources will the program consume.</span>
<span>Instead, resource-consumption is observed empirically.</span>
</li>
<li>
<span>Poor performance. Usually, it is significantly more efficient to allocate and free resources in batches.</span>
<span>Cleanup code for individual resources is scattered throughout codebase, increasing code bloat</span>
</li>
<li>
<span>Spaghetti architecture. Resource allocation is an architecturally salient thing.</span>
<span>If all resource management is centralized to a single place, it becomes significantly easier to understand lifecycle of resources.</span>
</li>
</ul>
<p><span>I think this is a fair criticism.</span>
<span>In fact, I think this is the same criticism that C++ and Rust programmers aim at garbage collected languages.</span>
<span>This is a spectrum:</span></p>

<figure>


<pre><code><span>           GC object graph</span>
<span>                 v v</span>
<span>                  v</span>
<span>        Tree of values with RAII</span>
<span>                 v v</span>
<span>                  v</span>
<span>Static allocation of resources at startup</span></code></pre>

</figure>
<p><span>Rust programmers typically are not exposed to the lowest level of this pyramid.</span>
<span>But there</span>’<span>s a relatively compact exercise to gain the relevant experience: try re-implementing your favorite Rust programs on hard mode.</span></p>
<p><strong><strong><span>Hard Mode</span></strong></strong><span> means that you split your program into </span><code>std</code><span> binary and </span><code>#![no_std]</code><span> no-alloc library.</span>
<span>Only the small binary is allowed to directly ask OS for resources.</span>
<span>For the library, all resources must be injected.</span>
<span>In particular, to do memory allocation, the library receives a slice of bytes of a fixed size, and should use that for all storage.</span>
<span>Something like this:</span></p>

<figure>


<pre><code><span><span>// app/src/main.rs</span></span>
<span><span>fn</span> <span>main</span>() {</span>
<span>  <span>let</span> <span>mem_limit</span> = <span>64</span> * <span>1024</span>;</span>
<span>  <span>let</span> <span>memory</span> = <span>vec!</span>[<span>0u8</span>; mem_limit];</span>
<span>  app::<span>run</span>(&amp;<span>mut</span> memory)</span>
<span>}</span>
<span></span>
<span><span>// app/src/lib.rs</span></span>
<span><span>#![no_std]</span> <span>// &lt;- the point of the exercise</span></span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>run</span>(memory: &amp;<span>mut</span> [<span>u8</span>]) {</span>
<span>  ...</span>
<span>}</span></code></pre>

</figure>
</section>
<section id="Ray-Tracing">

    <h2>
    <a href="#Ray-Tracing"><span>Ray Tracing</span> </a>
    </h2>
<p><span>So, this is what the post is about: my experience implementing a toy hard mode ray tracer.</span>
<span>You can find the code on GitHub: </span><a href="http://github.com/matklad/crt">http://github.com/matklad/crt</a><span>.</span></p>
<p><span>The task of a ray tracer is to convert a description of a 3D scene like the following one:</span></p>

<figure>


<pre><code><span>background #000000</span>
<span></span>
<span>camera {</span>
<span>    pos 0,10,-50</span>
<span>    look_at 0,0,0</span>
<span>    up 0,-1,0</span>
<span>    focus 50</span>
<span>    dim 80x60</span>
<span>}</span>
<span></span>
<span>light {</span>
<span>    pos -20,10,0</span>
<span>    color #aa1111</span>
<span>}</span>
<span></span>
<span>plane {</span>
<span>    pos 0,-10,0</span>
<span>    normal 0,1,0</span>
<span>    material {</span>
<span>        color #5566FF</span>
<span>        diffuse 3</span>
<span>    }</span>
<span>}</span>
<span></span>
<span>mesh {</span>
<span>    material {</span>
<span>        color #BB5566</span>
<span>        diffuse 3</span>
<span>    }</span>
<span></span>
<span>    data {</span>
<span>        v 5.92,4.12,0.00</span>
<span>        v 5.83,4.49,0.00</span>
<span>        v 5.94,4.61,0.00</span>
<span>        v 6.17,4.49,0.00</span>
<span>        v 6.42,4.12,0.00</span>
<span>        v 5.38,4.12,2.74</span>
<span>        ...</span>
<span></span>
<span>        vn -0.96,-0.25,0.00</span>
<span>        vn -0.96,0.25,0.00</span>
<span>        vn -0.09,0.99,0.00</span>
<span>        vn 0.68,0.73,0.00</span>
<span>        vn 0.87,0.49,0.00</span>
<span>        vn -0.89,-0.25,-0.36</span>
<span>        ...</span>
<span></span>
<span>        f 1/1 2/2 3/3</span>
<span>        f 4/4 5/5 6/6</span>
<span>        ...</span>
<span>    }</span>
<span></span>
<span>}</span></code></pre>

</figure>
<p><span>Into a rendered image like this:</span></p>

<figure>

<img alt="" src="https://user-images.githubusercontent.com/1711539/194287665-05583649-dcb0-4014-82b9-424f945e19a4.png"/>
</figure>
<p><span>This works rather intuitive conceptually.</span>
<span>First, imagine the above scene, with an infinite fuchsia colored plane and a red Utah teapot hovering above that.</span>
<span>Then, imagine a camera standing at </span><code>0,10,-50</code><span> (in cartesian coordinates) and aiming at the origin.</span>
<span>Now, draw an imaginary rectangular 80x60 screen at a focus distance of 50 from the camera along its line of sight.</span>
<span>To get a 2D picture, we shoot a ray from the camera through each </span>“<span>pixel</span>”<span> on the screen, note which object on the scene is hit (plan, teapot, background), and color the pixel accordingly.</span>
<span>See </span><a href="https://pbrt.org"><span>PBRT Book</span></a><span> if you feel like falling further into this particular rabbit hole (warning: it is very deep) (I apologize for </span>“<span>little square pixels</span>”<span> simplification I use throughout the post :-) ).</span></p>
<p><span>I won</span>’<span>t focus on specific algorithms to implement that (indeed, crt is a very naive tracer), but rather highlight Hard Mode Rust specific concerns.</span></p>
</section>
<section id="Pixel-Buffer">

    <h2>
    <a href="#Pixel-Buffer"><span>Pixel Buffer</span> </a>
    </h2>
<p><span>Ultimately, the out of a ray tracer is a 2D buffer with 8bit RGB pixels.</span>
<span>One would typically represent it as follows:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Color</span> { r: <span>u8</span>, g: <span>u8</span>, b: <span>u8</span> }</span>
<span></span>
<span><span>pub</span> <span>struct</span> <span>Buf</span> {</span>
<span>  dim: [<span>u32</span>; <span>2</span>]</span>
<span>  <span>// invariant: data.len() == dim.0 * dim.1</span></span>
<span>  data: <span>Box</span>&lt;[Color]&gt;,</span>
<span>}</span></code></pre>

</figure>
<p><span>For us, we want someone else (main) to allocate that box of colors for us, so instead we do the following:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Buf</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  dim: [<span>u32</span>; <span>2</span>],</span>
<span>  buf: &amp;<span>&#39;m</span> <span>mut</span> [Color],</span>
<span>}</span>
<span></span>
<span><span>impl</span>&lt;<span>&#39;m</span>&gt; Buf&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>new</span>(dim: Idx, buf: &amp;<span>&#39;m</span> <span>mut</span> [Color]) <span>-&gt;</span> Buf&lt;<span>&#39;m</span>&gt; {</span>
<span>    <span>assert!</span>(dim.<span>0</span> * dim.<span>1</span> == buf.<span>len</span>() <span>as</span> <span>u32</span>);</span>
<span>    Buf { dim, buf }</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>The </span><code>&#39;m</code><span> lifetime we use for abstract memory managed elsewhere.</span>
<span>Note how the struct grew an extra lifetime!</span>
<span>This is extra price we have to pay for not relying on RAII to cleanup resources for us:</span></p>

<figure>


<pre><code><span><span>// Easy Mode</span></span>
<span><span>fn</span> <span>paint</span>(buf: &amp;<span>mut</span> Buf) { ... }</span>
<span></span>
<span><span>struct</span> <span>PaintCtx</span>&lt;<span>&#39;a</span>&gt; {</span>
<span>  buf: &amp;<span>&#39;a</span> <span>mut</span> Buf</span>
<span>}</span>
<span></span>
<span><span>// Hard Mode</span></span>
<span><span>fn</span> <span>paint</span>(buf: &amp;<span>mut</span> Buf&lt;<span>&#39;_</span>&gt;) { ... }</span>
<span></span>
<span><span>struct</span> <span>PaintCtx</span>&lt;<span>&#39;a</span>, <span>&#39;m</span>&gt; {</span>
<span>  buf: &amp;<span>&#39;a</span> <span>mut</span> Buf&lt;<span>&#39;m</span>&gt;</span>
<span>}</span></code></pre>

</figure>
<p><span>Note in particular how the </span><code>Ctx</code><span> struct now has to include two lifetimes.</span>
<span>This feels unnecessary: </span><code>&#39;a</code><span> is shorter than </span><code>&#39;m</code><span>.</span>
<span>I wish it was possible to somehow abstract that away:</span></p>

<figure>


<pre><code><span><span>struct</span> <span>PaintCtx</span>&lt;<span>&#39;a</span>&gt; {</span>
<span>  buf: &amp;<span>&#39;a</span> <span>mut</span> Buf&lt;<span>&#39;_</span>&gt; <span>// &amp;&#39;a mut exists&lt;&#39;m&gt;: Buf&lt;&#39;m&gt;</span></span>
<span>}</span></code></pre>

</figure>
<p><span>I don</span>’<span>t think that</span>’<span>s really possible (</span><a href="https://matklad.github.io/2018/05/04/encapsulating-lifetime-of-the-field.html"><span>earlier post about this</span></a><span>).</span>
<span>In particular, the following would run into variance issues:</span></p>

<figure>


<pre><code><span><span>struct</span> <span>PaintCtx</span>&lt;<span>&#39;a</span>&gt; {</span>
<span>  buf: &amp;<span>&#39;a</span> <span>mut</span> Buf&lt;<span>&#39;a</span>&gt;</span>
<span>}</span></code></pre>

</figure>
<p><span>Ultimately, this is annoying, but not a deal breaker.</span></p>
<p><span>With this </span><code>rgb::Buf&lt;&#39;_&gt;</code><span>, we can sketch the program:</span></p>

<figure>


<pre><code><span><span>// hard mode library</span></span>
<span><span>#![no_std]</span></span>
<span><span>pub</span> <span>fn</span> <span>render</span>&lt;<span>&#39;a</span>&gt;(</span>
<span>  crt: &amp;<span>&#39;a</span> <span>str</span>,   <span>// textual description of the scene</span></span>
<span>  mem: &amp;<span>mut</span> [<span>u8</span>], <span>// all the memory we can use</span></span>
<span>  buf: &amp;<span>mut</span> rgb::Buf, <span>// write image here</span></span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;(), Error&lt;<span>&#39;a</span>&gt;&gt; {</span>
<span>  ...</span>
<span>}</span>
<span></span>
<span><span>// main</span></span>
<span><span>#[derive(argh::FromArgs)]</span></span>
<span><span>struct</span> <span>Args</span> {</span>
<span>  <span>#[argh(option, default = <span>&#34;64&#34;</span>)]</span>  mem: <span>usize</span>,</span>
<span>  <span>#[argh(option, default = <span>&#34;800&#34;</span>)]</span> width: <span>u32</span>,</span>
<span>  <span>#[argh(option, default = <span>&#34;600&#34;</span>)]</span> height: <span>u32</span>,</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>main</span>() <span>-&gt;</span> anyhow::<span>Result</span>&lt;()&gt; {</span>
<span>  <span>let</span> <span>args</span>: Args = argh::<span>from_env</span>();</span>
<span></span>
<span>  <span>let</span> <span>mut </span><span>crt</span> = <span>String</span>::<span>new</span>();</span>
<span>  io::<span>stdin</span>()</span>
<span>    .<span>read_to_string</span>(&amp;<span>mut</span> crt)</span>
<span>    .<span>context</span>(<span>&#34;reading input&#34;</span>)?;</span>
<span></span>
<span>  <span>// Allocate all the memory.</span></span>
<span>  <span>let</span> <span>mut </span><span>mem</span> = <span>vec!</span>[<span>0</span>; args.mem * <span>1024</span>];</span>
<span></span>
<span>  <span>// Allocate the image</span></span>
<span>  <span>let</span> <span>mut </span><span>buf</span> = <span>vec!</span>[</span>
<span>    rgb::Color::<span>default</span>();</span>
<span>    (args.width * args.height) <span>as</span> <span>usize</span></span>
<span>  ];</span>
<span>  <span>let</span> <span>mut </span><span>buf</span> =</span>
<span>    rgb::Buf::<span>new</span>([args.width, args.height], &amp;<span>mut</span> buf);</span>
<span></span>
<span>  render::<span>render</span>(</span>
<span>    &amp;crt,</span>
<span>    &amp;<span>mut</span> mem,</span>
<span>    &amp;<span>mut</span> buf,</span>
<span>  )</span>
<span>  .<span>map_err</span>(|err| anyhow::format_err!(<span>&#34;{err}&#34;</span>))?;</span>
<span></span>
<span>  <span>// Write result as a PPM image format.</span></span>
<span>  <span>write_ppm</span>(&amp;buf, &amp;<span>mut</span> io::<span>stdout</span>().<span>lock</span>())</span>
<span>    .<span>context</span>(<span>&#34;writing output&#34;</span>)?;</span>
<span>  <span>Ok</span>(())</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>write_ppm</span>(</span>
<span>  buf: &amp;rgb::Buf,</span>
<span>  w: &amp;<span>mut</span> <span>dyn</span> io::Write,</span>
<span>) <span>-&gt;</span> io::<span>Result</span>&lt;()&gt; {</span>
<span>  ...</span>
<span>}</span></code></pre>

</figure>
</section>
<section id="Hard-Mode-Rayon">

    <h2>
    <a href="#Hard-Mode-Rayon"><span>Hard Mode Rayon</span> </a>
    </h2>
<p><span>Ray tracing is an embarrassingly parallel task </span>—<span> the color of each output pixel can be computed independently.</span>
<span>Usually, the excellent </span><a href="https://lib.rs/crates/rayon"><span>rayon</span></a><span> library is used to take advantage of parallelism, but for our raytracer I want to show a significantly simpler API design for taking advantage of many cores.</span>
<span>I</span>’<span>ve seen this design in </span><a href="https://github.com/sorbet/sorbet/blob/master/common/concurrency/WorkerPool.h"><span>Sorbet</span></a><span>, a type checker for Ruby.</span></p>
<p><span>Here</span>’<span>s how a </span><code>render</code><span> function with support for parallelism looks:</span></p>

<figure>


<pre><code><span><span>type</span> <span>ThreadPool</span>&lt;<span>&#39;t</span>&gt; = <span>dyn</span> <span>Fn</span>(&amp;(<span>dyn</span> <span>Fn</span>() + <span>Sync</span>)) + <span>&#39;t</span>;</span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>render</span>&lt;<span>&#39;a</span>&gt;(</span>
<span>  crt: &amp;<span>&#39;a</span> <span>str</span>,</span>
<span>  mem: &amp;<span>mut</span> [<span>u8</span>],</span>
<span>  in_parallel: &amp;ThreadPool&lt;<span>&#39;_</span>&gt;,</span>
<span>  buf: &amp;<span>mut</span> rgb::Buf&lt;<span>&#39;_</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;(), Error&lt;<span>&#39;a</span>&gt;&gt; {</span></code></pre>

</figure>
<p><span>The interface here is the </span><code>in_parallel</code><span> function, which takes another function as an argument and runs it, in parallel, on all available threads.</span>
<span>You typically use it like this:</span></p>

<figure>


<pre><code><span><span>let</span> <span>work</span>: ConcurrentQueue&lt;Work&gt; = ConcurrentQueue::<span>new</span>();</span>
<span>work.<span>extend</span>(available_work);</span>
<span><span>in_parallel</span>(&amp;|| {</span>
<span>  <span>while</span> <span>let</span> <span>Some</span>(item) = work.<span>pop</span>() {</span>
<span>    <span>process</span>(item);</span>
<span>  }</span>
<span>})</span></code></pre>

</figure>
<p><span>This is </span><em><span>similar</span></em><span> to a typical threadpool, but different.</span>
<span>Similar to a threadpool, there</span>’<span>s a number of threads (typically one per core) which execute arbitrary jobs.</span>
<span>The first difference is that a typical threadpool sends a job to to a single thread, while in this design the same job is broadcasted to all threads.</span>
<span>The job is </span><code>Fn + Sync</code><span> rather than </span><code>FnOnce + Send</code><span>.</span>
<span>The second difference is that we </span><em><span>block</span></em><span> until the job is done on all threads, so we can borrow data from the stack.</span></p>
<p><span>It</span>’<span>s on the caller to explicitly implement a concurrent queue to distributed specific work items.</span>
<span>In my implementation, I slice the image in rows</span></p>

<figure>


<pre><code><span><span>type</span> <span>ThreadPool</span>&lt;<span>&#39;t</span>&gt; = <span>dyn</span> <span>Fn</span>(&amp;(<span>dyn</span> <span>Fn</span>() + <span>Sync</span>)) + <span>&#39;t</span>;</span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>render</span>&lt;<span>&#39;a</span>&gt;(</span>
<span>  crt: &amp;<span>&#39;a</span> <span>str</span>,</span>
<span>  mem: &amp;<span>mut</span> [<span>u8</span>],</span>
<span>  in_parallel: &amp;ThreadPool&lt;<span>&#39;_</span>&gt;,</span>
<span>  buf: &amp;<span>mut</span> rgb::Buf&lt;<span>&#39;_</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;(), Error&lt;<span>&#39;a</span>&gt;&gt; {</span>
<span>  ...</span>
<span>  <span>// Note: this is not mut, because this is</span></span>
<span>  <span>// a concurrent iterator.</span></span>
<span>  <span>let</span> <span>rows</span> = buf.<span>partition</span>();</span>
<span>  <span>in_parallel</span>(&amp;|| {</span>
<span>    <span>// next_row increments an atomic and</span></span>
<span>    <span>// uses the row index to give an `&amp;mut`</span></span>
<span>    <span>// into the row&#39;s pixels.</span></span>
<span>    <span>while</span> <span>let</span> <span>Some</span>(row) = rows.<span>next_row</span>() {</span>
<span>      <span>let</span> <span>y</span>: <span>u32</span> = row.y;</span>
<span>      <span>let</span> <span>buf</span>: &amp;<span>mut</span> [rgb::Color] = row.buf;</span>
<span>      <span>for</span> <span>x</span> <span>in</span> <span>0</span>..dim[<span>0</span>] {</span>
<span>        <span>let</span> <span>color</span> = render::<span>render_pixel</span>(&amp;scene, [x, y]);</span>
<span>        buf[x <span>as</span> <span>usize</span>] = <span>to_rgb</span>(&amp;color);</span>
<span>      }</span>
<span>    }</span>
<span>  });</span>
<span>  ...</span>
<span>}</span></code></pre>

</figure>
<p><span>In </span><code>main</code><span>, we implement a concrete </span><code>ThreadPool</code><span> by spawning a thread per core:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>main</span>() <span>-&gt;</span> anyhow::<span>Result</span>&lt;()&gt; {</span>
<span>  ...</span>
<span>  <span>let</span> <span>threads</span> = <span>match</span> args.jobs {</span>
<span>    <span>Some</span>(it) =&gt; Threads::<span>new</span>(it),</span>
<span>    <span>None</span> =&gt; Threads::<span>with_max_threads</span>()?,</span>
<span>  };</span>
<span>  render::<span>render</span>(</span>
<span>    &amp;crt,</span>
<span>    &amp;<span>mut</span> mem,</span>
<span>    &amp;|f| threads.<span>in_parallel</span>(f),</span>
<span>    &amp;<span>mut</span> buf,</span>
<span>  )</span>
<span>  .<span>map_err</span>(|err| anyhow::format_err!(<span>&#34;{err}&#34;</span>))?;</span>
<span>}</span></code></pre>

</figure>
</section>
<section id="Allocator">

    <h2>
    <a href="#Allocator"><span>Allocator</span> </a>
    </h2>
<p><span>The scenes we are going to render are fundamentally dynamically sized.</span>
<span>They can contain arbitrary number of objects.</span>
<span>So we can</span>’<span>t just statically allocate all the memory up-front.</span>
<span>Instead, there</span>’<span>s a CLI argument which sets the amount of memory a ray tracer can use, and we should either manage with that, or return an error.</span>
<span>So we do need to write our own allocator.</span>
<span>But we</span>’<span>ll try very hard to only allocate the memory we actually need, so we won</span>’<span>t have to implement memory deallocation at all.</span>
<span>So a simple bump allocator would do:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Mem</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  raw: &amp;<span>&#39;m</span> <span>mut</span> [<span>u8</span>],</span>
<span>}</span>
<span></span>
<span><span>#[derive(Debug)]</span></span>
<span><span>pub</span> <span>struct</span> <span>Oom</span>;</span>
<span></span>
<span><span>impl</span>&lt;<span>&#39;m</span>&gt; Mem&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>new</span>(raw: &amp;<span>&#39;m</span> <span>mut</span> [<span>u8</span>]) <span>-&gt;</span> Mem&lt;<span>&#39;m</span>&gt; {</span>
<span>    Mem { raw }</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>alloc</span>&lt;T&gt;(&amp;<span>mut</span> <span>self</span>, t: T) <span>-&gt;</span> <span>Result</span>&lt;&amp;<span>&#39;m</span> <span>mut</span> T, Oom&gt; { ... }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>alloc_array</span>&lt;T&gt;(</span>
<span>    &amp;<span>mut</span> <span>self</span>,</span>
<span>    n: <span>usize</span>,</span>
<span>    <span>mut</span> element: <span>impl</span> <span>FnMut</span>(<span>usize</span>) <span>-&gt;</span> T,</span>
<span>  ) <span>-&gt;</span> <span>Result</span>&lt;&amp;<span>&#39;m</span> <span>mut</span> [T], Oom&gt; { ... }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>alloc_array_default</span>&lt;T: <span>Default</span>&gt;(</span>
<span>    &amp;<span>mut</span> <span>self</span>,</span>
<span>    n: <span>usize</span>,</span>
<span>  ) <span>-&gt;</span> <span>Result</span>&lt;&amp;<span>&#39;m</span> <span>mut</span> [T], Oom&gt; {</span>
<span>    <span>self</span>.<span>alloc_array</span>(n, |_| T::<span>default</span>())</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>We can create an allocator from a slice of bytes, and then ask it to allocate values and arrays.</span>
<span>Schematically, </span><code>alloc</code><span> looks like this:</span></p>

<figure>


<pre><code><span><span>// PSEUDOCODE, doesn&#39;t handle alignment and is broken.</span></span>
<span><span>pub</span> <span>fn</span> <span>alloc</span>&lt;<span>&#39;a</span>, T&gt;(</span>
<span>  &amp;<span>&#39;a</span> <span>mut</span> <span>self</span>,</span>
<span>  val: T,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;&amp;<span>&#39;m</span> <span>mut</span> T, Oom&gt; {</span>
<span>  <span>let</span> <span>size</span> = mem::size_of::&lt;T&gt;();</span>
<span>  <span>if</span> <span>self</span>.raw.<span>len</span>() &lt; size {</span>
<span>    <span>// Return error if there isn&#39;t enough of memory.</span></span>
<span>    <span>return</span> <span>Err</span>(Oom);</span>
<span>  }</span>
<span></span>
<span>  <span>// Split off size_of::&lt;T&gt; bytes from the start,</span></span>
<span>  <span>// doing a little `mem::take` dance to placate</span></span>
<span>  <span>// the borrowchecker.</span></span>
<span>  <span>let</span> <span>res</span>: &amp;<span>&#39;m</span> <span>mut</span> [<span>u8</span>] = {</span>
<span>    <span>let</span> <span>raw</span> = mem::<span>take</span>(&amp;<span>mut</span> <span>self</span>.raw);</span>
<span>    <span>let</span> (res, raw) = raw.<span>split_at_mut</span>(size);</span>
<span>    <span>self</span>.raw = raw;</span>
<span>    res</span>
<span>  }</span>
<span></span>
<span>  <span>// Initialize the value</span></span>
<span>  <span>let</span> <span>res</span> = res <span>as</span> *<span>mut</span> [<span>u8</span>] <span>as</span> *<span>mut</span> <span>u8</span> <span>as</span> *<span>mut</span> T;</span>
<span>  <span>unsafe</span> {</span>
<span>    ptr::<span>write</span>(res, val);</span>
<span>    <span>Ok</span>(&amp;<span>mut</span> *res)</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>To make this fully kosher we need to handle alignment as well, but I cut that bit out for brevity.</span></p>
<p><span>For allocating arrays, it</span>’<span>s useful if all-zeros bitpattern is a valid default instance of type, as that allows to skip element-wise initialization.</span>
<span>This condition isn</span>’<span>t easily expressible in today</span>’<span>s Rust though, so we require initializing every array member.</span></p>
<p><span>The result of an allocation is </span><code>&amp;&#39;m T</code><span> </span>—<span> this is how we spell </span><code>Box&lt;T&gt;</code><span> on hard mode.</span></p>
</section>
<section id="Parsing">

    <h2>
    <a href="#Parsing"><span>Parsing</span> </a>
    </h2>
<p><span>The scene contains various objects, like spheres and planes:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Sphere</span> {</span>
<span>  <span>pub</span> center: v64, <span>// v64 is [f64; 3]</span></span>
<span>  <span>pub</span> radius: <span>f64</span>,</span>
<span>}</span>
<span></span>
<span><span>pub</span> <span>struct</span> <span>Plane</span> {</span>
<span>  <span>pub</span> origin: v64,</span>
<span>  <span>pub</span> normal: v64,</span>
<span>}</span></code></pre>

</figure>
<p><span>Usually, we</span>’<span>d represent a scene as</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Scene</span> {</span>
<span>  <span>pub</span> camera: Camera,</span>
<span>  <span>pub</span> spheres: <span>Vec</span>&lt;Sphere&gt;,</span>
<span>  <span>pub</span> planes: <span>Vec</span>&lt;Plane&gt;,</span>
<span>}</span></code></pre>

</figure>
<p><span>We </span><em><span>could</span></em><span> implement a resizable array (</span><code>Vec</code><span>), but doing that would require us to either leak memory, or to implement proper deallocation logic in our allocator, and add destructors to reliably trigger that.</span>
<span>But destructors is exactly something we are trying to avoid in this exercise.</span>
<span>So our scene will have to look like this instead:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Scene</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> camera: Camera,</span>
<span>  <span>pub</span> spheres: &amp;<span>&#39;m</span> <span>mut</span> [Sphere],</span>
<span>  <span>pub</span> planes: &amp;<span>&#39;m</span> <span>mut</span> [Plane],</span>
<span>}</span></code></pre>

</figure>
<p><span>And that means we want to know the number of objects we</span>’<span>ll need upfront.</span>
<span>The way we solve this problem is by doing two-pass parsing.</span>
<span>In the first pass, we just count things, then we allocate them, then we actually parse them into allocated space.</span></p>

<figure>


<pre><code><span><span>pub</span>(<span>crate</span>) <span>fn</span> <span>parse</span>&lt;<span>&#39;m</span>, <span>&#39;i</span>&gt;(</span>
<span>  mem: &amp;<span>mut</span> Mem&lt;<span>&#39;m</span>&gt;,</span>
<span>  input: &amp;<span>&#39;i</span> <span>str</span>,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;Scene&lt;<span>&#39;m</span>&gt;, Error&lt;<span>&#39;i</span>&gt;&gt; {</span>
<span>  <span>// Size the allocations.</span></span>
<span>  <span>let</span> <span>mut </span><span>n_spheres</span> = <span>0</span>;</span>
<span>  <span>let</span> <span>mut </span><span>n_planes</span> = <span>0</span>;</span>
<span>  <span>for</span> <span>word</span> <span>in</span> input.<span>split_ascii_whitespace</span>() {</span>
<span>    <span>match</span> word {</span>
<span>      <span>&#34;sphere&#34;</span> =&gt; n_spheres += <span>1</span>,</span>
<span>      <span>&#34;plane&#34;</span> =&gt; n_planes += <span>1</span>,</span>
<span>      _ =&gt; (),</span>
<span>    }</span>
<span>  }</span>
<span></span>
<span>  <span>// Allocate.</span></span>
<span>  <span>let</span> <span>mut </span><span>res</span> = Scene {</span>
<span>    camera: <span>Default</span>::<span>default</span>(),</span>
<span>    spheres: mem.<span>alloc_array_default</span>(n_spheres)?</span>
<span>    planes: mem.<span>alloc_array_default</span>(n_planes)?,</span>
<span>  };</span>
<span></span>
<span>  <span>// Parse _into_ the allocated scene.</span></span>
<span>  <span>let</span> <span>mut </span><span>p</span> = Parser::<span>new</span>(mem, input);</span>
<span>  <span>scene</span>(&amp;<span>mut</span> p, &amp;<span>mut</span> res)?;</span>
<span>  <span>Ok</span>(res)</span>
<span>}</span></code></pre>

</figure>
<p><span>If an error is encountered during parsing, we want to create a helpful error message.</span>
<span>If the message is fully dynamic, we</span>’<span>d have to allocate it </span><em><span>into</span></em><span> </span><code>&#39;m</code><span>, but it seems simpler to just re-use bits of input for error message.</span>
<span>Hence, </span><code>Error&lt;&#39;i&gt;</code><span> is tied to the input lifetime </span><code>&#39;i</code><span>, rather memory lifetime </span><code>&#39;m</code><span>.</span></p>
</section>
<section id="Nested-Objects">

    <h2>
    <a href="#Nested-Objects"><span>Nested Objects</span> </a>
    </h2>
<p><span>One interesting type of object on the scene is a mesh of triangles (for example, the teapot is just a bunch of triangles).</span>
<span>A naive way to represent a bunch of triangles is to use a vector:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Triangle</span> {</span>
<span>  <span>pub</span> a: v64,</span>
<span>  <span>pub</span> b: v64,</span>
<span>  <span>pub</span> c: v64,</span>
<span>}</span>
<span></span>
<span><span>type</span> <span>Mesh</span> = <span>Vec</span>&lt;Triangle&gt;;</span></code></pre>

</figure>
<p><span>This is wasteful: in a mesh, each edge is shared by two triangles.</span>
<span>So a single vertex belongs to a bunch of triangles.</span>
<span>If we store a vector of triangles, we are needlessly duplicating vertex data.</span>
<span>A more compact representation is to store unique vertexes once, and to use indexes for sharing:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Mesh</span> {</span>
<span>  <span>pub</span> vertexes: <span>Vec</span>&lt;v64&gt;,</span>
<span>  <span>pub</span> faces: <span>Vec</span>&lt;MeshFace&gt;,</span>
<span>}</span>
<span><span>// Indexes point into vertexes vector.</span></span>
<span><span>pub</span> <span>struct</span> <span>MeshFace</span> { a: <span>u32</span>, b: <span>u32</span>, c: <span>u32</span> }</span></code></pre>

</figure>
<p><span>Again, on hard mode that would be</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Mesh</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> vertexes: &amp;<span>&#39;m</span> <span>mut</span> [v64],</span>
<span>  <span>pub</span> faces: &amp;<span>&#39;m</span> <span>mut</span> [MeshFace],</span>
<span>}</span></code></pre>

</figure>
<p><span>And a scene contains a bunch of meshes :</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Scene</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> camera: Camera,</span>
<span>  <span>pub</span> spheres: &amp;<span>&#39;m</span> <span>mut</span> [Sphere],</span>
<span>  <span>pub</span> planes: &amp;<span>&#39;m</span> <span>mut</span> [Plane],</span>
<span>  <span>pub</span> meshes: &amp;<span>&#39;m</span> <span>mut</span> [Mesh&lt;<span>&#39;m</span>&gt;],</span>
<span>}</span></code></pre>

</figure>
<p><span>Note how, if the structure is recursive, we have </span>“<span>owned pointers</span>”<span> of </span><code>&amp;&#39;m mut T&lt;&#39;m&gt;</code><span> shape.</span>
<span>Originally I worried that that would cause problem with variance, but it seems to work fine for ownership specifically.</span>
<span>During processing, you still need </span><code>&amp;&#39;a mut T&lt;&#39;m&gt;</code><span> though.</span></p>
<p><span>And that</span>’<span>s why parsing functions hold an uncomfortable bunch of lifetimes:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>mesh</span>&lt;<span>&#39;m</span>, <span>&#39;i</span>&gt;(</span>
<span>  p: &amp;<span>mut</span> Parser&lt;<span>&#39;m</span>, <span>&#39;i</span>, <span>&#39;_</span>&gt;,</span>
<span>  res: &amp;<span>mut</span> Mesh&lt;<span>&#39;m</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;(), Error&lt;<span>&#39;i</span>&gt;&gt; { ... }</span></code></pre>

</figure>
<p><span>The parser </span><code>p</code><span> holds </span><code>&amp;&#39;i str</code><span> input and a </span><code>&amp;&#39;a mut Mem&lt;&#39;m&gt;</code><span> memory.</span>
<span>It parses input </span><em><span>into</span></em><span> a </span><code>&amp;&#39;b mut Mesh&lt;&#39;m&gt;</code><span>.</span></p>
</section>
<section id="Bounding-Volume-Hierarchy">

    <h2>
    <a href="#Bounding-Volume-Hierarchy"><span>Bounding Volume Hierarchy</span> </a>
    </h2>
<p><span>With </span><code>Scene&lt;&#39;m&gt;</code><span> fully parsed, we can finally get to rendering the picture.</span>
<span>A naive way to do this would be to iterate through each pixel, shooting a ray through it, and then do a nested iterations over every shape, looking for the closest intersection.</span>
<span>That</span>’<span>s going to be slow!</span>
<span>The teapot model contains about 1k triangles, and we have 640*480 pixels, which gives us 307</span><span>_200</span><span>_000 ray-triangle intersection tests, which is quite slow even with multithreading.</span></p>
<p><span>So we are going to speed this up.</span>
<span>The idea is simple </span>—<span> just don</span>’<span>t intersect a ray with each triangle.</span>
<span>It is possible to quickly discard batches of triangles.</span>
<span>If we have a  batch of triangles, we can draw a 3D box around them as a pre-processing step.</span>
<span>Now if the ray doesn</span>’<span>t intersect the bounding box, we know that it can</span>’<span>t intersect any of the triangles.</span>
<span>So we can use one test with a bounding box instead of many tests for each triangle.</span></p>
<p><span>This is of course one-sided </span>—<span> if the ray intersects the box, it might still miss all of the triangles.</span>
<span>But, if we place bounding boxes smartly (small boxes which cover many adjacent triangles), we can hope to skip a lot of work.</span></p>
<p><span>We won</span>’<span>t go for really smart ways of doing that, and instead will use a simple divide-and-conquer scheme.</span>
<span>Specifically, we</span>’<span>ll draw a large box around all triangles we have.</span>
<span>Then, we</span>’<span>ll note which dimension of the resulting box is the longest.</span>
<span>If, for example, the box is very tall, we</span>’<span>ll cut it in half horizontally, such that each half contains half of the triangles.</span>
<span>Then, we</span>’<span>ll recursively subdivide the two halves.</span></p>
<p><span>In the end, we get a binary tree, where each node contains a bounding box and two children, whose bounding boxes are contained in the parent</span>’<span>s bounding box.</span>
<span>Leaves contains triangles.</span>
<span>This construction is called a bounding volume hierarchy, bvh.</span></p>
<p><span>To intersect the ray with bvh, we use a recursive procedure.</span>
<span>Starting at the root node, we descend into children whose bounding boxes are intersected by the ray.</span>
<span>Sometimes we</span>’<span>ll have to descend into both children, but often enough at least one child</span>’<span>s bounding box won</span>’<span>t touch the ray, allowing us to completely skip the subtree.</span></p>
<p><span>On easy mode Rust, we can code it like this:</span></p>

<figure>


<pre><code><span><span>struct</span> <span>BoundingBox</span> {</span>
<span>  <span>// Opposite corners of the box.</span></span>
<span>  lo: v64, hi: v64,</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>Bvh</span> {</span>
<span>  root: BvhNode</span>
<span>}</span>
<span></span>
<span><span>enum</span> <span>BvhNode</span> {</span>
<span>  Split {</span>
<span>    bb: BoundingBox,</span>
<span>    children: [<span>Box</span>&lt;BvhNode&gt;; <span>2</span>],</span>
<span>    <span>/// Which of X,Y,Z dimensions was used</span></span>
<span>    <span>// to cut the bb in two.</span></span>
<span>    axis: <span>u8</span>,</span>
<span>  }</span>
<span>  Leaf {</span>
<span>    bb: BoundingBox,</span>
<span>    <span>/// Index of the triangle in a mesh.</span></span>
<span>    triangle: <span>u32</span>,</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>On hard mode, we don</span>’<span>t really love all those separate boxes, we love arrays!</span>
<span>So what we</span>’<span>d rather have is</span></p>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Bvh</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  splits: &amp;<span>&#39;m</span> <span>mut</span> [BvhSplit],</span>
<span>  leaves: &amp;<span>&#39;m</span> <span>mut</span> [BvhLeaf],</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>BvhSplit</span> {</span>
<span>  <span>/// Index into either splits or leaves.</span></span>
<span>  <span>/// The `tag` is in the highest bit.</span></span>
<span>  children: [<span>u32</span>; <span>2</span>],</span>
<span>  bb: BoundingBox,</span>
<span>  axis: <span>u8</span>,</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>BvhLeaf</span> {</span>
<span>  face: <span>u32</span>,</span>
<span>  bb: BoundingBox,</span>
<span>}</span></code></pre>

</figure>
<p><span>So we want to write the following function which recursively constructs a bvh for a mesh:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>fn</span> <span>build</span>(</span>
<span>  mem: &amp;<span>mut</span> Mem&lt;<span>&#39;m</span>&gt;,</span>
<span>  mesh: &amp;Mesh&lt;<span>&#39;m</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;Bvh&lt;<span>&#39;m</span>&gt;, Oom&gt; { ... }</span></code></pre>

</figure>
<p><span>The problem is, unlike the parser, we can</span>’<span>t cheaply determine the number of leaves and splits without actually building the whole tree.</span></p>
</section>
<section id="Scratch-Space">

    <h2>
    <a href="#Scratch-Space"><span>Scratch Space</span> </a>
    </h2>
<p><span>So what we are going to do here is to allocate a pointer-tree structure into some scratch space, and then copy that into an </span><code>&amp;&#39;m mut</code><span> array.</span>
<span>How do we find the scratch space?</span>
<span>Our memory is </span><code>&amp;&#39;m [u8]</code><span>.</span>
<span>We allocate stuff from the start of the region.</span>
<span>So we can split of some amount of scratch space from the end:</span></p>

<figure>


<pre><code><span>&amp;<span>&#39;m</span> <span>mut</span> [<span>u8</span>] <span>-&gt;</span> (&amp;<span>&#39;m</span> <span>mut</span> [<span>u8</span>], &amp;<span>&#39;s</span> <span>mut</span> [<span>u8</span>])</span></code></pre>

</figure>
<p><span>Stuff we allocate into the first half is allocated </span>“<span>permanently</span>”<span>.</span>
<span>Stuff we allocate into the second half is allocated temporarily.</span>
<span>When we drop temp buffer, we can reclaim all that space.</span></p>
<p><span>This</span>…<span> probably is the most sketchy part of the whole endeavor.</span>
<span>It is </span><code>unsafe</code><span>, requires lifetimes casing, and I actually can</span>’<span>t get it past miri.</span>
<span>But it should be fine, right?</span></p>
<p><span>So, I have the following thing API:</span></p>

<figure>


<pre><code><span><span>impl</span> <span>Mem</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>with_scratch</span>&lt;T&gt;(</span>
<span>    &amp;<span>mut</span> <span>self</span>,</span>
<span>    size: <span>usize</span>,</span>
<span>    f: <span>impl</span> <span>FnOnce</span>(&amp;<span>mut</span> Mem&lt;<span>&#39;m</span>&gt;, &amp;<span>mut</span> Mem&lt;<span>&#39;_</span>&gt;) <span>-&gt;</span> T,</span>
<span>  ) <span>-&gt;</span> T { ... }</span>
<span>}</span></code></pre>

</figure>
<p><span>It can be used like this:</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>test_scratch</span>() {</span>
<span>  <span>let</span> <span>mut </span><span>buf</span> = [<span>0u8</span>; <span>4</span>];</span>
<span>  <span>let</span> <span>mut </span><span>mem</span> = Mem::<span>new</span>(&amp;<span>mut</span> buf);</span>
<span></span>
<span>  <span>let</span> <span>x</span> = mem.<span>alloc</span>(<span>0u8</span>).<span>unwrap</span>();</span>
<span>  <span>let</span> <span>y</span> = mem.<span>with_scratch</span>(<span>2</span>, |mem, scratch| {</span>
<span>    <span>// Here, we can allocate _permanent_ stuff from `mem`,</span></span>
<span>    <span>// and temporary stuff from `scratch`.</span></span>
<span>    <span>// Only permanent stuff can escape.</span></span>
<span></span>
<span>    <span>let</span> <span>y</span> = mem.<span>alloc</span>(<span>1u8</span>).<span>unwrap</span>();</span>
<span>    <span>let</span> <span>z</span> = scratch.<span>alloc</span>(<span>2u8</span>).<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>((*x, *y, *z), (<span>0</span>, <span>1</span>, <span>2</span>));</span>
<span></span>
<span>    <span>// The rest of memory is occupied by scratch.</span></span>
<span>    <span>assert!</span>(mem.<span>alloc</span>(<span>0u8</span>).<span>is_err</span>());</span>
<span></span>
<span>    y <span>// Returning z here fails.</span></span>
<span>  });</span>
<span></span>
<span>  <span>// The scratch memory is now reclaimed.</span></span>
<span>  <span>let</span> <span>z</span> = mem.<span>alloc</span>(<span>3u8</span>).<span>unwrap</span>();</span>
<span>  <span>assert_eq!</span>((*x, *y, *z), (<span>0</span>, <span>1</span>, <span>3</span>));</span>
<span>  <span>assert_eq!</span>(buf, [<span>0</span>, <span>1</span>, <span>3</span>, <span>0</span>]);</span>
<span>  <span>// Will fail to compile.</span></span>
<span>  <span>// assert_eq!(*x, 0);</span></span>
<span>}</span></code></pre>

</figure>
<p><span>And here</span>’<span>s how </span><code>with_scratch</code><span> implemented:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>fn</span> <span>with_scratch</span>&lt;T&gt;(</span>
<span>  &amp;<span>mut</span> <span>self</span>,</span>
<span>  size: <span>usize</span>,</span>
<span>  f: <span>impl</span> <span>FnOnce</span>(&amp;<span>mut</span> Mem&lt;<span>&#39;m</span>&gt;, &amp;<span>mut</span> Mem&lt;<span>&#39;_</span>&gt;) <span>-&gt;</span> T,</span>
<span>) <span>-&gt;</span> T {</span>
<span>  <span>let</span> <span>raw</span> = mem::<span>take</span>(&amp;<span>mut</span> <span>self</span>.raw);</span>
<span></span>
<span>  <span>// Split off scratch space.</span></span>
<span>  <span>let</span> <span>mid</span> = raw.<span>len</span>() - size;</span>
<span>  <span>let</span> (mem, scratch) = raw.<span>split_at_mut</span>(mid);</span>
<span></span>
<span>  <span>self</span>.raw = mem;</span>
<span>  <span>let</span> <span>res</span> = <span>f</span>(<span>self</span>, &amp;<span>mut</span> Mem::<span>new</span>(scratch));</span>
<span></span>
<span>  <span>let</span> <span>data</span> = <span>self</span>.raw.<span>as_mut_ptr</span>();</span>
<span>  <span>// Glue the scratch space back in.</span></span>
<span>  <span>let</span> <span>len</span> = <span>self</span>.raw.<span>len</span>() + size;</span>
<span>  <span>// This makes miri unhappy, any suggestions? :(</span></span>
<span>  <span>self</span>.raw = <span>unsafe</span> { slice::<span>from_raw_parts_mut</span>(data, len) };</span>
<span>  res</span>
<span>}</span></code></pre>

</figure>
<p><span>With this infrastructure in place, we can finally implement bvh construction!</span>
<span>We</span>’<span>ll do it in three steps:</span></p>
<ol>
<li>
<span>Split of half the memory into a scratch space.</span>
</li>
<li>
<span>Build a dynamically-sized tree in that space, counting leaves and interior nodes.</span>
</li>
<li>
<span>Allocate arrays of the right size in the permanent space, and copy data over once.</span>
</li>
</ol>

<figure>


<pre><code><span><span>pub</span> <span>struct</span> <span>Bvh</span>&lt;<span>&#39;m</span>&gt; {</span>
<span>  splits: &amp;<span>&#39;m</span> <span>mut</span> [BvhSplit],</span>
<span>  leaves: &amp;<span>&#39;m</span> <span>mut</span> [BvhLeaf],</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>BvhSplit</span> {</span>
<span>  children: [<span>u32</span>; <span>2</span>],</span>
<span>  bb: BoundingBox,</span>
<span>  axis: <span>u8</span>,</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>BvhLeaf</span> {</span>
<span>  face: <span>u32</span>,</span>
<span>  bb: BoundingBox,</span>
<span>}</span>
<span></span>
<span><span>// Temporary tree we store in the scratch space.</span></span>
<span><span>enum</span> <span>Node</span>&lt;<span>&#39;s</span>&gt; {</span>
<span>  Split {</span>
<span>    children: [&amp;<span>&#39;s</span> <span>mut</span> Node&lt;<span>&#39;s</span>&gt;; <span>2</span>],</span>
<span>    bb: BoundingBox,</span>
<span>    axis: <span>u8</span></span>
<span>  },</span>
<span>  Leaf { face: <span>u32</span>, bb: BoundingBox },</span>
<span>}</span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>build</span>(</span>
<span>  mem: &amp;<span>mut</span> Mem&lt;<span>&#39;m</span>&gt;,</span>
<span>  mesh: &amp;Mesh&lt;<span>&#39;m</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;Bvh&lt;<span>&#39;m</span>&gt;, Oom&gt; {</span>
<span>  <span>let</span> <span>free_mem</span> = mem.<span>free</span>();</span>
<span>  mem.<span>with_scratch</span>(free_mem / <span>2</span>, |mem, scratch| {</span>
<span>    <span>let</span> (node, n_splits, n_leaves) =</span>
<span>      <span>build_scratch</span>(scratch, mesh);</span>
<span></span>
<span>    <span>let</span> <span>mut </span><span>res</span> = Bvh {</span>
<span>      splits: mem.<span>alloc_array_default</span>(n_splits <span>as</span> <span>usize</span>)?,</span>
<span>      leaves: mem.<span>alloc_array_default</span>(n_leaves <span>as</span> <span>usize</span>)?,</span>
<span>    };</span>
<span>    <span>copy</span>(&amp;<span>mut</span> res, &amp;node);</span>
<span></span>
<span>    <span>Ok</span>(res)</span>
<span>  })</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>build_scratch</span>&lt;<span>&#39;s</span>&gt;(</span>
<span>  mem: &amp;<span>mut</span> Mem&lt;<span>&#39;s</span>&gt;,</span>
<span>  mesh: &amp;Mesh&lt;<span>&#39;_</span>&gt;,</span>
<span>) <span>-&gt;</span> <span>Result</span>&lt;(&amp;<span>&#39;s</span> <span>mut</span> Node&lt;<span>&#39;s</span>&gt;, <span>usize</span>, <span>usize</span>), Oom&gt; {</span>
<span>  ...</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>copy</span>&lt;<span>&#39;m</span>, <span>&#39;s</span>&gt;(res: &amp;<span>mut</span> Bvh&lt;<span>&#39;m</span>&gt;, node: &amp;Node&lt;<span>&#39;s</span>&gt;) {</span>
<span>  ...</span>
<span>}</span></code></pre>

</figure>
<p><span>And that</span>’<span>s it!</span>
<span>The thing actually works, miri complaints notwithstanding!</span></p>
</section>
<section id="Conclusions">

    <h2>
    <a href="#Conclusions"><span>Conclusions</span> </a>
    </h2>
<p><span>Actually, I am impressed.</span>
<span>I was certain that this won</span>’<span>t actually work out, and that I</span>’<span>d have to write copious amount of unsafe to get the runtime behavior I want.</span>
<span>Specifically, I believed that </span><code>&amp;&#39;m mut T&lt;&#39;m&gt;</code><span> variance issue would force my hand to add </span><code>&#39;m</code><span>, </span><code>&#39;mm</code><span>, </span><code>&#39;mmm</code><span> and further lifetimes, but that didn</span>’<span>t happen.</span>
<span>For </span>“<span>owning</span>”<span> pointers, </span><code>&amp;&#39;m mut T&lt;&#39;m&gt;</code><span> turned out to work fine!</span>
<span>It</span>’<span>s only when processing you might need extra lifetimes.</span>
<code>Parser&lt;&#39;m, &#39;i, &#39;a&gt;</code><span> is at least two lifetimes more than I am completely comfortable with, but I guess I can live with that.</span></p>
<p><span>I wonder how far this style of programming can be pushed.</span>
<span>Aesthetically, I quite like that I can tell precisely how much memory the program would use!</span></p>
<p><span>Code for the post: </span><a href="http://github.com/matklad/crt">http://github.com/matklad/crt</a><span>.</span></p>
<p><span>Discussion on </span><a href="https://old.reddit.com/r/rust/comments/xx7xci/blog_post_hard_mode_rust/"><span>/r/rust</span></a><span>.</span></p>
</section>
</article>
  </div></div>
  </body>
</html>
