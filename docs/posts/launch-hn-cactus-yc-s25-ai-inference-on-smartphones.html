<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/cactus-compute/cactus">Original</a>
    <h1>Launch HN: Cactus (YC S25) – AI inference on smartphones</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/cactus-compute/cactus/blob/main/assets/banner.jpg"><img src="https://github.com/cactus-compute/cactus/raw/main/assets/banner.jpg" alt="Logo"/></a></p>
<p dir="auto">Energy-efficient AI inference framework &amp; kernels for phones &amp; AI-native hardware.
Budget and mid-range phones control over 70% of the market, but frameworks today optimise for the highend phones.
Cactus is designed bottom-up with no dependencies for all mobile devices.</p>
<p dir="auto">Example (CPU-only):</p>
<ul dir="auto">
<li>Model: Qwen3-600m-INT8</li>
<li>File size: 370-420mb</li>
<li>16-20 t/s on Pixel 6a, Galaxy S21, iPhone 11 Pro</li>
<li>50-70 t/s on Pixel 9, Galaxy S25, iPhone 16</li>
</ul>

<p dir="auto">Cactus exposes 4 levels of abstraction.</p>
<div data-snippet-clipboard-copy-content="┌─────────────────┐
│   Cactus FFI    │ ←── OpenAI compatible C API for integration  
└─────────────────┘
         │
┌─────────────────┐
│  Cactus Engine  │ ←── High-level transformer engine
└─────────────────┘
         │
┌─────────────────┐  
│  Cactus Graph   │ ←── Unified zero-copy computation graph 
└─────────────────┘
         │
┌─────────────────┐
│ Cactus Kernels  │ ←── Low-level ARM-specific SIMD operations
└─────────────────┘"><pre><code>┌─────────────────┐
│   Cactus FFI    │ ←── OpenAI compatible C API for integration  
└─────────────────┘
         │
┌─────────────────┐
│  Cactus Engine  │ ←── High-level transformer engine
└─────────────────┘
         │
┌─────────────────┐  
│  Cactus Graph   │ ←── Unified zero-copy computation graph 
└─────────────────┘
         │
┌─────────────────┐
│ Cactus Kernels  │ ←── Low-level ARM-specific SIMD operations
└─────────────────┘
</code></pre></div>
<p dir="auto">Cactus Graph is a general numerical computing framework that runs on Cactus Kernels.
Great for implementing custom models and scientific computing, like JAX for phones.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include cactus.h

CactusGraph graph;

auto a = graph.input({2, 3}, Precision::FP16);
auto b = graph.input({3, 4}, Precision::INT8);

auto x1 = graph.matmul(a, b, false);
auto x2 = graph.transpose(x1);
auto result = graph.matmul(b, x2, true);

float a_data[6] = {1.1f, 2.3f, 3.4f, 4.2f, 5.7f, 6.8f};
float b_data[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};

graph.set_input(a, a_data, Precision::FP16);
graph.set_input(b, b_data, Precision::INT8);
graph.execute();

void* output_data = graph.get_output(result);
graph.hard_reset(); 
"><pre>#<span>include</span> cactus.h

CactusGraph graph;

<span>auto</span> a = graph.input({<span>2</span>, <span>3</span>}, Precision::FP16);
<span>auto</span> b = graph.input({<span>3</span>, <span>4</span>}, Precision::INT8);

<span>auto</span> x1 = graph.matmul(a, b, <span>false</span>);
<span>auto</span> x2 = graph.transpose(x1);
<span>auto</span> result = graph.matmul(b, x2, <span>true</span>);

<span>float</span> a_data[<span>6</span>] = {<span>1</span>.<span>1f</span>, <span>2</span>.<span>3f</span>, <span>3</span>.<span>4f</span>, <span>4</span>.<span>2f</span>, <span>5</span>.<span>7f</span>, <span>6</span>.<span>8f</span>};
<span>float</span> b_data[<span>12</span>] = {<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>};

graph.set_input(a, a_data, Precision::FP16);
graph.set_input(b, b_data, Precision::INT8);
graph.execute();

<span>void</span>* output_data = graph.get_output(result);
graph.hard_reset(); 
</pre></div>
<p dir="auto">Cactus Engine is a transformer inference engine built on top of Cactus Graphs.
It is abstracted via Cactus Foreign Function Interface.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include cactus.h

const char* model_path = &#34;path/to/weight/folder&#34;;
cactus_model_t model = cactus_init(model_path, 2048);

const char* messages = R&#34;([
    {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;},
    {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;/nothink My name is Henry Ndubuaku&#34;}
])&#34;;

const char* options = R&#34;({
    &#34;temperature&#34;: 0.1,
    &#34;top_p&#34;: 0.95,
    &#34;top_k&#34;: 20,
    &#34;max_tokens&#34;: 50,
    &#34;stop_sequences&#34;: [&#34;&lt;|im_end|&gt;&#34;]
})&#34;;

char response[1024];
int result = cactus_complete(model, messages, response, sizeof(response), options, nullptr, nullptr, nullptr);"><pre>#<span>include</span> cactus.h

<span>const</span> <span>char</span>* model_path = <span><span>&#34;</span>path/to/weight/folder<span>&#34;</span></span>;
<span>cactus_model_t</span> model = cactus_init(model_path, <span>2048</span>);

<span>const</span> <span>char</span>* messages = <span><span>R&#34;(</span>[</span>
<span>    {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;},</span>
<span>    {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;/nothink My name is Henry Ndubuaku&#34;}</span>
<span>]<span>)&#34;</span></span>;

<span>const</span> <span>char</span>* options = <span><span>R&#34;(</span>{</span>
<span>    &#34;temperature&#34;: 0.1,</span>
<span>    &#34;top_p&#34;: 0.95,</span>
<span>    &#34;top_k&#34;: 20,</span>
<span>    &#34;max_tokens&#34;: 50,</span>
<span>    &#34;stop_sequences&#34;: [&#34;&lt;|im_end|&gt;&#34;]</span>
<span>}<span>)&#34;</span></span>;

<span>char</span> response[<span>1024</span>];
<span>int</span> result = cactus_complete(model, messages, response, <span>sizeof</span>(response), options, <span>nullptr</span>, <span>nullptr</span>, <span>nullptr</span>);</pre></div>
<p dir="auto">With tool support:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const char* tools = R&#34;([
    {
        &#34;function&#34;: {
            &#34;name&#34;: &#34;get_weather&#34;,
            &#34;description&#34;: &#34;Get weather for a location&#34;,
            &#34;parameters&#34;: {
                &#34;properties&#34;: {
                    &#34;location&#34;: {
                        &#34;type&#34;: &#34;string&#34;,
                        &#34;description&#34;: &#34;City name&#34;,
                        &#34;required&#34;: true
                    }
                },
                &#34;required&#34;: [&#34;location&#34;]
            }
        }
    }
])&#34;;

int result = cactus_complete(model, messages, response, sizeof(response), options, tools, nullptr, nullptr);"><pre><span>const</span> <span>char</span>* tools = <span><span>R&#34;(</span>[</span>
<span>    {</span>
<span>        &#34;function&#34;: {</span>
<span>            &#34;name&#34;: &#34;get_weather&#34;,</span>
<span>            &#34;description&#34;: &#34;Get weather for a location&#34;,</span>
<span>            &#34;parameters&#34;: {</span>
<span>                &#34;properties&#34;: {</span>
<span>                    &#34;location&#34;: {</span>
<span>                        &#34;type&#34;: &#34;string&#34;,</span>
<span>                        &#34;description&#34;: &#34;City name&#34;,</span>
<span>                        &#34;required&#34;: true</span>
<span>                    }</span>
<span>                },</span>
<span>                &#34;required&#34;: [&#34;location&#34;]</span>
<span>            }</span>
<span>        }</span>
<span>    }</span>
<span>]<span>)&#34;</span></span>;

<span>int</span> result = cactus_complete(model, messages, response, <span>sizeof</span>(response), options, tools, <span>nullptr</span>, <span>nullptr</span>);</pre></div>
<p dir="auto">This makes it easy to write Cactus bindings for any language.
Header files are self-documenting but documentation contributions are welcome.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Using Cactus in your apps</h2><a id="user-content-using-cactus-in-your-apps" aria-label="Permalink: Using Cactus in your apps" href="#using-cactus-in-your-apps"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Cactus SDKs run 500k+ weekly inference tasks in production today, try them!</p>
<a href="https://github.com/cactus-compute/cactus-flutter">
  <img alt="Flutter" src="https://camo.githubusercontent.com/d57d3164dc073311fc19c11367c7aa4011bab2182b3c5f1bc5f0c5aef3471b8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466c75747465722d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d466c7574746572266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Flutter-grey.svg?style=for-the-badge&amp;logo=Flutter&amp;logoColor=white"/>
</a> <a href="https://github.com/cactus-compute/cactus-react">
  <img alt="React Native" src="https://camo.githubusercontent.com/fe61c2055c44a2fab881671623eba1a62b544ffb5b87630950d1fb1d07ad932e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742532304e61746976652d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d7265616374266c6f676f436f6c6f723d253233363144414642" data-canonical-src="https://img.shields.io/badge/React%20Native-grey.svg?style=for-the-badge&amp;logo=react&amp;logoColor=%2361DAFB"/>
</a> <a href="https://github.com/cactus-compute/cactus-kotlin">
  <img alt="Kotlin Multiplatform" src="https://camo.githubusercontent.com/6256a84b4568b4c8b1ced300592082852c763cd18cac9d1411db5047de672f76/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4b6f746c696e5f4d756c7469706c6174666f726d2d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f746c696e266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Kotlin_Multiplatform-grey.svg?style=for-the-badge&amp;logo=kotlin&amp;logoColor=white"/>
</a>

<a href="https://cactuscompute.com/docs" rel="nofollow">
  <img alt="Documentation" src="https://camo.githubusercontent.com/66eae253333dba0dc826720ca250cd806b2b8a9bb8e07f64f4c12ab7b974c90b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63756d656e746174696f6e2d3441393045323f7374796c653d666f722d7468652d6261646765266c6f676f3d676974626f6f6b266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Documentation-4A90E2?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white"/>
</a> <a href="https://discord.gg/bNurx3AXTJ" rel="nofollow">
  <img alt="Discord" src="https://camo.githubusercontent.com/62d3d35241760cf174631c4e6b5f4503c0a6b34640fd306e36a829ab5ec47b14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d3538363546323f7374796c653d666f722d7468652d6261646765266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white"/>
</a>

<a href="https://apps.apple.com/gb/app/cactus-chat/id6744444212" rel="nofollow">
  <img alt="Download iOS App" src="https://camo.githubusercontent.com/35be197596b80ef392cccd1610b6204c38198b871e5c90d2c8c02d3b9e46e28c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5472795f694f535f44656d6f2d677265793f7374796c653d666f722d7468652d6261646765266c6f676f3d6170706c65266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Try_iOS_Demo-grey?style=for-the-badge&amp;logo=apple&amp;logoColor=white"/>
</a> <a href="https://play.google.com/store/apps/details?id=com.rshemetsubuser.myapp&amp;pcampaignid=web_share" rel="nofollow">
  <img alt="Download Android App" src="https://camo.githubusercontent.com/7b16e937255afaf712ca03a71a3c1d1b93f15173c637e0b2ca779d6c77f03050/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5472795f416e64726f69645f44656d6f2d677265793f7374796c653d666f722d7468652d6261646765266c6f676f3d616e64726f6964266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Try_Android_Demo-grey?style=for-the-badge&amp;logo=android&amp;logoColor=white"/>
</a>
<div dir="auto"><h2 tabindex="-1" dir="auto">Contributing or Using the Repo</h2><a id="user-content-contributing-or-using-the-repo" aria-label="Permalink: Contributing or Using the Repo" href="#contributing-or-using-the-repo"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can run these codes directly on Macbooks with Apple chips due to their design.
Performance gain is observed in mobile devices but for testing during development,
Vanilla M3 CPU-only can run Qwen3-600m-INT8 at 60-70 toks/sec, use the following:</p>
<ol dir="auto">
<li><strong>Generate weights from HuggingFace model:</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python3 tools/convert_hf.py Qwen/Qwen3-0.6B weights/qwen3-600m-i8/ --precision INT8"><pre>python3 tools/convert_hf.py Qwen/Qwen3-0.6B weights/qwen3-600m-i8/ --precision INT8</pre></div>
<ol start="2" dir="auto">
<li><strong>Build and test:</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./tests/run.sh # remember to chmod +x any script first time
"><pre>./tests/run.sh <span><span>#</span> remember to chmod +x any script first time</span>
</pre></div>

<ul dir="auto">
<li>Gemma, SmolVLM, Liquid, Kitten, Vosk etc.</li>
<li>SMMLA, NPU &amp; DSP for high-end phones.</li>
<li>INT4 support for 1B+ models.</li>
<li>Python tools for porting Torch/JAX cactus.</li>
</ul>
<p dir="auto">Preliminary results:</p>
<ul dir="auto">
<li>Qwen3-4B-INT4 on iPhone 16 Pro NPU = 21 t/s</li>
</ul>

<p dir="auto">While Cactus can be used for all Apple devices including Macbooks, for computers/AMD/Intel/Nvidia generally,
please use HuggingFace, Llama.cpp, Ollama, vLLM, MLX. They&#39;re built for those, support x86, and are all great!</p>
</article></div></div>
  </body>
</html>
