<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.sturdystatistics.com/posts/show_hn/">Original</a>
    <h1>State of Show HN: 2025</h1>
    
    <div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">





<p>Macroeconomics, DIY Hardware and AI-Driven Voting Pools</p>
<p>I downloaded every Show HN post since the site was launched and ran them through a hierarchical topic model. I set out to discover what the Hacker News community finds interesting but in the process I ended up uncovering macro-economic trends, evidence of voting rings/fraud, and subtle shifts in behavior over the lifespan of the post</p>
<section id="what-does-hacker-news-like">
<h2 data-anchor-id="what-does-hacker-news-like">What Does Hacker News Like?</h2>
<div>
<div id="863c1788" data-execution_count="1">
<div>
<div>                                                </div>
</div>
</div>
</div>
<figcaption>
<strong>Figure 1:</strong> Treemap visualization of every Show HN posts. Grouped first by year, then by high level topic group, then by granular topic. Each box is colored by the likelihood of its category to receive over 100 points. Dark is higher likelihood, lighter is lower likelihood.
</figcaption>
<details id="main-code-block">
<summary>
Reproducible Code
</summary>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span># pip install sturdy-stats-sdk plotly</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span>from</span> sturdystats <span>import</span> Index</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span>from</span> plotly <span>import</span> express <span>as</span> px</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>index <span>=</span> Index(<span>id</span><span>=</span><span>&#34;index_f2ffe2f7901845c59c15aab45685fa3c&#34;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df <span>=</span> index.queryMeta(<span>&#34;&#34;&#34;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span>WITH t AS (</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span>    SELECT </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span>        UNNEST(sum_topic_counts_vals) as topic_vals,</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span>        UNNEST(sum_topic_counts_inds) - 1 as topic_id, -- duckdb is 1 indexed</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span>        year(published::DATE) as year,</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span>        score</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span>    FROM doc</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span>)</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span>SELECT </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span>    topic_id,</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span>    year,</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span>    count(*) as n_posts,</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span>    avg(score) as avg_score,</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span>    avg((score &gt; 10)::int) as p10,</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span>    avg((score &gt; 100)::int) as p100,</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span>FROM t</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span>WHERE topic_vals &gt; 5</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span>GROUP BY topic_id, year</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span>ORDER BY topic_id, year</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span>&#34;&#34;&#34;</span>, paginate<span>=</span><span>True</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>tmp <span>=</span> index.topicSearch(limit<span>=</span><span>500</span>).set_index(<span>&#34;topic_id&#34;</span>).to_dict()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>df[<span>&#34;topic&#34;</span>] <span>=</span> (df.topic_id).<span>apply</span>(tmp[<span>&#34;short_title&#34;</span>].get)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>df[<span>&#34;topic_group&#34;</span>] <span>=</span> (df.topic_id).<span>apply</span>(tmp[<span>&#34;topic_group_short_title&#34;</span>].get)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>df <span>=</span> df.dropna().copy()</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>df.sample(<span>5</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span>## Add a prior to require a higher standard of evidence </span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>df[<span>&#34;P(score&gt;100)&#34;</span>] <span>=</span> df.<span>apply</span>(<span>lambda</span> x: (x[<span>&#34;p100&#34;</span>]<span>*</span>x[<span>&#34;n_posts&#34;</span>]<span>+</span> <span>2</span>)<span>/</span> (x[<span>&#34;n_posts&#34;</span>]<span>+</span><span>50</span>), axis<span>=</span><span>1</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>df[<span>&#34;title&#34;</span>] <span>=</span> <span>&#34;Show HN&lt;br&gt;Performance&#34;</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>fig <span>=</span> px.treemap(df, path<span>=</span>[<span>&#34;title&#34;</span>, <span>&#34;year&#34;</span>, <span>&#34;topic_group&#34;</span>, <span>&#34;topic&#34;</span>], </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            values<span>=</span><span>&#34;n_posts&#34;</span>, color_continuous_scale<span>=</span><span>&#34;greens&#34;</span>,</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            color<span>=</span><span>&#34;P(score&gt;100)&#34;</span>, height<span>=</span><span>600</span>,  )</span></code></pre></div>
</details>
<p>If a picture is a thousand words, I like to think this interactive treemap is at least one thousand and one. You can click into a box to dig into the year or topic group. The first thing that jumps out is just how much bigger the 2025 box is than any other year. The second is how much lighter the 2025 box is compared to the previous few years.</p>
<p>I enjoy history, but I am often told that people care much more about what is happening now. So let’s dig into specifically 2025.</p>
<section id="these-are-the-top-performing-topics-in-2025">
<h4 data-anchor-id="these-are-the-top-performing-topics-in-2025">These are the top performing topics in 2025:</h4>
<table>
<thead>
<tr>
<th>topic</th>
<th>P(score&gt;100)</th>
</tr>
</thead>
<tbody>
<tr>
<td>DIY Hardware IoT Projects</td>
<td>0.0939227</td>
</tr>
<tr>
<td>Open Source Projects</td>
<td>0.0879849</td>
</tr>
<tr>
<td>Error Handling and Debugging</td>
<td>0.0786517</td>
</tr>
<tr>
<td>Programming Language Interpreters</td>
<td>0.077095</td>
</tr>
<tr>
<td>Life Narratives</td>
<td>0.0675676</td>
</tr>
</tbody>
</table>
<p>Again, what sticks out to me is the discrepency between the average 2025 post’s average performance compared to the previous few years. The top performing topic in 2025 has the same likelihood of receiving 100 points as the average post in 2022. That’s a discrepency that I want to dig a bit deeper into.</p>
</section>
</section>
<section id="performance-across-years">
<h2 data-anchor-id="performance-across-years">Performance Across Years</h2>
<div>
<figure>
<p><img src="https://podviaznikov.com/writings/Show-HN-cumsum.png"/></p>
<figcaption>Cumulative sum of likilihood a post received &lt;= N points, stratified by year. You can see that there are three distinct groups. a post in 2025 has the lowest likelihood with a 11% chance of receiving more than 10 points, while 2022 posts have the same likelihood to receive 60 points.</figcaption>
</figure>
</div>
<details>
<summary>
Reproducible Code
</summary>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span># pip install sturdy-stats-sdk seaborn </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span>from</span> sturdystats <span>import</span> Index</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span>import</span> seaborn <span>as</span> sns</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>index <span>=</span> Index(<span>id</span><span>=</span><span>&#34;index_f2ffe2f7901845c59c15aab45685fa3c&#34;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df <span>=</span> index.queryMeta(<span>&#34;&#34;&#34;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span>    SELECT year(timestamp::TIMESTAMP) as year, </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span>    score FROM doc </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span>    ORDER BY doc_id&#34;&#34;&#34;</span>, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>paginate<span>=</span><span>True</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span>=</span>(<span>10</span>, <span>6</span>))</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>Xmax <span>=</span> <span>100</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>tmpdf <span>=</span> df.loc[df.year <span>&gt;</span> <span>2020</span>].copy().sort_values(<span>&#34;year&#34;</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>tmpdf[<span>&#34;year&#34;</span>] <span>=</span> tmpdf.year.astype(<span>str</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>tmpdf[<span>&#34;score&#34;</span>] <span>=</span> tmpdf.score.<span>apply</span>(<span>lambda</span> x: <span>min</span>(x, Xmax))</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>sns.displot(tmpdf, x<span>=</span><span>&#34;score&#34;</span>, kind<span>=</span><span>&#34;ecdf&#34;</span>, hue<span>=</span><span>&#34;year&#34;</span> )</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span>&#39;Score Distribution by Year (CDF)&#39;</span>, fontsize<span>=</span><span>14</span>, fontweight<span>=</span><span>&#39;bold&#39;</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span>&#39;Score&#39;</span>, fontsize<span>=</span><span>12</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span>&#39;Density&#39;</span>, fontsize<span>=</span><span>12</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span>10</span>, Xmax])</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span>.75</span>, <span>1.0</span>])</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</details>
<p>There are three distinct groups: 2022 as the heyday of Show HN posts, 2021, 2023, &amp; 2024 as still extremely highly performing, and 2025 with a significant performance reduction. If I were to make a guess at the root cause of this difference, I would have two (not necessarily contradictory) theories.</p>
<p>The first is tied to the software job market. I can easily imagine that the combination of remote work and post-covid tech boom drove much more overall Hacker News engagement and more interesting Show HN projects. The job market and remote work receded a little in ’23 and ’24 but morale seems to have cratered in 2025. Which leads to my second theory.</p>
<p>AI has driven much more content, by both aiding in its creation and creating a cohort of startups and companies chasing a piece of the pie. This AI-driven content tends to be more shallow, and its noise makes it harder to discover genuine, interesting content. There is some evidence for this theory in the expontential growth in the quantity of hacker news posts from 2022 onwards.</p>
<p>These are both guesses. I don’t have an easy avenue to dig into the economic theory, but I do want to dig a bit deeper into the composition of posts in 2025.</p>
</section>
<section id="digging-into-2025">
<h2 data-anchor-id="digging-into-2025">Digging into 2025</h2>
<p>The first thing I want to dig into is the change in topics of viral posts. Take a look at this <em>slope plot</em>, which shows the change in content of all posts between 2024 and 2025. Each side of the plot lists topics by rank, and a line connects their 2024 position to their 2025 position; topics which decreased in prominence have negative slopes, shown in <em>red</em>. Topics which surged in prominence have positive slopes, shown in <em>blue</em>.</p>

<div>
    
</div>
    


<div>
    
</div>
    

<p>The last thing I wanted to dig into is the audience segmentation aspect of Hacker News. There’s two distinct audiences viewing posts. The first is the much more hardcore technical readers that view the “New” and “Show” pages. The second is the more mass market crowd that goes on the front page.</p>

<div>
    
</div>
    

<p>So some takeaways I have is:</p>
<ol type="1">
<li><p>The real heavy-lifting for the performance of “DIY Hardware” projects is really coming from the first wave of Hacker News readers (though it does get a sizeable boost from the front page audience as well).</p></li>
<li><p>Nearly every AI related topic does worse once it clears the 10 point threshold than any other category. This means that either the people looking through the New and Show sections are disporportionately interested in AI. This is very possible, but from my interaction with this crowd from my posts, these users tend to be more technically minded (think DIY hardware, rather than landing-page builders).</p>
<p>However, my Spidey-sense is going off a little bit. AI has received a massive wave of funding for startups and enterprises have carved out budget space to invest in solutions. This is obviously not hard evidence, but circumstantially, it looks like there is a evidence that some level of voting rings are on within this AI posts.</p>
<p>However, either explanation would explain why 2025 is such a challenging year for viral Show HN posts. There exists this set of topics that are more frequent than ever, that quickly garner early points, but do not resonate with the broader audience. Beyond that is speculation on my part.</p></li>
</ol>
</section>
<section id="whats-the-best-time-to-post">
<h2 data-anchor-id="whats-the-best-time-to-post">What’s the best time to post?</h2>
<p>Ah the question you really wanted to know. This was actually the first question I asked as well. I did a simple SQL query estimate. However, Mike McCourt saw a chance to apply a Gelman-style hierarchical mixed-effects model to better leverage the data to answer this question. I won’t spoil his analysis but I’ll leave you with a little preview …</p>
<div>
<figure>
<p><img src="https://podviaznikov.com/writings/heatmap.png"/></p>
<figcaption>HN Heatmap</figcaption>
</figure>
</div>


</section>

</main> <!-- /main -->

</div></div>
  </body>
</html>
