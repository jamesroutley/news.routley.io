<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41598-022-20460-9">Original</a>
    <h1>Deep language algorithms predict semantic comprehension from brain activity</h1>
    
    <div id="readability-page-1" class="page"><div>
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div id="Abs1-section"><h2 id="Abs1">Abstract</h2><p>Deep language algorithms, like GPT-2, have demonstrated remarkable abilities to process text, and now constitute the backbone of automatic translation, summarization and dialogue. However, whether these models encode information that relates to human comprehension still remains controversial. Here, we show that the representations of GPT-2 not only map onto the brain responses to spoken stories, but they also predict the extent to which subjects understand the corresponding narratives. To this end, we analyze 101 subjects recorded with functional Magnetic Resonance Imaging while listening to 70 min of short stories. We then fit a linear mapping model to predict brain activity from GPT-2’s activations. Finally, we show that this mapping reliably correlates (<span>\(\mathcal {R}=0.50, p&lt;10^{-15}\)</span>) with subjects’ comprehension scores as assessed for each story. This effect peaks in the angular, medial temporal and supra-marginal gyri, and is best accounted for by the long-distance dependencies generated in the deep layers of GPT-2. Overall, this study shows how deep language models help clarify the brain computations underlying language comprehension.</p></div></section>
            

                
            
                <div>
                <p>In less than two years, language transformers like GPT-2 have revolutionized the field of natural language processing (NLP). These deep learning architectures are typically trained on very large corpora to complete partially-masked texts, and provide a one-fit-all solution to translation, summarization, and question-answering tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Radford, A. et al. Language models are unsupervised multitask learners. OpenAI blog 1(8), 9 (2019)." href="#ref-CR1" id="ref-link-section-d11833034e403">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. 
                  arXiv:1810.04805
                  
                 [cs], (2019)." href="#ref-CR2" id="ref-link-section-d11833034e403_1">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R. R., &amp; Le, Q. V. XLNet: Generalized Autoregressive Pretraining for Language Understanding. 
                  arXiv:1906.08237
                  
                 [cs], (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR3" id="ref-link-section-d11833034e406">3</a></sup>. These advances raise a major question: do these algorithms process language like the human brain? Recent studies suggest that they partially do: the hidden representations of various deep neural networks have shown to linearly predict single-sample fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C., Gramfort, A., &amp; King, J. R. Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects. In EMNLP 2021-Conference on Empirical Methods in Natural Language Processing, (2021a)." href="#ref-CR4" id="ref-link-section-d11833034e410">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="#ref-CR5" id="ref-link-section-d11833034e410_1">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proc. Natl. Acad. Sci. 118(45), e2105646118. 
                  https://doi.org/10.1073/pnas.2105646118
                  
                 (2021)." href="#ref-CR6" id="ref-link-section-d11833034e410_2">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="#ref-CR7" id="ref-link-section-d11833034e410_3">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C., Gramfort, A., &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In International Conference on Machine Learning, 1336–1348. PMLR, (2021b)." href="#ref-CR8" id="ref-link-section-d11833034e410_4">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hale, J., Campanelli, L., Li, J., Bhattasali, S., Pallier, C. &amp; Brennan, J. Neuro-computational models of language processing. Annu. Rev. Linguist., (2021)." href="#ref-CR9" id="ref-link-section-d11833034e410_5">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Anderson, A. J. et al. Deep artificial neural networks reveal a distributed cortical network encoding propositional sentence-level meaning. J. Neurosci. 41(18), 4100–4119. 
                  https://doi.org/10.1523/JNEUROSCI.1152-20.2021
                  
                 (2021)." href="#ref-CR10" id="ref-link-section-d11833034e410_6">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jingyuan, S., Shaonan, W., Jiajun, Z. &amp; Chengqing, Z. Neural encoding and decoding with distributed sentence representations. IEEE Trans. Neural Netw. Learn. Syst. 32(2), 589–603. 
                  https://doi.org/10.1109/TNNLS.2020.3027595
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR11" id="ref-link-section-d11833034e413">11</a></sup>, MEG<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e417">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e420">7</a></sup>, and intracranial responses to spoken and written texts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proc. Natl. Acad. Sci. 118(45), e2105646118. 
                  https://doi.org/10.1073/pnas.2105646118
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR6" id="ref-link-section-d11833034e424">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Goldstein, A. et al. Thinking ahead: Prediction in context as a keystone of language in humans and machines. bioRxiv
                  https://doi.org/10.1101/2020.12.02.403477
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR12" id="ref-link-section-d11833034e427">12</a></sup>.</p><p>However, whether these models encode, retrieve and pay attention to information that specifically relates to behavior in general, and to comprehension in particular remains controversial<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., &amp; Kiela, D. Adversarial nli: A new benchmark for natural language understanding. arXiv preprint
                  arXiv:1910.14599
                  
                , (2019)." href="#ref-CR13" id="ref-link-section-d11833034e434">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? 
                  arXiv:2101.02258
                  
                 [cs], (2021)." href="#ref-CR14" id="ref-link-section-d11833034e434_1">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hupkes, D., Dankers, V., Mul, M. &amp; Bruni, E. Compositionality decomposed: How do neural networks generalise?. J. Artif. Intell. Res. 67, 757–795 (2020)." href="#ref-CR15" id="ref-link-section-d11833034e434_2">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. 
                  arXiv:2008.01766
                  
                 [cs], (2021)." href="#ref-CR16" id="ref-link-section-d11833034e434_3">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Linzen, T. &amp; Baroni, M. Syntactic structure from deep learning. Annu. Rev. Linguist. 7, 195–212 (2021)." href="#ref-CR17" id="ref-link-section-d11833034e434_4">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="McClelland, J. L., Hill, F., Rudolph, M., Baldridge, J. &amp; Schütze, H. Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models. Proc. Natl. Acad. Sci. 117(42), 25966–25974. 
                  https://doi.org/10.1073/pnas.1910416117
                  
                 (2020)." href="#ref-CR18" id="ref-link-section-d11833034e434_5">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Gary, M. Gpt-2 and the nature of intelligence. The Gradient. 
                  https://thegradient.pub/gpt2-and-the-nature-of-intelligence/
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR19" id="ref-link-section-d11833034e437">19</a></sup>. This issue is all-the-more relevant that the behavior of deep language models remains challenged by complex questions, including subject-verb agreement<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? 
                  arXiv:2101.02258
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR14" id="ref-link-section-d11833034e441">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Hupkes, D., Dankers, V., Mul, M. &amp; Bruni, E. Compositionality decomposed: How do neural networks generalise?. J. Artif. Intell. Res. 67, 757–795 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR15" id="ref-link-section-d11833034e444">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Linzen, T. &amp; Baroni, M. Syntactic structure from deep learning. Annu. Rev. Linguist. 7, 195–212 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR17" id="ref-link-section-d11833034e447">17</a></sup>, causal reasoning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. 
                  arXiv:2008.01766
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR16" id="ref-link-section-d11833034e451">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Gary, M. Gpt-2 and the nature of intelligence. The Gradient. 
                  https://thegradient.pub/gpt2-and-the-nature-of-intelligence/
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR19" id="ref-link-section-d11833034e454">19</a></sup>, story generation, text summarization as well as dialogue and question answering <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Holtzman, A., Buys, J., Du, L., Forbes, M. &amp; Choi, Y. The curious case of neural text degeneration. 
                  arXiv:1904.09751
                  
                 [cs], (2020)." href="#ref-CR20" id="ref-link-section-d11833034e458">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wiseman, S., Shieber, S. M. &amp; Rush, A. M. Challenges in data-to-document generation. 
                  arXiv:1707.08052
                  
                 [cs], (2017)." href="#ref-CR21" id="ref-link-section-d11833034e458_1">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Thakur, N., Reimers, N., Ruckle, A., Srivastava, A., &amp; Gurevych, I. BEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models. 
                  arXiv:2104.08663
                  
                 [cs], (2021)." href="#ref-CR22" id="ref-link-section-d11833034e458_2">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W. &amp; Liu, P.J. Exploring the limits of transfer learning with a unified text-to-text transformer. 
                  arXiv:1910.10683
                  
                 [cs, stat], (2020)." href="#ref-CR23" id="ref-link-section-d11833034e458_3">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Krishna, K., Roy, A. &amp; Iyyer, M. Hurdles to progress in long-form question answering. 
                  arXiv:2103.06332
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR24" id="ref-link-section-d11833034e461">24</a></sup>.</p><p>To explore the relationship between comprehension and the representations of GPT-2, we compare GPT-2’s activations to the functional Magnetic Resonance Imaging of 101 subjects listening to 70min of seven short stories. We first quantify this similarity with a “brain score” (M)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc. Natl. Acad. Sci. 111(23), 8619–8624. 
                  https://doi.org/10.1073/pnas.1403112111
                  
                 (2014)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR25" id="ref-link-section-d11833034e468">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532(7600), 453–458. 
                  https://doi.org/10.1038/nature17637
                  
                 (2016)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR26" id="ref-link-section-d11833034e471">26</a></sup>. We then evaluate how brain scores systematically vary with – and thus predict – semantic comprehension, as individually assessed by a questionnaire at the end of each story. Finally, by decomposing and manipulating GPT-2’s processes, we identify (1) the brain regions, (2) the levels of representations (phonological, lexical, compositional), and (3) the attentional gating that specifically relates to this prediction.</p><div><p>The alignment identified between behavior, brain activations and the representations of GPT-2 suggest that comprehension relies on a specific computational hierarchy, whereby the auditory cortices integrate information over short time windows, and the fronto-parietal areas combine supra-lexical information over long time windows.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Figure 1"><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Figure 1</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="264"/></picture></a></div><p>Brain scores and their correlation with comprehension. (<b>A</b>) 101 subjects listen to narratives (70 min of unique audio stimulus in total) while their brain signal is recorded using functional MRI. At the end of each story, a questionnaire is submitted to each subject to assess their understanding, and the answers are summarized into a comprehension score specific to each (narrative, subject) pair (grey box). In parallel (blue box on the left), we measure the mapping between the subject’s brain activations and the activations of GPT-2, a deep network trained to predict a word given its past context, both elicited by the same narrative. To this end, a linear spatio-temporal model (<span>\(f \circ g\)</span>) is fitted to predict the brain activity of one voxel <i>Y</i>, given GPT-2 activations <i>X</i> as input. The degree of mapping, called “brain score” is defined for each voxel as the Pearson correlation between predicted and actual brain activity on held-out data (blue equation, cf. Methods). Finally, we test the correlation between the comprehension scores of the subjects and their corresponding brain scores using Pearson’s correlation (red equation). A positive correlation means that the representations shared across the brain and GPT-2 are key for the subjects to understand a narrative. (<b>B</b>) Brain scores (fMRI predictability) of the activations of the eighth layer of GPT-2. Scores are averaged across subjects, narratives, and voxels within brain regions (142 regions in each hemisphere, following a subdivision of Destrieux Atlas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. Neuroimage 53(1), 1–15. 
                  https://doi.org/10.1016/j.neuroimage.2010.06.010
                  
                 (2010)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR27" id="ref-link-section-d11833034e525">27</a></sup>, cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">A</a>). Only significant regions are displayed, as assessed with a two-sided Wilcoxon test across (subject, narrative) pairs, testing whether the brain score is significantly different from zero (threshold: 0.05). (<b>C</b>) Brain scores, averaged across fMRI voxels, for different activation spaces: phonological features (word rate, phoneme rate, phonemes, tone and stress, in green), the non-contextualized word embedding of GPT-2 (“Word”, light blue) and the activations of the contextualized layers of GPT-2 (from layer one to layer twelve, in blue). The error bars refer to the standard error of the mean across (subject, narrative) pairs (<i>n</i> = 237). (<b>D</b>) Comprehension and GPT-2 brain scores, averaged across voxels, for each (subject, narrative) pair. In red, Pearson’s correlation between the two (denoted <span>\(\mathcal {R}\)</span>), the corresponding regression line and the 95% confidence interval of the regression coefficient. (<b>E</b>) Correlations (<span>\(\mathcal {R}\)</span>) between comprehension and brain scores over regions of interest. Brain scores are first averaged across voxels within brain regions (similar to <b>B</b>), then correlated to the subjects’ comprehension scores. Only significant correlations are displayed (threshold: 0.05). (<b>F</b>) Correlation scores (<span>\(\mathcal {R}\)</span>) between comprehension and the subjects’ brain mapping with phonological features (M(Phonemic) (i), the share of the word-embedding mapping that is not accounted by phonological features <span>\(\mathcal {M}(\mathrm {Word}) - \mathcal {M}(\mathrm {Phonemic})\)</span> (ii) and the share of the GPT-2 eighth layer’s mapping not accounted by the word-embedding <span>\(\mathcal {M}(\mathrm {GPT2}) - \mathcal {M}(\mathrm {Word})\)</span> (iii). (<b>G</b>) Relationship between the average GPT-2-to-brain mapping (eighth layer) per region of interest (similar to <b>B</b>), and the corresponding correlation with comprehension (<span>\(\mathcal {R}\)</span>, similar to <b>D</b>). Only regions of the left hemisphere, significant in both (<b>B</b>) and (<b>E</b>) are displayed. In black, the top ten regions in terms of brain and correlation scores (cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">A</a> for the acronyms). Significance in (<b>D</b>), (<b>E</b>) and (<b>F</b>) is assessed with Pearson’s <i>p</i>-value provided by SciPy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Virtanen, P. et al. SciPy 1.0 contributors. SciPy 1.0: Fundamental algorithms for scientific computing in python. Nat. Methods 17, 261–272. 
                  https://doi.org/10.1038/s41592-019-0686-2
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR28" id="ref-link-section-d11833034e751">28</a></sup>. In (<b>B</b>), (<b>E</b>) and (<b>F</b>), <i>p</i>-values are corrected for multiple comparison using a False Discovery Rate (Benjamin/Hochberg) over the 2 <span>\(\times\)</span> 142 regions of interest.</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Figure 2"><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Figure 2</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="636"/></picture></a></div><p>Impact of GPT-2’s attention span on brain scores and comprehension scores. (<b>A</b>) The heatmap displays the average (across subjects, stories and voxels) brain scores as a function of attention span (“distance”) and layers. The top line displays the layer coefficients for each attention span (averaged across subjects, stories and voxels). The right line displays the distance coefficient for each layer (averaged across subjects, stories and voxels). The error bars correspond to the Standard Errors of the Mean (SEM) across subject-story pairs. (<b>B</b>) Distance coefficients for each brain region (averaged across subjects and stories). Statistical significance is assessed with a Wilcoxon test across subject-story pairs. (<b>C</b>) Layer coefficients for each brain region (averaged across subjects and stories). (<b>D</b>)–(<b>F</b>) Similar as (<b>A</b>)–(<b>C</b>), but the layer (and distance, respectively) coefficients now assess the relationship between layer (or distance, respectively) and comprehension scores. Statistical significance is assessed using a bootstrapping procedure with 1000 subsamples of subject-story pairs. Error bars are standard deviation across subsamples. For all brain maps, only significant values are displayed (<span>\(p&lt;0.05\)</span> after FDR correction across brain regions).</p></div></figure></div></div><section data-title="Results"><div id="Sec1-section"><h2 id="Sec1">Results</h2><div id="Sec1-content"><h3 id="Sec2">GPT-2’s activations linearly map onto fMRI responses to spoken narratives</h3><p>To assess whether GPT-2 generates similar representations to those of the brain, we analyze the Narratives dataset: 101 subjects listening to seven short stories while their brain activity is recorded with fMRI. Note that subjects do not necessarily listen to the same stories (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig3">3</a>). First, we evaluate, for each voxel, subject and narrative independently, whether the fMRI responses can be predicted from a linear combination of GPT-2’s activations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>A). We summarize the precision of this mapping with a brain score <span>\(\mathcal {M}\)</span>: i.e. the correlation between the true fMRI responses and the fMRI responses linearly predicted, with cross-validation, from GPT-2’s responses to the same narratives (cf. Methods).</p><p>To mitigate the spatial resolution of fMRI and the necessity to correct voxel analyses for multiple comparisons, we here report either 1) the average brain scores across voxels or 2) the average score within each region of interest (<span>\(n=314\)</span>, following an automatic subdivision of the Destrieux atlas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. Neuroimage 53(1), 1–15. 
                  https://doi.org/10.1016/j.neuroimage.2010.06.010
                  
                 (2010)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR27" id="ref-link-section-d11833034e919">27</a></sup>, cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">A</a>), and correct statistical tests for multiple comparisons across the brain regions. Consistent with previous findings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e926">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e929">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Jain, S. &amp; Huth, A. G. Incorporating context into language encoding models for fMRI. preprint, Neuroscience (2018)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR29" id="ref-link-section-d11833034e932">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Schrimpf, M., Kubilius, J., Hong, H., Majaj, N.J., Rajalingham, R., Issa, E.B., Kar, K., Bashivan, P., Prescott-Roy, J., Geiger, F. &amp; Schmidt, K., Brain-score: Which artificial neural network for object recognition is most brain-like? preprint, Neuroscience (2018)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR30" id="ref-link-section-d11833034e935">30</a></sup>, these brain scores are significant over a distributed and bilateral cortical network, and peak in middle- and superior-temporal gyri and sulci, as well as in the supra-marginal and the infero-frontal cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e939">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e942">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Jain, S. &amp; Huth, A. G. Incorporating context into language encoding models for fMRI. preprint, Neuroscience (2018)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR29" id="ref-link-section-d11833034e945">29</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>B).</p><p>By separately analyzing the activations of each layer of GPT-2, we confirm that middle layers best map onto the brain (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>C), as previously reported<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e959">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e962">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Jain, S. &amp; Huth, A. G. Incorporating context into language encoding models for fMRI. preprint, Neuroscience (2018)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR29" id="ref-link-section-d11833034e965">29</a></sup>. For clarity, the following analyses focus on the activations extracted from the eighth layer, i.e. the layer with the highest brain score on average across voxels (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>C). However, the results generalize to other contextual layers of GPT-2 (Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">E</a>, Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">S4</a>).</p><h3 id="Sec3">The brain predictions of GPT-2 correlate with semantic comprehension</h3><p>Does the linear mapping between GPT-2 and the brain reflect a fortunate correspondence<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e986">7</a></sup>? Or, on the contrary, does it reflect similar representations of high-level semantics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Caucheteux, C., Gramfort, A., &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In International Conference on Machine Learning, 1336–1348. PMLR, (2021b)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR8" id="ref-link-section-d11833034e990">8</a></sup>? To address this issue, we correlate these brain scores to the level of comprehension of the subjects, assessed for each subject-story pair with a questionnaire at the end of each story. On average across all voxels, the correlation between brain scores and comprehension reaches <span>\(\mathcal {R}=0.50\)</span> (<span>\(p&lt;10^{-15}\)</span>, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>D, as assessed across subject-story pairs with the Pearson’s test provided by SciPy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Virtanen, P. et al. SciPy 1.0 contributors. SciPy 1.0: Fundamental algorithms for scientific computing in python. Nat. Methods 17, 261–272. 
                  https://doi.org/10.1038/s41592-019-0686-2
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR28" id="ref-link-section-d11833034e1057">28</a></sup>). This correlation is significant across a wide variety of the bilateral temporal, parietal and prefrontal cortices typically linked to language processing (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>E). Together, these results suggest that the shared representations between GPT-2 and the brain reliably vary with semantic comprehension.</p><h3 id="Sec4">Low-level processing only partially accounts for the correlation between comprehension and GPT-2’s mapping</h3><p>Low-level speech representations typically vary with attention<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Mesgarani, N. &amp; Chang, E. F. Selective cortical representation of attended speaker in multi-talker speech perception. Nature 485(7397), 233–236. 
                  https://doi.org/10.1038/nature11020
                  
                 (2012)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR31" id="ref-link-section-d11833034e1072">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Cohen, L., Salondy, P., Pallier, C. &amp; Dehaene, S. How does inattention affect written and spoken language processing?. Cortex 138, 212–227 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR32" id="ref-link-section-d11833034e1075">32</a></sup>, and could thus, in turn, influence down-stream comprehension processes. Consequently, one can legitimately wonder whether the correlation between comprehension and GPT-2’s brain mapping is simply driven by variations in low-level auditory processing. To address this issue, we evaluate the predictability of fMRI given low-level phonological features: the word rate, phoneme rate, phonemes, stress and tone of the narrative (cf. Methods). The corresponding brain scores correlate with the subjects’ understanding (<span>\(\mathcal {R}=0.17, p&lt;10^{-2}\)</span>) but considerably less than the brain scores of GPT-2 (<span>\(\Delta \mathcal {R}=0.32\)</span>). These low-level correlations with comprehension peak in the left superior temporal cortex (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>F). Overall, this result suggests that the link between comprehension and GPT-2’s brain mapping may be partially explained by – but not reduced to – the variations of low-level auditory processing.</p><h3 id="Sec5">High-level representations best predict comprehension</h3><p>Is the correlation between comprehension and GPT-2’s mapping driven by a <i>lexical</i> process and/or by an ability to meaningfully combine words? To tackle this issue, we compare the correlations obtained from GPT-2’s word embedding (i.e. layer 0) to those obtained from GPT-2’s eighth layer, i.e. a contextual embedding. On average across voxels, the correlation with comprehension is 0.12 lower with GPT-2’s word embedding than with its contextual embedding. An analogous analysis, comparing word embedding to phonological features is displayed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>F. Strictly lexical effects (word-embedding <i>versus</i> phonological) peak in the superior-temporal lobe and in pars triangularis. By contrast, higher-level effects (GPT-2 eighth layer <i>versus</i> word-embedding) peak in the superior-frontal, posterior superior-temporal gyrus, in the precuneus and in both the triangular and opercular parts of the inferior frontal gyrus – a network typically associated with high-level language comprehension<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e1174">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. J. Neurosci. 31(8), 2906–2915. 
                  https://doi.org/10.1523/JNEUROSCI.3684-10.2011
                  
                 (2011)." href="#ref-CR33" id="ref-link-section-d11833034e1177">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pallier, C., Devauchelle, A.-D. &amp; Dehaene, S. Cortical representation of the constituent structure of sentences. Proc. Natl. Acad. Sci. 108(6), 2522–2527. 
                  https://doi.org/10.1073/pnas.1018711108
                  
                 (2011)." href="#ref-CR34" id="ref-link-section-d11833034e1177_1">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Fedorenko, E. et al. Neural correlate of the construction of sentence meaning. Proc. Natl. Acad. Sci. USA
                  https://doi.org/10.1073/pnas.1612132113
                  
                 (2016)." href="#ref-CR35" id="ref-link-section-d11833034e1177_2">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Friederici, A. D. The brain basis of language processing: From structure to function. Physiol. Rev. 91(4), 1357–1392. 
                  https://doi.org/10.1152/physrev.00006.2011
                  
                 (2011)." href="#ref-CR36" id="ref-link-section-d11833034e1177_3">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Hickok, G. &amp; Poeppel, D. The cortical organization of speech processing. Nat. Rev. Neurosci. 8(5), 393–402. 
                  https://doi.org/10.1038/nrn2113
                  
                 (2007)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR37" id="ref-link-section-d11833034e1180">37</a></sup>. Together, these model comparisons suggest that GPT-2 best predicts how brain responses to speech vary with comprehension.</p><h3 id="Sec6">Comprehension effects are mainly driven by individuals’ variability</h3><p>The variability in comprehension scores could result from exogeneous factors (e.g. some stories may be harder to comprehend than others for GPT-2) and/or from endogeneous factors (e.g. some subjects may better understand specific texts because of prior knowledge). To address this issue, we fit a linear mixed model to predict comprehension scores given brain scores, specifying the narrative as a random effect (cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">B</a>). The fixed effect of brain score (shared across narratives) is highly significant: <span>\(\beta =\,0.04, p&lt;10^{-29}\)</span>, cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">B</a>). However, the random effect (slope specific to each single narrative) is not (<span>\(\beta &lt;10^{-2}\)</span>, <span>\(p&gt;\,0.11\)</span>). We also replicate the main analysis (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>D) within each single narrative: the correlation with comprehension reaches 0.76 for the ‘Sherlock’ story and is above 0.40 for every story (cf. Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">C</a>). Overall, these analyses confirm that the link between GPT-2 and semantic comprehension is best accounted for by an endogeneous factor: i.e. individual differences in comprehension scores.</p><h3 id="Sec7">Decomposing the brain regions, levels of representation and attention distances underlying comprehension</h3><p>Can GPT-2 be further decomposed to identify the mechanisms responsible for generating representations that both (i) map with the human brain and (ii) predict subjects’ comprehension? To address this issue, we investigate the links between (1) short- and long-range attentional gating, (2) the depth of the representation and (3) brain and comprehension scores. Specifically, we compute both of these scores for different GPT-2 layer <i>k</i>, when restricting their attention span to different distances <i>d</i> (i.e. layers <span>\(k&#39;\le k\)</span> only access the <i>d</i> previous words). By systematically and independently varying <i>k</i> and <i>d</i>, we can compute <span>\(\beta _{\mathrm {distance}}\)</span> and <span>\(\beta _{\mathrm {layer}}\)</span>: the two coefficients that indicate how brain scores and comprehension scores vary across layers and attentional spans, respectively. Precisely, a positive <span>\(\beta _{\mathrm {distance}}\)</span> indicates that scores are sensitive to long-range dependencies. On the contrary, a null <span>\(\beta _{\mathrm {distance}}\)</span> indicates that scores are not sensitive to long-range-dependencies. Similarly, a positive <span>\(\beta _{\mathrm {layer}}\)</span> indicates that deep layers have better scores than shallow layers, while a negative <span>\(\beta _{\mathrm {layer}}\)</span> indicates that shallow layers have better scores than deep layers.</p><p>Our results are three-fold. First, both the brain score (<span>\(\mathcal {M}\)</span>) and the comprehension scores (<span>\(\mathcal {R}\)</span>) increase with the attention span (<span>\(\beta _{\mathrm {distance}}&gt;0\)</span>, <span>\(p^{M}&lt;10^{-14}\)</span> for brain scores, <span>\(p^{R}=\,0.01\)</span> for comprehension scores) as well as with the depth of the representation (<span>\(\beta _{\mathrm {layer}}&gt;0\)</span>, <span>\(p^{M}&lt; 10^{-4}\)</span>, <span>\(p^{R}=\,0.001\)</span>). The gain in scores obtained with attention to distant context is observed even up to the most distant items (e.g. between distance <span>\(\approx 1000\)</span> and 300 words: <span>\(\Delta R&gt;\,0\)</span>, <span>\(p^{M}&lt;10^{-4}\)</span>, <span>\(p^{R}=\,0.02\)</span>, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig2">2</a>A).</p><p>Second, the attention span primarily impacts the brain scores and the comprehension scores of the middle layers (difference between layer 8 and layer 12: <span>\(\Delta \beta _{\mathrm {distance}}=\,0.001\)</span>, <span>\(p^{M}&lt;10^{-8}\)</span> for brain scores, <span>\(\Delta \beta _{\mathrm {distance}}=\,0.03\)</span>, <span>\(p^{R}=\,0.005\)</span> for comprehension scores, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig2">2</a>AD). Interestingly, and to our surprise, restricting the attention span of the first layers improved their ability to predict comprehension (e.g. for the first layer, difference between scores with an attention of 10 words and full attention <span>\(\Delta R=\,0.06\)</span>, <span>\(p=\,0.004\)</span>, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig2">2</a>D). This unexpected result suggests that language transformers could be made more similar to the brain by increasing the attention span as a function of depth.</p><p>Finally, brain regions commonly associated with high-level comprehension are better predicted by the deep and contextual representations of the network, and their corresponding brain scores and comprehension scores are relatively strongly modulated by long-distance attention (e.g. in angular gyrus: <span>\(\beta _{\mathrm {layer}}= 0.14&gt;0\)</span>, <span>\(p=\,0.002\)</span>, <span>\(\beta _{\mathrm {distance}}=\,0.03&gt;0\)</span>, <span>\(p=\,0.016\)</span> for comprehension scores). On the contrary, low-level acoustic regions are best predicted by the shallow layers of the network, and are, in comparison, little altered by long-distance dependencies (e.g. for the comprehension scores in Heschl gyrus, <span>\(\beta _{\mathrm {layer}}=\,-0.076&lt;0\)</span>, <span>\(p=\,0.004\)</span>, <span>\(\beta _{\mathrm {distance}}=\,-0.014&lt;0\)</span>, <span>\(p=\,0.012\)</span>).</p><p>Overall, our analysis suggests that comprehension depends on a hierarchy of neural representations, whereby the first areas of the language network deploys shallow and short-span attention processes, while the fronto–parietal network relies on compositional and long-span attention processes. Interestingly, our analysis also highlights that shortening the attention span of lower layers makes them more brain-like, and could perhaps thus provide a useful inductive bias to these algorithms.</p></div></div></section><section data-title="Discussion"><div id="Sec8-section"><h2 id="Sec8">Discussion</h2><div id="Sec8-content"><p>Our analyses reveal a reliable correlation between story comprehension and the degree to which language transformers like GPT-2 maps onto brain responses to the corresponding story. Furthermore, the systematic comparison, decomposition and manipulation of such language models allow us to decompose (1) the brain regions (2) the level of representation (sub-lexical, lexical, supra-lexical) and (3) the attentional gating (i.e. the short- or long-range retrieval of past stimuli) that relate to the comprehension of complex narratives.</p><p>These findings complement prior work on the brain bases of comprehension in three major ways. First, a number of qualitative theories describe how words may be combined into meaningful representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Friederici, A. D. The brain basis of language processing: From structure to function. Physiol. Rev. 91(4), 1357–1392. 
                  https://doi.org/10.1152/physrev.00006.2011
                  
                 (2011)." href="#ref-CR36" id="ref-link-section-d11833034e2347">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hickok, G. &amp; Poeppel, D. The cortical organization of speech processing. Nat. Rev. Neurosci. 8(5), 393–402. 
                  https://doi.org/10.1038/nrn2113
                  
                 (2007)." href="#ref-CR37" id="ref-link-section-d11833034e2347_1">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hagoort, P., Baggio, G. &amp; Wlllems, R. M.. Semantic unification. In The Cognitive Neurosciences, 4th ed., 819–835 ( Massachusetts Institute of Technology, Cambridge, MA, 2009)." href="#ref-CR38" id="ref-link-section-d11833034e2347_2">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hagoort, P. MUC (Memory, Unification, Control) and beyond. Front. Psychol. 4, 416 (2013)." href="#ref-CR39" id="ref-link-section-d11833034e2347_3">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hagoort, P. &amp; Indefrey, P. The neurobiology of language beyond single words. Annu. Rev. Neurosci. 37, 347–362. 
                  https://doi.org/10.1146/annurev-neuro-071013-013847
                  
                 (2014)." href="#ref-CR40" id="ref-link-section-d11833034e2347_4">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bornkessel-Schlesewsky, I. &amp; Schlesewsky, M. The extended argument dependency model: A neurocognitive approach to sentence comprehension across languages. Psychol. Rev. 113, 787–821. 
                  https://doi.org/10.1037/0033-295X.113.4.787
                  
                 (2006)." href="#ref-CR41" id="ref-link-section-d11833034e2347_5">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bornkessel-Schlesewsky, I. &amp; Schlesewsky, M. Reconciling time, space and function: a new dorsal-ventral stream model of sentence comprehension. Brain Lang. 125(1), 60–76. 
                  https://doi.org/10.1016/j.bandl.2013.01.010
                  
                 (2013)." href="#ref-CR42" id="ref-link-section-d11833034e2347_6">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Ullman, M. T. A neurocognitive perspective on language: The declarative/procedural model. Nat. Rev. Neurosci. 2(10), 717–726. 
                  https://doi.org/10.1038/35094573
                  
                 (2001)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR43" id="ref-link-section-d11833034e2350">43</a></sup>. For example, the Memory, Unification and Control model (MUC) distinguishes three types of computations and links them to the temporal lobe, Broca area and the rest of the prefrontal lobe, respectively. Similarly, the extended Argument Dependency Model (eADM) proposes that the ventral and the dorsal streams of the auditory pathway compute time-independent and time-dependent unifications, respectively. Our results support an analogous division of acoustics, lexical and compositional representations in the language areas. However, we reveal a slightly different functional anatomy: the early areas of the language network, located around the auditory cortices, deploy sub-lexical and shallow representations thanks to short attention spans. By contrast, the fronto–parietal network tracks and unifies very distant contexts to current words (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>F). How these cortical areas communicate with the hippocampus and retrieve words from long-term memory remains an exciting direction for future studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Lu, Q., Hasson, U. &amp; Norman, K. A. A neural network model of when to retrieve and encode episodic memories. Elife 11, e74445. 
                  https://doi.org/10.7554/eLife.74445
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR44" id="ref-link-section-d11833034e2357">44</a></sup>.</p><p>Second, several quantitative approaches have been proposed to investigate comprehension, either with “model-free” methods based on inter-subject correlation (e.g.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. J. Neurosci. 31(8), 2906–2915. 
                  https://doi.org/10.1523/JNEUROSCI.3684-10.2011
                  
                 (2011)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR33" id="ref-link-section-d11833034e2364">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Fedorenko, E. et al. Neural correlate of the construction of sentence meaning. Proc. Natl. Acad. Sci. USA
                  https://doi.org/10.1073/pnas.1612132113
                  
                 (2016)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR35" id="ref-link-section-d11833034e2367">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Dehghani, M. et al. Decoding the neural representation of story meanings across languages: Decoding the neural representation. Hum. Brain Mapp. 38(12), 6096–6106. 
                  https://doi.org/10.1002/hbm.23814
                  
                 (2017)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR45" id="ref-link-section-d11833034e2370">45</a></sup>) or “model-based” methods based on word vectors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Broderick, M. P., Zuk, N. J., Anderson, A. J. &amp; Lalor E. C. More than Words: Neurophysiological correlates of semantic dissimilarity depend on comprehension of the speech narrative. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR46" id="ref-link-section-d11833034e2374">46</a></sup>. For example, Lerner et al. analyzed the fMRI activity of subjects listening to either normal texts or texts scrambled at the word, sentence or paragraph level<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. J. Neurosci. 31(8), 2906–2915. 
                  https://doi.org/10.1523/JNEUROSCI.3684-10.2011
                  
                 (2011)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR33" id="ref-link-section-d11833034e2378">33</a></sup>. While brain activity correlated across subjects in the primary and secondary auditory areas even when the input was heavily scrambled (and thus poorly comprehensible), the bilateral infero-frontal and temporo-parietal cortex only correlated across subjects when sentences and/or paragraphs were not scrambled (and thus comprehensible). Broderick et al. used a similar design to investigate electro-encephalography (EEG) responses to variably scrambled versions of the same story<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Broderick, M. P., Zuk, N. J., Anderson, A. J. &amp; Lalor E. C. More than Words: Neurophysiological correlates of semantic dissimilarity depend on comprehension of the speech narrative. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR46" id="ref-link-section-d11833034e2382">46</a></sup>, as well as the EEG responses to speech played in reverse and in noise<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Broderick, M. P., Anderson, A. J., Di Liberto, G. M., Crosse, M. J. &amp; Lalor, E. C. Electrophysiological Correlates of Semantic Dissimilarity Reflect the Comprehension of Natural. Narrative Speech. Curr. Biol. 28(5), 803–809. 
                  https://doi.org/10.1016/j.cub.2018.01.080
                  
                 (2018)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR47" id="ref-link-section-d11833034e2386">47</a></sup>. Consistently with our results, they showed that the mapping between word embeddings’ and the EEG activity varies with comprehension as manipulated by these various protocols. Our results thus complement these findings by showing (1) the brain regions where GPT-2’s predictions vary with subject’s comprehension, and (2) what type of representations these features relate to: comprehension appears here to depend on a hierarchy of neural representations, whereby the first areas of the language network deploys shallow and short-span-attention processes, while the fronto–parietal network relies on compositional and long-span-attention processes.</p><p>Finally, previous analyses have investigated the role of attention in the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e2393">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Sabri, M. et al. Attentional and linguistic interactions in speech perception. Neuroimage 39(3), 1444–1456. 
                  https://doi.org/10.1016/j.neuroimage.2007.09.052
                  
                 (2008)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR48" id="ref-link-section-d11833034e2396">48</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Kok, P., Jehee, J. F. M. &amp; de Lange, F. P. Less is more: Expectation sharpens representations in the primary visual cortex. Neuron 75(2), 265–270. 
                  https://doi.org/10.1016/j.neuron.2012.04.034
                  
                 (2012)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR49" id="ref-link-section-d11833034e2399">49</a></sup>. We complement these studies by (1) showing that very-long term attention affects brain scores (even above 1,000 words), (2) identifying the brain regions that are sensitive to long vs. short attention spans, and(3) investigating the interactions between attention span, the ability to generate brain-like representations, and one behavioral metric: comprehension.</p><p>Interestingly, some regions, like the angular and supramarginal gyri, present a modest brain score and nevertheless strongly predict comprehension. How can one interpret such dissociation? We propose that deep neural networks encode a variety of features, ranging from low- to high-level representations. While some of these features may relate to general language processing (e.g. short-range information about words), others may specifically relate to and thus predict comprehension (e.g. long-range dependencies). In this view, the regions that are best predicted by GPT-2’s representations (e.g. Heschel’s gyrus) need not be identical to those that best predict comprehension (e.g. Angular gyrus). Our ablation studies fit this hypothesis: the auditory cortices are marked by high brain scores but low comprehension scores (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>G) and indeed appear to encode short-range and shallow representations – i.e. features that presumably only indirectly relate to the comprehension of a narrative (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig2">2</a>). By contrast, the angular gyrus demonstrates a high comprehension score (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>G) and indeed appears to encode long-range dependencies and deep representations – i.e. features that presumably relate to the latent structures of narratives, and from which comprehension should depend (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig2">2</a>).</p><p>Overall, the present study suggests that GPT-2 retrieves information that relates to human comprehension, thus strengthening previous works that study the similarities between deep language models and the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C., Gramfort, A., &amp; King, J. R. Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects. In EMNLP 2021-Conference on Empirical Methods in Natural Language Processing, (2021a)." href="#ref-CR4" id="ref-link-section-d11833034e2422">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="#ref-CR5" id="ref-link-section-d11833034e2422_1">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proc. Natl. Acad. Sci. 118(45), e2105646118. 
                  https://doi.org/10.1073/pnas.2105646118
                  
                 (2021)." href="#ref-CR6" id="ref-link-section-d11833034e2422_2">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="#ref-CR7" id="ref-link-section-d11833034e2422_3">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C., Gramfort, A., &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In International Conference on Machine Learning, 1336–1348. PMLR, (2021b)." href="#ref-CR8" id="ref-link-section-d11833034e2422_4">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hale, J., Campanelli, L., Li, J., Bhattasali, S., Pallier, C. &amp; Brennan, J. Neuro-computational models of language processing. Annu. Rev. Linguist., (2021)." href="#ref-CR9" id="ref-link-section-d11833034e2422_5">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Anderson, A. J. et al. Deep artificial neural networks reveal a distributed cortical network encoding propositional sentence-level meaning. J. Neurosci. 41(18), 4100–4119. 
                  https://doi.org/10.1523/JNEUROSCI.1152-20.2021
                  
                 (2021)." href="#ref-CR10" id="ref-link-section-d11833034e2422_6">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jingyuan, S., Shaonan, W., Jiajun, Z. &amp; Chengqing, Z. Neural encoding and decoding with distributed sentence representations. IEEE Trans. Neural Netw. Learn. Syst. 32(2), 589–603. 
                  https://doi.org/10.1109/TNNLS.2020.3027595
                  
                 (2021)." href="#ref-CR11" id="ref-link-section-d11833034e2422_7">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Goldstein, A. et al. Thinking ahead: Prediction in context as a keystone of language in humans and machines. bioRxiv
                  https://doi.org/10.1101/2020.12.02.403477
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR12" id="ref-link-section-d11833034e2425">12</a></sup>. For instance, several studies showed that deep nets’ encoding accuracy correlated with the level of semantic and syntactic information of their activations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jingyuan, S., Shaonan, W., Jiajun, Z. &amp; Chengqing, Z. Neural encoding and decoding with distributed sentence representations. IEEE Trans. Neural Netw. Learn. Syst. 32(2), 589–603. 
                  https://doi.org/10.1109/TNNLS.2020.3027595
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR11" id="ref-link-section-d11833034e2429">11</a></sup>, as well as their ability to predict a word from context<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proc. Natl. Acad. Sci. 118(45), e2105646118. 
                  https://doi.org/10.1073/pnas.2105646118
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR6" id="ref-link-section-d11833034e2433">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e2436">7</a></sup>. We complement these results and show that the encoding accuracy of GPT-2 correlates with the level of understanding of the subjects, as assessed with comprehension questionnaires. Interestingly, our analysis also highlights that shortening the attention span of the lower layers would make them more brain-like. Thus, these results contribute to revealing remaining functional differences between brains and language models, and could thus help guide the development of modern algorithms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e2440">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Long-range and hierarchical language predictions in brains and algorithms. 
                  arXiv:2111.14232
                  
                 [cs, q-bio], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR50" id="ref-link-section-d11833034e2443">50</a></sup>.</p><p>The relationship between GPT-2’s representations and human comprehension remains to be qualified, however. First, we restrict the challenging and composite notion of semantic comprehension to an empirical definition: i.e. the extent to which subjects understand a narrative, as assessed by a questionnaire presented at the end of each story. We acknowledge that comprehension spans a very diverse set of conditions, ranging from scientific writing to newspapers, which are not presently tested.</p><p>Second, our results remain solely based on correlations. Supplementary analyses suggest that GPT-2’s brain scores may be partially explained by – but not reduced to – attentional processes (Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">H</a>). Yet, the factors that causally influence comprehension, such as attention, prior knowledge, working memory capacity, and language complexity are not controlled here and should thus be explicitly examined and manipulated in future work. In particular, it would be interesting to evaluate how working memory capacity, cognitive control, vocabulary, as well as an continuous-monitoring of subjects’ attention separately contribute to the fluctuation of comprehension and specifically account for the link between GPT-2 and the brain. Similarly, the study of inter-individual differences could further help modeling specific cognitive deficits associated with comprehension such as dyspraxia, dyslexia or autistic syndrome. However, such investigation would likely require large amounts of data, and thus a dedicated effort<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Scott, M. et al. Reproducible brain-wide association studies require thousands of individuals. Nature
                  https://doi.org/10.1038/s41586-022-04492-9
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR51" id="ref-link-section-d11833034e2456">51</a></sup>.</p><p>Third, we find that the long-distance representations of GPT-2 middle layers specifically account for comprehension in associative cortices, while the short-distance information encoded in the shallow layers account for comprehension in lower-level brain regions. However, what these features actually represent remains largely unknown. Previous studies have shown that language transformers explicitly represent syntactic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? 
                  arXiv:2101.02258
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR14" id="ref-link-section-d11833034e2463">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proc. Natl. Acad. Sci.
                  https://doi.org/10.1073/pnas.1907367117
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR52" id="ref-link-section-d11833034e2466">52</a></sup> and semantic features<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? 
                  arXiv:2101.02258
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR14" id="ref-link-section-d11833034e2470">14</a></sup>. Similarly, Manning et al. showed that syntactic trees appear to be encoded by the distances between contextualized word embedding<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proc. Natl. Acad. Sci.
                  https://doi.org/10.1073/pnas.1907367117
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR52" id="ref-link-section-d11833034e2474">52</a></sup>. Clarifying the nature of word embeddings remains an important direction to explore (e.g. syntactic vs. semantic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Caucheteux, C., Gramfort, A., &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In International Conference on Machine Learning, 1336–1348. PMLR, (2021b)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR8" id="ref-link-section-d11833034e2478">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jingyuan, S., Shaonan, W., Jiajun, Z. &amp; Chengqing, Z. Neural encoding and decoding with distributed sentence representations. IEEE Trans. Neural Netw. Learn. Syst. 32(2), 589–603. 
                  https://doi.org/10.1109/TNNLS.2020.3027595
                  
                 (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR11" id="ref-link-section-d11833034e2481">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Gauthier, J. &amp; Levy, R. Linking artificial and human neural representations of language. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 529–539, Hong Kong, China, (2019). Association for Computational Linguistics. 
                  https://doi.org/10.18653/v1/D19-1050
                  
                ." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR53" id="ref-link-section-d11833034e2484">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Reddy, A. J. &amp; Wehbe, L. Syntactic representations in the human brain: Beyond effort-based metrics. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR54" id="ref-link-section-d11833034e2487">54</a></sup>.</p><p>Finally, although highly significant, and significantly better than alternative models (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">S3</a>), the brain-scores of GPT-2 are relatively low<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e2497">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532(7600), 453–458. 
                  https://doi.org/10.1038/nature17637
                  
                 (2016)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR26" id="ref-link-section-d11833034e2500">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Fedorenko, E. et al. Neural correlate of the construction of sentence meaning. Proc. Natl. Acad. Sci. USA
                  https://doi.org/10.1073/pnas.1612132113
                  
                 (2016)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR35" id="ref-link-section-d11833034e2503">35</a></sup>. This phenomenon is largely expected: we fit and evaluate the brain mapping at the single-TR single-voxel level and across all brain voxels to avoid selection biases. Nonetheless, these brain scores reach up to 32% of the noise ceiling (Supplementary Information <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">D</a>, Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#MOESM1">S2</a>). This indicates that while GPT-2 may be our best model of language representations in the brain, it remains far from fully capturing those of complex narratives.</p><p>The comparison between brains, behavior and deep nets was originally introduced in vision research<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Yamins, D. L. K. &amp; DiCarlo, J. J. Using goal-driven deep learning models to understand sensory cortex. Nat. Neurosci. 19(3), 356–365. 
                  https://doi.org/10.1038/nn.4244
                  
                 (2016)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR55" id="ref-link-section-d11833034e2517">55</a></sup>. The present study strengthens this approach and clarifies the links between GPT-2 and the brain. Specifically, we show that GPT-2’s mapping correlates with comprehension up to <span>\(\mathcal {R}=0.50\)</span>. This result is both promising and limited: on the one hand, we reveal that the similarity between deep nets and the brain non-trivially relates to a high-level cognitive process. On the other hand, half of the comprehension variability remains unexplained by this algorithm.</p><p>This limit is expected: several studies demonstrate that current deep language models fail to capture several aspects critical to comprehension<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. 
                  arXiv:2008.01766
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR16" id="ref-link-section-d11833034e2549">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Gary, M. Gpt-2 and the nature of intelligence. The Gradient. 
                  https://thegradient.pub/gpt2-and-the-nature-of-intelligence/
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR19" id="ref-link-section-d11833034e2552">19</a></sup>: they (i) often fail to generalize beyond the training distribution<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. Philos. Trans. R. Soc. B Biol. Sci. 375(1791), 20190307. 
                  https://doi.org/10.1098/rstb.2019.0307
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR56" id="ref-link-section-d11833034e2556">56</a></sup>, (ii) do not perfectly capture deep syntactic structures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? 
                  arXiv:2101.02258
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR14" id="ref-link-section-d11833034e2560">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proc. Natl. Acad. Sci.
                  https://doi.org/10.1073/pnas.1907367117
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR52" id="ref-link-section-d11833034e2563">52</a></sup> and (iii) remain relatively poor at summarizing texts, generating stories and answering questions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Holtzman, A., Buys, J., Du, L., Forbes, M. &amp; Choi, Y. The curious case of neural text degeneration. 
                  arXiv:1904.09751
                  
                 [cs], (2020)." href="#ref-CR20" id="ref-link-section-d11833034e2567">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wiseman, S., Shieber, S. M. &amp; Rush, A. M. Challenges in data-to-document generation. 
                  arXiv:1707.08052
                  
                 [cs], (2017)." href="#ref-CR21" id="ref-link-section-d11833034e2567_1">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Thakur, N., Reimers, N., Ruckle, A., Srivastava, A., &amp; Gurevych, I. BEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models. 
                  arXiv:2104.08663
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR22" id="ref-link-section-d11833034e2570">22</a></sup>. Furthermore, GPT-2 is only trained with textual data and does not situate objects in a grounded environment that would capture their real-world interactions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="McClelland, J. L., Hill, F., Rudolph, M., Baldridge, J. &amp; Schütze, H. Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models. Proc. Natl. Acad. Sci. 117(42), 25966–25974. 
                  https://doi.org/10.1073/pnas.1910416117
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR18" id="ref-link-section-d11833034e2574">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Bisk, Y., Holtzman, A., Thomason, J., Andreas, J., Bengio, Y., Chai, J., Lapata, M., Lazaridou, A., May, J., Nisnevich, A., Pinto, N. &amp; Turian, J. Experience grounds language. 
                  arXiv:2004.10151
                  
                 [cs], (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR57" id="ref-link-section-d11833034e2577">57</a></sup>. These limits may be temporary, however: the latest models appear to be more robust to out-of-distribution sampling<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I. &amp; Amodei, D. Language models are few-shot learners. 
                  arXiv:2005.14165
                  
                 [cs], (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR58" id="ref-link-section-d11833034e2582">58</a></sup> and trained on multimodal data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G. &amp; Sutskever, I. Learning transferable visual models from natural language supervision. 
                  arXiv:2103.00020
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR59" id="ref-link-section-d11833034e2586">59</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M. &amp; Sutskever, I. Zero-shot text-to-image generation. 
                  arXiv:2102.12092
                  
                 [cs], (2021)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR60" id="ref-link-section-d11833034e2589">60</a></sup>.</p><p>Together, these elements suggest that modern language algorithms like GPT-2 offer a promising basis to unravel the brain and computational signatures of comprehension. Vice versa, by highlighting the similarities and remaining differences between deep language models and the brain, our study reinforces the mutual relevance of neuroscience and AI.</p></div></div></section><section data-title="Materials and methods"><div id="Sec9-section"><h2 id="Sec9">Materials and methods</h2><div id="Sec9-content"><p>Our analyses rely on the “Narratives” dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e2604">61</a></sup>, composed of the brain signals, recorded using fMRI, of 345 subjects listening to 27 narratives. The dataset is publicly available and the methods were performed in accordance with relevant guidelines and regulations.</p><h3 id="Sec10">Narratives and comprehension score</h3><p>Among the 27 stories of the dataset, we selected the seven stories for which subjects were asked to answer a comprehension questionnaire at the end, and for which the answers varied across subjects (more than ten different comprehension scores across subjects), resulting in 70 min of audio stimuli in total, from four to 19 minutes per story (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig3">3</a>). Questionnaires were either multiple-choice, fill-in-the blank, or open questions (answered with free text) rated by humans<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e2618">61</a></sup>. Here, we used the comprehension score computed in the original dataset which was either a proportion of correct answers or the sum of the human ratings, scaled between 0 and 1<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e2622">61</a></sup>. It summarizes the comprehension of one subject for one narrative (specific to each (narrative, subject) pair).</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Figure 3"><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Figure 3</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-022-20460-9/MediaObjects/41598_2022_20460_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="295"/></picture></a></div><p>For each of the seven narratives: number of subjects (<i>n</i>), distribution of comprehension scores across subjects and length of the narrative.</p></div></figure></div><h3 id="Sec11">Brain activations</h3><p>The brain activations of the 101 subjects who listened to the seven selected narratives were recorded using fMRI. As suggested in the original paper<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e2655">61</a></sup>, pairs of (subject, narrative) were excluded because of noisy recordings, resulting in 237 pairs in total.</p><p>All seven studies used a repetition time (TR) of 1.5 seconds. As stated in the orginal paper<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e2662">61</a></sup>, the “Merlin”, “Sherlock”, “Slumlord” and “Reach for the Stars” datasets were collected on a 3T Siemens Magnetom Skyra (Erlangen, Germany) with a 20-channel phased-array head coil using the following acquisition parameters. “Functional BOLD images were acquired in an interleaved fashion using gradient-echo echo-planar imaging (EPI) with an in-plane acceleration factor of 2 using GRAPPA. The full acquisition details are summarized here for simplicity: TR/TE = 1500/28 ms, flip angle = 64 degrees, bandwidth = 1445 Hz/Px, in-plane resolution = 3x3mm, slice thickness <span>\(= 4\)</span> mm, matrix size = <span>\(64\times 64\)</span>, FoV = <span>\(192\times 192\)</span> mm, 27 axial slices with roughly full brain coverage and no gap, anterior–posterior phase encoding, prescan normalization, fat suppression. At the beginning of each run, three dummy scans were acquired and discarded by the scanner to allow for signal stabilization.</p><p>The “Pie Man (PNI)” (pieman-pni) “Running from the Bronx”(bronx), “I Knew You Were Black” (black) and “The Man Who Forgot Ray Bradbury”(forgot) datasets were collected on the same 3T Siemens Magnetom Prisma with a 64-channel head coil using different acquisition parameters. Functional images were acquired in an interleaved fashion using gradient-echo EPI with a multiband acceleration factor of 3 using blipped CAIPIRINHA and no in-plane acceleration: TR/TE 1500/31 ms, flip angle = 67 degrees, bandwidth = 2480 Hz/Px, in-plane resolution = <span>\(2.5\times 2.5\)</span> mm, slice thickness 2.5 mm, matrix size = <span>\(96\times 96\)</span>, FoV = <span>\(240 \times 240\)</span> mm, 48 axial slices with full brain coverage and no gap, anterior–posterior phase encoding, prescan normalization, fat suppression, three dummy scans.”</p><h3 id="Sec12">GPT-2 activations</h3><p>GPT-2<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Radford, A. et al. Language models are unsupervised multitask learners. OpenAI blog 1(8), 9 (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR1" id="ref-link-section-d11833034e2819">1</a></sup> is a high-performing neural language model trained to predict a word given its previous context (it does not have access to succeeding words), given millions of examples (e.g Wikipedia texts). It consists of multiple Transformer modules (twelve, each of them called “layer”) stacked on a non-contextual word embedding (a look-up table that outputs a single vector per vocabulary word)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Radford, A. et al. Language models are unsupervised multitask learners. OpenAI blog 1(8), 9 (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR1" id="ref-link-section-d11833034e2823">1</a></sup>. Each layer <i>k</i> can be seen as a nonlinear system that takes a sequence of <i>w</i> words as input, and outputs a contextual vector of dimension (<i>w</i>, <i>d</i>), called the “activations” of layer <i>k</i> (<span>\(d=\,768\)</span>). Intermediate layers were shown to better encode syntactic and semantic information than input and output layers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Jawahar, G., Sagot, B. &amp; Seddah, D. What Does BERT learn about the structure of language? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3651–3657, Florence, Italy, (2019). Association for Computational Linguistics. 
                  https://doi.org/10.18653/v1/P19-1356
                  
                ." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR62" id="ref-link-section-d11833034e2869">62</a></sup>, and to better map onto brain activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). 
                  arXiv:1905.11833
                  
                 [cs, q-bio], (2019)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR5" id="ref-link-section-d11833034e2873">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun. Biol. 5(1), 1–10. 
                  https://doi.org/10.1038/s42003-022-03036-1
                  
                 (2022)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR7" id="ref-link-section-d11833034e2876">7</a></sup>. Here, we show that the <i>eighth</i> layer of GPT-2 best predicts brain activity Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>C. We thus select the eighth layer of GPT-2 for our analyses. Our conclusions remain unchanged with other intermediate-to-deep layers of GPT-2 (from <span>\(6^{\text{th}}\)</span> to <span>\(12^{\text{th}}\)</span> layers).</p><p>In practice, the narratives’ transcripts were formatted (replacing special punctuation marks such as “–” and duplicated marks “?.” by dots), tokenized using GPT-2 tokenizer and input to the GPT-2 pretrained model provided by Huggingface<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T. L., Gugger, S., Drame, M., Lhoest, Q. &amp; Rush, A. M. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 38–45, Online (2020). Association for Computational Linguistics." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR63" id="ref-link-section-d11833034e2948">63</a></sup>. The representation of each token is computed separately using a sliding context window of 1024 tokens. For instance, to compute the representation of the third token of the story, we input GPT-2 with the third, second and first token, and then extract the activations corresponding to the third token. Similarly, to compute the activations of the <span>\(1500^{\text{ th}}\)</span> token, we input the model with the word 1500 and the 1023 words before. Overall, the activations of every word <span>\(w_k\)</span> are computed by inputting the model with the word <span>\(w_k\)</span> and the 1023 previous tokens (at most), and then extracting the activations corresponding to <span>\(w_k\)</span>. The procedure results in a vector of activations of size (<i>w</i>, <i>d</i>) with <i>w</i> the number of tokens in the story and <i>d</i> the dimensionality of the model. There are fewer fMRI scans than words. Thus, the activation vectors between successive fMRI measurements are summed to obtain one vector of size <i>d</i> per measurement. To match the fMRI measurements and the GPT-2 vectors over time, we used the speech-to-text correspondences provided in the fMRI dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR61" id="ref-link-section-d11833034e3061">61</a></sup>.</p><h3 id="Sec13">Linear mapping between GPT-2 and the brain</h3><p>For each (subject, narrative) pair, we measure the mapping between (i) the fMRI activations elicited by the narrative and (ii) the activations of GPT-2 (layer eight) elicited by the same narrative. To this end, a linear spatiotemporal model is fitted on a train set to predict the fMRI scans given the GPT-2 activations as input. Then, the mapping is evaluated by computing the Pearson correlation between predicted and actual fMRI scans on a held out set <i>I</i>:</p><div id="Equ1"><p><span>$$\begin{aligned} {\mathcal {M}}^{(s, w)} : I \mapsto \mathcal {L} \bigg ( f \circ g(X^{(w)})_{i \in I}, (Y^{(s, w)}_i)_{i \in I} \bigg ) \end{aligned}$$</span></p><p>
                    (1)
                </p></div><p>With <span>\(f\circ g\)</span> the fitted estimator (g: temporal and f: spatial mappings), <span>\(\mathcal {L}\)</span> Pearson’s correlation, <span>\(X^{(w)}\)</span> the activations of GPT-2 and <span>\(Y^{(s, w)}\)</span> the fMRI scans of subjects <i>s</i>, both elicited by the narrative <i>w</i>.</p><p>In practice, <i>f</i> is a <span>\(\ell _2\)</span>-penalized linear regression, following scikit-learn implementation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Pedregosa, F. et al. Scikit-learn: Machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR64" id="ref-link-section-d11833034e3389">64</a></sup>. The regularization parameter is chosen for each voxel separately using nested cross validation on the train set. Specifically, we use scikit-learn’s RidgeCV estimator with built-in leave-one-sample-out cross-validation, with ten possible regularization parameters log-spaced between <span>\(10^{-1}\)</span> and <span>\(10^8\)</span>, one hyper-parameter being selected for each voxel independently. <i>g</i> is a finite impulse response (FIR) model with 5 delays, where each delay sums the activations of GPT-2 input with the words presented between two TRs. For each (subject, narrative) pair, we split the corresponding fMRI time series into five contiguous chunks using scikit-learn cross-validation. The procedure is repeated across the five train (80% of the fMRI scans) and disjoint test folds (20% of the fMRI scans). Pearson correlations are averaged across test folds to obtain a single score per (subject, narrative) pair. This score, denoted <span>\(\mathcal {M}(X)\)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>A, measures the mapping between the activations space <i>X</i> and the brain of one subject, elicited by one narrative.</p><h3 id="Sec14">Phonological features</h3><p>To account for low-level speech processing, we computed the alignment (Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Equ1">1</a>)) between the fMRI brain recordings <i>Y</i> and phonological features <i>X</i>: the word rate (of dimension <span>\(d=\,1\)</span>, the number of words per fMRI scan), the phoneme rate (<span>\(d=\,1\)</span>, the number of phonemes per fMRI scan) and the concatenation of phonemes, stresses and tones of the words in the stimuli (categorical feature, <span>\(d=\,117\)</span>). The latter phonological features are provided in the original dataset and computed using Gentle<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Gentle. 
                  https://lowerquality.com/gentle/
                  
                ." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR65" id="ref-link-section-d11833034e3577">65</a></sup>. The 117 dimensions are the combination of phonetic categories, stresses and tones. We use 40 English phonemes in the corpus, and 4 possible tones, which results in 40 x 4 = 160 possible categories. Some categories are never pronounced here. If we ignore these categories, this results in 117 categories, and thus 117 dimensions after one-hot encoding.</p><h3 id="Sec15">Voxel-level and ROI-level analyses</h3><p>All of the first-level analyses are performed at the voxel level (computation of the mapping scores <span>\(\mathcal {M}\)</span> in Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Equ1">1</a>), in blue in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>). We then average these effects either (1) within each brain region (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>B, E, F and G) or (2) across the whole brain (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>C and D). From these average values, we compute the correlation with comprehension (in red in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>). This approach mitigates the localization of the effect and the statistical correction for multiple comparisons.</p><h3 id="Sec16">Significance</h3><p>Significance was either assessed by using either (i) a second-level Wilcoxon test (two-sided) across subject-narrative pairs, testing whether the mapping (one value per pair) was significantly different from zero (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>B), or (ii) by using the first-level Pearson <i>p</i>-value provided by SciPy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Virtanen, P. et al. SciPy 1.0 contributors. SciPy 1.0: Fundamental algorithms for scientific computing in python. Nat. Methods 17, 261–272. 
                  https://doi.org/10.1038/s41592-019-0686-2
                  
                 (2020)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR28" id="ref-link-section-d11833034e3637">28</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>D–G). In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#Fig1">1</a>B, E, F, <i>p</i>-values were corrected for multiple comparison (2 <span>\(\times\)</span> 142 ROIs) using False Discovery Rate (Benjamin/Hochberg)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Gramfort, A. et al. MEG and EEG data analysis with MNE-Python. Front. Neurosci. 7(267), 1–13. 
                  https://doi.org/10.3389/fnins.2013.00267
                  
                 (2013)." href="https://mytimeatrecurse.substack.com/articles/s41598-022-20460-9#ref-CR66" id="ref-link-section-d11833034e3669">66</a></sup>.</p></div></div></section>
                </div>
            

            <section data-title="Data availibility"></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Radford, A. <i>et al.</i> Language models are unsupervised multitask learners. <i>OpenAI blog</i> <b>1</b>(8), 9 (2019).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Language%20models%20are%20unsupervised%20multitask%20learners&amp;journal=OpenAI%20blog&amp;volume=1&amp;issue=8&amp;publication_year=2019&amp;author=Radford%2CA&amp;author=Wu%2CJ&amp;author=Child%2CR&amp;author=Luan%2CD&amp;author=Amodei%2CD&amp;author=Sutskever%2CI">
                    Google Scholar</a> 
                </p></li><li data-counter="2."><p id="ref-CR2">Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. <a href="http://arxiv.org/abs/1810.04805">arXiv:1810.04805</a> [cs], (2019).</p></li><li data-counter="3."><p id="ref-CR3">Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R. R., &amp; Le, Q. V. XLNet: Generalized Autoregressive Pretraining for Language Understanding. <a href="http://arxiv.org/abs/1906.08237">arXiv:1906.08237</a> [cs], (2020).</p></li><li data-counter="4."><p id="ref-CR4">Caucheteux, C., Gramfort, A., &amp; King, J. R. Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects. In <i>EMNLP 2021-Conference on Empirical Methods in Natural Language Processing</i>, (2021a).</p></li><li data-counter="5."><p id="ref-CR5">Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). <a href="http://arxiv.org/abs/1905.11833">arXiv:1905.11833</a> [cs, q-bio], (2019).</p></li><li data-counter="6."><p id="ref-CR6">Schrimpf, M. <i>et al.</i> The neural architecture of language: Integrative modeling converges on predictive processing. <i>Proc. Natl. Acad. Sci.</i> <b>118</b>(45), e2105646118. <a href="https://doi.org/10.1073/pnas.2105646118">https://doi.org/10.1073/pnas.2105646118</a> (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXisVGqt7jO" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.2105646118" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.2105646118" aria-label="Article reference 6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34737231" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8694052" aria-label="PubMed Central reference 6">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neural%20architecture%20of%20language%3A%20Integrative%20modeling%20converges%20on%20predictive%20processing&amp;journal=Proc.%20Natl.%20Acad.%20Sci.&amp;doi=10.1073%2Fpnas.2105646118&amp;volume=118&amp;issue=45&amp;publication_year=2021&amp;author=Schrimpf%2CM&amp;author=Blank%2CIA&amp;author=Tuckute%2CG&amp;author=Kauf%2CC&amp;author=Hosseini%2CEA&amp;author=Kanwisher%2CN&amp;author=Tenenbaum%2CJB&amp;author=Fedorenko%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="7."><p id="ref-CR7">Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. <i>Commun. Biol.</i> <b>5</b>(1), 1–10. <a href="https://doi.org/10.1038/s42003-022-03036-1">https://doi.org/10.1038/s42003-022-03036-1</a> (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s42003-022-03036-1" data-track-action="article reference" href="https://doi.org/10.1038%2Fs42003-022-03036-1" aria-label="Article reference 7">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Brains%20and%20algorithms%20partially%20converge%20in%20natural%20language%20processing&amp;journal=Commun.%20Biol.&amp;doi=10.1038%2Fs42003-022-03036-1&amp;volume=5&amp;issue=1&amp;pages=1-10&amp;publication_year=2022&amp;author=Caucheteux%2CC&amp;author=King%2CJ-R">
                    Google Scholar</a> 
                </p></li><li data-counter="8."><p id="ref-CR8">Caucheteux, C., Gramfort, A., &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In <i>International Conference on Machine Learning</i>, 1336–1348. PMLR, (2021b).</p></li><li data-counter="9."><p id="ref-CR9">Hale, J., Campanelli, L., Li, J., Bhattasali, S., Pallier, C. &amp; Brennan, J. Neuro-computational models of language processing. <i>Annu. Rev. Linguist.</i>, (2021).</p></li><li data-counter="10."><p id="ref-CR10">Anderson, A. J. <i>et al.</i> Deep artificial neural networks reveal a distributed cortical network encoding propositional sentence-level meaning. <i>J. Neurosci.</i> <b>41</b>(18), 4100–4119. <a href="https://doi.org/10.1523/JNEUROSCI.1152-20.2021">https://doi.org/10.1523/JNEUROSCI.1152-20.2021</a> (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhtlWlurfP" aria-label="CAS reference 10">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1152-20.2021" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1152-20.2021" aria-label="Article reference 10">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33753548" aria-label="PubMed reference 10">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8176751" aria-label="PubMed Central reference 10">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20artificial%20neural%20networks%20reveal%20a%20distributed%20cortical%20network%20encoding%20propositional%20sentence-level%20meaning&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1152-20.2021&amp;volume=41&amp;issue=18&amp;pages=4100-4119&amp;publication_year=2021&amp;author=Anderson%2CAJ">
                    Google Scholar</a> 
                </p></li><li data-counter="11."><p id="ref-CR11">Jingyuan, S., Shaonan, W., Jiajun, Z. &amp; Chengqing, Z. Neural encoding and decoding with distributed sentence representations. <i>IEEE Trans. Neural Netw. Learn. Syst.</i> <b>32</b>(2), 589–603. <a href="https://doi.org/10.1109/TNNLS.2020.3027595">https://doi.org/10.1109/TNNLS.2020.3027595</a> (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TNNLS.2020.3027595" data-track-action="article reference" href="https://doi.org/10.1109%2FTNNLS.2020.3027595" aria-label="Article reference 11">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20encoding%20and%20decoding%20with%20distributed%20sentence%20representations&amp;journal=IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.&amp;doi=10.1109%2FTNNLS.2020.3027595&amp;volume=32&amp;issue=2&amp;pages=589-603&amp;publication_year=2021&amp;author=Jingyuan%2CS&amp;author=Shaonan%2CW&amp;author=Jiajun%2CZ&amp;author=Chengqing%2CZ">
                    Google Scholar</a> 
                </p></li><li data-counter="12."><p id="ref-CR12">Goldstein, A. <i>et al.</i> Thinking ahead: Prediction in context as a keystone of language in humans and machines. <i>bioRxiv</i><a href="https://doi.org/10.1101/2020.12.02.403477">https://doi.org/10.1101/2020.12.02.403477</a> (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1101/2020.12.02.403477" data-track-action="article reference" href="https://doi.org/10.1101%2F2020.12.02.403477" aria-label="Article reference 12">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33564759" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7872347" aria-label="PubMed Central reference 12">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Thinking%20ahead%3A%20Prediction%20in%20context%20as%20a%20keystone%20of%20language%20in%20humans%20and%20machines&amp;journal=bioRxiv&amp;doi=10.1101%2F2020.12.02.403477&amp;publication_year=2021&amp;author=Goldstein%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="13."><p id="ref-CR13">Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., &amp; Kiela, D. Adversarial nli: A new benchmark for natural language understanding. <i>arXiv preprint</i><a href="http://arxiv.org/abs/1910.14599">arXiv:1910.14599</a>, (2019).</p></li><li data-counter="14."><p id="ref-CR14">Lakretz, Y., Desbordes, T., King, J.-R. Crabbé, B., Oquab, M. &amp; Dehaene, S. Can RNNs learn recursive nested subject-verb agreements? <a href="http://arxiv.org/abs/2101.02258">arXiv:2101.02258</a> [cs], (2021).</p></li><li data-counter="15."><p id="ref-CR15">Hupkes, D., Dankers, V., Mul, M. &amp; Bruni, E. Compositionality decomposed: How do neural networks generalise?. <i>J. Artif. Intell. Res.</i> <b>67</b>, 757–795 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=4084229" aria-label="MathSciNet reference 15">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1613/jair.1.11674" data-track-action="article reference" href="https://doi.org/10.1613%2Fjair.1.11674" aria-label="Article reference 15">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Compositionality%20decomposed%3A%20How%20do%20neural%20networks%20generalise%3F&amp;journal=J.%20Artif.%20Intell.%20Res.&amp;doi=10.1613%2Fjair.1.11674&amp;volume=67&amp;pages=757-795&amp;publication_year=2020&amp;author=Hupkes%2CD&amp;author=Dankers%2CV&amp;author=Mul%2CM&amp;author=Bruni%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="16."><p id="ref-CR16">Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. <a href="http://arxiv.org/abs/2008.01766">arXiv:2008.01766</a> [cs], (2021).</p></li><li data-counter="17."><p id="ref-CR17">Linzen, T. &amp; Baroni, M. Syntactic structure from deep learning. <i>Annu. Rev. Linguist.</i> <b>7</b>, 195–212 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-linguistics-032020-051035" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-linguistics-032020-051035" aria-label="Article reference 17">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Syntactic%20structure%20from%20deep%20learning&amp;journal=Annu.%20Rev.%20Linguist.&amp;doi=10.1146%2Fannurev-linguistics-032020-051035&amp;volume=7&amp;pages=195-212&amp;publication_year=2021&amp;author=Linzen%2CT&amp;author=Baroni%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="18."><p id="ref-CR18">McClelland, J. L., Hill, F., Rudolph, M., Baldridge, J. &amp; Schütze, H. Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models. <i>Proc. Natl. Acad. Sci.</i> <b>117</b>(42), 25966–25974. <a href="https://doi.org/10.1073/pnas.1910416117">https://doi.org/10.1073/pnas.1910416117</a> (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020PNAS..11725966M" aria-label="ADS reference 18">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXitFCktrbF" aria-label="CAS reference 18">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1910416117" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1910416117" aria-label="Article reference 18">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32989131" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7585006" aria-label="PubMed Central reference 18">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Placing%20language%20in%20an%20integrated%20understanding%20system%3A%20Next%20steps%20toward%20human-level%20performance%20in%20neural%20language%20models&amp;journal=Proc.%20Natl.%20Acad.%20Sci.&amp;doi=10.1073%2Fpnas.1910416117&amp;volume=117&amp;issue=42&amp;pages=25966-25974&amp;publication_year=2020&amp;author=McClelland%2CJL&amp;author=Hill%2CF&amp;author=Rudolph%2CM&amp;author=Baldridge%2CJ&amp;author=Sch%C3%BCtze%2CH">
                    Google Scholar</a> 
                </p></li><li data-counter="19."><p id="ref-CR19">Gary, M. Gpt-2 and the nature of intelligence. <i>The Gradient</i>. <a href="https://thegradient.pub/gpt2-and-the-nature-of-intelligence/">https://thegradient.pub/gpt2-and-the-nature-of-intelligence/</a> (2020).</p></li><li data-counter="20."><p id="ref-CR20">Holtzman, A., Buys, J., Du, L., Forbes, M. &amp; Choi, Y. The curious case of neural text degeneration. <a href="http://arxiv.org/abs/1904.09751">arXiv:1904.09751</a> [cs], (2020).</p></li><li data-counter="21."><p id="ref-CR21">Wiseman, S., Shieber, S. M. &amp; Rush, A. M. Challenges in data-to-document generation. <a href="http://arxiv.org/abs/1707.08052">arXiv:1707.08052</a> [cs], (2017).</p></li><li data-counter="22."><p id="ref-CR22">Thakur, N., Reimers, N., Ruckle, A., Srivastava, A., &amp; Gurevych, I. BEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models. <a href="http://arxiv.org/abs/2104.08663">arXiv:2104.08663</a> [cs], (2021).</p></li><li data-counter="23."><p id="ref-CR23">Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W. &amp; Liu, P.J. Exploring the limits of transfer learning with a unified text-to-text transformer. <a href="http://arxiv.org/abs/1910.10683">arXiv:1910.10683</a> [cs, stat], (2020).</p></li><li data-counter="24."><p id="ref-CR24">Krishna, K., Roy, A. &amp; Iyyer, M. Hurdles to progress in long-form question answering. <a href="http://arxiv.org/abs/2103.06332">arXiv:2103.06332</a> [cs], (2021).</p></li><li data-counter="25."><p id="ref-CR25">Yamins, D. L. K. <i>et al.</i> Performance-optimized hierarchical models predict neural responses in higher visual cortex. <i>Proc. Natl. Acad. Sci.</i> <b>111</b>(23), 8619–8624. <a href="https://doi.org/10.1073/pnas.1403112111">https://doi.org/10.1073/pnas.1403112111</a> (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2014PNAS..111.8619Y" aria-label="ADS reference 25">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXnslWnsb4%3D" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1403112111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1403112111" aria-label="Article reference 25">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24812127" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4060707" aria-label="PubMed Central reference 25">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance-optimized%20hierarchical%20models%20predict%20neural%20responses%20in%20higher%20visual%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.&amp;doi=10.1073%2Fpnas.1403112111&amp;volume=111&amp;issue=23&amp;pages=8619-8624&amp;publication_year=2014&amp;author=Yamins%2CDLK&amp;author=Hong%2CH&amp;author=Cadieu%2CCF&amp;author=Solomon%2CEA&amp;author=Seibert%2CD&amp;author=DiCarlo%2CJJ">
                    Google Scholar</a> 
                </p></li><li data-counter="26."><p id="ref-CR26">Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. <i>Nature</i> <b>532</b>(7600), 453–458. <a href="https://doi.org/10.1038/nature17637">https://doi.org/10.1038/nature17637</a> (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016Natur.532..453H" aria-label="ADS reference 26">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature17637" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature17637" aria-label="Article reference 26">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27121839" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309" aria-label="PubMed Central reference 26">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20speech%20reveals%20the%20semantic%20maps%20that%20tile%20human%20cerebral%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fnature17637&amp;volume=532&amp;issue=7600&amp;pages=453-458&amp;publication_year=2016&amp;author=Huth%2CAG&amp;author=Heer%2CWA&amp;author=Griffiths%2CTL&amp;author=Theunissen%2CFE&amp;author=Gallant%2CJL">
                    Google Scholar</a> 
                </p></li><li data-counter="27."><p id="ref-CR27">Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. <i>Neuroimage</i> <b>53</b>(1), 1–15. <a href="https://doi.org/10.1016/j.neuroimage.2010.06.010">https://doi.org/10.1016/j.neuroimage.2010.06.010</a> (2010).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.010" aria-label="Article reference 27">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20547229" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20parcellation%20of%20human%20cortical%20gyri%20and%20sulci%20using%20standard%20anatomical%20nomenclature&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.010&amp;volume=53&amp;issue=1&amp;pages=1-15&amp;publication_year=2010&amp;author=Destrieux%2CC&amp;author=Fischl%2CB&amp;author=Dale%2CA&amp;author=Halgren%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="28."><p id="ref-CR28">Virtanen, P. <i>et al.</i> SciPy 1.0 contributors. SciPy 1.0: Fundamental algorithms for scientific computing in python. <i>Nat. Methods</i> <b>17</b>, 261–272. <a href="https://doi.org/10.1038/s41592-019-0686-2">https://doi.org/10.1038/s41592-019-0686-2</a> (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXislCjuro%3D" aria-label="CAS reference 28">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41592-019-0686-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41592-019-0686-2" aria-label="Article reference 28">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32015543" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7056644" aria-label="PubMed Central reference 28">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=SciPy%201.0%20contributors.%20SciPy%201.0%3A%20Fundamental%20algorithms%20for%20scientific%20computing%20in%20python&amp;journal=Nat.%20Methods&amp;doi=10.1038%2Fs41592-019-0686-2&amp;volume=17&amp;pages=261-272&amp;publication_year=2020&amp;author=Virtanen%2CP&amp;author=Gommers%2CR&amp;author=Oliphant%2CTE&amp;author=Haberland%2CM&amp;author=Reddy%2CT&amp;author=Cournapeau%2CD&amp;author=Burovski%2CE&amp;author=Peterson%2CP&amp;author=Weckesser%2CW&amp;author=Bright%2CJ&amp;author=Walt%2CSJ">
                    Google Scholar</a> 
                </p></li><li data-counter="29."><p id="ref-CR29">Jain, S. &amp; Huth, A. G. Incorporating context into language encoding models for fMRI. preprint, Neuroscience (2018).</p></li><li data-counter="30."><p id="ref-CR30">Schrimpf, M., Kubilius, J., Hong, H., Majaj, N.J., Rajalingham, R., Issa, E.B., Kar, K., Bashivan, P., Prescott-Roy, J., Geiger, F. &amp; Schmidt, K., Brain-score: Which artificial neural network for object recognition is most brain-like? preprint, Neuroscience (2018).</p></li><li data-counter="31."><p id="ref-CR31">Mesgarani, N. &amp; Chang, E. F. Selective cortical representation of attended speaker in multi-talker speech perception. <i>Nature</i> <b>485</b>(7397), 233–236. <a href="https://doi.org/10.1038/nature11020">https://doi.org/10.1038/nature11020</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012Natur.485..233M" aria-label="ADS reference 31">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC38XlslShur8%3D" aria-label="CAS reference 31">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature11020" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature11020" aria-label="Article reference 31">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22522927" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Selective%20cortical%20representation%20of%20attended%20speaker%20in%20multi-talker%20speech%20perception&amp;journal=Nature&amp;doi=10.1038%2Fnature11020&amp;volume=485&amp;issue=7397&amp;pages=233-236&amp;publication_year=2012&amp;author=Mesgarani%2CN&amp;author=Chang%2CEF">
                    Google Scholar</a> 
                </p></li><li data-counter="32."><p id="ref-CR32">Cohen, L., Salondy, P., Pallier, C. &amp; Dehaene, S. How does inattention affect written and spoken language processing?. <i>Cortex</i> <b>138</b>, 212–227 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cortex.2021.02.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cortex.2021.02.007" aria-label="Article reference 32">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20does%20inattention%20affect%20written%20and%20spoken%20language%20processing%3F&amp;journal=Cortex&amp;doi=10.1016%2Fj.cortex.2021.02.007&amp;volume=138&amp;pages=212-227&amp;publication_year=2021&amp;author=Cohen%2CL&amp;author=Salondy%2CP&amp;author=Pallier%2CC&amp;author=Dehaene%2CS">
                    Google Scholar</a> 
                </p></li><li data-counter="33."><p id="ref-CR33">Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. <i>J. Neurosci.</i> <b>31</b>(8), 2906–2915. <a href="https://doi.org/10.1523/JNEUROSCI.3684-10.2011">https://doi.org/10.1523/JNEUROSCI.3684-10.2011</a> (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXislGitrs%3D" aria-label="CAS reference 33">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3684-10.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3684-10.2011" aria-label="Article reference 33">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21414912" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3089381" aria-label="PubMed Central reference 33">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Topographic%20mapping%20of%20a%20hierarchy%20of%20temporal%20receptive%20windows%20using%20a%20narrated%20story&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3684-10.2011&amp;volume=31&amp;issue=8&amp;pages=2906-2915&amp;publication_year=2011&amp;author=Lerner%2CY&amp;author=Honey%2CCJ&amp;author=Silbert%2CLJ&amp;author=Hasson%2CU">
                    Google Scholar</a> 
                </p></li><li data-counter="34."><p id="ref-CR34">Pallier, C., Devauchelle, A.-D. &amp; Dehaene, S. Cortical representation of the constituent structure of sentences. <i>Proc. Natl. Acad. Sci.</i> <b>108</b>(6), 2522–2527. <a href="https://doi.org/10.1073/pnas.1018711108">https://doi.org/10.1073/pnas.1018711108</a> (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2011PNAS..108.2522P" aria-label="ADS reference 34">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1018711108" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1018711108" aria-label="Article reference 34">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21224415" aria-label="PubMed reference 34">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3038732" aria-label="PubMed Central reference 34">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20representation%20of%20the%20constituent%20structure%20of%20sentences&amp;journal=Proc.%20Natl.%20Acad.%20Sci.&amp;doi=10.1073%2Fpnas.1018711108&amp;volume=108&amp;issue=6&amp;pages=2522-2527&amp;publication_year=2011&amp;author=Pallier%2CC&amp;author=Devauchelle%2CA-D&amp;author=Dehaene%2CS">
                    Google Scholar</a> 
                </p></li><li data-counter="35."><p id="ref-CR35">Fedorenko, E. <i>et al.</i> Neural correlate of the construction of sentence meaning. <i>Proc. Natl. Acad. Sci. USA</i><a href="https://doi.org/10.1073/pnas.1612132113">https://doi.org/10.1073/pnas.1612132113</a> (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1612132113" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1612132113" aria-label="Article reference 35">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27671642" aria-label="PubMed reference 35">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5068329" aria-label="PubMed Central reference 35">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlate%20of%20the%20construction%20of%20sentence%20meaning&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1612132113&amp;publication_year=2016&amp;author=Fedorenko%2CE&amp;author=Scott%2CT&amp;author=Brunner%2CP&amp;author=Coon%2CW&amp;author=Pritchett%2CB&amp;author=Schalk%2CG&amp;author=Kanwisher%2CN">
                    Google Scholar</a> 
                </p></li><li data-counter="36."><p id="ref-CR36">Friederici, A. D. The brain basis of language processing: From structure to function. <i>Physiol. Rev.</i> <b>91</b>(4), 1357–1392. <a href="https://doi.org/10.1152/physrev.00006.2011">https://doi.org/10.1152/physrev.00006.2011</a> (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/physrev.00006.2011" data-track-action="article reference" href="https://doi.org/10.1152%2Fphysrev.00006.2011" aria-label="Article reference 36">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22013214" aria-label="PubMed reference 36">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20brain%20basis%20of%20language%20processing%3A%20From%20structure%20to%20function&amp;journal=Physiol.%20Rev.&amp;doi=10.1152%2Fphysrev.00006.2011&amp;volume=91&amp;issue=4&amp;pages=1357-1392&amp;publication_year=2011&amp;author=Friederici%2CAD">
                    Google Scholar</a> 
                </p></li><li data-counter="37."><p id="ref-CR37">Hickok, G. &amp; Poeppel, D. The cortical organization of speech processing. <i>Nat. Rev. Neurosci.</i> <b>8</b>(5), 393–402. <a href="https://doi.org/10.1038/nrn2113">https://doi.org/10.1038/nrn2113</a> (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXksFSis7w%3D" aria-label="CAS reference 37">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2113" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2113" aria-label="Article reference 37">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17431404" aria-label="PubMed reference 37">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cortical%20organization%20of%20speech%20processing&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2113&amp;volume=8&amp;issue=5&amp;pages=393-402&amp;publication_year=2007&amp;author=Hickok%2CG&amp;author=Poeppel%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="38."><p id="ref-CR38">Hagoort, P., Baggio, G. &amp; Wlllems, R. M.. Semantic unification. In <i>The Cognitive Neurosciences</i>, 4th ed., 819–835 ( Massachusetts Institute of Technology, Cambridge, MA, 2009).</p></li><li data-counter="39."><p id="ref-CR39">Hagoort, P. MUC (Memory, Unification, Control) and beyond. <i>Front. Psychol.</i> <b>4</b>, 416 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fpsyg.2013.00416" data-track-action="article reference" href="https://doi.org/10.3389%2Ffpsyg.2013.00416" aria-label="Article reference 39">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=MUC%20%28Memory%2C%20Unification%2C%20Control%29%20and%20beyond&amp;journal=Front.%20Psychol.&amp;doi=10.3389%2Ffpsyg.2013.00416&amp;volume=4&amp;publication_year=2013&amp;author=Hagoort%2CP">
                    Google Scholar</a> 
                </p></li><li data-counter="40."><p id="ref-CR40">Hagoort, P. &amp; Indefrey, P. The neurobiology of language beyond single words. <i>Annu. Rev. Neurosci.</i> <b>37</b>, 347–362. <a href="https://doi.org/10.1146/annurev-neuro-071013-013847">https://doi.org/10.1146/annurev-neuro-071013-013847</a> (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhsVKgtL7K" aria-label="CAS reference 40">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-neuro-071013-013847" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-neuro-071013-013847" aria-label="Article reference 40">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24905595" aria-label="PubMed reference 40">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neurobiology%20of%20language%20beyond%20single%20words&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev-neuro-071013-013847&amp;volume=37&amp;pages=347-362&amp;publication_year=2014&amp;author=Hagoort%2CP&amp;author=Indefrey%2CP">
                    Google Scholar</a> 
                </p></li><li data-counter="41."><p id="ref-CR41">Bornkessel-Schlesewsky, I. &amp; Schlesewsky, M. The extended argument dependency model: A neurocognitive approach to sentence comprehension across languages. <i>Psychol. Rev.</i> <b>113</b>, 787–821. <a href="https://doi.org/10.1037/0033-295X.113.4.787">https://doi.org/10.1037/0033-295X.113.4.787</a> (2006).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-295X.113.4.787" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.113.4.787" aria-label="Article reference 41">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20extended%20argument%20dependency%20model%3A%20A%20neurocognitive%20approach%20to%20sentence%20comprehension%20across%20languages&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.113.4.787&amp;volume=113&amp;pages=787-821&amp;publication_year=2006&amp;author=Bornkessel-Schlesewsky%2CI&amp;author=Schlesewsky%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="42."><p id="ref-CR42">Bornkessel-Schlesewsky, I. &amp; Schlesewsky, M. Reconciling time, space and function: a new dorsal-ventral stream model of sentence comprehension. <i>Brain Lang.</i> <b>125</b>(1), 60–76. <a href="https://doi.org/10.1016/j.bandl.2013.01.010">https://doi.org/10.1016/j.bandl.2013.01.010</a> (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.bandl.2013.01.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bandl.2013.01.010" aria-label="Article reference 42">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23454075" aria-label="PubMed reference 42">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Reconciling%20time%2C%20space%20and%20function%3A%20a%20new%20dorsal-ventral%20stream%20model%20of%20sentence%20comprehension&amp;journal=Brain%20Lang.&amp;doi=10.1016%2Fj.bandl.2013.01.010&amp;volume=125&amp;issue=1&amp;pages=60-76&amp;publication_year=2013&amp;author=Bornkessel-Schlesewsky%2CI&amp;author=Schlesewsky%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="43."><p id="ref-CR43">Ullman, M. T. A neurocognitive perspective on language: The declarative/procedural model. <i>Nat. Rev. Neurosci.</i> <b>2</b>(10), 717–726. <a href="https://doi.org/10.1038/35094573">https://doi.org/10.1038/35094573</a> (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BD38Xmt1WhtLs%3D" aria-label="CAS reference 43">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/35094573" data-track-action="article reference" href="https://doi.org/10.1038%2F35094573" aria-label="Article reference 43">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11584309" aria-label="PubMed reference 43">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20neurocognitive%20perspective%20on%20language%3A%20The%20declarative%2Fprocedural%20model&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2F35094573&amp;volume=2&amp;issue=10&amp;pages=717-726&amp;publication_year=2001&amp;author=Ullman%2CMT">
                    Google Scholar</a> 
                </p></li><li data-counter="44."><p id="ref-CR44">Lu, Q., Hasson, U. &amp; Norman, K. A. A neural network model of when to retrieve and encode episodic memories. <i>Elife</i> <b>11</b>, e74445. <a href="https://doi.org/10.7554/eLife.74445">https://doi.org/10.7554/eLife.74445</a> (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BB38XhvF2ht7bE" aria-label="CAS reference 44">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.74445" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.74445" aria-label="Article reference 44">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35142289" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9000961" aria-label="PubMed Central reference 44">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20neural%20network%20model%20of%20when%20to%20retrieve%20and%20encode%20episodic%20memories&amp;journal=Elife&amp;doi=10.7554%2FeLife.74445&amp;volume=11&amp;publication_year=2022&amp;author=Lu%2CQ&amp;author=Hasson%2CU&amp;author=Norman%2CKA">
                    Google Scholar</a> 
                </p></li><li data-counter="45."><p id="ref-CR45">Dehghani, M. <i>et al.</i> Decoding the neural representation of story meanings across languages: Decoding the neural representation. <i>Hum. Brain Mapp.</i> <b>38</b>(12), 6096–6106. <a href="https://doi.org/10.1002/hbm.23814">https://doi.org/10.1002/hbm.23814</a> (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hbm.23814" data-track-action="article reference" href="https://doi.org/10.1002%2Fhbm.23814" aria-label="Article reference 45">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28940969" aria-label="PubMed reference 45">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6867091" aria-label="PubMed Central reference 45">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20the%20neural%20representation%20of%20story%20meanings%20across%20languages%3A%20Decoding%20the%20neural%20representation&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2Fhbm.23814&amp;volume=38&amp;issue=12&amp;pages=6096-6106&amp;publication_year=2017&amp;author=Dehghani%2CM&amp;author=Boghrati%2CR&amp;author=Man%2CK&amp;author=Hoover%2CJ&amp;author=Gimbel%2CSI&amp;author=Vaswani%2CA&amp;author=Zevin%2CJD&amp;author=Immordino-Yang%2CMH&amp;author=Gordon%2CAS&amp;author=Damasio%2CA&amp;author=Kaplan%2CJT">
                    Google Scholar</a> 
                </p></li><li data-counter="46."><p id="ref-CR46">Broderick, M. P., Zuk, N. J., Anderson, A. J. &amp; Lalor E. C. More than Words: Neurophysiological correlates of semantic dissimilarity depend on comprehension of the speech narrative. preprint, Neuroscience (2020).</p></li><li data-counter="47."><p id="ref-CR47">Broderick, M. P., Anderson, A. J., Di Liberto, G. M., Crosse, M. J. &amp; Lalor, E. C. Electrophysiological Correlates of Semantic Dissimilarity Reflect the Comprehension of Natural. <i>Narrative Speech. Curr. Biol.</i> <b>28</b>(5), 803–809. <a href="https://doi.org/10.1016/j.cub.2018.01.080">https://doi.org/10.1016/j.cub.2018.01.080</a> (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXjt1SgsLc%3D" aria-label="CAS reference 47">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2018.01.080" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2018.01.080" aria-label="Article reference 47">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29478856" aria-label="PubMed reference 47">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrophysiological%20Correlates%20of%20Semantic%20Dissimilarity%20Reflect%20the%20Comprehension%20of%20Natural&amp;journal=Narrative%20Speech.%20Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2018.01.080&amp;volume=28&amp;issue=5&amp;pages=803-809&amp;publication_year=2018&amp;author=Broderick%2CMP&amp;author=Anderson%2CAJ&amp;author=Liberto%2CGM&amp;author=Crosse%2CMJ&amp;author=Lalor%2CEC">
                    Google Scholar</a> 
                </p></li><li data-counter="48."><p id="ref-CR48">Sabri, M. <i>et al.</i> Attentional and linguistic interactions in speech perception. <i>Neuroimage</i> <b>39</b>(3), 1444–1456. <a href="https://doi.org/10.1016/j.neuroimage.2007.09.052">https://doi.org/10.1016/j.neuroimage.2007.09.052</a> (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2007.09.052" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2007.09.052" aria-label="Article reference 48">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17996463" aria-label="PubMed reference 48">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Attentional%20and%20linguistic%20interactions%20in%20speech%20perception&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2007.09.052&amp;volume=39&amp;issue=3&amp;pages=1444-1456&amp;publication_year=2008&amp;author=Sabri%2CM&amp;author=Binder%2CJR&amp;author=Desai%2CR&amp;author=Medler%2CDA&amp;author=Leitl%2CMD&amp;author=Liebenthal%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="49."><p id="ref-CR49">Kok, P., Jehee, J. F. M. &amp; de Lange, F. P. Less is more: Expectation sharpens representations in the primary visual cortex. <i>Neuron</i> <b>75</b>(2), 265–270. <a href="https://doi.org/10.1016/j.neuron.2012.04.034">https://doi.org/10.1016/j.neuron.2012.04.034</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhtV2nurvO" aria-label="CAS reference 49">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2012.04.034" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2012.04.034" aria-label="Article reference 49">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22841311" aria-label="PubMed reference 49">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Less%20is%20more%3A%20Expectation%20sharpens%20representations%20in%20the%20primary%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2012.04.034&amp;volume=75&amp;issue=2&amp;pages=265-270&amp;publication_year=2012&amp;author=Kok%2CP&amp;author=Jehee%2CJFM&amp;author=Lange%2CFP">
                    Google Scholar</a> 
                </p></li><li data-counter="50."><p id="ref-CR50">Caucheteux, C., Gramfort, A. &amp; King, J.-R. Long-range and hierarchical language predictions in brains and algorithms. <a href="http://arxiv.org/abs/2111.14232">arXiv:2111.14232</a> [cs, q-bio], (2021).</p></li><li data-counter="51."><p id="ref-CR51">Scott, M. <i>et al.</i> Reproducible brain-wide association studies require thousands of individuals. <i>Nature</i><a href="https://doi.org/10.1038/s41586-022-04492-9">https://doi.org/10.1038/s41586-022-04492-9</a> (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-022-04492-9" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-022-04492-9" aria-label="Article reference 51">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36131014" aria-label="PubMed reference 51">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9259496" aria-label="PubMed Central reference 51">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Reproducible%20brain-wide%20association%20studies%20require%20thousands%20of%20individuals&amp;journal=Nature&amp;doi=10.1038%2Fs41586-022-04492-9&amp;publication_year=2022&amp;author=Scott%2CM&amp;author=Brenden%2CTC&amp;author=Calabro%2CFJ&amp;author=Montez%2CDF&amp;author=Kay%2CBP&amp;author=Hatoum%2CAS&amp;author=Donohue%2CMR&amp;author=Foran%2CW&amp;author=Miller%2CRL&amp;author=Hendrickson%2CTJ&amp;author=Malone%2CSM&amp;author=Kandala%2CS&amp;author=Feczko%2CE&amp;author=Miranda-Dominguez%2CO&amp;author=Graham%2CAM&amp;author=Earl%2CEA&amp;author=Perrone%2CAJ&amp;author=Cordova%2CM&amp;author=Doyle%2CO&amp;author=Moore%2CLA&amp;author=Conan%2CGM&amp;author=Uriarte%2CJ&amp;author=Snider%2CK&amp;author=Lynch%2CBJ&amp;author=Wilgenbusch%2CJC&amp;author=Pengo%2CT&amp;author=Tam%2CA&amp;author=Chen%2CJ&amp;author=Newbold%2CDJ&amp;author=Zheng%2CA&amp;author=Seider%2CNA&amp;author=Van%2CAN&amp;author=Metoki%2CA&amp;author=Chauvin%2CRJ&amp;author=Laumann%2CTO&amp;author=Greene%2CDJ&amp;author=Petersen%2CSE&amp;author=Garavan%2CH&amp;author=Thompson%2CWK&amp;author=Nichols%2CTE&amp;author=Yeo%2CBTT&amp;author=Barch%2CDM&amp;author=Luna%2CB&amp;author=Fair%2CDA&amp;author=Nico%2CUFD">
                    Google Scholar</a> 
                </p></li><li data-counter="52."><p id="ref-CR52">Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. <i>Proc. Natl. Acad. Sci.</i><a href="https://doi.org/10.1073/pnas.1907367117">https://doi.org/10.1073/pnas.1907367117</a> (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1907367117" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1907367117" aria-label="Article reference 52">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33234572" aria-label="PubMed reference 52">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7768717" aria-label="PubMed Central reference 52">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Emergent%20linguistic%20structure%20in%20artificial%20neural%20networks%20trained%20by%20self-supervision&amp;journal=Proc.%20Natl.%20Acad.%20Sci.&amp;doi=10.1073%2Fpnas.1907367117&amp;publication_year=2020&amp;author=Manning%2CCD&amp;author=Clark%2CK&amp;author=Hewitt%2CJ&amp;author=Khandelwal%2CU&amp;author=Levy%2CO">
                    Google Scholar</a> 
                </p></li><li data-counter="53."><p id="ref-CR53">Gauthier, J. &amp; Levy, R. Linking artificial and human neural representations of language. In <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</i>, 529–539, Hong Kong, China, (2019). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D19-1050">https://doi.org/10.18653/v1/D19-1050</a>.</p></li><li data-counter="54."><p id="ref-CR54">Reddy, A. J. &amp; Wehbe, L. Syntactic representations in the human brain: Beyond effort-based metrics. preprint, Neuroscience (2020).</p></li><li data-counter="55."><p id="ref-CR55">Yamins, D. L. K. &amp; DiCarlo, J. J. Using goal-driven deep learning models to understand sensory cortex. <i>Nat. Neurosci.</i> <b>19</b>(3), 356–365. <a href="https://doi.org/10.1038/nn.4244">https://doi.org/10.1038/nn.4244</a> (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://mytimeatrecurse.substack.com/articles/cas-redirect/1:CAS:528:DC%2BC28XjtVOjt7k%3D" aria-label="CAS reference 55">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4244" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4244" aria-label="Article reference 55">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26906502" aria-label="PubMed reference 55">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20goal-driven%20deep%20learning%20models%20to%20understand%20sensory%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4244&amp;volume=19&amp;issue=3&amp;pages=356-365&amp;publication_year=2016&amp;author=Yamins%2CDLK&amp;author=DiCarlo%2CJJ">
                    Google Scholar</a> 
                </p></li><li data-counter="56."><p id="ref-CR56">Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. <i>Philos. Trans. R. Soc. B Biol. Sci.</i> <b>375</b>(1791), 20190307. <a href="https://doi.org/10.1098/rstb.2019.0307">https://doi.org/10.1098/rstb.2019.0307</a> (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2019.0307" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2019.0307" aria-label="Article reference 56">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Linguistic%20generalization%20and%20compositionality%20in%20modern%20artificial%20neural%20networks&amp;journal=Philos.%20Trans.%20R.%20Soc.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2019.0307&amp;volume=375&amp;issue=1791&amp;publication_year=2020&amp;author=Baroni%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="57."><p id="ref-CR57">Bisk, Y., Holtzman, A., Thomason, J., Andreas, J., Bengio, Y., Chai, J., Lapata, M., Lazaridou, A., May, J., Nisnevich, A., Pinto, N. &amp; Turian, J. Experience grounds language. <a href="http://arxiv.org/abs/2004.10151">arXiv:2004.10151</a> [cs], (2020).</p></li><li data-counter="58."><p id="ref-CR58">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I. &amp; Amodei, D. Language models are few-shot learners. <a href="http://arxiv.org/abs/2005.14165">arXiv:2005.14165</a> [cs], (2020).</p></li><li data-counter="59."><p id="ref-CR59">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G. &amp; Sutskever, I. Learning transferable visual models from natural language supervision. <a href="http://arxiv.org/abs/2103.00020">arXiv:2103.00020</a> [cs], (2021).</p></li><li data-counter="60."><p id="ref-CR60">Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M. &amp; Sutskever, I. Zero-shot text-to-image generation. <a href="http://arxiv.org/abs/2102.12092">arXiv:2102.12092</a> [cs], (2021).</p></li><li data-counter="61."><p id="ref-CR61">Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A. &amp; Hasson, U. Narratives: fMRI data for evaluating models of naturalistic language comprehension. preprint, Neuroscience (2020).</p></li><li data-counter="62."><p id="ref-CR62">Jawahar, G., Sagot, B. &amp; Seddah, D. What Does BERT learn about the structure of language? In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</i>, 3651–3657, Florence, Italy, (2019). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P19-1356">https://doi.org/10.18653/v1/P19-1356</a>.</p></li><li data-counter="63."><p id="ref-CR63">Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T. L., Gugger, S., Drame, M., Lhoest, Q. &amp; Rush, A. M. Transformers: State-of-the-art natural language processing. In <i>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</i>, 38–45, Online (2020). Association for Computational Linguistics.</p></li><li data-counter="64."><p id="ref-CR64">Pedregosa, F. <i>et al.</i> Scikit-learn: Machine learning in Python. <i>J. Mach. Learn. Res.</i> <b>12</b>, 2825–2830 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2854348" aria-label="MathSciNet reference 64">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="math reference" href="http://www.emis.de/MATH-item?1280.68189" aria-label="MATH reference 64">MATH</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Scikit-learn%3A%20Machine%20learning%20in%20Python&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=12&amp;pages=2825-2830&amp;publication_year=2011&amp;author=Pedregosa%2CF&amp;author=Varoquaux%2CG&amp;author=Gramfort%2CA&amp;author=Michel%2CV&amp;author=Thirion%2CB&amp;author=Grisel%2CO&amp;author=Blondel%2CM&amp;author=Prettenhofer%2CP&amp;author=Weiss%2CR&amp;author=Dubourg%2CV&amp;author=Vanderplas%2CJ&amp;author=Passos%2CA&amp;author=Cournapeau%2CD&amp;author=Brucher%2CM&amp;author=Perrot%2CM&amp;author=Duchesnay%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="65."><p id="ref-CR65">Gentle. <a href="https://lowerquality.com/gentle/">https://lowerquality.com/gentle/</a>.</p></li><li data-counter="66."><p id="ref-CR66">Gramfort, A. <i>et al.</i> MEG and EEG data analysis with MNE-Python. <i>Front. Neurosci.</i> <b>7</b>(267), 1–13. <a href="https://doi.org/10.3389/fnins.2013.00267">https://doi.org/10.3389/fnins.2013.00267</a> (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnins.2013.00267" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnins.2013.00267" aria-label="Article reference 66">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=MEG%20and%20EEG%20data%20analysis%20with%20MNE-Python&amp;journal=Front.%20Neurosci.&amp;doi=10.3389%2Ffnins.2013.00267&amp;volume=7&amp;issue=267&amp;pages=1-13&amp;publication_year=2013&amp;author=Gramfort%2CA&amp;author=Luessi%2CM&amp;author=Larson%2CE&amp;author=Engemann%2CDA&amp;author=Strohmeier%2CD&amp;author=Brodbeck%2CC&amp;author=Goj%2CR&amp;author=Jas%2CM&amp;author=Brooks%2CT&amp;author=Parkkonen%2CL&amp;author=H%C3%A4m%C3%A4l%C3%A4inen%2CMS">
                    Google Scholar</a> 
                </p></li><li data-counter="67."><p id="ref-CR67">Seabold, S. &amp; Perktold, J. Statsmodels: Econometric and statistical modeling with python. In <i>9th Python in Science Conference</i>, (2010).</p></li><li data-counter="68."><p id="ref-CR68">Nunez-Elizalde, A. O., Huth, A. G. &amp; Gallant, J. L. Voxelwise encoding models with non-spherical multivariate normal priors. <i>Neuroimage</i> <b>197</b>, 482–492. <a href="https://doi.org/10.1016/j.neuroimage.2019.04.012">https://doi.org/10.1016/j.neuroimage.2019.04.012</a> (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2019.04.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2019.04.012" aria-label="Article reference 68">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31075394" aria-label="PubMed reference 68">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Voxelwise%20encoding%20models%20with%20non-spherical%20multivariate%20normal%20priors&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2019.04.012&amp;volume=197&amp;pages=482-492&amp;publication_year=2019&amp;author=Nunez-Elizalde%2CAO&amp;author=Huth%2CAG&amp;author=Gallant%2CJL">
                    Google Scholar</a> 
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-022-20460-9?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div id="Ack1-section"><h2 id="Ack1">Acknowledgements</h2><p>We are grateful to Sam Nastase and collaborators for providing additional information on the Narrative datasets. This work was supported by ANR-17-EURE-0017, the Fyssen Foundation and the Bettencourt Foundation to JRK for his work at PSL.</p></div></section><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Meta AI Research, Paris, France</p><p>Charlotte Caucheteux &amp; Jean-Rémi King</p></li><li id="Aff2"><p>Université Paris-Saclay, Inria, CEA, Palaiseau, France</p><p>Charlotte Caucheteux &amp; Alexandre Gramfort</p></li><li id="Aff3"><p>École normale supérieure, PSL University, CNRS, Paris, France</p><p>Jean-Rémi King</p></li></ol><h3 id="contributions">Contributions</h3><p>All three authors designed the experiments and research question. C.C. launched the experiments, prepared the figures and analysed the results. All three authors interpreted the findings and wrote the paper.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:ccaucheteux@fb.com">Charlotte Caucheteux</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar1">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><div id="additional-information-content"><h3>Publisher&#39;s note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Supplementary Information"><div id="Sec17-section"><h2 id="Sec17">Supplementary Information</h2></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#39;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#39;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Deep%20language%20algorithms%20predict%20semantic%20comprehension%20from%20brain%20activity&amp;author=Charlotte%20Caucheteux%20et%20al&amp;contentID=10.1038%2Fs41598-022-20460-9&amp;copyright=The%20Author%28s%29&amp;publication=2045-2322&amp;publicationDate=2022-09-29&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s41598-022-20460-9" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-022-20460-9" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Caucheteux, C., Gramfort, A. &amp; King, JR. Deep language algorithms predict semantic comprehension from brain activity.
                    <i>Sci Rep</i> <b>12</b>, 16327 (2022). https://doi.org/10.1038/s41598-022-20460-9</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-022-20460-9?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2021-11-17">17 November 2021</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2022-09-13">13 September 2022</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2022-09-29">29 September 2022</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41598-022-20460-9</span></p></li></ul></div></div></div></div></section>

            

            
                <section data-title="Comments"><div id="article-comments-section"><h2 id="article-comments">Comments</h2><p>By submitting a comment you agree to abide by our <a href="https://mytimeatrecurse.substack.com/info/tandc.html">Terms</a> and <a href="https://mytimeatrecurse.substack.com/info/community-guidelines.html">Community Guidelines</a>. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.</p></div></section>
                
            

            </div></div>
  </body>
</html>
