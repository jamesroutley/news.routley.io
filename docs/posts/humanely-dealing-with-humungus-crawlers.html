<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://flak.tedunangst.com/post/humanely-dealing-with-humungus-crawlers">Original</a>
    <h1>Humanely dealing with humungus crawlers</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>I host a bunch of hobby code on my server. I would think it’s really only interesting to me, but it turns out every day, thousands of people from all over the world are digging through my code, reviewing years old changesets. On the one hand, wow, thanks, this is very flattering. On the other hand, what the heck is wrong with you?</p><p>This has been building up for a while, and I’ve been intermittently developing and deploying <a href="https://flak.tedunangst.com/post/anticrawl">countermeasures</a>. It’s been a lot like solving a sliding block puzzle. Lots of small moves and changes, and eventually it starts coming together.</p><p>My primary principle is that I’d rather not annoy real humans more than strictly intended. If there’s a challenge, it shouldn’t be too difficult, but ideally, we want to minimize the number of challenges presented. You should never suspect that I suspected you of being an enemy agent.</p><p>First measure is we only challenge on the deep URLs. So, for instance, I can link to the <a href="https://humungus.tedunangst.com/r/anticrawl">anticrawl</a> repo no problem, or even the source for <a href="https://humungus.tedunangst.com/r/anticrawl/v/tip/f/anticrawl.go">anticrawl.go</a>, and that’ll be served immediately. All the pages any casual browser would visit make up less than 1% of the possible URLs that exist, but probably contain 99% of the interesting content.</p><p>Also, these pages get cached by the reverse proxy first, so anticrawl doesn’t even evaluate them. We’ve already done the work to render the page, and we’re trying to shed load, so why would I want to increase load by generating challenges and verifying responses? It annoys me when I click a seemingly popular blog post and immediately get challenged, when I’m 99.9% certain that somebody else clicked it two seconds before me. Why isn’t it in cache? We must have different objectives in what we’re trying to accomplish. Or who we’re trying to irritate.</p><p>The next step is that anybody loading <code>style.css</code> gets marked friendly. Big Basilisk doesn’t care about my artisanal styles, but most everybody else loves them. So if you start at a normal page, and then start clicking deeper, that’s fine, still no challenge. (Sorry lynx browsers, but don’t worry, it’s not game over for you yet.)</p><p>And then let’s say somebody directly links to a changeset like <a href="https://humungus.tedunangst.com/r/vertigo/v/b5ea481ff167">/r/vertigo/v/b5ea481ff167</a>. The first visitor will probably hit a challenge, but then we record that URL as in use. The bots are shotgun crawling all over the place, but if a single link is visited more than once, I’ll assume it’s human traffic, and bypass the challenge. No promises, but clicking that link will mostly likely just return content, no challenge.</p><p>The very first version of anticrawl relied on a weak POW challenge (find a SHA hash with first byte 42), just to get something launched, but this does seem <a href="https://lock.cmpxchg8b.com/anubis.html">counter intuitive</a>. Why are we making humans solve a challenge optimized for machines? Instead I have switched to a much more diabolical challenge. You are asked how many Rs in strawberry. Or maybe something else. To be changed as necessary. But really, the key observation is that any challenge, anything at all, easily sheds like 99.99% of the crawling load.</p><p>Notably, because the challenge does not include its own javascript solver, even a smart crawler isn’t going to solve it automatically. If you include the solution on the challenge page, at least some bots are going to use it. All anticrawl challenges now require some degree of contemplation, not just blind interpretation.</p><p>It took a few iterations because the actual deployment involves a few pieces. I had to reduce the <code>style.css</code> cache time, so that visitors would periodically refresh it (and thus their humanity). And then exclude it from the caching proxy, so that the request would be properly observed. Basically, a few minutes tinkering now and then while I wait for my latte to arrive, and now I think I’ve gotten things to the point where it’s unlikely to burden anybody except malignant crawlers.</p><h3 id="elsewhere">elsewhere</h3><p>I have focused my bot detection efforts on humungus because the ratio of crawler to legit traffic was out of control. But now that I know what to look for, I see the same patterns scraping everywhere else. Seems really unlikely a worldwide colelctive of Opera users is suddenly interested in my old honks. I’m starting to deploy similar countermeasures.</p><h3 id="appendix">appendix</h3><p>Some log samples. There’s always somebody to insist these could be real humans, and I have somehow misjudged them. Make your own decision.</p><details><summary>logs</summary><pre><code>136.158.49.199 810.886µs humungus.tedunangst.com [2025/09/07 11:31:06] &#34;GET /r/old-flak/v/d720c11fbb57 HTTP/1.1&#34; 402 904 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36&#34;
179.42.10.152 831.235µs humungus.tedunangst.com [2025/09/07 11:31:31] &#34;GET /r/flak/v/8b31c923ca0f HTTP/1.1&#34; 402 900 &#34;&#34; &#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36&#34;
43.128.250.84 863.565µs humungus.tedunangst.com [2025/09/07 11:31:32] &#34;GET /r/vertigo/v/71df18bb3819 HTTP/1.1&#34; 402 961 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36&#34;
78.182.153.38 639.086µs humungus.tedunangst.com [2025/09/07 11:31:46] &#34;GET /r/gerc/v/692abbdefe18 HTTP/1.1&#34; 402 900 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36&#34;
119.28.100.182 525.152µs humungus.tedunangst.com [2025/09/07 11:31:47] &#34;GET /r/honk3/v/462b7440c563 HTTP/1.1&#34; 402 959 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#34;
185.163.26.50 678.609µs humungus.tedunangst.com [2025/09/07 11:31:49] &#34;GET /r/azorius/v/b48a3aa3e060 HTTP/1.1&#34; 402 961 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#34;
43.167.157.150 758.749µs humungus.tedunangst.com [2025/09/07 11:32:01] &#34;GET /r/humungus/v/0442f94c95fc HTTP/1.1&#34; 402 904 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36&#34;
43.134.75.63 574.875µs humungus.tedunangst.com [2025/09/07 11:32:03] &#34;GET /r/azorius/v/969314b9f388 HTTP/1.1&#34; 402 903 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#34; 
119.28.203.219 497.67µs humungus.tedunangst.com [2025/09/07 11:32:04] &#34;GET /r/gerc/v/8ddbf7307214 HTTP/1.1&#34; 402 900 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#34;
43.128.84.91 727.05µs humungus.tedunangst.com [2025/09/07 11:32:06] &#34;GET /r/vertigo/v/eb31940f6fa2 HTTP/1.1&#34; 402 903 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36&#34;
178.163.207.155 566.9µs humungus.tedunangst.com [2025/09/07 11:32:09] &#34;GET /r/lua-tedu/v/300e67089469 HTTP/1.1&#34; 402 904 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36&#34;
181.120.225.184 561.48µs humungus.tedunangst.com [2025/09/07 11:32:12] &#34;GET /r/azorius/v/43120b8aac5a HTTP/1.1&#34; 402 961 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#34;
150.109.20.69 612.716µs humungus.tedunangst.com [2025/09/07 11:32:13] &#34;GET /r/gojxl/v/tip/f/pool.go HTTP/1.1&#34; 404 19 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#34;
49.51.170.84 629.056µs humungus.tedunangst.com [2025/09/07 11:32:27] &#34;GET /r/gerc/v/41b8b28ee893 HTTP/1.1&#34; 402 958 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36&#34;
5.62.146.6 843.157µs humungus.tedunangst.com [2025/09/07 11:32:33] &#34;GET /r/honk/v/f6b8a7bee881 HTTP/1.1&#34; 402 900 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36&#34;
129.226.112.105 595.173µs humungus.tedunangst.com [2025/09/07 11:32:40] &#34;GET /r/azorius/v/6179155ac315 HTTP/1.1&#34; 402 903 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.81 Safari/537.36&#34;
43.167.204.48 514.371µs humungus.tedunangst.com [2025/09/07 11:32:42] &#34;GET /r/vertigo/v/fae0082c32c2 HTTP/1.1&#34; 402 961 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36&#34;
43.132.108.190 715.327µs humungus.tedunangst.com [2025/09/07 11:32:56] &#34;GET /r/vertigo/v/8b5fcd06f8c6 HTTP/1.1&#34; 402 903 &#34;&#34; &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36&#34;</code></pre></details></div><div><p>
Posted 10 Sep 2025 16:42 by tedu Updated: 10 Sep 2025 16:42 
</p></div></div>
  </body>
</html>
