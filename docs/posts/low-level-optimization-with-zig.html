<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://alloc.dev/2025/06/07/zig_optimization">Original</a>
    <h1>Low-Level Optimization with Zig</h1>
    
    <div id="readability-page-1" class="page"><div>
        <div>
            
            <p>
                &#34;Beware of the <a href="https://en.wikipedia.org/wiki/Turing_tarpit" target="_blank">Turing tar-pit</a>
                in which everything is possibile, but nothing of interest is easy.&#34; - Alan Perlis 1982
            </p>
            <p>
                What is of interest to you? Many things, I am certain. One such topic that I am constantly intrigued by
                is program optimization. Whether you are looking to <a href="https://youtu.be/KzT9I1d-LlQ" target="_blank">compute the largest fibonacci number</a> in one second, or creating the <a href="https://tigerbeetle.com/" target="_blank">fastest financial transaction database</a> ever
                written, or even just <a href="https://gaultier.github.io/blog/lessons_learned_from_a_successful_rust_rewrite.html" target="_blank">rewriting something in rust</a>, you likely know how rewarding optimization can be.
            </p>
            <p>
                Optimization separates the weak from the fast. Optimization isn&#39;t a thing of the past. Advances in
                technology shape the form of our programs, but don&#39;t negate the need to optimize. Well optimized
                programs save money, enable higher-tier scaling opportunities, and preserve system simplicity. Would you
                rather spend thousands to run shoddy code on autoscaling cloud infrastructure, or write better code,
                letting you use a handful of mid-tier servers at reduced latency and cost?
            </p>
            <p>
                In this article I aim to explain the concept of low-level optimization, and why Zig is particularly well
                suited for it. If you enjoy what you read, please consider <a href="https://www.paypal.com/donate/?business=2Z3H3UQA37LML&amp;no_recurring=0&amp;item_name=Like+what+you+see?+A+dollar+or+two+will+help+me+learn+and+publish+more+-+Thanks!&amp;currency_code=USD" target="_blank">supporting me</a> :)
            </p>
            <p><img src="https://alloc.dev/2025/06/07/servers.webp" width="100%"/>
        </p></div>

        <div id="trust_compiler">
            <h2> Trust the compiler? </h2>
            <p>
                Some people would say &#34;trust the compiler, it knows best.&#34; It sure does, for most low-level situations!
                Optimizing compilers have come a long ways. Increased system resources and <a href="https://blog.vortan.dev/ematching" target="_blank">advances in IR transformations</a> have
                enabled compiler backends like <a href="https://github.com/llvm/llvm-project" target="_blank">LLVM</a>
                to deliver <a href="https://blog.matthieud.me/2020/exploring-clang-llvm-optimization-on-programming-horror/" target="_blank">impressive results</a>.
            </p>
            <p>
                Compilers are complicated beasts. The best optimizing backends will still <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,selection:(endColumn:2,endLineNumber:7,positionColumn:2,positionLineNumber:7,selectionStartColumn:2,selectionStartLineNumber:7,startColumn:2,startLineNumber:7),source:&#39;const+std+%3D+@import(%22std%22)%3B%0A%0Aexport+fn+makeArray()+%5B*%5Du8+%7B%0A++++var+list+%3D+std.ArrayListUnmanaged(u8).initCapacity(std.heap.c_allocator,+1)+catch+unreachable%3B%0A++++list.appendAssumeCapacity(123)%3B%0A++++return+list.items.ptr%3B%0A%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Zig+source+%231&#39;,t:&#39;0&#39;)),k:50.12184508268059,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:z0141,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,libs:!(),options:&#39;-O+ReleaseFast+-fomit-frame-pointer+-mcpu+x86_64_v3+-lc&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+zig+0.14.1+(Editor+%231)&#39;,t:&#39;0&#39;)),k:49.878154917319414,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">generate sub</a>-<a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1AAvPMFJL6yAngGVG6AMKpaAVxYMJAdlIOAMngMmABy7gBGmMR6AA6oCoS2DM5uHt6ksfE2AgFBoSwRUVwWmFZZDEIETMQEye6eXD6WmNaJFVUEOSHhkXoKldW1qQ0W/R2BXfk9XACUFqiuxMjsHAD0KwDUAOoIAJ7reArrhuuYqtG0eMiE6zQMhJjrfUwED0yuRCzPAuuo0TYseGMmHQ6wiBBexFBez8fgAagBZACkAGYAGKIjQAQQxmNOsWqNwY63oTGiAE1MFVMRAdpSoutXMiAEzTUGoFzrRFeABCOPW/JuCiYIEeAHdCMgEOsIAABJgKCCMpmkdYaaasrm8rECnWqznIgAiKOwnJ5fN1FrwVGltKqnKZAFZ1pJ9UbDaqNWbtRaffy0IJAq4HiAqEL1lwUVrMb6dVyDSdaEpTVGYz7/TYGEH1iGw5JI%2BbU3GC7q46RizquK7jcnyz6rTa6fanVwNBoq%2B61TXvamdenA8HQ0x1kz892Y3GE0nNbXU33MwOw8jR9Ge0Wx7GvAay%2BuBUz2ybpzvLdaaY3EY7na32/HO4eVz2BXOszmh0vkSnV5vJw87w/e7J%2B2zQdnWXB813vEtN23CCdWRfd1mITACAWIkCGIINoN9F0UTdE1EOQ4giSoMQlEwn0SinQ1q1cBhEKYSUmDCegyP5cC2KxPESAIQliUpck6W5U8qhFJVWTCdlaC7CD6yEyFzydbCqI7T0P2PBs7Xk8MrxwnCPSkh8ZNtOSL0kK8wDAXTby9GCe3wlCbhIzBQM/I0j1NVybP5OzCPWNCg2c1jN2LbyiMc5c4w4WZaE4B1eE8DgtFIVBOAALTMR55kWH8mWRHhSAITRItmABrEBJAATgAOkkAA2DRkQ0JkvHK8qauRZFJGkaKOEkOLCqSzheAUEANHywrZjgWAkDQFhojoSJyEoGa5voKJjA0KQihoWgIWGiAwn6sJAiqHZODyo7mGIHYAHkwm0ZoCu4XgZrYQRroYWhToS3gsDCVxgEcMREzOn7ME%2BIxxG%2B0h8EQloADdMGGqHTmad5ljywIXm6xKLjCYgTucLB%2BrQvAWBB0gEeIcSlANMHDGAC4jHGvgDGABRYTwTBRWu6JGHJ/hBBEMR2CkGRBEUFR1Ch3QigMJnTHMXHhsgWZfjKJGAFproAJRKSklCET5aEkjX%2BABAhTfxtgNdiTHIl4VBKeIPAsGViBZiaFo7AgBxBnqXwGHQTo8gKGI4gSAQ/bDzJEmD7pCmKUpWlGKOik9so2mqOPJgTp4BhcOpelGbPQ5mOYFiWCQopivqoeSjh1gV1VKqkFvpVwQgSHtXLpl4R6tHVUhSodDRKodZFWvKrwmVbZEapqh0fG63rSHixL66Gkaxu%2BwfuqZWv18G7eB9mSn4jsSQgA%3D" target="_blank">par code</a> in some cases. In fact, even
                state-of-art compilers will <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1AB9U8lJL6yAngGVG6AMKpaAVxYMQAJlIOAMngMmABy7gBGmMQSPgAOqAqEtgzObh7epHEJNgIBQaEsEVFcPpaY1klCBEzEBCnuniWYVtkMldUEuSHhkdEWVTV1aSX9HYFdBT3FAJQWqK7EyOwcAKReAMyByG5YANTLa44KBPiCAHQI%2B9jLGgCC1zcAbqh46Du0qKgxAOKoAELEAOIEFcgQIay8xgIO1UUz2AHZfvcdsidiDBODITs8Hs1gARaH7RG3FE7ADuCDomB2EGx%2B0c%2B3xMPhRJuJJJAHp2TsAJJUaFYhQ7YDETBMAiRHYEBCGHYaVRUBWKqgAVlIOyY6BOwB2XA0ktQWLJc1orzEpKYAE9BSKFK5aAQkWzkZysQx1TsFCwxPRiDsHmJXFT0IH9TtUA9IlR3qSdgBaHY2u02Iyu9VuwI0BiEKnvT6nR1Ol2OMAcQUKGJlPA0UQtdW0aOC8OR6Nht2uBgJYBBV6gzDASIKNUKA1bQzavAKAtsl0PWwGZPaqVUxweivIHYISKYfPEp2G1aIvE6jSEqfLOG4%2B7n3EcGa0TjK3ieDhaUioTgr4fzRZ7dY8UgEJot4zJuGo9BAMwANYgMqGj6JwkhPkBb6cLwCggHBgEvrepBwLAMCICgqAsDElJkBQEBoCRZEoMAXDKlwfB0OKxDoRAYTIWEgTVBanD/lxzDEBaADyYTaGUWH/lRbCCMJDC0Lx2GkFgYSuMAjjeuh3C8FgXpGOISn4CK5QRlpr6YKoZSuOKfG8L295KbQeBhMQPHOFgyEEMQeAsLZpARsQYTxJguKYHpwBOUYQEzFGTDAAoABqeCYKSwkVs%2B/78IIIhiOwUgyIIigqOoSm6IxBhRaYxjmE5YToZAMyfC0WmxsJay8E2AIvJg9UQRYTQSUk9gME4Lj1Ho/hjPkhR6JkiQCIMniMXNLSdNNkz9c0FQjIteilOUAhtDUa3dEUfTtLtjFHO0J0TEUMxfgseV3g%2BSFKe%2BHDQgAHAAbLGP2SEKyDrvRpxcNSuCECQv5rFwUy8FhWhTCBopYFEfXQbB8EcIhpC%2BVjz6vh9aEYQB0W4QREBIFRpE%2BuQlA0zRwMVcAXgaLqTH2gOlAcUpAk8X5/NCaJ4nWH50mMAQckKchKlqRp9Zaf%2BuljgZr5GYNpnIRZVk2dp5CCE0yG1a5QnuUsr5eT5fkBUFSiheFkWgNhMUGPFSUpWljB%2BVlwiiOI%2BW%2B0VajIboPgsyAVU1c5vWNTEzWcK17VvgF3lYLHm2DXYEAOJdvgjbdM3LfE83JGNaTF1kSSFxt%2B0tEdtTl0tmcHa0Iw12d10DE3e3t1Np0SA9cxPYP2OPqQhMdZw31/QDOyjimbNg6ceoQJDRC%2BqssPw2TLso2B6MvTjvD43Bk8oRwJOYdFUEwXBDnJ%2BfxO70jR9eG9ROoS/wH%2BQOQ2SEAA" target="_blank">break language
                    specifications</a> (<a href="https://github.com/llvm/llvm-project/issues/143046" target="_blank">Clang assumes</a> that all loops without side effects will terminate). It is up to
                us to give our compilers as much information as possible, and verify that the compiler is functioning
                correctly. In the case of most low-level languages, you can generally massage your code until the
                compiler realizes it can apply a certain transform. In other situations, it&#39;s not so easy.
            </p>
            <p>
                Why are low-level languages generally more performant? You might think the reason is that high level
                languages are doing a lot of extra work, such as garbage collection, string interning, interpreting
                code, etc. While you are right, this isn&#39;t *entirely* complete. High level languages lack something that
                low level languages have in great adundance - intent.
            </p>
            <p>
                The verbosity of low level programming languages enable us to produce code that the compiler can reason
                about very well. As an example, consider the following JavaScript code:
            </p>
            <pre><code>function maxArray(x, y) {
    for (let i = 0; i &lt; 65536; i++) {
        x[i] = y[i] &gt; x[i] ? y[i] : x[i];
    }
}</code></pre>
            <p>
                As humans, we can interpret this code as setting the values in <code>x</code> as the maximum of
                <code>x</code> and <code>y</code>. The <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:javascript,selection:(endColumn:51,endLineNumber:15,positionColumn:51,positionLineNumber:15,selectionStartColumn:51,selectionStartLineNumber:15,startColumn:51,startLineNumber:15),source:&#39;function+maxArray(x,+y)+%7B%0A++++for+(let+i+%3D+0%3B+i+%3C+65536%3B+i%2B%2B)+%7B%0A++++++++x%5Bi%5D+%3D+y%5Bi%5D+%3E+x%5Bi%5D+%3F+y%5Bi%5D+:+x%5Bi%5D%3B%0A++++%7D%0A%7D%0A%0Alet+arrA+%3D+new+Float64Array(65536).fill(1)%3B+//+all+1s%0Alet+arrB+%3D+new+Float64Array(65536).fill(2)%3B+//+all+2s%0A%0A//+Prepare+and+warm+up+the+function%0A%25PrepareFunctionForOptimization(maxArray)%3B%0AmaxArray(arrA,+arrB)%3B++++++//+Fill+type+feedback%0AmaxArray(arrA,+arrB)%3B++++++//+Stabilize+into+monomorphic%0A%25OptimizeFunctionOnNextCall(maxArray)%3B%0AmaxArray(arrA,+arrB)%3B++++++//+Trigger+optimization&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Javascript+source+%231&#39;,t:&#39;0&#39;)),k:49.48081530907177,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:v8trunk,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:javascript,libs:!(),options:&#39;&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+v8+(trunk)+(Editor+%231)&#39;,t:&#39;0&#39;)),header:(),k:50.51918469092824,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">generated bytecode</a> for this JavaScript (under V8) is pretty bloated. As a
                comparison, here is what the function might look like if it were written in Zig:
            </p>
            <pre><code>fn maxArray(
    noalias x: *align(64) [65536]f64,
    y: *align(64) const [65536]f64,
) void {
    for (x, y, 0..) |a, b, i| {
        x[i] = if (b &gt; a) b else a;
    }
}</code></pre>
            <p>
                In this more verbose language, we can tell the compiler additional information about our code. For
                example, the optimizer now knows about alignment, aliasing requirements, array sizes, and array element
                types - all at compile-time. Using this information, the compiler generates <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,selection:(endColumn:2,endLineNumber:8,positionColumn:2,positionLineNumber:8,selectionStartColumn:2,selectionStartLineNumber:8,startColumn:2,startLineNumber:8),source:&#39;export+fn+maxArray(%0A++++noalias+x:+*align(64)+%5B65536%5Df64,%0A++++y:+*align(64)+const+%5B65536%5Df64,%0A)+void+%7B%0A++++for+(x,+y,+0..)+%7Ca,+b,+i%7C+%7B%0A++++++++x%5Bi%5D+%3D+if+(b+%3E+a)+b+else+a%3B%0A++++%7D%0A%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Zig+source+%231&#39;,t:&#39;0&#39;)),k:54.464285714285715,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:z0141,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,libs:!(),options:&#39;-OReleaseFast+-mcpu%3Dznver5+-fomit-frame-pointer&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+zig+0.14.1+(Editor+%231)&#39;,t:&#39;0&#39;)),header:(),k:45.5357142857143,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">far superior, even vectorized</a> code.
                If you were wondering, <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:rust,selection:(endColumn:17,endLineNumber:10,positionColumn:17,positionLineNumber:10,selectionStartColumn:17,selectionStartLineNumber:10,startColumn:17,startLineNumber:10),source:&#39;%23%5Brepr(align(64))%5D%0Apub+struct+Aligned%3CT:+%3FSized%3E(T)%3B%0A%0Apub+fn+max_array(x:+%26mut+Aligned%3C%5Bf64%3B+65536%5D%3E,+y:+%26Aligned%3C%5Bf64%3B+65536%5D%3E)+%7B%0A++++for+(x,+y)+in+x.0.iter_mut().zip(y.0.iter())+%7B%0A++++++++*x+%3D+if+*y+%3E+*x+%7B+*y+%7D+else+%7B+*x+%7D%3B%0A++++%7D%0A%7D%0A%0Apub+fn+main()+%7B%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Rust+source+%231&#39;,t:&#39;0&#39;)),k:54.464285714285715,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:r1870,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:rust,libs:!(),options:&#39;-C+opt-level%3D3+-C+target-cpu%3Dznver5&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+rustc+1.87.0+(Editor+%231)&#39;,t:&#39;0&#39;)),header:(),k:45.5357142857143,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">equivalent Rust
                    code</a> generates near identical assembly.
            </p>
            <p>
                So can we *really* trust our compilers? It depends. Are you looking to uncover transformations to triple
                the throughput of your program&#39;s performance bottleneck? You should probably look at what the compiler
                is doing, and figure out if there are better ways to express *your intent* to the compiler. You may need
                to tweak the code to get the transforms you want. In the worst cases, you may discover that the compiler
                isn&#39;t applying optimal transforms to your code. In these cases, you may need to write inline assembly to
                squeeze out that last drop.
            </p>
            <p>
                But what about high level code? Except for <a href="https://spiral.net/" target="_blank">niche
                    cases</a>, the most we can do is <a href="https://github.com/llvm/llvm-project/tree/main/polly" target="_blank">reason about loops</a>. In other words, compilers cannot change our algorithms and
                optimize our paradigms. Their scope is relatively narrow.
            </p>
        </div>

        <div id="what_about_zig">
            <h2> So where does Zig fall? </h2>
            <p>
                I love Zig for it&#39;s verbosity. Due to this verbosity, it&#39;s easier to write more performant programs than
                with most other languages. With Zig&#39;s <a href="https://ziglang.org/documentation/master/#Builtin-Functions" target="_blank">builtin
                    functions</a>, non-optional <a href="https://ziglang.org/documentation/master/#Pointers" target="_blank">pointers</a>, <a href="https://ziglang.org/documentation/master/#unreachable" target="_blank"><code>unreachable</code> keyword</a>, well chosen <a href="https://ziglang.org/documentation/master/#Illegal-Behavior" target="_blank">illegal
                    behavior</a>, Zig&#39;s excellent <a href="https://ziglang.org/documentation/master/#comptime" target="_blank">comptime</a>... LLVM is practically spoon-fed information about our code.
            </p>
            <p>
                It isn&#39;t all rainbows though, there are tradeoffs. For example, Rust&#39;s memory model allows the compiler
                to always assume that function arguments never alias. You must manually specify this in Zig. If the
                compiler can&#39;t tell that your Zig function is always called with non-aliasing arguments, Rust
                functions will outperform the non-annotated Zig functions.
            </p>
            <p>
                If we take in well-annotated LLVM IR as the *only* metric of a language&#39;s optimization capability, then
                Zig does well. This is not all that Zig has up it&#39;s sleeves. Zig&#39;s true optimization superpower lies in
                compile-time execution.
            </p>
            <p><img src="https://alloc.dev/2025/06/07/gotta_go_fast.webp" alt="speedily (poorly) drawn lizard with a space helmet" width="100%"/>
        </p></div>

        <div id="what_is_comptime">
            <h2> What is <code>comptime</code>? </h2>
            <p>
                <a href="https://ziglang.org/documentation/master/#comptime" target="_blank">Zig&#39;s
                    <code>comptime</code></a> is all about code generation. Do you want to use a constant in your code?
                You can generate it at compile-time and the value will be embedded in the produced binary. Do you want
                to avoid writing the same <a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank">hashmap
                    structure</a> for each type of data it can store? <code>comptime</code> has your back. Do you have
                data which is known at compile-time, and want the optimizer to elide code using this data? Yes, <a href="https://www.scottredig.com/blog/bonkers_comptime/" target="_blank">you can do this</a> with
                <code>comptime</code>. Zig&#39;s <code>comptime</code> is an example of <a href="https://en.wikipedia.org/wiki/Metaprogramming">metaprogramming</a>.
            </p>
            <p>
                So how is this different from macros? It&#39;s pretty nuanced. The purpose of <code>comptime</code> is
                essentially the same as macros. Some macros will modify the raw text of your code, and others can modify
                your program&#39;s <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree" target="_blank">AST</a>
                directly. This allows macros to inline code specific to the types and values of data in your program. In
                Zig, <code>comptime</code> code is just regular code running at compile-time. This code cannot have
                side-effects - such as network IO - and the emulated machine will match the compilation target.
            </p>
            <p>
                The reason that Zig&#39;s <code>comptime</code> can match up so well to macros is twofold. Firstly, almost
                all Zig code can be run at compile-time, using <code>comptime</code>. Secondly, at compile-time, all
                types can be inspected, reflected, and generated. This is <a href="https://ziglang.org/documentation/0.14.1/#Generic-Data-Structures" target="_blank">how
                    generics are implemented</a> in Zig.
            </p>
            <p>
                The flexibility of Zig&#39;s <code>comptime</code> has resulted in some rather nice improvements in other
                programming languages. For example, Rust has the <a href="https://docs.rs/crabtime/latest/crabtime/" target="_blank">&#34;crabtime&#34;</a> crate, which provides more flexibility and power than standard Rust
                macros. I believe a benefit of <code>comptime</code> over current alternatives lies in how seamlessly
                <code>comptime</code> fits into the Zig language. Unlike C++&#39;s <code>constexpr</code>, you can use
                <code>comptime</code> without needing to learn a new &#34;language&#34; of sorts. C++ <a href="https://youtu.be/bIc5ZxFL198" target="_blank">is improving</a>, but it has a long ways to go
                if it hopes to compete with Zig in this domain.
            </p>
            <p>
                So can Zig&#39;s <code>comptime</code> do *everything* macros can? Nope. Token-pasting macros don&#39;t have a
                mirror in Zig&#39;s comptime. Zig is designed to be easy to read, and macros which modify or create
                variables in a unrelated scopes just don&#39;t cut it. Macros can define other macros, macros can alter the
                AST, and macros can implement mini-languages, or DSLs. Zig&#39;s <code>comptime</code> can&#39;t directly alter
                the AST. If you really want to, you can implement a DSL in Zig. For example, Zig&#39;s print function <a href="https://ziglang.org/documentation/master/#Case-Study-print-in-Zig" target="_blank">relies on
                    <code>comptime</code></a> to parse the format string. The print function&#39;s format string is a DSL of
                sorts. Based on the format string, Zig&#39;s <code>comptime</code> will construct a graph of functions to
                serialize your data. Here are some other examples of <code>comptime</code> DSLs in the wild: the <a href="https://github.com/tigerbeetle/tigerbeetle/blob/main/src/state_machine.zig#L5840" target="_blank">TigerBeetle account testing DSL</a>, <a href="https://github.com/InKryption/comath" target="_blank">comath: comptime math</a>, and <a href="https://github.com/ymndoseijin/zilliam" target="_blank">zilliam</a>, a Geometric Algebra library.
            </p>
            <p>
                Here are more resources for learning about Zig&#39;s <code>comptime</code>:
            </p>
            <ul>
                <li> <a href="https://andrewkelley.me/post/string-matching-comptime-perfect-hashing-zig.html" target="_blank">
                        String Matching based on Compile Time Perfect Hashing in Zig - Andrew Kelley </a> </li>
                <li> <a href="https://kristoff.it/blog/what-is-zig-comptime/" target="_blank">
                        What is Zig&#39;s Comptime? - Loris Cro </a> </li>
                <li> <a href="https://matklad.github.io/2025/04/19/things-zig-comptime-wont-do.html" target="_blank">
                        Things Zig comptime Wonâ€™t Do - matklad </a> </li>
                <li> <a href="https://zig.news/edyu/wtf-is-zig-comptime-and-inline-257b" target="_blank">
                        Zig Comptime - WTF is Comptime (and Inline) - Ed Yu </a> </li>
                <li> <a href="https://ziglang.org/documentation/master/#comptime" target="_blank">
                        Comptime - Zig Language Reference </a> </li>
                <li> <a href="https://zig.guide/language-basics/comptime/" target="_blank">
                        Comptime - zig.guide </a> </li>
            </ul>
        </div>

        <div id="string_comparison">
            <h2> String Comparison with <code>comptime</code>: </h2>
            <p>
                How do you compare two strings? Here&#39;s an approach that works in any language:
            </p>
            <pre><code>function stringsAreEqual(a, b) {
    if (a.length !== b.length) return false;
    for (let i = 0; i &lt; a.length; i++)
        if (a[i] !== b[i]) return false;
    return true;
}</code></pre>
            <p>
                We know that two strings aren&#39;t equal if their lengths aren&#39;t equal. We also know that if one byte isn&#39;t
                equal, then the strings as a whole aren&#39;t equal. Pretty simple, right? Yes, and the <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,selection:(endColumn:2,endLineNumber:14,positionColumn:2,positionLineNumber:14,selectionStartColumn:2,selectionStartLineNumber:14,startColumn:2,startLineNumber:14),source:&#39;const+std+%3D+@import(%22std%22)%3B%0A%0Aexport+fn+isHelloWorldA(str:+%5B*%5Dconst+u8,+len:+usize)+bool+%7B%0A++++const+hello+%3D+%22Hello,+world!!%5Cn%22%3B%0A++++if+(len+!!%3D+hello.len)+return+false%3B%0A++++return+staticEqlA(hello.len,+hello.*,+str)%3B%0A%7D%0A%0Afn+staticEqlA(comptime+len:+usize,+comptime+a:+%5Blen%5Du8,+b:+%5B*%5Dconst+u8)+bool+%7B%0A++++for+(0..len)+%7Cidx%7C+%7B%0A++++++++if+(a%5Bidx%5D+!!%3D+b%5Bidx%5D)+return+false%3B%0A++++%7D%0A++++return+true%3B%0A%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Zig+source+%231&#39;,t:&#39;0&#39;)),header:(),k:50,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:z0141,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,libs:!(),options:&#39;-OReleaseFast+-fomit-frame-pointer+-mcpu%3Dznver5+-target+x86_64-linux&#39;,overrides:!(),selection:(endColumn:28,endLineNumber:8,positionColumn:28,positionLineNumber:8,selectionStartColumn:28,selectionStartLineNumber:8,startColumn:28,startLineNumber:8),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+zig+0.14.1+(Editor+%231)&#39;,t:&#39;0&#39;)),header:(),k:50,l:&#39;4&#39;,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">generated assembly</a> for this function
                reflects that. There&#39;s a slight issue though. We need to load individual bytes from both strings,
                comparing them individually. It would be nice if there was some way to optimize this. We could use SIMD
                here, chunking the input strings and comparing them block by block, but we would still be loading from
                two separate strings. In most cases, we already know one of the strings at compile-time. Can we do
                better? Yes:
            </p>
            <pre><code>fn staticEql(comptime a: []const u8, b: []const u8) bool {
    if (a.len != b.len) return false;
    for (0..a.len) |idx| {
        if (a[idx] != b[idx]) return false;
    }
    return true;
}</code></pre>
            <p>
                The difference here is that one of the strings is required to be known at compile-time. The compiler can
                use this new information to <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,selection:(endColumn:1,endLineNumber:4,positionColumn:1,positionLineNumber:4,selectionStartColumn:1,selectionStartLineNumber:4,startColumn:1,startLineNumber:4),source:&#39;export+fn+isHello(str:+%5B*%5Dconst+u8,+len:+usize)+bool+%7B%0A++++return+staticEql(%22Hello!!%5Cn%22,+str%5B0..len%5D)%3B%0A%7D%0A%0Afn+staticEql(comptime+a:+%5B%5Dconst+u8,+b:+%5B%5Dconst+u8)+bool+%7B%0A++++if+(a.len+!!%3D+b.len)+return+false%3B%0A++++for+(0..a.len)+%7Cidx%7C+%7B%0A++++++++if+(a%5Bidx%5D+!!%3D+b%5Bidx%5D)+return+false%3B%0A++++%7D%0A++++return+true%3B%0A%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Zig+source+%231&#39;,t:&#39;0&#39;)),header:(),k:48.0168776371308,l:&#39;4&#39;,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:z0141,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,libs:!(),options:&#39;-OReleaseFast+-fomit-frame-pointer+-mcpu%3Dznver5+-target+x86_64-linux&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+zig+0.14.1+(Editor+%231)&#39;,t:&#39;0&#39;),(h:output,i:(compilerName:&#39;zig+trunk&#39;,editorid:1,fontScale:14,fontUsePx:&#39;0&#39;,j:1,wrap:&#39;1&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Output+of+zig+0.14.1+(Compiler+%231)&#39;,t:&#39;0&#39;)),header:(),k:51.983122362869196,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">produce
                    improved</a> assembly code:
            </p>
            <pre><code>isHello:
        cmp     rsi, 7
        jne     .LBB0_8
        cmp     byte ptr [rdi], 72
        jne     .LBB0_8
        cmp     byte ptr [rdi + 1], 101
        jne     .LBB0_8
        cmp     byte ptr [rdi + 2], 108
        jne     .LBB0_8
        cmp     byte ptr [rdi + 3], 108
        jne     .LBB0_8
        cmp     byte ptr [rdi + 4], 111
        jne     .LBB0_8
        cmp     byte ptr [rdi + 5], 33
        jne     .LBB0_8
        cmp     byte ptr [rdi + 6], 10
        sete    al
        ret
.LBB0_8:
        xor     eax, eax
        ret</code></pre>
            <p>
                Is this not amazing? We just used <code>comptime</code> to make a function which compares a string
                against <code>&#34;Hello!\n&#34;</code>, and the assembly will run much faster than the naive comparison
                function. It&#39;s unfortunately still not perfect. Because we know the length of the expected string at
                compile-time, we can compare much larger sections of text at a time, instead of just byte-by-byte:
            </p>
            <pre><code>const std = @import(&#34;std&#34;);

fn staticEql(comptime a: []const u8, b: []const u8) bool {
    const block_len = std.simd.suggestVectorLength(u8) orelse @sizeOf(usize);

    // Exit early if the string lengths don&#39;t match up
    if (a.len != b.len) return false;

    // Find out how many large &#34;blocks&#34; we can compare at a time
    const block_count = a.len / block_len;
    // Find out how many extra bytes we need to compare
    const rem_count = a.len % block_len;

    // Compare &#34;block_len&#34; bytes of text at a time
    for (0..block_count) |idx| {
        const Chunk = std.meta.Int(.unsigned, block_len * 8);
        const a_chunk: Chunk = @bitCast(a[idx * block_len ..][0..block_len].*);
        const b_chunk: Chunk = @bitCast(b[idx * block_len ..][0..block_len].*);
        if (a_chunk != b_chunk) return false;
    }

    // Compare the remainder of bytes in both strings
    const Rem = std.meta.Int(.unsigned, rem_count * 8);
    const a_rem: Rem = @bitCast(a[block_count * block_len ..][0..rem_count].*);
    const b_rem: Rem = @bitCast(b[block_count * block_len ..][0..rem_count].*);
    return a_rem == b_rem;
}</code></pre>
            <p>
                Ok, so it&#39;s a bit more complex than the first example. Is it worth it though? Yep. The <a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,selection:(endColumn:1,endLineNumber:6,positionColumn:1,positionLineNumber:6,selectionStartColumn:1,selectionStartLineNumber:6,startColumn:1,startLineNumber:6),source:&#39;const+std+%3D+@import(%22std%22)%3B%0A%0Aexport+fn+isHelloWorld(str:+%5B*%5Dconst+u8,+len:+usize)+bool+%7B%0A++++return+staticEql(%22Hello,+World!!%5Cn%22,+str%5B0..len%5D)%3B%0A%7D%0A%0Afn+staticEql(comptime+a:+%5B%5Dconst+u8,+b:+%5B%5Dconst+u8)+bool+%7B%0A++++const+block_len+%3D+std.simd.suggestVectorLength(u8)+orelse+@sizeOf(usize)%3B%0A%0A++++//+Exit+early+if+the+string+lengths+don!&#39;t+match+up%0A++++if+(a.len+!!%3D+b.len)+return+false%3B%0A%0A++++//+Find+out+how+many+large+%22blocks%22+we+can+compare+at+a+time%0A++++const+block_count+%3D+a.len+/+block_len%3B%0A++++//+Find+out+how+many+extra+bytes+we+need+to+compare%0A++++const+rem_count+%3D+a.len+%25+block_len%3B%0A%0A++++//+Compare+%22block_len%22+bytes+of+text+at+a+time%0A++++for+(0..block_count)+%7Cidx%7C+%7B%0A++++++++const+Chunk+%3D+std.meta.Int(.unsigned,+block_len+*+8)%3B%0A++++++++const+a_chunk:+Chunk+%3D+@bitCast(a%5Bidx+*+block_len+..%5D%5B0..block_len%5D.*)%3B%0A++++++++const+b_chunk:+Chunk+%3D+@bitCast(b%5Bidx+*+block_len+..%5D%5B0..block_len%5D.*)%3B%0A++++++++if+(a_chunk+!!%3D+b_chunk)+return+false%3B%0A++++%7D%0A%0A++++//+Compare+the+remainder+of+bytes+in+both+strings%0A++++const+Rem+%3D+std.meta.Int(.unsigned,+rem_count+*+8)%3B%0A++++const+a_rem:+Rem+%3D+@bitCast(a%5Bblock_count+*+block_len+..%5D%5B0..rem_count%5D.*)%3B%0A++++const+b_rem:+Rem+%3D+@bitCast(b%5Bblock_count+*+block_len+..%5D%5B0..rem_count%5D.*)%3B%0A++++return+a_rem+%3D%3D+b_rem%3B%0A%7D&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Zig+source+%231&#39;,t:&#39;0&#39;)),header:(),k:56.046814044213264,l:&#39;4&#39;,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:z0141,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,binaryObject:&#39;1&#39;,commentOnly:&#39;0&#39;,debugCalls:&#39;1&#39;,demangle:&#39;0&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;0&#39;,trim:&#39;1&#39;,verboseDemangling:&#39;0&#39;),flagsViewOpen:&#39;1&#39;,fontScale:14,fontUsePx:&#39;0&#39;,j:1,lang:zig,libs:!(),options:&#39;-OReleaseFast+-fomit-frame-pointer+-mcpu%3Dznver5+-target+x86_64-linux&#39;,overrides:!(),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;+zig+0.14.1+(Editor+%231)&#39;,t:&#39;0&#39;),(h:output,i:(compilerName:&#39;zig+trunk&#39;,editorid:1,fontScale:14,fontUsePx:&#39;0&#39;,j:1,wrap:&#39;1&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;Output+of+zig+0.14.1+(Compiler+%231)&#39;,t:&#39;0&#39;)),header:(),k:43.953185955786736,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4" target="_blank">generated assembly</a> is much more optimal. Comparing larger chunks utilizes
                larger registers, and reduces the number of conditional branches in our code:
            </p>
            <pre><code>isHelloWorld:
        cmp     rsi, 14 ; The length of &#34;Hello, World!\n&#34;
        jne     .LBB0_1
        movzx   ecx, word ptr [rdi + 12]
        mov     eax, dword ptr [rdi + 8]
        movabs  rdx, 11138535027311
        shl     rcx, 32 ; Don&#39;t compare out-of-bounds data
        or      rcx, rax
        movabs  rax, 6278066737626506568
        xor     rax, qword ptr [rdi]
        xor     rdx, rcx
        or      rdx, rax ; Both chunks must match
        sete    al
        ret
.LBB0_1:
        xor     eax, eax
        ret</code></pre>
            <p>
                If you try to compare much larger strings, you&#39;ll notice that this more advanced function will generate
                assembly which uses the larger SIMD registers. Just testing against <code>&#34;Hello, World!\n&#34;</code>
                though, you can tell that we <a href="https://gist.github.com/RetroDev256/660824008ff5526ea785d8b3659c29f2" target="_blank">significantly improved</a> the runtime performance of this function. (<code>a</code>
                was the runtime-only function, <code>b</code> was the same function where one argument was known at
                compile-time, and <code>c</code> was the more advanced function).
            </p>
            <p><img src="https://alloc.dev/2025/06/07/string_bench.webp" width="100%" alt="basic comptime was 45% faster while advanced comptime was 70% faster"/>
        </p></div>

        <div id="runtime_at_comptime">
            <h2> Runtime-known data at <code>comptime</code>: </h2>
            <p>
                Zig&#39;s <code>comptime</code> powers aren&#39;t limited to compile-time. You can generate some number of
                procedures at compile-time for simple cases, and dynamically dispatch to the right procedure,
                falling-back to a fully runtime implementation if you don&#39;t want to bloat your binary:
            </p>
            <pre><code>fn dispatchFn(runtime_val: u32) void {
    switch (runtime_val) {
        inline 0...100 =&gt; |comptime_val| {
            staticFn(comptime_val);
        },
        else =&gt; runtimeFn(runtime_val),
    }
}

fn staticFn(comptime val: u32) void {
    _ = val; // ...
}

fn runtimeFn(runtime_val: u32) void {
    _ = runtime_val; // ...
}</code></pre>
        </div>

        <div id="conclusion">
            <h2> Conclusion: </h2>
            <p>
                Is <code>comptime</code> useful? I would say so. I use it every time I write Zig code. It fits into the
                language really well, and removes the need for templates, macros, generics, and manual code generation.
                Yes, you can do all of this with other languages, but it isn&#39;t nearly as clean. Whenever I use Zig, I
                feel it&#39;s easier to write performant code for *actually useful* scenarios. In other words, Zig is not
                the &#34;Turing tar-pit&#34;.
            </p>
            <p>
                The possibilities are <a href="https://github.com/RetroDev256/comptime_suffix_automaton" target="_blank">only limited to your imagination</a>. If you are required to use a language without
                good generics, code generation, templates, macros, or comptime at your workplace, I feel sorry for you.
            </p>
            <p>
                Hopefully you enjoyed this article. If you did, please consider <a href="https://www.paypal.com/donate/?business=2Z3H3UQA37LML&amp;no_recurring=0&amp;item_name=Like+what+you+see?+A+dollar+or+two+will+help+me+learn+and+publish+more+-+Thanks!&amp;currency_code=USD" target="_blank">supporting me</a>. On a final note, I think it&#39;s time for the language wars to end.
                Turing completeness is all that we need, and the details fade away when we look for the bigger picture.
                Does this mean we can&#39;t have favorite languages? No, it does not. People will still mistakenly say &#34;C is
                faster than Python&#34;, when the language isn&#39;t what they are benchmarking. On that note, enjoy this Zig
                propaganda:
            </p>
            <iframe width="100%" src="https://www.youtube.com/embed/0Ahr2XWymPk" title="Zig Go Brrrrrr" frameborder="0" allowfullscreen=""></iframe>
        </div>
    </div></div>
  </body>
</html>
