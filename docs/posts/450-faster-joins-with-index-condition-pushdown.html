<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://readyset.io/blog/optimizing-straddled-joins-in-readyset-from-hash-joins-to-index-condition-pushdown">Original</a>
    <h1>450× Faster Joins with Index Condition Pushdown</h1>
    
    <div id="readability-page-1" class="page"><div><p>Optimizing Straddled Joins in Readyset: From Hash Joins to Index Condition Pushdown</p><p><img alt="Optimizing Straddled Joins in Readyset: From Hash Joins to Index Condition Pushdown" loading="lazy" width="640" height="320" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fblog.readyset.io%2Fcontent%2Fimages%2F2025%2F08%2FBlog-Card.png&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fblog.readyset.io%2Fcontent%2Fimages%2F2025%2F08%2FBlog-Card.png&amp;w=1920&amp;q=75 2x" src="https://readyset.io/_next/image?url=https%3A%2F%2Fblog.readyset.io%2Fcontent%2Fimages%2F2025%2F08%2FBlog-Card.png&amp;w=1920&amp;q=75"/></p></div><div><div><p><strong>Introduction</strong></p><p>Readyset is designed to serve queries from cached views with sub-millisecond latency. This post focuses on the cold path—cases where a cache miss forces execution against the base tables. In these scenarios, Readyset must evaluate the query from scratch, including materializing intermediate results. The focus here is on straddled joins, where filtering predicates apply to both sides of the join in addition to the ON clause.</p><p>Example:</p><pre><div dir="ltr"><div data-radix-scroll-area-viewport=""><p><code><code>SELECT u.id, u.name, o.order_id, o.total
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.email = &#39;some@provide.com&#39;
 AND o.status = &#39;SHIPPED&#39;;</code></code></p></div></div></pre><p>In a previous optimization, we transitioned from nested loop joins to hash joins (see <a href="https://readyset.io/blog/introducing-hash-join-algorithm?ref=blog.readyset.io" rel="noopener noreferrer" target="_blank">https://readyset.io/blog/introducing-hash-join-algorithm</a>), eliminating the need to repeatedly scan one side of the join. This brought significant performance improvements for many workloads, however, some queries remained problematic.</p><p>Straddled joins are common in production workloads; for example, filtering users by some property on the left table and orders by a status flag on the right table, then joining on user_id. While our hash join algorithm improved over nested loops, it was still inefficient in these cases, especially when one side’s predicate had low cardinality (like a boolean flag or status column).</p><p>This post explains why the old execution strategy struggled, and how our new optimization using Index Condition Pushdown (ICP) changes the execution model to make straddled joins much more efficient.</p><p><strong>Previous algorithm</strong></p><p>During evaluation of straddled joins on cache misses, we observed significant latency in up-queries. To identify the underlying bottleneck, we profiled query execution and analyzed the resulting flamegraphs</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcY87nR5HKMzKcMPViXsYt8Hj7j9bCewn3CzLTSGEYBpgzRvfLaTcjHrWvkVu8jhlT-7fo2OMjGo9kunj9BPrAf_A4qg285JlB9Hi_j2WnezLD3QX5aYmF6J0ZjzzOxmpyrzbb5XA?key=ZK18KrmOAWsI_qGCwONGoQ" alt="" loading="lazy" width="624" height="269"/></figure><p>Approximately 30% of the query execution time was attributed to data decompression. We initially suspected the RocksDB compression algorithm as the bottleneck and proceeded to benchmark alternative compression methods to validate this hypothesis.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdbelLwzGeF8yMnlZu_vGKPr2n7hmXV_C7EzF_3Dx_F0feA1LAvvpV8lkH9__eGRxupXXHI8QAtwKsO6bBnY6lAZxTrml3Vcm1bhUBBx8C0GQxOp8o7CAIayG0WZyF0GJrhO7cs5A?key=ZK18KrmOAWsI_qGCwONGoQ" alt="" loading="lazy" width="624" height="253"/></figure><p>Switching to ZSTD did not improve performance. Decompression remained a dominant contributor to query execution time. As the next step, we disabled compression in RocksDB entirely to isolate its impact. This came with a space tradeoff but was necessary to confirm whether compression was the root cause:</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdx_yw6raNEDmSUFkN6vdHhQ0LZUvVMT38LJ06IGkfjmlKatbjIyBPXd8jE1xQjms0PqjK-ELR_GVjY5RT3LKLElkgcc_es6zfK2QhKpehDSHkcEP_1TxPdu7rC_Zu0FD2AWdGhEw?key=ZK18KrmOAWsI_qGCwONGoQ" alt="" loading="lazy" width="624" height="272"/></figure><p>Disabling compression didn’t eliminate the problem, it merely shifted the bottleneck. The system began spending the majority of execution time on disk reads, as evident from increased I/O activity on ext4. </p><p>This made it clear that compression wasn’t the issue; rather, the excessive amount of data being read from disk was the primary cause. Isolated iostat output for the query confirmed this:</p><pre><div dir="ltr"><div data-radix-scroll-area-viewport=""><p><code><code>Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
nvme1n1       10068.00  55728.00     0.00   0.00    0.08     5.54    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.79  81.00</code></code></p></div></div></pre><p>The NVMe device was handling approximately 10K IOPS, with the majority of reads around 5KB in size. Despite their small size, the device reached ~81% utilization while executing a single join query, indicating I/O saturation.</p><p>Upon examining the query pattern, we identified that one side of the join had a low-cardinality index, causing the engine to scan nearly the entire table on each execution. Due to internal constraints (such as maintaining key provenance and supporting incremental view maintenance) the join engine was independently evaluating both sides of the join, regardless of selectivity.</p><p><strong>Execution example</strong></p><pre><div dir="ltr"><div data-radix-scroll-area-viewport=""><p><code><code>SELECT u.id, u.name, o.order_id, o.totalFROM users uJOIN orders o ON u.id = o.user_idWHERE u.email = &#39;some@provide.com&#39; AND o.status = &#39;SHIPPED&#39;;</code></code></p></div></div></pre><p>Scenario:</p><ul><li>Users table: The predicate u.email = &#39;some@provide.com&#39; is highly selective, returning exactly one row.</li><li>Orders table: The predicate o.status = &#39;SHIPPED&#39; is very low selectivity — ~99% of all rows match.</li></ul><p><strong>Old Execution Strategy: Hash Joins</strong></p><p>The old algorithm relied on the hash join approach:</p><ol><li>Lookup both sides independently:<ol><li>users: filter by email → 1 row.</li><li>orders: filter by status → ~99% of the table.</li></ol></li><li>Materialize both result sets:<ol><li>Millions of orders rows, plus 1 users row.</li></ol></li><li>Build and probe a hash table: <ol><li>Hash on o.user_id.</li><li>Probe with the user row. </li><li>Discard nearly all rows after the join.</li></ol></li></ol><p>Why This Is Inefficient:</p><ul><li>High I/O: We had to read essentially the entire orders table.</li><li>High memory usage: Millions of rows materialized only to discard them.</li><li>Wasteful CPU work: The join considered far more rows than necessary.</li></ul><p><strong>New Execution Strategy: Index Condition Pushdown</strong></p><p>The new algorithm issues an initial upquery to one side of the join, then combines the resulting join key with the original predicates on the other side. This composite condition is pushed down to RocksDB, allowing index-based retrieval of only the rows required to satisfy the join. This eliminates unnecessary data reads and avoids full-table scans.</p><p>Step‑by‑Step:</p><ol><li>Apply the left predicate first: u.email = &#39;some@provide.com&#39; → 1 row (u.id = 123).</li><li>Group rows by join key: collect distinct values {123}.</li><li>For each join key, build a right‑side lookup:</li></ol><pre><div dir="ltr"><div data-radix-scroll-area-viewport=""><p><code><code>WHERE o.status = &#39;SHIPPED&#39;
AND o.user_id = 123;</code></code></p></div></div></pre><ol start="4"><li>Leverage storage engine indexes: with an index on (user_id, status), fetch only matching rows.</li><li>Build the result set incrementally: combine left row(s) with right rows per join key, no full materialization needed.</li></ol><h2 id="benchmark-measuring-the-impact"><strong>Benchmark: Measuring the Impact</strong></h2><p>To quantify the performance improvement brought by the new Index Condition Pushdown strategy, we ran a controlled benchmark comparing the old hash join algorithm against the new execution model on the same hardware and dataset.</p><h3 id="old-algorithm-hash-join"><strong>Old Algorithm: Hash Join</strong></h3><p>Under the previous strategy, Readyset executed straddled joins using independent filtering on both sides, followed by full materialization and hash-based probing. This approach was highly inefficient when one side had low-cardinality filters.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc_1NqEdGLBVhRtF9utFIWgFAIhshZVL23xDTVWO8rrCF0_mz0xOR8b2l0nE28P9ZbUTXL03cJ6BAf0-HViq5ADCrlrBzegJBwlwdUx3T6FsoROWfp4rV25NLlAsXwMTU6q_zGj?key=ZK18KrmOAWsI_qGCwONGoQ" alt="" loading="lazy" width="624" height="239"/></figure><p><strong>Results:</strong></p><ul><li><strong>Throughput:</strong> 7.0 events/s</li><li><strong>Latency (avg):</strong> 2,284 ms</li><li><strong>95th percentile latency:</strong> 4,129 ms</li><li><strong>Max latency:</strong> 6,831 ms</li><li><strong>Total events processed:</strong> 4,203 over 10 minutes</li></ul><p>The system was CPU- and IO-bound, spending excessive time reading and decompressing unnecessary rows from disk; most of which were discarded after join evaluation.</p><hr/><h3 id="new-algorithm-index-condition-pushdown"><strong>New Algorithm: Index Condition Pushdown</strong></h3><p>With the ICP-enabled join model, Readyset instead defers right-side lookups until left-side predicates are evaluated, allowing the use of compound indexes (e.g. (user_id, status)) to fetch only relevant rows. This minimizes materialization and disk reads.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf6WS2f1VpCmRUOo371U1pXcM-PVJ8WLWlQZcWLhH5RBskEBgnvv6iTxCiwD5B4OrolgfGn8_w29criYBF1VO7q0wIAqukIRBsHkYmbA52D73Tf19fxOFj87H2KBcSFOEsO5LbMug?key=ZK18KrmOAWsI_qGCwONGoQ" alt="" loading="lazy" width="624" height="235"/></figure><p><strong>Results:</strong></p><ul><li><strong>Throughput:</strong> 3,214.4 events/s</li><li><strong>Latency (avg):</strong> 4.98 ms</li><li><strong>95th percentile latency:</strong> 11.87 ms</li><li><strong>Max latency:</strong> 3,467.2 ms</li><li><strong>Total events processed:</strong> 1,928,645 over 10 minutes</li></ul><p>This represents a <strong>&gt;450x throughput improvement</strong> and <strong>&gt;450x latency reduction</strong>. The join strategy is now highly cache- and index-efficient, with the storage engine only returning matching rows based on precise key lookups.</p><h3 id="conclusion"><strong>Conclusion</strong></h3><p>While Readyset excels in delivering low-latency results via caching, optimizing the cold path is critical for consistent performance during cache misses. By rethinking how straddled joins are executed and leveraging Index Condition Pushdown, we’ve significantly improved real-world performance for these workloads.</p></div></div></div>
  </body>
</html>
