<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.newyorker.com/culture/the-weekend-essay/the-hidden-pregnancy-experiment">Original</a>
    <h1>The Hidden-Pregnancy Experiment: Could I Hide My Pregnancy from My Phone?</h1>
    
    <div id="readability-page-1" class="page"><div><div data-journey-hook="client-content" data-testid="BodyWrapper"><div><p>Shortly after I became pregnant with my second child, in the fall of 2022, I decided to try a modest experiment. I wanted to see whether I could hide my pregnancy from my phone. After spending my twenties eagerly surveilling and sharing the details of my life online, I had already begun trying to erect some walls of technological privacy: I’d deleted most apps on my phone and turned off camera, location, and microphone access for nearly all of the ones that I did have; I had disabled Siri—I just found it annoying—and I didn’t have any smart devices. For the experiment, I would abide by some additional restrictions. I wouldn’t Google anything about pregnancy nor shop for baby stuff either online or using a credit card, and neither would my husband, because our I.P. addresses—and thus the vast, matrixed fatbergs of personal data assembled by unseen corporations to pinpoint our consumer and political identities—were linked. I wouldn’t look at pregnancy accounts on Instagram or pregnancy forums on Reddit. I wouldn’t update my period tracker or use a pregnancy app.</p><p>Nearly every time we load new content on an app or a Web site, ad-exchange companies—Google being the largest among them—broadcast data about our interests, finances, and vulnerabilities to determine exactly what we’ll see; more than a <a data-offer-url="https://www.iccl.ie/wp-content/uploads/2023/11/Americas-hidden-security-crisis.pdf" data-event-click="{&#34;element&#34;:&#34;ExternalLink&#34;,&#34;outgoingURL&#34;:&#34;https://www.iccl.ie/wp-content/uploads/2023/11/Americas-hidden-security-crisis.pdf&#34;}" href="https://www.iccl.ie/wp-content/uploads/2023/11/Americas-hidden-security-crisis.pdf" rel="noopener" target="_blank">billion</a> of these transactions take place in the U.S. every hour. Each of us, the data-privacy expert Wolfie Christl told me, has “dozens or even hundreds” of digital identifiers attached to our person; there’s an estimated eighteen-billion-dollar industry for location data alone. In August, 2022, Mozilla reviewed twenty pregnancy and period-tracking apps and found that fifteen of them made a “buffet” of personal data available to third parties, including addresses, I.P. numbers, sexual histories, and medical details. In most cases, the apps used vague language about when and how this data could be shared with law enforcement. (A 2020 <em>FOIA</em> lawsuit filed by the A.C.L.U. revealed that the Department of Homeland Security had <a href="https://www.aclu.org/cases/aclu-v-department-homeland-security-commercial-location-data-foia">purchased</a> access to location data for millions of people in order to track them without a warrant. <em>ICE</em> and C.B.P. subsequently said they would stop using such data.) The scholar Shoshana Zuboff has called this <a href="https://www.newyorker.com/culture/cultural-comment/building-the-digital-iron-cage">surveillance capitalism</a>, “a new economic order that claims human experience as free raw material for hidden commercial practices of extraction, prediction, and sales.” Through our phones, we are under perpetual surveillance by companies that buy and sell data about what kind of person we are, whom we might vote for, what we might purchase, and what we might be nudged into doing.</p><p>A decade ago, the sociology professor Janet Vertesi conducted a more rigorous form of the hidden-pregnancy experiment. Using an elaborate system of code words and the anonymous browser Tor, she managed to digitally hide her pregnancy all the way up to the birth of her child. In an <a href="https://time.com/83200/privacy-internet-big-data-opt-out/">article</a> about the experience, for <em>Time</em>, she pointed to a <em>Financial Times</em> report, which found that identifying a single pregnant woman is as valuable to data brokers as knowing the age, gender, and location of more than two hundred non-pregnant people, because of how much stuff new parents tend to buy. She also noted that simply attempting to evade market detection—by, for example, purchasing stacks of gift cards in order to buy a stroller—made her and her husband look as though they were trying to commit fraud.</p><p>I wasn’t going to do anything so strict or elaborate. I’d allow myself to text and send e-mails about my pregnancy, and to talk about it with my phone nearby. I assumed that, eventually, it would notice; I’d just wait and see when a diaper ad popped up on Instagram. I liked the idea of establishing a buffer zone between my psyche and the object that most closely monitors it. I found it almost shocking to remember that this was possible.</p><p>Pregnancy tends to erode both your freedom and your privacy. Past a certain point in your second trimester, strangers will begin reaching toward your stomach and telling you about the real difference between boys and girls. But I had eluded this during my first pregnancy, because <em>COVID</em> hit before I started showing. In the months that followed, I began to feel the difference between witnessing something and surveilling it, and to recognize that the most pleasurable moments in my life had occurred out of the reach of any oversight. I had felt then an almost psychedelic sense of autonomy; time was dilating, and the slow bloom inside me was beyond anyone’s reach. I wanted to see if I could feel anything like that again.</p><p>During pregnancy, and in the early days of parenthood, one is both the object and the conductor of intense surveillance. Last year, the artist and filmmaker Sophie Hamacher co-edited an anthology of writing on the subject, called “<a data-offer-url="https://www.amazon.com/Supervision-Motherhood-Surveillance-Jessica-Hankey/dp/0262047810" data-event-click="{&#34;element&#34;:&#34;ExternalLink&#34;,&#34;outgoingURL&#34;:&#34;https://www.amazon.com/Supervision-Motherhood-Surveillance-Jessica-Hankey/dp/0262047810&#34;}" href="https://www.amazon.com/Supervision-Motherhood-Surveillance-Jessica-Hankey/dp/0262047810" rel="noopener" target="_blank">Supervision</a>,” which was published by M.I.T. Press. “As I became absorbed with tracking and monitoring my child,” Hamacher writes in the preface, “I was increasingly aware that I was a subject of tracking and monitoring by others: advertisers, medical professionals, government entities, people on the street. I began to wonder about the relationship between the way I watched her and the ways we were being watched.” Surveillance encompasses both policing and caretaking, Hamacher notes. In practice, its polarized qualities—“beneficial and harmful, intimate and distanced”—intertwine. Baby monitors use technology developed for the military. Many contemporary models run on CCTV.</p><p>Most American households with young children use baby monitors or trackers; two recent surveys put market penetration at <a href="https://www.cnbc.com/2015/03/20/next-frontier-for-internet-of-things-babies.html">seventy-five</a> and <a data-offer-url="https://www.thebump.com/news/summer-study-dads-quicker-to-check-on-baby" data-event-click="{&#34;element&#34;:&#34;ExternalLink&#34;,&#34;outgoingURL&#34;:&#34;https://www.thebump.com/news/summer-study-dads-quicker-to-check-on-baby&#34;}" href="https://www.thebump.com/news/summer-study-dads-quicker-to-check-on-baby" rel="noopener" target="_blank">eighty-three</a> per cent, respectively. (Both surveys were conducted by companies that make these devices.) And there are now countless other ways that technology will help you to observe and scrutinize your child: nanny-cam Teddy bears, G.P.S. stroller accessories, scales that track your baby’s weight over time, disks that can be affixed to diapers and which will notify you if your baby rolls onto his stomach while he’s asleep. Increasingly, such products use A.I. to detect signs of distress. “The need to know whether a child is safe and well is perfectly natural, which makes the nature of such surveillance appear innocent,” the writer and scholar Hannah Zeavin notes in “Family Scanning,” one of the essays in “Supervision.” But, she adds, “these technologies conceal the possibility of false positives, disrupted emergency services, and of collaboration with state forces—wittingly or unwittingly—all in the name of keeping children safe.” As a general rule, these devices don’t lead to better outcomes for the babies they monitor. More often—like social media, which promises connection as a salve for the loneliness created by social media—parenting tech exacerbates, even calls into existence, the parental anxieties that it pledges to soothe.</p><p>This has become a common pattern in contemporary life. Nearly a fifth of U.S. households are estimated to use doorbell cameras, many of them from Ring, the Amazon-owned company that has expanded its reach through police partnerships and a dedicated app that encourages users to post footage of strangers. Ring cameras haven’t made neighborhoods measurably safer, but they have made users measurably more paranoid, and placed more people, sometimes with grave outcomes, in contact with the police. Until recently, police could readily access surveillance footage from the Ring network without a warrant by posting requests on the app. It also gave its own employees and third-party contractors “ ‘<a href="https://www.ftc.gov/business-guidance/blog/2023/05/not-home-alone-ftc-says-rings-lax-practices-led-disturbing-violations-users-privacy-security">free range</a>’ access” to view and download videos from users’ homes.</p><p>In 2015, the company Owlet started selling a two-hundred-and-fifty-dollar Smart Sock, which monitored babies’ heart rates and oxygen levels, and alerted parents if these figures were abnormal. Although the company insists that it has made clear that the product is not intended to “treat or diagnose” sudden infant death syndrome—and there is no evidence that it reduces the risk of <em>SIDS</em> occurring—such devices are sometimes referred to as “<em>SIDS</em> monitors.” But, in 2017, an opinion piece in the <em>Journal of the American Medical Association</em> <a href="https://jamanetwork.com/journals/jama/article-abstract/2598780">cautioned</a> physicians against recommending the product. “There are no medical indications for monitoring healthy infants at home,” the authors wrote. The device, they noted, could “stimulate unnecessary fear, uncertainty, and self-doubt in parents about their abilities to keep their infants safe.” The following year, a <a href="https://jamanetwork.com/journals/jama/fullarticle/2697685">study</a> in the same journal found “concerning” inaccuracies in oxygen readings. When Owlet went public, in February, 2021, the company had a valuation of more than a billion dollars; later that year, the F.D.A. issued a warning letter that the Smart Sock wasn’t an authorized medical device, and the company pulled it off the market. A million units had already been sold. The following year, Owlet launched a new version, called the Dream Sock, which would receive F.D.A. approval. Most of the reviews for the Dream Sock exude profound gratitude. Parents write about the peace of mind that comes from knowing the baby is being constantly monitored, about not knowing what they would do if the device didn’t exist.</p><p>Surveillance capitalism, Zuboff writes, “aims to impose a new collective order based on total certainty.” But little is certain when it comes to babies. The control that we feel when we’re engaged in surveillance almost always proves illusory, though the control, or at least the influence, that others exert on us through surveillance is real.</p><p>It is not a coincidence that Roe v. Wade, a ruling grounded in the right to privacy, was <a href="https://www.newyorker.com/magazine/2022/07/04/we-are-not-going-back-to-the-time-before-roe-we-are-going-somewhere-worse">overturned</a> at a time when privacy in the U.S was on its conceptual deathbed. There are other legal principles that might have served as a stronger foundation for abortion rights: the right to equal protection, or the right to bodily integrity. As Christyne Neff wrote, in 1991, the physical effects of an ordinary pregnancy and delivery resemble those of a severe beating—flesh lacerated, organs rearranged, half a quart of blood lost. Can the state, she asked, rightfully compel a person to undergo this?</p><p>Since Roe fell, two years ago, fourteen states have claimed that power in absolute terms, banning abortion almost completely. Two states have successfully passed abortion-vigilante laws, which confer the power of carceral supervision on the public. Indiana’s attorney general has argued that abortion records should be publicly available, like death records; Kansas recently passed a law that would require abortion providers to collect details about the personal lives of their patients and make that information available to the government. Birth control and sex itself may be up next for criminal surveillance: the <a href="https://www.newyorker.com/magazine/2021/08/09/the-big-money-behind-the-big-lie">Heritage Foundation</a>, last year, insisted, on Twitter, that “conservatives have to lead the way in restoring sex to its true purpose, &amp; ending recreational sex &amp; senseless use of birth control pills.”</p><p>For many women in America, pregnancy was a conduit to state surveillance long before the end of Roe. Poor women, especially poor nonwhite women, are often drug-tested during pregnancy, and sometimes during labor and delivery, without their informed consent. Women who take drugs during pregnancy have been charged with child abuse or neglect, including in cases in which the drugs were legal; women who have miscarried after taking drugs have been charged with manslaughter, even homicide, even when no causal link was proved. Sometimes this happens because the woman in question had responded to billboards and service announcements promising to help pregnant people who are struggling with substance use. In multiple states, women have been taken into custody when the safety of the fetus was called into question. “To be pregnant and poor in the United States is to play a game of roulette with one’s privacy, presumed confidential relationship with medical providers, and basic constitutional and medical rights,” the law professor Michele Goodwin writes in “<a data-offer-url="https://www.amazon.com/Policing-Womb-Invisible-Criminalization-Motherhood/dp/110703017X" data-event-click="{&#34;element&#34;:&#34;ExternalLink&#34;,&#34;outgoingURL&#34;:&#34;https://www.amazon.com/Policing-Womb-Invisible-Criminalization-Motherhood/dp/110703017X&#34;}" href="https://www.amazon.com/Policing-Womb-Invisible-Criminalization-Motherhood/dp/110703017X" rel="noopener" target="_blank">Policing the Womb</a>,” from 2020.</p><p>Goodwin describes the case of a woman in Iowa named Christine Taylor, who, in 2010, as a twenty-two-year-old mother of two, was accused of attempted feticide after she fell down the stairs while pregnant. Part of the evidence cited by the police was that she reportedly told a nurse that she hadn’t wanted the baby. (Ultimately, prosecutors decided not to press charges.) The carceral surveillance of pregnancy entails the criminalization of ambivalence, the inspection of these innermost desires. But the deepest truths about motherhood seem to me to be rooted in conflicting, coexisting emotions: nightmare and rapture in the same moment during labor, the love and despair that box each other at night in the weeks that follow, the joy of cuddling my nine-month-old undergirded by the horror of knowing that other babies are starving and dying in rubble. Before I had my first child, I had badly wanted to get pregnant. I had planned for it, prepared for it, hoped for it. Still, when I saw the positive test result, I cried.</p><p>My modest experiment went surprisingly smoothly. Because I’d had my first child not long before, this time I didn’t need to buy anything, and I didn’t want to learn anything. I smooth-brained my way to three months, four months, five; no diaper ads. I called up a lawyer and data-privacy specialist named Dominique Shelton Leipzig to get her perspective. Globally, she told me, we generate 2.5 quintillion bytes—that’s eighteen zeroes—of data per day. “The short answer is, you probably haven’t hidden what you think you have,” she said. I told her about the rules I’d set for myself, that I didn’t have many apps and had bought nothing but prenatal vitamins, and that Instagram did not appear to have identified me as pregnant. She paused. “I’m amazed,” she told me. “If you didn’t see any ads, I think you might have succeeded.” I congratulated myself by instantly dropping the experiment and buying maternity pants; ads for baby carriers popped up on my Instagram within minutes.</p><p>I had felt little satisfaction hiding from the ad trackers—if anything, I’d only become more conscious of how much surveillance I was engaged in, as both subject and object, and how much more insidious the problem was becoming. We rarely have a clear understanding of what we’re doing when we engage in surveillance of ourselves or others. Life360, an app that’s used by more than sixty million people and is marketed as an easy way to track your child’s location via their smartphone, was found in 2021 to be selling raw location information to data brokers. (The company said it now sells only aggregate data.) In a <a href="https://www.pewresearch.org/short-reads/2023/10/18/key-findings-about-americans-and-data-privacy/">Pew survey</a> from 2023, seventy-seven per cent of Americans said they had very little to no trust in how social-media executives handle user data, and seventy-one per cent were concerned about how the government uses it. In another survey, ninety-three per cent of Americans said they wouldn’t buy a doorbell camera if it sold data about their family. People just want to be safer. I had wanted security, too, and affirmation—and I had wanted to be a writer. I had disclosed so much of my life to people I’ll never know.</p><p>My husband and I had not bought a baby monitor for our first child, a choice that satisfied his desire to not buy things and my desire to insist that certain aspects of experience are fundamentally ungovernable. But shortly after the second child was born she developed eczema, and started scratching her sweet, enormous cheeks in her sleep. One morning, my husband went to her and found that she’d clawed her face open, leaving blood smudged all over her sleep sack and smeared all over her face. “We need a video monitor!” I wailed, already Googling options. “We need to buy a video monitor today.”</p><p>We didn’t buy one, but for weeks I regretted it and second-guessed myself. And I surveilled the baby with technology in other ways all the time. In the early weeks, I relied on an app to tell me how much milk she’d drunk and how many soiled diapers she’d had that day—activities that I myself had witnessed just hours before. I felt like a Biblical angel with a thousand eyes, somehow unable to see anything. I took pictures because I knew I would have no memory of the precise contours of this exact baby in a month. When she didn’t seem hungry enough, I panicked, obsessing over every feed.</p><p>“What’s the line between pathological self-surveillance and care for a newborn? Is there one?” Sarah Blackwood, an English professor at Pace University, asks, in “Supervision.” Blackwood contrasts the “fantasy of efficiency and sterility” built into parenting tech with the “psychic state of watchfulness so many mothers find themselves in”—a state that is “metastatic, fecund, beyond.” One afternoon, my husband took the baby from me: she was sobbing, and I was incoherently frantic, trying to get her to eat. She was O.K., he told me; she’d eat when she needed to. But I know what’s good for her, and it’s my job to make her do it, I thought, furious. Around the fringes of my consciousness, I felt a flicker of understanding about how this idea that everything was controllable had become so ubiquitous, how we had confused coercion with care. ♦</p></div></div></div></div>
  </body>
</html>
