<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.aiengineering.report/p/claude-code-vs-codex-sentiment-analysis-reddit">Original</a>
    <h1>Claude Code vs. Codex: I built a sentiment dashboard from Reddit comments</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><article><div><div><div dir="auto"><div id="youtube2-0RSMIdoXRsw" data-attrs="{&#34;videoId&#34;:&#34;0RSMIdoXRsw&#34;,&#34;startTime&#34;:&#34;3s&#34;,&#34;endTime&#34;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/0RSMIdoXRsw?start=3s&amp;rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><span>Most benchmarks tell us how AI coding models perform in carefully constructed scenarios. But they don’t tell us what developers actually think when they use these tools every day. That gap is why I built a Reddit sentiment analysis dashboard to see how real engineers compare </span><strong>Claude Code vs Codex</strong><span> in the wild. You can find the dashboard at </span></p><p><a href="https://claude-vs-codex-dashboard.vercel.app/" rel="">https://claude-vs-codex-dashboard.vercel.app/</a></p><p><span>and the source code at: </span><a href="https://github.com/waprin/claude-vs-codex-dashboard" rel="">https://github.com/waprin/claude-vs-codex-dashboard</a></p><p>There are some options to view sentiment weighted or unweighted by upvotes, and compare on specific categories like speed, problem solving, and workflows. </p><p>In this newsletter edition, I’ll discuss:</p><ul><li><p>What trends the sentiment analysis dashboard uncovers on Claude Code vs Codex discussions on Reddit</p></li><li><p>The methodology I used to build the dashboard and plans for future improvements</p></li></ul><p><span>While notable AI benchmarks like </span><a href="https://www.swebench.com/" rel="">SWEbench</a><span>, </span><a href="https://prarena.ai/" rel="">PR Arena</a><span>, </span><a href="https://www.tbench.ai/" rel="">TerminalBench</a><span>, and </span><a href="https://lmarena.ai/" rel="">LMArena</a><span> help us navigate the landscape of the quality of AI models, </span><strong>I don’t think </strong><em><strong>any</strong></em><strong> benchmark can truly capture how most software engineers are using agentic coding models day-to-day</strong><span>. We don’t typically “set-it-and-forget” the agent on a constructed task but rather there’s an interactive back-and-forth conversational session. Furthermore, engineers in the wild are facing a far greater diversity of tasks than any given benchmark could hope to capture.</span></p><p><span>For those reasons, I believe a survey of the “wisdom of the crowd” </span><em>is</em><span> valuable to gain a broader understanding of which agentic coding models are performing better. To do so, I scraped a wide variety of comments on Reddit from AI-coding focused subreddits such as </span><strong>/r/ChatGPTCoding,</strong><span> /</span><strong>r/ClaudeCode</strong><span>, and </span><strong>/r/Codex</strong><span>. I then used the Claude Haiku model to classify whether the comment directly compared Claude Code and Codex, and classified the sentiment accordingly.</span></p><p><span>(note: this analysis was done </span><em>before </em><span>the new Haiku model that </span><a href="https://www.anthropic.com/news/claude-haiku-4-5" rel="">Anthropic announced yesterday</a><span>) </span></p><p>Since this post is fairly long, I’ll summarize here:</p><ul><li><p><strong>Overall, Codex has much more positive sentiment than Claude Code in comments that compare the two directly</strong></p></li><li><p><strong>However, Claude Code has much more discussion overall, at about 4x the volume of Codex, raising the question of whether its popularity leads to its detractors</strong></p></li><li><p><strong>On specific topics like performance, model quality, and problem-solving, Codex leads in all categories except two - speed and workflows. Claude Code is considered faster to respond and has a better terminal UX and ecosystem of tools</strong><span>. </span><strong>Codex frequently gets complimented for outperforming Claude Code on more challenging problems. </strong></p></li></ul><p>Claude Code performing better on speed but Codex on problem-solving also aligns with some tweets I’ve seen in the wild.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!GTG2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!GTG2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 424w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 848w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 1272w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!GTG2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png" width="614" height="359" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:359,&#34;width&#34;:614,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:58135,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.aiengineering.report/i/176279172?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!GTG2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 424w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 848w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 1272w, https://substackcdn.com/image/fetch/$s_!GTG2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35e8afd5-f35c-456e-9674-6a24d664e768_614x359.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p>Let’s dive into some specific takeaways, and then I’ll circle back to my notes on the methodology.</p><p>The first takeaway is that Codex is compared more positively against Claude Code by a fairly large margin:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!RYLh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!RYLh!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 424w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 848w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 1272w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!RYLh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png" width="1456" height="299" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:299,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:111873,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.aiengineering.report/i/176279172?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!RYLh!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 424w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 848w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 1272w, https://substackcdn.com/image/fetch/$s_!RYLh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52edd2ff-3e33-4255-aa47-c7e7707de440_2578x530.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>As you can see, </span><strong>65.3% of Reddit comments comparing Claude Code vs Codex prefer Codex.</strong></p><p><span>The above metric only tallies raw </span><em>number</em><span> of comments. If we weight those comments by upvotes, so a comment with 10 upvotes counts ten times as much as a comment with 1 upvote, the sentiment difference is even more stark. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!hJcw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!hJcw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 424w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 848w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 1272w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!hJcw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png" width="1456" height="295" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:295,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:159163,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.aiengineering.report/i/176279172?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!hJcw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 424w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 848w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 1272w, https://substackcdn.com/image/fetch/$s_!hJcw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f227fb9-8f39-478e-b5cf-877e051ac86d_2668x540.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>We can see that </span><strong>79.9% of Reddit upvotes prefer Codex to Claude Code</strong><span>. </span></p><p>The dashboard also lets you see all the Reddit comments at the bottom, sorted by upvotes and optionally filtered by themes such as speed or price, if you want to see the original comments.</p><p><span>While Codex has far more positive sentiment than Claude Code, it’s worth noting that people are simply </span><em>talking </em><span>about Claude Code </span><em>significantly</em><span> more than Codex. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!P15c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!P15c!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 424w, https://substackcdn.com/image/fetch/$s_!P15c!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 848w, https://substackcdn.com/image/fetch/$s_!P15c!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 1272w, https://substackcdn.com/image/fetch/$s_!P15c!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!P15c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png" width="1456" height="319" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:319,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:133447,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.aiengineering.report/i/176279172?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!P15c!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 424w, https://substackcdn.com/image/fetch/$s_!P15c!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 848w, https://substackcdn.com/image/fetch/$s_!P15c!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 1272w, https://substackcdn.com/image/fetch/$s_!P15c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4a13ff4-290e-464f-b584-b5d9a69dbffc_2548x558.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>As you can see, “Codex&gt;CC” has 98 comments vs. 18 comments that have “CC&gt;Codex”. But if we look at comments that don’t directly compare the tools, </span><em>both </em><span>Claude Code and Codex have more negative comments than positive comments. People tend to complain more than praise on the internet. But of the 500 comments, Claude Code had 40 comments and Codex only had 10. This means people are talking about Claude Code </span><em>about four times as much</em><span> as they’re talking about Codex.</span></p><p>You can also see the volume of Claude Code discussion evidenced by the subreddits themselves, with /r/ClaudeCode having 4.2k weekly contributions and /r/codex having 1.2k weekly contributions.</p><p>This raises the question of how much negativity towards Claude Code is because the most popular tool tends to get the most criticism. </p><p><span>I was surprised to see extensive discussion comparing Claude Code and Codex to another competitor I never even heard of, GLM, a Chinese agentic coding agent. In fact, one of the top threads in /r/ClaudeCode recently is: </span><strong><a href="https://www.reddit.com/r/ClaudeCode/comments/1nzet39/comment/ni1k50k/" rel="">Why I Finally Quit Claude (and Claude Code) for GLM</a><span>, </span></strong><span>with the top comment reading:</span></p><blockquote><p>GLM surprised me when I tried it recently. It’s not as good (yet) in terms of agentic capabilities compared to Codex or Claude, but it’s good enough it produces quality results for pennies on the dollar in terms of cost. Easily the best value LLM around right now.</p></blockquote><blockquote><p><span>i‘ve been testing sonnet 4.5, gpt5-codex and glm 4.6 plans over the past few days with a nextjs project.</span></p><p><span>— User serialoverflow (</span><a href="https://www.reddit.com/r/ChatGPTCoding/comments/1nxthkn/comment/nhpqc9f/" rel="">source</a><span>)</span></p></blockquote><blockquote><p>Former Claude Code user for a few months on Max 20x, fairly heavy user too. Loved it at the time, but feels like at least during part of last month the quality of the model responses degraded. I found myself having to regularly steer Claude into not making changes I didn’t actually agree on (yes I use the plan mode, it’s highly valuable). Claude also often told me that code was production ready when it wasn’t, it either failed to compile or had some kind of flaw that needed addressing.</p><p>The biggest challenge I’ve given it so far was to refactor a long overdue and messy .cs file that contained about 3k LOC. I’ve tried this with various other AI LLMs, including Claude Code (which couldn’t read the entire file as it was over 25k tokens), but they just ultimately make bugs and mess things up when trying to do so. I didn’t think GPT-5 would be any different, but my god, it surprised me again. I planned with it, did it in small bits and pieces at a time, and a day or so later I’m now down to around 1k LOC for that file. It seems to be working fine too.</p><p><span>— User Hauven (</span><a href="https://www.reddit.com/r/ChatGPTCoding/comments/1n8c82u/comment/nce1em4/" rel="">source</a><span>)</span></p></blockquote><p><span>The dashboard allows you to filter by specific </span><em>topics</em><span>, and Codex leads Claude Code on 8 of 10 categories. However, Claude Code leads on two - speed and workflows. This aligns with much of the discussion I’ve seen online, where people generally think Codex is a stronger model but notice that Claude Code just returns a response </span><em>faster</em><span> and that the terminal UX and tool ecosystem is stronger. </span></p><p><span>Codex won the rest of the categories: </span><em>pricing, performance, reliability, usage limits, code generation, problem solving, and code quality.</em></p><p>To decide which Reddit comments to even scrape, I first used Google Search with the query `site:reddit.com “claude code” codex`. The vast majority of the results were from Claude-related subreddits - namely /r/ClaudeCode , /r/ClaudeAI, and /r/Anthropic. The only other subreddit with a large number of results is /r/ChatGPTCoding, which despite its name, is geared towards any sort of AI-coding discussion and is not ChatGPT specific. </p><p>Some other subreddits such as /r/Cursor, /r/OpenAI, /r/LLMDevs, /r/vibecoding, /r/AI_Agents, etc had a small number of results but were not significant.</p><p>Given that the Google Search API is severely limited in the number of results you can return, and the Bing API is being deprecated, the simplest way to scrape these comments is to use the Reddit API. </p><p>I focused on /r/ClaudeCode, /r/ChatGPTCoding, and /r/Codex. However, while I have some /r/Codex comments, none of them made it into this first analysis pass. I decided not to include /r/ClaudeAI despite a significant amount of discussion there because the dataset was already heavily biased towards Claude-centric discussions. </p><p><span>I decided to use Claude Haiku to analyze the sentiment on each comment. I </span><em>did </em><span>make sure that each comment had its entire parent chain within its context when doing the sentiment analysis. This is important context if a comment says something like “I agree”.</span></p><p><span>I was curious if I should save time and cost by batching comments, but Claude itself recommended against this approach and suggested it could too easily distort results. There are actually </span><em>two</em><span> ways to consider batching here. We could batch by asking it to rate multiple comments at a time, which I decided against and there’s the B</span><a href="https://docs.claude.com/en/docs/build-with-claude/batch-processing" rel="">atch processing Anthropic API</a><span>, which I didn’t get around to using yet but might add in the future to save time. </span></p><p>I did use Haiku since it’s one of the cheaper models. Overall, the cost was not an issue, but the time took surprisingly long. For some data points:</p><p><em>50 comments took 3 minutes, 28k input tokens, 10k output tokens, and $0.08 to analyze.</em></p><p><em>500 comments took 26.7 minutes, 273k input tokens, and $0.77 to analyze</em></p><p>As you can see, even fairly big batches cost under $1 to analyze, but waiting 25 minutes for the results was slightly annoying. </p><p>Haiku may have been slighty overkill, as Gemini Flash may have been cheaper, but Haiku was cheap enough as-is. </p><p>Again, check out the link to the dashboard at the top of the post or the GitHub repo if you’re curious to dig in yourself.</p><p><span>On a personal note, I’ve played with Codex but have been finding myself using Claude Code more because </span><em>speed</em><span> makes programming more fun for me, and having fun means I stick to the work longer. But I am exploring how to upskill my agentic coding with background agents and spec-driven development, and it’s very clear that the broader community sentiment suggests Codex is a stronger tool here than Claude Code.</span></p><p>Let me know if you’re interested in this topic by replying to this email or leaving a comment on Substack. I plan to add more comments to the analysis, and I’m also interested in comparing the sentiment analysis result of Haiku vs stronger models like GPT-5 or Sonnet and see if any differences emerge. Thanks for reading!</p><p data-attrs="{&#34;url&#34;:&#34;https://www.aiengineering.report/p/claude-code-vs-codex-sentiment-analysis-reddit/comments&#34;,&#34;text&#34;:&#34;Leave a comment&#34;,&#34;action&#34;:null,&#34;class&#34;:null}" data-component-name="ButtonCreateButton"><a href="https://www.aiengineering.report/p/claude-code-vs-codex-sentiment-analysis-reddit/comments" rel=""><span>Leave a comment</span></a></p></div></div></div></article></div></div></div><div><div id="discussion"><div><h4>Discussion about this post</h4></div></div></div></div>
  </body>
</html>
