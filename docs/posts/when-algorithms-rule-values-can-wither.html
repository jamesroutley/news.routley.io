<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sloanreview.mit.edu/article/when-algorithms-rule-values-can-wither/">Original</a>
    <h1>When Algorithms Rule, Values Can Wither</h1>
    
    <div id="readability-page-1" class="page"><div id="article-content">
        <header>
    <a href="https://sloanreview.mit.edu/issue/2023-winter/"><span>Magazine Winter 2023 Issue</span></a>     
    <p>Building responsible AI systems starts with recognizing that technology solutions implicitly prioritize efficiency.</p>

            <div>
            <p>
            <time datetime="2022-12-05T07:00:15-05:00" pubdate="">
                <abbr title="2022-12-05T07:00:15-05:00">December 05, 2022</abbr>
            </time>
            <span>Reading Time: 12 minÂ </span>
        </p></div>
    </header>

<div>

    


    







    
        
    
<figure>
<img src="https://sloanreview.mit.edu/wp-content/uploads/2022/10/WINTER22-Lindebaum-1290x860-1.jpg" alt=""/><figcaption>
<p>Aad Goudappel/theispot.com</p>
</figcaption></figure>
<p>Interest in the possibilities afforded by algorithms and big data continues to blossom as early adopters gain benefits from AI systems that automate decisions as varied as making customer recommendations, screening job applicants, detecting fraud, and optimizing logistical routes.<a id="reflink1" href="#ref1">1</a> But when AI applications fail, they can do so quite spectacularly.<a id="reflink2" href="#ref2">2</a></p>
<p>Consider the recent example of Australiaâ€™s â€œrobodebtâ€ scandal.<a id="reflink3" href="#ref3">3</a> In 2015, the Australian government established its Income Compliance Program, with the goal of clawing back unemployment and disability benefits that had been made inappropriately to recipients. It set out to identify overpayments by analyzing discrepancies between the annual income that individuals reported and the income assessed by the Australian Tax Office. Previously, the department had used a data-matching technique to identify discrepancies, which government employees subsequently investigated to determine whether the individuals had in fact received benefits to which they were not entitled. Aiming to scale this process to increase reimbursements and cut costs, the government developed a new, automated system that <em>presumed</em> that every discrepancy reflected an overpayment. A notification letter demanding repayment was issued in every case, and the burden of proof was on any individuals who wished to appeal. If someone did not respond to the letter, their case was automatically forwarded to an external debt collector. By 2019, the program was estimated to have identified over 734,000 overpayments worth a total of 2 billion Australian dollars ($1.3 billion U.S.).<a id="reflink4" href="#ref4">4</a></p>
<div id="news-signup-47405-1413002416">
    <div>
                    <h2><p>Get Updates on Leading With AI and Data</p>
</h2>
                            <p>Get monthly insights on how artificial intelligence impacts your organization and what it means for your company and customers.</p>
                
        <p>Please enter a valid email address</p>
        <p>Thank you for signing up</p>
        <p><a href="https://sloanreview.mit.edu/privacy-policy/">Privacy Policy</a></p>
    </div>
</div>

<p>The new system was designed to optimize efficiency, but without being attentive to the particulars of individual cases. The idea was that by eliminating human judgment, which is shaped by biases and personal values, the automated program would make better, fairer, and more rational decisions at much lower cost. Unfortunately, choices made by system designers both in how the algorithm was designed and how the process worked resulted in the government demanding repayments from hundreds of thousands of people who had been entitled to the benefits they had received. Some were compelled to prove that they had not illegitimately claimed benefits as long ago as seven years earlier. The consequences for many individuals were dire.</p>
<p>Subsequent parliamentary reviews pointed to â€œa fundamental lack of procedural fairnessâ€ and called the program â€œincredibly disempowering to those people who had been affected, causing significant emotional trauma, stress, and shame.â</p>

    
    
    

        <div id="article-authors">
                <h4>About the Authors</h4>
        <p>Dirk Lindebaum is a senior professor in organization and management at Grenoble Ecole de Management. Vern Glaser is associate professor of entrepreneurship and family enterprise and the Eric Geddes Professor of Business in the Strategy, Entrepreneurship, and Management Department at the University of Alberta. Christine Moser is associate professor of organization theory at the Vrije Universiteit Amsterdam. Mehreen Ashraf is a doctoral student at Cardiff Business School.</p>
    </div>

        <div id="article-ref">
        <h4>References</h4>
        <div>
            <p id="ref1"><b>1.</b> T.H. Davenport and R. Bean, â€œ<a href="https://sloanreview.mit.edu/article/becoming-an-ai-powerhouse-means-going-all-in/">Becoming an â€˜AI Powerhouseâ€™ Means Going All In</a>,â€ MIT Sloan Management Review, June 15, 2022, https://sloanreview.mit.edu.</p>

<p id="ref2"><b>2.</b> C. Oâ€™Neil, â€œWeapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracyâ€ (New York: Crown Publishers, 2016).</p>

<p id="ref3"><b>3.</b> â€œ<a href="https://parlinfo.aph.gov.au/parlInfo/download/committees/reportsen/024846/toc_pdf/AccountabilityandjusticeWhyweneedaRoyalCommissionintoRobodebt.pdf;fileType=application%2Fpdf">Accountability and Justice: Why We Need a Royal Commission Into Robodebt</a>,â€ PDF file (Canberra, Australia: Senate Community Affairs Reference Committee, May 2022), https://parlinfo.aph.gov.au.</p>

<p id="ref4"><b>4.</b> â€œ<a href="https://parlinfo.aph.gov.au/parlInfo/download/committees/reportsen/024338/toc_pdf/Centrelink&#39;scomplianceprogram.pdf;fileType=application%2Fpdf">Centrelinkâ€™s Compliance Program: Second Interim Report</a>,â€ PDF file (Canberra, Australia: Senate Community Affairs Reference Committee, September 2020), chap. 1, https://parlinfo.aph.gov.au.</p>

<p id="ref5"><b>5.</b> â€œCentrelinkâ€™s Compliance Program,â€ chap. 2.</p>

<p id="ref6"><b>6.</b> Ibid.</p>

<p id="ref7"><b>7.</b> D. Lindebaum, C. Moser, M. Ashraf, et al., â€œ<a href="https://journals.aom.org/doi/abs/10.5465/amr.2021.0159">Reading â€˜The Technological Societyâ€™ to Understand the Mechanization of Values and Its Ontological Consequences</a>,â€ Academy of Management Review, July 2022, https://journals.aom.org.</p>

<p id="ref8"><b>8.</b> Oâ€™Neil, â€œWeapons of Math Destruction.â€</p>

<p id="ref9"><b>9.</b> M. Rokeach, â€œThe Role of Values in Public Opinion Research,â€ Public Opinion Quarterly 32, no. 4 (winter 1968-1969): 550.</p>

<p id="ref10"><b>10.</b> Oâ€™Neil, â€œWeapons of Math Destruction.â€</p>        </div>
    </div>

    
        

        

</div>    </div></div>
  </body>
</html>
