<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">Original</a>
    <h1>Weird architectures weren’t supported to begin with (2021)</h1>
    
    <div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/series">Series</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net">Main Site</a></li>
    
</ul>

<hr/>



<h2>
  <p>
    <span><em>Feb 28, 2021</em></span>

       

    
      <span>
        Tags:
        
        
          <a href="https://blog.yossarian.net/tags#oss">oss</a>,
        
          <a href="https://blog.yossarian.net/tags#programming">programming</a>,
        
          <a href="https://blog.yossarian.net/tags#rant">rant</a>
        
      </span>
    

       

    
  </p>
</h2>

<hr/>

<h4 id="preword">Preword</h4>

<p>This post contains my own opinions, not the opinions of my employer or any open source groups I
belong or contribute to.</p>

<p>It’s also been rewritten 2½ times, and (I think) reads confusingly in places. But I promised
myself that I’d get it out of the door instead of continuing to sit on it, so here we go.</p>

<hr/>

<p>There’s been a decent amount of <del>drama</del> debate in the open source community about <em>support</em>
recently, originating primarily from
<a href="https://github.com/pyca/cryptography/issues/5771">pyca/cryptography’s decision to use Rust for some ASN.1 parsing routines</a><sup id="fnref:asn1" role="doc-noteref"><a href="#fn:asn1" rel="footnote">1</a></sup>.</p>

<p>To summarize the situation: building the latest <code>pyca/cryptography</code> release from scratch now requires
a Rust toolchain. The only current<sup id="fnref:gccrust" role="doc-noteref"><a href="#fn:gccrust" rel="footnote">2</a></sup> Rust toolchain is built on <a href="https://llvm.org/">LLVM</a>, which
supports a (relatively) limited
<a href="https://llvm.org/docs/CompilerWriterInfo.html">set of architectures</a>. Rust further whittles this
set down into <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">support tiers</a>, with
some targets not receiving automated testing (tier 2) or official builds (tier 3).</p>

<p>By contrast, upstream<sup id="fnref:gcchell" role="doc-noteref"><a href="#fn:gcchell" rel="footnote">3</a></sup> GCC supports a <a href="https://gcc.gnu.org/backends.html">somewhat larger</a>
set of architectures. But C<sup id="fnref:c" role="doc-noteref"><a href="#fn:c" rel="footnote">4</a></sup>, cancer that it is, finds its way onto every architecture with or
without GCC (or LLVM’s) help, and thereby bootstraps <a href="https://github.com/python/cpython">everything</a>
<a href="https://www.gnome.org/">else</a>.</p>

<p>Program packagers and distributors (frequently separate from project maintainers themselves)
are very used to C’s universal presence. They’re so used to it that they’ve built generic
mechanisms for putting entire distributions onto new architectures with
only a single assumption: the presence of a serviceable C compiler.</p>

<p>This is the heart of the conflict: Rust (and many other modern, safe languages) use LLVM for its
relative simplicity<sup id="fnref:simple" role="doc-noteref"><a href="#fn:simple" rel="footnote">5</a></sup>, but LLVM does not support either native or cross-compilation to many
less popular (read: niche) architectures. Package managers are increasingly finding that one of
their oldest assumptions can be easily violated, and they’re not happy about that.</p>

<p>But here’s the problem: <em>it’s a bad assumption</em>. The fact that it’s the default
represents an <strong>unmitigated</strong> security, reliability, and reproducibility <em>disaster</em>.</p>

<h2 id="a-little-thought-problem">A little thought problem</h2>

<p>Imagine, for a moment, that you’re a maintainer of a popular project.</p>

<p>Everything has gone right for you: you have happy users, an active development base, and maybe even
corporate sponsors. You’ve also got a CI/CD pipeline that produces canonical releases of your
project on tested architectures; you treat any issues with uses of those releases as a bug in the
project itself, since you’ve taken responsibility for packaging it.</p>

<p>Because your project is popular, <strong>others</strong> also distribute it: Linux distributions, third-party
package managers, and corporations seeking to deploy their own controlled builds. These others have
slightly different needs and setups and, to varying degrees, will:</p>

<ul>
  <li>Build your project with slightly (or completely) different versions of dependencies</li>
  <li>Build your project with slightly (or completely) different optimization flags and other potentially
ABI-breaking options</li>
  <li>Distribute your project with insecure or outright broken defaults</li>
  <li>Disable important security features because other parts of their ecosystem haven’t caught up</li>
  <li>Patch your project or its build to make it “work” (read: compile and not crash immediately) with
completely new dependencies, compilers, toolchains, architectures, and environmental constraints</li>
</ul>

<p>You don’t know about <em>any</em> of the above until the bug reports start rolling in: users will report
bugs that have already been fixed, bugs that you explicitly document as caused by unsupported
configurations, bugs that <em>don’t make any sense whatsoever</em>.</p>

<p>You struggle to debug your users’ reports, since you don’t have access to the niche
hardware, environments, or corporate systems that they’re running on. You slowly burn out
under an unending deluge of already fixed bugs that never seem to make it to your users. Your
user base is unhappy, and you start to wonder why you’re putting all this effort into
project maintenance in the first place. Open source was supposed to be fun!</p>

<p>What’s the point of this spiel? It’s <em>precisely</em> what happened to <code>pyca/cryptography</code>:
nobody asked them whether it was a good idea to try to run their code on
<a href="https://en.wikipedia.org/wiki/PA-RISC">HPPA</a>, much less
<a href="https://en.wikipedia.org/wiki/IBM_System/390">System/390</a><sup id="fnref:s390" role="doc-noteref"><a href="#fn:s390" rel="footnote">6</a></sup>; some packagers just went ahead
and did it, and are frustrated that it no longer works. People just <em>assumed</em> that it
would, because there is <em>still</em> a norm that everything flows from C, and that any
host with a halfway-functional C compiler should have the entire open source ecosystem
at its disposal.</p>

<h3 id="reflections-on-trusting-random-platforms">Reflections on trusting random platforms<sup id="fnref:rott" role="doc-noteref"><a href="#fn:rott" rel="footnote">7</a></sup></h3>

<p>Security-sensitive software<sup id="fnref:security" role="doc-noteref"><a href="#fn:security" rel="footnote">8</a></sup><sup>,</sup><sup id="fnref:reliability" role="doc-noteref"><a href="#fn:reliability" rel="footnote">9</a></sup>, <em>particularly</em> software written
in unsafe languages, is <strong>never</strong> secure in its own right.</p>

<p>The security of a program is a function of its own design and testing,
<em>as well as</em> the design, testing, and basic correctness of its underlying platform: everything from
the userspace, to the kernel, to the compilers themselves. The latter
is an <strong>unsolved problem</strong> in the <em>very best of cases</em>: bugs are <em>regularly</em>
found in even the most mature compilers (Clang, GCC) and their most mature backends (x86, ARM). Tiny
changes to or differences in build systems can have profound effects at the binary level, like
<a href="https://insights.sei.cmu.edu/cert/2018/08/when-aslr-is-not-really-aslr---the-case-of-incorrect-assumptions-and-bad-defaults.html">accidentally removing security mitigations</a>.
Seemingly innocuous patches can make otherwise safe code
<a href="https://wiki.gentoo.org/wiki/Hardened/GNU_stack_quickstart">exploitable</a> in the context of
other vulnerabilities.</p>

<p>The problem gets worse as we move towards niche architectures and targets that are used
primarily by small hobbyist communities.
Consider <a href="https://en.wikipedia.org/wiki/Motorola_68000_series">m68k</a>
(one of the other architectures affected by <code>pyca/cryptography</code>’s move to Rust): even
GCC <a href="https://gcc.gnu.org/legacy-ml/gcc-patches/2019-10/msg02044.html">was considering</a> removing
support due to lack of maintenance, until hobbyists stepped in. That isn’t to say that any
<em>particular</em> niche target is full of bugs<sup id="fnref:although" role="doc-noteref"><a href="#fn:although" rel="footnote">10</a></sup>; only to say that it’s a greater likelihood
for niche targets <em>in general</em>. <strong>Nobody</strong> is regularly testing the mountain of userspace
code that implicitly forms an operating contract with arbitrary programs on these platforms.</p>

<p>Project maintainers don’t want to chase down compiler bugs on ISAs or systems that they never
intended to support in the first place, and aren’t receiving any active support feedback about.
They <em>especially</em> don’t want to have vulnerabilities associated
with their projects because of buggy toolchains <em>or</em> tooling inertia when working on security
improvements.</p>

<h3 id="some-more-finger-pointing">Some more finger-pointing</h3>

<p>As someone who <em>likes</em> C: this is all C’s fault. Really.</p>

<p>Beyond language-level unsafety (plenty of people have
<a href="https://fishinabarrel.github.io/">covered that already</a>), C is <em>organizationally</em> unsafe:</p>

<ul>
  <li>
    <p>There’s no standard way to write tests for C.</p>

    <p>Functional and/or unit tests <em>alone</em> would go a long
way in assuring baseline correctness on weird architectures or platforms, but the cognitive
overhead of testing C <em>and</em> getting those tests running ensures that well-tested builds of C
programs will continue to be the exception, rather than the rule.</p>
  </li>
  <li>
    <p>There’s no standard way to build C programs.</p>

    <p><a href="https://blog.yossarian.net/2019/04/23/Make-is-probably-fine">Make is fine</a>, but it’s not standard.
Disturbingly large swathes of critical open source infrastructure are compiled using a hodgepodge
of Make, autogenerated rules from autotools, and the maintainer’s boutique shell scripts. One
consequence of this is that C builds tend to be flexible <em>to a fault</em>: prospective packagers
can inject all sorts of behavior-modifying flags that may not be attested directly
in the compiled binary or other build products. The result: it’s almost impossible to prove that
two separate builds on different machines are the same, which means more maintainer pain.</p>
  </li>
  <li>
    <p>There’s no standard way to distribute C programs.</p>

    <p>Yes, I know that package managers exist. Yes, I know how to statically link. Yes, I know how to
vendor libraries and distribute self-contained program “bundles”. None of these are or amount to
a <em>complete</em> standard, and each introduces additional logistical or security problems.</p>
  </li>
  <li>
    <p>There’s no such thing as truly cross-platform C.</p>

    <p>The C abstract machine, despite looking a lot like a PDP-11, leaks the underlying memory
and ordering semantics of the architecture being targeted. The result is that even seasoned
C programmers regularly rely on architecture-specific assumptions when writing ostensibly
cross-platform code: assumptions about the atomicity of reads and writes, operation ordering,
coherence and visibility in self-modifying code, the safety and performance of unaligned accesses,
and so forth. Each of these, apart from being a potential source of unsafety, are <strong>impossible
to detect</strong> statically in the general case: they are, after all, perfectly correct
(and frequently intended!) on the programmer’s host architecture.</p>
  </li>
</ul>

<p>By contemporary programming language standards, these are conspicuous gaps in functionality:
we’ve long since learned to bake testing, building, distribution, and sound abstract machine
semantics into the standard tooling for languages (and language design itself). But their absence
is <strong>doubly pernicious</strong>: they ensure that C remains a perpetually
unsafe development ecosystem, <em>and</em> an appealing target when bootstrapping a new platform.</p>

<h2 id="the-life-of-a-package-maintainer-is-hard">The life of a package maintainer is hard</h2>

<p>The project maintainer isn’t the only person hurting in the status quo.</p>

<p>Everything stated above <em>also</em> leads to a bum job for the lowly package maintainer<sup id="fnref:yt" role="doc-noteref"><a href="#fn:yt" rel="footnote">11</a></sup>. They’re
(probably) also an unpaid open source hobbyist, and they’re operating with constraints that
the upstream isn’t likely to immediately understand:</p>

<ul>
  <li>The need to link against versions of dependencies that have already been packaged (and perhaps patched)</li>
  <li>ABI and ISA subset constraints, stemming from a need to distribute binaries that function with
relatively old versions of <code>glibc</code> or x86-64 CPUs without modern extensions</li>
  <li>Limited visibility into each project’s test suite and how to run it, much less what to do when
it fails</li>
</ul>

<p>They <em>also</em> have to deal with users who are unsympathetic to those reports, and who:</p>

<ul>
  <li>Rarely submit reports to the packager (they bug the project directly instead!), or don’t follow
up on reports</li>
  <li>Demand fundamentally conflicting properties in their packages: both the latest and greatest
features from the upstream, and <em>also</em> that the packagers never break their deployments
(hence the neverending stream of untested, unofficial patches)</li>
</ul>

<p>All of this leads to package maintainer burnout<sup id="fnref:pmburnout" role="doc-noteref"><a href="#fn:pmburnout" rel="footnote">12</a></sup>, and an (increasingly) adversarial
relationship between projects and their downstream distributors. Neither of those bodes well for
projects, the health of critical packaging ecosystems, or (most importantly of all) the users
themselves.</p>

<h2 id="a-path-forwards">A path forwards?</h2>

<p>I am <del>just barely</del> conceited enough to think that my potential solutions are worth broadcasting
to the world. Here they are.</p>

<h3 id="build-system-and-distribution-transparency">Build system and distribution transparency</h3>

<p>Build systems are a mess; I’ve talked about their complexity in a
<a href="https://blog.trailofbits.com/2020/11/25/high-fidelity-build-instrumentation-with-blight/">professional setting</a>.</p>

<p>A long term solution to the problem of support for platforms not originally considered by
project authors is going to be two-pronged:</p>

<ul>
  <li>
    <p>Builds need to be <em>observable</em> and <em>reviewable</em>: project maintainers should be able to
get the exact invocations and dependencies that a build was conducted with <em>and</em> perform
automatic triaging of build information. This will require environment and ecosystem-wide changes:
object and packaging formats will need to be updated; standards for metadata and sharing information
from an arbitrary distributor to a project will need to be devised. Reasonable privacy concerns
about the scope of information and its availability will need to be addressed.</p>
  </li>
  <li>
    <p>Reporting needs to be better directed: individual (minimally technical!) end users should be
able to figure out <em>what</em> exactly is failing and <em>who</em> to phone when it falls over. That means
<strong>rigorously tracking</strong> the patches that distributors apply (see build observability above)
and creating mechanisms that deliver information to the people who need it. Those same mechanisms
need to have <em>some</em> mechanism for interaction: there’s nothing worse than a flood of automated,
bug reports with insufficient context<sup id="fnref:context" role="doc-noteref"><a href="#fn:context" rel="footnote">13</a></sup>.</p>
  </li>
</ul>

<h3 id="support-tiers">Support tiers</h3>

<p>Rust certainly isn’t the first ecosystem to provide different support tiers, but they
do a <em>great</em> job:</p>

<ul>
  <li>
    <p>Tiers are explicitly enumerated and documented. If you’re in a particular tier bucket, you
know <em>exactly</em> what you’re getting, what’s guaranteed about it, and what you’ll need to do on
your own.</p>
  </li>
  <li>
    <p>Official builds provide transitive guarantees: they can carry patches to the compiler and other
components without needing the entire system to be patched. Carrying patches still isn’t great,
but it currently isn’t avoidable.</p>
  </li>
  <li>
    <p>Tiers are baked into the tooling itself: you can’t use <code>rustup</code> on DEC ALPHA and (incorrectly)
expect to pull down a mature, tested toolchain. You can’t because it would be a lie. This
is in contrast to the C paradigm, where an un(der)-tested compiler will happily be under-checked
by a big blob of
<a href="https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html">autotools</a>
shell, producing a build of indeterminate correctness.</p>
  </li>
  <li>
    <p>Expectations are managed. This point is really just a culmination of the first three: with
explicit tiers, there’s no more implicit guarantee that a minimally functional build toolchain
entails fully functional and supported software. Users can be pointed to a single page that
tells them that they’re doing something that nobody has tried to (or currently wants to) support,
and <strong>expose options</strong> to them: help out, fund the project, nag their employer, &amp;c.</p>
  </li>
</ul>

<h3 id="give-up-on-weird-isas-and-platforms">Give up on weird ISAs and platforms</h3>

<p>I put this one last because it’s flippant, but it’s maybe the most important one:
outside of hobbyists playing with weird architectures for fun (and accepting the overwhelming
likelihood that most projects won’t immediately work for them), <strong>open source groups should
not be unconditionally supporting the ecosystem for a large corporation’s hardware
and/or platforms.</strong></p>

<p>Companies should be paying for this <strong>directly</strong>: if <code>pyca/cryptography</code> <em>actually</em> broke on HPPA
or IA-64, then HP or Intel or <em>whoever</em> should be forking over money to get it fixed <em>or</em>
using their own horde of engineers to fix it themselves. No free work for platforms that only
corporations are using<sup id="fnref:humble" role="doc-noteref"><a href="#fn:humble" rel="footnote">14</a></sup>. No, this doesn’t violate the open-source ethos<sup id="fnref:oss" role="doc-noteref"><a href="#fn:oss" rel="footnote">15</a></sup>; nothing about
OSS says that you have to bend over backwards to support a corporate platform that you didn’t
care about in the first place.</p>

<hr/>




<hr/>


<span>
  Discussions:
  
  <a href="https://www.reddit.com/r/enosuchblog/comments/lujs78/weird_architectures_werent_supported_to_begin_with/">Reddit</a>
  
</span>
<hr/>



  


  





</div>
  </body>
</html>
