<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://modal.com/docs/examples/slack-finetune">Original</a>
    <h1>DoppelBot: Replace Your CEO with an LLM</h1>
    
    <div id="readability-page-1" class="page"><div> <article> <p><em>(quick links:
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot#usage">add to your own Slack</a>;
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot">source code</a>)</em></p> <p>Internally at Modal, we spend a <em data-svelte-h="svelte-r6ouuz">lot</em> of time talking to each other on Slack.
Now, with the advent of open-source large language models, we had started to
wonder if all of this wasn’t a bit redundant. Could we have these language
models bike-shed on Slack for us, so we could spend our time on higher leverage
activities such as
<a rel="nofollow" href="https://twitter.com/modal_labs/status/1642262543757352960">paddleboarding in Tahiti</a>
instead?</p> <p>To test this, we fine-tuned
<a rel="nofollow" href="https://ai.meta.com/blog/meta-llama-3-1/">Llama 3.1</a> on
<a rel="nofollow" href="https://twitter.com/bernhardsson">Erik</a>’s Slack messages, and <code data-svelte-h="svelte-1g3u75n">@erik-bot</code> was
born.</p> <p> <img src="https://modal.com/_app/immutable/assets/erik-bot-1.CjDvIhCc.jpeg" alt="erik-bot"/> </p>   <p data-svelte-h="svelte-1fpttp3">Since then, <code>@erik-bot</code> has been an invaluable asset to us, in areas ranging from <a href="https://modal.com/_app/immutable/assets/erik-bot-2.CDmWvLM4.png">API design</a> to <a href="https://modal.com/_app/immutable/assets/erik-bot-3.C_m8x6a2.png">legal advice</a> to thought leadership.</p> <p> <img src="https://modal.com/_app/immutable/assets/erik-bot-4.CEbrQZVg.png" alt="erik-bot-3"/> </p> <p data-svelte-h="svelte-19925bp">We were planning on releasing the weights for <code>@erik-bot</code> to the world, but all
our metrics have been going up and to the right a little too much since we’ve
launched him…</p> <p>So, we are releasing the next best thing. <code data-svelte-h="svelte-166thr5">DoppelBot</code> is a Slack bot that you
can install in your own workspace, and fine-tune on your own Slack messages.
Follow the instructions <a rel="nofollow" href="https://github.com/modal-labs/doppel-bot#usage">here</a>
to replace your own CEO with an LLM today.</p> <p>All the components—scraping, fine-tuning, inference and slack event handlers run
on Modal, and the code itself is open-source and available
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot">here</a>. If you’re new to Modal, it’s
worth reiterating that <strong data-svelte-h="svelte-1ku0u9a">all of these components are also serverless and scale
to zero</strong>. This means that you can deploy and forget about them, because you’ll
only pay for compute when your app is used!</p> <h2 id="how-it-works" data-svelte-h="svelte-1a1youw">How it works</h2> <p>DoppelBot uses the Slack SDK to scrape messages from a Slack workspace, and
converts them into prompt/response pairs. It uses these to fine-tune a language
model using <a rel="nofollow" href="https://arxiv.org/abs/2106.09685">Low-Rank Adaptation (LoRA)</a>, a
technique that produces a small adapter that can be merged with the base model
when needed, instead of modifying all the parameters in the base model. The
fine-tuned adapters for each user are stored in a Modal
<a href="https://modal.com/docs/guide/volumes">Volume</a>. When a user <code data-svelte-h="svelte-gbsc1q">@</code>s the bot,
Slack sends a webhook call to Modal, which loads the adapter for that user and
generates a response.</p> <p>We go into detail into each of these steps below, and provide commands for
running each of them individually. To follow along,
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot">clone the repo</a> and
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot#create-a-slack-app">set up a Slack token</a>
for yourself.</p> <h3 id="scraping-slack" data-svelte-h="svelte-7zwp6x">Scraping slack</h3>  <p>The scraper uses Modal’s <a href="https://modal.com/docs/guide/scale#scaling-out"><code data-svelte-h="svelte-15xk0yb">.map()</code></a> to fetch
messages from all public channels in parallel. Each thread is split into
contiguous messages from the target users and continguous messages from other
users. These will be fed into the model as prompts in the following format:</p>  <p data-svelte-h="svelte-1gft8ig">Initial versions of the model were prone to generating short responses
— unsurprising, because a majority of Slack communication is pretty terse.
Adding a minimum character length for the target user’s messages fixed this.</p> <p data-svelte-h="svelte-u8ly6e">If you’re following along at home, you can run the scraper with the following
command:</p>  <p>Scraped results are stored in a Modal
<a href="https://modal.com/docs/guide/volumes">Volume</a>, so they can be used by the next step.</p> <h3 id="fine-tuning" data-svelte-h="svelte-1mpeoh0">Fine-tuning</h3>  <p>Next, we use the prompts to fine-tune a language model. We chose
<a rel="nofollow" href="https://ai.meta.com/blog/meta-llama-3-1/">Llama 3.1</a> because of its permissive license and high quality relative to its small size. Fine-tuning is
done using <a rel="nofollow" href="https://arxiv.org/abs/2106.09685">Low-Rank Adaptation (LoRA)</a>, a
<a rel="nofollow" href="https://huggingface.co/blog/peft">parameter-efficient fine-tuning</a> technique
that produces a small adapter that can be merged with the base model when needed
(~60MB for the rank we’re using).</p> <p>Our fine-tuning implementation uses <a rel="nofollow" href="https://github.com/pytorch/torchtune">torchtune</a>, a new PyTorch library for easily configuring fine-tuning runs.</p> <p data-svelte-h="svelte-1pw8e1">Because of the typically small sample sizes we’re working with, training for
longer than a couple hundred steps (with our batch size of 128) quickly led to
overfitting. Admittedly, we haven’t thoroughly evaluated the hyperparameter
space yet — do reach out to us if you’re interested in collaborating on this!</p> <p> <img src="https://modal.com/_app/immutable/assets/train-loss.DFD7oOI8.png" alt="train-loss"/> </p> <p data-svelte-h="svelte-1p21b9i">To try this step yourself, run:</p>  <h3 id="inference" data-svelte-h="svelte-m1ii7y">Inference</h3>  <p>We use <a rel="nofollow" href="https://github.com/vllm-project/vllm">vLLM</a> as our inference engine, which now comes with support for dynamically swapping LoRA adapters <a rel="nofollow" href="https://docs.vllm.ai/en/latest/features/lora.html">out of the box</a>.</p> <p data-svelte-h="svelte-1x43796">With parametrized functions, every user model gets its own pool of containers
that scales up when there are incoming requests, and scales to 0 when there’s
none. Here’s what that looks like stripped down to the essentials:</p>  <p data-svelte-h="svelte-1tzj64k">If you’ve fine-tuned a model already in the previous step, you can run inference
using it now:</p>  <p data-svelte-h="svelte-1ejsiyh">(We have a list of sample inputs in the file, but you can also try it out with
your own messages!)</p> <h3 id="slack-bot" data-svelte-h="svelte-va6bst">Slack Bot</h3>  <p>Finally, it all comes together in
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot/blob/main/src/bot.py"><code data-svelte-h="svelte-195divq">bot.py</code></a>. As
you might have guessed, all events from Slack are handled by serverless Modal
functions. We handle 3 types of events:</p> <ul><li><a rel="nofollow" href="https://github.com/modal-labs/doppel-bot/blob/24609583c43c0e722f56f85a1c00bb55b46c7754/src/bot.py#L112"><code data-svelte-h="svelte-hfc5fx">url_verification</code></a>:
To verify that this is a Slack app, Slack expects us to return a challenge
string.</li> <li><a rel="nofollow" href="https://github.com/modal-labs/doppel-bot/blob/main/src/bot.py#L118"><code data-svelte-h="svelte-14xb794">app_mention</code></a>:
When the bot is mentioned in a channel, we retrieve the recent messages from
that thread, do some basic cleaning and call the user’s model to generate a
response.</li></ul>  <ul><li><a rel="nofollow" href="https://github.com/modal-labs/doppel-bot/blob/main/src/bot.py#L182"><code data-svelte-h="svelte-qklpw8">doppel</code> slash command</a>:
This command kicks off the scraping -&gt; finetuning pipeline for the user.</li></ul> <p data-svelte-h="svelte-ty1iqi">To deploy the slackbot in its entirety, you need to run:</p>  <p data-svelte-h="svelte-17rplom"><h3 id="multi-workspace-support">Multi-Workspace Support</h3></p> <p>Everything we’ve talked about so far is for a single-workspace Slack app. To
make it work with multiple workspaces, we’ll need to handle
<a rel="nofollow" href="https://api.slack.com/authentication/oauth-v2">workspace installation and authentication with OAuth</a>,
and also store some state for each workspace.</p> <p>Luckily, Slack’s <a rel="nofollow" href="https://slack.dev/bolt-python/concepts">Bolt</a> framework
provides a complete (but frugally documented) OAuth implemention. A neat feature
is that the OAuth state can be backed by a file system, so all we need to do is
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot/blob/24609583c43c0e722f56f85a1c00bb55b46c7754/src/bot.py#L78">point Bolt</a>
at a Modal <a href="https://modal.com/docs/guide/volumes">Volume</a>, and then we don’t need to worry about
managing this state ourselves.</p> <p>To store state for each workspace, we’re using <a rel="nofollow" href="https://neon.tech/">Neon</a>, a
serverless Postgres database that’s really easy to set up and <em data-svelte-h="svelte-wgki5y">just works</em>. If
you’re interested in developing a multi-workspace app,
<a rel="nofollow" href="https://github.com/modal-labs/doppel-bot#optional-multi-workspace-app">follow our instructions</a>
on how to set up Neon with Modal.</p> <h2 id="next-steps" data-svelte-h="svelte-1cfb4gb">Next Steps</h2> <p data-svelte-h="svelte-v0847i">If you’ve made it this far, you have just found a way to increase your team’s
productivity by 10x! Congratulations on the well-earned vacation! 🎉</p> <p>If you’re interested in learning more about Modal, check out our <a href="https://modal.com/docs">docs</a>
and other <a href="https://modal.com/examples">examples</a>.</p></article></div></div>
  </body>
</html>
