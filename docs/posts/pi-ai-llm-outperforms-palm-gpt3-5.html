<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://inflection.ai/inflection-1">Original</a>
    <h1>Pi.ai LLM Outperforms Palm/GPT3.5</h1>
    
    <div id="readability-page-1" class="page"><div><div justify="center"><div><div><p>At Inflection, our mission is to create a personal AI for everyone. In May 2023, we released Pi (<a href="https://pi.ai" target="_blank" rel="noopener noreferrer">Pi.ai</a>) – your personal AI, designed to be empathetic, useful, and safe (<a href="https://inflection.ai/press" target="_blank" rel="noopener noreferrer">Pi press release</a>).</p>
<p>We believe that pre-training is as important as finetuning when it comes to creating high quality, safe, and useful AI experiences. That’s why we set out to develop our own state-of-the-art LLMs. As a vertically integrated AI studio, we do everything in-house for AI training and inference: from data ingestion, to model design, to high-performance infrastructure.</p>
<p>To offer our users superb quality and speed, we needed to develop a model that is both scalable in production, as well as more capable than widely deployed LLMs such as GPT-3.5 and LLaMA. We are excited to share that we have now achieved this goal.</p>
<p>Today, we are announcing “<strong>Inflection-1</strong>”, our in-house LLM, which powers <a href="https://heypi.com/talk" target="_blank" rel="noopener noreferrer">Pi.ai</a> and will soon be available via our conversational <a href="https://docs.google.com/forms/d/e/1FAIpQLScM9Iz1KzaRlfgDrYrldoPDnXbhO5LW3-hqmQCd56YpheEN7g/viewform" target="_blank" rel="noopener noreferrer">API</a>.</p>
<p>Inflection-1 was trained using thousands of NVIDIA H100 GPUs on a very large dataset. Our team has been able to take advantage of our end-to-end pipeline to develop a number of proprietary technical advances that have enabled these results. This <a href="https://inflection.ai/assets/Inflection-1_0622.pdf" target="_blank" rel="noopener noreferrer">technical memo</a> summarizes our evaluations and compares our performance against other LLMs.</p>
<p>The memo shows that Inflection-1 is the <strong>best model in its compute class, outperforming GPT-3.5, LLaMA, Chinchilla, and PaLM-540B</strong> on a wide range of benchmarks commonly used for comparing LLMs. We will also be releasing a technical memo detailing one of our models in the same compute class as PaLM-2 and GPT-4.</p>
<p>This is an achievement we are proud of, having started Inflection just over a year ago. We expect dramatic improvements in the coming months as we continue to scale and innovate to deliver on our mission to build the most capable and safe AI products, accessible to millions of users.</p>
<p><strong>Summary Evaluation Results</strong></p>
<p>We evaluated Inflection-1 on a wide range of benchmarks against models in the same compute class, defined as models trained using at most the FLOPs of PaLM-540B. A summary of the  six most popular benchmarks follows. Further details are available in our <a href="https://inflection.ai/assets/Inflection-1_0622.pdf" target="_blank" rel="noopener noreferrer">technical memo</a>.</p></div></div></div></div></div>
  </body>
</html>
