<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Nixtla/statsforecast/blob/main/experiments/neuralprophet/README.md">Original</a>
    <h1>Show HN: Exp. Smoothing is 32% more accurate and 100x faster than Neural-Prophet</h1>
    
    <div id="readability-page-1" class="page"><div>

    <div data-target="readme-toc.content">
      
  


        <div id="readme">
    <article itemprop="text">
<p dir="auto">We benchmarked on more than 55K series and show that <code>ETS</code> improves <em>MAPE</em> and <em>sMAPE</em> forecast accuracy by <em>32%</em> and <em>19%</em>, respectively, with <em>104x</em> less computational time over <a href="https://neuralprophet.com/html/index.html" rel="nofollow"><code>NeuralProphet</code></a>.</p>
<h3 dir="auto"><a id="user-content-install-statsforecast" aria-hidden="true" href="#install-statsforecast"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Install StatsForecast</h3>
<div data-snippet-clipboard-copy-content="pip install statsforecast"><pre>pip install statsforecast</pre></div>
<h2 dir="auto"><a id="user-content-results-on-ercot-ettm2-m3-m4-and-tourism" aria-hidden="true" href="#results-on-ercot-ettm2-m3-m4-and-tourism"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Results on ERCOT, ETTm2, M3, M4, and Tourism:</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://donnywinston.com/Nixtla/statsforecast/blob/main/experiments/neuralprophet/comparison.png"><img src="https://donnywinston.com/Nixtla/statsforecast/raw/main/experiments/neuralprophet/comparison.png" alt="comparison"/></a></p>
<h2 dir="auto"><a id="user-content-background" aria-hidden="true" href="#background"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Background</h2>
<p dir="auto">In this experiment, we test <a href="https://neuralprophet.com/html/index.html" rel="nofollow"><code>NeuralProphet</code></a>&#39;s introduction as a &#34;successor&#34; to Facebook-<code>Prophet</code> and compare it with classic Exponential Smoothing (<code>ETS</code>). We show that it is not the case that <code>ETS</code> has &#34;too restrictive assumptions and parametric nature limit their performance in real-world applications&#34; as claimed by <code>NeuralProphet</code>&#39;s <a href="https://arxiv.org/pdf/2111.15397.pdf" rel="nofollow">paper</a>. Moreover, we show that <code>NeuralProphet</code>&#39;s predictions are outperformed both in accuracy and computation time by this statistical model.</p>
<h2 dir="auto"><a id="user-content-empirical-validation" aria-hidden="true" href="#empirical-validation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Empirical validation</h2>
<p dir="auto">To compare <code>NeuralProphet</code> against <code>ETS</code>, we designed a pipeline considering the M3, M4, and Tourism datasets (standard benchmarks in the forecasting practice). In correspondence with the author he suggested to further test the model in electricity datasets and try including auto regresor and covariates. Therefore we also included the ERCOT dataset (used in the <a href="https://neuralprophet.com/html/lagged_covariates_energy_ercot.html#24-steps-ahead-Neural-Model-with-Long-AR-and-Lagged-Regressors" rel="nofollow"><code>NeuralProphet</code>&#39;s documentation</a>), and ETTm2. <code>NeuralProphet</code> fits the time series globally using autoregressive terms and produces forecasts using a multistep approach.</p>
<h3 dir="auto"><a id="user-content-notes" aria-hidden="true" href="#notes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Notes</h3>
<ul dir="auto">
<li>We used the out-of-the-box configuration of the NeuralProphet model in its global-multistep version, using autoregressive terms based on the seasonality of the data and the forecast horizon. This experiment concludes that hyperparameter optimization could be highly costly, particularly for big datasets.</li>
<li>For the ERCOT dataset, we used the <code>NeuralProphet</code> <a href="https://neuralprophet.com/html/lagged_covariates_energy_ercot.html#24-steps-ahead-Neural-Model-with-Long-AR-and-Lagged-Regressors" rel="nofollow">configuration used in its documentation</a>.</li>
<li>Additionally, we test the performance of <code>NeuralProphet</code> using different learning rates (1e-5, 1e-4, 1e-3, 1e-2, 1e-1). The performance is similar.</li>
<li>During the execution of the experiment, we found issues with the <code>NeuralProphet</code> implementation related to Monthly, Quarterly, and Yearly frequencies. We <a href="https://github.com/ourownstory/neural_prophet/pull/705" data-hovercard-type="pull_request" data-hovercard-url="/ourownstory/neural_prophet/pull/705/hovercard">fixed the issue and opened a Pull Request to solve the problem</a>.</li>
<li>According to the paper and a <a href="https://github.com/ourownstory/neural_prophet/discussions/408" data-hovercard-type="discussion" data-hovercard-url="/ourownstory/neural_prophet/discussions/408/hovercard">discussion on GitHub</a>, the <code>NeuralProphet</code> implementation is not available in GPU. There is a <a href="https://github.com/ourownstory/neural_prophet/pull/420" data-hovercard-type="pull_request" data-hovercard-url="/ourownstory/neural_prophet/pull/420/hovercard">work-in-progress Pull Request</a>, though.</li>
<li>We also performed experiments for the M4-Monthly data set, but <code>NeuralProphet</code> did not finish after three days of computation. <code>ETS</code> results are reported.</li>
</ul>
<h2 dir="auto"><a id="user-content-results" aria-hidden="true" href="#results"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Results</h2>
<p dir="auto">The following table shows the <em>MAPE</em>, <em>sMAPE</em>, and <em>Time</em> (in minutes) <code>ETS</code> improvements over <code>NeuralProphet</code> for each dataset.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://donnywinston.com/Nixtla/statsforecast/blob/main/experiments/neuralprophet/results-table.png"><img src="https://donnywinston.com/Nixtla/statsforecast/raw/main/experiments/neuralprophet/results-table.png" alt="table"/></a></p>
<h2 dir="auto"><a id="user-content-reproducibility" aria-hidden="true" href="#reproducibility"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Reproducibility</h2>
<ol dir="auto">
<li>Create a conda environment <code>exp_neuralprophet</code> using the <code>environment.yml</code> file.</li>
</ol>
<div data-snippet-clipboard-copy-content="conda env create -f environment.yml"><pre>conda env create -f environment.yml</pre></div>
<ol start="3" dir="auto">
<li>Activate the conda environment using</li>
</ol>
<div data-snippet-clipboard-copy-content="conda activate exp_neuralprophet"><pre>conda activate exp_neuralprophet</pre></div>
<ol start="4" dir="auto">
<li>Run the experiments for each dataset and each model using</li>
</ol>
<div data-snippet-clipboard-copy-content="python -m src.[model] --dataset [dataset] --group [group]"><pre>python -m src.[model] --dataset [dataset] --group [group]</pre></div>
<p dir="auto">The variable <code>model</code> can be <code>statsforecast</code> (<code>ETS</code> model) or <code>neuralprophet</code>. For <code>M4</code>, the groups are <code>Yearly</code>, <code>Quarterly</code>, <code>Weekly</code>, <code>Daily</code>, and <code>Hourly</code>. For <code>M3</code>, the groups are <code>Yearly</code>, <code>Monthly</code>, <code>Quarterly</code>, and <code>Other</code>. For <code>Tourism</code>, the groups are <code>Yearly</code>, <code>Monthly</code>, and <code>Quarterly</code>. To run <code>ETTm2</code> use <code>LongHorizon</code> as dataset and <code>ETTm2</code> as group. To run <code>ERCOT</code> use <code>ERCOT</code> as dataset and <code>Other</code> as group.</p>
<ol start="5" dir="auto">
<li>Evaluate the results using</li>
</ol>

<h2 dir="auto"><a id="user-content-conclusion" aria-hidden="true" href="#conclusion"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conclusion</h2>
<ul dir="auto">
<li>Always use strong baselines when forecasting.</li>
<li>Quick and easy results are sometimes <a href="https://en.wikipedia.org/wiki/Streetlight_effect" rel="nofollow">misleading</a>.</li>
<li>Simpler models are sometimes <a href="https://en.wikipedia.org/wiki/Occam%27s_razor" rel="nofollow">better</a>.</li>
<li>Both Prophet and NeuralProphet are definitely <strong>not</strong> models for Forecasting at Scale.</li>
<li>We find the claim that <strong>&#34;NeuralProphet bridges the gap between traditional time-series models and deep learning methods.&#34;</strong> simply to be false, given that this model does not outperform classical statistical methods neither in accuracy nor speed.</li>
</ul>
<h2 dir="auto"><a id="user-content-misc" aria-hidden="true" href="#misc"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Misc.</h2>
<ul dir="auto">
<li><a href="https://github.com/nixtla/statsforecast"><code>StatsForecast</code></a> also includes a variety of lightning fast baseline models.</li>
<li>If you really need to do forecast at scale, <a href="https://github.com/nixtla/statsforecast/tree/main/experiments/ray">here</a> we show how to forecast 1 million time series under 30 minutes using <a href="https://github.com/ray-project/ray">Ray</a>.</li>
<li>If you are interested in SOTA Deep Learning models, check <a href="https://github.com/nixtla/neuralforecast"><code>NeuralForecast</code></a></li>
</ul>
</article>
  </div>

    </div>

  </div></div>
  </body>
</html>
