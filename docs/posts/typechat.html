<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://microsoft.github.io/TypeChat/blog/introducing-typechat/">Original</a>
    <h1>TypeChat</h1>
    
    <div id="readability-page-1" class="page"><article>

<p><em>July 20, 2023 by Anders Hejlsberg, Steve Lucco, Daniel Rosenwasser, Pierce Boggan, Umesh Madan, Mike Hopcroft, and Gayathri Chandrasekaran</em></p>
<p>In the last few months, we&#39;ve seen a rush of excitement around the newest wave of large language models.
While chat assistants have been the most direct application, there&#39;s a big question around how to best integrate these models into existing app interfaces.</p>
<p>In other words, how do we <em>augment</em> traditional UI with natural language interfaces?
How do we use AI to take a user request and turn it into something our apps can operate on?
And how do we make sure our apps are safe, and doing work that developers and users alike can trust?</p>
<p>Today we&#39;re releasing <strong>TypeChat</strong>, an experimental library that aims to answer these questions.
It uses the type definitions in your codebase to retrieve structured AI responses that are type-safe.</p>
<p>You can get up and running with TypeChat today by running</p>
<pre tabindex="0"><code><span><span>npm install typechat</span></span>
<span><span></span></span></code></pre>
<p>and hooking it up with any language model to work with your app.</p>
<p>But let&#39;s first quickly explore why TypeChat exists.</p>
<h2>Pampering and Parsing</h2>
<p>The current wave of LLMs default to conversational <em>natural</em> language — languages that humans communicate in like English.
Parsing natural language is an extremely difficult task, no matter how much you pamper a prompt with rules like &#34;respond in the form a bulleted list&#34;.
Natural language might have structure, but it&#39;s hard for typical software to reconstruct it from raw text.</p>
<p>Surprisingly, we can ask LLMs to respond in the form of JSON, and they generally respond with something sensible!</p>
<blockquote>
<p><strong>User:</strong></p>
<p>Translate the following request into JSON.</p>
<blockquote>
<p>Could I get a blueberry muffin and a grande latte?</p>
</blockquote>
<p>Respond only in JSON like the following:</p>
<pre tabindex="0"><code><span><span>{</span></span>
<span><span>    </span><span>&#34;items&#34;</span><span>: [</span></span>
<span><span>        { </span><span>&#34;name&#34;</span><span>: </span><span>&#34;croissant&#34;</span><span>, </span><span>&#34;quantity&#34;</span><span>: </span><span>2</span><span>  },</span></span>
<span><span>        { </span><span>&#34;name&#34;</span><span>: </span><span>&#34;latte&#34;</span><span>, </span><span>&#34;quantity&#34;</span><span>: </span><span>1</span><span>, </span><span>&#34;size&#34;</span><span>: </span><span>&#34;tall&#34;</span><span> }</span></span>
<span><span>    ]</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p><strong>ChatBot:</strong></p>
<pre tabindex="0"><code><span><span>{</span></span>
<span><span>    </span><span>&#34;items&#34;</span><span>: [</span></span>
<span><span>        {</span></span>
<span><span>            </span><span>&#34;name&#34;</span><span>: </span><span>&#34;blueberry muffin&#34;</span><span>,</span></span>
<span><span>            </span><span>&#34;quantity&#34;</span><span>: </span><span>1</span></span>
<span><span>        },</span></span>
<span><span>        {</span></span>
<span><span>            </span><span>&#34;name&#34;</span><span>: </span><span>&#34;latte&#34;</span><span>,</span></span>
<span><span>            </span><span>&#34;quantity&#34;</span><span>: </span><span>1</span><span>,</span></span>
<span><span>            </span><span>&#34;size&#34;</span><span>: </span><span>&#34;grande&#34;</span></span>
<span><span>        }</span></span>
<span><span>    ]</span></span>
<span><span>}</span></span>
<span></span></code></pre>
</blockquote>
<p>This is good — though this example shows the best-case response.
While examples can help guide structure, they don&#39;t define what an AI should return extensively, and they don&#39;t provide anything we can validate against.</p>
<h2>Just Add Types!</h2>
<p>Luckily <strong>types</strong> do precisely that.
What we&#39;ve found is that because LLMs have seen so many type definitions in the wild, types also act as a great guide for how an AI should respond.
Because we&#39;re typically working with JSON — <em>JavaScript</em> Object Notation — and because it&#39;s is very near and dear to our hearts, we&#39;ve been using TypeScript types in our prompts.</p>
<blockquote>
<p><strong>User:</strong></p>
<p>Translate the following request into JSON.</p>
<blockquote>
<p>Could I get a blueberry muffin and a grande latte?</p>
</blockquote>
<p>Respond only in JSON that satisfies the <code>Response</code> type:</p>
<pre tabindex="0"><code><span><span>type</span><span> </span><span>Response</span><span> = {</span></span>
<span><span>    </span><span>items</span><span>: </span><span>Item</span><span>[];</span></span>
<span><span>};</span></span>
<span></span>
<span><span>type</span><span> </span><span>Item</span><span> = {</span></span>
<span><span>    </span><span>name</span><span>: </span><span>string</span><span>;</span></span>
<span><span>    </span><span>quantity</span><span>: </span><span>number</span><span>;</span></span>
<span><span>    </span><span>size</span><span>?: </span><span>string</span><span>;</span></span>
<span><span>    </span><span>notes</span><span>?: </span><span>string</span><span>;</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p><strong>ChatBot:</strong></p>
<pre tabindex="0"><code><span><span>{</span></span>
<span><span>  </span><span>&#34;items&#34;</span><span>: [</span></span>
<span><span>    {</span></span>
<span><span>      </span><span>&#34;name&#34;</span><span>: </span><span>&#34;blueberry muffin&#34;</span><span>,</span></span>
<span><span>      </span><span>&#34;quantity&#34;</span><span>: </span><span>1</span></span>
<span><span>    },</span></span>
<span><span>    {</span></span>
<span><span>      </span><span>&#34;name&#34;</span><span>: </span><span>&#34;latte&#34;</span><span>,</span></span>
<span><span>      </span><span>&#34;quantity&#34;</span><span>: </span><span>1</span><span>,</span></span>
<span><span>      </span><span>&#34;size&#34;</span><span>: </span><span>&#34;grande&#34;</span></span>
<span><span>    }</span></span>
<span><span>  ]</span></span>
<span><span>}</span></span>
<span></span></code></pre>
</blockquote>
<p>This is pretty great!
TypeScript has shown that it&#39;s well-suited to precisely describe JSON.
But what happens when a language model stumbles and makes up a response that doesn&#39;t conform to our types?</p>
<p>Well because these types are valid TypeScript code, we can validate the response against them using the TypeScript compiler itself!
In fact, the error feedback from the compiler can even be used to guide repairs.
When put together, we can get a robust process for getting well-typed responses that our apps can further massage, validate with a user, etc.</p>
<p>In other words, <strong>types are all you need</strong>.</p>
<h2>Enter TypeChat</h2>
<p>The technique of combining a human prompt and a &#34;response schema&#34; is not necessarily unique — but it is promising.
And as we&#39;ve focused on translating user intent to structured data, we&#39;ve found that TypeScript is very well-suited for the task.
We&#39;ve grown more confident with this approach, and in order to prove it out, we&#39;re releasing a library called TypeChat to help make it easier to use in your apps.
<a href="https://npmjs.com/package/typechat">TypeChat is already on npm</a> if you want to try it now, and provides tools for prompt prototyping, schema validation, repair, and more.</p>
<p>Here&#39;s the basic code to hook TypeChat up to an LLM and decide if a sentence is negative, neutral, or positive.</p>
<pre tabindex="0"><code><span><span>// ./src/sentimentSchema.ts</span></span>
<span></span>
<span><span>// The following is a schema definition for determining the sentiment of a some user input.</span></span>
<span></span>
<span><span>export</span><span> </span><span>interface</span><span> </span><span>SentimentResponse</span><span> {</span></span>
<span><span>    </span><span>/** The sentiment of the text. */</span></span>
<span><span>    </span><span>sentiment</span><span>: </span><span>&#34;negative&#34;</span><span> | </span><span>&#34;neutral&#34;</span><span> | </span><span>&#34;positive&#34;</span><span>;</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<pre tabindex="0"><code><span><span>// ./src/main.ts</span></span>
<span></span>
<span><span>import</span><span> </span><span>*</span><span> </span><span>as</span><span> </span><span>fs</span><span> </span><span>from</span><span> </span><span>&#34;fs&#34;</span><span>;</span></span>
<span><span>import</span><span> </span><span>*</span><span> </span><span>as</span><span> </span><span>path</span><span> </span><span>from</span><span> </span><span>&#34;path&#34;</span><span>;</span></span>
<span><span>import</span><span> </span><span>dotenv</span><span> </span><span>from</span><span> </span><span>&#34;dotenv&#34;</span><span>;</span></span>
<span><span>import</span><span> </span><span>*</span><span> </span><span>as</span><span> </span><span>typechat</span><span> </span><span>from</span><span> </span><span>&#34;typechat&#34;</span><span>;</span></span>
<span><span>import</span><span> { </span><span>SentimentResponse</span><span> } </span><span>from</span><span> </span><span>&#34;./sentimentSchema&#34;</span><span>;</span></span>
<span></span>
<span><span>// Load environment variables.</span></span>
<span><span>dotenv</span><span>.</span><span>config</span><span>({ </span><span>path:</span><span> </span><span>path</span><span>.</span><span>join</span><span>(</span><span>__dirname</span><span>, </span><span>&#34;../.env&#34;</span><span>) });</span></span>
<span></span>
<span><span>// Create a language model based on the environment variables.</span></span>
<span><span>const</span><span> </span><span>model</span><span> = </span><span>typechat</span><span>.</span><span>createLanguageModel</span><span>(</span><span>process</span><span>.</span><span>env</span><span>);</span></span>
<span></span>
<span><span>// Load up the contents of our &#34;Response&#34; schema.</span></span>
<span><span>const</span><span> </span><span>schema</span><span> = </span><span>fs</span><span>.</span><span>readFileSync</span><span>(</span><span>path</span><span>.</span><span>join</span><span>(</span><span>__dirname</span><span>, </span><span>&#34;sentimentSchema.ts&#34;</span><span>), </span><span>&#34;utf8&#34;</span><span>);</span></span>
<span><span>const</span><span> </span><span>translator</span><span> = </span><span>typechat</span><span>.</span><span>createJsonTranslator</span><span>&lt;</span><span>SentimentResponse</span><span>&gt;(</span><span>model</span><span>, </span><span>schema</span><span>, </span><span>&#34;SentimentResponse&#34;</span><span>);</span></span>
<span></span>
<span><span>// Process requests interactively.</span></span>
<span><span>typechat</span><span>.</span><span>processRequests</span><span>(</span><span>&#34;😀&gt; &#34;</span><span>, </span><span>/*inputFile*/</span><span> </span><span>undefined</span><span>, </span><span>async</span><span> (</span><span>request</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>    </span><span>const</span><span> </span><span>response</span><span> = </span><span>await</span><span> </span><span>translator</span><span>.</span><span>translate</span><span>(</span><span>request</span><span>);</span></span>
<span><span>    </span><span>if</span><span> (!</span><span>response</span><span>.</span><span>success</span><span>) {</span></span>
<span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>response</span><span>.</span><span>message</span><span>);</span></span>
<span><span>        </span><span>return</span><span>;</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>`The sentiment is </span><span>${</span><span>response</span><span>.</span><span>data</span><span>.</span><span>sentiment</span><span>}</span><span>`</span><span>);</span></span>
<span><span>});</span></span>
<span></span></code></pre>
<p>TypeChat can be used in a number of different ways.
The way we&#39;ve discussed here so far is all about using a &#34;data schema&#34; to turn some user intent into a structured response;
however, TypeChat also makes it possible to use an &#34;API schema&#34; to construct basic programs.
We have some <a href="https://microsoft.github.io/TypeChat/docs/">docs</a> and <a href="https://microsoft.github.io/TypeChat/docs/examples/">examples</a> to get a sense of the different ways you can use TypeChat.</p>
<h2>Open and Pluggable</h2>
<p>First of all, TypeChat is open-source.
We&#39;re MIT-licensed and you can <a href="https://github.com/Microsoft/TypeChat">find us on GitHub</a> where we&#39;re eager to hear your thoughts, share our ideas, and build with you.</p>
<p>Second, TypeChat is built in a way that is meant to be model-neutral.
While we have some very basic integration with the OpenAI API and the Azure OpenAI service for convenience, this approach should work for any chat completion-style API that you want to use — though note that at the moment, TypeChat works best with models that have been trained on both prose and code.</p>
<h2>Try It Today!</h2>
<p>We&#39;d love to know if TypeChat is something that&#39;s useful and interests you!
As we mentioned, we&#39;ll be welcoming you on <a href="https://github.com/Microsoft/TypeChat">GitHub</a> if you have any question, suggestions, and more.</p>
<p>Happy Hacking!</p>

</article></div>
  </body>
</html>
