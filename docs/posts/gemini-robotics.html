<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/">Original</a>
    <h1>Gemini Robotics</h1>
    
    <div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    
      

      
      
        
          
            <div>
              
                
                
                  
                  
<div>
    <div>
      <p>Research</p>
      

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2025-03-12">12 March 2025</time></dd>
      
      
        <dt>Authors</dt>
        <dd><p data-block-key="u3urr">Carolina Parada</p></dd>
      
    </dl>
  

      <div>
        
        <section data-glue-expansion-panel-expand-tooltip="Share: Expand to see social channels" data-glue-expansion-panel-collapse-tooltip="Share: Hide social channels" id="share-0a158152-e138-4285-a5b8-f9186f0e8f7e">
    <div>
      <h2>
        
        Share
      </h2>

      <ul role="list">
        <li>
          <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" title="Share on Facebook" target="_blank" rel="noopener">
            <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#post-facebook"></use>
  </svg>
          </a>
        </li>
        <li>
          <a href="https://x.com/intent/tweet?text=https%3A//deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" title="Share on X" target="_blank" rel="noopener">
            <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#x"></use>
  </svg>
          </a>
        </li>
        <li>
          <a href="https://www.linkedin.com/shareArticle?url=https%3A//deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/&amp;mini=true" title="Share on LinkedIn" target="_blank" rel="noopener">
            <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#post-linkedin"></use>
  </svg>
          </a>
        </li>
        <li>
          <a href="mailto:?subject=Gemini%20Robotics%20brings%20AI%20into%20the%20physical%20world&amp;body=https%3A//deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" title="Share via Email" target="_blank" rel="noopener">
            
          </a>
        </li>
        <li>
          <div>
            

            
          </div>
        </li>
      </ul>
    </div>
  </section>
      </div>
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w2144-h1206-n-nu-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w1856-h1044-n-nu-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w1056-h594-n-nu-rw 2x"/>
      <img alt="Hands from the Robot’s POV. A pair of robotic hands move tiles into the word ‘world’ under the text ‘Gemini for the Physical’." height="603" src="https://lh3.googleusercontent.com/I3LyOcpijrKfJ90UteiAN9ny73Ly-eNb2l3vsC6fOtl3UQKKufCzgeZMh26--7nV36oTUOk9B7B4FIhCKrVYAksGW2DVcviQoWL5BmErDNsIMiX7AQ=w1072-h603-n-nu" width="1072"/>
    </picture>
    
  
    
  </div>
                
              
                
                
                  
                  <div>
  <p data-block-key="q2c97">Introducing Gemini Robotics, our Gemini 2.0-based model designed for robotics</p><p data-block-key="3djrg">At Google DeepMind, we&#39;ve been making progress in how our Gemini models solve complex problems through multimodal reasoning across text, images, audio and video. So far however, those abilities have been largely confined to the digital realm. In order for AI to be useful and helpful to people in the physical realm, they have to demonstrate “embodied” reasoning — the humanlike ability to comprehend and react to the world around us— as well as safely take action to get things done.</p><p data-block-key="73qu7">Today, we are introducing two new AI models, based on Gemini 2.0, which lay the foundation for a new generation of helpful robots.</p><p data-block-key="4he0s">The first is Gemini Robotics, an advanced vision-language-action (VLA) model that was built on Gemini 2.0 with the addition of physical actions as a new output modality for the purpose of directly controlling robots. The second is Gemini Robotics-ER, a Gemini model with advanced spatial understanding, enabling roboticists to run their own programs using Gemini’s embodied reasoning (ER) abilities.</p><p data-block-key="dtsn7">Both of these models enable a variety of robots to perform a wider range of real-world tasks than ever before. As part of our efforts, we’re partnering with Apptronik to build the next generation of humanoid robots with Gemini 2.0. We’re also working with a selected number of trusted testers to guide the future of Gemini Robotics-ER.</p><p data-block-key="im3d">We look forward to exploring our models’ capabilities and continuing to develop them on the path to real-world applications.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-c0fc8135-59e8-4260-bd69-d04865397c8d">
  <div><gdm-youtube>
    <div>
     
        
    
    
    <picture aria-hidden="true">
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w1070-rw 1x, https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w928-rw 1x, https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w1856-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w528-rw 1x, https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w1056-rw 2x"/>
      <img alt="" height="601" role="presentation" src="https://lh3.googleusercontent.com/zo-SCEFuW2ioZP9wEgwEnm4zi3OhDS8F94U3Ve_4_3S_SLk7YxnMamFphbkUmqjaHUPG1joanng9RIswfARavtYNzyMH6PSU6Qx-KVXJGSY2YpMjtA=w1070" width="1070"/>
    </picture>
    
  
      
      <div>
        <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#video-youtube"></use>
  </svg>
        <p>Watch &#34;Gemini Robotics: Bringing AI to the physical world&#34;</p>
      </div>
    </div>
    
  </gdm-youtube></div>

  <figcaption>
      <p data-block-key="xzn4c">A summary of our efforts</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="2q7pg">Gemini Robotics: Our most advanced vision-language-action model</h2><p data-block-key="3d8qf">To be useful and helpful to people, AI models for robotics need three principal qualities: they have to be general, meaning they’re able to adapt to different situations; they have to be interactive, meaning they can understand and respond quickly to instructions or changes in their environment; and they have to be dexterous, meaning they can do the kinds of things people generally can do with their hands and fingers, like carefully manipulate objects.</p><p data-block-key="5bthq">While our previous work demonstrated progress in these areas, Gemini Robotics represents a substantial step in performance on all three axes, getting us closer to truly general purpose robots.</p><p data-block-key="2bhs2"><strong>Generality</strong></p><p data-block-key="at04h">Gemini Robotics leverages Gemini&#39;s world understanding to generalize to novel situations and solve a wide variety of tasks out of the box, including tasks it has never seen before in training. Gemini Robotics is also adept at dealing with new objects, diverse instructions, and new environments. In <a href="https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf" rel="noopener" target="_blank">our tech report</a>, we show that on average, Gemini Robotics more than doubles performance on a comprehensive generalization benchmark compared to other state-of-the-art vision-language-action models.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-f629fa4d-725a-4e13-b06f-958a3b6ff6f3">
  <div><gdm-youtube>
    <div>
     
        
    
    
    <picture aria-hidden="true">
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w1070-rw 1x, https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w928-rw 1x, https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w1856-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w528-rw 1x, https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w1056-rw 2x"/>
      <img alt="" height="601" loading="lazy" role="presentation" src="https://lh3.googleusercontent.com/45LKQcA5YAcMnyYGHmvPj-28mnpCo2GFr-wwNuMFtbKjvJToNTcwva7R7tMiJ0HfR4SO4XzwTJY7AZQD_CE3_js6aqAMyqGvgsW5qKxxBCYuXBEK4Q=w1070" width="1070"/>
    </picture>
    
  
      
      <div>
        <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#video-youtube"></use>
  </svg>
        <p>Watch &#34;Gemini Robotics: General&#34;</p>
      </div>
    </div>
    
  </gdm-youtube></div>

  <figcaption>
      <p data-block-key="t82k8">A demonstration of Gemini Robotics’s world understanding.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="2q7pg"><strong>Interactivity</strong></p><p data-block-key="5merb">To operate in our dynamic, physical world, robots must be able to seamlessly interact with people and their surrounding environment, and adapt to changes on the fly.</p><p data-block-key="lvkr">Because it’s built on a foundation of Gemini 2.0, Gemini Robotics is intuitively interactive. It taps into Gemini’s advanced language understanding capabilities and can understand and respond to commands phrased in everyday, conversational language and in different languages.</p><p data-block-key="eo201">It can understand and respond to a much broader set of natural language instructions than our previous models, adapting its behavior to your input. It also continuously monitors its surroundings, detects changes to its environment or instructions, and adjusts its actions accordingly. This kind of control, or “steerability,” can better help people collaborate with robot assistants in a range of settings, from home to the workplace.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-47d85e98-c673-4ad9-a46e-da921cb43b9b">
  <div><gdm-youtube>
    <div>
     
        
    
    
    <picture aria-hidden="true">
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w1070-rw 1x, https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w928-rw 1x, https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w1856-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w528-rw 1x, https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w1056-rw 2x"/>
      <img alt="" height="601" loading="lazy" role="presentation" src="https://lh3.googleusercontent.com/Ol9zZz6cyuRAD_K2d-rS8FUFnxFl49pe8BXh1Tmu974n-ohlTNLLeVb0INZwnAyBAzt6-w-odpt80jYt3XqGd_iMyTmrDU5BdpEFgbUpy1naDdY8_5Q=w1070" width="1070"/>
    </picture>
    
  
      
      <div>
        <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#video-youtube"></use>
  </svg>
        <p>Watch &#34;Gemini Robotics: Interactive&#34;</p>
      </div>
    </div>
    
  </gdm-youtube></div>

  <figcaption>
      <p data-block-key="a6zg7">If an object slips from its grasp, or someone moves an item around, Gemini Robotics quickly replans and carries on — a crucial ability for robots in the real world, where surprises are the norm.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="2q7pg"><strong>Dexterity</strong></p><p data-block-key="ev4ji">The third key pillar for building a helpful robot is acting with <a href="https://deepmind.google/discover/blog/advances-in-robot-dexterity/" rel="noopener" target="_blank">dexterity</a>. Many everyday tasks that humans perform effortlessly require surprisingly fine motor skills and are still too difficult for robots. By contrast, Gemini Robotics can tackle extremely complex, multi-step tasks that require precise manipulation such as origami folding or packing a snack into a Ziploc bag.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-b9331385-f6f6-44b8-9a78-12992940d893">
  <div><gdm-youtube>
    <div>
     
        
    
    
    <picture aria-hidden="true">
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w1070-rw 1x, https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w928-rw 1x, https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w1856-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w528-rw 1x, https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w1056-rw 2x"/>
      <img alt="" height="601" loading="lazy" role="presentation" src="https://lh3.googleusercontent.com/aCLLuYMMvEK6Q5AmlMpgnVt8YStv_y7TltTj1OZO2z4_s3WPMGTM7AyF39FXPEln5ptvEvBOgzT94Va2HADYp03zDjRy2RL3XLGtdjkyZfTKZJ_-Sw=w1070" width="1070"/>
    </picture>
    
  
      
      <div>
        <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#video-youtube"></use>
  </svg>
        <p>Watch &#34;Gemini Robotics: Dexterous&#34;</p>
      </div>
    </div>
    
  </gdm-youtube></div>

  <figcaption>
      <p data-block-key="ex5b9">Gemini Robotics displays advanced levels of dexterity</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="2q7pg"><strong>Multiple embodiments</strong></p><p data-block-key="2co1s">Finally, because robots come in all shapes and sizes, Gemini Robotics was also designed to easily adapt to different robot types. We trained the model primarily on data from the bi-arm robotic platform, <a href="https://aloha-2.github.io/" rel="noopener" target="_blank">ALOHA 2</a>, but we also demonstrated that it could control a bi-arm platform, based on the Franka arms used in many academic labs. Gemini Robotics can even be specialized for more complex embodiments, such as the humanoid Apollo robot developed by Apptronik, with the goal of completing real world tasks.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-7373c1b3-efa4-4519-8053-d36df232fd8f">
  <div><gdm-video-embed data-autoplay="true">
    
    
    <picture aria-hidden="true">
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w1070-rw 1x, https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w928-rw 1x, https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w1856-rw 2x"/><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w528-rw 1x, https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w1056-rw 2x"/>
      <img alt="" height="601" loading="lazy" role="presentation" src="https://lh3.googleusercontent.com/ePXalcBMYj6deL_wmUJ0SHNggyHsGcwAXO2-m7B86cPkXpNfq8QFMqzcb3qICqPWE72GCyQNB2U6wY1cfLELcnMkXqa2B31Lg0UwDI-VnCVzGvrRwQ=w1070" width="1070"/>
    </picture>
    
  
        <template>
          <video muted="" playsinline="" loop="" width="16" height="9"><source src="/api/blob/website/media/Gemini_Robotics_-_cross-embodiment_2.mp4" type="video/mp4"/>
  </video>
        </template></gdm-video-embed></div>

  <figcaption>
      <p data-block-key="xnqp1">Gemini Robotics works on different kinds of robots</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="2q7pg">Enhancing Gemini’s world understanding</h2><p data-block-key="6k4gb">Gemini Robotics-ER improves Gemini 2.0’s existing abilities like pointing and 3D detection by a large margin. Combining spatial reasoning and Gemini’s coding abilities, Gemini Robotics-ER can instantiate entirely new capabilities on the fly. For example, when shown a coffee mug, the model can intuit an appropriate two-finger grasp for picking it up by the handle and a safe trajectory for approaching it.</p><p data-block-key="1lam2">Gemini Robotics-ER can perform all the steps necessary to control a robot right out of the box, including perception, state estimation, spatial understanding, planning and code generation. In such an end-to-end setting the model achieves a 2x-3x success rate compared to Gemini 2.0. And where code generation is not sufficient, Gemini Robotics-ER can even tap into the power of in-context learning, following the patterns of a handful of human demonstrations to provide a solution.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-b5cc8c3f-baf6-4ee6-ae2f-4c3c8d9630a8">
  <div>
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1070" height="601" srcset="https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w1070-rw 1x, https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w2140-rw 2x"/><source media="(min-width: 600px)" type="image/webp" width="928" height="521" srcset="https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w928-rw 1x, https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w1856-rw 2x"/><source type="image/webp" width="528" height="296" srcset="https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w528-rw 1x, https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w1056-rw 2x"/>
      <img alt="Gemini Robotics-ER excels at embodied reasoning capabilities including detecting objects and pointing at object parts, finding corresponding points and detecting objects in 3D. This is a collage of visualizations showcasing these capabilities. Top left: 2D object detection, top right: pointing, bottom left: multi-view correspondence, bottom right: 3d object detection." height="601" loading="lazy" src="https://lh3.googleusercontent.com/gs6-8ViSSMd63YQlQR6eSoIpKNrpJMRn_jAFkLlATk8IzYUEbOGN4Fq3uthY6w7fGiQeMTipo6MNJ0CJDy9Dc-H1k-Dx3ua7zyu4KkophVhOn2yhSg=w1070" width="1070"/>
    </picture>
    
  </div>

  <figcaption>
      <p data-block-key="jgf1i">Gemini Robotics-ER excels at embodied reasoning capabilities including detecting objects and pointing at object parts, finding corresponding points and detecting objects in 3D.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="2q7pg">Responsibly advancing AI and robotics<br/></h2><p data-block-key="16hbn">As we explore the continuing potential of AI and robotics, we’re taking a layered, <a href="https://sites.google.com/corp/view/safe-robots" rel="noopener" target="_blank">holistic</a> approach to addressing safety in our research, from low-level motor control to high-level semantic understanding.</p><p data-block-key="7s8sj">The physical safety of robots and the people around them is a longstanding, foundational concern in the science of robotics. That&#39;s why roboticists have classic safety measures such as avoiding collisions, limiting the magnitude of contact forces, and ensuring the dynamic stability of mobile robots. Gemini Robotics-ER can be interfaced with these ‘low-level’ safety-critical controllers, specific to each particular embodiment. Building on Gemini’s core safety features, we enable Gemini Robotics-ER models to understand whether or not a potential action is safe to perform in a given context, and to generate appropriate responses.</p><p data-block-key="3dcnu">To advance robotics safety research across academia and industry, we are also releasing a new dataset to evaluate and improve semantic safety in embodied AI and robotics. In previous work, we showed how a <a href="https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/" rel="noopener" target="_blank">Robot Constitution</a> inspired by Isaac Asimov’s Three Laws of Robotics could help prompt an LLM to select safer tasks for robots. We have since developed a framework to automatically generate data-driven constitutions - rules expressed directly in natural language – to steer a robot’s behavior. This framework would allow people to create, modify and apply constitutions to develop robots that are safer and more aligned with human values. Finally, the <a href="https://asimov-benchmark.github.io/" rel="noopener" target="_blank">new ASIMOV dataset</a> will help researchers to rigorously measure the safety implications of robotic actions in real-world scenarios.</p><p data-block-key="ch213">To further assess the societal implications of our work, we collaborate with experts in our Responsible Development and Innovation team and as well as our Responsibility and Safety Council, an internal review group committed to ensure we develop AI applications responsibly. We also consult with external specialists on particular challenges and opportunities presented by embodied AI in robotics applications.</p><p data-block-key="cis52">In addition to our partnership with Apptronik, our Gemini Robotics-ER model is also available to trusted testers including Agile Robots, Agility Robots, Boston Dynamics, and Enchanted Tools. We look forward to exploring our models’ capabilities and continuing to develop AI for the next generation of more helpful robots.</p>
</div>
                
              
                
                
                  
                  

<section>
  

  <ul>
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf" rel="noopener" target="_blank">
      <span>Read our paper</span>
      <svg aria-hidden="true" role="presentation">
    <use href="/static/glue-icons.87e996bc684c.svg#open-in-new"></use>
  </svg>
    </a>
            </gemini-button>
        </li>
        
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://jamiepalatnik.com/technologies/gemini-robotics/" aria-label="https://deepmind.google/technologies/gemini-robotics/">
      <span>Gemini Robotics</span>
      
    </a>
            </gemini-button>
        </li>
        
    
  </ul>
</section>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="2q7pg">Acknowledgements</h2><p data-block-key="duspu">This work was developed by the Gemini Robotics team. For a full list of authors and acknowledgements please view <a href="https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf" rel="noopener" target="_blank">our technical report</a>.</p>
</div>
                
              
            </div>
          
        
      

      
    
  
  

  

  </article>

    </div></div>
  </body>
</html>
