<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ipinfo.io/blog/vpn-location-mismatch-report">Original</a>
    <h1>VPN location claims don&#39;t match real traffic exits</h1>
    
    <div id="readability-page-1" class="page"><div><p>In a large-scale analysis of 20 popular VPNs, IPinfo found that 17 of those VPNs exit traffic from <em>different countries than they claim</em>. Some claim 100+ countries, but many of them point to the same handful of physical data centers in the US or Europe.</p><p>That means the majority of VPN providers we analyzed donâ€™t route your traffic via the countries they claim to, and they claim many more countries than they actually support.Â </p><p>Analyzing over <strong>150,000 exit IPs</strong> across <strong>137 possible exit countries,</strong> and comparing what providers claim to what IPinfo measures, shows that:</p><ul><li><strong>17 in 20 providers </strong>had traffic exiting in a different country.</li><li><strong>38 countries</strong> were â€œvirtual-onlyâ€ in our dataset (claimed by at least one provider, but never observed as the actual traffic exit country for any provider we tested).</li><li>We were only able to verify all provider announced locations for <strong>3 providers</strong> out of the 20.</li><li>Across ~150,000 VPN exit IPs tested, ProbeNet, our internet measurement platform, detected roughly <strong>8,000 cases</strong> where widely-used IP datasets placed the server in the wrong country â€” sometimes thousands of kilometers off.</li></ul><p>This report walks through what we saw across VPN and IP data providers, provides a closer look at two particularly interesting countries, explores why measurement-based IP data matters if you care where your traffic really goes, and shares how we ran the investigation.</p><h2 id="which-vpns-matched-reality-and-which-didn%E2%80%99t">Which VPNs Matched Reality (And Which Didnâ€™t)</h2><p>Here is the overlap between the number of listed countries each VPN provider claims to offer versus the countries with real VPN traffic that we measured â€” lower percentages indicate providers whose claimed lists best match our data:</p>
</div><div>
<p><em>It&#39;s important to note that we used the most commonly and widely supported technologies in this research, to make comparison between providers as fair as possible while giving us significant data to analyze, so this will not be the full coverage for each provider.</em></p><p>These are some of the most visible names in the market. They also tend to have very long country lists on their websites. Notably, three well-known providers had zero mismatches across all the countries we tested: Mullvad, IVPN, and Windscribe<strong>.</strong></p><p>Country mismatches doesnâ€™t automatically mean some providers offer â€œbad VPNs,â€ but it does mean that if youâ€™re choosing a VPN because it claims â€œ100+ countries,â€ you should know that a significant share of those flags may be labels, or virtual locations.</p><h2 id="what-%E2%80%9Cvirtual-locations%E2%80%9D-really-mean">What â€œVirtual Locationsâ€ Really Mean</h2><p>When a VPN lets you connect to, for example, â€œBahamasâ€ or â€œSomalia,â€ that doesnâ€™t always mean traffic routes through there. In many cases, itâ€™s somewhere entirely different, like Miami or London, but presented as if traffic is in the country you picked.</p><p>This setup is known as a virtual location:</p><ul><li>The VPN app shows â€œCountry Xâ€ (e.g. Bahamas).</li><li>The IP registry data also says â€œCountry Xâ€ â€” because the provider self-declared it that way.</li><li>But the network measurements (latency and routing) show the traffic actually exits in â€œCountry Yâ€ â€” often thousands of kilometers away.</li></ul><p>The problem? Without active network measurement, most IP datasets will rely on what the IPâ€™s owner told the internet registry or published in WHOIS/geofeeds: a self-reported country tag. If that record is wrong or outdated, the mistake spreads everywhere. Thatâ€™s where IPinfoâ€™s ProbeNet comes in: by running live RTT tests from 1,200+ points of presence worldwide, we anchor each IP to its real-world location, not just its declared one.</p><p>Across the dataset, we found <strong>97 countries</strong> where at least one VPN brand only ever appeared as virtual or unmeasurable in our data. In other words, for a noticeable slice of the world map, some â€œlocationsâ€ in VPNs never show up as true exits in our measurements.Â </p><p>We also found <strong>38 countries</strong> where every mention behaved this way: at least one VPN claimed them, but <strong>none</strong> ever produced a stable, measurable exit in that country in our sample.</p><p>You can think of these 38 as the â€œunmeasurableâ€ countries in this study â€“ places that exist in server lists, config files, and IP geofeeds, but never once appeared as the actual exit country in our measurements. Theyâ€™re not randomly scattered â€“ they cluster in specific parts of the map. By region, that includes:</p><figure><img src="https://ipinfo.io/blog/content/images/2025/12/VPN-research----unmeasurable--countries-map---Non-measurable.png" alt="" loading="lazy" width="2000" height="1055" srcset="https://ipinfo.io/blog/content/images/size/w600/2025/12/VPN-research----unmeasurable--countries-map---Non-measurable.png 600w, https://ipinfo.io/blog/content/images/size/w1000/2025/12/VPN-research----unmeasurable--countries-map---Non-measurable.png 1000w, https://ipinfo.io/blog/content/images/size/w1600/2025/12/VPN-research----unmeasurable--countries-map---Non-measurable.png 1600w, https://ipinfo.io/blog/content/images/size/w2400/2025/12/VPN-research----unmeasurable--countries-map---Non-measurable.png 2400w" sizes="(min-width: 720px) 720px"/></figure><p>This doesnâ€™t prove there is zero VPN infrastructure in those countries globally. It does show that, across the providers and locations we measured, the dominant pattern is to serve those locations from elsewhere. Here are three of the most interesting examples of how this looks at the IP level.</p><h2 id="case-studies-two-countries-that-only-exist-on-the-map">Case Studies: Two Countries That Only Exist on the Map</h2><p>To make this concrete, letâ€™s look at three countries where every provider in our dataset turned out to be virtual: <strong>Bahamas</strong>, and <strong>Somalia</strong>.</p><h3 id="bahamas-all-inclusive-hosted-in-the-us">Bahamas: All-Inclusive, Hosted in the US</h3><p>In our measurements, five providers offered locations labeled as â€œBahamasâ€: NordVPN, ExpressVPN, Private Internet Access, FastVPN, and IPVanish.</p><p>For all of them, measured traffic was in the United States, usually with sub-millisecond RTT to US probes.</p>
</div><div>
<h3 id="somalia-mogadishu-via-france-and-the-uk">Somalia: Mogadishu, via France and the UK</h3><p>Somalia appears in our sample for only two providers: NordVPN and ProtonVPN.Â </p><p>Both label Mogadishu explicitly in their naming, but these RTTs are exactly what youâ€™d expect for traffic in Western Europe, and completely inconsistent with traffic in East Africa. Both providers go out of their way in the labels (e.g. â€œSO, Mogadishuâ€), but the actual traffic is in Nice and London, not Somalia.</p>
</div><div>
<h2 id="when-legacy-ip-providers-agree-with-the-wrong-vpn-locations">When Legacy IP Providers Agree With the Wrong VPN Locations</h2><p>So far, weâ€™ve talked about VPN claims versus our measurements. But other IP data providers donâ€™t run active RTT tests. They rely on self-declared IP data sources, and often assume that if an IP is tagged as â€œCountry X,â€ it must actually be there.</p><p>In these cases, the IP legacy datasets typically â€œfollowâ€ the VPN providerâ€™s story: if the VPN markets the endpoint as Country X, the legacy IP dataset also places it in Country X.</p><p>To quantify that, we looked at 736 VPN exits where ProbeNetâ€™s measured country disagreed with one or more widely used legacy IP datasets.</p><p>We then compared the country IPinfo&#39;s ProbeNet measured (backed by RTT and routing) with the country reported by these other IP datasets and computed the distance between them. The gaps are large:</p><h3 id="how-far-off-were-the-other-ip-datasets">How Far Off Were the Other IP Datasets?</h3>
</div><div>
<p>The median error between ProbeNet and the legacy datasets was roughly 3,100 km<strong>. </strong>On the ProbeNet side, we have strong latency evidence that our measured country is the right one:</p><ul><li><strong>The median minimum RTT</strong> to a probe in the measured country was <strong>0.27 ms</strong>.</li><li>About <strong>90%</strong> of these locations had a <strong>sub-millisecond</strong> RTT from at least one probe.</li></ul><p>Thatâ€™s what you expect when traffic is genuinely in that country, not thousands of kilometers away.</p><h3 id="an-ip-example-you-can-test-yourself">An IP Example You Can Test Yourself</h3><p>This behavior is much more tangible if you can see it on a single IP.Â </p><p>Here&#39;s <a href="https://ipinfo.io/74.118.126.154?ref=ipinfo.io"><u>one VPN exit IP</u></a> where ProbeNet places the server in the United Kingdom, backed by sub-millisecond RTT from local probes, while other widely used legacy IP datasets place the same IP in Mauritius, 9,691 kilometers away.</p><p><strong>ğŸ‡¬ğŸ‡§ United Kingdom vs ğŸ‡²ğŸ‡º Mauritius (ProtonVPN)</strong></p><figure><img src="https://ipinfo.io/blog/content/images/2025/12/location-alert.png" alt="" loading="lazy" width="697" height="86" srcset="https://ipinfo.io/blog/content/images/size/w600/2025/12/location-alert.png 600w, https://ipinfo.io/blog/content/images/2025/12/location-alert.png 697w"/></figure><figure><img src="https://ipinfo.io/blog/content/images/2025/12/location-evidence.png" alt="" loading="lazy" width="1574" height="648" srcset="https://ipinfo.io/blog/content/images/size/w600/2025/12/location-evidence.png 600w, https://ipinfo.io/blog/content/images/size/w1000/2025/12/location-evidence.png 1000w, https://ipinfo.io/blog/content/images/2025/12/location-evidence.png 1574w" sizes="(min-width: 720px) 720px"/></figure><p>If you want to check this yourself, you can plug it into a public measurement tool like <a href="https://ping.sx/?ref=ipinfo.io"><u>https://ping.sx/</u></a> and run pings or traceroutes from different regions. Tools like this one provide a clear visual for where latency is lowest.</p><p>ProbeNet uses the same basic idea, but at a different scale: we maintain a network of 1,200+ points of presence (PoPs) around the world, so we can usually get even closer to the real physical location than public tools with smaller networks.</p><p>If youâ€™d like to play with more real IPs (not necessarily VPNs) where ProbeNet and IPinfo get the country right and other datasets donâ€™t, you can find a fuller set of examples on our IP geolocation <a href="http://ipinfo.io/accuracy/?ref=ipinfo.io"><u>accuracy page</u></a>.</p><h2 id="why-this-happens-and-how-it-impacts-trust">Why This Happens and How It Impacts Trust</h2><p>Itâ€™s worth separating technical reasons from trust issues. There are technical reasons to use virtual or hubbed infrastructure:</p><ul><li><strong>Risk &amp; regulation.</strong> Hosting in certain countries can expose both the provider and users to local surveillance or seizure.</li><li><strong>Infrastructure quality.</strong> Some regions simply donâ€™t have the same density of reliable data centers or high-capacity internet links, so running servers there is harder and riskier.</li><li><strong>Performance &amp; cost.</strong> Serving â€œBahamasâ€ from Miami or â€œCambodiaâ€ from Singapore can be cheaper, faster, and easier to maintain.</li></ul><p>From this perspective, a virtual location can be a reasonable compromise: you get a regional IP and content unblocking without the downsides of hosting in a fragile environment.</p><h3 id="where-it-becomes-a-trust-problem">Where It Becomes a Trust Problem</h3><p>Three things change the picture:</p><ul><li><strong>Lack of disclosure. </strong>Marking something clearly as â€œVirtual Bahamas (US-based)â€ is transparent. Listing â€œBahamasâ€ alongside â€œGermanyâ€ without any hint that one is virtual and the other is physical blurs the line between marketing and reality.</li><li><strong>Scale of the mismatch. </strong>Itâ€™s one thing to have a few virtual locations in hard-to-host places. Itâ€™s another when dozens of countries exist only as labels across your entire footprint, or when more than half of your tested locations are actually somewhere else.</li><li><strong>Downstream reliance. </strong>Journalists, activists, and NGOs may pick locations based on safety assumptions. Fraud systems, compliance workflows, and geo-restricted services may treat â€œSomaliaâ€ vs â€œFranceâ€ as a meaningful difference. If both the VPN UI and the IP data say â€œSomaliaâ€ while the traffic is physically in France, everyone is making decisions on a false premise.</li></ul><p>That last point leads directly into the IP data problem that we are focused on solving.</p><h2 id="so-how-much-should-you-trust-your-vpn">So How Much Should You Trust Your VPN?</h2><p>If youâ€™re a VPN user, here are some practical takeaways from this work:</p><ul><li><strong>Treat â€œ100+ countriesâ€ as a marketing number, not a guarantee. </strong>In our sample, 97 countries existed only as claims, not reality, across 17 providers.</li><li><strong>Check how your provider talks about locations. </strong>Do they clearly label â€œvirtualâ€ servers? Document where theyâ€™re actually hosted? Or do they quietly mix virtual and physical locations in one long list?</li><li><strong>If you rely on IP data professionally, ask where it comes from. </strong>A static â€œ99.x% accurate worldwideâ€ claim doesnâ€™t tell you how an IP data provider handles fast-moving, high-stakes environments like VPN infrastructure.</li></ul><p>Ultimately, this isnâ€™t an argument against VPNs, or even against virtual locations. Itâ€™s an argument for honesty and evidence. If a VPN provider wants you to trust that map of flags, they should be willing, and able, to show that it matches the real network underneath.</p><h2 id="how-ipinfo-approaches-ip-data-differently">How IPinfo Approaches IP Data Differently</h2><p>Most legacy IP data providers rely on regional internet registry (RIR) allocation data and heuristics around routing and address blocks. These providers will often accept self-declared data like customer feedback, corrections, and geofeeds, without a clear way to verify them.Â </p><p>IPinfo takes a measurement-first approach:</p><ol><li><strong>Proprietary ProbeNet with 1,200+ points of presence</strong></li><li><strong>Active measurements</strong></li><li><strong>Evidence-based geolocation</strong></li></ol><p>This measurement-first approach is unique in the IP data space. Once we realized how much inaccuracy came from self-declared data, we started investing heavily in research and building ProbeNet to use active measurements at scale. Our goal is to make IP data as evidence-based as possible, verifying with observation on how the internet actually behaves.</p><h2 id="our-methodology-for-this-report">Our Methodology for This Report</h2><p>We approached this VPN investigation the way a skeptical but well-equipped user would: start from the VPNsâ€™ own claims, then test them.</p><h3 id="step-1-collecting-what-providers-say">Step 1: Collecting What Providers Say</h3><p>For each of the <strong>20 VPN providers</strong>, we pulled together three kinds of data:</p><ul><li><strong>Marketing promises: </strong>The â€œservers in X countriesâ€ claims and country lists from their websites. When a country was clearly listed there, we treated it as the locations they actively promote.Â </li><li><strong>Configurations and locations lists: </strong>Configurations from different protocols like OpenVPN or WireGuard were collected along with location information available on provider command-line tools, mobile applications, or APIs.</li><li><strong>Unique providerâ€“location entries: </strong>We ended up with over 6,000,000 data points and a list of provider + location combinations we could actually try to connect to with multiple IPs each.</li></ul><h3 id="step-2-observing-where-the-traffic-really-goes">Step 2: Observing Where the Traffic Really Goes</h3><p>Next, we used IPinfo infrastructure and ProbeNet to dial into those locations and watch what actually happens:</p><ul><li>We connected to each VPN â€œlocationâ€ and captured the exit IP addresses.</li><li>For each exit IP address, we used IPinfo + ProbeNetâ€™s active measurements to determine a measured country, plus:<ul><li>The nearest ProbeNet vantage point (e.g., US, Brazil, France)</li><li>The round-trip time (RTT) from that probe (often under 1 ms), which is a strong hint about physical proximity</li></ul></li></ul><p>Now we had two views for each location:</p><ul><li><strong>Expected/Claimed country</strong>: What the VPN claims in its UI/configs/website</li><li><strong>Measured country</strong>: Where IPinfo + ProbeNet actually see the exit IP</li></ul><h3 id="step-3-comparing-claims-vs-reality">Step 3: Comparing Claims vs Reality</h3><p>For each location where a country was clearly specified, we asked a very simple question: Does the expected country match the measured country?</p><p>If yes, we counted it as a match. If not, it became a mismatch: a location where the app says one country, but the traffic exits somewhere else.</p><h3 id="acknowledgements-limitations-and-constrains">Acknowledgements, Limitations, and Constrains</h3><p>We deliberately used a very narrow definition of â€œmismatch.â€ For a location to be counted, two things had to be true: the provider had to clearly claim a specific country (on their website, in their app, or in configs), and we had direct active measurements from ProbeNet for the exit IPs behind that location.</p><p>We ignored any locations where the marketing was ambiguous, where we hadnâ€™t measured the exit directly, or where we only had weaker hints like hostname strings, registry data, or third-party IP databases. Those signals can be useful and true, but we wanted our numbers to be as hard-to-argue-with as possible.</p><p>The result is that the mismatch rates we show here are conservative. With a looser methodology that also leaned on those additional hints, the numbers would almost certainly be higher, not lower.Â </p></div></div>
  </body>
</html>
