<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gianluca.ai/2024-41/">Original</a>
    <h1>Weeknotes: Gigabucks, burning my Mac&#39;s GPU, and Karpathy&#39;s lament</h1>
    
    <div id="readability-page-1" class="page"><div><p>Find previous weeknotes <a href="https://medicalxpress.com/tags/weeknotes/">here</a>.</p><hr/><p>A full and chaotic week. I got off to a raging start and made great progress at Recurse, but got slammed by some hard walls of bureaucracy in the second half. My mission is to <em>become stronger, defy Nature, and have fun</em>. Tax accounting is the opposite of all three of those…</p><h2 id="updates">Updates</h2><p>RC hosts “Impossible Stuff Day” once per batch, a whole day to spend working on something well beyond the edge of your abilities that feels totally impossible. The <a href="https://medicalxpress.com/rc-weeknotes-03/#doing-the-impossible">last one</a> wasn’t productive for me, but I took a different approach this time around and <a href="https://medicalxpress.com/devlog-llmpossible/">wrote a DevLog</a> in real time as I participated.</p><p>Despite challenges with download speeds and privacy issues, I successfully set up a 3B-parameter LLM with GPU acceleration on my Mac through a custom command-line interface. I did the “llmpossible.”</p><p>I finally migrated <a href="https://www.goodreads.com/user/show/56535709-gianluca-truda">my Goodreads data</a> to my personal site. See the new <a href="https://medicalxpress.com/books/">books</a> page.</p><p>You can also view the code and use it to liberate your own Goodreads data: <a href="https://github.com/gianlucatruda/goodreads-to-md">gianlucatruda/goodreads-to-md: Convert Goodreads books to markdown files (Obsidian, Hugo, Jekyll etc.)</a></p><h2 id="inputs--outputs">Inputs / outputs</h2><ul><li>Updated my site’s code snippets so they have line wrapping, nicer highlighting, and robust copy-paste.</li><li>ML Paper Cuts study group: We covered the CLIP model from <a href="https://arxiv.org/abs/2103.00020">Learning transferable visual models from natural language supervision</a>.<ul><li>I first studied CLIP at release. It was clear then that it was a breakthrough way to unify text and image modalities at scale. But revisiting it in detail unlocked some interesting nuances of its training approach and limitations.</li></ul></li><li>I impromptu co-hosted Creative Coding this week. The theme was “visual abnormality” so we mob programmed artistic interpretations of the webcam feed. Everyone was spectacularly creative in their approaches to representing colour blindness, double vision, and hallucinations.<ul><li>After a bit more time to polish it, I produced a WebGL shader that uses the webcam as a texture from which you can explore fractals and discontinuities in colourspace.</li><li>Try it in your browser at <a href="https://webcam-aberration.vercel.app/">webcam-aberration.vercel.app</a>. It’s best on desktop browsers.</li><li>The source code is at <a href="https://github.com/gianlucatruda/webcam-aberration">gianlucatruda/webcam-aberration</a></li></ul></li><li>I started working through <a href="https://thebookofshaders.com/">The Book of Shaders</a>, which we discussed at the Graphics study group before going down various rabbit holes about how to debug parallel GPU code, graphics drivers and engines, and our favourite aspirational shader artworks.</li></ul><p>Here’s a short demo video of me using <a href="https://webcam-aberration.vercel.app/">webcam-aberration</a>, but it looks nowhere near as good as the real thing because of all the compression artefacts, so please do try it yourself!</p><h2 id="ideas">Ideas</h2><h3 id="another-llm-workflow-for-terminal-dwellers">Another LLM workflow for terminal dwellers</h3><p>I don’t need Cursor, I just use</p><div><pre tabindex="0"><code data-lang="bash"><span><span>cat instructions.md <span>|</span> llm --model o1-preview &gt;&gt; response.md
</span></span></code></pre></div><ul><li><code>o1-preview</code> managed to one-shot my request to reformat some disgusting <code>.js</code> from a Twitter export into a nice <code>.csv</code> with the same structure as the old export format.</li><li>I’ve since used this approach to few-shot many <a href="https://github.com/gianlucatruda/goodreads-to-md">little scripts</a> and it’s rapid and clean. The key is to write <em>great</em> instructions in <code>instructions.md</code>.</li><li>Having the output in <code>response.md</code> instead of <code>stdout</code> is handy, as you can always refer to it, but also you can open it in a vim buffer and then yank the actual code snippet across to your working code buffer.</li></ul><h3 id="karpathys-lament">Karpathy’s Lament</h3><p>I coin <em>Karpathy’s Lament</em>: The current paradigm of large language model training converges on moderately smart tools that write obscenely cringe-worthy slop.</p><blockquote><p>“Not fully sure why all the LLMs sound about the same - over-using lists, delving into “multifaceted” issues, over-offering to assist further, about same length responses, etc. Not something I had predicted at first because of many independent companies doing the finetuning”</p></blockquote><p>— via <a href="https://x.com/karpathy/status/1843005000206909856">this tweet</a></p><h3 id="a-chain-of-mathematical-equivalence">A chain of mathematical equivalence</h3><ul><li>Did you know: <a href="https://x.com/keenanisalive/status/1838241399202038118">taking the Fourier series of a function is equivalent to changing basis vectors</a>.</li><li>And speaking of Fourier transforms, <a href="https://twitter.com/nrehiew_/status/1832412663273464152">diffusion is autoregression in frequency space</a>.</li><li>But that’s not all. <a href="https://arxiv.org/pdf/2410.02543">Diffusion models are evolutionary algorithms</a>.<ul><li>My <a href="https://arxiv.org/abs/1907.05363">undergrad thesis</a> found the breakthrough with evolutionary algorithms <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> and my <a href="https://arxiv.org/abs/2308.14784">postgrad thesis</a> found the breakthrough with diffusion models. I’m delighted that it turns out they were the same thing.</li></ul></li></ul><h3 id="re-frame-your-limited-perceptual-lifetime">Re-frame your limited perceptual lifetime</h3><ul><li>Credible attempts at meaningful things take around 5 years. So you <a href="https://x.com/j_foerst/status/1844023863476400440">only have about 6 shots in your career</a>. Use them wisely.</li><li>Moreover, <a href="https://x.com/sdand/status/1821965217284358291">your perception of time is logarithmic over the course of your life, so by 21 you’re already half-way through your perceptual lifespan</a>. What to do? “You can live the equivalent of many lives by following the dopaminergic gradient and seeking novelty” — <a href="https://x.com/basedbeffjezos/status/1822063839556595851">Beff’s aphorism</a>. Just do more cool shit!</li><li>I love <a href="https://x.com/nickcammarata/status/1843053928600244406">Nick Cammarata’s trick</a> of viewing money in terms of <em>kilobucks</em>, <em>megabucks</em>, and <em>gigabucks</em> instead of thousands, millions, and billions. Suddenly, everything is more fun for us builders and gamers. Instead of trying to “do something on a budget”, you’re trying to “optimise something to fit on one kilobuck”. Your company isn’t “delivering shareholder value”, it’s trying to “build a gigabuck factory.”</li></ul><blockquote><p>maybe bc with money it’s cool to be inefficient (to show off your surplus, eg $500 bottles at a club or whatever) but in programming/hacker culture it’s pretty much always cool to be efficient.
also to me it brings up the q of “well, how much do you need to run the thing you want to make” vs like you need to max out how much memory/money you have, always need more. If you’re making Call of Duty you prob need a lot but Super Mario is tbh more fun and doesn’t need much.
And building a fun Super Mario isn’t thaaat much easier with infinite memory. It’s hard to make it good and fun, but not because of memory constraints. There’s a lot of other bottlenecks that adding memory doesn’t automatically fix</p></blockquote><p>— via <a href="https://x.com/nickcammarata/status/1843053928600244406">his thread</a></p><h3 id="distribution-shift-in-vibespace">Distribution shift in vibespace</h3><ul><li>As the founder, “you are the upper bound on how much people in your company care.” — Alexandr Wang (Scale.ai) via <a href="https://twitter.com/snowmaker/status/1842792076414742590">this tweet</a></li><li>“are autists failed empaths whose natural sensory clarity was so high they had to turn off all the most salient channels (looking at eyes, empathy, love, etc) and invest all their processing into lower human-saliency things like math as a way to cope with constant overwhelm” — <a href="https://x.com/nickcammarata/status/1836573676147478584">Nick Cammarata</a></li><li>“basically one thing that’s happening globally right now is that american ideological strains escaped from america. they’re incredibly potent and while americans have been selected for resistance the rest of the world is naive. basically brain smallpox but for the old world” — <a href="https://x.com/eigenrobot/status/1840962611937939849">@eigenrobot</a></li><li>“the vast majority of humanity would never become billionaires. they wouldn’t even want to. mo money mo problems as they say. honestly most of ya’ll would tap out at 8 figures and start drinking wine with chamath or something […] that level of wealth is a side effect of mental illness / an aberration. it’s the same thing that would compel someone to hit top 0.2 percentile in starcraft. there is no reason to actually do it. there’s just something extremely powerful compelling you to do so […] There are people that want something so bad the universe will align itself to give it to them.” — <a href="https://x.com/yacineMTB/status/1842974907363381447">@yacineMTB</a></li></ul><h2 id="links">Links</h2><ul><li>The moon’s orbit is <a href="https://www.youtube.com/watch?v=KBcxuM-qXec">even weirder</a> than I thought.</li><li><a href="https://www.youtube.com/watch?v=rjcx295mI2c">Why are movies so obsessed with trains?</a></li><li><a href="https://www.youtube.com/watch?v=6WUxgmMDts4">Blowing up Capacitors at 187,000FPS</a></li><li>Jacob Geller <a href="https://www.youtube.com/watch?v=8KSl_lMN7-c">goes deep on Spec Ops: The Line</a> (a superb video essay, as usual from Jacob)</li><li><a href="https://youtu.be/MPyJBJTHyO0">Tantacrul’s three-hour documentary on the history of Facebook</a></li><li>Not even <a href="https://youtu.be/-Cw37g39g00">Stephen Fry</a> knows what to make of AI</li><li><a href="https://youtu.be/5aIPRw0RcvY">The delightfully-invisible art of foley sound</a></li><li>If you’re a technical person who want’s to understand the LLM playing field, as well as how FAANG and startups fit in, these are great listens <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> while doing household chores:<ul><li><a href="https://overcast.fm/+AAeZyDb16UM">Lex Fridman Podcast #447 – Cursor Team: Future of Programming with AI</a></li><li><a href="https://overcast.fm/+AAeZyDTZwOM">Lex Fridman Podcast #434 – Aravind Srinivas: Perplexity CEO on Future of AI, Search &amp; the Internet</a></li><li><a href="https://overcast.fm/+AA_ztz2NprE">Acquired: The Mark Zuckerberg Interview</a></li></ul></li></ul><h2 id="this-week-i-learned">This week I learned</h2><p>(Copy-pasted from my <code>#TIL</code>-tagged notes in Obsidian from the past week.)</p><ul><li><code>ciq</code>, <code>yib</code>, <code>dap</code>, etc. Vim motions (that I use constantly) actually work <em>anywhere</em> on the line. I’ve been first seeking the objects and then using them, but you don’t have to do that first step. Vim is smart enough to find the nearest valid target. via <a href="https://twitter.com/dhh/status/1835112408089870511">DHH on twitter</a></li><li>Two handy Vim objects I didn’t know: <code>W</code> for whitespace and <code>i</code> for indentation level. For example, <code>dii</code> deletes everything at the current indentation and <code>yiW</code> copies everything between whitespace. via <a href="https://twitter.com/dhh/status/1835112408089870511">DHH on twitter</a></li></ul><hr/><p>Thanks for reading! I’ve tweaked the format and emphasis this week. Please let me know what you think and what you found most interesting.</p></div></div>
  </body>
</html>
