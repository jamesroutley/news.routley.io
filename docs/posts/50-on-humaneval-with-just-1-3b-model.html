<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://twitter.com/sytelus/status/1671333552204693504">Original</a>
    <h1>50% on HumanEval with just 1.3B model</h1>
    
    <div id="readability-page-1" class="page"><div role="main"><div><div><div><div data-testid="primaryColumn"><div aria-label="Home timeline" tabindex="0"><div itemscope="" itemtype="https://schema.org/Collection"><meta content="Tweet with replies" itemprop="name"/><section aria-labelledby="accessible-list-142640" role="region"><div aria-label="Timeline: Conversation"><div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671333552204693504" itemprop="identifier"/><meta content="1" itemprop="position"/><meta content="7" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T01:45:45.000Z" itemprop="dateCreated"/><meta content="2023-06-21T01:45:45.000Z" itemprop="datePublished"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="mainEntityOfPage"/><meta content="https://twitter.com/SebastienBubeck/status/1671326369626853376" itemprop="isBasedOn"/><article aria-labelledby="id__yzjx7emmd2 id__f7qexk25c94 id__dxu1bkatf0d id__whc3m1smppo id__ggiik3rnwk4 id__qbl35d7ad3l id__otkh96wm4 id__jo0udjqzno id__n437ktwt9xd id__c4bniqxn1bo id__cxtt9q0z9am id__esb25nsz5cl id__hn6yxphq8bi id__cs3ije5c4ji id__s5uokcpxvha id__kwrqoxd0he7 id__804clywjgb id__yo39g4bawf8 id__rnxda8k545g" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-sytelus"><div><div><div><div><a href="https://www.cyberdemon.org/sytelus" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1600058846332190720/XeRAikbl_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div><div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Amazing work by our group at Microsoft Research is finally public!

Can you achieve 50% on HumanEval with a mere 1.3B code generation model? Yes you can! </span><span>üòá</span><span>

How about cracking 45% with a ‚Äútiny‚Äù 350M model? No problem! </span><span>ü§Ø</span><span>

</span><a dir="ltr" href="https://t.co/LXa6M2jFZx" rel="noopener noreferrer nofollow" target="_blank" role="link"><span aria-hidden="true">https://</span>arxiv.org/abs/2306.11644</a></p></div></div></div><div><div aria-labelledby="id__xydokagpn id__e8jgbj72srv" id="id__hn6yxphq8bi"><div id="id__xydokagpn"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-SebastienBubeck"><div><div><div><div><a href="https://www.cyberdemon.org/SebastienBubeck" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1600209313863151616/5V6V5YGs_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><p><span>New LLM in town:

***phi-1 achieves 51% on HumanEval w. only 1.3B parameters &amp; 7B tokens training dataset***

Any other &gt;50% HumanEval model is &gt;1000x bigger (e.g., WizardCoder from last week is 10x in model size and 100x in dataset size).

How?

***Textbooks Are All You Need***</span></p><p><span>Show this thread</span></p></div><div><div><div><div><div><div><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzG-Q6JakAQRTwX?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671339038069121026" itemprop="identifier"/><meta content="2" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:07:33.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:07:33.000Z" itemprop="datePublished"/><meta content="https://twitter.com/jkronand/status/1671339038069121026" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__lrjkthwja79 id__v15pomfkz5 id__5urfxbhuv87 id__4ouw78k13qt id__ex2ep0j6vuv id__8cba121i7l9 id__2o34857ymot id__lmpwuiafzda id__jit7lwil47p id__abguspeel4w id__dwt3sxt9bwk id__s2u4ranc6w id__jcsicc81m1 id__xhvrgcnevlb id__3zd3bw9jt8l id__9vw2vs3c1n8 id__6mt0y1x1gcn id__5wielshq4ys id__ghkkqugphji" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-jkronand"><div><div><div><div><a href="https://www.cyberdemon.org/jkronand" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1635756469986689024/lPOWrGg5_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><div dir="auto" lang="en" id="id__dwt3sxt9bwk" data-testid="tweetText"><p><span>Wow. I had not expected that good results The right data carefully stratified is powerful though. Lots of correlations in typical data that is not really informative for the task. 

</span></p><p><span> How do you think this generalizes to other sorts of of coding evals?</span></p></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671489381268439041" itemprop="identifier"/><meta content="3" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T12:04:57.000Z" itemprop="dateCreated"/><meta content="2023-06-21T12:04:57.000Z" itemprop="datePublished"/><meta content="https://twitter.com/rohanpaul_ai/status/1671489381268439041" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__3e9vtqfxsvp id__y29hijzxwt id__yx1pffdovdn id__g0s54ot6yv5 id__l12p3t2nqkh id__svff4ftvhz id__21dk83tbvxm id__immtjj4mba id__2u3qa9kwmt5 id__222o96pd19o id__qykdtoi14k8 id__o4hisf4qvsr id__cc0xkueetvp id__39bzbjg0nnp id__440pycxnx9q id__supu72ct1zp id__vjji7fsrvp id__sn5e0frg6br" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-rohanpaul_ai"><div><div><div><div><a href="https://www.cyberdemon.org/rohanpaul_ai" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1516198999602393089/XdkyzdBy_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>This is a very promising follow-up to the huge potential of TinyStories. Absolutely great development</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671335511435145217" itemprop="identifier"/><meta content="4" itemprop="position"/><meta content="1" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T01:53:32.000Z" itemprop="dateCreated"/><meta content="2023-06-21T01:53:32.000Z" itemprop="datePublished"/><meta content="https://twitter.com/inductionheads/status/1671335511435145217" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__cyciqtnc5nf id__nd5h6vohyab id__lxr2lrhmr9m id__5y0i50h6hgk id__liqd91sx3pe id__dka27deqrp8 id__ucb8kksql8 id__pu2sopjnth id__2dertu89et6 id__9dvt1dd9u0e id__b0a5rgpnj8q id__qjckhpd5pxd id__w03h22q7kba id__3n7dsgja148 id__4jl11me79on id__atxfybkg46u id__m86lbtg28dj id__qdn883qv0nr id__m6urkaed0t" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-inductionheads"><div><div><div><div><a href="https://www.cyberdemon.org/inductionheads" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1641399057322000386/1WPqyV9L_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Unreal.  What was state of the art 10 months ago is now beaten by something running on a raspberry pi zero</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671347652779290624" itemprop="identifier"/><meta content="5" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:41:47.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:41:47.000Z" itemprop="datePublished"/><meta content="https://twitter.com/TheXeophon/status/1671347652779290624" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__5ijv63e1inl id__2dcoj6i3ov9 id__li2frzq6rjc id__jsb2ugpahc id__9dkbw70sf5r id__nz2kif6wxba id__rc71f0lsew id__uz6u7ogty4 id__waqyefi7rf id__5j4lvts0jgu id__uojuws816a8 id__xctl37iq6m id__kge9ji56hc id__v01q5gznw9b id__ir3dyeh1j9 id__tu1z5ue9iyh id__p9c53omq7go id__h4jrupuo8uw" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-TheXeophon"><div><div><div><div><a href="https://www.cyberdemon.org/TheXeophon" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1575944848443572227/uEQ11nR2_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>In the data pruning section (5.2) you prune w/ different AST match rates while keeping the embedding distance the same (?). Is the embedding distance you prune 0.16 as in Appendix C?</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671349550416625664" itemprop="identifier"/><meta content="6" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:49:19.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:49:19.000Z" itemprop="datePublished"/><meta content="https://twitter.com/TheXeophon/status/1671349550416625664" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__l4sdlw5abel id__425w0aj92mu id__xe1pa9zce6d id__phrz0ypahmi id__dn2l57o5fvi id__bq4980xfs6l id__245f8kjxcmh id__k5tqi5qdzw9 id__ei5aiq5s82 id__m97byi5hjr id__iaz8jcd99th id__9aqzk2hzp3k id__9q4gcazbba id__dd4uwkcypb7 id__3h5xw2cbgop id__sdukhpvrsmn id__nckhmq83w8 id__ducwhsdyvu id__ad2k7oez4dw" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-TheXeophon"><div><div><div><div><a href="https://www.cyberdemon.org/TheXeophon" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1575944848443572227/uEQ11nR2_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Any particular reason you used GPT-4 for labeling (to train the RF in Sec 2.1) but also use GPT3.5 for generating new Data (in Sec 2.2)? Wouldn‚Äôt a model capable of generating good synthetic data also be able to label data good enough? Or was 3.5 way worse than 4?</span></p></div></div></div></div></div></div></article></div></div><div><div><h2 aria-level="2" role="heading"><p><span>Discover more</span></p></h2><p><span>Sourced from across Twitter</span></p></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671267150101721090" itemprop="identifier"/><meta content="7" itemprop="position"/><meta content="37" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-20T21:21:53.000Z" itemprop="dateCreated"/><meta content="2023-06-20T21:21:53.000Z" itemprop="datePublished"/><meta content="https://twitter.com/soumithchintala/status/1671267150101721090" itemprop="url"/><meta content="https://twitter.com/pommedeterre33/status/1671263789914677248" itemprop="isBasedOn"/><article aria-labelledby="id__2ah3hrrt9j5 id__lbamwc8y15r id__er0tutq8bgu id__u3kro53grki id__e2as0s87r2c id__86lh313kdal id__r2cy5ofnrrr id__82cmelbxan id__bh1pni6ufgw id__4912t3q5pyj id__3ptz079wmh9 id__446kehr66ev id__5pu4eiiutxf id__fe32eovl9ti id__miyb4eqfkln id__3stghc68km4 id__f4frv0i5wp id__qm80qyp21pq id__ea2epfwisd8" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-soumithchintala"><div><div><div><div><a href="https://www.cyberdemon.org/soumithchintala" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/959995586689691648/DAFep10r_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>i might have heard the same </span><span>üòÉ</span><span> -- I guess info like this is passed around but no one wants to say it out loud.
GPT-4: 8 x 220B experts trained with different data/task distributions and 16-iter inference.
Glad that Geohot said it out loud.

Though, at this point, GPT-4 is‚Ä¶</span><span tabindex="0" data-testid="tweet-text-show-more-link-1671267150101721090"><span>¬†</span><span>Show more</span></span></p></div></div><div aria-labelledby="id__byl80160i4 id__snupry724kf" id="id__5pu4eiiutxf"><div id="id__byl80160i4"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-pommedeterre33"><div><div><div><div><a href="https://www.cyberdemon.org/pommedeterre33" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/378800000579324326/77fad234674d1f22af356706ab2b50de_400x400.jpeg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><p><span>Unexpected description of GPT4 architecture from geohotz in a recent interview he gave. At least it‚Äôs plausible.</span></p></div><div><div><div><div><div><div><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzGFjqwX0AI05GV?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671360619986010112" itemprop="identifier"/><meta content="8" itemprop="position"/><meta content="5" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T03:33:18.000Z" itemprop="dateCreated"/><meta content="2023-06-21T03:33:18.000Z" itemprop="datePublished"/><meta content="https://twitter.com/_akhaliq/status/1671360619986010112" itemprop="url"/><article aria-labelledby="id__6v4wsf9c47u id__wnrlkbi7xqa id__stm8i9bhxt id__529e6uk4h7p id__km9wb3i235p id__mu19czxhd4d id__3uvhm3ke0a id__v6bjpnmtagm id__0erexoseartf id__44yb307z7js id__310yc3682oq id__a4jykaxi3aq id__wei5q73e1m id__r0g1yxqrsf id__x48jphnjxzg id__1tjokrnmz81 id__ltmufwco4r id__t6ok6ulxnp id__frar48djwg" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-_akhaliq"><div><div><div><div><a href="https://www.cyberdemon.org/_akhaliq" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Textbooks Are All You Need

paper page: </span><a dir="ltr" href="https://t.co/D0AEOSLfGM" rel="noopener noreferrer nofollow" target="_blank" role="link"><span aria-hidden="true">https://</span>huggingface.co/papers/2306.11<span aria-hidden="true">644</span><span aria-hidden="true">‚Ä¶</span></a><span>

introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection‚Ä¶</span><span tabindex="0" data-testid="tweet-text-show-more-link-1671360619986010112"><span>¬†</span><span>Show more</span></span></p></div></div><div aria-labelledby="id__miqk5sg47zk id__cwiacjxzzkq" id="id__wei5q73e1m"><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzHdjLJWwAE0myK?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671361731837456385" itemprop="identifier"/><meta content="9" itemprop="position"/><meta content="2" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T03:37:43.000Z" itemprop="dateCreated"/><meta content="2023-06-21T03:37:43.000Z" itemprop="datePublished"/><meta content="https://twitter.com/EldanRonen/status/1671361731837456385" itemprop="url"/><meta content="https://twitter.com/SebastienBubeck/status/1671326369626853376" itemprop="isBasedOn"/><article aria-labelledby="id__5hayy7naico id__zn2124la4v id__aomt09tu38m id__j5vua3ew93s id__ryvovjma3h id__uprns7850q id__j0nswfhgdx id__49yj5b75tkn id__i21s3pbrhkk id__wp023i2uv2f id__38su2p61gkp id__8u8ogl6ketn id__5q3xbnh0xp2 id__vfxgyc308g id__za2ddlj7ykc id__7k6js7yij5j id__g1wjp0vh6pc id__mmvdmidoygd id__djrrzu9icd" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-EldanRonen"><div><div><div><div><a href="https://www.cyberdemon.org/EldanRonen" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1574594835776176128/Yp0ZPmZg_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><div dir="auto" lang="en" id="id__38su2p61gkp" data-testid="tweetText"><p><span>High-quality synthetic datasets strike again. Following up on the technique of TinyStories (and many new ideas on top) at </span></p><p><span> we curated textbook-quality training data for coding. The results beat our expectations.

For skeptics- model will be on HF soon, give it a try.</span></p></div></div></div><div aria-labelledby="id__sbn2btbepy id__hh91uc8z84" id="id__5q3xbnh0xp2"><div id="id__sbn2btbepy"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-SebastienBubeck"><div><div><div><div><a href="https://www.cyberdemon.org/SebastienBubeck" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1600209313863151616/5V6V5YGs_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><p><span>New LLM in town:

***phi-1 achieves 51% on HumanEval w. only 1.3B parameters &amp; 7B tokens training dataset***

Any other &gt;50% HumanEval model is &gt;1000x bigger (e.g., WizardCoder from last week is 10x in model size and 100x in dataset size).

How?

***Textbooks Are All You Need***</span></p><p><span>Show this thread</span></p></div><div><div><div><div><div><div><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzG-Q6JakAQRTwX?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671238819801346050" itemprop="identifier"/><meta content="10" itemprop="position"/><meta content="4" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-20T19:29:19.000Z" itemprop="dateCreated"/><meta content="2023-06-20T19:29:19.000Z" itemprop="datePublished"/><meta content="https://twitter.com/profjoeyg/status/1671238819801346050" itemprop="url"/><meta content="https://twitter.com/zhuohan123/status/1671234707206590464" itemprop="isBasedOn"/><article aria-labelledby="id__hkwsjotni9h id__s0xkwx351a id__h2dql79ufl id__nkx96i79u5 id__ogcmbun79t id__z3bqnk9fqoa id__pxs9f8dpwfm id__eain4akkeep id__qm2rabmrie id__0pqak65opj1 id__wu1hbmtx92 id__4cqozynb7x3 id__t37ice8zt6k id__rz59w7632n id__2rtoun194bo id__fm7iqn7fcus id__5h2w3mnzev9 id__dil4ll0i0va id__rb4ynynd92" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-profjoeyg"><div><div><div><div><a href="https://www.cyberdemon.org/profjoeyg" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1276216056520925184/IdYx_g-j_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Serving LLMs? My students found a way to accelerate serving by over an order-of-magnitude just by changing the way memory is managed (spoiler alert): gpu memory fragmentation = slow. Introducing vLLM with PagedAttention:</span></p></div></div><div aria-labelledby="id__vu7krvpjxqd id__xl1ow7f1qc" id="id__t37ice8zt6k"><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzFuhtiaMAQoOjO?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div><div id="id__vu7krvpjxqd"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-zhuohan123"><div><div><div><div><a href="https://www.cyberdemon.org/zhuohan123" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1230577035170340864/NRvpL0H8_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><div><div><p><img alt="üåü" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/1f31f.svg"/><span> Thrilled to introduce vLLM with </span><span><span dir="ltr">@woosuk_k</span></span><span>!

</span><img alt="üöÄ" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/1f680.svg"/><span> vLLM is an open-source LLM inference and serving library that accelerates HuggingFace Transformers by 24x and powers </span><span><span dir="ltr">@lmsysorg</span></span><span> Vicuna and Chatbot Arena.

Github: </span><span dir="ltr"><span aria-hidden="true">https://</span>github.com/vllm-project/v<span aria-hidden="true">llm</span><span aria-hidden="true">‚Ä¶</span></span><span>
Blog: </span><span dir="ltr"><span aria-hidden="true">https://</span>vllm.ai</span></p><p><span>Show this thread</span></p></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div></section></div></div></div></div></div></div></div></div>
  </body>
</html>
