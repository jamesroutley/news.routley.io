<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://twitter.com/sytelus/status/1671333552204693504">Original</a>
    <h1>50% on HumanEval with just 1.3B model</h1>
    
    <div id="readability-page-1" class="page"><div role="main"><div><div><div><div data-testid="primaryColumn"><div aria-label="Home timeline" tabindex="0"><div itemscope="" itemtype="https://schema.org/Collection"><meta content="Tweet with replies" itemprop="name"/><section aria-labelledby="accessible-list-3524" role="region"><div aria-label="Timeline: Conversation"><div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671333552204693504" itemprop="identifier"/><meta content="1" itemprop="position"/><meta content="7" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T01:45:45.000Z" itemprop="dateCreated"/><meta content="2023-06-21T01:45:45.000Z" itemprop="datePublished"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="mainEntityOfPage"/><meta content="https://twitter.com/SebastienBubeck/status/1671326369626853376" itemprop="isBasedOn"/><article aria-labelledby="id__izx1z52e409 id__2nl9h1malr4 id__etog7qfttx4 id__3wq805o4fbr id__327kr0ctgtp id__xcg1vkevck id__pqn4e4ch51g id__f0w2fwhpmc8 id__4id5dh5el6j id__fsek15t5x1g id__h0pwbixk3kl id__6n565y92noe id__3658xveetm id__lyv17jpdvgm id__uxdlaijfzjn id__vrxcn5xxfvp id__4cbezh45pi5 id__ymffogcovm id__itkpf20o5bo" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-sytelus"><div><div><div><div><a href="https://twitter.com/sytelus" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1600058846332190720/XeRAikbl_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div><div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Amazing work by our group at Microsoft Research is finally public!

Can you achieve 50% on HumanEval with a mere 1.3B code generation model? Yes you can! </span><span>üòá</span><span>

How about cracking 45% with a ‚Äútiny‚Äù 350M model? No problem! </span><span>ü§Ø</span><span>

</span><a dir="ltr" href="https://t.co/LXa6M2jFZx" rel="noopener noreferrer nofollow" target="_blank" role="link"><span aria-hidden="true">https://</span>arxiv.org/abs/2306.11644</a></p></div></div></div><div><div aria-labelledby="id__xarbuqt3ov id__onlmef5qfo" id="id__3658xveetm"><div id="id__xarbuqt3ov"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-SebastienBubeck"><div><div><div><div><a href="https://twitter.com/SebastienBubeck" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1600209313863151616/5V6V5YGs_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><p><span>New LLM in town:

***phi-1 achieves 51% on HumanEval w. only 1.3B parameters &amp; 7B tokens training dataset***

Any other &gt;50% HumanEval model is &gt;1000x bigger (e.g., WizardCoder from last week is 10x in model size and 100x in dataset size).

How?

***Textbooks Are All You Need***</span></p><p><span>Show this thread</span></p></div><div><div><div><div><div><div><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzG-Q6JakAQRTwX?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671339038069121026" itemprop="identifier"/><meta content="2" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:07:33.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:07:33.000Z" itemprop="datePublished"/><meta content="https://twitter.com/jkronand/status/1671339038069121026" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__kqw0b7wj0im id__pl1jzls97hq id__peddop6b8hq id__hvcgr4uzsjs id__pd9ctexcrp id__yv43scs5yml id__6fls2da6z6p id__ngij9p8kmbn id__avkm79ydhhq id__8i0uqs5chn9 id__t3je29azfvi id__gyrxjls9o7v id__jlq7l2a53hl id__4ordjgrfp9 id__imhcvk555b id__zigmzd8onf id__vco9c8kvko9 id__8azsz09sxf6" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-jkronand"><div><div><div><div><a href="https://twitter.com/jkronand" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1635756469986689024/lPOWrGg5_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><div dir="auto" lang="en" id="id__t3je29azfvi" data-testid="tweetText"><p><span>Wow. I had not expected that good results The right data carefully stratified is powerful though. Lots of correlations in typical data that is not really informative for the task. 

</span></p><p><span> How do you think this generalizes to other sorts of of coding evals?</span></p></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671489381268439041" itemprop="identifier"/><meta content="3" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T12:04:57.000Z" itemprop="dateCreated"/><meta content="2023-06-21T12:04:57.000Z" itemprop="datePublished"/><meta content="https://twitter.com/rohanpaul_ai/status/1671489381268439041" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__kmds2vhcu4 id__7tmujejx2m id__kqn4rwj0l6o id__twjl1v1075m id__jvk7c61jaq id__ibb7ksqf1ja id__jgtp4pf228 id__u21whsz76j id__yopf2igerng id__dtbp3y2blsc id__516apqz924m id__yqdf87cns id__llg5z8huini id__2m2p7kwpvun id__lhvc7hupwu id__xqrp0tm7d id__zzdlrqw7z8 id__y3r0xkh0dwp" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-rohanpaul_ai"><div><div><div><div><a href="https://twitter.com/rohanpaul_ai" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1516198999602393089/XdkyzdBy_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>This is a very promising follow-up to the huge potential of TinyStories. Absolutely great development</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671335511435145217" itemprop="identifier"/><meta content="4" itemprop="position"/><meta content="1" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T01:53:32.000Z" itemprop="dateCreated"/><meta content="2023-06-21T01:53:32.000Z" itemprop="datePublished"/><meta content="https://twitter.com/inductionheads/status/1671335511435145217" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__wopix9vgp4 id__ee1hdrf73ml id__ymw88d79ror id__i4zggqpaerk id__v5i1udpu9ve id__v3g88mebwh9 id__kif5aq9bzq id__0t6gvsn2mkwn id__xox0tkmgzr id__xleialja8jp id__qrytfio1sj id__7kzjonq2p0q id__jh4ag4lr1d id__w5tpv8840l id__tbajax0kzgh id__v500n39fqkf id__5et5wek97wb id__n4em2bfpsq id__b5iuz413r57" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-inductionheads"><div><div><div><div><a href="https://twitter.com/inductionheads" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1641399057322000386/1WPqyV9L_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Unreal.  What was state of the art 10 months ago is now beaten by something running on a raspberry pi zero</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671347652779290624" itemprop="identifier"/><meta content="5" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:41:47.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:41:47.000Z" itemprop="datePublished"/><meta content="https://twitter.com/TheXeophon/status/1671347652779290624" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__5mofgg9rzzo id__5llhk4wp6uc id__bin6d7z1txa id__numtd9vf9wo id__fzv1vqfc55g id__lhoqkoc5nn id__s41361qlirs id__wmxm64pqdy id__l1cccdqry5h id__pjk1vz8dyim id__xqlennxxvl id__eytso7kcap id__h3xy4its5ml id__muzy9x9g62o id__kfs2sc1ron id__2vjku376zfj id__kpy0os72lg id__pyuezxrjzms" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-TheXeophon"><div><div><div><div><a href="https://twitter.com/TheXeophon" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1575944848443572227/uEQ11nR2_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>In the data pruning section (5.2) you prune w/ different AST match rates while keeping the embedding distance the same (?). Is the embedding distance you prune 0.16 as in Appendix C?</span></p></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671349550416625664" itemprop="identifier"/><meta content="6" itemprop="position"/><meta content="0" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T02:49:19.000Z" itemprop="dateCreated"/><meta content="2023-06-21T02:49:19.000Z" itemprop="datePublished"/><meta content="https://twitter.com/TheXeophon/status/1671349550416625664" itemprop="url"/><meta content="https://twitter.com/sytelus/status/1671333552204693504" itemprop="isPartOf"/><article aria-labelledby="id__50sshs3qexa id__d69uem0hino id__lvl2j3l1h5i id__agf7r6fanbg id__66maztrvoo id__55jstvx0vdk id__fjg5f76wldv id__jphgzmgjv1 id__jjwt6xj7pl id__81ws0xxp2z7 id__bwq58r14jib id__rapi0ma7jh8 id__tixb8zk8sp id__2kecx9vahy4 id__vl9wo44zh7j id__npwhpl3p82p id__rwry3j21qu id__xs3m7l6t04 id__2khjgral72i" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-TheXeophon"><div><div><div><div><a href="https://twitter.com/TheXeophon" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1575944848443572227/uEQ11nR2_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Any particular reason you used GPT-4 for labeling (to train the RF in Sec 2.1) but also use GPT3.5 for generating new Data (in Sec 2.2)? Wouldn‚Äôt a model capable of generating good synthetic data also be able to label data good enough? Or was 3.5 way worse than 4?</span></p></div></div></div></div></div></div></article></div></div><div><div><h2 aria-level="2" role="heading"><p><span>Discover more</span></p></h2><p><span>Sourced from across Twitter</span></p></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671267150101721090" itemprop="identifier"/><meta content="7" itemprop="position"/><meta content="37" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-20T21:21:53.000Z" itemprop="dateCreated"/><meta content="2023-06-20T21:21:53.000Z" itemprop="datePublished"/><meta content="https://twitter.com/soumithchintala/status/1671267150101721090" itemprop="url"/><meta content="https://twitter.com/pommedeterre33/status/1671263789914677248" itemprop="isBasedOn"/><article aria-labelledby="id__czyrf2xlhao id__4aw7vj9hb2k id__9dr38aitedg id__5nov44pp1ge id__myh190eeb id__a7hqd9zm3q id__0g5odoe7vaal id__zruofqwzjsj id__pobyckii3xe id__sy9vmtgpjzt id__f0oyn2gjzfh id__pd9c06srvbc id__89ghzhoss14 id__4ot7iieyljq id__4n6x1i6ijiw id__h90w0bdtitc id__nw07pfcmgoi id__rb8ql32h75 id__xn2ewre5wzr" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-soumithchintala"><div><div><div><div><a href="https://twitter.com/soumithchintala" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/959995586689691648/DAFep10r_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>i might have heard the same </span><span>üòÉ</span><span> -- I guess info like this is passed around but no one wants to say it out loud.
GPT-4: 8 x 220B experts trained with different data/task distributions and 16-iter inference.
Glad that Geohot said it out loud.

Though, at this point, GPT-4 is‚Ä¶</span><span tabindex="0" data-testid="tweet-text-show-more-link-1671267150101721090"><span>¬†</span><span>Show more</span></span></p></div></div><div aria-labelledby="id__6c745rzeyn2 id__g474gfmi86l" id="id__89ghzhoss14"><div id="id__6c745rzeyn2"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-pommedeterre33"><div><div><div><div><a href="https://twitter.com/pommedeterre33" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/378800000579324326/77fad234674d1f22af356706ab2b50de_400x400.jpeg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><p><span>Unexpected description of GPT4 architecture from geohotz in a recent interview he gave. At least it‚Äôs plausible.</span></p></div><div><div><div><div><div><div><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzGFjqwX0AI05GV?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671360619986010112" itemprop="identifier"/><meta content="8" itemprop="position"/><meta content="5" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T03:33:18.000Z" itemprop="dateCreated"/><meta content="2023-06-21T03:33:18.000Z" itemprop="datePublished"/><meta content="https://twitter.com/_akhaliq/status/1671360619986010112" itemprop="url"/><article aria-labelledby="id__h3cg3l7btyt id__qd6ld2t2jd id__8i8bgfqqlsv id__cxq79yx5mga id__ajn4yjpzr54 id__t0cl0no7xe id__x2adyvxta2 id__8ojb01d4gog id__3it79qebehe id__6fewg8t0tq8 id__o8niznj4y9p id__bg4odxgh7rj id__zojcxgbfoin id__k965xzlq8x id__icq9fz4pnc id__i92vsva6ezr id__tv67isgcp6p id__050yk8eplzul id__kyhz0l8q4se" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-_akhaliq"><div><div><div><div><a href="https://twitter.com/_akhaliq" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Textbooks Are All You Need

paper page: </span><a dir="ltr" href="https://t.co/D0AEOSLfGM" rel="noopener noreferrer nofollow" target="_blank" role="link"><span aria-hidden="true">https://</span>huggingface.co/papers/2306.11<span aria-hidden="true">644</span><span aria-hidden="true">‚Ä¶</span></a><span>

introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection‚Ä¶</span><span tabindex="0" data-testid="tweet-text-show-more-link-1671360619986010112"><span>¬†</span><span>Show more</span></span></p></div></div><div aria-labelledby="id__qvn388x49ko id__yjb31llutj" id="id__zojcxgbfoin"><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzHdjLJWwAE0myK?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671317900387565568" itemprop="identifier"/><meta content="9" itemprop="position"/><meta content="2" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-21T00:43:33.000Z" itemprop="dateCreated"/><meta content="2023-06-21T00:43:33.000Z" itemprop="datePublished"/><meta content="https://twitter.com/Skiminok/status/1671317900387565568" itemprop="url"/><meta content="https://twitter.com/soumithchintala/status/1671267150101721090" itemprop="isBasedOn"/><article aria-labelledby="id__gpkd1tsve87 id__nyly3c17oh8 id__8ibgxpp1h2l id__z177opl7qw id__s9d6q77hzdd id__a3mzpz00vv id__67tzvlazfgi id__7zfju2xafde id__mwaaikkffhh id__u1j9puf8lqq id__owzvowlxop id__5wds2s01wtw id__wuqtrpkmsk id__5uzsbkcnkkp id__xy7bwov5z9k id__ynec8q0c5xg id__kraltv9ljzo id__zwz9tdvgv6 id__n6buk1jogbl" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-Skiminok"><div><div><div><div><a href="https://twitter.com/Skiminok" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1021961254192082947/G_sBkQXe_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>OpenAI employees: oh no, someone leaked our model architecture details on the Internet!
Google employees:</span></p></div></div><div aria-labelledby="id__wisb36j9vkl id__qa0iw1awmo" id="id__wuqtrpkmsk"><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzG2xjYaEAImja3?format=jpg&amp;name=900x900"/></p></div></div></div></div></div></div></div></div></div><div id="id__wisb36j9vkl"><p><span>Quote Tweet</span></p><div tabindex="0"><div><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div data-testid="UserAvatar-Container-soumithchintala"><div><div><div><div><a href="https://twitter.com/soumithchintala" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/959995586689691648/DAFep10r_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div></div><div><div><div><p><span>i might have heard the same </span><img alt="üòÉ" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/1f603.svg"/><span> -- I guess info like this is passed around but no one wants to say it out loud.
GPT-4: 8 x 220B experts trained with different data/task distributions and 16-iter inference.
Glad that Geohot said it out loud.

Though, at this point, GPT-4 is‚Ä¶ twitter.com/pommedeterre33‚Ä¶</span><a href="https://twitter.com/soumithchintala/status/1671267150101721090" role="link" data-testid="tweet-text-show-more-link-1671267150101721090"><span>¬†</span><span>Show more</span></a></p></div></div></div></div></div></div></div></div></div></div></div></article></div></div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1671263789914677248" itemprop="identifier"/><meta content="10" itemprop="position"/><meta content="10" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-06-20T21:08:32.000Z" itemprop="dateCreated"/><meta content="2023-06-20T21:08:32.000Z" itemprop="datePublished"/><meta content="https://twitter.com/pommedeterre33/status/1671263789914677248" itemprop="url"/><article aria-labelledby="id__sfpb71yxsgs id__2rtwidc5rj7 id__ezrpbvv9x0k id__djr9o3675uv id__uetsst46jm id__zrt6lyaljw id__b1jy0u0as69 id__6lmtlq22fla id__44tezbrx65a id__mos2lrl0pnn id__g66o28bypc id__7hlm08g99ew id__961yu9nrew6 id__86vu93qz7p id__avjydat1cff id__urgizir4ruq id__m4mdm2xjbv8 id__wgfwghv40w id__qattpms9fr" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-pommedeterre33"><div><div><div><div><a href="https://twitter.com/pommedeterre33" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/378800000579324326/77fad234674d1f22af356706ab2b50de_400x400.jpeg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>Unexpected description of GPT4 architecture from geohotz in a recent interview he gave. At least it‚Äôs plausible.</span></p></div></div><div aria-labelledby="id__wfqwuuunyki id__m7gytgz5cl" id="id__961yu9nrew6"><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Image" data-testid="tweetPhoto"><p><img alt="Image" draggable="true" src="https://pbs.twimg.com/media/FzGFjqwX0AI05GV?format=jpg&amp;name=large"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div></section></div></div></div></div></div></div></div></div>
  </body>
</html>
