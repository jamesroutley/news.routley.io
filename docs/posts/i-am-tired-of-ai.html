<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.ontestautomation.com/i-am-tired-of-ai/">Original</a>
    <h1>I Am Tired of AI</h1>
    
    <div id="readability-page-1" class="page"><div>
      



<div id="main" role="main">
  
  



  <div>
    
      
    
    <p>Unless you have been living under a rock for the last few years, you probably have seen the same massive surge I’ve seen in the application of artificial intelligence (AI) to pretty much every problem out there, in software testing, in software development, and in life in general.</p>

<p>Now, I am all for finding and developing new solutions to existing problems, but boy, am I tired of AI, of how it is used and of how it is marketed.</p>

<p>Every tech fart smelling of ‘AI’ these days is almost instantly labeled as a ‘game changer’, only to be replaced by the next ‘pivotal’ and ‘revolutionary’ ‘solution’ the next week.</p>

<p>Yes, I realize that thinking like this and writing this make me a <a href="https://en.wikipedia.org/wiki/Neo-Luddism" target="_blank">Neo-Luddite</a> in your eyes. That’s fine. Everybody is entitled to their opinion, and this is mine. Feel free to stop reading if you’re not interested.</p>

<p>Please note that I don’t necessarily have anything against AI itself. I’m pretty sure that there are some areas where applying AI might be useful. I use AI myself, too, albeit sparingly and with caution. That doesn’t change the fact that I’m really, really tired of most of it.</p>

<p>Allow me to elaborate.</p>

<h3 id="i-am-tired-of-ai-as-a-professional-in-software-testing">I am tired of AI as a professional in software testing</h3>

<p>I’ve been working in testing, with a focus on test automation, for some 18 years now. In that time, several things have changed, but there is a lot that has remained pretty much the same. Full-stack end-to-end tests have always been the slowest and most expensive. To address that challenge, discussing testability has always been a cornerstone in enabling the writing of faster, smaller tests. After that, writing good automated tests has always required a working knowledge of good fundamental programming principles.</p>

<p>There are no shortcuts to solving these problems, it takes time and experience to tackle them. Simply throwing more tools at the problem hasn’t helped so far. Yet, that’s exactly what many ‘AI-powered test automation solutions’ and similar buzzword bingo high score contenders do.</p>

<p>If anything, these tools will produce results faster. Sometimes, that’s exactly what you’re looking for. Often, what we would really benefit from, though, is <em>better</em> results, not merely <em>faster</em> results, and I’ve not seen a lot of AI-powered tools actually produce <em>better</em> results, if any at all.</p>

<p>Again, that doesn’t mean I never use AI in my work. Of course it doesn’t. If it helps me to get a result, or a suggestion towards to result, faster than using other methods, I’ll gladly use AI to do just that. But that’s exactly what AI is: a means to produce some result of indeterminate quality and value faster. I’ll still need to apply my own knowledge and experience to determine the usefulness of a result, and often also to wrangle the output so that it is actually usable. Are those AI-generated results helpful in certain cases? Absolutely. Do I trust it enough to replace what a skilled and experienced human being does? Absolutely not.</p>

<p>But I guess that doesn’t make for sexy marketing material.</p>

<h3 id="i-am-tired-of-ai-as-a-conference-program-committee-member-and-organizer">I am tired of AI as a conference program committee member and organizer</h3>

<p>Over the last few years, I’ve had the honour of being the member of the program committee for three different conferences, and a one-off reviewer for one or two more. What I have seen in these years is a significant rise in proposals that were clearly written with the help of, or in many cases, entirely by ChatGPT or similar software.</p>

<p>Is that a bad thing? Yes, I think it is, for multiple reasons.</p>

<p>First of all, all these auto-generated proposals sound very much the same. ‘In the ever-changing world of …’. ‘Delve’. ‘Pivotal’. All words and phrases that smell suspiciously like someone used ChatGPT to write a proposal, instead of taking the time and effort to do it themselves. I don’t think that’s a great way to stand out and demonstrate your knowledge or experience of or unique take on a subject.</p>

<p>Second of all, a proposal is your first, and often only, opportunity to show use who <em>you</em> are, and what <em>your</em> experience with or opinion on a certain topic is. Why on earth would you want to outsource that opportunity to a piece of software and reduce your unique and thoughtful ideas to a piece of run-of-the-mill text that’s dull as dishwater and about as impressive?</p>

<p>Third of all, if you can’t even write a proposal yourself, why on that same earth would we as the program committee trust you to come up with a unique presentation? Or are you just going to read prompt results out loud for 40 minutes, too? I hope not, but we will not take the chance.</p>

<p>It has gotten so bad that I, for one, immediately reject a proposal when it is clear that it was written by or with the help of AI, no matter how interesting the topic is or how good of a talk you will be able to deliver in person. I’m not taking the chance if you don’t put in the effort of writing a good proposal yourself, and I am pretty confident I’m not the only conference program committee member thinking that way.</p>

<h3 id="i-am-tired-of-ai-as-a-human-being">I am tired of AI as a human being</h3>

<p>Finally, and most of all, I am tired of AI as a human being.</p>

<p>Like so many people, I love listening to good music. Reading a moving book. Watching a captivating movie. What makes these pieces of music, books and movies so attractive is the fact that they are created by human beings, and that these human beings transported their thoughts, their feelings and their emotions to the sheet music, the book manuscript or the movie script.</p>

<p>There’s no way that creative process and the result can be replicated by AI, or at least, I haven’t seen it.</p>

<p>What I have seen, though, is a <em>lot</em> of dull AI-generated posts on social media, with dull AI-generated images, and even more dull AI-generated comments.</p>

<p>I’ve seen and heard examples of texts, videos and music that were generated by AI, and while technically impressive, it doesn’t even begin to evoke the same kind of emotional reaction in me that pieces of art and other human creations can, unless you count boredom as an emotion.</p>

<p>Meanwhile…</p>

<ul>
  <li>people are scared that AI is going to take their jobs</li>
  <li>companies continue to blindly throw ridiculous sums of money towards the next AI prodigy without ever seeing a decent ROI, and</li>
  <li>AI’s carbon footprint is reaching more alarming levels every day</li>
</ul>

<p>I honestly don’t think we’re moving in the right direction this way.</p>

<p>Again, there are <em>some</em> cases where AI is used as a force for good. Early detection of diseases, for example. That’s great. That’s progress. We should definitely keep using AI to do that, and try to make it even better.</p>

<p>But I’m pretty sure I can do without all that AI-generated music, images, text, conference proposals, test cases, LinkedIn posts and so much other AI-generated nonsense.</p>



<p>&#34;
  </p></div>
</div>
    </div></div>
  </body>
</html>
