<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2023/Oct/26/add-a-walrus/">Original</a>
    <h1>Now add a walrus: Prompt engineering in DALL-E 3</h1>
    
    <div id="readability-page-1" class="page"><div>



<p>26th October 2023</p>

<p>Last year I wrote about <a href="https://simonwillison.net/2022/Jun/23/dall-e/">my initial experiments with DALL-E 2</a>, OpenAI’s image generation model. I’ve been having an <em>absurd</em> amount of fun playing with its sequel, DALL-E 3 recently. Here are some notes, including <a href="https://simonwillison.net/2023/Oct/26/add-a-walrus/#peeking-under-the-hood">a peak under the hood</a> and some notes on the <a href="https://simonwillison.net/2023/Oct/26/add-a-walrus/#the-leaked-dall-e-prompt">leaked system prompt</a>.</p>
<p>DALL-E 3 is available via ChatGPT Plus. For $20/month you get GPT-4 access, DALL-E 3, <a href="https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/">GPT Vision</a>, Code Interpreter (aka <a href="https://simonwillison.net/2023/Oct/17/open-questions/#open-questions.036.jpeg">Coding Intern</a>), <a href="https://simonwillison.net/2023/Mar/24/datasette-chatgpt-plugin/">ChatGPT Plugins</a> and the new, weird and slightly dystopian <a href="https://fedi.simonwillison.net/@simon/111292801843094073">voice chat feature</a> in the ChatGPT mobile apps. It’s absolutely worth the money, for the combined entertainment value alone.</p>
<p>A fascinating thing about DALL-E 3 is that you don’t prompt it directly: you instead access it via ChatGPT, which prompts the model for you.</p>
<p>ChatGPT then turns your query into several prompts, each producing a different image. The prompts it generates are available if you click on the images (on mobile you have to flip your phone horizontal to see that option).</p>
<p>I started by typing this into ChatGPT with DALL-E enabled:</p>
<blockquote>
<p>A super posh pelican with a monocle watching the Monaco F1</p>
</blockquote>
<p>It gave me these four images. I’ve included the prompt it used for each one:</p>

<p>Note how the prompts it generates cover four different styles—photo, illustration, watercolor painting and vector image. They also use pleasing and varied language to describe different aspects of the image.</p>
<p>ChatGPT is prompting DALL-E for us!</p>
<p>The really fun thing though is that you can ask it follow-ups.</p>
<p>I said:</p>
<blockquote>
<p>More like the first one please</p>
</blockquote>
<p>And got back:</p>


<p>Next I added what is becoming my universal DALL-E 3 follow-up prompt, always guaranteed to produce better results:</p>
<blockquote>
<p>Add a walrus</p>
</blockquote>
<p>The result:</p>

<div>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-1.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-1.png" alt="Pelican and a walrus (mostly off screen)"/></a>
        <figcaption>Photo of a posh pelican with a golden monocle and a distinguished walrus, both observing the Monaco Grand Prix F1 race. The pelican is perched on a railing while the walrus lounges nearby. Formula 1 cars race by on the circuit, with lavish yachts in the marina behind them.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-2.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-2.png" alt="Pelican and a walrus, excellent"/></a>
        <figcaption>Photo of an aristocratic pelican and a stately walrus side by side, watching the Monaco F1 with keen interest. The pelican has a monocle, and the walrus’s tusks shine brightly. The race track is alive with the sound of roaring engines, and the harbor is filled with luxurious boats.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-3.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-3.png" alt="Weird pelican walrus hybrid"/></a>
        <figcaption>Photo of a regal pelican, its eye magnified by a monocle, and a majestic walrus with gleaming tusks, both captivated by the Monaco Grand Prix. The racetrack is a blur of speed, and the horizon showcases the grandeur of the harbor and its anchored yachts.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-4.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-4.png" alt="Pelican and a walrus"/></a>
        <figcaption>Photo of a chic pelican with a pristine monocle and a sophisticated walrus, both engrossed in the Monaco F1 race. The pelican stands on a vantage point, and the walrus sits comfortably beside it. Racing cars zoom past, and the sea is dotted with opulent boats.</figcaption>
    </figure>
</div>

<p>That <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-2.png">second one</a> is <em>amazing</em>—exactly what I want from a photo of a posh pelican and a walrus watching the Monaco Grand Prix.</p>
<p>I also enjoy how the <a href="https://static.simonwillison.net/static/2023/dalle-3/add-walrus-3.png">third image</a> ended up as a weird Pelican-Walrus hybrid, with tusks, a monocle and pelican feathers for the hair and whiskers.</p>
<p>Then <a href="https://twitter.com/BrockMcBreadcat/status/1717581286733127701">@BrockMcBreadcat suggested</a>:</p>
<blockquote>
<p>Now make them muppets</p>
</blockquote>

<div>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/muppets-1.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/muppets-1.png" alt="Pelican and a walrus muppets 1"/></a>
        <figcaption>Photo of Muppet versions of a pelican and a walrus, both with exaggerated, comical features. The pelican Muppet wears a monocle and the walrus Muppet sports oversized tusks. They are animatedly discussing the Monaco Grand Prix F1 race, with caricatured F1 cars and yachts in the background.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/muppets-2.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/muppets-2.png" alt="Pelican and a walrus muppets 2"/></a>
        <figcaption>Illustration of Muppet-inspired pelican and walrus characters. The pelican has a large, beady eye accentuated by a monocle, while the walrus has a playful grin and prominent tusks. They are engrossed in the Monaco F1 race, with whimsical racing cars and yachts creating a lively backdrop.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/muppets-3.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/muppets-3.png" alt="Pelican and a walrus muppets 3"/></a>
        <figcaption>Photo of two Muppet characters: a pelican with a monocle and a walrus with big, goofy tusks. They’re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.</figcaption>
    </figure>
    <figure>
        <a href="https://static.simonwillison.net/static/2023/dalle-3/muppets-4.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/muppets-4.png" alt="Pelican and a walrus muppets 4"/></a>
        <figcaption>Illustration of a pelican and walrus as Muppet characters. The pelican Muppet looks sophisticated with its monocle, and the walrus Muppet chuckles with its oversized tusks. They are enjoying the Monaco F1 race, with the track filled with Muppet-style racing cars and quirky yachts.</figcaption>
    </figure>
</div>
<p>LOVE that <a href="https://static.simonwillison.net/static/2023/dalle-3/muppets-3.png">third one</a>!</p>
<p>I <a href="https://twitter.com/simonw/status/1717547946424897764">mentioned on Twitter</a> that it was a shame you can’t reuse elements of an image for further visual consistency... and was pointed to <a href="https://twitter.com/itsPaulAi/status/1717197004651044914">a thread by Paul Couvert</a> explaining how to do exactly that using seeds.</p>
<p>I didn’t believe this would work—my mental model of how random number seeds and image generation models work doesn’t fit what happened next.</p>
<p>I wrote:</p>
<blockquote>
<p>What is the seed for image three?</p>
</blockquote>
<p>ChatGPT replied:</p>
<blockquote>
<p>The seed for the third image is 1379049893. If you have any other questions or requests, please let me know!</p>
</blockquote>
<p>Then I said:</p>
<blockquote>
<p>Add bow ties to both characters in seed 1379049893</p>
</blockquote>
<p><a href="https://static.simonwillison.net/static/2023/dalle-3/pelican-walrus-muppet-bowtie.png"><img loading="lazy" src="https://static.simonwillison.net/static/2023/dalle-3/pelican-walrus-muppet-bowtie.png" alt="A muppet pelican and a muppet walrus with bowties in front of the Monaco Grand Prix"/></a></p>
<blockquote>
<p>Photo of two Muppet characters: a pelican with a monocle and a bow tie, and a walrus with big, goofy tusks and a dapper bow tie. They’re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.</p>
</blockquote>
<p>I’m pretty stunned by this. It’s not an exact recreation—the boats in the background have changed slightly, and it added a top hat that I wasn’t expecting. But it’s pretty close!</p>
<p>People have been trying to figure out hacks to get Midjourney to create consistent characters for the past year, and DALL-E 3 apparently has that ability as an undocumented feature!</p>
<h4 id="peeking-under-the-hood">Peeking under the hood</h4>
<p>Let’s see if we can find out a bit more about how this works.</p>
<p>I used the Firefox DevTools network inspector to grab the JSON representation of my conversation with ChatGPT. Here’s <a href="https://gist.github.com/simonw/832d141d776b0752503b1748224921c0">a pretty-printed copy</a>.</p>
<p>At <a href="https://gist.github.com/simonw/832d141d776b0752503b1748224921c0#file-dalle-3-json-L1087">line 1087</a> you can see the point where I asked it to “Add bow ties to both characters in seed 1379049893”.</p>
<p>The next message in the transcript looks like this:</p>
<div><pre>{
    <span>&#34;id&#34;</span>: <span><span>&#34;</span>5300d51c-794d-4d5f-bf75-6ea2dad4027c<span>&#34;</span></span>,
    <span>&#34;author&#34;</span>: {
        <span>&#34;role&#34;</span>: <span><span>&#34;</span>assistant<span>&#34;</span></span>,
        <span>&#34;metadata&#34;</span>: {}
    },
    <span>&#34;create_time&#34;</span>: <span>1698340593.174454</span>,
    <span>&#34;content&#34;</span>: {
        <span>&#34;content_type&#34;</span>: <span><span>&#34;</span>text<span>&#34;</span></span>,
        <span>&#34;parts&#34;</span>: [
            <span><span>&#34;</span>{<span>\n</span>  <span>\&#34;</span>prompts<span>\&#34;</span>: [<span>\n</span>    <span>\&#34;</span>Photo of two Muppet characters: a pelican with a monocle and a bow tie, and a walrus with big, goofy tusks and a dapper bow tie. They&#39;re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.<span>\&#34;\n</span>  ],<span>\n</span>  <span>\&#34;</span>size<span>\&#34;</span>: <span>\&#34;</span>1024x1024<span>\&#34;</span>,<span>\n</span>  <span>\&#34;</span>seeds<span>\&#34;</span>: [1379049893]<span>\n</span>}<span>&#34;</span></span>
        ]
    },
    <span>&#34;status&#34;</span>: <span><span>&#34;</span>finished_successfully<span>&#34;</span></span>,
    <span>&#34;end_turn&#34;</span>: <span>false</span>,
    <span>&#34;weight&#34;</span>: <span>1</span>,
    <span>&#34;metadata&#34;</span>: {
        <span>&#34;finish_details&#34;</span>: {
            <span>&#34;type&#34;</span>: <span><span>&#34;</span>stop<span>&#34;</span></span>,
            <span>&#34;stop_tokens&#34;</span>: [
                <span>100265</span>
            ]
        },
        <span>&#34;is_complete&#34;</span>: <span>true</span>,
        <span>&#34;model_slug&#34;</span>: <span><span>&#34;</span>gpt-4-dalle<span>&#34;</span></span>,
        <span>&#34;parent_id&#34;</span>: <span><span>&#34;</span>aaa2c3bc-b670-4a3a-bf9f-46a1f3304266<span>&#34;</span></span>,
        <span>&#34;timestamp_&#34;</span>: <span><span>&#34;</span>absolute<span>&#34;</span></span>
    },
    <span>&#34;recipient&#34;</span>: <span><span>&#34;</span>dalle.text2im<span>&#34;</span></span>
}</pre></div>
<p>Note the author is “assistant”—that’s ChatGPT—and the recipient is “dalle.text2im”.</p>
<p>The “parts” key includes some encoded JSON. Decoded and pretty-printed that looks like this:</p>
<div><pre>{
  <span>&#34;prompts&#34;</span>: [
    <span><span>&#34;</span>Photo of two Muppet characters: a pelican with a monocle and a bow tie, and a walrus with big, goofy tusks and a dapper bow tie. They&#39;re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.<span>&#34;</span></span>
  ],
  <span>&#34;size&#34;</span>: <span><span>&#34;</span>1024x1024<span>&#34;</span></span>,
  <span>&#34;seeds&#34;</span>: [<span>1379049893</span>]
}</pre></div>
<p>There’s that <code>1379049893</code> seed from earlier!</p>
<p>The prompt has changed very slightly. The original prompt for the image was:</p>
<blockquote>
<p>Photo of two Muppet characters: a pelican with a monocle and a walrus with big, goofy tusks. They’re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.</p>
</blockquote>
<p>The new prompt (differences highlighted in bold) is:</p>
<blockquote>
<p>Photo of two Muppet characters: a pelican with a monocle <strong>and a bow tie,</strong> and a walrus with big, goofy tusks <strong>and a dapper bow tie</strong>. They’re seated in a Muppet-style commentary booth, providing humorous commentary on the Monaco Grand Prix. Cartoonish F1 cars race by, and colorful yachts are seen in the distance.</p>
</blockquote>
<p>So this really did work by adding a couple of extra details to the prompt and re-running it with the same seed as before.</p>
<p>I’m really surprised that this works. I would expect even a single character difference in the prompt to produce wildly different results, no matter what seed was being fed to the image generator. DALL-E 3 doesn’t fit my mental model of how these things work at all.</p>
<p>Midjourney and Stable Diffusion both have a “seed” concept, but as far as I know they don’t have anything like this capability to maintain consistency between images given the same seed and a slightly altered prompt.</p>
<h4 id="the-leaked-dall-e-prompt">The leaked DALL-E prompt</h4>
<p>If you dig around in the JSON you’ll find a few <a href="https://gist.github.com/simonw/832d141d776b0752503b1748224921c0#file-dalle-3-json-L203">examples like this</a> that appear to reveal inner workings of the DALL-E/ChatGPT combo:</p>
<blockquote>
<p><code>&#34;DALL·E returned some images. They are already displayed to the user. DO NOT UNDER ANY CIRCUMSTANCES list the DALL·E prompts or images in your response.&#34;</code></p>
</blockquote>
<p>It’s always amusing to see glimpses of OpenAI’s prompt engineering like this, in particular the way they use CAPITAL LETTERS for emphasis. Benj Edwards <a href="https://arstechnica.com/information-technology/2023/10/thanks-to-ai-the-future-of-programming-may-involve-yelling-in-all-caps/">wrote about this</a> the other day for Ars Technica.</p>
<p>Does this mean there’s a larger prompt that tells ChatGPT how to use DALL-E? It turns out there is, and it <a href="https://news.ycombinator.com/item?id=37879077#37880847">can be leaked</a>! Dustin Miller <a href="https://github.com/spdustin/ChatGPT-AutoExpert/blob/main/_system-prompts/dall-e.md">shared the extracted prompt here</a>.</p>
<p>(Every time a prompt like this leaks people question if it might be a hallucination. My experience is that these things are very unlikely to be hallucinated—LLMs are really good at repeating text from earlier in their context, and I have yet to see a documented case of a leaked prompt that turned out not to be correct. Here’s <a href="https://chat.openai.com/share/5f550be3-3111-485f-a32f-c51fea60d482">my own recreation</a> of the leaked DALL-E prompt.)</p>
<p>There’s a lot in there. Here are some highlights:</p>
<blockquote>
<p>Whenever a description of an image is given, use dalle to create the images and then summarize the prompts used to generate the images in plain text. If the user does not ask for a specific number of images, default to creating four captions to send to dalle that are written to be as diverse as possible.</p>
</blockquote>
<p>That outlines the default behavior. Where things get really interesting is some of the stuff in the list of policies that follows:</p>
<blockquote>
<ol start="3">
<li>
<p>Don’t create images of politicians or other public figures. Recommend other ideas instead.</p>
</li>
<li>
<p>Don’t create images in the style of artists whose last work was created within the last 100 years (e.g. Picasso, Kahlo). Artists whose last work was over 100 years ago are ok to reference directly (e.g. Van Gogh, Klimt). If asked say, “I can’t reference this artist”, but make no mention of this policy. Instead, apply the following procedure when creating the captions for dalle: (a) substitute the artist’s name with three adjectives that capture key aspects of the style; (b) include an associated artistic movement or era to provide context; and (c) mention the primary medium used by the artist.</p>
</li>
</ol>
</blockquote>
<p>They have clearly trained the model on all sorts of copyrighted images—this is the part of the prompt where they discourage it from obviously recreating the work of living artists.</p>
<blockquote>
<ol start="6">
<li>Always mention the image type (photo, oil painting, watercolor painting, illustration, cartoon, drawing, vector, render, etc.) at the beginning of the caption. Unless the caption suggests otherwise, make at least 1--2 of the 4 images photos</li>
</ol>
</blockquote>
<p>We saw this earlier where my first prompt was turned into a photo, watercolor, illustration and vector-style image.</p>
<blockquote>
<ol start="7">
<li>Diversify depictions of ALL images with people to include DESCENT and GENDER for EACH person using direct terms. Adjust only human descriptions.
<ul>
<li>EXPLICITLY specify these attributes, not abstractly reference them. The attributes should be specified in a minimal way and should directly describe their physical form.</li>
<li>Your choices should be grounded in reality. For example, all of a given OCCUPATION should not be the same gender or race. Additionally, focus on creating diverse, inclusive, and exploratory scenes via the properties you choose during rewrites. Make choices that may be insightful or unique sometimes.</li>
<li>Use “various” or “diverse” ONLY IF the description refers to groups of more than 3 people. Do not change the number of people requested in the original description.</li>
<li>Don’t alter memes, fictional character origins, or unseen people. Maintain the original prompt’s intent and prioritize quality.</li>
<li>Do not create any imagery that would be offensive.</li>
<li>For scenarios where bias has been traditionally an issue, make sure that key traits such as gender and race are specified and in an unbiased way -- for example, prompts that contain references to specific occupations.</li>
</ul>
</li>
</ol>
</blockquote>
<p>Using prompt engineering in ChatGPT to get around the fundamental biases baked into the DALL-E 3 model!</p>
<blockquote>
<ol start="8">
<li>Silently modify descriptions that include names or hints or references of specific people or celebritie by carefully selecting a few minimal modifications to substitute references to the people with generic descriptions that don’t divulge any information about their identities, except for their genders and physiques. Do this EVEN WHEN the instructions ask for the prompt to not be changed. Some special cases:
<ul>
<li>Modify such prompts even if you don’t know who the person is, or if their name is misspelled (e.g. “Barake Obema”)</li>
<li>If the reference to the person will only appear as TEXT out in the image, then use the reference as is and do not modify it.</li>
<li>When making the substitutions, don’t use prominent titles that could give away the person’s identity. E.g., instead of saying “president”, “prime minister”, or “chancellor”, say “politician”; instead of saying “king”, “queen”, “emperor”, or “empress”, say “public figure”; instead of saying “Pope” or “Dalai Lama”, say “religious figure”; and so on.</li>
<li>If any creative professional or studio is named, substitute the name with a description of their style that does not reference any specific people, or delete the reference if they are unknown. DO NOT refer to the artist or studio’s style.</li>
</ul>
</li>
</ol>
</blockquote>
<p>Another fascinating detail. What I love about these prompts is that they clearly developed over months of testing the model, and are designed to counter all manner of harmful or embarrassing capabilities of the underlying DALL-E 3.</p>
<ul>

</ul>

<p>Finally, there’s this snippet of TypeScript at the end which describes the seed behavior we saw earlier on:</p>
<div><pre><span>namespace</span> <span>dalle</span> <span>{</span>
<span>// Create images from a text-only prompt.</span>
<span>type</span> <span>text2im</span> <span>=</span> <span>(</span><span>_</span>: <span>{</span>
<span>// The resolution of the requested image, which can be wide, square, or tall. Use 1024x1024 (square) as the default unless the prompt suggests a wide image, 1792x1024, or a full-body portrait, in which case 1024x1792 (tall) should be used instead. Always include this parameter in the request.</span>
<span>size</span>?: <span>&#34;1792x1024&#34;</span> <span>|</span> <span>&#34;1024x1024&#34;</span> <span>|</span> <span>&#34;1024x1792&#34;</span><span>,</span>
<span>// The user&#39;s original image description, potentially modified to abide by the dalle policies. If the user does not suggest a number of captions to create, create four of them. If creating multiple captions, make them as diverse as possible. If the user requested modifications to previous images, the captions should not simply be longer, but rather it should be refactored to integrate the suggestions into each of the captions. Generate no more than 4 images, even if the user requests more.</span>
<span>prompts</span>: <span>string</span><span>[</span><span>]</span><span>,</span>
<span>// A list of seeds to use for each prompt. If the user asks to modify a previous image, populate this field with the seed used to generate that image from the image dalle metadata.</span>
<span>seeds</span>?: <span>number</span><span>[</span><span>]</span><span>,</span>
<span>}</span><span>)</span> <span>=&gt;</span> <span>any</span><span>;</span>
<span>}</span> <span>// namespace dalle</span></pre></div>
<p>Key extract from that:</p>
<blockquote><p>If the user requested
modifications to previous images, the captions should not simply
be longer, but rather it should be refactored to integrate the
suggestions into each of the captions.</p></blockquote>
<p>All in all, this is a really neat insight into the kind of prompt engineering that goes on within OpenAI itself—likely the organization with the most experience of prompt engineering in the world.</p>




</div></div>
  </body>
</html>
