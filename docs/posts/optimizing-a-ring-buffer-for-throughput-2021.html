<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rigtorp.se/ringbuffer/">Original</a>
    <h1>Optimizing a ring buffer for throughput (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
				<p>In this article I will take a look at the classic concurrent ring buffer and how
it can be optimized to increase throughput. I will show you how to significantly
increase throughput from 5.5M items/s to 112M items/s, beating the
<a href="https://www.boost.org/">Boost</a> and <a href="https://github.com/facebook/folly">Folly</a>
implementations. If you need a ready implementation with these optimizations
checkout my <a href="https://github.com/rigtorp/SPSCQueue"><em>SPSCQueue.h</em> library</a>.</p>
<p>The ringer buffer data structure is also referred to as a circular buffer or
single producer single consumer (SPSC) queue. It’s a wait-free (hence also
lock-free) concurrency primitive. It has a lot of uses for example it’s used to
communicate network packets between NICs and OS drivers and to receive I/O
completion events in the recently introduced
<a href="https://lwn.net/Articles/776703/"><em>io_uring</em></a> asynchronous I/O API.</p>
<h2 id="the-classic-ring-buffer">The classic ring buffer</h2>
<p>First let’s start by implementing a simple ring buffer. In C++ it can be defined
like this:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>ringbuffer</span> <span>{</span>
  <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>data_</span><span>;</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>readIdx_</span><span>{</span><span>0</span><span>};</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>writeIdx_</span><span>{</span><span>0</span><span>};</span>

  <span>ringbuffer</span><span>(</span><span>size_t</span> <span>capacity</span><span>)</span> <span>:</span> <span>data_</span><span>(</span><span>capacity</span><span>,</span> <span>0</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div><p>In this implementation I chose to allow any queue size as opposed to allowing
only sizes that are a power-of-two. This means that at least one queue item is
unused in order to disambiguate between the empty queue and full queue state.
You can choose to require a power-of-two size to avoid this if memory is at a
premium.</p>
<p>Another important thing to note is that read (<code>readIdx_</code>) and write
(<code>writeIdx_</code>) indices are aligned to the size of a cache line (<code>alignas(64)</code>).
This is done to reduce cache coherency traffic. On AMD64 / x86_64 and ARM a
cache line is 64 bytes, on other CPUs you need to adjust to the appropriate
alignment, using
<a href="https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size"><code>std::hardware_destructive_interference_size</code></a>
is a good choice if it’s available. It can also be interesting to try aligning
to a multiple of the cache line size in case adjacent cache lines are being
pre-fetched.</p>
<p>This is quite similar to how <em>io_uring</em> defines its ring buffer inside the Linux
kernel:</p>
<div><pre><code data-lang="c"><span>struct</span> <span>io_uring</span> <span>{</span>
  <span>u32</span> <span>head</span> <span>____cacheline_aligned_in_smp</span><span>;</span>
  <span>u32</span> <span>tail</span> <span>____cacheline_aligned_in_smp</span><span>;</span>
<span>};</span>
</code></pre></div><p><a href="https://www.boost.org/doc/libs/1_76_0/doc/html/boost/lockfree/spsc_queue.html"><em>boost::lockfree::spsc</em></a>
also defines it’s ring buffer in pretty much the same way.</p>
<p>We can now implement the push (or write) operation:</p>
<div><pre><code data-lang="cpp"><span>bool</span> <span>push</span><span>(</span><span>int</span> <span>val</span><span>)</span> <span>{</span>
  <span>auto</span> <span>const</span> <span>writeIdx</span> <span>=</span> <span>writeIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>
  <span>auto</span> <span>nextWriteIdx</span> <span>=</span> <span>writeIdx</span> <span>+</span> <span>1</span><span>;</span>
  <span>if</span> <span>(</span><span>nextWriteIdx</span> <span>==</span> <span>data_</span><span>.</span><span>size</span><span>())</span> <span>{</span>
    <span>nextWriteIdx</span> <span>=</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>nextWriteIdx</span> <span>==</span> <span>readIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span> <span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span>
  <span>data_</span><span>[</span><span>writeIdx</span><span>]</span> <span>=</span> <span>val</span><span>;</span>
  <span>writeIdx_</span><span>.</span><span>store</span><span>(</span><span>nextWriteIdx</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
  <span>return</span> <span>true</span><span>;</span>
<span>}</span>
</code></pre></div><p>Note how one item is left unused to indicate that the queue is full, when
<code>writeIdx_</code> is one item behind <code>readIdx_</code> the queue is full.</p>
<p>Next we implement the pop (or read) operation:</p>
<div><pre><code data-lang="cpp"><span>bool</span> <span>pop</span><span>(</span><span>int</span> <span>&amp;</span><span>val</span><span>)</span> <span>{</span>
  <span>auto</span> <span>const</span> <span>readIdx</span> <span>=</span> <span>readIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>
  <span>if</span> <span>(</span><span>readIdx</span> <span>==</span> <span>writeIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span> <span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span>
  <span>val</span> <span>=</span> <span>data_</span><span>[</span><span>readIdx</span><span>];</span>
  <span>auto</span> <span>nextReadIdx</span> <span>=</span> <span>readIdx</span> <span>+</span> <span>1</span><span>;</span>
  <span>if</span> <span>(</span><span>nextReadIdx</span> <span>==</span> <span>data_</span><span>.</span><span>size</span><span>())</span> <span>{</span>
    <span>nextReadIdx</span> <span>=</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>readIdx_</span><span>.</span><span>store</span><span>(</span><span>nextReadIdx</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
  <span>return</span> <span>true</span><span>;</span>
<span>}</span>
</code></pre></div><p>Again note that <code>readIdx_ == writeIdx_</code> indicates that the queue is empty.</p>
<p>I chose a very small item size (<code>sizeof(int) == 4</code>) since for large item sizes
the performance will be dominated by the memory copying of the items and the
goal is not to measure the performance of <code>memcpy()</code>. This of course also means
that if you have large items you don’t have much to gain from optimizing your
ring buffer.</p>
<p>Now lets analyze the performance of this queue. I wrote <a href="https://rigtorp.se/ringbuffer.cpp">a simple benchmark
<code>ringbuffer.cpp</code></a> that pushes 100M items between 2 threads
through a ring buffer of size 100k. Measuring how long it takes until the reader
thread has read all items. Compile <a href="https://rigtorp.se/ringbuffer.cpp"><code>ringbuffer.cpp</code></a> as
follows:</p>
<div><pre><code data-lang="shell">g++ -Wall -O3 -march<span>=</span>native -std<span>=</span>c++20 ringbuffer.cpp
</code></pre></div><p>I ran this on a AMD Ryzen 9 3900X 12-Core Processor
placing the two threads on different chiplets / core complexes (CCX):</p>
<pre><code data-lang="console">$ perf stat -e cache-misses,cache-references,l2_request_g1.change_to_x ./a.out 1 11
5513850 ops/s

 Performance counter stats for &#39;./a.out 1 11&#39;:

       349,857,603      cache-misses:u            #   91.228 % of all cache refs    
       383,497,078      cache-references:u                                          
         6,673,242      l2_request_g1.change_to_x:u                                   

      18.137421039 seconds time elapsed

      36.140630000 seconds user
       0.002986000 seconds sys

</code></pre><p>We see here that we achieved a throughput of 5.5M items per second. This is in
line with the performance you will see from libraries such as
<a href="https://www.boost.org/doc/libs/1_76_0/doc/html/boost/lockfree/spsc_queue.html"><em>boost::lockfree::spsc</em></a>
and
<a href="https://github.com/facebook/folly/blob/master/folly/docs/ProducerConsumerQueue.md"><em>folly::ProducerConsumerQueue</em></a>.
The number of cache misses (~300M) seems to be proportional (3x) to the number
of items (100M) that were processed.</p>
<h2 id="the-optimized-ring-buffer">The optimized ring buffer</h2>
<p>Why do we have 3 cache misses per read-write pair? Consider a read operation:
the read index needs to be updated and thus that cache line is loaded into the
L1 cache in exclusive state (see <a href="https://en.wikipedia.org/wiki/MESI_protocol">MESI
protocol</a>). The write index needs
to be read in order to check that the queue is not empty and is thus loaded into
the L1 cache in shared state. Since a queue write operation needs to read the
read index it causes the reader’s read index cache line to be evicted or
transition into shared state. Now the read operation requires some cache
coherency traffic to bring the read index cache line back into exclusive state.
In turn a write operation will require some cache coherency traffic to bring the
write index cache line back into exclusive state. In the worst case there will
be one cache line transition from shared to exclusive for every read and write
operation. These cache line state transitions are counted as cache misses. We
don’t know the exact implementation details of the cache coherency protocol, but
it will behave roughly as the MESI protocol.</p>
<p>To reduce the amount of coherency traffic the reader and writer can keep a
cached copy of the write and read index respectively. In this case when a reader
first observes that <em>N</em> items are available to read, it caches this information
and the <em>N-1</em> subsequent reads won’t need to read the write index. Similarly
when a writer first observes that <em>N</em> items are available for writing, it caches
this information and the <em>N-1</em> subsequent writes won’t need to read the read
index.</p>
<p>The new ring buffer is defined as follows:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>ringbuffer2</span> <span>{</span>
  <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>data_</span><span>{};</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>readIdx_</span><span>{</span><span>0</span><span>};</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>size_t</span> <span>writeIdxCached_</span><span>{</span><span>0</span><span>};</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>writeIdx_</span><span>{</span><span>0</span><span>};</span>
  <span>alignas</span><span>(</span><span>64</span><span>)</span> <span>size_t</span> <span>readIdxCached_</span><span>{</span><span>0</span><span>};</span>

  <span>ringbuffer2</span><span>(</span><span>size_t</span> <span>capacity</span><span>)</span> <span>:</span> <span>data_</span><span>(</span><span>capacity</span><span>,</span> <span>0</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div><p>The push operation is updated to first consult the cached read index
(<code>readIdxCached_</code>) and if that fails retry after updating the cache:</p>
<div><pre><code data-lang="cpp"><span>if</span> <span>(</span><span>nextWriteIdx</span> <span>==</span> <span>readIdxCached_</span><span>)</span> <span>{</span>
  <span>readIdxCached_</span> <span>=</span> <span>readIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>);</span>
  <span>if</span> <span>(</span><span>nextWriteIdx</span> <span>==</span> <span>readIdxCached_</span><span>)</span> <span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>The pop operation is updated in a similar way to first consult the cached write
index (<code>writeIdxCached_</code>):</p>
<div><pre><code data-lang="cpp"><span>if</span> <span>(</span><span>readIdx</span> <span>==</span> <span>writeIdxCached_</span><span>)</span> <span>{</span>
  <span>writeIdxCached_</span> <span>=</span> <span>writeIdx_</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>);</span>
  <span>if</span> <span>(</span><span>readIdx</span> <span>==</span> <span>writeIdxCached_</span><span>)</span> <span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Re-running the same benchmark as before with the new ring buffer implementation:</p>
<pre><code data-lang="console">$ perf stat -e cache-misses,cache-references,l2_request_g1.change_to_x ./a.out 1 11
112287037 ops/s

 Performance counter stats for &#39;./a.out 1 11&#39;:

        15,010,392      cache-misses:u            #   32.553 % of all cache refs    
        46,110,663      cache-references:u                                          
         6,781,273      l2_request_g1.change_to_x:u                                   

       0.892256380 seconds time elapsed

       1.775185000 seconds user
       0.000996000 seconds sys

</code></pre><p>Wow this is great! Throughput is now 112M items per second and the number of
cache misses was significantly reduced. Checkout
<a href="https://rigtorp.se/ringbuffer.cpp"><code>ringbuffer.cpp</code></a> if you want to verify this yourself.</p>
<h2 id="further-optimizations">Further optimizations</h2>
<p>Supporting batched push and pop operations can reduce the number of times the
read and write indices needs to be updated to less than once per item.</p>
<p>Using huge pages for the ring buffer backing memory can reduce TLB misses.</p>

			</div></div>
  </body>
</html>
