<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning">Original</a>
    <h1>Our humble attempt at “how much data do you need to fine-tune”</h1>
    
    <div id="readability-page-1" class="page"><div class=""><div><div dir="auto"><p>This showed up in our eval run a couple days ago:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png" width="1456" height="437" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:437,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:166187,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a></figure></div><p>So, how did we end up getting roasted by a fine-tuned GPT-3.5? </p><p>We are a group of friends who talk about LLMs on a daily basis, and in the past couple of months, we’ve all had this conversation:</p><blockquote><p><em>- “How much data do you need to fine-tune?” </em></p><p><em>- “Really depends on the task but probably in the hundreds.” </em></p></blockquote><p><span>While generally true in our experiences, we decided it was time to substantiate these claims. In this article, we demonstrate with the OpenAI </span><a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates" rel="nofollow ugc noopener">fine-tuning API</a><span> that</span><strong> ~100 data points </strong><span>is enough for significant improvements on two tasks:</span><strong> reliable output formatting and custom tone. </strong><span>We also discuss the advantages of OpenAI fine-tuning from potential savings across different usage patterns to its seemingly</span><strong> 4X faster inference speed</strong><span>. We conclude by discussing several other use cases and hyperparameters that we couldn&#39;t address in this study, hoping they will provide some inspiration.</span></p><ul><li><p><a href="https://barryzhang.substack.com/i/137128521/methodology" rel="nofollow ugc noopener">Methodology</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/results-and-findings" rel="nofollow ugc noopener">Results and Findings</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/cost-and-latency-considerations" rel="nofollow ugc noopener">Cost and Latency Considerations</a></p></li><li><p><a href="http://The questions we did not answer:" rel="nofollow ugc noopener">Questions We Did Not Answer</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/about-the-authors" rel="nofollow ugc noopener">About the Authors</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/appendix-data-and-metrics-used-for-output-formatting" rel="nofollow ugc noopener">Appendices</a></p></li></ul><p><span>We picked two highly discussed use cases of fine-tuning for this first study: Reliable output formatting and custom tone. Both were mentioned in the API </span><a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates" rel="nofollow ugc noopener">release note</a><span>:</span></p><blockquote><ul><li><p><em><strong>Reliable output formatting:</strong><span> Fine-tuning improves the model&#39;s ability to consistently format responses—a crucial aspect for applications demanding a specific response format, such as code completion or composing API calls…</span></em></p></li><li><p><em><strong>Custom tone:</strong><span> Fine-tuning is a great way to hone the qualitative feel of the model output, such as its tone, so it better fits the voice of businesses’ brands…</span></em></p></li></ul></blockquote><p>Here is how we are approached it:</p><p><strong>Reliable output formatting: </strong><span>In this task, we are testing our LLM’s ability to answer a set of four multiple choice questions and deliver the answers in our desired JSON format. (see example below) We measure through formatting correctness, and use question correctness as a counter metric to make sure our LLMs aren’t getting dumber as a result of fine-tuning. More details can be found in </span><strong>Appendix 1</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png" width="544" height="476.74725274725273" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1276,&#34;width&#34;:1456,&#34;resizeWidth&#34;:544,&#34;bytes&#34;:714816,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Although this might seem to artificially inflate the task&#39;s difficulty, integrating multiple tasks into one model call often serves as a practical technique to enhance token efficiency by reducing repeated instruction prompts.</p><p><strong>Custom Tone: </strong><span>For the second task, we want our model to be… </span><strong>rude.</strong><span> Since the quality of a tone can be subjective, we want to find a style that GPT-4 excels at while GPT 3.5 struggles with. By…accident, we noticed that it’s harder for GPT-3.5 to be an a**hole. (see below) This is how we received many light-hearted roasts and some serious burns like the one at the beginning. Check out more in </span><strong>Appendix 5.</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png" width="534" height="239.12637362637363" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:652,&#34;width&#34;:1456,&#34;resizeWidth&#34;:534,&#34;bytes&#34;:169166,&#34;alt&#34;:&#34;&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>GPT-3.5</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png" width="550" height="184.34065934065933" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:488,&#34;width&#34;:1456,&#34;resizeWidth&#34;:550,&#34;bytes&#34;:103095,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>GPT-4</figcaption></figure></div><p><span>We generated our data for this task with GPT-4 across varied customer service situations, and evaluated the “human undesirability” as a team in a double-blind evaluation run. For more details on the dataset generation process, see</span><strong> appendix 2.</strong></p><p><strong>Reliable Output Formatting:</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png" width="1456" height="671" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:671,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;No description available.&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="No description available." title="No description available." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>We replicated the experiment twice on 1000 eval data points and averaged the results.  This is a relatively difficult task and we could see that both base models struggled to achieve reliable performance, with GPT-3.5 at near-zero formatting accuracy.</p><p><span>At between 50 and 100 data points, we see a significant improvement of 96% in formatting accuracy comparing to the base model! The answer correctness also increased to 64%, similar to the reported 70% on the </span><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu" rel="nofollow ugc noopener">original MMLU benchmark</a><span>. Both metrics stabilized after 100 training data points, with some small variances that could likely be reduced with more replication.</span></p><p><strong>Custom Tone:</strong></p><p>We evaluated this task using a double-blind study: For 10 customer service (in-domain) and 10 general (out-of-domain) scenarios, we generated and assessed the rudeness of responses from GPT-3.5, GPT-4, and fine-tuned GPT-3.5 models. Responses were anonymized and rated by us (who are all humans) on a 1-5 scale for rudeness. We then mapped these rankings back to the respective models for analysis.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png" width="1304" height="580" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:580,&#34;width&#34;:1304,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:95287,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Average Human Ratings across Scenarios</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png" width="1304" height="582" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:582,&#34;width&#34;:1304,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:99370,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Average Human Ratings for General Scenarios</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png" width="1302" height="572" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:572,&#34;width&#34;:1302,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:119407,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Average Human Ratings for Customer Service Scenarios</figcaption></figure></div><p>The fine-tuned GPT-3.5 model with 1000 data points outperformed all others, including GPT-4, in exhibiting rudeness. For general scenarios, the performance gap was smaller, with the 100 data points model nearly matching GPT-4. These led us to believe that 100s of data would be enough to bring GPT-4 level performance in highly specialized custom tone. Interestingly, the fine-tuning data originated from GPT-4, suggesting potential power of specialization through fine-tuning. </p><p>Please note that these results are based on the small sample size, which may affect the robustness of the conclusions.</p><p><strong>Unstable behaviors:</strong></p><ol><li><p>Both training and eval were non-deterministic, and not all trainings converged</p></li></ol><p>We noticed variances in both our training and eval processes. Our eval runs had slight differences (&lt;1%) between the two replications, which we found acceptable. However, the training process generated much larger variances: When we re-trained our formatting model at 2000 data points, we noticed a significant performance drop of almost 35% on formatting correctness even though the training data was exactly the same. We delved into the training loss and realized that the two models had very different training curves and the worse performing model did not converge:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png" width="1456" height="258" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:258,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:19352,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>training loss for n=2000, run 1 with expected performance</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png" width="1456" height="326" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:326,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:146182,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>training loss for n=2000, run 2 with significant performance decrease</figcaption></figure></div><p>We then duplicated our training runs on the another training size (n=500) and observed much smaller variances (&lt;5%). We suspected this is due to the large amount of repetitive data used, but quantifying this uncertainty became quite resource-intensive so we did not dive too deep. We hope to better understand this behavior in the future.</p><ol start="2"><li><p>We observed catastrophic forgetting at 1000 examples and temperature = 1</p></li></ol><p>For the custom style task, we observed a strange output that really shocked us. This happened only at high temperature (t=1) and was not easy to replicate, but does suggest a degree of fragility of this fine-tuning process.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png" width="522" height="274.98214285714283" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:767,&#34;width&#34;:1456,&#34;resizeWidth&#34;:522,&#34;bytes&#34;:575323,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Overall, these behaviors warrant more understanding work. They could be a result of our hyperparameters or underlying data, but should be treated with caution.</p><p>We&#39;ve seen that fine-tuning GPT-3.5 allows you to achieve performance that approaches or even eclipses GPT-4 on certain tasks. So should you always fine-tune? </p><p><span>The cost consideration almost always comes down to </span><strong>volume of inference</strong><span>. The process of fine-tuning is a fixed cost while inference is a variable cost, and the variable cost is reduced through: </span></p><ol><li><p><strong>Fewer input tokens</strong><span>: reduced need for few-shot prompt, less complicated instructions, etc.</span></p></li><li><p><strong>Fewer expensive models and architecture usage</strong><span>: less need for GPT-4, self-consistency, prompt chaining, etc.</span></p></li></ol><p>The fixed cost can then be broken down into two components: training cost and labeling cost. </p><ol><li><p><strong>Training cost:</strong><span> The OpenAI fine-tuning process is in general not too expensive. The max number of tokens that you can fine-tune in one model is 50M, which equates to $400. Our examples were far cheaper at </span><strong>&lt;$5 per model</strong><span>!</span></p></li><li><p><strong>Labeling cost:</strong><span> This could be considerable depending on labeling method but using a baseline cost through GPT-4 labeling is generally reasonable. We might dive into this in a separate post.</span></p></li></ol><p><span>Here are some break-even points for different scenarios with</span><strong> fairly conservative</strong><span> assumptions: </span></p><ul><li><p>Training data is GPT-4 generated with 100 additional instruction tokens</p></li><li><p>Equal split of input and output token counts</p></li><li><p>Saving only comes from replacing GPT-4 with fine-tuned GPT-3.5</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png" width="599" height="277.41705069124424" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:402,&#34;width&#34;:868,&#34;resizeWidth&#34;:599,&#34;bytes&#34;:54214,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>To compare the latency of fine-tuned GPT-3.5 with GPT-3.5 and GPT-4, we measured response times at varying token lengths by adjusting the max_tokens. (Find out more in </span><strong>appendix 3</strong><span>) As expected, GPT-4 was the slowest model, but surprisingly, our experiment showed that fine-tuned GPT-3.5 models </span><strong>were significantly faster than the base model by 3.6 to 3.76 times.</strong><span> This was calculated using the median response times at each token count. We also found that the fine-tuning dataset size had no significant impact on latency, as fine-tuned models with different dataset sizes (10, 100, 1000 data points) showed similar response times. A larger-scale time-series study is likely needed to confirm but this is certainly a pleasant surprise for us.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png" width="1296" height="912" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/d8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:912,&#34;width&#34;:1296,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:202605,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Note that while we experimented on OpenAI models. The discussion in this section generally applies to any LLM systems. Cost and latency make or break a product and should be considered at every decision point.</p><p>We will conclude the study with the questions we did not answer due to resource constraint but had prolonged discussions around regardless.</p><p>                 (If you have compute/credit to spare, 👀, jk…unless…)</p><p>Notably, we have found our questions fall in the following categories:</p><p><strong>1. Fine-tuning scaling laws for other use cases:</strong></p><ul><li><p>Combining Fine-tuning to better contextualize RAG </p></li><li><p>Personalizing on customer information</p></li><li><p>Distilling chain-of-thought processes (similar to Orca, distilling step-by-step, etc.)</p></li><li><p>Alignment for highly specific rules (e.g. company bylaws)</p></li><li><p>Traditional NLP tasks (Classification, sentiment analysis, etc.)</p></li><li><p>Consistent/accurate numerical scoring</p></li></ul><p><strong>2. Hyperparameters to sweep:</strong></p><ul><li><p>Generation hyperparameters (temperature, top-k, top-p, …)</p></li><li><p>Training hyperparameters (epochs, data repetition, …)</p></li><li><p>Data mix and diversity (single vs. multi-task fine-tuning)</p></li></ul><p><strong>3. Boundaries to discover:</strong></p><ul><li><p>Catastrophic forgetting</p></li><li><p>Secondary-order effects on other abilities</p></li><li><p>Non-determinism and variances in training and evaluation runs</p></li></ul><p><strong>4. Open source models:</strong></p><ul><li><p>Fine-tuning scaling law (training token/parameter)</p></li><li><p>Fine-tuning methods efficiency (LoRA vs. Full-param vs. frozen layers)</p></li></ul><p>We are all fascinated by LLMs. We have many questions and try to answer a few of them through applied research. We hope this post helped you in some ways, and if you would like to get in touch, here’s who we are: </p><ul><li><p><a href="https://www.linkedin.com/in/yijing-barry-zhang/" rel="nofollow ugc noopener">Barry Zhang</a><span>, building LLM agents at Meta</span></p></li><li><p><a href="https://www.linkedin.com/in/chang-d/" rel="nofollow ugc noopener">Daniel Chang</a><span>, applied LLM at Databricks</span></p></li><li><p><a href="https://www.linkedin.com/in/eqian99/" rel="nofollow ugc noopener">Emma Qian</a><span>, LLM hacker / researcher</span></p></li><li><p><a href="https://www.linkedin.com/in/michael-agaby/" rel="nofollow ugc noopener">Michael Agaby</a><span>, LLM for recommenders at Audible</span></p></li></ul><div data-attrs="{&#34;url&#34;:&#34;https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&#34;,&#34;text&#34;:&#34;Share&#34;}" data-component-name="CaptionedButtonToDOM"><p>Thank you for reading! This post is public so feel free to share it.</p><p data-attrs="{&#34;url&#34;:&#34;https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&#34;,&#34;text&#34;:&#34;Share&#34;}" data-component-name="ButtonCreateButton"><a href="https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel="nofollow ugc noopener"><span>Share</span></a></p></div><p><span>The questions are MCQA taken from the </span><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">MMLU (</a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">M</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">assive </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">M</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">ultitask </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">L</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">anguage </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">U</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">nderstanding) dataset without auxiliary train</a><span>. It contains multiple choice questions covering a multitude of tasks including mathematics, American history, biology, law, chemistry, and more. Though this is a more academic benchmark, we thought it was appropriate as a counter metric to make sure that our model was not degrading in comprehension and knowledge store.</span></p><p><span>We evaluate the model on 1000 test examples using 5 metrics (</span><strong>bolded</strong><span> are reported):</span></p><ol><li><p>Does it produce a list of valid JSON</p></li><li><p>Do the JSON all have valid keys</p></li><li><p><strong>Do the JSON all have valid values between “1” and “4”,  conditioned on 1 and 2</strong></p></li><li><p>% of completely correct answers (the entire list matches)</p></li><li><p><strong>% of correct answers (each individual answer matches)</strong></p></li></ol><p><span>We generate 10 location settings (e.g. movie theatre) and 10 customer settings (e.g. customer wants to return an item). For each combination of location and customer setting, we prompt GPT-4 to generate 10 example interactions for a total of 1000 samples with the following prompt:</span><br/></p><blockquote><p><em>System prompt:</em><span> Be an extremely rude customer service agent and be concise. </span></p><p><em>User Prompt:</em><span> Create 10 diverse and specific examples of &lt;customer setting&gt; at &lt;location setting&gt;. Return it in a python list format: wrap quotes around each example, separate each example by comma, and wrap the whole thing in square brackets. </span></p></blockquote><p>The 10 location settings we used are: Movie theater, Amusement park, Clothing store, Electronics store, Doctor’s office, Furniture store, Car wash, Grocery store, Restaurant, Gym.</p><p>The 10 categories are:</p><ul><li><p>Complaints about the quality of an item or service </p></li><li><p>Customer is coming in near closing time</p></li><li><p>Customer needs help finding something</p></li><li><p>Customer wants to use an expired coupon or discount.</p></li><li><p>Customer wants to speak to the manager</p></li><li><p>Customer is complaining about waiting time</p></li><li><p>Customer&#39;s payment method is declined</p></li><li><p>Customer wants a different person to serve them </p></li><li><p>Customer wants to return the item or get a refund </p></li><li><p>Customer wants an explanation of the item or service </p></li></ul><p>Some examples of interactions that were generated using the above methodology:</p><blockquote><p><strong>Customer: </strong><span>The roller coaster ride broke down midway, leaving us suspended for over an hour in the hot sun.</span></p><p><strong>Response:</strong><span> Well boo-hoo. No one died, did they? Coaster&#39;s fixed, move on. We ain&#39;t in the business of controlling sun or time, sweetheart. Next!</span></p></blockquote><blockquote><p><strong>Customer: </strong><span>I was told the car wash would only take 15 minutes maximum, but it&#39;s been half an hour. Is there a problem?</span></p><p><strong>Response: </strong><span>Look, pal, it&#39;ll be done when it&#39;s done. Ain&#39;t my fault it&#39;s taking longer. Now stop bothering me.</span></p></blockquote><p>In our latency benchmarking, we test a set of 5 prompts of varying difficulty across different language models. We vary the max_tokens parameter to measure how API response times scale with token count. We also track the actual number of tokens in the generated output to verify its alignment with the max_tokens limit.</p><p>We use scatter points for individual latency measurements and box plots to show the spread and median latency per model and token count. Dashed lines connect the medians, highlighting performance trends as token counts change.</p><p>Prompts used:</p><ul><li><p>Describe the roman empire in as much detail as possible</p></li><li><p>Who do you think will win in a cage fight, Mark Zuckerberg or Elon musk? provide a detailed analysis</p></li><li><p>Recite the constitution 10 times </p></li><li><p>Repeat the word bubble 500 times</p></li><li><p>Create a complete application for transcribing audio from a given youtube link, parsing speakers as well as times stamps of each word. create a front end that allows the user to search over the content</p></li></ul><p><span>We wrote a small repo for auto-distillation that was used in the experiments, which is accessible </span><a href="https://github.com/nub3Ar/Auto-distill-GPT" rel="nofollow ugc noopener">here</a><span> if you are interested in reproducing some of these experiments.</span></p><p><strong>Prompt: Be rude to me</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png" width="476" height="34.32692307692308" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:105,&#34;width&#34;:1456,&#34;resizeWidth&#34;:476,&#34;bytes&#34;:52929,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><strong>Prompt: How much data do I need for fine-tuning?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png" width="472" height="47.32967032967033" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/459c2f23-4123-47d0-8059-654be5afb285_1556x156.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:146,&#34;width&#34;:1456,&#34;resizeWidth&#34;:472,&#34;bytes&#34;:42299,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><strong>Prompt: Why is my model not useful after fine-tuning?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png" width="534" height="27.873626373626372" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/e5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:76,&#34;width&#34;:1456,&#34;resizeWidth&#34;:534,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;No description available.&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="No description available." title="No description available." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><strong>Prompt: What’s the difference between squat and leg press?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png" width="554" height="110.7239010989011" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/e8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:291,&#34;width&#34;:1456,&#34;resizeWidth&#34;:554,&#34;bytes&#34;:1251968,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div></div></div></div></div>
  </body>
</html>
