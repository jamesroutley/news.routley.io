<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/">Original</a>
    <h1>AI assisted search-based research works now</h1>
    
    <div id="readability-page-1" class="page"><div>


<div data-permalink-context="/2025/Apr/21/ai-assisted-search/">
<h2>AI assisted search-based research actually works now</h2>
<p>21st April 2025</p>



<p>For the past two and a half years the feature I’ve most wanted from LLMs is the ability to take on search-based research tasks on my behalf. We saw the first glimpses of this back in early 2023, with Perplexity (first launched <a href="https://en.wikipedia.org/wiki/Perplexity_AI">December 2022</a>, first prompt leak <a href="https://simonwillison.net/2023/Jan/22/perplexityai/">in January 2023</a>) and then the GPT-4 powered Microsoft Bing (which launched/cratered spectacularly <a href="https://simonwillison.net/2023/Feb/15/bing/">in February 2023</a>). Since then a whole bunch of people have taken a swing at this problem, most notably <a href="https://gemini.google.com/">Google Gemini</a> and <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT Search</a>.</p>
<p>Those 2023-era versions were promising but very disappointing. They had a strong tendency to hallucinate details that weren’t present in the search results, to the point that you couldn’t trust anything they told you.</p>
<p>In this first half of 2025 I think these systems have finally crossed the line into being genuinely useful.</p>

<ul>
  <li><a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/#deep-research-from-three-different-vendors">Deep Research, from three different vendors</a></li>
  <li><a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/#o3-and-o4-mini-are-really-good-at-search">o3 and o4-mini are really good at search</a></li>
  <li><a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/#google-and-anthropic-need-to-catch-up">Google and Anthropic need to catch up</a></li>
  <li><a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/#lazily-porting-code-to-a-new-library-version-via-search">Lazily porting code to a new library version via search</a></li>
  <li><a href="https://simonwillison.net/2025/Apr/21/ai-assisted-search/#how-does-the-economic-model-for-the-web-work-now-">How does the economic model for the Web work now?</a></li>
</ul>

<h4 id="deep-research-from-three-different-vendors">Deep Research, from three different vendors</h4>
<p>First came the <strong>Deep Research</strong> implementations—<a href="https://blog.google/products/gemini/google-gemini-deep-research/">Google Gemini</a> and <a href="https://openai.com/index/introducing-deep-research/">then OpenAI</a> and <a href="https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research">then Perplexity</a> launched products with that name and they were all impressive: they could take a query, then churn away for several minutes assembling a lengthy report with dozens (sometimes hundreds) of citations. Gemini’s version had a <em>huge</em> upgrade a few weeks ago when they <a href="https://blog.google/products/gemini/deep-research-gemini-2-5-pro-experimental/">switched it to using Gemini 2.5 Pro</a>, and I’ve had some outstanding results from it since then.</p>
<p>Waiting a few minutes for a 10+ page report isn’t my ideal workflow for this kind of tool. I’m impatient, I want answers faster than that!</p>
<h4 id="o3-and-o4-mini-are-really-good-at-search">o3 and o4-mini are really good at search</h4>
<p>Last week, OpenAI released <a href="https://openai.com/index/introducing-o3-and-o4-mini/">search-enabled o3 and o4-mini</a> through <a href="https://chatgpt.com/">ChatGPT</a>. On the surface these look like the same idea as we’ve seen already: LLMs that have the option to call a search tool as part of replying to a prompt.</p>
<p>But there’s one <em>very significant</em> difference: these models can run searches as part of the chain-of-thought reasoning process they use before producing their final answer.</p>
<p>This turns out to be a <em>huge</em> deal. I’ve been throwing all kinds of questions at ChatGPT (in o3 or o4-mini mode) and getting back genuinely useful answers grounded in search results. I haven’t spotted a hallucination yet, and unlike prior systems I rarely find myself shouting &#34;no, don’t search for <em>that</em>!&#34; at the screen when I see what they’re doing.</p>
<p>Here are four recent example transcripts:</p>
<ul>
<li><a href="https://chatgpt.com/share/6805758b-acc8-8006-88a3-bdd78866ee15">Get me specs including VRAM for RTX 5090 and RTX PRO 6000—plus release dates and prices</a></li>
<li><a href="https://chatgpt.com/share/68057580-02c8-8006-8ff4-7ae3ce816342">Find me a website tool that lets me paste a URL in and it gives me a word count and an estimated reading time</a></li>
<li><a href="https://chatgpt.com/share/6805756c-4268-8006-82ab-014f7c304622">Figure out what search engine ChatGPT is using for o3 and o4-mini</a></li>
<li><a href="https://chatgpt.com/share/6805755b-4aa0-8006-ab0b-42ae569da6a8">Look up Cloudflare r2 pricing and use Python to figure out how much this (screenshot of dashboard) costs</a></li>
</ul>
<p>Talking to o3 feels like talking to a Deep Research tool in real-time, without having to wait for several minutes for it to produce an overly-verbose report.</p>
<p>My hunch is that doing this well requires a very strong reasoning model. Evaluating search results is hard, due to the need to wade through huge amounts of spam and deceptive information. The disappointing results from previous implementations usually came down to the Web being full of junk.</p>
<p>Maybe o3, o4-mini and Gemini 2.5 Pro are the first models to cross the gullibility-resistance threshold to the point that they can do this effectively?</p>
<h4 id="google-and-anthropic-need-to-catch-up">Google and Anthropic need to catch up</h4>
<p>The user-facing <a href="https://gemini.google.com/">Google Gemini app</a> can search too, but it doesn’t show me what it’s searching for. As a result, I just don’t trust it. This is a big missed opportunity since Google presumably have by far the best search index, so they really should be able to build a great version of this. And Google’s AI assisted search on their regular search interface hallucinates <em>wildly</em> to the point that it’s actively damaging their brand. I just checked and Google is still showing slop <a href="https://simonwillison.net/2024/Dec/29/encanto-2/">for Encanto 2</a>!</p>
<p>Claude also finally <a href="https://simonwillison.net/2025/Mar/20/">added web search</a> a month ago but it doesn’t feel nearly as good. It’s <a href="https://simonwillison.net/2025/Mar/21/anthropic-use-brave/">using the Brave search index</a> which I don’t think is as comprehensive as Bing or Gemini, and searches don’t happen as part of that powerful reasoning flow.</p>
<h4 id="lazily-porting-code-to-a-new-library-version-via-search">Lazily porting code to a new library version via search</h4>
<p>The truly magic moment for me came <a href="https://simonwillison.net/2025/Apr/18/gemini-image-segmentation/#gemini-2-5-flash-non-thinking">a few days ago</a>.</p>
<p>My <a href="https://simonwillison.net/2025/Apr/18/gemini-image-segmentation/">Gemini image segmentation tool</a> was using the <a href="https://www.npmjs.com/package/@google/generative-ai">@google/generative-ai</a> library which has been <a href="https://github.com/google-gemini/deprecated-generative-ai-js">loudly deprecated</a> in favor of the still in preview <a href="https://github.com/googleapis/js-genai">Google Gen AI SDK @google/genai</a> library.</p>
<p>I did <strong>not</strong> feel like doing the work to upgrade. On a whim, I pasted <a href="https://github.com/simonw/tools/blob/aa310a4f9cde07d5e8e87572f70fceca532884dd/gemini-mask.html">my full HTML code</a> (with inline JavaScript) into ChatGPT o4-mini-high and prompted:</p>
<blockquote>
<p><code>This code needs to be upgraded to the new recommended JavaScript library from Google. Figure out what that is and then look up enough documentation to port this code to it.</code></p>
</blockquote>
<p>(I couldn’t even be bothered to look up the name of the new library myself!)</p>
<p>... it did <a href="https://chatgpt.com/share/68028f7b-11ac-8006-8150-00c4205a2507">exactly that</a>. It churned away thinking for 21 seconds, ran a bunch of searches, figured out the new library (which existed <em>way</em> outside of its training cut-off date), found the <a href="https://ai.google.dev/gemini-api/docs/migrate">upgrade instructions</a> and produced <a href="https://github.com/simonw/tools/commit/d199de213dc3f866a3b8efbcdd2dde34204dc409">a new version</a> of my code that worked perfectly.</p>
<p><img src="https://static.simonwillison.net/static/2025/o4-thinking.jpg" alt="Screenshot of AI assistant response about upgrading Google Gemini API code. Shows &#34;Thought for 21 seconds&#34; followed by web search results for &#34;Google Gemini API JavaScript library recommended new library&#34; with options including Google AI for Developers, GitHub, and Google for Developers. The assistant explains updating from GoogleGenerativeAI library to @google-ai/generative, with code samples showing: import { GoogleGenAI } from &#39;https://cdn.jsdelivr.net/npm/@google/genai@latest&#39;; and const ai = new GoogleGenAI({ apiKey: getApiKey() });"/></p>
<p>I ran this prompt on my phone out of idle curiosity while I was doing something else. I was <em>extremely</em> impressed and surprised when it did exactly what I needed.</p>
<h4 id="how-does-the-economic-model-for-the-web-work-now-">How does the economic model for the Web work now?</h4>
<p>I’m writing about this today because it’s been one of my “can LLMs do this reliably yet?” questions for over two years now. I think they’ve just crossed the line into being useful as research assistants, without feeling the need to check <em>everything</em> they say with a fine-tooth comb.</p>
<p>I still don’t trust them not to make mistakes, but I think I might trust them enough that I’ll skip my own fact-checking for lower-stakes tasks.</p>
<p>This also means that a bunch of the potential dark futures we’ve been predicting for the last couple of years are a whole lot more likely to become true. Why visit websites if you can get your answers directly from the chatbot instead?</p>
<p>The lawsuits over this <a href="https://simonwillison.net/2023/Dec/31/ai-in-2023/#ethics-diabolically-complex">started flying</a> back when the LLMs were still mostly rubbish. The stakes are a lot higher now that they’re actually good at it!</p>
<p>I can feel my usage of Google search taking a nosedive already. I expect a bumpy ride as a new economic model for the Web lurches into view.</p>


</div>


</div></div>
  </body>
</html>
