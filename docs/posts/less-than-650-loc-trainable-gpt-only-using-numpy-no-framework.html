<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/joennlae/tensorli">Original</a>
    <h1>Show HN: less than 650 LOC trainable GPT only using NumPy (no framework)</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/joennlae/tensorli/blob/main/logo.png"><img src="https://github.com/joennlae/tensorli/raw/main/logo.png" alt="logo" width="200"/></a></p><h3 tabindex="-1" dir="auto"><a id="user-content-minimalistic-implementation-of-a-gpt-like-transformer-using-only-numpy-650-lines" aria-hidden="true" tabindex="-1" href="#minimalistic-implementation-of-a-gpt-like-transformer-using-only-numpy-650-lines"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>
Minimalistic implementation of a GPT-like transformer using only numpy (&lt;650 lines).
</h3>
</div>
<hr/>
<p dir="auto">The implementation includes:</p>
<ul dir="auto">
<li>Automatic differentiation</li>
<li><code>Tensorli</code> object (PyTorch like)</li>
<li>Simple NN layers: <code>Linearli</code>, <code>Embeddingli</code>, <code>MultiheadAttentionli</code>, <code>LayerNorm</code></li>
<li>Optimizers: <code>Adamli</code></li>
</ul>
<p dir="auto">All that is &#34;needed&#34; to train and execute a GPT-like transformer model.</p>
<p dir="auto"><em><code>...and everything else is just efficiency</code></em> ~ Andrej Karpathy<sup><a href="#myfootnote1">1</a></sup>.</p>
<p dir="auto"><a name="user-content-myfootnote1">1</a>: <a href="https://youtu.be/VMj-3S1tku0?si=6qISQdXUKBSMOy3Z&amp;t=474" rel="nofollow">Youtube - micrograd</a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-example" aria-hidden="true" tabindex="-1" href="#example"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<div dir="auto" data-snippet-clipboard-copy-content="from tensorli.tensorli import Tensorli
from tensorli.models.transformerli import Transformerli

vocb_size, embd_dim, seq_len, n_layer, n_head, batch_size = 10, 64, 10, 3, 4, 16

transformer = Transformerli(vocb_size, embd_dim, seq_len, n_layer, n_head)

x_numpy = np.random.randint(0, vocb_size - 1, size=(batch_size, seq_len))
x = Tensorli(x_numpy)

out = transformer(x)"><pre><span>from</span> <span>tensorli</span>.<span>tensorli</span> <span>import</span> <span>Tensorli</span>
<span>from</span> <span>tensorli</span>.<span>models</span>.<span>transformerli</span> <span>import</span> <span>Transformerli</span>

<span>vocb_size</span>, <span>embd_dim</span>, <span>seq_len</span>, <span>n_layer</span>, <span>n_head</span>, <span>batch_size</span> <span>=</span> <span>10</span>, <span>64</span>, <span>10</span>, <span>3</span>, <span>4</span>, <span>16</span>

<span>transformer</span> <span>=</span> <span>Transformerli</span>(<span>vocb_size</span>, <span>embd_dim</span>, <span>seq_len</span>, <span>n_layer</span>, <span>n_head</span>)

<span>x_numpy</span> <span>=</span> <span>np</span>.<span>random</span>.<span>randint</span>(<span>0</span>, <span>vocb_size</span> <span>-</span> <span>1</span>, <span>size</span><span>=</span>(<span>batch_size</span>, <span>seq_len</span>))
<span>x</span> <span>=</span> <span>Tensorli</span>(<span>x_numpy</span>)

<span>out</span> <span>=</span> <span>transformer</span>(<span>x</span>)</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-naming" aria-hidden="true" tabindex="-1" href="#naming"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Naming</h2>
<p dir="auto">In the region where I grew up, a word for &#34;little&#34; is used as a suffix [<a href="https://de.wikipedia.org/wiki/-li" rel="nofollow">2</a>]. For example, &#34;little dog&#34; would be &#34;dogli&#34;. I thought it would be a nice name for a minimalistic implementation of a neural network library.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-caveats" aria-hidden="true" tabindex="-1" href="#caveats"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Caveats</h3>
<p dir="auto">This library works, but it is NOT optimized. It is not meant to be used in production or for anything at scale. It is meant to be used as a learning tool.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-inspiration" aria-hidden="true" tabindex="-1" href="#inspiration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Inspiration</h2>
<p dir="auto">This library is heavily inspired by the following projects:</p>
<ul dir="auto">
<li><a href="https://github.com/karpathy/minGPT">minGPT</a></li>
<li><a href="https://github.com/tinygrad/tinygrad">tinygrad</a></li>
</ul>
<p dir="auto">I highly recommend checking them out.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-plans--outlook" aria-hidden="true" tabindex="-1" href="#plans--outlook"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Plans &amp; Outlook</h3>
<ul>
<li> Add Dropout</li>
<li> Add more experimental architectures</li>
</ul>
</article>
          </div></div>
  </body>
</html>
