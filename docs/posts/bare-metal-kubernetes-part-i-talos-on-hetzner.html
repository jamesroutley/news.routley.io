<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-1-talos-on-hetzner/">Original</a>
    <h1>Bare-Metal Kubernetes, Part I: Talos on Hetzner</h1>
    
    <div id="readability-page-1" class="page"><div>
        
	  <p>I&#39;ve been running a Kubernetes cluster on a mix of virtual and bare metal machines with Hetzner for about a year now, and while the setup has served me well, being a very exploratory exercise at the time it wasn&#39;t very well documented.</p>
<p>To rectify this, and to get a chance to play with some tools I wasn&#39;t aware of at the time, I&#39;ve decided to rebuild the cluster from scratch and document the process through these posts.</p>
<p>I have a rough sketch of the end product on my mind, which I plan to materialize through these steps/posts:</p>
<ul>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-1-talos-on-hetzner/">Part I: Talos on Hetzner</a></strong>
Covers provisioning of the first server, installation of Talos Linux and configuration and bootstrapping</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-2-cilium-and-firewalls/">Part II: Cilium CNI &amp; Firewalls</a></strong> Choosing a CNI and implementing network policies and firewall rules without locking ourselves out.</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-3-encrypted-gitops-with-fluxcd/">Part III: Encrypted GitOps with FluxCD</a></strong> Keeping track of deployed resources with FluxCD, using <a href="https://github.com/mozilla/sops">SOPS</a> to store encrypt secrets in-repository.</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-4-ingress-dns-certificates/">Part IV: Ingress, DNS and Certificates</a></strong> Installing an ingress controller (nginx), DNS controller (external-dns), and certificate manager for automating routing.</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-5-scaling-out/">Part V: Scaling Out</a></strong> A single node does not a cluster make! Time to scale the cluster up to 3 nodes</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-6-persistent-storage-with-rook-ceph/">Part VI: Persistent Storage with Rook Ceph</a></strong> With 3 nodes and 6 available disks, we&#39;re finally eligible to store data long term, which we&#39;ll need going forward.</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-7-private-registry-with-harbor/">Part VII: Private Registry with Harbor</a></strong> Persistent storage allows us to store and cache the images we use, so let&#39;s!</p>
</li>
<li>
<p><strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-8-containerizing-our-work-environment/">Part VIII: Containerizing our Work Environment</a></strong> Compile our entire working environment into a single image to make upgrades easy.</p>
</li>
</ul>
<p>Complete source code for the live cluster is available <a href="https://github.com/MathiasPius/kronform">@github/MathiasPius/kronform</a></p>

<p>I&#39;ve deployed Kubernetes clusters in a myriad ways over the years, with all sorts of combinations of k8s|k3s|k0s using kubeadm|<a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">the hard way</a>|managed(EKS &amp; Exoscale) packaged using both Docker and Hashicorp&#39;s Packer and deployed with Ansible or Terraform, or more recently <a href="https://syself.com/">syself</a>&#39;s <a href="https://github.com/syself/cluster-api-provider-hetzner">Cluster API Provider for Hetzner</a>.</p>
<p>My conclusion at this point is that if you can afford it, both in terms of privacy/GDPR and dollarinos then <em>managed</em> is the way to go. If you can&#39;t, then you have a bit of investigative work ahead of you.</p>
<p>All of the different tools I&#39;ve tried have seemed great on paper, but usually had some annoying trade-off or caveat.</p>
<p>For <a href="https://www.packer.io/">Packer</a> and <a href="https://www.terraform.io/">Terraform</a> it&#39;s state management. Building static virtual machine images for all your control plane and worker nodes sounds great in theory, but you have to put those images <em>somewhere</em>. Kubernetes clusters are also not pure idempotent structures, even if they largely aspire to be. Handling cluster bootstrapping, node joining, etc. in Terraform is borderline impossible, not because Terraform is a bad tool, but because it is so far outside the realm of what it&#39;s designed to do. Terraform is about desired state, but you can&#39;t &#34;desire&#34; your way into bootstrapping a distributed system unless someone has hidden all the nitty gritty details from you behind a managed service.</p>
<p>For Cluster API and its providers, the issue is more of a me-problem than a them-problem. It&#39;s a very flexible setup, which is what allows it to work across so many providers and scenarios, even ones that make no effort to provide any kind of official Kubernetes support like Hetzner, or your own desktop Raspberry Pi cluster. All aspects of the cluster itself are managed through Kubernetes and Custom Resource Definitions, which is cool in its own right, but if you dig into the sausage of the Hetzner provider, you&#39;ll realize it&#39;s a tower built on <em>bash</em>. None of this should by any means disqualify it from use, but my experience with it was one of confusion. It did everything it should, but it was at times really hard to follow <em>why</em> it was doing what it did, or how. Like I said, I&#39;m really impressed with their work otherwise and Cluster API might be the future, so it&#39;s probably a me-problem.</p>
<p>For <a href="https://k3s.io/">k3s</a>, <a href="https://k0sproject.io/">k0s</a> and all the other minimal Kubernetes distributions the problem is <em>alignment</em>. They&#39;re able to achieve their streamlined deployment and setup stories by making a lot of difficult decisions for you, which is great as long as your values align with theirs, otherwise you have to compromise, hack or turn back.</p>
<p>Talos Linux of course suffers the same curse as k3s and k0s, taking the decision-making to the extreme and choosing even the kernel for you. Fortunately however, their choices align perfectly with my needs and values. I really like the philosophy of container-oriented distributions and have previously dabbled in <a href="https://www.flatcar.org/">Flatcar Container Linux</a>, but at least at the time I found it very difficult to get working on Hetzner&#39;s bare metal servers, although the exact reasons elude me at this time.</p>
<p>Having read through the documentation for Talos Linux, I really like their approach to node and cluster configuration. It&#39;s very similar to the way Cluster API approaches it, but by owning the underlynig Linux distribution and not relying on existing tools like kubeadm to interact with the cluster, they get to radically simplify the interface exposed to the administrator, which makes it at least <em>look</em> like a very pleasant experience.</p>
<p>Based on that very subjective feeling, my past experience, and of course a healthy dose of grass always being greener, Talos Linux is my choice for this cluster.</p>

<p>Their <a href="https://www.talos.dev/v1.4/introduction/quickstart/">Quickstart</a> and <a href="https://www.talos.dev/v1.4/introduction/getting-started/">Getting Started</a> guides can get you started with a local Docker-based cluster, or with installing it on one of the supported providers, but deploying it to a Hetzner dedicated server takes some extra steps.</p>
<p>We can&#39;t provide the dedicated server with a custom ISO to boot from, but we can boot into Hetzner&#39;s rescue system and write the Talos ISO directly to a hard drive which means that next time we reboot the server (providing no other disks have valid boot configurations and take precedence) our server will boot into an unconfigured Talos instance running in Maintenance mode. This was the script I used to install Talos v1.4.4 onto my dedicated server from the Linux rescue system:</p>
<pre data-lang="bash"><code data-lang="bash"><span># I&#39;m intentionally picking a version that&#39;s behind by patch version so I 
</span><span># can try out the upgrade procedure once it&#39;s up and running.
</span><span>TALOS_VERSION</span><span>=&#34;</span><span>v1.4.4</span><span>&#34;
</span><span># Keep in mind that device paths might change between reboots so either
</span><span># double-check the device path, or use one of the udev paths instead.
</span><span>TARGET_DISK</span><span>=&#34;</span><span>/dev/sda</span><span>&#34;
</span><span>
</span><span># Download the release asset designed for (bare) metal deployments.
</span><span>wget -O</span><span> /tmp/talos.tar.gz https://github.com/siderolabs/talos/releases/download/$</span><span>TALOS_VERSION</span><span>/metal-amd64.tar.gz
</span><span># Unpack the archive 
</span><span>tar -xvf</span><span> /tmp/talos.tar.gz
</span><span># Write the raw disk image directly to the hard drive.
</span><span>dd</span><span> if=disk.raw of=$</span><span>TARGET_DISK </span><span>&amp;&amp; </span><span>sync
</span><span>shutdown -r</span><span> now
</span></code></pre>
<p>After a while the server should come back up, so let&#39;s see if it worked by using the <code>talosctl</code> command line utility to interact with the (hopefully up) talos API on the node:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> -n</span><span> 159.69.60.182 disks</span><span> --insecure
</span><span>error</span><span> getting disks: rpc error: code = Unavailable desc = connection error: desc = &#34;</span><span>transport: Error while dialing: dial tcp 159.69.60.182:50000: i/o timeout</span><span>&#34;
</span></code></pre>
<p>Curious! The server doesn&#39;t respond on the Talos API endpoint, looks like something went wrong.</p>
<p>Activating the Hetzner vKVM rescue system and forcing a hardware reset boots the server, and I can see the Talos interface. It even responds to my requests now:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> -n</span><span> 159.69.60.182 disks</span><span> --insecure
</span><span>DEV</span><span>        MODEL            TYPE    MODALIAS      SIZE     BUS_PATH       SYSTEM_DISK
</span><span>/dev/sda</span><span>   QEMU HARDDISK    HDD     scsi:t-0x00   2.0 TB   .../0:0:0:0/      
</span><span>/dev/sdb</span><span>   QEMU HARDDISK    HDD     scsi:t-0x00   2.0 TB   .../1:0:0:0/      
</span><span>/dev/sdc</span><span>   QEMU HARDDISK    HDD     scsi:t-0x00   256 GB   .../2:0:0:0/   *
</span></code></pre>
<p><small>output truncated to fit</small></p>
<p>I&#39;ve run into problems magically being solved by Hetzner&#39;s <a href="https://docs.hetzner.com/robot/dedicated-server/virtualization/vkvm/">vKVM system</a> before, so I&#39;m not convinced we&#39;re out of the woods yet. If we can boot the system without the vKVM system, I&#39;ll put it down to a random fluke and continue configuration.</p>
<p>After another hardware reset (without the rescue system) Talos is still responding to our requests. I&#39;m still not sure of the cause, but let&#39;s get on with it.</p>

<p>In order to build a Kubernetes cluster from Talos, you must first configure Talos. This is done in two steps, first by generating a <code>talosconfig</code> which similarly to <code>kubeconfig</code> contains the definition of a collection of Talos endpoints and credentials to access them with. With Kubernetes you generally configure the cluster first and then extract the kubeconfig, but with Talos, you instead generate the configuration first and then <em>imprint</em> it on the individual nodes.</p>
<p>Following along in the <a href="https://www.talos.dev/v1.4/introduction/getting-started/">Getting Started</a> guide we first have to decide on a cluster name and endpoint. My intention is to run this cluster purely on bare metal, so I don&#39;t want to put a load balancer in front of the cluster, although that particular configuration was worked well for me in the past. I want to get as close to a DIY setup as I can, so it can potentially be migrated or extended to on-premise at a later date. For the same reason, and because of the high cost associated with it, using vSwitch and floating IPs is off the table as well.</p>
<p>I&#39;ve chosen to use DNS load balancing, since I don&#39;t expect a lot of churn in control plane/talos nodes, nor heavy load.</p>
<h2 id="cluster-name-and-endpoint"><a href="#cluster-name-and-endpoint" aria-label="Anchor link for: cluster-name-and-endpoint">Cluster Name and Endpoint</a></h2>
<p>Let&#39;s start by exporting our cluster name and endpoint for future reference. I&#39;ve picked the clustername &#34;kronform&#34; semi-arbitrarily, and will be using it as a subdomain of one of my existing domains to access it.</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> export CLUSTER_NAME=&#34;</span><span>kronform</span><span>&#34;
</span><span>[mpd@ish]$</span><span> export API_ENDPOINT=&#34;</span><span>https://api.kronform.pius.dev:6443</span><span>&#34;
</span></code></pre>
<h2 id="dns"><a href="#dns" aria-label="Anchor link for: dns">DNS</a></h2>
<p>Create the DNS record pointing to our one node, so it has a chance to propagate by the time we&#39;ll need it.</p>
<p><img src="https://datavirke.dk/posts/bare-metal-kubernetes-part-1-talos-on-hetzner/dns-configuration.png" alt="DNS Configuration"/></p>
<p>I&#39;ve configured both IPv4 and IPv6 and set a low time-to-live, so if a node dies and has to be removed from the cluster in the future, its address should get cleared out of most DNS caches relatively quickly.</p>
<h2 id="secrets"><a href="#secrets" aria-label="Anchor link for: secrets">Secrets</a></h2>
<p>First we need to generate a secrets bundle which contains all the sensitive keys used to define our cluster:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl gen secrets</span><span> --output-file</span><span> secrets.yaml
</span></code></pre>
<p>We&#39;ll need to keep this file safe, but won&#39;t be able commit it to git until we have a method of encrypting it.</p>
<h2 id="talosconfig"><a href="#talosconfig" aria-label="Anchor link for: talosconfig">talosconfig</a></h2>
<p>Generate the <code>talosconfig</code> based on the cluster name and endpoint specified earlier.</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl gen config  \
</span><span>    --with-secrets</span><span> secrets.yaml \
</span><span>    --output-types</span><span> talosconfig  \
</span><span>    --output</span><span> talosconfig        \
</span><span>    $</span><span>CLUSTER_NAME               </span><span>\
</span><span>    $</span><span>API_ENDPOINT
</span></code></pre>
<p>I&#39;m not entirely sure why the API endpoint is required at this stage since it doesn&#39;t seem to figure in the generated <code>talosconfig</code> and the endpoint specified is just <code>127.0.0.1</code>. Meanwhile the provided <code>$CLUSTER_NAME</code> is used to name the context, so that at least makes sense:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span>context</span><span>: </span><span>kronform
</span><span>contexts</span><span>:
</span><span>  </span><span>kronform</span><span>:
</span><span>    </span><span>endpoints</span><span>:
</span><span>    - </span><span>127.0.0.1
</span><span>    </span><span>ca</span><span>: </span><span>LS0t...
</span><span>    </span><span>crt</span><span>: </span><span>LS0t...
</span><span>    </span><span>key</span><span>: </span><span>LS0t...
</span></code></pre>
<p>Neither the <code>crt</code> or <code>ca</code> field certificate contain references to this endpoint either, and I suppose they wouldn&#39;t since it&#39;s for Kubernetes, and this relates to the Talos API.</p>
<p>Like the <code>secrets.yaml</code> file, this client configuration is also sensitive.</p>
<p>You can either copy this config file to <code>~/.talos/config</code> or use the <code>talosctl</code> merge command, which doesn&#39;t destroy any existing configurations you might have:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl config merge ./talosconfig
</span></code></pre>

<p>Now it&#39;s finally time to generate a talos machine configuration for our very first node!</p>
<p>... But not so fast! We&#39;ll need to customize it a bit. Now we could use <code>talosctl</code> to generate a <code>controlplane.yaml</code> generic machine configuration and then modify it to fit our needs, or we could use the patch system as intended instead to generate the finished config directly.</p>
<p>I&#39;ve created a couple of directories to keep track of all this:</p>
<ol>
<li><code>patches/</code> where I&#39;ll put cluster-wide patches,</li>
<li><code>nodes/</code> which will contain the per-node patch files, and finally</li>
<li><code>rendered/</code> where I&#39;ll output the finished machine configurations.</li>
</ol>
<p>First of all we&#39;ll want to enable workloads on our control plane machines. Our servers are quite beefy and since we&#39;re going to run only bare metal, we&#39;ll need <em>somewhere</em> to run the workloads.</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># patches/allow-controlplane-workloads.yaml
</span><span>cluster</span><span>:
</span><span>  </span><span>allowSchedulingOnControlPlanes</span><span>: </span><span>true
</span></code></pre>
<p>Secondly since we&#39;ll want to use <a href="https://cilium.io/">Cilium</a> as our CNI, so we need to disable the default CNI and disable <code>kube-proxy</code>, since Cilium comes with its own replacement as per the Talos <a href="https://www.talos.dev/v1.4/kubernetes-guides/network/deploying-cilium/#machine-config-preparation">documentation</a>:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># patches/disable-kube-proxy-and-cni.yaml
</span><span>cluster</span><span>:
</span><span>  </span><span>network</span><span>:
</span><span>    </span><span>cni</span><span>:
</span><span>      </span><span>name</span><span>: </span><span>none
</span><span>  </span><span>proxy</span><span>:
</span><span>    </span><span>disabled</span><span>: </span><span>true
</span></code></pre>
<p>We also want to override the cluster name and DNS domain. This is completely optional, but it&#39;s nice to have:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># patches/cluster-name.yaml
</span><span>cluster</span><span>:
</span><span>  </span><span>clusterName</span><span>: </span><span>kronform.pius.dev
</span><span>  </span><span>network</span><span>:
</span><span>    </span><span>dnsDomain</span><span>: </span><span>local.kronform.pius.dev
</span></code></pre>
<p>Finally, we need to add some customizations for our one node (named n1 here):</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># nodes/n1.yaml
</span><span>machine</span><span>:
</span><span>  </span><span>install</span><span>:
</span><span>    </span><span>disk</span><span>: </span><span>none
</span><span>    </span><span>diskSelector</span><span>:
</span><span>      </span><span>size</span><span>: &#39;</span><span>&lt; 1TB</span><span>&#39;
</span><span>    </span><span>image</span><span>: </span><span>ghcr.io/siderolabs/installer:v1.4.4
</span><span>  </span><span>network</span><span>:
</span><span>    </span><span>hostname</span><span>: </span><span>n1
</span><span>    </span><span>interfaces</span><span>:
</span><span>    - </span><span>interface</span><span>: </span><span>eth0
</span><span>      </span><span>dhcp</span><span>: </span><span>true
</span></code></pre>
<p>I&#39;m using the size-based disk selector since both the basic device path <code>/dev/sda</code> and the device bus path are subject to change between reboots, which is not ideal since our node is designed to attempt to converge on our desired state, which in some circumstances could cause Talos to reinstall itself multiple times on multiple devices.</p>
<p>I&#39;m also (temporarily) hard-coding the image to use Talos v1.4.4 so we can try out the upgrade procedure once it&#39;s up and running. You should omit this line (<code>image: ghcr...</code>) from your configuration, if you don&#39;t care about that.</p>
<p>With all that done, it&#39;s time to generate the actual machine config for our node:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl gen config \
</span><span>        --output</span><span> rendered/n1.yaml                                 \
</span><span>        --output-types</span><span> controlplane                               \
</span><span>        --dns-domain</span><span> local.$</span><span>CLUSTER_NAME                          </span><span>\
</span><span>        --with-cluster-discovery</span><span>=false                            \
</span><span>        --with-secrets</span><span> secrets.yaml                               \
</span><span>        --config-patch</span><span> @patches/cluster-name.yaml                 \
</span><span>        --config-patch</span><span> @patches/disable-kube-proxy-and-cni.yaml   \
</span><span>        --config-patch</span><span> @patches/allow-controlplane-workloads.yaml \
</span><span>        --config-patch</span><span> @nodes/n1.yaml                             \
</span><span>        $</span><span>CLUSTER_NAME                                             </span><span>\
</span><span>        $</span><span>API_ENDPOINT
</span></code></pre>
<p>Configuration can now be found in <code>nodes/n1.yaml</code></p>

<p>Review the rendered configuration in <code>rendered/n1.yaml</code> and apply it!</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> --nodes</span><span> 159.69.60.182 apply-config</span><span> --file</span><span> rendered/n1.yaml</span><span> --insecure
</span></code></pre>
<p>Rather anticlimactically we get absolutely no response. Luckily, we can use Talos&#39; dashboard functionality to see what&#39;s going on:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> -n</span><span> 159.69.60.182 dashboard
</span><span>rpc</span><span> error: code = Unavailable desc = connection error: desc = &#34;</span><span>transport: Error while dialing: dial tcp 127.0.0.1:50000: connect: connection refused</span><span>&#34;
</span></code></pre>
<p>Right. Our <code>talosconfig</code> doesn&#39;t know about the endpoint, so it just put in 127.0.0.1, let&#39;s fix that.</p>
<p>In <code>~/.talos/config</code> find the <code>endpoints</code> array...</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># ~/.talos/config (before)
</span><span>context</span><span>: </span><span>kronform
</span><span>contexts</span><span>:
</span><span>    </span><span>kronform</span><span>:
</span><span>        </span><span>endpoints</span><span>:
</span><span>            - </span><span>127.0.0.1
</span><span># (...)
</span></code></pre>
<p>... And replace <code>127.0.0.1</code> with our one and only node <code>159.69.60.182</code>:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span># ~/.talos/config (after)
</span><span>context</span><span>: </span><span>kronform
</span><span>contexts</span><span>:
</span><span>    </span><span>kronform</span><span>:
</span><span>        </span><span>endpoints</span><span>:
</span><span>            - </span><span>159.69.60.182
</span><span># (...)
</span></code></pre>
<p>Let&#39;s try again!</p>
<p><img src="https://datavirke.dk/posts/bare-metal-kubernetes-part-1-talos-on-hetzner/talos-dashboard.png" alt="Talos Dashboard"/></p>
<p>Sweet! Scrolling back up the logs a bit we can see that the configuration was applied, and the <code>STAGE</code> has changed to <code>Booting</code>, where it would previously have been <code>Maintenance</code>.</p>
<p>More recently in the logs we can see a warning indicating that <code>etcd</code> is waiting to join a cluster. This is our cue to initiate the cluster bootstrap, so let&#39;s go ahead:</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> --nodes</span><span> 159.69.60.182 bootstrap
</span></code></pre>
<p>Watching the dashboard logs scroll by, talos will start spewing out a ton of warnings as it starts to reconcile the desired state of the newly bootstrapped cluster, bringing up services.</p>
<p>Eventually it will settle down, and the <code>READY</code> state of the node will change to <code>True</code>, and all the Kubernetes service indicators will switch to <code>Healthy</code>.</p>
<p><img src="https://datavirke.dk/posts/bare-metal-kubernetes-part-1-talos-on-hetzner/all-green.png" alt="All Green Dashboard"/></p>
<p>Let&#39;s reboot the node and see if it the installation stuck, or if we&#39;ve just been dilly-dallying around in memory.</p>
<p>Since we don&#39;t have SSH access to the server, we can either request a hardware reset from the Hetzner Robot interface, or we can just ask Talos to do it for us.</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> --nodes</span><span> 159.69.60.182 reboot
</span></code></pre>
<p>This will launch a nice dynamic display of the status of the reboot, which is probably useful if you&#39;re rebooting multiple nodes.</p>
<p>The node will show as green, go red as it becomes unavailable, switch to yellow as it boots and then finally... Oh.</p>
<p>It never transitions back to green. Interesting. Talos dashboard works, and all the Kubernetes services are up, so let&#39;s extract the kubeconfig and see for ourselves.</p>
<p>The following command will create a systems administrator kubeconfig for our new cluster, merge it with our current <code>~/.kube/config</code> if one exists, and automatically set our cluster as the currently selected context.</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> talosctl</span><span> -n</span><span> 159.69.60.182 kubeconfig
</span></code></pre>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> kubectl get nodes
</span><span>NAME</span><span>   STATUS     ROLES           AGE   VERSION
</span><span>n1</span><span>     NotReady   control-plane   14m   v1.27.2
</span></code></pre>
<p>Our node <em>exists</em> so that&#39;s good, but it&#39;s <code>NotReady</code>, why?</p>
<pre data-lang="bash"><code data-lang="bash"><span>[mpd@ish]$</span><span> kubectl describe node n1 | </span><span>grep</span><span> NotReady
</span><span>  </span><span>Ready</span><span>            False   Thu, 22 Jun 2023 17:36:18 +0200   Thu, 22 Jun 2023 17:21:32 +0200   KubeletNotReady              container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized
</span></code></pre>
<p>Duh. We haven&#39;t installed a CNI yet!</p>
<p>We&#39;ll consider the job done for now, and tackle CNI-installation in the next post: <strong><a href="https://datavirke.dk/posts/bare-metal-kubernetes-part-2-cilium-and-firewalls/">Part II: Cilium CNI &amp; Firewalls</a></strong></p>

<p>Here I&#39;ve gathered some of my reflections and learnings from the process.</p>



	</div></div>
  </body>
</html>
