<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://crazystupidtech.com/2025/09/29/irobot-founder-dont-believe-the-ai-robotics-hype/">Original</a>
    <h1>iRobot Founder: Don&#39;t Believe the (AI and Robotics) Hype</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Every so often, we find ourselves in the middle of a massive technological wave that starts to upend our presumptions and our ideas about the past, present, and future. These waves come with excess—optimism, excitement, hype, and speculation. Since non-believers don’t invent the future and speculators are always on a hustle, I often turn to practitioners to get a fix on the coordinates of reality. It has always helped me maintain a sense of pragmatic optimism when the rest of the world around me seems either overtly hyperbolic or depressingly pessimistic.</p>



<p>We are in the middle of another massive technological wave, thanks to generative artificial intelligence and its offshoot, robotics. A tanker load of money is being poured into these two areas, and it has come with increasingly breathless promotional activity. It warrants a reality check. For that, I turned to Rodney Brooks, who has spent decades in both arenas. The Australian-born Brooks was a Professor of Robotics at MIT and former director of the MIT Computer Science and Artificial Intelligence Laboratory. He has founded three companies: iRobot (maker of the Roomba), Rethink Robotics, and now <a target="_blank" rel="noreferrer noopener" href="http://robust.ai/">Robust.AI</a>, which now builds warehouse automation robots. He is an academic who entered the startup arena and hasn’t left it since.</p>



<p>We recently connected for a conversation about robotics, artificial intelligence, and the future. Contrary to many, he believes humans will do just fine in a world filled with robots and AI. He poured cold water on the humanoid robot hype. He also said that if you look at the computer and internet revolutions, the AI revolution is going to take a lot longer than most think. “There’s a tendency to go for the flashy demo. But the flashy demo doesn’t deal with the real environment. It’s going to have to operate in—the messy reality. That’s why it takes so long for these technologies,” he said. He painted a more pragmatic yet optimistic vision ahead. He warned that humanoid hype is creating a lot of false expectations. Excerpts from our conversation.</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1024" height="768" data-attachment-id="386" data-permalink="https://crazystupidtech.com/2025/09/29/irobot-founder-dont-believe-the-ai-robotics-hype/rodney%20brooks%20by%20christopher%20michel%201992799-17-21/" data-orig-file="https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?fit=4000%2C3000&amp;ssl=1" data-orig-size="4000,3000" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;4&#34;,&#34;credit&#34;:&#34;Christopher P. Michel&#34;,&#34;camera&#34;:&#34;GFX100S&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;1631873861&#34;,&#34;copyright&#34;:&#34;CHRISTOPHER MICHEL&#34;,&#34;focal_length&#34;:&#34;32&#34;,&#34;iso&#34;:&#34;160&#34;,&#34;shutter_speed&#34;:&#34;0.0125&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;1&#34;}" data-image-title="Rodney%20Brooks%20by%20christopher%20michel%201992799-17-21" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?fit=1024%2C768&amp;ssl=1" src="https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=1024%2C768&amp;ssl=1" alt="A thoughtful man holding a robotic device, seated in low light with a dark background." srcset="https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/crazystupidtech.com/wp-content/uploads/2025/09/Rodney20Brooks20by20christopher20michel201992799-17-21.jpg?w=3000&amp;ssl=1 3000w" sizes="(max-width: 1000px) 100vw, 1000px"/></figure>



<p><strong>Om:</strong> You have a rare quality as a science person to write about tech in an understandable fashion. I think it’s always helpful to think beyond the tech directly and consider what the consequences are. When I hear people talk about AGI taking over, I point out that we have already become machine-idiots. We just follow the machine blindly.</p>



<p>You wrote something about Waymo recently, where you said there is not really full self-driving because there is human intervention. I would argue it’s not even the best human intervention. Waymo dropped me off at a completely different location, even though on the map it showed the right location.</p>



<p><strong>Rodney:</strong> At MIT, I taught big classes with lots of students, so maybe that helped. I came here in an Uber this morning and asked the guy what street we were on. He had no clue. He said, “I just follow it.” (‘It’ being the GPS—Ed.) And that’s the issue—there’s human intervention, but people can’t figure out how to help when things go wrong.</p>



<p><strong>Om:</strong> We are now <em>Machine Idiots</em>. So what are you working on now?</p>



<p><strong>Rodney:</strong> My new company is putting smart carts in fulfillment warehouses. It doesn’t sound like much, but in fulfillment, many people work picking orders and shipping them out. There are enormous warehouses everywhere full of human workers because human hands are just so much better than anything else. They’re picking, putting orders in totes in these carts, and pushing the carts around.</p>



<p>We’ve got this cart called Carta that has cameras. It knows where it is, goes to the right place, and helps people figure out where the item they want is. It doesn’t do the grasping—people do the picking.</p>



<p>The big thing we do is reduce the amount of walking people have to do. In these warehouses, a typical number of steps per day for a person is 30,000. Now we all know what 10,000 steps feels like (it’s about 5 miles), so imagine doing 30,000 steps a day. It’s really hard on people’s bodies.</p>



<p>When they finish a pick-tour, instead of walking back and pushing a heavy cart 400 feet, they just say ‘done,’ and the robot goes off and takes the items to the correct location. We have <a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Affordance">affordances</a> on the cart that lower the cognitive load. (Affordance is an action humans can easily perceive—Ed.)</p>



<p>In comparison, the state of the art is that people have scan guns, and on their wrists are tiny screens with character-based software—it’s ’80s or ’90s technology emulated on an Android device. They have to read that to know what bin number, what thing to do.</p>



<p><strong>Om:</strong> How does this company relate to all the companies you’ve started?</p>



<p><strong>Rodney:</strong> My companies have always been about letting the person still have control. The previous one, Rethink Robotics, involved people showing the robot what to do. The Roomba had a handle; if it got stuck, you could pick it up and move it. If a human grabs the Carta cart, they’re now in charge. If you grab its magic handlebar, you are like Superman—you move your hand a little, and it amplifies what you’re doing. We make the floor worker take control and put it in the right place without much physical effort.</p>



<p>The cart knows a ladder and knows not to go near ladders because a person is up there—if it hit one, it would be disastrous. If it’s going down an aisle and there’s a person there, it’s polite, waits for the person to move, tries to go around them. But if a pallet is blocking the aisle, it recognizes that it’s not going to move by itself. There’s no point waiting. It turns around and tells the central system that this aisle is blocked. It’s simple intelligence, which is what we can do today and make reliable. It’s not sexy. It’s technology in the service of making things easier for workers and more efficient.</p>



<p><strong>Om:</strong> You’re building a product which is simpler, unsexy, but when I think about the Roomba and all the companies you’ve done in the past, they have always made things very futuristic—like some robot is cleaning my house. Whereas now we’re in the phase of automation where we almost take robots for granted as humans, even though you’re solving problems like those robots inside Amazon’s warehouse.</p>



<p><strong>Rodney:</strong> Amazon has automated and manual warehouses. We’re trying to put technology in the manual warehouses, whether it’s DHL—our biggest customer—or Amazon. It’s about putting robots in places where there are no robots. And it’s not saying it’s a humanoid that’s going to do everything.</p>



<p>You’re right, it’s not sexy. And you know what that means for me? It’s hard to raise money. “Why aren’t you doing something sexy?” the VCs ask. But this is a $4 trillion market that will be there for decades.</p>



<p><strong>Om:</strong> It’s much easier to fund the promise than a real business, because real businesses have limitations on how fast they can grow. Whereas if you don’t know, you can live (and fund) the dream. There’s nothing wrong with living the dream—that’s how you get to fund crazy things in this industry. But people doing more rational things do pay the price.</p>



<p>You’ve been in robotics for a long time. There are misconceptions about robots and robotics. The biggest fallacy is that we think of them in human form. Ten years later, that idea of a humanoid has become so pervasive. We don’t think about things that do robotic tasks, like ad systems that serve ads constantly—they are also robots.</p>



<p><strong>Rodney:</strong> The robots—they’re not embodied. I always say about a physical robot, the physical appearance makes a promise about what it can do. The Roomba was this little disc on the floor. It didn’t promise much—you saw it and thought, that’s not going to clean the windows. But you can imagine it cleaning the floor. But the human form sort of promises it can do anything a human can. And that’s why it’s so attractive to people—it’s selling a promise that is amazing.</p>



<p><strong>Om:</strong> What do you think about the current state of robotics in the US versus how people are funding robots and thinking about them?</p>



<p><strong>Rodney:</strong> There’s good news and bad news. The amount of processing power we have now is amazing—amounts of computation and small sensors largely driven by the phone market.</p>



<p>With my company, the motors we use are hub motors from electric scooters because they are made in the millions. They’re cheap and much better than the motors you could buy 10 years ago at a much lower price. So instead of building custom motors, we ride that curve.</p>



<p>Likewise with GPUs—I think Nvidia is the luckiest company in the world. They were building graphics processing units and they turned out to be able to do the computation of neural networks. The GPUs are great for the vision computations you need to localize, to know where you are—SLAM, simultaneous localization and mapping.</p>



<p>You can do so much more computation, sensing, some actuation, but people underestimate the long tail of the natural environment. That’s what we see with autonomous vehicles. I first attended a talk on autonomous vehicles in 1979 in Tokyo. By 1990, Ernst Dickmanns in Germany had his truck driving on the Autobahn at 100 kilometers an hour. He took it to Paris, and an autonomous vehicle drove around Paris in 1990. Then in 2007, 2008, people saw the DARPA autonomous vehicle and said, “Oh, it’s going to be everywhere instantly.” But it’s taken almost 20 years, and it’s still only in little tiny geographical areas because of the long tail of all the things that can happen.</p>



<p>There’s a tendency to go for the flashy demo, but the flashy demo doesn’t deal with the real environment. It’s going to have to operate in the messy reality. That’s why it takes so long for these technologies.</p>



<p><strong>Om:</strong> Like Waymo—they still require human intervention.</p>



<p><strong>Rodney:</strong> That’s why I’m skeptical of the Tesla taxi system. At the last earnings call, Elon said they’re going to have safety drivers in the Teslas and they’re hiring remote drivers. It’s sort of a charade.</p>



<p><strong>Om:</strong> There is a habit in our modern society to forget how long it takes for something to actually find its true form, like PCs. I remember using MS-DOS, then eventually where we are today where we don’t even think about what the PC looks like. The same with smartphones—I used the earliest examples from Nokia and Palm and then eventually seeing where we are today. There is a way to minimize the effort needed for technology to find its perfect form, but that’s going to be a challenge for self-driving as well.</p>



<p><strong>Rodney:</strong> It’ll take a long time for adoption.</p>



<p><strong>Om:</strong> You did early work on mapping and (Simultaneous Localization and Mapping) SLAM about 40 years ago. When you were thinking about that future, how were you thinking about it?</p>



<p><strong>Rodney:</strong> The SLAM paper was released in 1985. I was working on mobile robots, and Waymos are mobile robots. It never occurred to me that there would be, in my lifetime, the level of Waymos we have, even though it’s not where people think it is. I was just wanting to get mobile robots that could move around and do things in the world, and they had to know where they were and how to get somewhere. That was the problem I was solving—just the next few steps.</p>



<p>Around the same time, I wrote some whimsical things about home cleaning robots, mixing nanotechnology with robotics. I talked about lots of little robots living on your floor, picking up stuff and putting it in a pile for the big robot to come and suck up the dirt—societies of robots around us, which was a science fiction thing that has not happened.</p>



<p><strong>Om:</strong> What was the genesis of your fascination with robots?</p>



<p><strong>Rodney:</strong> I grew up in a working-class environment. My parents didn’t come close to finishing high school. Somehow I just won the genetic lottery. I was born in the ’50s, a white male in an English-speaking country, which turned out to be really important. But on top of that, I had mathematical ability that was so obvious that by the time I was four, my parents referred to me as “the professor.”</p>



<p>My parents found these How and Why Wonder books—one on electricity and one on computers and giant brains. The publication date is 1961. I probably got them when I was seven. I read these books, learned how to make circuits out of stuff I had—wires, nails, batteries, flashlight bulbs. The computers had pictures of imagined robots and explained binary systems, so I learned how to build circuits and then saw how to build little bits of computation. I was always trying to build computers for the rest of my childhood because there were no computers available. I tried building robotic devices but wasn’t really good at mechanisms, so I really wanted to build robots.</p>



<p><strong>Om:</strong> Where did you grow up?</p>



<p><strong>Rodney:</strong> Adelaide, South Australia.</p>



<p><strong>Om:</strong> Still a fan of cricket?</p>



<p><strong>Rodney:</strong> Here’s my superpower. When I was eight years old, Ian and Greg Chappell coached me when I was a child. It did me zero good—I was so bad. But as far as all my countrymen are concerned, they think I am the luckiest guy on the planet. (The Chappell brothers – Ian and Greg are legends of the game of cricket, much like the baseball legends, the DiMaggio brothers.)</p>



<p><strong>Om:</strong> When you look at that SLAM paper you wrote, what has been the big lesson of turning something on paper into reality?</p>



<p><strong>Rodney:</strong> All these things require so much more engineering than some initial idea. My initial idea was loop closing, which is critical to SLAM. But my version of merging observations probabilistically was actually quite terrible. In 1985, someone else who read the paper published a paper a year later to improve on that part. Then other people started to see little pieces—”Oh, I can improve here, I can improve there.” During the ’90s, there were hundreds of papers every year coming out on SLAM. It was a hot topic, and people realized it was going to be important for getting moving robots into environments.</p>



<p>Even now, it’s only in the last five years that we’ve been able to do it with computer vision because we didn’t have enough computational power. Up until recently, it was all LIDAR-based. So technologies wait for other technologies to come along. The computer vision wasn’t driven by that, but then it got good enough to do it. Some things might be a good idea, and you can see how it could work, but it may require so many side technologies that you haven’t worked through all the details to make it practical. That could be a long time.</p>



<p><strong>Om:</strong> Knowing what you know, do you think we need to be rethinking how we approach innovation, education, and our perspective on the world? Forty years may have worked in the pre-network era, but now we live in a post-network world with new intensity and rhythm.</p>



<p><strong>Rodney</strong>: There’s a new rhythm, and what I fear is that everyone jumps into new orthodoxies. For a few years now, people have been saying if you’re not working on neural net-based AI, you’re in the past, you’re a dinosaur. I guarantee there will be things that people have been working on for years that will become important and they’re not neural-based.</p>



<p><strong>Om:</strong> You have very strong opinions about generative AI. When I talk to young people, I wonder if we have an entire society trained on an answer-based value metric—we read a book, get an answer, take an exam, give an answer. Whereas generative AI means we’re more question-oriented going forward. The ability to ask the right questions is going to separate us from being really good versus just average. You have to be someone special to be able to ask questions in philosophy and art and robotics and AI. Not everybody can connect the dots. So maybe there’s a whole new class of educational approaches that need to emerge.</p>



<p><strong>Rodney:</strong> I think we need multiple education approaches and not put everything in the same bucket. I see this in Australia—”What’s your bachelor’s degree?” “I’m doing a bachelor’s degree in tourism management.” That’s not an intellectual pursuit, that’s job training, and we should make that distinction. The German system has had this for a long time—job training being a very big part of their education, but it’s not the same as their elite universities.</p>



<p>[ Brooks is right in pointing out that we are busy propping up an education system that creates work for an industrial and industrial-version of digital economies. Germans (and many other parts of the world) have this idea of diplomas in specialized trade skills, which is exactly how we are going to be thinking about in the future, because the idea of work, augmented by digitized automation, both robotic and software, will need to evolve. As such, we need to really rethink the entire map of employment and fine-tune “collegial output” in terms of jobs needed to be done in tandem with the emergence of rapid computerized automation. The United States is still trying to use the same template of education that it has for decades. –OM ]</p>



<p><strong>Om:</strong> In India too, we had diplomas which were very targeted—if you wanted to work in a power station, you got a diploma.</p>



<p><strong>Rodney:</strong> Australia too, diplomas for teaching primary school, which is honorable. But it’s not necessarily—although I wish, looking back at the history teaching I got, it didn’t teach me about the world because it was just regurgitating “this happened, that happened,” instead of why it happened, what were the intellectual ideas driving it.</p>



<p><strong>Om:</strong> I struggled in college because I was always the one asking, “Why are we doing this experiment? What is the outcome? Why are we looking for this outcome?” We already know the answer—some scientist discovered it—but no one explains why we’re repeating it and what we gain from it as students.</p>



<p><strong>Rodney:</strong> I remember undergraduates working in my lab at MIT. One guy who ended up being a professor would be doing stuff and then say, “That’s why they taught me that thing in that class, now I see what”—because the classes, even at MIT, didn’t necessarily connect why this question is interesting, why it’s important. Then through the practice of trying to build real things, “Oh, that’s what I needed to know.”</p>



<p><strong>Om:</strong> I think of being a journalist as the best education I ever got, especially writing about tech, because I learned about microcontrollers, embedded operating systems, networks, switches, and compute. I also learned about the impact of all these technologies on real people and the real world. There’s no way any college could have taught me that. In this world, I was happier than in school because in school, I wasn’t able to connect the dots. In the real world, the dots were connecting in my brain.</p>



<p>I look at why I’m okay with all the generative AI stuff that has come to market—I know the right questions to ask. I know how to talk to ChatGPT. I’ve grown up interviewing people, so I know when the response is nonsense.</p>



<p><strong>Rodney:</strong> Generative AI challenges us intellectually. John Searle at Berkeley talked about the Chinese Room argument. (<em>It says that no matter how smart a computer seems, it can’t have human consciousness.–Ed</em>) Well, the Chinese Room showed up. I recently gave an example. I used Google to give me a Chinese output for: “Who is Ai Weiwei?”</p>



<p>I cut and pasted those Chinese characters into ChatGPT, and it gave a biography of him. So there’s the Chinese room—I feed in symbols in Chinese and it feeds me back symbols in Chinese. Searle was saying the Chinese room is absurd because they could never understand Chinese just by symbol matching. And here it did it. So there’s a challenge to what it means to understand language.</p>



<p>There are these rules of language, and the only reason we can understand language is because of biological structures in our brain attuned to language. Here’s generative AI—did it have the universal grammar machine in it, yet it’s so adept at language. So that’s another challenge.</p>



<p>Generative AI challenges long-held notions of how things work. In the worst case, it says we’re not as smart as we think we are because this dumb thing can do what we do. We always have a view of ourselves as people being special. I remember when the human genome was decoded and we had fewer genes than a potato—people were outraged.</p>



<p><strong>Om:</strong> More is more, right? More must be better.</p>



<p><strong>Rodney:</strong> Through the history of mankind—the world is the center of the universe, the sun goes around it, God is up there looking at us. Then we discover other planets, other solar systems, other galaxies, and we’re one of billions of billions of planets. But we’re special! It gets people upset. I was at the World Economic Forum on stage talking about AI and being provocative. Yehudi Menuhin was in the audience and stood up and yelled at me for devaluing humans by talking about machine intelligence.</p>



<p><strong>Om:</strong> If you stop thinking about generative AI as this road to AGI and think of it as simply a way to interact with information—</p>



<p><strong>Rodney:</strong> That’s what I do take it as. If you’d explained it to me 15 years ago, I would have said, “There’s no way that can work.” So it’s a surprise that it works, but it is an encoding of information.</p>



<p><strong>Om:</strong> What are you thinking about the future right now? How should we contextualize artificial intelligence and robotics? Do you want my really crazy stuff?</p>



<p><strong>Rodney:</strong> If I look at history and history of ideas, we often get sucked in by the wrong idea. One of my examples is Sir Isaac Newton. Really smart dude—he invented calculus, figured out gravity and movement of bodies in 3D, did optics, split light into multiple colors. But he spent over half his life working on alchemy, trying to convert lead to gold. Really smart guy. Why did he do that? He thought, as everyone did, that it was chemical. They had primitive chemistry. He didn’t know about nuclear—the nucleus is what you have to deal with to convert lead to gold. Everyone thought it was the same kind of thing they were used to, burning stuff and mixing stuff. He had the wrong underlying model.</p>



<p>When Elon Musk decided he wanted to put stuff into orbit, he didn’t say, “I’ll write a Python script, and that will get stuff into orbit.” He had to figure out how to burn fuel efficiently, worry about mass, liquid flows, high temperatures, because you can write as big a program as you want, it’s not going to get stuff into orbit. Computation is not the stuff you need to physically move things.</p>



<p>Somehow, we’ve decided that computation is what happens in our brain. Is it really computation? And why is that?</p>



<p>Between 1945 and 1965, there were four disciplines that were of focus. You have this two-by-two chart of science, and engineering. And you have life and intelligence.</p>



<p>Over here we have neuroscience. Here we have AI. Here we have artificial life. And here we have abiogenesis—turning abiotic into biotic. These four modern computational disciplines all came into being 1945 to 1965. If you look at any two of them, I can show you someone who worked in those two fields. For any three of them, mostly I can find someone who worked in all three fields—von Neumann, McCulloch, a whole bunch of people.</p>



<p>Any of the four have taken computation as their primary metaphor. Abiogenesis is still chemical, not computational. But why are any of these computational? Is that the right stuff?</p>



<p>Or are we trying to build a rocket by writing a program, which is doomed to failure? In the same way, Newton was doomed to failure with alchemy because it’s not chemical—it’s nuclear, and no one knew about the nucleus. So that’s my bigger picture. AGI could be 300 years away because we’re dealing in the wrong kind of stuff.</p>



<p><strong>Om:</strong> I am trying to figure out what AGI is.</p>



<p><strong>Rodney:</strong> Building a machine which could do all the things we do with our brain. It may be something that we haven’t even thought about.</p>



<p>There’s this assumption of the infinite power of the human mind. I like to think about orcas. Orcas are really smart, really brutal, as we are. There’s great footage where they’re going after seals up on rocks, but they’ve got to sneak up on them in shallow water, so they roll over at 90 degrees so their dorsal fin doesn’t show above water. So they’re solving problems. They have some self-model.</p>



<p>But we never think they’re going to build a foundry and start smelting metal. We don’t think they’re smart enough, but we think we’re infinitely smart and we’ll solve all these problems with technology. Just like the orcas, we may have limits and we don’t like that.</p>



<p><strong>Om:</strong> But humans do solve problems. And look how far we’ve come.</p>



<p><strong>Rodney:</strong> We’ve come so far compared to orcas, but orcas can only come so far. Maybe there’s a natural limit for us.</p>



<p><strong>Om:</strong> But what I was trying to say is that we have entered a new reality. The world existed pre-internet and post-internet. It was not creating digital data at the speed we generate now, so we need new tools to deal with this reality.</p>



<p><strong>Rodney:</strong> I agree with you, but I think that’s the pedestrian part of our existence.</p>



<p><strong>Om:</strong> I find it more exciting because it’s going to be more disruptive than this idea of AGI. We have all this money going into robots, humanoid robots, and other AI, but we don’t have manufacturing in this country. We don’t make anything. When I look at what China is doing with their EVs or their self-driving cars, they’re building new cities with roads that have sensors—essentially built for this new reality. I feel we are not thinking about the opportunities correctly because the Chinese have the end market for manufacturing. They are very good at manufacturing—that’s what they’ve been doing for the last 25 years.</p>



<p><strong>Rodney:</strong> I started manufacturing in China in the late ’90s. Just last week, my company put out a press release that Foxconn is going to build our robots at scale. They’re based in Taiwan, but it’s undeniable—if you want to do something at scale, that’s how you have to do it.</p>



<p>But let’s look ahead to this century. Fifty years from now, all the innovation is going to be happening in Nigeria. They’re going to be such a big part of the world population, and they’re going to have so many problems they have to deal with, and they will deal with them. Nigeria is going to be the center of the technological universe by the end of this century. (Just as China and its large population, and its need to solve its problems made it into an economic powerhouse, Brooks believes the sheer size of Nigeria is going to make it an economic and technological epicenter.–Ed)</p>



<p><strong>Om:</strong> How are we going to have all these companies build robots in the U.S.? What will be our manufacturing? What will be our place in this world? What do we think about the American future in manufacturing? Do we think about a post-capitalist future where scale is not what we think about? How does the world change?</p>



<p><strong>Rodney:</strong> Will manufacturing be driven by 3D printing? It’s not yet. We’re starting to use 3D printing for components of machines. Electron (a New Zealand company) that launches satellites from New Zealand—they 3D print their rocket motors. But they can afford to do that because it’s such a high-value thing. As 3D printing becomes more general, in the same way information technology and payment systems got adopted in the third world more quickly than in the US, 3D printing will become the engine of manufacturing.</p>



<p>Right now, the supply chain is the reason China is so effective. Chinese manufacturing companies realized they had to diversify and started building supply chains in places like Malaysia, Vietnam. But if 3D printing really gets to be effective, the supply chain becomes all about raw materials that get poured into the front of those 3D printers. It’ll be about certain chemicals, about raw materials, because then every item would ultimately be 3D printed. That completely breaks the dynamic of what made Chinese manufacturing so strong—the supply chain of components.</p>



<p><strong>Om:</strong> But then that flies in the face of manufacturing jobs being the savior of any economy.</p>



<p><strong>Rodney:</strong> I was at a Brown University commencement giving a talk. And we were bemoaning the loss of US manufacturing. I asked the parents of the about to be Brown graduates—do who wants your kids to work in a factory? Oh no, not us! The poor people need the jobs, not my child. Who aspires that their kid is going to work at the sewage company? This bemoaning of manufacturing being lost is a little duplicitous—it’s not for us, it’s for the poor people.</p>



<p><strong>OM</strong>: Manufacturing jobs are like a political hot potato. Politicians love to talk about manufacturing jobs as it wins votes. If you believe in the robotic revolution and 3D printing, things are going to be very different 25 years from now. I recently saw a video of BYD’s new factory in China. It is supposed to be as big as the city of San Francisco and it will have only 40,000 people making cars. The rest are all BYD-made robots. That’s the future of manufacturing at scale. This is very counter to the idea of “manufacturing jobs” as politicians like to talk about it.</p>



<p><strong>Rodney:</strong> That’s why I brought up 3D printing. There’ll be other technologies that come in, not just robotics. One of the most interesting things is applying AI to creating materials—you can make predictions about what material properties will be and you don’t have to laboriously make each material and test it. As materials change, there’s 3D printing, changes in materials, a whole bunch of things that can come together. My answer is I don’t know, but I know it’s going to be different.</p>



<p><strong>Om:</strong> Before you go, how should we correctly think about robotics and AI. Right now there is a hype way of thinking about it, there is a negative way of thinking about it. What is the right way?</p>



<p><strong>Rodney:</strong> The right way of thinking about it is that appearance alone is not everything. There are things that are incredibly hard for us to do with technology at the moment, which we just don’t know how to do. So many of the promises of the hype of robotics and AI gloss over things we don’t know how to do well. We do not know how to manipulate things with robot hands. Everyone is excited about a robot hand, and Chinese companies are making the same mistake, thinking that it’s dexterous.</p>



<p>But the way that we do stuff with our hands, we have no way of reproducing, nor should we think that hands should be five-fingered. When this first structure appeared in animals, it was the first creatures that crawled out of the ocean onto the land. They had five bones to make pads that could be pushed around. This is an accident of evolution. Maybe in the future, the dexterous things will look more like sea anemones, lots of tentacles filled with cilia and they just pour stuff in and it gets manipulated.</p>



<p>I think the correct thing is not to think about it as being a duplication of humans. It’s never a duplication of humans that is the optimal solution or the most cost-effective solution. So it will be different from humans.</p>



<p><strong>Om:</strong> You’ve said something about quantum computing having an impact and materials and physics.</p>



<p><strong>Rodney:</strong> The effective quantum computers for the next 10 years are going to be using quantum computers to simulate physical systems, not doing classical computation way better. That’s still a long way off. I used to make the joke, people would ask me, “When are we going to get quantum computers?” And I would say, “I don’t know, but I’m pretty sure they’re going to be fusion powered.” Now we’re starting to see a diversity of approaches to fusion. Never say never, but for the next few years quantum computers are going to be much more about simulating physical systems.</p>



<p><strong>Om:</strong> If you were to describe yourself right now, would you describe yourself as an optimist about AI or maybe not so much?</p>



<p><strong>Rodney:</strong> I model myself as a realist. I’ve lived through so many hype cycles in AI. They weren’t as big in public as this one, but they were brutal amongst AI practitioners. The arguments were strong and deeply held—screaming matches would happen. I’ve seen that happen again and again. Neural is ascendant at the moment, but neural was ascendant four or five times before and then got crushed. Something else took over, came back.</p>



<p>You can see that in agentic AI. Now suddenly everyone’s got agent-based AI. They didn’t have it six months ago. I suspect it’s a little more marketing than reality. But when was the first paper on agentic AI published? It was in 1959 by Oliver Selfridge. There’s been agent-based systems—SOAR, there’s been lots. They come and go, all these ideas, and they get improved every time they come back. I’m not saying it’s stupid, I’m just saying as someone who’s been involved, it is not just the shiny new thing. This thing that looks shiny now may not be so shiny in a few years.</p>



<p><strong>Om:</strong> But when I think about it, I feel that the amount of money being poured into this sector is going to have an impact. It’s going to push things along much faster.</p>



<p><strong>Rodney:</strong> It’s going to have an impact and a lot of it will be wasted too.</p>



<p><strong>Om:</strong> The networks were overbuilt and then that allowed a company like Google to come in and build out its own network and offer search so cheaply.</p>



<p><strong>Rodney:</strong> There is an upside. Let me tell you my upside version—thinking of how to use all these data centers once the crash comes in training generative AI models. There will be so much competition in these data centers, just sitting there waiting to be used. I’m not going to use it to mine bitcoin, but smart people would be thinking beyond the crash of how to use—as you said, the networks were there, they were overbuilt, they were ready. So I think these data centers are getting overbuilt. They’ll be ready to be used for something new. If you can figure out how to do that, if some kid can figure out how to do that, they’re going to be working right now on it in obscurity and poverty and then boom.</p>



<p><strong>Om:</strong> It would have been fun to keep talking, but I know we’ve gone over our time.</p>



<p><strong>Rodney:</strong> Thank you for the conversation. It’s been stimulating to think through these ideas with someone who understands both the technical and broader implications.</p>



<p>Photo Credit: <a href="https://www.christophermichel.com/New-Heroes">Christopher Michel</a>. </p>




</div></div>
  </body>
</html>
