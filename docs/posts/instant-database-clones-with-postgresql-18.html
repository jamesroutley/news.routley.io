<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://boringsql.com/posts/instant-database-clones/">Original</a>
    <h1>Instant database clones with PostgreSQL 18</h1>
    
    <div id="readability-page-1" class="page"><div>
      <p>Have you ever watched long running migration script, wondering if it&#39;s about
to wreck your data? Or wish you can &#34;just&#34; spin a fresh copy of database for
each test run? Or wanted to have reproducible snapshots to reset between
runs of your test suite, (and yes, because you are reading boringSQL) needed
to reset the learning environment?</p>
<p>When your database is a few megabytes, <code>pg_dump</code> and restore works fine. But
what happens when you&#39;re dealing with hundreds of megabytes/gigabytes - or more?
Suddenly &#34;just make a copy&#34; becomes a burden.</p>
<p>You&#39;ve probably noticed that PostgreSQL connects to <code>template1</code> by default. What
you might have missed is that there&#39;s a whole templating system hiding in plain
sight. Every time you run</p>
<pre><code><span>CREATE DATABASE dbname;
</span></code></pre>
<p>PostgreSQL quietly clones standard system database <code>template1</code> behind the
scenes. Making it same as if you would use</p>
<pre><code><span>CREATE DATABASE dbname TEMPLATE template1;
</span></code></pre>
<p>The real power comes from the fact that you can replace <code>template1</code> with any
database. You can find more at <a href="https://www.postgresql.org/docs/current/manage-ag-templatedbs.html">Template Database
documentation</a>.</p>
<p>In this article, we will cover a few tweaks that turn this templating system
into an instant, zero-copy database cloning machine.</p>
<h2 id="create-database-strategy">CREATE DATABASE ... STRATEGY<a href="#create-database-strategy" aria-label="Anchor link for: create-database-strategy"></a>
</h2>
<p>Before PostgreSQL 15, when you created a new database from a template, it
operated strictly on the file level. This was effective, but to make it
reliable, Postgres had to flush all pending operations to disk (using
<code>CHECKPOINT</code>) before taking a consistent snapshot. This created a massive I/O
spike - a &#34;Checkpoint Storm&#34; - that could stall your production traffic.</p>
<p>Version 15 of PostgreSQL introduced new parameter <code>CREATE DATABASE ... STRATEGY = [strategy]</code> and at the same time changed the default behaviour how the new
databases are created from templates. The new default become <code>WAL_LOG</code> which
copies block-by-block via the Write-Ahead Log (WAL), making I/O sequential (and
much smoother) and support for concurrency without facing latency spike. This
prevented the need to CHECKPOINT but made the database cloning operation
potentially significantly slower. For an empty <code>template1</code>, you won&#39;t notice the
difference. But if you try to clone a 500GB database using WAL_LOG, you are
going to be waiting a long time.</p>
<p>The <code>STRATEGY</code> parameter allows us to switch back to the original method
<code>FILE_COPY</code> to keep the behaviour, and speed. And since PostgreSQL 18, this
opens the whole new set of options.</p>
<h2 id="file-copy">FILE_COPY<a href="#file-copy" aria-label="Anchor link for: file-copy"></a>
</h2>
<p>Because the <code>FILE_COPY</code> strategy is a proxy to operating system file operations,
we can change how the OS handles those files.</p>
<p>When using standard file system (like <code>ext4</code>), PostgreSQL reads every byte of
the source file and writes it to a new location. It&#39;s a physical copy. However
starting with PostgreSQL 18 - <code>file_copy_method</code> gives you options to switch
that logic; while default option remains <code>copy</code>.</p>
<p>With modern filesystems (like ZFS, XFS with reflinks, APFS, etc.) you can switch
it to <code>clone</code> and leverage <code>CLONE</code> (<code>FICLONE</code> on Linux) operation for almost
instant operation. And it won&#39;t take any additional space.</p>
<p>All you have to do is:</p>
<ul>
<li>Linux with XFS or ZFS support (we will use XFS for the demostration) or similar
operating system. MacOS APFS is also fully supported. FreeBSD with ZFS also
supported (which normally would be my choice, but haven&#39;t got time to test so
far)</li>
<li>PostgreSQL cluster on that file system</li>
<li>update the configuration <code>file_copy_method = clone</code></li>
<li>and reload the configuration</li>
</ul>
<h2 id="the-benchmark">The benchmark<a href="#the-benchmark" aria-label="Anchor link for: the-benchmark"></a>
</h2>
<p>We need some dummy data to copy. This is the only part of the tutorial where you
have to wait. Let&#39;s generate a ~6GB database.</p>
<pre data-lang="sql"><code data-lang="sql"><span>CREATE DATABASE </span><span>source_db</span><span>;
</span><span>\c source_db
</span><span>
</span><span>CREATE TABLE </span><span>boring_data</span><span> (
</span><span>    id </span><span>serial PRIMARY KEY</span><span>,
</span><span>    payload </span><span>text
</span><span>);
</span><span>
</span><span>-- generate 50m rows
</span><span>INSERT INTO</span><span> boring_data (payload)
</span><span>SELECT</span><span> md5(random()::</span><span>text</span><span>) || md5(random()::</span><span>text</span><span>)
</span><span>FROM</span><span> generate_series(</span><span>1</span><span>, </span><span>50000000</span><span>);
</span><span>
</span><span>-- force a checkpoint
</span><span>CHECKPOINT;
</span></code></pre>
<p>You can verify the database now has roughly 6GB of data.</p>
<pre><code><span>Name              | source_db
</span><span>Owner             | postgres
</span><span>Encoding          | UTF8
</span><span>Locale Provider   | libc
</span><span>Collate           | en_US.UTF-8
</span><span>Ctype             | en_US.UTF-8
</span><span>Locale            |
</span><span>ICU Rules         |
</span><span>Access privileges |
</span><span>Size              | 6289 MB
</span><span>Tablespace        | pg_default
</span><span>Description       |
</span></code></pre>
<p>While enabling <code>\timing</code> you can test the default (WAL_LOG) strategy. And on my
test volume (relatively slow storage) I get</p>
<pre><code><span>CREATE DATABASE slow_copy TEMPLATE source_db;
</span><span>CREATE DATABASE
</span><span>Time: 67000.615 ms (01:07.001)
</span></code></pre>
<p>Now, let&#39;s verify our configuration is set for speed:</p>
<pre><code><span>show file_copy_method;
</span><span> file_copy_method
</span><span>------------------
</span><span> clone
</span><span>(1 row)
</span></code></pre>
<p>Let&#39;s request the semi-instant clone of the same database, without taking
extra disk space at the same time.</p>
<pre><code><span>CREATE DATABASE fast_clone TEMPLATE source_db STRATEGY=FILE_COPY;
</span><span>CREATE DATABASE
</span><span>Time: 212.053 ms
</span></code></pre>
<p>That&#39;s a quite an improvement, isn&#39;t it?</p>
<h2 id="working-with-cloned-data">Working with cloned data<a href="#working-with-cloned-data" aria-label="Anchor link for: working-with-cloned-data"></a>
</h2>
<p>That was the simple part. But what is happening behind the scenes?</p>
<p>When you clone a database with <code>file_copy_method = clone</code>, PostgreSQL doesn&#39;t
duplicate any data. The filesystem creates new metadata entries that point to
the same physical blocks. Both databases share identical storage.</p>
<p>This can create some initial confusion. If you ask PostgreSQL for the size:</p>
<pre data-lang="sql"><code data-lang="sql"><span>SELECT</span><span> pg_database_size(&#39;</span><span>source_db</span><span>&#39;) as source,
</span><span>       pg_database_size(&#39;</span><span>fast_clone</span><span>&#39;) as clone;
</span></code></pre>
<p>PostgreSQL reports both as ~6GB because that&#39;s the logical size - how much data
each database &#34;contains&#34; - i.e. logical size.</p>
<pre><code><span>-[ RECORD 1 ]------
</span><span>source | 6594041535
</span><span>clone  | 6594041535
</span></code></pre>
<p>The interesting part happens when you start writing. PostgreSQL doesn&#39;t update
tuples in place. When you UPDATE a row, it writes a new tuple version somewhere
(often a different page entirely) and marks the old one as dead. The filesystem
doesn&#39;t care about PostgreSQL internals - it just sees writes to 8KB pages. Any
write to a shared page triggers a copy of that entire page.</p>
<p>A single UPDATE will therefore trigger copy-on-write on multiple pages:</p>
<ul>
<li>the page holding the old tuple</li>
<li>the page receiving the new tuple</li>
<li>index pages if any indexed columns changed</li>
<li>FSM and visibility map pages as PostgreSQL tracks free space</li>
</ul>
<p>And later, VACUUM touches even more pages while cleaning up dead tuples. In this
case diverging quickly from the linked storage.</p>
<h2 id="xfs-proof">XFS proof<a href="#xfs-proof" aria-label="Anchor link for: xfs-proof"></a>
</h2>
<p>Using the database OID and relfilenode we can verify the both databases are now
sharing physical blocks.</p>
<pre><code><span>root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16402/16404
</span><span>Filesystem type is: 58465342
</span><span>File size of /var/lib/postgresql/18/main/base/16402/16404 is 1073741824 (262144 blocks of 4096 bytes)
</span><span> ext:     logical_offset:        physical_offset: length:   expected: flags:
</span><span>   0:        0..    2031:   10471550..  10473581:   2032:             shared
</span><span>   1:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
</span><span>   2:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
</span><span>   3:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
</span><span>   4:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
</span><span>   5:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
</span><span>   6:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
</span><span>/var/lib/postgresql/18/main/base/16402/16404: 7 extents found
</span><span>root@clone-demo:/var/lib/postgresql#
</span><span>root@clone-demo:/var/lib/postgresql#
</span><span>root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16418/16404
</span><span>Filesystem type is: 58465342
</span><span>File size of /var/lib/postgresql/18/main/base/16418/16404 is 1073741824 (262144 blocks of 4096 bytes)
</span><span> ext:     logical_offset:        physical_offset: length:   expected: flags:
</span><span>   0:        0..    2031:   10471550..  10473581:   2032:             shared
</span><span>   1:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
</span><span>   2:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
</span><span>   3:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
</span><span>   4:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
</span><span>   5:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
</span><span>   6:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
</span><span>/var/lib/postgresql/18/main/base/16418/16404: 7 extents found
</span></code></pre>
<p>All it takes is to update some rows using</p>
<pre data-lang="sql"><code data-lang="sql"><span>update</span><span> boring_data </span><span>set</span><span> payload = &#39;</span><span>new value</span><span>&#39; || id </span><span>where</span><span> id IN (</span><span>select</span><span> id </span><span>from</span><span> boring_data </span><span>limit </span><span>20</span><span>);
</span></code></pre>
<p>and the situation will start to change.</p>
<pre><code><span>root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16402/16404
</span><span>Filesystem type is: 58465342
</span><span>File size of /var/lib/postgresql/18/main/base/16402/16404 is 1073741824 (262144 blocks of 4096 bytes)
</span><span> ext:     logical_offset:        physical_offset: length:   expected: flags:
</span><span>   0:        0..      39:   10471550..  10471589:     40:
</span><span>   1:       40..    2031:   10471590..  10473581:   1992:             shared
</span><span>   2:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
</span><span>   3:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
</span><span>   4:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
</span><span>   5:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
</span><span>   6:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
</span><span>   7:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
</span><span>/var/lib/postgresql/18/main/base/16402/16404: 7 extents found
</span><span>root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16418/16404
</span><span>Filesystem type is: 58465342
</span><span>File size of /var/lib/postgresql/18/main/base/16418/16404 is 1073741824 (262144 blocks of 4096 bytes)
</span><span> ext:     logical_offset:        physical_offset: length:   expected: flags:
</span><span>   0:        0..      39:   10297326..  10297365:     40:
</span><span>   1:       40..    2031:   10471590..  10473581:   1992:   10297366: shared
</span><span>   2:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
</span><span>   3:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
</span><span>   4:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
</span><span>   5:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
</span><span>   6:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
</span><span>   7:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
</span><span>/var/lib/postgresql/18/main/base/16418/16404: 8 extents found
</span><span>root@clone-demo:/var/lib/postgresql#
</span></code></pre>
<p>In this case extent 0 no longer has shared flag, first 40 blocks size (with
default size 4KB) now diverge, making it total of 160KB. Each database now has
its own copy at different physical address. The remaining extents are still
shared.</p>
<h2 id="things-to-be-aware-of">Things to be aware of<a href="#things-to-be-aware-of" aria-label="Anchor link for: things-to-be-aware-of"></a>
</h2>
<p>Cloning is tempting but there&#39;s one serious limitation you need to be aware if
you ever attempt to do it in production. The source database can&#39;t have any
active connections during cloning. This is a PostgreSQL limitation, not a
filesystem one. For production use, this usually means you create a dedicated
template database rather than cloning your live database directly. Or given the
relatively short time the operation takes you have to schedule the cloning in
times where you can temporary block/terminate all connections.</p>
<p>Other limitation is that the cloning only works within a single filesystem. If
your databases spans multiple table spaces on different mount points, cloning
will fall back to regular physical copy.</p>
<p>Finally, in most managed cloud environments (AWS RDS, Google Cloud SQL), you
will not have access to the underlying filesystem to configure this. You are
stuck with their proprietary (and often billed) functionality. But for your own
VMs or bare metal? Go ahead and try it.</p>

  </div></div>
  </body>
</html>
