<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://organicdonut.com/2024/06/cuda-two/">Original</a>
    <h1>CUDA â€“ Two</h1>
    
    <div id="readability-page-1" class="page"><div>
			<p>I have an art sale coming up in three days, so Iâ€™m spending most of my focus time finishing up the inventory for that. But in my spare time between holding the baby and helping my older kid sell lemonade, Iâ€™ve started exploring a few of the topics Iâ€™m interested in from the <a href="https://organicdonut.com/2024/06/cuda-one/">previous post</a>.</p>
<p><strong>Convolutions</strong></p>
<p>Something I was reading mentioned convolutions, and I had no idea what that meant, so I tried to find out! I read several posts and articles, but the thing that made Convolutions click for me was <a href="https://youtu.be/KuXjwB4LzSA">a video by 3 Blue 1 Brown</a>. The video has intuitive visualizations. Cheers to good technology and math communicators.</p>
<p>Sliding a kernel over data feels intuitive to me, and it looks like one of the cool things about this is that you can do this with extreme parallelism. Iâ€™m pretty sure this is covered early on in the textbook, so Iâ€™m not going to worry about understanding this completely yet.</p>
<p>It seems like convolutions are important for image processing, especially things like blur and edge detection, but also in being able to do feature detection â€“ it allows us to search for a feature across an entire image, and not just in a specific location in an image.</p>
<p>One thing I donâ€™t understand yet is how to build a convolution kernel for complicated feature detection. One of the articles I read mentioned that you could use feature detection convolution for something like eyes, which I assume requires a complicated kernel thatâ€™s trained with ML techniques. But I donâ€™t quite understand what that kernel would look like or how you would build it.</p>
<p><strong>Parallel Processing</strong></p>
<p>I started readingÂ <em>Programming Massively Parallel</em> <em>Processors,</em> and so far itâ€™s just been the introduction. I did read it out loud to my newborn, so hopefully heâ€™ll be a machine learning expert by the time heâ€™s one.</p>
<p>Topics covered so far have been the idea of massive parallelism, the difference between CPU and GPU, and a formal definition of â€œspeed upâ€œ.</p>
<p>I do like that the book is focused on parallel programming andÂ <em>not</em> ML. It allows me to focus on just that one topic without needing to learn several other difficult concepts at the same time. I peeked ahead and saw a chapter on massively parallel radix sort, and the idea intrigues me.</p>
<p><strong>Differentiation and Gradient Descent</strong></p>
<p>Again, <a href="https://youtu.be/IHZwWFHWa-w">3B1B had the best video</a> on this topic that I could find. The key new idea here was that you can encode the weights of a neural network as an enormous vector, and then map that vector to a fitness score via a function. Finding the minimum of this function gives us the best neural network for whatever fitness evaluation method weâ€™ve chosen. It hurts my brain a bit to think in that many dimensions, but I just need to get used to that if Iâ€™m going to work with ML. I donâ€™t fully understand what differentiation means in this context, but Iâ€™m starting to get some of the general concept (we can see a â€œgood directionâ€ to move in).</p>
<p>I havenâ€™t worked with gradients since Calc III in college, which was over a decade ago, but Iâ€™ve done it once and I can do it again ğŸ’ª. It also looks like I need to understand the idea of total derivative versus partial derivative, which feels vaguely familiar.</p>
<p><strong>Moving Forward</strong></p>
<p>Once the art sale is over, Iâ€™ll hopefully have more focus time for this ğŸ™‚ For now, itâ€™ll be bits and pieces here and there. For learning CUDA in particular, it looks like working through the textbook is going to be my best bet, so Iâ€™m going to focus some energy there.</p>
<p>From Grand Rapids,</p>

					</div></div>
  </body>
</html>
