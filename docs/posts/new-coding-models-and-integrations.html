<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ollama.com/blog/coding-models">Original</a>
    <h1>New coding models and integrations</h1>
    
    <div id="readability-page-1" class="page"><article>
    
    <h2>October 16, 2025</h2>
    
    
    <section>
      <p><img src="https://files.ollama.com/ollama-coding.png" alt="Illustration of Ollama coding"/></p>

<p><a href="https://ollama.com/library/glm-4.6">GLM-4.6</a> and <a href="https://ollama.com/library/qwen3-coder">Qwen3-coder-480B</a> are available on Ollama’s cloud service with easy integrations to the tools you are familiar with. Qwen3-Coder-30B has been updated for faster, more reliable tool calling in Ollama’s new engine.</p>

<h2 id="get-started">Get started</h2>

<p><strong>GLM-4.6</strong></p>

<pre><code>ollama run glm-4.6:cloud
</code></pre>

<p><strong>Qwen3-Coder-480B</strong></p>

<pre><code>ollama run qwen3-coder:480b-cloud
</code></pre>

<p>For users with more than 300GB of VRAM, <a href="https://ollama.com/library/qwen3-coder"><code>qwen3-coder:480b</code></a> is also available locally.</p>

<p><strong>Qwen3-Coder-30B</strong></p>

<pre><code>ollama run qwen3-coder:30b
</code></pre>

<h3 id="example-prompts">Example prompts</h3>

<pre><code>Create a single-page app in a single HTML file with the following requirements:

Name: Ollama&#39;s Adventure 
Goal: Jump over obstacles to survive as long as possible.
Features: Increasing speed, high score tracking, retry button, and funny sounds for actions and events.

The UI should be colorful, with parallax scrolling backgrounds.
The characters should look cartoonish, related to alpacas and be fun to watch.
The game should be enjoyable for everyone.
</code></pre>

<p><a href="https://gist.github.com/mchiang0610/32bce599bcf926ad4989ee8136bd35ec">Example code</a> by GLM-4.6 in a single prompt</p>

<p><img src="https://files.ollama.com/ollama-adventure-1-min.png" alt="example image of the HTML site running"/></p>

<p><img src="https://files.ollama.com/ollama-adventure-2-min.png" alt="example image 2 of the HTML site running"/></p>

<h2 id="usage-with-vs-code">Usage with VS Code</h2>

<p>First, pull the coding models so they can be accessed via VS Code:</p>

<pre><code>ollama pull glm-4.6:cloud
ollama pull qwen3-coder:480b-cloud
</code></pre>

<ol>
<li>Open the copilot chat sidebar</li>
<li>Select the model dropdown → <strong>Manage models</strong></li>
<li>Click on <strong>Ollama</strong> under <strong>Provider Dropdown,</strong> then select desired models</li>
<li>Select the model dropdown → and choose the model (e.g. <code>glm-4.6</code>)</li>
</ol>

<h2 id="usage-with-zed">Usage with Zed</h2>

<p>First pull the coding models so they can be accessed via Zed:</p>

<pre><code>ollama pull glm-4.6:cloud
ollama pull qwen3-coder:480b-cloud
</code></pre>

<p>Then, open <a href="https://zed.dev/download">Zed</a> (now available for Windows!)</p>

<ol>
<li>Click on the agent panel button (glittering stars)</li>
<li>Click on the <strong>model dropdown</strong> → <strong>Configure</strong></li>
<li>Select <strong>LLM providers</strong> → <strong>Ollama</strong></li>
<li>Confirm the <strong>Host URL</strong> is <strong><code>http://localhost:11434</code></strong>, then click <strong>Connect</strong></li>
<li>Select a model under <strong>Ollama</strong></li>
</ol>

<h2 id="usage-with-droid">Usage with Droid</h2>

<p>First, <a href="https://docs.factory.ai/cli/getting-started/quickstart">install Droid</a>:</p>

<pre><code>curl -fsSL https://app.factory.ai/cli | sh
</code></pre>

<p>Add the following configuration to <code>~/.factory/config.json</code>:</p>

<pre><code>{
  &#34;custom_models&#34;: [
    {
      &#34;model_display_name&#34;: &#34;GLM-4.6&#34;,
      &#34;model&#34;: &#34;glm-4.6:cloud&#34;,
      &#34;base_url&#34;: &#34;http://localhost:11434/v1&#34;,
      &#34;api_key&#34;: &#34;not-needed&#34;,
      &#34;provider&#34;: &#34;generic-chat-completion-api&#34;,
      &#34;max_tokens&#34;: 16384
    },
    {
      &#34;model_display_name&#34;: &#34;Qwen3-Coder-480B&#34;,
      &#34;model&#34;: &#34;qwen3-coder:480b-cloud&#34;,
      &#34;base_url&#34;: &#34;http://localhost:11434/v1&#34;,
      &#34;api_key&#34;: &#34;not-needed&#34;,
      &#34;provider&#34;: &#34;generic-chat-completion-api&#34;,
      &#34;max_tokens&#34;: 16384
    }
  ]
}
</code></pre>

<p>Then run Droid and type <code>/model</code> to change to the model:</p>

<pre><code>╭──────────────────────────────────────────────────╮
│ &gt; GLM-4.6 [current]                              │
│   Qwen3-Coder-480B                               │
│                                                  │
│ ↑/↓ to navigate, Enter to select, ESC to go back │
╰──────────────────────────────────────────────────╯
</code></pre>

<h2 id="integrations">Integrations</h2>

<p>Ollama’s documentation now includes sections on using Ollama with popular coding tools:</p>

<ul>
<li><a href="https://docs.ollama.com/integrations/codex">Codex</a></li>
<li><a href="https://docs.ollama.com/integrations/cline">Cline</a></li>
<li><a href="https://docs.ollama.com/integrations/vscode">VS Code</a></li>
<li><a href="https://docs.ollama.com/integrations/zed">Zed</a></li>
<li><a href="https://docs.ollama.com/integrations/droid">Droid</a></li>
<li><a href="https://docs.ollama.com/integrations/roo-code">Roo code</a></li>
</ul>

<h2 id="cloud-api-access">Cloud API access</h2>

<p>Cloud models such as <code>glm-4.6</code> and <code>qwen3-coder:480b</code> can also be accessed directly via ollama.com’s cloud API:</p>

<p>First, <a href="https://ollama.com/settings/keys">create an API key</a>, and set it in your environment</p>

<pre><code>export OLLAMA_API_KEY=&#34;your_api_key_here&#34;
</code></pre>

<p>Then, call ollama.com’s API</p>

<pre><code>curl https://ollama.com/api/chat \
    -H &#34;Authorization: Bearer $OLLAMA_API_KEY&#34; \
    -d &#39;{
    &#34;model&#34;: &#34;glm-4.6&#34;,
    &#34;messages&#34;: [{
      &#34;role&#34;: &#34;user&#34;,
      &#34;content&#34;: &#34;Write a snake game in HTML.&#34;
    }]
}&#39;
</code></pre>

<p>For more information see the Ollama’s <a href="https://docs.ollama.com/cloud#cloud-api-access">API documentation</a>.</p>

    </section>
  </article></div>
  </body>
</html>
