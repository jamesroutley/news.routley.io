<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.featureform.com/post/deploy-mcp-on-aws-lambda-with-mcpengine">Original</a>
    <h1>MCP on AWS Lambda with MCPEngine</h1>
    
    <div id="readability-page-1" class="page"><div><p>Model Context Protocol (MCP) is quickly becoming the standard for enabling LLMs to call external tools. It’s built around clean, declarative tool definitions—but most current implementations fall short of being production-ready. Every official MCP server in the Anthropic repo, for instance, runs locally and communicates over stdio. Even the few that support HTTP rely on Server-Sent Events (SSE) for streaming. This introduces stateful behavior, requiring persistent TCP connections, complicating retries, and ultimately making it incompatible with stateless environments like AWS Lambda. <a href="https://www.featureform.com/post/what-mcp-gets-wrong">We’ve written more about these limitations, and how we’ve addressed them with MCPEngine.</a></p><p>AWS Lambda offers instant scalability, no server management, and efficient, event-driven execution. We built native support for it in MCPEngine, so that MCP tools can run cleanly and reliably in serverless environments.</p><p><a href="http://github.com/featureform/mcp-engine"><strong>MCPEngine</strong></a> is an open-source implementation of MCP that supports streamable HTTP alongside SSE, making it compatible with Lambda. It also includes first-class support for authentication, packaging, and other capabilities to build and deploy production-grade MCP servers.</p><p>This post walks through building three progressively more realistic examples:</p><ol role="list"><li>A stateless MCP server with a single tool</li><li>A stateful version using RDS and a context handler</li><li>An authenticated version using OIDC (Google or Cognito)</li></ol><p>All three run entirely in Lambda, don&#39;t require a custom agent, and are MCP-spec compliant.</p><h2><strong>1. Build and Deploy a Stateless Weather MCP API</strong></h2><p>You can follow along on <a href="https://github.com/featureform/mcp-engine/tree/main/examples/servers/lambda-weather">GitHub here for the full project</a>.</p><h3><strong>1.1 Defining the MCP Server</strong></h3><p>We&#39;ll start with a single tool called get_weather. It takes a city name and returns a canned string response. There&#39;s no state or external API call — just enough to validate end-to-end behavior with a live LLM.</p><p>Install the Python SDK:</p><pre contenteditable="false"><code><span>pip install mcpengine[cli,lambda]</span></code></pre><p>Create a file called app.py:</p><pre contenteditable="false"><code><span>from</span><span> mcpengine </span><span>import</span><span> MCPEngine
</span>
engine = MCPEngine()

<span></span><span>@engine.tool()</span><span>
</span><span></span><span>def</span><span> </span><span>get_weather</span><span>(</span><span>city: </span><span>str</span><span>) -&gt; </span><span>str</span><span>:</span><span>
</span><span>    </span><span>&#34;&#34;&#34;Return the current weather for a given city.
</span><span>    &#34;&#34;&#34;</span><span>
</span><span>    </span><span>return</span><span> </span><span>f&#34;The weather in </span><span>{city}</span><span> is sunny and 72°F.&#34;</span><span>‍
</span>
handler = engine.get_lambda_handler()</code></pre><p>What this does:</p><ul role="list"><li><code>@engine.tool</code> registers the function with the MCP manifest. The function name (`get_weather`) becomes the tool name exposed to the LLM.</li><li>The docstring is exposed in the manifest and shown to the LLM during tool selection.</li><li>handler is the AWS Lambda-compatible entry point. No glue code required — Lambda is configured to look for a global named handler and MCPEngine handles the request lifecycle.</li></ul><h3><strong>1.2 Deploying to Lambda</strong></h3><p>You can deploy this manually or use Terraform to automate setup.</p><h4><strong>Option 1: Terraform</strong></h4><p>If you want to skip most of the boilerplate, we provide Terraform scripts that:</p><ul role="list"><li>Creates an ECR repository to host the image</li><li>Provisions the Lambda function and IAM roles</li><li>Exposes it via a Function URL</li></ul><p>You can run it in the directory by calling:</p><pre contenteditable="false"><code><span>terraform apply</span></code></pre><p>Grab the ECR repository url and Lambda function name from the terraform output:</p><pre contenteditable="false"><code><span>export</span><span> REPOSITORY_URL=$(terraform output -raw repository_url)
</span><span></span><span>export</span><span> FUNCTION_NAME=$(terraform output -raw lambda_name) </span></code></pre><p>And then build, tag, and push the image:</p><pre contenteditable="false"><code><span>docker build --platform=linux/amd64 --provenance=</span><span>false</span><span> -t mcp-lambda:latest .
</span><span>docker tag mcp-lambda </span><span>${REPOSITORY_URL}</span><span>:latest
</span><span>docker push </span><span>${REPOSITORY_URL}</span><span>:latest</span></code></pre><p>Finally, we’ll update the Lambda with this new image:</p><pre contenteditable="false"><code><span>aws lambda update-function-code \
</span><span>--function-name </span><span>${FUNCTION_NAME}</span><span> \
</span><span>--image-uri </span><span>${REPOSITORY_URL}</span><span>:latest</span></code></pre><p>And the application will be running. Once deployed, you can tear it down with:</p><pre contenteditable="false"><code><span>terraform destroy</span></code></pre><h4><strong>Option 2: From Scratch</strong></h4><p>If you prefer to deploy manually:</p><p>Step 1: Dockerize the Server</p><pre contenteditable="false"><code><span>FROM</span><span> public.ecr.aws/lambda/python:</span><span>3.12</span><span>
</span><span></span><span># Set working directory in the container</span><span>
</span><span></span><span>WORKDIR</span><span> /var/task</span><span>
</span><span></span><span># Copy application code</span><span>
</span><span></span><span>COPY</span><span> . .</span><span>
</span><span></span><span># Install dependencies</span><span>
</span><span></span><span>RUN</span><span> pip install --system --no-cache-dir .</span><span>
</span><span></span><span># Expose port for the server</span><span>
</span><span></span><span>EXPOSE</span><span> </span><span>8000</span><span>
</span><span></span><span># Command to run the web server</span><span>
</span><span></span><span>CMD</span><span> [</span><span>&#34;weather.server.handler&#34;</span><span>]</span></code></pre><p>Then:</p><pre contenteditable="false"><code><span>docker build --platform=linux/amd64 --provenance=</span><span>false</span><span> -t mcp-lambda .</span></code></pre><p>Step 2: Push to ECR</p><pre contenteditable="false"><code><span>docker tag mcp-lambda:latest &lt;your-ecr-url&gt;/mcp-lambda:latest
</span>docker push &lt;your-ecr-url&gt;/mcp-lambda:latest</code></pre><p>Step 3: Deploy to Lambda</p><pre contenteditable="false"><code><span>aws lambda create-function \
</span>  --function-name mcp-lambda \
  --package-type Image \
  --code ImageUri=&lt;your-ecr-url&gt;/mcp-lambda:latest \
  --role arn:aws:iam::&lt;account-id&gt;:role/&lt;lambda-role&gt;
</code></pre><p>Step 4: Add permissions for Lambda</p><pre contenteditable="false"><code><span>aws iam create-role \
</span>    --role-name lambda-container-execution \
<span>    --assume-role-policy-document </span><span>&#39;{
</span><span>        &#34;Version&#34;: &#34;2012-10-17&#34;,
</span><span>        &#34;Statement&#34;: [
</span><span>            {
</span><span>                &#34;Effect&#34;: &#34;Allow&#34;,
</span><span>                &#34;Principal&#34;: {
</span><span>                    &#34;Service&#34;: &#34;lambda.amazonaws.com&#34;
</span><span>                },
</span><span>                &#34;Action&#34;: &#34;sts:AssumeRole&#34;
</span><span>            }
</span><span>        ]
</span><span>    }&#39;</span><span>
</span>aws iam attach-role-policy \
    --role-name lambda-container-execution \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole</code></pre><p>Step 5: Enable a Function URL, and add an allow-all permission to call it:</p><pre contenteditable="false"><code><span>aws lambda create-function-url-config \
</span>  --function-name mcp-lambda \
  --auth-type NONE
aws lambda add-permission \
    --function-name mcp-lambda \
    --function-url-auth-type NONE \
    --action lambda:InvokeFunctionUrl \
    --statement-id PublicInvoke \
<span>    --principal </span><span>&#39;*&#39;</span></code></pre><h3><strong>1.3 Connecting via Claude</strong></h3><p>Once deployed, you can connect to the server using any compatible LLM. For example, to connect from Claude:</p><pre contenteditable="false"><code><span>mcpengine proxy &lt;service-name&gt; &lt;your-lambda-function-url&gt; --mode http --claude</span></code></pre><p>Open Claude, and your tool should appear at the bottom of the chat bubble. When you ask something like &#34;What&#39;s the weather in Tokyo?&#34;, Claude will:</p><ul role="list"><li>Select the tool based on its manifest description</li><li>Prompt the user to authorize the request</li><li>Call the endpoint with the tool name and arguments</li></ul><p>That&#39;s it. You now have a fully deployed, Lambda-hosted MCP server, responding to real LLM calls over HTTP.</p><h2><strong>2. Building and Deploying a Stateful Slack-like MCP API</strong></h2><p>You can follow along on <a href="https://github.com/featureform/mcp-engine/tree/main/examples/servers/smack">GitHub here for the full project</a>.</p><p>Stateless tools are useful for demos, but most real applications need to persist data. In this section, we&#39;ll extend the minimal MCP server to include state. Specifically, we&#39;ll build a basic Slack-like message board that stores and retrieves messages from a relational database.</p><p>This version uses:</p><ul role="list"><li>Postgres on Amazon RDS for persistent storage</li><li>A context handler to manage a connection pool</li><li>Two tools: one to post a message, one to list messages</li></ul><p>The goal is not to build a full chat system, just to show how you can add state to an MCP server without giving up stateless infrastructure like Lambda.</p><h3><strong>2.1 Defining the Data Model</strong></h3><p>We&#39;ll store each message as a row in a single table. For simplicity, all messages go into the same global timeline.</p><p>The schema will look like:</p><pre contenteditable="false"><code><span>CREATE</span><span> </span><span>TABLE</span><span> messages (
</span><span>  id SERIAL </span><span>PRIMARY</span><span> KEY, 
</span><span>  username TEXT </span><span>NOT</span><span> </span><span>NULL</span><span>, 
</span><span>  text TEXT </span><span>NOT</span><span> </span><span>NULL</span><span>, 
</span><span>  </span><span>timestamp</span><span> </span><span>TIMESTAMP</span><span> </span><span>DEFAULT</span><span> now() 
</span>);</code></pre><p><code>post_message()</code> will insert into this table, and <code>get_messages()</code> will return the most recent entries.</p><h3><strong>2.2 Managing Connections with a Context Handler</strong></h3><p>You shouldn&#39;t open database connections inside your tool functions. Instead, MCPEngine provides a context system: you define a setup function that runs before the server boots up, and MCPEngine makes the result available as <code>ctx</code>.</p><p>In this case, the context will:</p><ul role="list"><li>Open a connection pool to RDS</li><li>Attach it to the request context (<code>ctx.db</code>)</li><li>Clean up after the tool finishes</li></ul><p>This keeps your tools focused on business logic, not lifecycle management.</p><h3><strong>2.3 Implementing the Tools &amp; Context</strong></h3><p>Assuming <code>ctx.db</code> is a valid psycopg2 connection, the tools look like this:</p><pre contenteditable="false"><code><span>@engine.tool()</span><span>
</span><span></span><span>def</span><span> </span><span>post_message</span><span>(</span><span>ctx: Context, username: </span><span>str</span><span>, text: </span><span>str</span><span>) -&gt; </span><span>str</span><span>:</span><span> 
</span><span>    </span><span>&#34;&#34;&#34;Post a message to the global timeline.&#34;&#34;&#34;</span><span> 
</span><span>    </span><span>with</span><span> ctx.db.cursor() </span><span>as</span><span> cur:
</span><span>        cur.execute(</span><span>&#34;INSERT INTO messages (username, text) VALUES (%s, %s)&#34;</span><span>, (username, text)) 
</span>        ctx.db.commit() 
<span>    </span><span>return</span><span> </span><span>&#34;Message posted.&#34;</span><span>
</span>
<span></span><span>@engine.tool()</span><span>
</span><span></span><span>def</span><span> </span><span>get_messages</span><span>(</span><span>ctx: Context</span><span>) -&gt; </span><span>list</span><span>[</span><span>str</span><span>]:</span><span> 
</span><span>    </span><span>&#34;&#34;&#34;Get the most recent messages.&#34;&#34;&#34;</span><span> 
</span><span>    </span><span>with</span><span> ctx.db.cursor() </span><span>as</span><span> cur: 
</span><span>        cur.execute(</span><span>&#34;SELECT username, text FROM messages ORDER BY timestamp DESC LIMIT 10&#34;</span><span>) 
</span><span>        </span><span>return</span><span> [</span><span>f&#34;</span><span>{row[</span><span>0</span><span>]}</span><span>: </span><span>{row[</span><span>1</span><span>]}</span><span>&#34;</span><span> </span><span>for</span><span> row </span><span>in</span><span> cur.fetchall()]</span></code></pre><p>Add the context handler:</p><pre contenteditable="false"><code><span>@asynccontextmanager</span><span>
</span><span></span><span>def</span><span> </span><span>app_lifespan</span><span>():</span><span> 
</span><span>    </span><span>import</span><span> psycopg2 
</span>    conn = psycopg2.connect( 
<span>        host=os.environ[</span><span>&#34;DB_HOST&#34;</span><span>], 
</span><span>        user=os.environ[</span><span>&#34;DB_USER&#34;</span><span>], 
</span><span>        password=os.environ[</span><span>&#34;DB_PASS&#34;</span><span>], 
</span><span>        dbname=os.environ[</span><span>&#34;DB_NAME&#34;</span><span>], 
</span>    ) 
<span>    </span><span>try</span><span>: 
</span><span>        </span><span>yield</span><span> {</span><span>&#34;db&#34;</span><span>: conn} 
</span><span>    </span><span>finally</span><span>: 
</span>        conn.close()</code></pre><p>You then update the constructor of the MCPEngine, to pass it this lifespan context builder.</p><pre contenteditable="false"><code><span>engine = MCPEngine(
</span>    lifespan=app_lifespan,
)</code></pre><p>MCPEngine will run the lifecycle to get the connection pool as the server boots up, and will attach it as context to every request that comes in. Additionally, when the server stops and shuts down, it will run the cleanup (everything after the yield statement).</p><h3><strong>2.4 Deploying the Server</strong></h3><p>We recommend using Terraform here, since this version involves provisioning an RDS instance, IAM roles, and security groups. If you prefer to deploy manually, you can use the Terraform script as a reference.</p><pre contenteditable="false"><code><span>terraform apply</span></code></pre><p>This will:</p><ul role="list"><li>Create the database</li><li>Set up a Lambda function with the correct environment variables</li></ul><p>Grab the ECR repository url and Lambda function name from the terraform output:</p><pre contenteditable="false"><code><span>export</span><span> REPOSITORY_URL=$(terraform output -raw repository_url)
</span><span></span><span>export</span><span> FUNCTION_NAME=$(terraform output -raw lambda_name)</span></code></pre><p>And then build, tag, and push the image:</p><pre contenteditable="false"><code><span>docker build --platform=linux/amd64 --provenance=</span><span>false</span><span> -t mcp-lambda:latest .
</span><span>docker tag mcp-lambda </span><span>${REPOSITORY_URL}</span><span>:latest
</span><span>docker push </span><span>${REPOSITORY_URL}</span><span>:latest</span></code></pre><p>Finally, we’ll update the Lambda with this new image:</p><pre contenteditable="false"><code><span>aws lambda update-function-code \
</span><span>  --function-name </span><span>${FUNCTION_NAME}</span><span> \
</span><span>  --image-uri </span><span>${REPOSITORY_URL}</span><span>:latest</span></code></pre><p>When you&#39;re done, you can tear down the resources with:</p><pre contenteditable="false"><code><span>terraform destroy</span></code></pre><h3><strong>2.5 Connecting and Testing</strong></h3><p>Once deployed, connect Claude again using:</p><pre contenteditable="false"><code><span>mcpengine proxy &lt;service-name&gt; &lt;your-</span><span>lambda</span><span>-function-url&gt; --claude --mode http</span></code></pre><p>Open Claude and you should now see two tools: <code>post_message</code> and <code>get_messages</code>.</p><p>You can prompt Claude to send or retrieve messages. You can also connect from another Claude window, use the same tools, and confirm the messages are shared — even across users and cold starts.</p><h2><strong>3. Adding Authentication with Google SSO</strong></h2><p>You can follow along on <a href="https://github.com/featureform/mcp-engine/tree/main/examples/servers/smack">GitHub here for the full project</a>.</p><p>The tools we&#39;ve built so far work, but they&#39;re open. Anyone can call them, impersonate any username, and there&#39;s no mechanism for verifying identity. That might be fine for testing, but it&#39;s not acceptable in anything that resembles a production system.</p><p>MCPEngine supports token-based authentication using standard OpenID Connect (OIDC). That means you can integrate with any identity provider that issues JWTs, including Google, AWS Cognito, Auth0, or your internal auth stack.</p><p>In this section, we&#39;ll secure our existing tools using Google as the identity provider. We&#39;ll:</p><ul role="list"><li>Register a Google OAuth app</li><li>Modify our MCP server to require valid tokens</li><li>Pass the token through Claude (or any other client)</li><li>Read the authenticated user from the request context</li></ul><h3><strong>3.1 Creating a Google OAuth App</strong></h3><p>First, set up an OAuth client in Google Cloud:</p><ol role="list"><li>Go to Google Cloud Console</li><li>Select or create a project</li><li>Navigate to APIs &amp; Services &gt; Credentials</li><li>Click Create Credentials &gt; OAuth client ID</li><li>Set application type to Web application</li><li>Add an authorized redirect URI (you can use<a href="http://localhost"> http://localhost</a> for local testing)</li><li>Save the client and note the Client ID</li></ol><p>That&#39;s all you need for server-side token validation — the Client ID and the standard Google issuer (<a href="https://accounts.google.com">https://accounts.google.com</a>).</p><h3><strong>3.2 Updating MCPEngine for Auth</strong></h3><p>To enable auth, you&#39;ll need to:</p><ol role="list"><li>Set the <code>idp_config</code>  when constructing the engine:</li></ol><pre contenteditable="false"><code><span>from</span><span> mcpengine </span><span>import</span><span> MCPEngine, GoogleIdpConfig
</span>
engine = MCPEngine(
    lifespan=app_lifespan,
    idp_config=GoogleIdpConfig(),
)</code></pre><p>This tells MCPEngine to use Google&#39;s public JWKS endpoint to verify incoming tokens.</p><ol start="2" role="list"><li>Restrict access to tools using <code>@engine.auth()</code>:</li></ol><pre contenteditable="false"><code><span>@engine.auth()</span><span>
</span><span></span><span>@engine.tool()</span><span>
</span><span></span><span>def</span><span> </span><span>post_message</span><span>(</span><span>text: </span><span>str</span><span>, ctx: Context</span><span>) -&gt; </span><span>str</span><span>:</span><span>
</span><span>    </span><span>&#34;&#34;&#34;Post a message to the global timeline.&#34;&#34;&#34;</span><span>
</span><span>    </span><span># Only runs if the token is valid</span><span>
</span>    ...</code></pre><p>If the request doesn&#39;t include a valid token, it will be rejected automatically. If it does, user info will be available through the context.</p><h3><strong>3.3 Updating the Client</strong></h3><p>When calling a protected tool from a client, you need to pass a valid Google-issued ID token. Claude handles this automatically once it sees that the tool requires authentication.</p><p>When you install the tool in Claude, add the client ID and client secret:</p><pre contenteditable="false"><code><span>mcpengine proxy &lt;service-name&gt; &lt;your-endpoint&gt; --claude --client-id &lt;google-client-id&gt; --client-secret &lt;google-client-secret&gt; --mode http</span></code></pre><p>This tells Claude to request a token from Google using your registered client ID. When the user grants permission, Claude includes that token in every call to your MCP server.</p><p>You don&#39;t need to verify anything manually; MCPEngine handles token validation and decoding internally.</p><h3><strong>3.4 Deploying the Updated Server</strong></h3><p>You don&#39;t need to change the Dockerfile or tool definitions — just make sure you:</p><ul role="list"><li>Pass the issuer_url (either in code or via environment variables)</li><li>Rebuild and push your Docker image</li><li>Redeploy to Lambda with the new version</li></ul><pre contenteditable="false"><code><span>docker build --platform=linux/amd64 --provenance=</span><span>false</span><span> -t mcp-lambda .
</span><span>docker tag mcp-lambda </span><span>${REPOSITORY_URL}</span><span>/mcp-lambda
</span><span>docker push </span><span>${REPOSITORY_URL}</span><span>/mcp-lambda
</span>aws lambda update-function-code \
  --function-name mcp-lambda \
<span>  --image-uri </span><span>${REPOSITORY_URL}</span><span>/mcp-lambda:latest</span></code></pre><h3><strong>3.5 Confirming It Works</strong></h3><p>Once deployed:</p><ul role="list"><li>Claude should now prompt the user to authenticate via Google before calling a protected tool</li><li>The call will only succeed if a valid token is present</li><li>You can access the user&#39;s identity via <code>ctx</code> </li></ul><h2><strong>Recap</strong></h2><p>With two changes — adding <code>idp_config</code> to the engine and decorating tools with <code>@engine.auth()</code> — we&#39;ve added working authentication to our MCP server. Google handles the user login. Claude handles the token flow. MCPEngine handles the verification and exposes identity to your tool code.</p><p>At this point, we&#39;ve deployed three working MCP servers on AWS Lambda:</p><ol role="list"><li>A stateless one that returns a weather response</li><li>A stateful one that uses RDS to persist and retrieve chat messages</li><li>A secure one using Google SSO for authentication</li></ol><p>The authenticated example is closer to a real-world use case. It&#39;s minimal, but demonstrates that you can build something stateful, Lambda-native, and MCP-compliant, without ever running a server or maintaining sticky connections.</p><p>We used Claude as the client here, but the interface is fully standard MCP. You can just as easily connect using the MCPEngine client from another LLM or orchestrator. This opens the door to agentic systems. For example, you could:</p><ul role="list"><li>Spin up a simulated product manager and engineer</li><li>Drop them into the same chatroom</li><li>Let them exchange ideas, log tickets, and revise specs — all in the open</li></ul><p>None of this requires any special integrations. Just tools, schemas, and tokens.</p><p>As of today, <a href="http://github.com/featureform/mcp-engine">MCPEngine is the only Python implementation of MCP that supports built-in authentication</a>. In the next post, we&#39;ll walk through more complex authentication patterns including scoped access, restricting tools to specific users, and surfacing identity inside the tool logic.</p></div></div>
  </body>
</html>
