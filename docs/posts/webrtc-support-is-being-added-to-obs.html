<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/obsproject/obs-studio/discussions/4021">Original</a>
    <h1>WebRTC support is being added to OBS</h1>
    
    <div id="readability-page-1" class="page"><div disabled="" sortable="">
  <div>
            <p dir="auto">So, here&#39;s my response, written w/ input from those in the FTL dev group; apologize for the length but I wanted to cover all points here.</p>
<p dir="auto">So, talking from a historical context, FTL&#39;s entire design goal was to get sub second (ideally 500ms or less, real world, we got to 200-250ms) from streamer to the browser under &#34;good&#34; to ideal Internet conditions without add-on software.</p>
<p dir="auto">To that end, it was specifically designed to skip a muxing step, allow for easy implementation of a O(1) hard real time ingest (a naive FTL ingest can be implemented simply by modifying a few bits of each RTP packet in transit). The entire intent was to implement like Stadia or xCloud <em>in browser</em>, and it was overwhelmingly successful in that role. While Microsoft didn&#39;t push Beam/Mixer Plays, the FTL technology has a six year history of doing exactly what it was designed to do.</p>
<p dir="auto">Creating a new streaming protocol was not done lightly at Mixer, and frankly, none of the alternatives promise to hit the real time concerns of &#34;in browser&#34; streaming that FTL can, and I&#39;m not convinced that even in ideal situations they will.</p>
<p dir="auto">The primary difference between WebRTC, RIST, and HST vs. FTL is that FTL is designed to lose packets and intentionally does not give any notion of reliable packet delivery. While there is a small retransmission buffer built into ftl-sdk (which was implemented after I stepped away from FTL), it&#39;s (as far as I can tell) primarily to smooth out H.264 issues. From the RIST specification, the re-transmission effect is much larger, and doesn&#39;t appear to have an upper bound on how far it can queue. The entire intent appears to re-implement TCP/IP reliability onto of RTP. While this will give good performance in good conditions and be manageable in bad, it creates a problem if you need to stay in realtime.</p>
<p dir="auto">With FTL, it essentially YOLOs each packet (and this plays into the last mile, but I&#39;ll get to that). RIST on the other hand is specifically designed as reliable and has a large middleware level to allow resumption in case of stream interruption. While RIST is indeed built on RTP and SRTP, it doesn&#39;t specifically promise a latency goal. While it <em>might</em> be possible to get the same low latency performance over RIST, it&#39;s not a design goal of the protocol, and TBH, I&#39;m less than fond of tossing out the &#34;known to work&#34; solution for one that is not proven.</p>
<p dir="auto">RIST’s retransmission facilities are also not really designed for the notion of synchronization. The client can request transmission via block or specific packets, but not to a specific KF interval like can be done with H.264/FTL streaming. While retransmission is technically optional, it does exist in FTL today for a specific purpose. The original VP8/Opus FTL implementation actually didn’t have any re-transmission facilities, and could hit 200-250ms latency real world. I do intend to look at reviving this functionality.</p>
<p dir="auto">In a RIST world, you send NAKs to get the packet retransmitted and you have a fairly large state machine on-top of that, which basically is TCP/IP implemented onto of UDP with RTP. Furthermore, RIST still doesn’t handle signaling of information like video metadata and similar which is a specific feature that Charon (FTL’s handshake) implements.</p>
<p dir="auto">While RIST might be a replacement for FTL at some day, it doesn’t actually provide anything over the current implementation, and still requires additional infrastructure to be used. In short, actually adopting RIST doesn’t solve a problem.</p>
<p dir="auto">This brings me to the topic of WISH/WHIP and WebRTC.</p>
<p dir="auto">To be frank, I’m not certain why WISH or WHIP is being brought up; given that we have two separate specifications that try to solve WebRTC signaling, it’s pretty clear this isn’t a solved problem.</p>
<p dir="auto">Before I dig into either, I do want to talk a bit about WebRTC’s own signaling mechanism: the Session Description Protocol (SDP). SDP underpins all WebRTC calls, and is also used in VOIP. It’s a nightmarishly complex handshake, with a very loosely defined standard. When I looked at doing FTL originally, I did actually look at the possibility of building the signaling information into SDP, and decided that the best solution was to run as fast as I can.</p>
<p dir="auto">WISH and WHIP both appear to be extensions of SDP which means they inherit all the problems with SDP. While it is a slightly old article, this sums up the pain points pretty well: <a href="https://webrtchacks.com/webrtc-sdp-inaki-baz-castillo/" rel="nofollow">https://webrtchacks.com/webrtc-sdp-inaki-baz-castillo/</a>. I highly recommend going through WebRTC Hack’s section about SDP before advocating any solution built around it.</p>
<p dir="auto">I’ll start by talking about WISH first: the IETF specification is in the Internet-Draft stage, and still in the Proposed WG state: <a href="https://datatracker.ietf.org/wg/wish/about/" rel="nofollow">https://datatracker.ietf.org/wg/wish/about/</a>. I’m not even certain there’s a reference implementation of the specification. Furthermore, WISH is a direct extension of the SDP protocol which means all the pain points are primarily there.</p>
<p dir="auto">SDP has a fiendishly complex protocol negotiation because its essentially intended to make two VoIP phones from different manufacturers agree on some sorta standard to talk with each other. WebRTC not only uses this for talking to browsers, but adds a very complicated stack of ICE connectivity. Even though things like STUN have gone to the wayside, it’s pretty hard to say that this is a desirable thing.</p>
<p dir="auto">In contrast, if you can make TCP and UDP connections from point to point, you can stream with FTL because its designed to go in one direction and only has an “accept/deny” state vs. offer/accept machinery. In effect, to adopt WISH into OBS would mean integrating a full WebRTC stack, signaling layer, and more to accomplish what FTL does with two RTP streams, a signaling protocol, and some basic invariants.</p>
<p dir="auto">There’s also the notion that both RIST and WISH are either new, or still being drafted. While both have the advantage of being an open standard from the get-go, they have no field test history, and neither are trying to hit the original sub second latency goal of the original FTL protocol.</p>
<p dir="auto">This brings me to SRT. Unlikely RIST or WISH, SRT is specifically designed as a low latency solution. However, SRT has two fundamental problems which make it unsuitable for use on “streamer-&gt;web browser pipeline”.</p>
<p dir="auto">The first is that SRT is not wire compatible with RTP nor does it use the same encoding standard. Part of the trick of FTL is that the packet generated by OBS is in fact the same packet sent to the browser with the least amount of post-processing done in the middle. Based off the benchmarks I did at Beam, each time we mux, demux, or re-encode a packet, we pick up a significant lag since in most cases, you need to have a fully assembled keyframe set to re-encode from location to location.</p>
<p dir="auto">FTL specifically bypasses that requirement by putting out something that WebRTC (with slight modifications) can digest directly. However, that’s not the only problem with SRT. SRT lacks a signaling mechanism.</p>
<p dir="auto">FTL’s Charon protocol acts as a signal for its two RTP streams, and can send metadata, signals keep alive, and could be potentially extended if ever needed. SRT merely defines a wire protocol and doesn’t specify any inband signaling. In short, you’d <em>still</em> need something like FTL’s Charon protocol to use SRT, and unless browsers adopt native SRT support, you still won’t be able to hit the same latency benchmarks you can hit with FTL.</p>
<p dir="auto">There’s also a final thing to consider. At the heart of this discussion,  we’re talking about ripping out a proven technology for something that only exists on paper. While theoretically, you could build low latency livestreaming solutions on several of the technologies listed here, no one has actually done it, and proved it works in the real world. FTL has, and it did so for more than half a decade. There’s something to be said for a proven solution.</p>
<p dir="auto">It is true that under Mixer, FTL wasn’t an open protocol, and the only implementation was Mixer itself. This was not the intent of FTL. FTL was intended as an open standard, and most of my reference notes were posted in the FTL-SDK. MSFT removed them, but they’re still in the git history.</p>
<p dir="auto">Furthermore, multiple people have reimplemented the server side from scratch using those notes, and the “last mile” part is easily implemented using the Janus gateway which was the same software the first FTL implementations were built on. Furthermore, the FTL RTP streams are essentially designed that the packet coming out of OBS is the packet that will go into WebRTC. The FTL implementation we used only had to change the SSRC in flight, and later ones had to add SRTP when it became mandated.</p>
<p dir="auto">Most of the work of the FTL standards effort is to essentially create a canonical version since there are some server behaviors that can’t be defined from the client, but on the whole, FTL is well understood, it’s documented (and getting bettered), and we’ll likely either code or canonicalize an existing implementation as the de facto reference implementation, and then resume development to add new features and to bring FTL out of the pit it was left in.</p>
<p dir="auto">In short, FTL was and is the only standard that is specifically targeting latency as it’s number 1 concern. Neither HST, RIST, or WISH can claim that.</p>
<p dir="auto">Furthermore, I need to ask a question: what is the ongoing cost to keep this code in OBS? ftl-sdk isn’t what I call a fast moving target, and most of it hasn’t changed in a long time.</p>
        </div>
</div></div>
  </body>
</html>
