<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://whynothugo.nl/journal/2025/08/06/gpts-and-feeling-left-behind/">Original</a>
    <h1>GPTs and Feeling Left Behind</h1>
    
    <div id="readability-page-1" class="page"><article><p>Every time that I read some blog post about “coding with AI”, or how cool new
models write entire libraries by themselves, I feel like I’m lagging behind,
like I’m missing out on some big, useful tool, and my skills are about to become
obsolete very soon.</p><p>So I try different models and tools, and it’s all incredibly underwhelming. It’s
honestly hard to believe that people get work done using these tools, because I
can spend a few hours on them (without getting even close to finishing the task
at hand) and realise that I could have done it myself in 25 minutes.</p><p>I tell myself <em>“learning to use Vim took a long time, but then it paid off”</em>
eventually. But I could (slowly) write text with Vim the first day. I can spend
an entire day with a GPT and produce nothing of value.</p><p>GPTs work great for finding the exact word to complete a sentence. They’re
surprisingly good at finding the exact type annotation for a Python function.
They can find nuanced bugs in a single function which I copy-paste into the GPT.
But anything beyond writing a simple function always leads to useless junk.
Often times, they solve big problems by just importing a library that does not
exist, and calling a function which does the bulk of the logic. ChatGPT told me
the other day “if you don’t want any dependencies, you’re going to have to
implement it yourself”. But couldn’t actually implement the necessary code.
Large portions of code have lots of hidden logic bugs, and when they fix one
they introduce another.</p><p>And then I see another post on Hacker News, about somebody using GPTs and how
they achieved great results on this and that. Part of me wants to think that
those articles are fake to generate hype, but the reality is that several of
them are written by well-known developers who’ve been around for over a decade.
Some of the results are actually publicly available online.</p><p>I’m in a state where I can’t reconcile my own results with other people’s
results. I hear people saying <em>“this hammer is indestructible”</em>, but when I pick
it up, it’s just origami: made of paper, intricate, delicate, very cool-looking
but I can’t even hammer a tomato with it.</p></article></div>
  </body>
</html>
