<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://csvbase.com/blog/8">Original</a>
    <h1>Caching secrets of the HTTP elders, part 1</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        <p>There is no hard limit on table size in csvbase.  Within reason, they can be as
big as you like.  And if you go off and run your own instance you can do
whatever you want.  Big Data isn&#39;t always Better Data, but it&#39;s nice to have
the option.</p>
<p>That said, wouldn&#39;t it be nice to have those tables cached, so that if you read
it twice you don&#39;t have to fully download it again the second time?</p>
<h2>Cache-control header - with max-age</h2>
<p>Perhaps this HTTP server header?:</p>
<div><pre><span></span><span>Cache-Control: max-age</span><span>=</span><span>86400</span><span></span>
</pre></div>
<p>The above header says &#34;keep using this file for a day [86400 seconds] before
re-downloading it&#34;.  Great!</p>
<p>Hang on though.  If someone changes that table you&#39;d be stuck looking at the
old version for up to 24 hours.  Being <a href="https://doi.org/10.1145%2F1435417.1435432">eventually
consistent</a> was once very trendy.
But it&#39;s no longer hip - even Amazon S3 <a href="https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/">no longer returns stale
data</a>.
So serving stale data just won&#39;t do for csvbase.</p>
<h2>HTTP/1.1 has a lot of caching features</h2>
<p>The elden ones <a href="https://doi.org/10.1109/ICDE.2000.839382">thought deeply about
caching</a>.  DNS <a href="https://www.internethalloffame.org/2012/07/23/why-does-net-still-work-christmas-paul-mockapetris/">is a
cache</a>.
<a href="https://www.linuxatemyram.com/">Virtual memory</a> is a cache.  And if you&#39;ve
ever wondered why HTTP/1.0 got a patch release (HTTP/1.1) less than a year
after it came out: more caching.</p>
<p>HTTP/1.0 had almost nothing in the way of caching.  In HTTP/1.1, a whole new
top-level section on the subject was added to the standard.  This was essential
because, back in the day, the repeated re-downloading of unchanged files was a
real headache.</p>
<p>This needless re-downloading was especially bad for popular sites, whose pages
would be massively re-downloaded over and over - even though they hadn&#39;t
changed - by many, many people.  Enough to start cause problems for the
internet as a whole.</p>
<p>One of the <em>cool new features</em> in HTTP/1.1 (implemented in Netscape Navigator 4.0,
available from all reputable software stockists) is the <code>ETag</code> header.  It
works like this:</p>
<p>The HTTP server generates a unique id for each version of a file.  &#39;Version&#39; in
this context means not just revision but also format, so CSV files get
different ids from Parquet files even if served from the same URL (csvbase
<a href="https://csvbase.com/blog/2">does this</a>).  The HTTP server returns this id in
the <code>ETag</code> header.</p>
<p>When an HTTP client requests the file again, it provides that same id in the
<code>If-None-Match</code> header.</p>
<p>If that ETag is up-to-date, the server just sets the status to <code>304 Not Modified</code> and returns absolutely nothing.  The client then knows that it should
use the file it already has.</p>
<p>This is a way to both keep a cache <em>and</em> avoid stale data.</p>
<h2>Generating the ETag</h2>
<p>How should the ETag be generated?  That is up to the server - up to csvbase.
csvbase could just md5sum the file and put that in the header.  That would be
valid and it would work.</p>
<p>Well, except.  Except, csvbase is not actually a database of CSV files.  The
name is a bit of a trick.  csvbase doesn&#39;t keep the CSV files on some
filesystem (or in an <a href="https://calpaterson.com/s3.html">object store</a> for that
matter).  Instead, uploaded CSV files are fully parsed and then put into a SQL
database.  When csvbase returns you a CSV file it&#39;s being generated <em>on the
fly</em>.  That&#39;s how csvbase returns other formats like Parquet, JSONlines, JSON, etc.</p>
<p>It would be quicker for csvbase not to have to regenerate the CSV file (or
Parquet file) each time, just in order to check whether the md5sum of that file
matched the <code>If-None-Match</code> header.</p>
<p>So instead of hashing the contents of the file, we&#39;ll create the ETag by
hashing a key:</p>
<p><code>(table id, last change time, file format, page number [if any])</code></p>
<p>That key represents both the version of the file plus what page is being looked
it (the JSON and HTML formats are paginated).  And if your table is changed,
last change time is different and the ETag changes too.  Fab.</p>
<h2>How long to cache for?</h2>
<p>At this point we have a caching system that:</p>
<ol>
<li>
Spares the client downloading the file<ul>
<li>though they must make a tiny request</li>
</ul>
</li>
<li>Also avoids the server regenerating the file</li>
<li>Prevents any stale results (ie: avoids <a href="https://calpaterson.com/ttl-hell.html">&#34;TTL
hell&#34;</a>)</li>
</ol>
<p>The only question now is how long we tell clients to cache stuff.  How long?</p>
<p>The answer is forever.  csvbase sets no <code>max-age</code>.  Clients can cache stuff as
long as they like, <strong>providing that they revalidate each time</strong> the use that
data.</p>
<p>Here&#39;s what csvbase&#39;s response looks like</p>
<div><pre><span></span><span>HTTP/1.1</span><span></span>
<span>content-type: text/csv</span><span></span>
<span>etag: &lt;some gobbledegook string&gt;</span><span></span>
<span>cache-control: no-cache, must-revalidate</span><span></span>
<span>[ then loads of CSV data ]</span><span></span>
</pre></div>
<p>The operative bit here is the <code>no-cache</code> pragma.  Despite the misleading name,
this tells clients that they can in fact cache this file, <em>but</em> that they must
revalidate each time they use it.  Here&#39;s how
<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#response_directives">MDN</a>
describes it (emphasis is mine):</p>
<blockquote>
<p><em>&#34;The no-cache response directive indicates that the <strong>response can be stored in
caches</strong>, but the response must be validated with the origin server before each
reuse, even when the cache is disconnected from the origin server.&#34;</em></p>
<p><em>&#34;If you want caches to always check for content updates while reusing stored
content, no-cache is the directive to use. It does this by requiring caches
to revalidate each request with the origin server.&#34;</em></p>
</blockquote>
<p><code>must-revalidate</code> is probably not necessary but the original RFC suggests that
maybe caches might choose, in exceptional circumstances, yadda yadda yadda, to
actually serve stale data anyway.  <code>must-revalidate</code> bans that.
<code>must-revalidate</code>&#39;s name actually makes sense so I probably don&#39;t need to quote
chapter and verse, but here, anyway, again from MDN:</p>
<blockquote>
<p><em>HTTP allows caches to reuse stale responses when they are disconnected from
the origin server. must-revalidate is a way to prevent this from happening -
either the stored response is revalidated with the origin server or a 504
(Gateway Timeout) response is generated.</em></p>
</blockquote>
<p>No TTL necessary.  And browsers really support this stuff.  It all works.</p>
<p><a href="https://pypi.org/project/csvbase-client/"><code>csvbase-client</code></a> also supports
this.  You can test it out this way:</p>
<div><pre><span></span><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span># read the table</span>
<span>df1</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>&#34;csvbase://calpaterson/opcodes-6502&#34;</span><span>)</span>

<span># read it again (this came from your local cache)</span>
<span>df2</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>&#34;csvbase://calpaterson/opcodes-6502&#34;</span><span>)</span>
</pre></div>
<p>And if you prefer just to use <code>curl</code>, here&#39;s how to test it:</p>
<div><pre><span></span>curl <span>\</span>
--etag-compare opcodes-6502-etag.txt <span>\</span>
--etag-save opcodes-6502-etag.txt <span>\</span>
https://csvbase.com/calpaterson/opcodes-6502.parquet
<span>\-</span>O
</pre></div>
<h2>What else is possible with ETags?</h2>
<p>A bit more.  Join me next time when I use ETags as an effective form of
concurrency control.  Until then:</p>
<ul>
<li>Try out csvbase and, really, really, importantly: <a href="mailto:cal@calpaterson.com">send me your
feedback</a></li>
<li>
Join the underground conspiracy on the <a href="https://discord.gg/zXHZNvv22N">csvbase discord
server</a><ul>
<li>memes to be kept to a socially acceptable level of dankness</li>
</ul>
</li>
<li>Leaf through <a href="https://github.com/calpaterson/csvbase">the source code</a></li>
<li>Or come and meet me in person at <a href="https://www.meetup.com/helpy-meetups/events/300305921/">Helsinki Python&#39;s May
meetup</a></li>
</ul>
<h2>See also</h2>
<p>I wrote <a href="https://calpaterson.com/ttl-hell.html">another article on caching</a> a
couple of years ago.  The subject bit different but the aim is the same: caching but
without correctness problems.</p>
<p>I loved Eric&#39;s Brewer&#39;s <a href="https://www.youtube.com/watch?v=E91oEn1bnXM">2004 lecture on
Inktomi</a>.
<a href="https://en.wikipedia.org/wiki/Inktomi">Inktomi</a> was effectively a primordial
Google who tried white-labelling instead of running the search engine
themselves.  They later changed to being a content distribution network and at
<a href="https://youtu.be/E91oEn1bnXM?si=zt5vj1TPSBOMkKzG&amp;t=3434">around 57 minutes</a>
Brewer relays the story of the release of the Starr report which vindicated
much of the effort put into web caching since HTTP/1.1 was released.  He is
very emotional throughout as Inktomi had gone spectacularly bust a couple of
years before.</p>
<p>One wrinkle I have not discussed is that many caching reverse proxies don&#39;t
have exactly have spectacular support for cache revalidation.  The going advice
on Varnish is to use some <a href="https://developers.cloudflare.com/cache/concepts/default-cache-behavior/">quite complicated
config</a>.
Cloudflare <a href="https://developers.cloudflare.com/cache/concepts/cache-control/#origin-cache-control-behavior">do the wrong thing with
<code>no-cache</code></a>
but it&#39;s possible to work around it.  What can&#39;t be worked around, for csvbase,
is their <a href="https://simonwillison.net/2023/Nov/20/cloudflare-does-not-consider-vary-values-in-caching-decisions/">lack of support for
<code>Vary</code></a>.
This is all HTTP/1.1 stuff - from 1997 - and browsers overwhelmingly support
it.  But reverse proxies don&#39;t, for some reason.</p>

      </div>
    </div></div>
  </body>
</html>
