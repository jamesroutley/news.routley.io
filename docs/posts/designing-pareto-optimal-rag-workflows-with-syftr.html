<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.datarobot.com/blog/pareto-optimized-ai-workflows-syftr/">Original</a>
    <h1>Designing Pareto-optimal RAG workflows with syftr</h1>
    
    <div id="readability-page-1" class="page"><div uk-grid="">
					<div>
						<div>
							
							
<p>You’re not short on tools. Or models. Or frameworks.</p>



<p>What you’re short on is a principled way to use them — <em>at scale.</em></p>



<p>Building effective generative AI workflows, especially agentic ones, means navigating a combinatorial explosion of choices.</p>



<p>Every new retriever, prompt strategy, text splitter, embedding model, or synthesizing LLM multiplies the space of possible workflows, resulting in a search space with over 10²³ possible configurations. </p>



<p>Trial-and-error doesn’t scale. And model-level benchmarks don’t reflect how components behave when stitched into full systems.</p>



<p><strong>That’s why we built syftr </strong>— an open source framework for automatically identifying Pareto-optimal workflows across accuracy, cost, and latency constraints.</p>



<div>
<h3 id="h-see-syftr-in-action"><strong><em>See syftr in action</em></strong></h3>



<p><em>Want a quick walkthrough before diving in? This short demo shows how syftr works to help AI teams efficiently explore generative AI workflow configurations and surface high-performing options.</em></p>



 <wistia-player media-id="wv6rqxarbq" aspect="1.7777777777777777"></wistia-player>
</div>



<h2 id="h-the-complexity-behind-generative-ai-workflows">The complexity behind generative AI workflows</h2>



<p>To illustrate how quickly complexity compounds, consider even a relatively simple RAG pipeline like the one shown in Figure 1.</p>



<p>Each component—retriever, prompt strategy, embedding model, text splitter, synthesizing LLM—requires careful selection and tuning. And beyond those decisions, there’s an expanding landscape of end-to-end workflow strategies, from single-agent workflows like <a href="https://docs.llamaindex.ai/en/stable/examples/agent/react_agent_with_query_engine/" rel="noindex nofollow noopener" target="_blank">ReAct</a> and <a href="https://docs.llamaindex.ai/en/v0.10.33/examples/agent/lats_agent/" rel="noindex nofollow noopener" target="_blank">LATS</a> to multi-agent workflows like <a href="https://docs.ag2.ai/latest/docs/use-cases/notebooks/notebooks/agentchat_captainagent/" rel="noindex nofollow noopener" target="_blank">CaptainAgent</a> and <a href="https://microsoft.github.io/autogen/dev//user-guide/agentchat-user-guide/magentic-one.html" rel="noindex nofollow noopener" target="_blank">Magentic-One</a>. </p>



<figure><img loading="lazy" decoding="async" width="1024" height="282" src="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_1_syftr_blog_post-1024x282.png" alt="Figure 1 syftr blog post" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_1_syftr_blog_post-1024x282.png 1024w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_1_syftr_blog_post-600x165.png 600w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_1_syftr_blog_post-1536x422.png 1536w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_1_syftr_blog_post-2048x563.png 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption><em><strong>Figure 1</strong>. Even a simple AI workflow requires selecting and testing multiple components and hyperparameters.</em></figcaption></figure>



<p>What’s missing is a scalable, principled way to explore this configuration space.</p>



<p>That’s where <strong>syftr</strong> comes in. </p>



<p>Its open source framework uses multi-objective <a href="https://bayesoptbook.com/" rel="noindex nofollow noopener" target="_blank">Bayesian Optimization</a> to efficiently search for Pareto-optimal RAG workflows, balancing cost, accuracy, and latency across configurations that would be impossible to test manually.</p>



<h2 id="h-benchmarking-pareto-optimal-workflows-with-syftr">Benchmarking Pareto-optimal workflows with syftr</h2>



<p>Once syftr is applied to a workflow configuration space, it surfaces candidate pipelines that achieve strong tradeoffs across key performance metrics. </p>



<p>The example below shows syftr’s output on the CRAG (Comprehensive RAG) Sports benchmark, highlighting workflows that maintain high accuracy while significantly reducing cost.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="429" src="https://www.datarobot.com/wp-content/uploads/2025/05/Fogire_2_syftr_blog_post-1024x429.png" alt="Fogire 2 syftr blog post" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Fogire_2_syftr_blog_post-1024x429.png 1024w, https://www.datarobot.com/wp-content/uploads/2025/05/Fogire_2_syftr_blog_post-600x251.png 600w, https://www.datarobot.com/wp-content/uploads/2025/05/Fogire_2_syftr_blog_post-1536x643.png 1536w, https://www.datarobot.com/wp-content/uploads/2025/05/Fogire_2_syftr_blog_post.png 1999w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption><em><em><strong>Figure 2</strong>. syftr searches across a large workflow configuration space to identify Pareto-optimal RAG workflows — agentic and non-agentic — that balance accuracy and cost. On the </em><a href="https://arxiv.org/abs/2406.04744" rel="noindex nofollow noopener" target="_blank"><em><span>CRAG Sports benchmark</span></em></a><em>, syftr identifies workflows that match the accuracy of top-performing configurations while reducing cost by nearly two orders of magnitude.</em></em></figcaption></figure>



<p>While Figure 2 shows what syftr can deliver, it’s equally important to understand how those results are achieved. </p>



<p>At the core of syftr is a multi-objective search process designed to efficiently navigate vast workflow configuration spaces. The framework prioritizes both performance and computational efficiency – essential requirements for real-world experimentation at scale.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="464" src="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_3_syftr-using-multi-objective-Bayesian-Optimization-1024x464.png" alt="Figure 3 syftr using multi objective Bayesian Optimization" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_3_syftr-using-multi-objective-Bayesian-Optimization-1024x464.png 1024w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_3_syftr-using-multi-objective-Bayesian-Optimization-600x272.png 600w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_3_syftr-using-multi-objective-Bayesian-Optimization-1536x696.png 1536w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_3_syftr-using-multi-objective-Bayesian-Optimization-2048x928.png 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption><em><strong>Figure 3.</strong> syftr uses multi-objective Bayesian Optimization (BO) to search across a space of approximately 10²³ unique workflows.</em></figcaption></figure>



<p>Since evaluating every workflow in this space isn’t feasible, we typically evaluate around 500 workflows per run. </p>



<p>To make this process even more efficient, syftr includes a novel early stopping mechanism — <strong>Pareto Pruner </strong>— which halts evaluation of workflows that are unlikely to improve the Pareto frontier. This significantly reduces computational cost and search time while preserving result quality. </p>



<h2 id="h-why-current-benchmarks-aren-t-enough">Why current benchmarks aren’t enough</h2>



<p>While model benchmarks, like <a href="https://arxiv.org/abs/2009.03300" rel="noindex nofollow noopener" target="_blank">MMLU</a>, <a href="https://livebench.ai/#/" rel="noindex nofollow noopener" target="_blank">LiveBench</a>, <a href="https://lmarena.ai/" rel="noindex nofollow noopener" target="_blank">Chatbot Arena</a>, and the <a href="https://gorilla.cs.berkeley.edu/leaderboard.html" rel="noindex nofollow noopener" target="_blank">Berkeley Function-Calling Leaderboard</a>, have advanced our understanding of isolated model capabilities, foundation models rarely operate alone in real-world production environments.</p>



<p>Instead, they’re typically one component — albeit an essential one — within larger, sophisticated AI systems.</p>



<p>Measuring intrinsic model performance is critical, but it leaves open critical system-level questions: </p>



<ul>
<li>How do you construct a workflow that meets task-specific goals for accuracy, latency, and cost?<br/></li>



<li>Which models should you use—and in which parts of the pipeline?</li>
</ul>







<p>It captures nuanced tradeoffs that emerge only when components interact within a broader pipeline, and systematically explores configuration spaces that are otherwise impractical to evaluate manually.</p>







<p>syftr is the first open-source framework specifically designed to automatically identify Pareto-optimal generative AI workflows that balance multiple competing objectives simultaneously — not just accuracy, but latency and cost as well.</p>



<p>It draws inspiration from existing research, including:</p>



<ul>
<li><a href="https://arxiv.org/abs/2410.20878" rel="noindex nofollow noopener" target="_blank">AutoRAG</a>, which focuses solely on optimizing for accuracy</li>



<li>Kapoor et al. ‘s work, <a href="https://arxiv.org/abs/2407.01502" rel="noindex nofollow noopener" target="_blank"><em>AI Agents That Matter</em></a><em>,</em> which emphasizes cost-controlled evaluation to prevent incentivizing overly costly, leaderboard-focused agents. This principle serves as one of our core research inspirations. </li>
</ul>







<p>In early experiments, syftr first identified Pareto-optimal workflows on the CRAG Sports benchmark. </p>



<p>We then applied Trace to optimize prompts across all of those configurations — taking a two-stage approach: multi-objective workflow search followed by fine-grained prompt tuning.</p>



<p><strong>The result:</strong> notable accuracy improvements, especially in low-cost workflows that initially exhibited lower accuracy (those clustered in the lower-left of the Pareto frontier). These gains suggest that post-hoc prompt optimization can meaningfully boost performance, even in highly cost-constrained settings.</p>



<p>This two-stage approach — first multi-objective configuration search, then prompt refinement — highlights the benefits of combining syftr with specialized downstream tools, enabling modular and flexible workflow optimization strategies.</p>



<figure><img loading="lazy" decoding="async" width="934" height="743" src="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_4_prompt-optimization-with-Trace-further-improves-Pareto-optimal-flows-identified-by-syftr.png" alt="Figure 4 prompt optimization with Trace further improves Pareto optimal flows identified by syftr" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_4_prompt-optimization-with-Trace-further-improves-Pareto-optimal-flows-identified-by-syftr.png 934w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_4_prompt-optimization-with-Trace-further-improves-Pareto-optimal-flows-identified-by-syftr-600x477.png 600w" sizes="auto, (max-width: 934px) 100vw, 934px"/><figcaption><em><strong>Figure 4.</strong> Prompt optimization with Trace further improves Pareto-optimal flows identified by syftr. In the CRAG Sports benchmark shown here, using Trace significantly enhanced the accuracy of lower-cost workflows, shifting the Pareto frontier upward.</em></figcaption></figure>



<h2 id="h-building-and-extending-syftr-s-search-space">Building and extending syftr’s search space</h2>



<p>Syftr cleanly separates the workflow search space from the underlying optimization algorithm. This modular design enables users to easily extend or customize the space, adding or removing flows, models, and components by editing configuration files.</p>



<p>The default implementation uses <a href="https://www.jair.org/index.php/jair/article/view/13188" rel="noindex nofollow noopener" target="_blank">Multi-Objective Tree-of-Parzen-Estimators (MOTPE)</a>, but syftr supports swapping in other optimization strategies.</p>



<p>Contributions of new flows, modules, or algorithms are welcomed via pull request at <a href="http://github.com/datarobot/syftr" rel="noindex nofollow noopener" target="_blank">github.com/datarobot/syftr</a>.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="436" src="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_5_syftr_blog_post-1024x436.png" alt="Figure 5 syftr blog post" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_5_syftr_blog_post-1024x436.png 1024w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_5_syftr_blog_post-600x255.png 600w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_5_syftr_blog_post-1536x654.png 1536w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_5_syftr_blog_post.png 1999w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption><em><strong>Figure 5. </strong>The current search space includes both agentic workflows (e.g., SubQuestion RAG, Critique RAG, ReAct RAG, LATS) and non-agentic RAG pipelines. Agentic workflows use non-agentic flows as subcomponents. The full space contains ~10²³ configurations.</em></figcaption></figure>



<h2 id="h-built-on-the-shoulders-of-open-source">Built on the shoulders of open source</h2>



<p>syftr builds on a number of powerful open source libraries and frameworks:</p>



<ul>
<li><a href="https://www.ray.io/#why-ray" rel="noindex nofollow noopener" target="_blank">Ray</a> for distributing and scaling search over large clusters of CPUs and GPUs<br/></li>



<li><a href="https://docs.ray.io/en/latest/serve/index.html" rel="noindex nofollow noopener" target="_blank">Ray Serve</a> for autoscaling model hosting<br/></li>



<li><a href="https://optuna.org/" rel="noindex nofollow noopener" target="_blank">Optuna</a> for its flexible define-by-run interface (similar to PyTorch’s eager execution) and support for state-of-the-art multi-objective optimization algorithms<br/></li>



<li><a href="https://www.llamaindex.ai/" rel="noindex nofollow noopener" target="_blank">LlamaIndex</a> for building sophisticated agentic and non-agentic RAG workflows</li>
</ul>



<ul>
<li><a href="https://huggingface.co/docs/datasets/en/index" rel="noindex nofollow noopener" target="_blank">HuggingFace Datasets</a> for fast, collaborative, and uniform dataset interface<br/></li>



<li><a href="https://github.com/microsoft/Trace" rel="noindex nofollow noopener" target="_blank">Trace</a> for optimizing textual components within workflows, such as prompts</li>
</ul>







<h2 id="h-case-study-syftr-on-crag-sports">Case study: syftr on CRAG Sports</h2>



<p><strong>Benchmark setup</strong></p>



<p>The CRAG benchmark dataset was introduced by Meta for the <a href="https://www.aicrowd.com/challenges/meta-comprehensive-rag-benchmark-kdd-cup-2024" rel="noindex nofollow noopener" target="_blank">KDD Cup 2024</a> and includes three tasks:</p>



<ul>
<li><strong>Task 1:</strong> Retrieval summarization<br/></li>



<li><strong>Task 2:</strong> Knowledge graph and web retrieval<br/></li>



<li><strong>Task 3:</strong> End-to-end RAG</li>
</ul>



<p>syftr was evaluated on Task 3 (CRAG3), which includes 4,400 QA pairs spanning a wide range of topics. The official benchmark performs RAG over 50 webpages retrieved for each question. </p>



<p>To increase difficulty, we combined all webpages across all questions into a single corpus, creating a more realistic, challenging retrieval setting.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="405" src="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_6_pareto-optimal-flows-discovered-by-syftr-on-CRAG-Task-3-1024x405.png" alt="Figure 6 pareto optimal flows discovered by syftr on CRAG Task 3" srcset="https://www.datarobot.com/wp-content/uploads/2025/05/Figure_6_pareto-optimal-flows-discovered-by-syftr-on-CRAG-Task-3-1024x405.png 1024w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_6_pareto-optimal-flows-discovered-by-syftr-on-CRAG-Task-3-600x237.png 600w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_6_pareto-optimal-flows-discovered-by-syftr-on-CRAG-Task-3-1536x607.png 1536w, https://www.datarobot.com/wp-content/uploads/2025/05/Figure_6_pareto-optimal-flows-discovered-by-syftr-on-CRAG-Task-3.png 1999w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption><strong><em>Figure 6.</em></strong><em> Pareto-optimal flows discovered by syftr on CRAG Task 3 (Sports dataset). syftr identifies workflows that are both more accurate and significantly cheaper than a default RAG pipeline built in LlamaIndex (white box). It also outperforms Amazon Q on the same task—an expected result, given that Q is built for general-purpose usage while syftr is tuned for the dataset. This highlights a key insight: </em><strong><em>custom flows can meaningfully outperform off-the-shelf solutions, </em></strong><em>especially in cost-sensitive, accuracy-critical applications.</em></figcaption></figure>



<h3 id="h-key-observations-and-insights">Key observations and insights</h3>



<p>Across datasets, syftr consistently surfaces meaningful optimization patterns:</p>



<ul>
<li><strong>Non-agentic workflows dominate the Pareto frontier.</strong> They’re faster and cheaper, leading the optimizer to favor these configurations more frequently than agentic ones.<br/></li>



<li><strong>GPT-4o-mini frequently appears in Pareto-optimal flows</strong>, suggesting it offers a strong balance of quality and cost as a synthesizing LLM.<br/></li>



<li><strong>Reasoning models like o3-mini perform well on quantitative tasks</strong> (e.g., FinanceBench, InfiniteBench), likely due to their multi-hop reasoning capabilities.<br/></li>



<li><strong>Pareto frontiers eventually flatten</strong> after an initial rise, with diminishing returns in accuracy relative to steep cost increases, underscoring the need for tools like syftr that help pinpoint efficient operating points.</li>
</ul>



<h3 id="h-cost-of-running-syftr">Cost of running syftr</h3>



<p>In our experiments, we allocated a budget of ~500 workflow evaluations per task. Although exact costs vary based on the dataset and search space complexity, we consistently identified strong Pareto frontiers with a one-time search cost of approximately <strong>$500 per use case</strong>.</p>



<p>We expect this cost to decrease as more efficient search algorithms and space definitions are developed. </p>



<p>Importantly, this initial investment is minimal relative to the long-term gains from deploying optimized workflows, whether through reduced compute usage, improved accuracy, or better user experience in high-traffic systems.</p>



<p>For detailed results across six benchmark tasks, including datasets beyond CRAG, refer to the <a href="https://arxiv.org/abs/2505.20266" rel="noindex nofollow noopener" target="_blank">full syftr paper. </a></p>



<h2 id="h-getting-started-and-contributing">Getting started and contributing</h2>



<p>To get started with syftr, clone or fork the repository on<a href="https://github.com/datarobot/syftr" rel="noindex nofollow noopener" target="_blank"> GitHub</a>. Benchmark datasets are available <a href="https://huggingface.co/DataRobot-Research" rel="noindex nofollow noopener" target="_blank">on HuggingFace</a>, and syftr also supports user-defined datasets for custom experimentation.</p>



<p>The current search space includes:</p>



<ul>
<li>9 proprietary LLMs</li>



<li>11 embedding models</li>



<li>4 general prompt strategies</li>



<li>3 retrievers</li>



<li>4 text splitters (with parameter configurations)</li>



<li>4 agentic RAG flows and 1 non-agentic RAG flow, each with associated hierarchical hyperparameters</li>
</ul>







<p>syftr is developed fully in the open. We welcome contributions via pull requests, feature proposals, and benchmark reports. We’re particularly interested in ideas that advance the research direction or improve the framework’s extensibility.</p>



<h2 id="h-what-s-ahead-for-syftr">What’s ahead for syftr</h2>



<p>syftr is still evolving, with several active areas of research designed to extend its capabilities and practical impact:</p>



<ul>
<li><strong>Meta-learning</strong></li>



<li><strong>Multi-agent workflow evaluation</strong></li>



<li><strong>Composability with prompt optimization frameworks</strong></li>



<li><strong>More agentic tasks</strong></li>
</ul>







<p>If you’re working in this space, we welcome your feedback, ideas, and contributions.</p>



<h2 id="h-try-the-code-read-the-research">Try the code, read the research</h2>



<p>To explore syftr further, check out the <a href="https://github.com/datarobot/syftr" rel="noindex nofollow noopener" target="_blank">GitHub</a> repository or <a href="https://arxiv.org/abs/2505.20266" rel="noindex nofollow noopener" target="_blank">read the full paper on ArXiv</a> for details on methodology and results.</p>



<p>Syftr has been accepted to appear at the <a href="https://2025.automl.cc/" rel="noindex nofollow noopener" target="_blank">International Conference on Automated Machine Learning (AutoML) in September, 2025</a> in New York City.</p>



<p>We look forward to seeing what you build and discovering what’s next, together.</p>






							
															
													</div>
					</div>
					

											
									</div></div>
  </body>
</html>
