<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/irrustible/ointers">Original</a>
    <h1>Ointers: A library for representing pointers where bits have been stolen (2021)</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://github.com/irrustible/ointers/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/ef35a4fd2448e10ec343e6c40a8035fc192754cd555e9b1d92596266f6d546d5/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f6c2f6f696e746572732e737667" alt="License" data-canonical-src="https://img.shields.io/crates/l/ointers.svg"/></a>
<a href="https://crates.io/crates/ointers" rel="nofollow"><img src="https://camo.githubusercontent.com/32e63caf3e4a985822d57ec2d7d0508c827b5ba1769d5d90e43abd52514b5118/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6f696e746572732e737667" alt="Package" data-canonical-src="https://img.shields.io/crates/v/ointers.svg"/></a>
<a href="https://docs.rs/ointers" rel="nofollow"><img src="https://camo.githubusercontent.com/fb810f41acd410f9175351f4019974196098a17c58638a830e265592cd684d1a/68747470733a2f2f646f63732e72732f6f696e746572732f62616467652e737667" alt="Documentation" data-canonical-src="https://docs.rs/ointers/badge.svg"/></a></p>

<p dir="auto">What do you call a pointer with the high bits stolen? An ointer!</p>
<p dir="auto">Ointers is a library for representing pointers where some bits have
been stolen so that they may be used by the programmer for something
else. In effect, it&#39;s a small amount of free storage</p>
<p dir="auto">Fully supports no_std, dependency-free, &lt;100loc.</p>

<p dir="auto">Ointers supports a handful of bit sources. It&#39;s up to you to determine
when it is safe to use them.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Alignment bits (const parameter A)</h3><a id="user-content-alignment-bits-const-parameter-a" aria-label="Permalink: Alignment bits (const parameter A)" href="#alignment-bits-const-parameter-a"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If we know that a pointer&#39;s address will always be aligned to <code>A</code>
bytes where A &gt; 1, we can steal log2(A-1) bytes. For an 8-byte aligned
value, this provides a modest 3 bits.</p>
<p dir="auto">If you have values aligned to some larger width, you could get even
more. It&#39;s common in parallel programming to pad data to a cache line
by increasing its alignment requirements in order eliminate false
sharing. Because a cache line on amd64 or aarch64 is effectively 128
bytes thanks to prefetching, you can reclaim a respectable 7 extra
bits.</p>
<p dir="auto">If your data is aligned wider still, the sky is the limit, but you
could get an incredible 24 bits if you have 16MB-aligned data!
Remember that the only alignment rust knows about is what is declared
for the type, so you must create a newtype wrapper to take full
advantage of large alignment sizes.</p>
<table>
<thead>
<tr>
<th>Bits</th>
<th>Min alignment</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2b</td>
</tr>
<tr>
<td>2</td>
<td>4b</td>
</tr>
<tr>
<td>3</td>
<td>8b</td>
</tr>
<tr>
<td>4</td>
<td>16b</td>
</tr>
<tr>
<td>5</td>
<td>32b</td>
</tr>
<tr>
<td>6</td>
<td>64b</td>
</tr>
<tr>
<td>7</td>
<td>128b</td>
</tr>
<tr>
<td>8</td>
<td>256b</td>
</tr>
<tr>
<td>9</td>
<td>512b</td>
</tr>
<tr>
<td>10</td>
<td>1k</td>
</tr>
<tr>
<td>11</td>
<td>2k</td>
</tr>
<tr>
<td>12</td>
<td>4k</td>
</tr>
<tr>
<td>13</td>
<td>8k</td>
</tr>
<tr>
<td>14</td>
<td>16k</td>
</tr>
<tr>
<td>15</td>
<td>32k</td>
</tr>
<tr>
<td>16</td>
<td>64k</td>
</tr>
<tr>
<td>17</td>
<td>128k</td>
</tr>
<tr>
<td>18</td>
<td>256k</td>
</tr>
<tr>
<td>19</td>
<td>512k</td>
</tr>
<tr>
<td>20</td>
<td>1m</td>
</tr>
<tr>
<td>21</td>
<td>2m</td>
</tr>
<tr>
<td>22</td>
<td>4m</td>
</tr>
<tr>
<td>23</td>
<td>8m</td>
</tr>
<tr>
<td>24</td>
<td>16m</td>
</tr>
</tbody>
</table>
<p dir="auto">Stealing bits from alignment is relatively innocuous, but we can only
get the compiler to check it for you in dev mode as things stand in
rust today.</p>

<p dir="auto">The most commonly used operating systems arrange memory so that the
high half of virtual memory space is reserved for the kernel and the
low half is given to userspace.</p>
<p dir="auto">Looked at as a signed integer, this makes the kernel half of address
space negative and the userspace half positive.</p>
<p dir="auto">Most programs do not deal with kernel addresses, thus giving us an
extra bit to play with.</p>
<p dir="auto">We can also get this extra bit in kernel mode if we know we will not
be dealing with userspace addresses. We do this by taking a pointer to
a value on the stack and stealing its sign bit.</p>
<p dir="auto">If you know you will be dealing with userspace addresses in kernel
space or kernel space addresses in userspace, or you are using or
implementing a kernel which does not follow this convention, you must
set <code>S</code> to <code>false</code>.</p>
<p dir="auto">The S bit is currently only tested with userspace pointers in
userspace. While we think it should work more generally, we currently
haven&#39;t got a test rig for other scenarios so we can&#39;t promise it does.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Unused virtual address space (V)</h3><a id="user-content-unused-virtual-address-space-v" aria-label="Permalink: Unused virtual address space (V)" href="#unused-virtual-address-space-v"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">In 64-bit mode, address space is plentiful: nobody has 64 bits&#39; worth
of RAM and even if they did, their processor is unable to address it
all. V is required to be 0 unless compiling for a 64bit target.</p>
<p dir="auto">The number of bits that may be safely stolen by this method depends
upon the microarchitecture in question and the page table depth.</p>
<p dir="auto">For x86-64 and aarch64, the following sizes apply:</p>
<table>
<thead>
<tr>
<th>Bits</th>
<th>PT depth</th>
<th>Support</th>
</tr>
</thead>
<tbody>
<tr>
<td>25</td>
<td>3</td>
<td>aarch64 only, uncommon, opt-in</td>
</tr>
<tr>
<td>16</td>
<td>4</td>
<td>most common default</td>
</tr>
<tr>
<td>7</td>
<td>5</td>
<td>some intel only, uncommon, opt-in</td>
</tr>
</tbody>
</table>
<p dir="auto">If you are made of money and need more than 128TB virtual address
space, you should limit yourself to 7 bits for V. Likewise if you know
you&#39;ll be on 3-deep page tables, you can steal a whopping 25 bits. But
you&#39;re probably limited to 16 bits in general.</p>

<p dir="auto">Contributions welcome, please be nice.</p>
<p dir="auto">The test suite requires std at present (because of rand&#39;s
ThreadRng). It takes about 36 seconds on my Ryzen 3900X. If you&#39;re on
a slower machine, you might want to reduce the loop iterations. It
should really only take one to shake most bugs out and a handful to
shake out the rest. The million iterations is just overkill to be sure
that&#39;s conveniently enabled by the incredible ease-of-use of rayon.</p>
<p dir="auto">The tests are extensive. The number of configurations I&#39;m currently
testing against is limited, however:</p>
<ul dir="auto">
<li>x86-64, linux with 4PT</li>
</ul>
<p dir="auto">We would like to support more. These should be easy:</p>
<ul dir="auto">
<li>x86, linux with 4PT should be possible through github actions.</li>
<li>aarch64, linux with 4PT shouldn&#39;t be too hard to find access to.</li>
<li>32-bit arm (3PT) should be doable as well.</li>
</ul>
<p dir="auto">These will likely be harder:</p>
<ul dir="auto">
<li>aarch64, linux with 3PT is probably not widely deployed</li>
<li>Intel&#39;s new 5PT is of incredibly niche interest - if you want us to
test it, you&#39;ll have to sponsor it because I don&#39;t have access to
the hardware..</li>
</ul>


<ul dir="auto">
<li>Optional pointer provenance support with the <code>sptr</code> feature (thanks @GoldsteinE!)</li>
</ul>

<p dir="auto">Security (please upgrade as soon as possible, i&#39;ve yanked old versions):</p>
<ul dir="auto">
<li>Fix possible UB when stealing alignment bits with <code>Ox</code>/<code>NotNull</code>.</li>
</ul>
<p dir="auto">Features:</p>
<ul dir="auto">
<li>Add method <code>new_stealing</code> for all types allowing to create while stealing data.</li>
</ul>

<ul dir="auto">
<li>Add <code>i_know_what_im_doing</code> feature to enable stealing from V when
not building for a 64-bit target.</li>
</ul>

<ul dir="auto">
<li>Make <code>Ointer&lt;T&gt;</code> and <code>NotNull&lt;T&gt;</code> be <code>Clone + Copy</code> even if T is not.</li>
</ul>

<p dir="auto">New APIS:</p>
<ul dir="auto">
<li><code>pack()</code> - packs a pointer into the low bits of a usize.</li>
<li><code>unpack()</code> - reverse of pack.</li>
<li><code>asv_mask()</code> - calculates a mask where the stolen bits are set on by a, s, v.</li>
<li><code>mask()</code> - calculates a mask where the stolen bits are set on by total bits.</li>
<li><code>Ointer::raw()</code> - returns the raw data in the ointer (stolen + ptr) as a usize.</li>
<li><code>NotNull::raw()</code> - same, but for <code>NotNull</code>.</li>
</ul>
<p dir="auto">Changes:</p>
<ul dir="auto">
<li><code>Ointer</code> now uses a usize internally.</li>
</ul>

<p dir="auto">Copyright (c) 2021 James Laver, ointers contributors.</p>
<p dir="auto"><a href="https://github.com/irrustible/ointers/blob/main/LICENSE">Licensed</a> under Apache License, Version 2.0 (<a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">https://www.apache.org/licenses/LICENSE-2.0</a>),
with LLVM Exceptions (<a href="https://spdx.org/licenses/LLVM-exception.html" rel="nofollow">https://spdx.org/licenses/LLVM-exception.html</a>).</p>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
licensed as above, without any additional terms or conditions.</p>
</article></div></div>
  </body>
</html>
