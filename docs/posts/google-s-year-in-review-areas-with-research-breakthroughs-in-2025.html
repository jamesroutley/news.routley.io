<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/ai/2025-research-breakthroughs/">Original</a>
    <h1>Google&#39;s year in review: areas with research breakthroughs in 2025</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    


<section>
  
</section>


    

    
      








<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
  }">
  
  <div>
    <div>
      
      
        <p>
          This was a year of AI agents, reasoning and scientific discovery.
        </p>
      
    </div>
  </div>
  
  <div>
    
    
      
        


<div data-component="uni-ai-generated-summary" data-analytics-module="{
    &#34;event&#34;: &#34;module_impression&#34;,
    &#34;module_name&#34;: &#34;ai_summary&#34;,
    &#34;section_header&#34;: &#34;CTA&#34;
  }">
  <div data-component="uni-ai-summary-btn">
    <div>
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>In 2025, Google made significant AI research breakthroughs with models like Gemini 3 and Gemma 3. These advancements improved AI&#39;s reasoning, multimodality, and efficiency, leading to new products and features across Google&#39;s portfolio. Expect more AI-driven innovations in science, computing, and tools for global challenges as Google prioritizes responsible AI development and collaboration.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_2">
          <h2>Bullet points</h2>
          <ul>
<li>&#34;Google&#39;s year in review: 8 areas with research breakthroughs in 2025&#34; highlights AI advancements and more.</li>
<li>Gemini 3 models showed big leaps in reasoning, multimodality, efficiency, and creative abilities.</li>
<li>AI is transforming Google&#39;s products, from Pixel 10 to Search, with agentic capabilities.</li>
<li>AI is boosting science, from genomics and healthcare to math, coding, and quantum computing.</li>
<li>Google is prioritizing AI safety, collaboration, and addressing global challenges like climate change.</li>
</ul>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_3">
          <h2>Basic explainer</h2>
          <p>Google had a super productive year with AI research. They made their AI models way better at thinking and understanding things. Google also made AI more useful in everyday products and helped people be more creative. Plus, they used AI to make big steps in science and to tackle global problems.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      
      
      

      </div>
  </div>
</div>

      
    
    
  </div>
</div>

    

    
      










<div>
  <div>
    <figure>
      <div>
        <p><img alt="The image depicts a visual collage or mosaic of multiple different images, with one image in the center that is black and displays the text &#34;Gemini 3&#34;." data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_209.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_209.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_20.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_20.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_20.width-2200.format-webp.webp 2200w"/>
        </p>
      </div>
      
    </figure>
  </div>
</div>






    

    
    <section>
      <div>
        
          
            
          
          
          <div data-reading-time="true" data-component="uni-article-body">

            
  
    



















<div data-component="uni-audio-player-tts" uni-l10n="{
       &#34;stop&#34;: &#34;Click to stop audio&#34;,
       &#34;play&#34;: &#34;Click to play audio&#34;,
       &#34;progress&#34;: &#34;Current audio progress minutes with seconds: [[progress]]&#34;,
       &#34;duration&#34;: &#34;Duration of the audio minutes with seconds: [[duration]]&#34;,
       &#34;settings&#34;: &#34;Click for settings&#34;,
       &#34;timeText&#34;: &#34;[[duration]] minutes&#34;
     }" data-analytics-module="{
      &#34;module_name&#34;: &#34;Audio TTS&#34;,
      &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
     }" data-tts-audios="[
      
        {&#34;voice_name&#34;: &#34;Gacrux&#34;,
        &#34;voice_source&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83015_gacrux_2025_12_23_19_37_44.wav&#34;,
        &#34;mimetype&#34;: &#34;audio/x-wav&#34;},
      
        {&#34;voice_name&#34;: &#34;Umbriel&#34;,
        &#34;voice_source&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83015_umbriel_2025_12_23_19_38_45.wav&#34;,
        &#34;mimetype&#34;: &#34;audio/x-wav&#34;}
      ]">
  <p><audio title="Google\u0027s year in review: 8 areas with research breakthroughs in 2025">
      <source src="self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type"/>
      <p>Your browser does not support the audio element.</p>
  </audio></p><div aria-label="">
    <div>
      <div>
        <p><span>
          Listen to article
          <span tabindex="0" role="tooltip" aria-label="This content is generated by Google AI. Generative AI is experimental">
            <p>This content is generated by Google AI. Generative AI is experimental</p>
            <svg>
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251215-1743#ttf-info"></use>
</svg>

          </span>
        </span></p><p>[[duration]] minutes</p>
      </div>
      
    </div>
  </div>
</div>

  





            
            
<!--article text-->

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="8cikp">2025 has been a year of extraordinary progress in research. With artificial intelligence, we can see its trajectory shifting from a tool to a utility: from something people use to something they can put to work. If 2024 was about laying the multimodal foundations for this era, 2025 was the year AI began to really think, act and explore the world alongside us. With quantum computing, we made progress towards real-world applications. And across the board, we helped turn research into reality, with more capable and useful products and tools making a positive impact on people&#39;s lives today.</p><p data-block-key="2qvrh">Here’s a look back at some of the breakthroughs, products and scientific milestones that defined the work of Google, Google DeepMind and Google Research in a year of relentless progress<b>.</b></p></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="8cikp">Delivering breakthroughs on world-class models</h2><p data-block-key="67v7e">This year, we significantly advanced our model capabilities with breakthroughs on reasoning, multimodal understanding, model efficiency, and generative capabilities, beginning with the release of Gemini 2.5 in March and culminating in the November launch of Gemini 3 and the December launch of Gemini 3 Flash.</p><p data-block-key="adj22">Built on a foundation of state-of-the-art reasoning, Gemini 3 Pro is our most powerful model to date, designed to help you bring any idea to life. It topped the LMArena Leaderboard and redefined multimodal reasoning with breakthrough scores on benchmarks like Humanity’s Last Exam — a fiendishly hard test for AI models to see if AI can truly think and reason like humans — and GPQA Diamond. It also set a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex. We followed shortly with Gemini 3 Flash, which combines Gemini 3&#39;s Pro-grade reasoning with Flash-level latency, efficiency and cost, making it the most performant model for its size. Gemini 3 Flash&#39;s quality surpasses our previous Gemini 2.5 Pro-scale model&#39;s capabilities at a fraction of the price and substantially better latency, continuing our Gemini-era trend of &#39;the next generation&#39;s Flash model is better than the previous generation&#39;s Pro model&#39;.</p><p data-block-key="2qsdp">Learn more about our progress on our world-class AI models this year:</p><ul><li data-block-key="4aapd"><a href="https://blog.google/products/gemini/gemini-3-flash/">Gemini 3 Flash: frontier intelligence built for speed</a> (Dec 2025)</li><li data-block-key="8p9pt"><a href="https://blog.google/products/gemini/gemini-3/">A new era of intelligence with Gemini 3</a> (Nov 2025)</li><li data-block-key="2ku9h"><a href="https://blog.google/technology/ai/nano-banana-pro/">Introducing Nano Banana Pro</a> (Nov 2025)</li><li data-block-key="1oibr"><a href="https://developers.googleblog.com/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/">Introducing Veo 3.1 and new creative capabilities in the Gemini API</a> (Nov 2025)</li><li data-block-key="5o13k"><a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/">Gemini 2.5: Our most intelligent AI model</a> (March 2025)</li></ul></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Gemini benchmarks table" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Google\u0027s year in review: 8 areas with research breakthroughs in 2025" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini-3-flash_final_benchmark-table_light_25-12-17_final.gif" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="kzwr4">Gemini 3 Flash price &amp; benchmark table. </p>
    </div>
  
  
    <p><img alt="Gemini benchmarks table" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini-3-flash_final_benchmark-table_light_25-12-17_final.gif"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="8cikp">We’re committed to making useful AI technology accessible, with state-of-the-art open models. We built our Gemma family of models to be lightweight and open for public use; this year we were able to introduce multimodal capabilities, significantly increase the context window, expand multilingual capabilities, and improve efficiency and performance.</p><p data-block-key="f0l1f">Learn more about this year’s advances in Gemma models:</p><ul><li data-block-key="c7dof"><a href="https://blog.google/technology/developers/gemma-3/">Introducing Gemma 3: The most capable model you can run on a single GPU or TPU</a> (March 2025)</li><li data-block-key="6ln2d"><a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Introducing Gemma 3 270M: The compact model for hyper-efficient AI</a> (Aug 2025)</li></ul></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Innovating and transforming our products with AI</h2><p data-block-key="fcih3">Throughout 2025, we continued to advance the trajectory of AI from tool to utility, transforming our portfolio of products with new, powerful agentic capabilities. We reimagined software development by moving beyond tools that assist coding to introducing powerful, agentic systems that collaborate with developers. Key advances, such as the impressive coding capabilities in Gemini 3 and the launch of <a href="https://antigravity.google/">Google Antigravity</a>, mark a new era in AI-assisted software development.</p><p data-block-key="a0ept">Learn more about this year’s advances building developer tools:</p><ul><li data-block-key="6dvis"><a href="https://blog.google/technology/developers/gemini-3-developers/">Start building with Gemini 3</a> (Nov 2025)</li><li data-block-key="da2ii"><a href="https://antigravity.google/blog/introducing-google-antigravity">Introducing Google Antigravity, a New Era in AI-Assisted Software Development</a> (Nov 2025)</li></ul></div>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="8" thumbnail-alt="Google Antigravity coding platform" video-id="6QeVnO709r0" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="al7tr">This evolution was also clear across our core products, from AI-enabled features on the Pixel 10 and updates to AI Mode in Search, to AI-first innovations like the Gemini app and NotebookLM, which gained advanced features like Deep Research.</p><p data-block-key="40hu0">Learn more about how we’ve transformed our products with AI:</p><ul><li data-block-key="3fp63"><a href="https://blog.google/products/pixel/google-pixel-10-ai-features-updates/">9 ways AI makes Pixel 10 our most helpful phone yet</a> (Aug 2025)</li><li data-block-key="an8rh"><a href="https://blog.google/products/search/ai-mode-search/">Expanding AI Overviews and introducing AI Mode</a> (March 2025)</li><li data-block-key="2nl4f"><a href="https://blog.google/products/gemini/gemini-3-gemini-app/">Gemini 3 brings upgraded smarts and new capabilities to the Gemini app</a> (Nov 2025)</li><li data-block-key="ej9fc"><a href="https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/">NotebookLM adds Deep Research and support for more source types</a> (Nov 2025)</li></ul></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Empowering creativity and co-creating with AI</h2><p data-block-key="6cf7b">2025 was a transformative year for generative media, giving people new and unprecedented capabilities to realize their creative ambitions. Generative media models and tools for video, images, audio and worlds became more effective and broadly used, with breakouts Nano Banana and Nano Banana Pro offering unprecedented capabilities for native image generation and editing. We worked with people in creative industries to develop tools like Flow and Music AI Sandbox, making them more helpful for creative workflows, and we expanded creative possibilities for people with new, AI-powered experiences in the Google Arts &amp; Culture lab, major upgrades to image editing within the Gemini app, and the introduction of powerful new generative media models like Veo 3.1, Imagen 4 and Flow.</p><p data-block-key="ffoia">Learn more about how we’re building AI to enhance creativity:</p><ul><li data-block-key="3lhhj"><a href="https://blog.google/outreach-initiatives/arts-culture/ai-cultural-learning/">Art, science, travel: 3 new AI-powered experiences this holiday season</a> (Nov 2025)</li><li data-block-key="cc29g"><a href="https://blog.google/technology/ai/veo-updates-flow/">Introducing Veo 3.1 and advanced capabilities in Flow</a> (Oct 2025)</li><li data-block-key="4uebb"><a href="https://blog.google/products/gemini/updated-image-editing-model/">Nano Banana: Image editing in Gemini just got a major upgrade</a> (Aug 2025)</li><li data-block-key="22gdl"><a href="https://blog.google/technology/ai/generative-media-models-io-2025/">Veo 3, Imagen 4, and Flow: Fuel your creativity with new generative media models and tools</a> (May 2025)</li><li data-block-key="b41j3"><a href="https://deepmind.google/blog/music-ai-sandbox-now-with-new-features-and-broader-access/">Music AI Sandbox, now with new features and broader access</a> (April 2025)</li></ul></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Image Editing Gemini Inline" external-image="" or-mp4-video-title="ImageEditing" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/ImageEditingGemini_Inline_XZuiDzE.mp4" section-header="Google\u0027s year in review: 8 areas with research breakthroughs in 2025" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="al7tr">As research breakthroughs continue to expand AI’s capabilities, Google Labs is where we share AI experiments as we develop them – hearing from users and evolving as we learn. Some of this year’s most engaging experiments from Labs: Pomelli, an AI experiment for on-brand marketing content; Stitch, which introduced a way to turn prompt and image inputs into complex UI designs and frontend code in minutes; Jules, an asynchronous coding agent that acts as a collaborative partner for developers; and Google Beam, a 3D video communications platform that used AI to advance the possibilities of remote presence.</p><p data-block-key="a3c6m">Learn more about how we’re experimenting in Labs:</p><ul><li data-block-key="b58r7"><a href="https://blog.google/technology/google-labs/pomelli/">Create on-brand marketing content for your business with Pomelli</a> (Oct 2025)</li><li data-block-key="ead1d"><a href="https://blog.google/technology/research/project-starline-google-beam-update/">Google Beam: Our AI-first 3D video communication platform</a> (May 2025)</li><li data-block-key="7m7g6"><a href="https://developers.googleblog.com/stitch-a-new-way-to-design-uis/">From idea to app: Introducing Stitch, a new way to design UIs</a> (May 2025)</li><li data-block-key="26gpp"><a href="https://blog.google/technology/google-labs/jules/">Build with Jules, your asynchronous coding agent</a> (May 2025)</li></ul></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Advancing science and mathematics</h2><p data-block-key="7p9cf">2025 was also a banner year for scientific advances with AI, marked by breakthroughs in life sciences, health, natural sciences, and mathematics.</p><p data-block-key="3rl8s">In the space of a year, we made progress in building AI resources and tools that empower researchers and help them understand, identify, and develop treatments in healthcare. In genomics, where we’ve been applying advanced technology to research for 10 years, we moved beyond sequencing, using AI to interpret the most complex data. We also marked the 5-year anniversary of AlphaFold, the Nobel-winning AI system that solved the 50-year-old protein folding problem. AlphaFold has been used by over 3 million researchers in more than 190 countries, including over 1 million users in low- and middle-income countries.</p><p data-block-key="s0fe">Learn more about how we’re using AI to advance life sciences and health:</p><ul><li data-block-key="8l8v5"><a href="https://deepmind.google/blog/alphafold-five-years-of-impact/">AlphaFold: Five years of impact</a> (Nov 2025)</li><li data-block-key="7e9u1"><a href="https://research.google/blog/using-ai-to-identify-genetic-variants-in-tumors-with-deepsomatic/">Using AI to identify genetic variants in tumors with DeepSomatic</a> (Oct 2025)</li><li data-block-key="da41m"><a href="https://research.google/blog/ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve/">AI as a research partner: Advancing theoretical computer science with AlphaEvolve</a> (Sept 2025)</li><li data-block-key="aofp2"><a href="https://deepmind.google/blog/alphagenome-ai-for-better-understanding-the-genome/">AlphaGenome: AI for better understanding the genome</a> (June 2025)</li><li data-block-key="5ndao"><a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/">Accelerating scientific breakthroughs with an AI co-scientist</a> (Feb 2025)</li></ul></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="AI co-scientist explanation animation" external-image="" or-mp4-video-title="AI Co-Scientist" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/AICoScientist-0-Hero.mp4" section-header="Google\u0027s year in review: 8 areas with research breakthroughs in 2025" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="al7tr">Gemini’s advanced thinking capabilities, including Deep Think, also enabled historic progress in mathematics and coding. Deep Think was able to solve problems that require deep abstract reasoning – achieving gold medal-standard in two international contests.</p><p data-block-key="97fsj">Learn more about how we’re advancing natural sciences and mathematics:</p><ul><li data-block-key="c43an"><a href="https://deepmind.google/blog/gemini-achieves-gold-medal-level-at-the-international-collegiate-programming-contest-world-finals/">Gemini achieves gold-medal level at the International Collegiate Programming Contest World Finals</a> (Sept 2025)</li><li data-block-key="bi9vr"><a href="https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/">Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad</a> (July 2025)</li></ul></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Shaping innovations in computing and the physical world</h2><p data-block-key="2ng3v">We’re also leading major discoveries and shaping the future of science in areas like quantum computing, energy and moonshots. Research in this area drew new levels of public attention, with progress towards real-world applications of quantum computing as demonstrated by Quantum Echoes and, notably, Googler Michel Devoret becoming a 2025 Physics Nobel Laureate along with former Googler John Martinis and UC Berkeley’s John Clarke, for their foundational 1980s quantum research.</p><p data-block-key="5bmlo">Learn more about our work on space infrastructure and quantum computing:</p><ul><li data-block-key="1dkv0"><a href="https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/">Project Suncatcher: Exploring a space-based, scalable AI infrastructure system design</a> (Nov 2025)</li><li data-block-key="4bp8o"><a href="https://blog.google/inside-google/company-announcements/googler-michel-devoret-awarded-the-nobel-prize-in-physics/">Googler Michel Devoret awarded the Nobel Prize in Physics</a> (Oct 2025)</li><li data-block-key="59ngu"><a href="https://blog.google/technology/research/quantum-echoes-willow-verifiable-quantum-advantage/">Our Quantum Echoes algorithm is a big step toward real-world applications for quantum computing</a> (Oct 2025)</li></ul><p data-block-key="dqc41">In 2025, we continued to advance the core infrastructure that powers our AI, focusing on breakthroughs in hardware design and improving energy efficiency. This included the introduction of Ironwood, a new TPU built for the age of inference, which was designed using a method called <a href="https://deepmind.google/blog/how-alphachip-transformed-computer-chip-design/">AlphaChip</a>, alongside a commitment to measuring the environmental impact of our technology.</p><p data-block-key="e5rqu">Learn more about how we’re using AI to develop chips, infrastructure and improve energy efficiency:</p><ul><li data-block-key="fsj47"><a href="https://blog.google/products/google-cloud/ironwood-google-tpu-things-to-know/">3 things to know about Ironwood, our latest TPU</a> (Nov 2025)</li><li data-block-key="dunkb"><a href="https://cloud.google.com/blog/products/infrastructure/measuring-the-environmental-impact-of-ai-inference">How much energy does Google’s AI use? We did the math</a> (Aug 2025)</li><li data-block-key="5fc9o"><a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/">Ironwood: The first Google TPU for the age of inference</a> (April 2025)</li></ul></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Ironwood Superpod" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Google\u0027s year in review: 8 areas with research breakthroughs in 2025" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Ironwood Superpod" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ironwood_superpod.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ironwood_superpod.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ironwood_superpod.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="al7tr">Our work in robotics and visual understanding brought AI agents into both the physical and virtual worlds, with advancements like the foundational Gemini Robotics models, the more sophisticated Gemini Robotics 1.5, and the introduction of Genie 3 as a new frontier for general-purpose world models.</p><p data-block-key="fo2ab">Learn more about our work with world models and robotics:</p><ul><li data-block-key="7nu4"><a href="https://deepmind.google/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/">Gemini Robotics 1.5 brings AI agents into the physical world</a> (Sept 2025)</li><li data-block-key="2ikg3"><a href="https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/">Genie 3: A new frontier for world models</a> (Aug 2025)</li><li data-block-key="e6vuf"><a href="https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/">Gemini Robotics brings AI into the physical world</a> (March 2025)</li></ul></div>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="22" thumbnail-alt="Genie 3 promotional video" video-id="PDKhUknuQDg" video-type="video">
  </uni-youtube-player-article>











  


  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Tackling global challenges and opportunities at scale</h2><p data-block-key="6ju6p">Our work throughout 2025 demonstrates how AI-enabled scientific progress is being directly applied to address the world&#39;s most critical and pervasive challenges. By leveraging state-of-the-art foundational models and agentic reasoning, we are significantly increasing our understanding of the planet and its systems, while also delivering impactful solutions in areas vital to human flourishing, including climate resilience, public health and education.</p><p data-block-key="bpln9">For example, we are using state-of-the-art foundational models and agentic reasoning to help increase our understanding of the planet, helping enable work that is making a difference in people’s lives now from weather predictions to urban planning to public health. For example, our flood forecasting information now covers more than two billion people in 150 countries for severe riverine floods. And our most advanced and efficient forecasting model, <a href="https://blog.google/technology/google-deepmind/weathernext-2/">WeatherNext 2</a> can generate forecasts 8x faster and with resolution up to 1-hour. Using this technology, we’ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.</p><p data-block-key="af618">Learn more about our work in weather, mapping and wildfires:</p><ul><li data-block-key="tqgc"><a href="https://blog.google/technology/google-deepmind/weathernext-2/">WeatherNext 2: Our most advanced weather forecasting model</a> (Nov 2025)</li><li data-block-key="83jgu"><a href="https://blog.google/technology/research/new-updates-and-more-access-to-google-earth-ai/">New updates and more access to Google Earth AI</a> (Oct 2025)</li><li data-block-key="em46a"><a href="https://blog.google/technology/ai/google-earth-ai/">Google Earth AI: Our state-of-the-art geospatial AI models</a> (July 2025)</li><li data-block-key="2cgpq"><a href="https://deepmind.google/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/">AlphaEarth Foundations helps map our planet in unprecedented detail</a> (July 2025)</li><li data-block-key="1fb49"><a href="https://deepmind.google/blog/how-were-supporting-better-tropical-cyclone-prediction-with-ai/">How we&#39;re supporting better tropical cyclone prediction with AI</a> (June 2025)</li><li data-block-key="944c9"><a href="https://blog.google/technology/ai/inside-firesat-launch-muon-space/">Inside the launch of FireSat, a system to find wildfires earlier</a> (March 2025)</li></ul><p data-block-key="fvikc">We are working with partners to apply AI-enabled scientific progress closer to patients, opening up new avenues for disease management and therapeutic discovery.</p><p data-block-key="vlom">Learn more about our health-related work:</p><ul><li data-block-key="equf2"><a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/">Cell2Sentence-Scale 27B:</a> <a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/">How a Gemma model helped discover a new potential cancer therapy pathway</a> (Oct 2025)</li><li data-block-key="bemfn"><a href="https://research.google/blog/from-diagnosis-to-treatment-advancing-amie-for-longitudinal-disease-management/">From diagnosis to treatment: Advancing AMIE for longitudinal disease management</a> (March 2025)</li></ul><p data-block-key="97km5">AI is proving to be a powerful tool in education, enabling new forms of understanding and expanding curiosity through initiatives like LearnLM and Guided Learning in Gemini. We brought Gemini’s most powerful translation capabilities to Google Translate, enabling much smarter, more natural and accurate translations and piloting new speech to speech translation capabilities.</p><p data-block-key="e48gj">Learn more about how we’re using AI to enable learning:</p><ul><li data-block-key="fajsl"><a href="https://blog.google/products/search/gemini-capabilities-translation-upgrades/">Bringing state-of-the-art Gemini translation capabilities to Google Translate</a> (Dec 2025)</li><li data-block-key="2imjk"><a href="https://blog.google/outreach-initiatives/education/guided-learning/">Guided Learning in Gemini: From answers to understanding</a> (Aug 2025)</li><li data-block-key="c6pqu"><a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/">How generative AI expands curiosity and understanding with LearnLM</a> (May 2025)</li></ul></div>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="25" thumbnail-alt="WeatherNext 2 promotional video" video-id="YQwqoEm_xis" video-type="video">
  </uni-youtube-player-article>











  


  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Prioritizing responsibility and safety</h2><p data-block-key="51tcq">We couple our research breakthroughs with rigorous and forward-looking work on responsibility and safety. As our models grow more capable, we’re continuing to advance and evolve our tools, resources and safety frameworks to anticipate and mitigate risk. Gemini 3 demonstrated this approach in action: it&#39;s our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. And we’re looking further ahead, exploring a responsible path to AGI, prioritizing readiness, proactive risk assessment, and collaboration with the wider AI community.</p><p data-block-key="4pgfk">Learn more about our responsibility and safety work:</p><ul><li data-block-key="fp3sj"><a href="https://blog.google/technology/ai/verify-google-ai-videos-gemini-app/">You can now verify Google AI-generated videos in the Gemini app</a> (Dec 2025)</li><li data-block-key="33kjv"><a href="https://blog.google/technology/ai/ai-image-verification-gemini-app/">How we’re bringing AI image verification to the Gemini app</a> (Nov 2025)</li><li data-block-key="a0obe"><a href="https://deepmind.google/blog/strengthening-our-frontier-safety-framework/">Strengthening our Frontier Safety Framework</a> (September 2025)</li><li data-block-key="dhkiq"><a href="https://deepmind.google/blog/taking-a-responsible-path-to-agi/">Taking a responsible path to AGI</a> (April 2025)</li><li data-block-key="a6atd"><a href="https://deepmind.google/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/">Evaluating potential cybersecurity threats of advanced AI</a> (April 2025)</li></ul></div>
      </div>
    </div>
  

  
    

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Google\u0027s year in review: 8 areas with research breakthroughs in 2025&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="al7tr">Leading frontier collaborations with industry, academia and civil society</h2><p data-block-key="6hthm">Advancing the frontier of AI responsibly demands collaboration across all parts of society. In 2025, we worked with leading AI labs to help to form the Agentic AI Foundation and support open standards to ensure a responsible and interoperable future for agentic AI. In education, we’ve partnered with school districts like Miami Dade County and education groups like Raspberry Pi to equip students with AI skills. Our research partnerships with universities like UC Berkeley, Yale, the University of Chicago and many more have been instrumental to some of this year’s most exciting frontier research, and we’re working with the US Department of Energy’s 17 national laboratories to transform how scientific research is conducted. And we’re working with filmmakers and other creative visionaries to put the best AI tools in their hands and explore storytelling in the age of AI.</p><p data-block-key="9e2s4">Learn more about our work on frontier collaboration:</p><ul><li data-block-key="3drvf"><a href="https://deepmind.google/blog/google-deepmind-supports-us-department-of-energy-on-genesis/">Google DeepMind supports U.S. Department of Energy on Genesis: a national mission to accelerate innovation and scientific discovery</a> (Dec 2025)</li><li data-block-key="9hala"><a href="https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation">Formation of the Agentic AI Foundation (AAIF), Anchored by New Project Contributions Including Model Context Protocol (MCP), goose and AGENTS.md</a> (Dec 2025)</li><li data-block-key="4n2md"><a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services">Announcing Model Context Protocol (MCP) support for Google services</a> (Dec 2025)</li><li data-block-key="3ri6n"><a href="https://blog.google/outreach-initiatives/education/ai-learning-commitments/">Our latest commitments in AI and learning</a> (Nov 2025)</li><li data-block-key="2orqk"><a href="https://blog.google/outreach-initiatives/education/google-ai-education-workforce-skills/">Partnering to power Miami’s AI-ready future</a> (Oct 2025)</li><li data-block-key="17udc"><a href="https://blog.google/technology/ai/sweetwater-film/">AI on Screen premiere: “Sweetwater” short film explores new AI narratives</a> (Sept 2025)</li><li data-block-key="m5oq"><a href="https://blog.google/technology/google-deepmind/ancestra-behind-the-scenes/">Behind “ANCESTRA”: combining Veo with live-action filmmaking</a> (Jun 2025)</li><li data-block-key="vts6"><a href="https://blog.google/technology/ai/lab-session-shankar-mahadevan/">How Indian music legend Shankar Mahadevan experiments with Music AI Sandbox</a> (April 2025)</li></ul><h2 data-block-key="6k1h2">Looking ahead</h2><p data-block-key="5b7km">As we look towards 2026, we’re looking forward to continuing to advance the frontier, safely and responsibly, for the benefit of humanity.</p></div>
      </div>
    </div>
  

  
    







<uni-related-content-tout title="2025 at Google" cta="See more" summary="Learn more about Google’s launches, milestones and more from 2025." hideimage="False" eyebrow="Collection" image-alt-text="" role="none" fullurl="https://blog.google/technology/ai/look-back-2025/" pagetype="collectiondetailpage" isarticlepage="">
  
    
  
</uni-related-content-tout>

  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
