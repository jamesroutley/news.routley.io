<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rpeszek.github.io/posts/2022-08-30-code-cognitiveload.html">Original</a>
    <h1>Cognitive loads in programming</h1>
    
    <div id="readability-page-1" class="page"><article>
    
    
    <section>
        
<blockquote>
<blockquote>
<p>  <em>“My brain hurts”, a quote from a code review</em></p>
</blockquote>
</blockquote>
<p><strong>DRAFT version:</strong> <em>This post is a work-in-progress. I am publishing it to solicit early feedback.</em></p>
<p>This long post presents programming in a different light than what is commonly considered. We will look at cognitive aspects of interacting with code.</p>
<p>We will examine cognitive effort that goes into the implementation and cognitive loads on these poor souls who need to work on that code later. We will consider the programming language, its libraries, and implemented programs as <em>instructional materials</em>. We will view the developer as both an <em>instructional designer</em> and a <em>learner</em>. We will think about bugs as cognitive overload and a missed learning opportunity. We will discuss the cognitive impact of abstractions, types, and programming principles.</p>
<p>Cognitive load of working with code is rarely considered. We ask “How long will it take?” (in fibonacci numbers, of course), we do not ask “How will it impact the overall complexity?”.</p>
<ul>
<li>show how considering <em>cognitive loads</em> in context of programming projects provides valuable insights</li>
<li>present some useful terminology for reasoning about code complexity.</li>
</ul>
<p>I will try to explain psychological terminology but this post assumes readers’ (high level) familiarity with concepts of FP and OOP.</p>
<p>My pet peeve is identifying specific <a href="https://rpeszek.github.io/tags/patterns-of-erroneous-code.html" target="_blank">patterns of erroneous code</a> and what could be causing them, there is a human factor and a technical part to these patterns.</p>
<p>This post reflects on my personal observations accumulated over 27 years of professional programming work, augmented by a few years of academic teaching.</p>
<h2 id="that-dreaded-yaml">That dreaded YAML</h2>
<p>I am perusing thousands of lines in Infrastructure as Code (IAC) yaml files. I am looking at an already refactored and improved version. It is a lot of templated <em>YAML</em> of k8s configuration at my work. The underlying reason for the complexity is the PL itself<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Did the refactor break things? Of course it did. Complexity has consequences. With some effort, the issues were fixed. This is how things are, there is nothing we can do about it. There isn’t?</p>
<p>I want to contrast <em>YAML</em> with a configuration language called <a href="https://dhall-lang.org/" target="_blank">Dhall</a> (one of my favorites). To use <em>Dhall</em> you may need to adjust to a Haskell-like syntax, maybe learn a few new concepts (like ADTs), think about configuration that uses lambda expressions. The return on the investment are Dhall safety features. Dhall even makes the process of refactoring safe, you can compare the previous configuration against the new and Dhall will tell you if both are equivalent or why not.</p>
<p><em>Dhall</em> and <em>YAML</em> come with very different cognitive challenges.</p>
<h2 id="cognitive-psychology">Cognitive psychology</h2>
<p>Cognitive load theory defines cognitive load as the amount of information that working memory holds at one time. The idea is that the human brain is limited in that capacity. Psychologists have identified the load to be about 3-5<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> “units of information” (also called “chunks”). This space appears to be quite limited.</p>
<p>The idea of decomposing the program into fewer (but bigger) “chunks” that interact in a clear way has been around for as long as I can remember. We will examine this idea in terms of <em>Cognitive Load Theory</em>.</p>
<p>Cognitive Load Theory is concerned with <em>instructional design</em> and improving how <em>information is presented</em> to a <em>learner</em>. Controlling the learner’s cognitive loads is an essential part of this work.</p>
<p>Continuous learning is a part of what programmers do, but implementing and modifying project code is by far the biggest cognitive effort that programmers face.</p>
<p>Cognitive psychology considers 3 types of cognitive load: <em>Intrinsic, Extraneous, Germane</em>. All are related to <em>information presentation</em> and we will think about them in the context of code.</p>
<ul>
<li><p><em>Intrinsic cognitive load</em> is the inherent level of difficulty associated with a specific (instructional) topic. Thinking about code, requirements are a good choice for a topic. A rough moral equivalent known to software developers is <em>essential complexity</em> (things are complex because they are, to reduce this load requirements would need to change).</p></li>
<li><p><em>Extraneous cognitive load</em> is generated by the manner in which information is presented to learners and is under the control of instructional designers. This term is often used to describe unnecessary (artificially induced) cognitive load. Thinking about code, a rough moral equivalent of high extraneous load is <em>accidental complexity</em><a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> (things are complex because the program made it so).</p></li>
<li><p>Germane cognitive load refers to the work that is put into constructing a long-lasting store of knowledge or schema. Schema is a pattern of thought or behavior that organizes categories of information and the relationships among them. Psychologists also use the term <em>“chunk”</em> and schema construction is the process of creating these chunks in memory.</p></li>
</ul>
<blockquote>
<p>  <em>Cognitive load theory thesis is about reducing extraneous cognitive load redirecting it towards germane load.</em></p>
</blockquote>
<p>Cognitive theory considers intrinsic load to be not movable, obviously requirements can be changed.</p>
<p>I need to emphasize that the <em>information presentation</em> under consideration facilitates understanding of the code itself and not so much the concepts (e.g. abstractions) used to create it. Knowledge of these concepts is a prerequisite. Prerequisites are an important caveat and one that ends up being contentious.</p>
<p><strong>Prerequisites:</strong> Working on a project code will reinforce knowledge of programming concepts (psychologists call something similar a <a href="https://en.wikipedia.org/wiki/Worked-example_effect" target="_blank">worked-example effect</a>) but, for a working programmer, learning new concepts ideally needs to happen outside of project work. In reality, there is no time for this. Also, available programming concepts are limited not only by what the developer and the team know, but also by what is supported by the PL (programming language). Developer backgrounds and what is supported in a PL vary a great deal. Thus, the list of prerequisites that can go into a programming project is limited.  </p>
<p>This sets the stage for what I want to discuss, but before continuing let me briefly review a <strong><em>few more relevant concepts.</em></strong></p>
<p><em>Cognitive overload</em> happens when working memory is overwhelmed by the 3 cognitive loads we have described, IMO, bugs are evidence of a cognitive overload.</p>
<p>I wanted to use <em>cognitive debt</em> in the title, intending it as a pun on “technical debt” because I am interested in discussing negative impacts on the team’s ability to understand and reason about the code. However, this term turns out to have a clinical meaning and I decided against using it.</p>
<blockquote>
<p>  <em>“excessive and repetitive thinking about current concerns, problems, past experiences or worries about the future”</em></p>
</blockquote>
<p>I do not claim to know a lot about clinical psychology but the definition clearly is very relevant to programmers and could partially explain why programmers are often unhappy<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>, or why programming discussion groups are often very negative.</p>
<p>You may want to think about <em>working memory</em> and <em>cognitive loads</em> as something akin to <em>RAM</em> in a computer.</p>
<p>These were cliff notes written by a non expert. There are many tricky and relevant bits like <em>information retrieval from long term memory</em>. Things I am progressively less and less component to describe in psychological context.</p>
<h2 id="easy-vs-simple">Easy vs Simple</h2>
<p>If you have looked at my <a href="https://rpeszek.github.io/tags/TypeScript-Notes.html" target="_blank">TypeScript types</a> series, you have seen me <a href="https://rpeszek.github.io/posts/2022-03-13-ts-types-part6.html#about-simplicity" target="_blank">write about it already</a>. I do not claim that my definitions are the only correct way that these terms should be interpreted. However, I have seen other programmers use a similar disambiguation so I am including it here.</p>
<p>I consider the terms simple and easy to have a different meaning.</p>
<p>Easy means fewer prerequisites and implies low germane load, hard means many prerequisites.</p>
<p>This differentiation could also be expressed as:</p>
<blockquote>
<p>  <em>Easy means low cost of creation, simple means low cost of consumption</em></p>
</blockquote>
<p>except, in this post my interest is the cognitive effort only not the total cost.</p>
<p>Achieving <em>simplicity</em> on a larger project is not <em>easy</em>. Easy does not scale well. There appears to be no free lunch, cognitive load needs to be somewhere. My big preference is trying to achieve <em>hard and simple</em> rather than <em>easy and complex</em>. In other words, I prefer to spend my cognitive bandwidth on germane load over extraneous load. This, I am pleased to note, is aligned with cognitive psychology.</p>
<p>Recall the advice from cognitive psychologists is to reduce extraneous load redirecting it towards germane load. This translates to:</p>
<blockquote>
<p>  <em>Move from complex to hard</em></p>
</blockquote>
<p>An interesting way to look at easy vs simple is to think about a creative process like writing a book. Easy to write is clearly very different from simple to read. In programming these two are bundled together, a program created by one developer needs to be consumed by another dev who needs to modify it or interact with it. The term “readable code” comes to mind. I consider it different from simple. E.g. readable code does not mean no subtle bugs. Message is readable if you know what it conveys, but what it conveys could be complex or even misleading.</p>
<p>IMO, the popularity of easy and the unpopularity of simple are a systemic problem in today’s programming and elsewhere.</p>
<p>Next section discusses examples of code which was intended to be easy and ended up complex.</p>

<p>What was the most complex code you’ve worked on?</p>
<p>This experience seems to me a good example of a big extraneous load, I had to deal with a load of 200 coupled “chunks”.</p>
<p>Maintaining messy code can be stressful. Fortunately, projects like these become “infamous” very fast and you get moral support from other team members. That really helps. Be a source of such support for your teammates as well. Few words of encouragement and acknowledgment of the hardship go a long way. Also, the information will slowly percolate up and the management may become more receptive to accept the cost of a big refactor or even a complete rewrite. This is what happened in my Java Struts example.  </p>
<p>My second example is something that happened more recently. I worked on reimplementing a JS application. It was one of these apps that can be described as: <em>was easy to write, is hard to maintain or understand</em>. I am sure very few readers will be surprised by the existence of a hard to maintain JS application, but let’s put talking about this aspect aside. Is writing “easy” code the same as generating excessive cognitive load for the maintainers? I think it typically is, it is not that hard to incrementally develop a non penetrable maze. Maintaining some code structure to manage the cognitive load is not “easy”.</p>
<blockquote>
<p>  <em>IMO, high quality code shifts cognitive load from maintainer to implementer</em></p>
</blockquote>
<p>This works great even if both are the same person.</p>
<p>Besides some common sense principles (feel free to add more), what else can we do to control extraneous load? Things are about to get more tricky.</p>
<p>Types are, obviously, an important tool in controlling cognitive load. Types <em>offload</em> many code verification tasks from the developer. This is significant, developers can ignore a potentially high extraneous load of a program by trusting its type. As I already mentioned, types can be an <em>instructional material</em>, a blueprint. Using a type checker can, in itself, be an interactive learning process (e.g. using REPL to ask type questions about the code).</p>
<p>Reducing cognitive load using abstractions and types is doable but requires navigating some tricky waters.</p>
<p><strong>In a unicorn universe,</strong> projects are not allowed to exceed certain thresholds of cognitive load. When the threshold is reached abstractions that lower the load are identified, learned, and respectfully applied. If that is not possible, requirements are reexamined. Unicorn managers are automatically beatified. 🦄  </p>

<p>Let’s define a bug as an unintended program defect. That removes all the temporary hacks from consideration. But it is the programmer’s job to figure these things out. A bug implies some issue in the mental process.</p>
<p>I consider cognitive overload to be the main cause of bugs. <em>Metacognition</em> is an important concept in cognitive psychology. It is about knowing strengths and weaknesses in our own cognitive process.</p>
<blockquote>
<p>  <em>Programming is an interactive process of finding and fixing bugs.</em></p>
</blockquote>
<p>“Insanity is doing the same thing over and over and expecting different results”. I promise you 2 things: When you start analyzing bugs, you will start seeing patterns (similar to <a href="https://rpeszek.github.io/tags/patterns-of-erroneous-code.html" target="_blank">patterns of erroneous code</a>). Unfortunately, you will likely have problems in communicating these patterns to developers who do not go through a similar process. I found that a code review session showing the same issue in a few places works better than trying to explain this without a concrete context (oops).</p>
<p>How about typos, trivial overlooks that are sometimes so hard to spot? That mysterious brain of ours is good at creating these. A great reading on this, in the context of (non-programming) typos, is <a href="https://www.wired.com/2014/08/wuwt-typos/" target="_blank">WUWT, Why It’s So Hard to Catch Your Own Typos</a>.</p>
<p>Side note: This line of thought could also partially explain why programmers seem to be at home in the code they wrote even if other programmers consider it a complete mess. Sometimes just changing font or background color allows us to spot issues we have overlooked before. Our perception changes if what we interact with feels foreign (interestingly this should increase the cognitive load). It appears that some mental reset is sometimes needed.  </p>
<p>Error proneness of programming at the level of PL statements is also consistent with the cognitive load theory. At this level a programmer needs to consider a multitude of details, most likely overwhelming the working memory limits.</p>
<p>Static compilation can prevent a lot of trivial errors and hopefully the prevented list will grow, but that list is not exhaustive.</p>
<p><strong>Section Summary</strong></p>
<p>My first point is that programmers should start considering cognitive aspects when thinking about bugs.</p>
<p>What is that we do when we discover a bug? We write a test, right? Does this reduce the cognitive load? Of course it does not. IMO, it is more important to spend time on some intro- and retrospection and look for ways to lower the extraneous load or build some type safety. If that is not possible, improving test coverage becomes important. I want to learn from bugs. <em>Fixing bugs is the least important part of the process.</em> I should also mention that this is, unfortunately, a <em>repetitive negative thinking</em> territory.</p>
<p>Here is an example that keeps popping into my mind when thinking about trivial errors. I have seen many stack overflow errors in my life, I have seen only 2 or 3 since I moved to Haskell but they were not easy to find. They all were caused by Haskell allowing this lambda expression:</p>

<p>This to me is a good example of extraneous complexity that could be prevented by the compiler. Many PLs (e.g. anything in ML groups like OCaml, Reason will not allow such code). Here is a relevant discussion on reddit: <a href="https://www.reddit.com/r/haskell/comments/lxnbrl/ghc_proposal_norecursivelet_prevent_accidental/" target="_blank">NoRecursiveLet</a>. Thinking about reducing extraneous load could impact such discussion (in this case, by supporting the proposal).</p>
<p>My second point is the recurring one, types and abstractions can play a big role in reducing bugs. Hopefully types and abstractions themselves are bug free!</p>
<p><strong>There is an alien civilization</strong> of programmers who analyze their bugs, Alien PL designers consider these analyses to decide which features are in and which are out. Their PLs do not even have strings. You can do a lot of harm with just strings.  </p>

<p>Summary of previous sections: Our cognitive load is limited but we are capable of abstract reasoning and can work with big <em>chunks</em> of knowledge. Abstractions seem like our best hope in reducing the overall code complexity. But …there are a few caveats.</p>
<p><strong>Poorly implemented abstractions</strong></p>
<p>You spotted an intermittent malfunction in a code you maintain. Luckily, you see only one commit in recent history and you have a strong hunch something is wrong with that commit. Only some 50 code changes. The one that caused the issue is: <code>var1 == var2</code> changed to <code>var2 == var1</code>. Would you be able to spot it? I call this type of issue a “gotcha”.</p>
<p>I like to think about this paraphrasing Gimli:</p>
<blockquote>
<p>  <em>“Computation Laws are upon you, whether you would risk them or not.”</em></p>
</blockquote>
<p>Equality is an example of an abstraction developers implement and use, but not think much about. However, the list of surprising behaviors like these is quite long affecting all kinds of abstractions. Gochas create chaos in the cognitive process. Gotchas often become mystery bugs and are resolved using workarounds.</p>
<p>Developers I talked to often responded to such examples by saying something like: “This is just bad code, whoever implemented it should have been more careful”. Except, I can point to examples in standard libraries of popular mainstream PLs or popular frameworks<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>. The issues come with no deprecation warning and, if documented, are considered a ‘feature’.</p>
<p><strong>Abstractions themselves causing cognitive issues</strong></p>
<p>OOP creates a very high cognitive load, to a point that even compiler writers mess it up all the time<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a>. I started my programming career as an OOP enthusiast and evangelist. OO programming has an appeal of simplicity and I was seduced by it for many years. It took me a long time to realize that OOP is not simple at all. Let’s talk OOP a little. Pick random training. You will probably learn that <em>Cat</em> <em>is a</em>n <em>Animal</em> and that everything is intuitive.</p>
<p>The concept of exception (i.e. <code>throw</code> and <code>catch</code> game) is another example of a risky complexity that impacts even Haskell<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a>.</p>
<p>You may notice that the examples of <em>gotchas</em> I am coming up with have something in common. These issues can be classified under: <em>not trustworthy types</em>. Misleading types will confuse any developer, that includes developers who work in dynamically typed languages and may not think about types explicitly.</p>
<p>Are there any “gotcha” free environments? Haskell comes close but is not perfect<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a>. Proof assistants like Idris come to mind, you get very sound abstractions, and these can even verify totality. That is kinda interesting, let’s pause for a bit here… Consider the levels of abstraction used in proof assistants. It appears that our brain needs something at the level of a dependently typed lambda calculus to work correctly<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a>. That could make sense, for things to be logical you need, well you need the logic itself. Proof assistants are not “gotcha” free though, they have different types of gotchas<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a>.</p>
<p><strong>Wrong abstraction for the job</strong></p>
<p>Let’s talk about data structures a bit. The choice you make can impact extraneous complexity a great deal. An example which emphasizes this is <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" target="_blank">CRDT</a>.</p>
<p><strong>High levels of abstraction, an extraneous aspect</strong></p>
<p>I have seen very abstract code where the abstraction was like trees preventing developers from noticing a forest. One source of such examples is error handling. Mathematics rarely concerns itself with error messages, falsehood is falsehood. I have blogged about it in my posts about <a href="https://rpeszek.github.io/posts/2021-01-17-maybe-overuse.html" target="_blank">Maybe Overuse</a> and <a href="https://rpeszek.github.io/posts/2021-02-13-alternative.html" target="_blank">Alternative and errors</a>.</p>
<p>Side note: Probably not surprisingly, these were rather negatively received, heavily downvoted posts. The topic itself is very much a <em>repetitive negative thinking</em>. Incidentally, the negative comments mostly belonged in the general “what you are describing is just bad code, whoever wrote it should have been more careful” category. I want to understand how code abstractions could promote erroneous code, my interest is in what makes people not careful.<br/>
 </p>
<p>Let’s focus on Haskell. One simple to explain and not very abstract example that still fits into this section is the <code>guard</code><a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> combinator. I see it used and I also scratch my head when, say, a JSON parser error says only <code>&#34;mempty&#34;</code>. Possibly, some programmers think about the abstraction called <code>Alternative</code> when they should be thinking about something like <code>MonadFail</code>, an abstraction that allows to specify error messages.</p>
<p><strong>Section Summary</strong></p>
<p>Gotchas presented to us (thank you very much) by language designers or library implementers should technically be classified as <em>intrinsic</em> since a common bloke like me can’t do much about them other than look for a job that has a better tooling. If you look at programming as a whole, these are extraneous loads.</p>
<p>I have left the subject of abstraction vs imperative (abstractions being less straightforward and harder to map to actual execution) untouched. I plan to return to this and to the topic of gotchas in my next post.</p>
<div><p><strong>There is a planet</strong> where PL designers treat all programming abstractions and types with respect. Only sound, correctly implemented abstractions are used.</p></div>
<h2 id="germane-and-intrinsic-load-of-fp">Germane and intrinsic load of FP</h2>
<p>I expect that nothing in this section will be surprising to a functional programmer, but FP has such a unique cognitive impact that it is hard for me to not talk about.</p>
<p>Functional Programming allows us to understand computations in ways that are not possible without FP. Understanding is a big cognitive simplifier<a href="#fn22" id="fnref22" role="doc-noteref"><sup>22</sup></a>. We are more at home with things we understand than with things we just know. Realizing that computations is something I can actually study to understand has been a game changer for me as a programmer.</p>
<p>Consider the following (middle-school?) formulas and how they relate to programming:</p>
<blockquote>
<p><span><em>a</em><sup>(<em>b</em> + <em>c</em>)</sup> = <em>a</em><sup><em>b</em></sup> * <em>a</em><sup><em>c</em></sup></span></p>
</blockquote>
<p>These, pattern match and currying formulas, suggest that computations relate to other things we already know in ways that are almost surprising<a href="#fn23" id="fnref23" role="doc-noteref"><sup>23</sup></a>.</p>
<p>FP is hard and there are 2 reasons why. One: it is simply hard (has a decent surface area but is also deep), two: it is different.</p>
<p>I was learning FP while working as a Java / Groovy developer. It took me 8 years, I estimated about 7000 hours. This effort included Category Theory, Types (my main interest), PLT, and programming in a bunch of FP languages. This has been, obviously, a big personal investment. And, I still had to internalize a lot of this when I started my actual Haskell job. Please do not interpret these stats as an argument that FP cannot be learned incrementally, or that learning FP does not provide immediate benefits. I am including these personal stats as evidence of an overall effort but also as evidence of the multitude of learning opportunities. We should resist thinking about knowledge as a binary checkbox.</p>
<p>FP requires a shift in how developers think. This shift is especially hard if the developer can only practice imperative skills at work. The tools we use impact our cognitive function.</p>
<blockquote>
<p>  “It is not only the violin that shapes the violinist, we are all shaped by the tools we train ourselves to use, and in this respect programming languages have a devious influence: they shape our thinking habits.”</p>
</blockquote>
<p>The quote is from <a href="https://chrisdone.com/posts/dijkstra-haskell-java/" target="_blank">Dijkstra letter to The University of Texas</a> protesting their Haskell -&gt; Java curriculum change. If you are into technical sports, you may have heard the term “muscle memory”. It is often harder to unlearn or adjust a body movement than learn a new one from scratch. It is even harder to “own” the old movement and the new movement at the same time. Psychologists also believe that unlearning is hard<a href="#fn24" id="fnref24" role="doc-noteref"><sup>24</sup></a>.</p>
<p>I will dig my hole a little deeper. This one line of code made a huge impact on me (it is called the <em>Free Monad</em> and is in Haskell<a href="#fn25" id="fnref25" role="doc-noteref"><sup>25</sup></a>):</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span>data</span> <span>Free</span> f a <span>=</span> <span>MkFree</span> (f (<span>Free</span> f a)) <span>|</span> <span>Pure</span> a </span></code></pre></div>
<p>I decided to dedicate a full summer to learning this line and it ended up taking longer than that. There is actually quite a bit to learn and <em>understand</em> here!</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span>newtype</span> <span>Fix</span> f a <span>=</span> <span>MkFix</span> (f (<span>Fix</span> f a))</span></code></pre></div>
<p>Or, how is this a monad? Does it satisfy monad laws? What does <em>free</em> mean? Can other things than monads be <em>free</em>? Can <code>Free</code>-s with different <code>f</code>-s be combined? If so, are there easier and harder ways of combining them? What is <em>freer</em>? How do I program with it? How does it (and should it) relate to <code>try-catch</code> games? And finally, what libraries implement and use <code>Free</code>? The point I am trying to make is that FP computations are a different breed. They actually have properties and the learner can build an understanding of these properties.</p>
<p>There has been some discussion about making Haskell itself more accessible (e.g. <a href="https://www.michaelpj.com/blog/2021/01/02/elementary-programming.html" target="_blank">Elementary Programming</a>) and some library effort in this direction as well (e.g. <a href="https://github.com/digitallyinduced/ihp" target="_blank">IHP</a>).</p>
<p>FP is a niche, I think FP has a stable niche in programming. Correctness and understanding of computations are problems almost nobody in the industry cares about but they are sometimes needed. This reminds me of a Terry Pratchett Diskworld character: Esmerelda (Granny) Weatherwax</p>
<blockquote>
<p>  <em>“Esme Weatherwax hadn’t done nice. She’d done what was needed.”</em></p>
</blockquote>
<p>Wanted means popular, needed means stable. However, basic principles of FP will probably find a wider use (as discussed in <a href="#extraneous-loads-that-grow">Extraneous loads that grow</a>).</p>
<p><strong>In a parallel dimension</strong> Alonso Church did not take a temporary break from lambda calculus and showed it to his student, Alan Turning. The first computer hardware was based on SKI calculus. In that dimension kids learn mathematics with proofs, imperative programming is considered a great addition after programmers learn the principles. In that dimension software has very few bugs, however, this universe has fewer programs, even fewer programmers, and the error messages suck. 🌌  </p>
<h2 id="post-summary">Post Summary</h2>
<p>My readers may get the impression that this post is a criticism of imperative programming. Applying cognitive load theory to programming does not translate to “imperative is complex”, rather it translates to “too much of imperative in one place (logically coupled) is complex”. IMO, some amount of imperative is often helpful.</p>
<p>I am sure you have noticed that I think a lot about code complexity. And, yes, I do not feel comfortable working in messy code. Assessing and controlling the level of code complexity is crucial to me.</p>
<p>It has dawned on me that my dislike of code complexity may not be shared by others. <em>False consensus effect</em> is assuming that everyone else thinks like me.</p>
<p>Are we doing a good job in managing code complexity? I think this a fair question to ask even if you think that simplicity is not crucially important. This post has argued that we are mostly failing on that front. In this post, we looked at how project complexity grows unnoticed, how bugs are a missed opportunity to learn about how we fail, and how FP changes the cognitive process but can be hard to learn. As a whole this post has been a bit of <em>repetitive negative thinking</em>, but I hope you found some positives and useful ideas in it as well. The main point of this post was to advocate for including cognitive aspects of programming projects into consideration and to present some useful terminology for doing it.</p>
<h2 id="there-is-much-more-to-it">There is much more to it</h2>
<p>This post took a very narrow path through the very broad subject of cognitive aspects of programming.</p>
<p>My focus was coding rather than process. I did not discuss things like cognitive loads in pool requests, cognitive considerations during sprint planning, git hygiene, etc.</p>
<p>Size of program files is an obvious, related topic I did not discuss.</p>
<p>Monorepo vs single projects has interesting relevance. Dependency graphs of or sorts (version, library deps) are a similar interesting topic.</p>
<p>Coding efficiency and the 10X programmer in the context of cognitive loads is an interesting (but contentious) topic.</p>
<p>Low Code: The idea of distributing cognitive load across different components is not new. The terms “decoupling” or “isolation of concerns” are in this space. Low code is an idea of a very lopsided distribution in which most of the complexity falls onto the infrastructure. I started writing about it but decided to remove my notes as this post feels already too long.</p>
<p>Some PLs (Haskell is a good example of this) suffer from what some people call the <em>Lisp curse</em>. Instead of using established libraries, proprietary or one-off tools are often created. It is interesting why this happens and what to do about it. Could love of abstractions be causing it (reuse abstractions, not a code)? Is writing it from scratch a lower cognitive effort than learning and applying an existing solution? The end result, obviously, increases the cognitive load.</p>
<p>Cognitive load should be viewed as a resource problem, one that does not scale very well, and one that is not well understood. Cognitive load is greatly impacted by turn over rates, switching of code ownership, and by installed processes. Context switching is very expensive, the programmer’s inability to find contiguous blocks of time to focus could be viewed as an indication of an under-resourced project.</p>
<p>Linting, formatting, aesthetics are all very interesting cognitive load topics. Most programmers seem to be very sensitive to how the code is presented, (e.g. would you ever use a light background in your code editor?). Similarly, syntax vs semantics, it seems syntax has a huge cognitive role even if we think about it as bikeshed.</p>
<p>Habit formation and unlearning are a big and very interesting topic.</p>
<p>Cognitive biases in the context of coding seem like very interesting topics too. In particular <em>bandwagon effect</em> (TypeScript is popular and hence must be very good), <em>framing effect</em> (new cool technology), <em>commitment bias</em> (we done it like this before, it has been tried and tested), <em>functional fixedness</em> (we do not need another PL), <em>omission neglect</em> (things we do not know are not important), <em>groupthink</em> (we want to work with people who think like us), <em>bikeshedding</em> (possibly most of this post 🙂).</p>
<p>Point-free code, I stayed away from discussing it.</p>
<p>Cognitive aspects of troubleshooting are something I only touched on.</p>
<p>Imperative vs denotative is something I only touched on.</p>
<p>One topic I do plan to discuss (in the next post) is a distinction between empirical and formal processes in programming and how it impacts cognitive loads and acts as a divider.</p>
<p>Cognitive loads are related to stress, I intend to return to this topic in the future as well.</p>
<p>This post did not run out of topics, rather I have run out of steam. I hope I gave you things to think about. Thank you for reading!</p>


    </section>
</article></div>
  </body>
</html>
