<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/jgbit/vuda">Original</a>
    <h1>VUDA: A Vulkan Implementation of CUDA</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a id="user-content-vuda" aria-hidden="true" href="#vuda"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>VUDA</h2>
<p dir="auto">VUDA is a header-only library based on Vulkan that provides a CUDA Runtime API interface for writing GPU-accelerated applications.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-documentation" aria-hidden="true" href="#documentation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<p dir="auto">VUDA is based on the <a href="https://www.khronos.org/vulkan/" rel="nofollow">Vulkan API</a>. The functionality of VUDA conforms (as much as possible) to the specification of the CUDA runtime. For normal usage consult the reference guide for the <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" rel="nofollow">NVIDIA CUDA Runtime API</a>, otherwise check the VUDA wiki:</p>
<ul dir="auto">
<li><a href="https://github.com/jgbit/vuda/wiki/Change-List">Change List</a></li>
<li><a href="https://github.com/jgbit/vuda/wiki/Setup-and-Compilation">Setup and Compilation</a></li>
<li><a href="https://github.com/jgbit/vuda/wiki/Deviations-from-CUDA">Deviations from CUDA</a></li>
<li><a href="https://github.com/jgbit/vuda/wiki/Implementation-Details">Implementation Details</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-usage" aria-hidden="true" href="#usage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">All VUDA functionality can be accessed by including <code>vuda.hpp</code> and using its namespace <code>vuda::</code>.
Alternatively, one can utilize <code>vuda_runtime.hpp</code> which wraps and redirect all CUDA functionality.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#if defined(__NVCC__)
    #include &lt;cuda_runtime.h&gt;
#else
    #include &lt;vuda_runtime.hpp&gt;
#endif

int main(void)
{
    // assign a device to the thread
    cudaSetDevice(0);
    // allocate memory on the device
    const int N = 5000;
    int a[N], b[N], c[N];
    for(int i = 0; i &lt; N; ++i)
    {
        a[i] = -i;
        b[i] = i * i;
    }
    int *dev_a, *dev_b, *dev_c;
    cudaMalloc((void**)&amp;dev_a, N * sizeof(int));
    cudaMalloc((void**)&amp;dev_b, N * sizeof(int));
    cudaMalloc((void**)&amp;dev_c, N * sizeof(int));
    // copy the arrays a and b to the device
    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice);
    // run kernel (vulkan shader module)
    const int blocks = 128;
    const int threads = 128;
#if defined(__NVCC__)
    add&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(dev_a, dev_b, dev_c, N);
#else
    const int stream_id = 0;
    vuda::launchKernel(&#34;add.spv&#34;, &#34;main&#34;, stream_id, blocks, threads, dev_a, dev_b, dev_c, N);
#endif
    // copy result to host
    cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);

    // do something useful with the result in array c ...        

    // free memory on device
    cudaFree(dev_a);
    cudaFree(dev_b);
    cudaFree(dev_c);
}"><pre>#<span>if</span> defined(__NVCC__)
    #<span>include</span> <span><span>&lt;</span>cuda_runtime.h<span>&gt;</span></span>
#<span>else</span>
    #<span>include</span> <span><span>&lt;</span>vuda_runtime.hpp<span>&gt;</span></span>
#<span>endif</span>

<span>int</span> <span>main</span>(<span>void</span>)
{
    <span><span>//</span> assign a device to the thread</span>
    <span>cudaSetDevice</span>(<span>0</span>);
    <span><span>//</span> allocate memory on the device</span>
    <span>const</span> <span>int</span> N = <span>5000</span>;
    <span>int</span> a[N], b[N], c[N];
    <span>for</span>(<span>int</span> i = <span>0</span>; i &lt; N; ++i)
    {
        a[i] = -i;
        b[i] = i * i;
    }
    <span>int</span> *dev_a, *dev_b, *dev_c;
    <span>cudaMalloc</span>((<span>void</span>**)&amp;dev_a, N * <span>sizeof</span>(<span>int</span>));
    <span>cudaMalloc</span>((<span>void</span>**)&amp;dev_b, N * <span>sizeof</span>(<span>int</span>));
    <span>cudaMalloc</span>((<span>void</span>**)&amp;dev_c, N * <span>sizeof</span>(<span>int</span>));
    <span><span>//</span> copy the arrays a and b to the device</span>
    <span>cudaMemcpy</span>(dev_a, a, N * <span>sizeof</span>(<span>int</span>), cudaMemcpyHostToDevice);
    <span>cudaMemcpy</span>(dev_b, b, N * <span>sizeof</span>(<span>int</span>), cudaMemcpyHostToDevice);
    <span><span>//</span> run kernel (vulkan shader module)</span>
    <span>const</span> <span>int</span> blocks = <span>128</span>;
    <span>const</span> <span>int</span> threads = <span>128</span>;
#<span>if</span> defined(__NVCC__)
    add&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(dev_a, dev_b, dev_c, N);
#<span>else</span>
    <span>const</span> <span>int</span> stream_id = <span>0</span>;
    <span>vuda::launchKernel</span>(<span><span>&#34;</span>add.spv<span>&#34;</span></span>, <span><span>&#34;</span>main<span>&#34;</span></span>, stream_id, blocks, threads, dev_a, dev_b, dev_c, N);
#<span>endif</span>
    <span><span>//</span> copy result to host</span>
    <span>cudaMemcpy</span>(c, dev_c, N * <span>sizeof</span>(<span>int</span>), cudaMemcpyDeviceToHost);

    <span><span>//</span> do something useful with the result in array c ...        </span>

    <span><span>//</span> free memory on device</span>
    <span>cudaFree</span>(dev_a);
    <span>cudaFree</span>(dev_b);
    <span>cudaFree</span>(dev_c);
}</pre></div>
</article>
          </div></div>
  </body>
</html>
