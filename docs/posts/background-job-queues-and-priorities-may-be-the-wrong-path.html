<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://alexis.bernard.io/blog/2023-10-15-background-job-queues-and-priorities-may-be-the-wrong-path.html">Original</a>
    <h1>Background job queues and priorities may be the wrong path</h1>
    
    <div id="readability-page-1" class="page"><div>
    <article>
      
      <p>
        <time datetime="2023-10-16">October 15, 2023</time>
      </p>

      <p>
        I got this idea after reading the <a href="https://island94.org/2023/10/reflections-on-good-job-for-solid-queue">Reflections on GoodJob for Solid Queue</a> from Ben Sheldon,
        who is the author of the excellent <a href="https://github.com/bensheldon/good_job">GoodJob</a>.
      </p>

      <p>
        I shared the same idea that purpose queues (mail, API, stats, …) were bad. I was convinced the best practice was to have job queues that define the priority, such as low, medium, and high.
        But after reading the following part, I completely changed my mind :
      </p>

      <blockquote>
        <strong>Queue design and multi-queue execution pools.</strong>
        I do think queue design is a place where lots of people do it wrong. I believe queues should be organized by maximum total latency SLO (latency_15s, latency_15m , latency_8h) and not by their purpose or dependencies (mailers, billing, api). Nate Berkopec believes similarly. And I think that informs that <strong>execution pools (e.g. thread pools) should be able to work from multiple queues and have independent concurrency configuration (e.g. number of threads)</strong>, both to ease transition from the latter to the former, but also because it allows sharing resources as optimally as possible (having 3 separate pools that pull from &#34;latency_15s&#34;, &#34;latency_15m, latency_15s&#34;, and &#34;latency_8h,*&#34; in GoodJob’s syntax). I personally think concepts like priority or ordered-queues lead to bad queue design, so I wouldn’t sweat that. Any ordering regime more complex than first-in-first-out (FIFO) prioritizes capacity (or lack thereof) over latency. This might sound strange coming from me who champions running workloads in the webbrowser on tiny dynos, but it’s different in my mind: I don’t think it’s possible to meet a latency target through prioritization when there is a fundamental lack of capacity.
      </blockquote>
    

      <p>
        Indeed, defining latency queues (latency_15s, latency_15m, latency_8h) is much better.
        Because if the high priority queue is always busy, others will never start.
        However, with the idea of SLO latency, we could totally get rid of queues.
      </p>

      <p>
        A job needs two attributes to define when it should be started: run_at and max_latency.
        That means the job worker only needs to order them by <code>run_at + max_latency</code>, and takes the first.
        It seems both flexible and simple.
      </p>

      <p>
        Here is an example to illustrate :
      </p>

      <pre><code code="">
        class ApplicationJob &lt; ActiveJob::Base
          max_latency 10.minutes # Arbitrary default value
        end

        class SendBoringEmailJob &lt; ApplicationJob
          max_latency 30.minutes # These jobs will be started in less that 30 minutes by default
        end

        class SendImportantEmailJob &lt; ApplicationJob
          max_latency 1.minute # These jobs will be started in less than a minute by default
        end

        # Of course, it should be possible to override default values
        # Job 1 will start between 10 and 15 minutes because it tolerates 5 minutes of latency
        SendBoringEmailJob.set(run_at: 10.minutes.from_now, max_latency: 5.minutes).perform_later

        # Job 2 will start in 11 minutes and does not tolerate latency
        SendBoringEmailJob.set(run_at: 11.minutes.from_now, max_latency: 0).perform_later

        # If workers are quiet, job1 will be run first in 10 minutes
        # If workers are busy, job2 will be run first in 11 minutes
        # If workers are too busy, both jobs will exceed their max latency.
        # The last case is a great indicator for either optimizing jobs or adding workers.
      </code></pre>

      <p>
        After having this revelation, I strongly believe that background jobs should neither have queues and priorities.
        Indeed, a maximum latency is enough to respect a <em>Service Level Objective</em>, which is much better.
        Job queues are from the past.
        Viva latency SLO!
      </p>

      <hr/>
      <p><a href="https://alexis.bernard.io/">Home</a></p>
    </article>
    </div></div>
  </body>
</html>
