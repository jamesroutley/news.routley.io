<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://apenwarr.ca/log/20170814">Original</a>
    <h1>Things we finally know about network queues (2017)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p><b>Things we (finally) know about network queues</b></p>
<p><img src="https://apenwarr.ca/log/queue-diagram.png"/></p>
<p>How big should your queue be, and what should you do when it fills up?  Many
times, we implement or even deploy a networking system before we have
answered those questions.  Luckily, recent research has given us some
guidelines.  Here&#39;s what we know:</p>
<ol>
<li>
<p>There are two ways to deal with a full queue: <strong>drop packets,</strong> or <strong>throttle
incoming packets (backpressure).</strong></p>
</li>
<li>
<p><strong>Most network queues are mostly empty.</strong>  The only exceptions are caused by
burstiness (uneven incoming packet rates), and bottlenecks (exactly one
slowest queue per network path).</p>
</li>
<li>
<p><strong>Queues exist only to handle burstiness.</strong>  If traffic flowed at a constant
rate, every queue would be empty except the bottleneck, which would be full
(bufferbloat), no matter its limit.</p>
<ul>
<li>Corollary: limit queue length to a statistically large burst (eg. 99th percentile).</li>
</ul>
</li>
<li>
<p><strong>Backpressure may be implicit.</strong>
For example, if an ethernet driver is slow to
pull packets from the Linux netdev queue <em>x</em> into the device&#39;s ring buffer
<em>y</em>, then there is implicit backpressure from <em>y</em> to <em>x</em> even though no
signal is sent to <em>x</em>.</p>
</li>
<li>
<p><strong>Dropping packets <em>should</em> be intentional.</strong>  An ethernet device will tail-drop
incoming packets if its (usually fixed-size) receive ring buffer is
exhausted, leaving software no control over what to drop.  To take control,
we could add a big software queue and unload the device&#39;s receive ring
buffer to it as quickly as possible.</p>
</li>
<li>
<p><strong>Burstiness can come from inside a router or switch.</strong> Examples: It&#39;s
more CPU-efficient to process 100 packets at a time instead of one.
<a href="https://en.wikipedia.org/wiki/Large_segment_offload">TSO/GSO</a>
are getting popular, and can produce, eg., bursts of 40+ packets from a
single 64k buffer.  (<a href="https://en.wikipedia.org/wiki/TCP_pacing">Pacing</a>
leaves time <em>between</em> 64k bursts.)
<a href="https://en.wikipedia.org/wiki/Frame_aggregation">Frame aggregation</a> does the same on wifi.  (Wifi nodes can negotiate reduced
aggregation sizes if their buffers are small.)</p>
</li>
<li>
<p><strong>Use backpressure when muxing.</strong>  In our diagram, from <em>i</em> to <em>x</em>,
it is best to use backpressure from <em>x</em> to <em>i</em> so that <em>i</em> can drop packets
from individual queues.</p>
<ul>
<li><strong>Prioritized handling of incoming packets is equivalent to muxing.</strong>
Multiple priority queues are drained by a single CPU, creating an implicit
single queue.  Draining them too slowly creates implicit backpressure.</li>
</ul>
</li>
<li>
<p><strong>Drop packets when demuxing.</strong>  From y to o, it&#39;s best to drop packets at o
rather than use backpressure from o to y.  Otherwise, a single full output
queue could starve the others by stopping y.  (Example: imagine if a full
queue to a 1 Mbps wifi station could stop traffic to a 100 Mbps wifi
station.  Some Linux wifi drivers suffer from this.)</p>
<ul>
<li><strong>Prioritizing outgoing packets is demuxing.</strong>  You must prioritize first, then
drop packets from the low-priority queues.  Prioritizing too slowly creates
backpressure on all packets, which would punish high priority packets.</li>
</ul>
</li>
<li>
<p><strong>Tail drop is worst drop.</strong>  There are several variants of AQM (active
queue management) with different tradeoffs, but almost all are better than
dropping the newest packet when a queue is full.  Even the opposite (&#34;head
drop&#34;) is better in many cases.  (Later TCP ACKs encompass all the
information from previous ACKs, so if you have to drop one, it might as well
be the oldest one.) <a href="https://en.wikipedia.org/wiki/CoDel">CoDel</a>
is a more refined AQM.  Most AQMs are the same speed or only slightly slower
than tail drop.</p>
</li>
<li>
<p><strong>Some queues are way too short,</strong> and you have to design around it.  For
example, consumer-grade ethernet switches might have only one or two packets
of queue space per port.  Burstiness must be artificially reduced in order
for these switches to protect traffic when busy.  This leads to inventions
like <a href="https://en.wikipedia.org/wiki/TCP_pacing">TCP pacing</a> and
<a href="https://cloudplatform.googleblog.com/2017/07/TCP-BBR-congestion-control-comes-to-GCP-your-Internet-just-got-faster.html">TCP BBR</a>.</p>
</li>
<li>
<p><strong><a href="https://en.wikipedia.org/wiki/Ethernet_flow_control">Ethernet &#34;pause&#34; frames</a> usually make things worse.</strong>  A
general-purpose ethernet switch looks like our diagram: a mux and a demux
chained together.  At the mux, you want backpressure on the individual
queues <em>i</em>.  At the demux, you want to drop packets when queues <em>o</em> get
full.  Unfortunately, the latter prevents the former; since <em>o</em> drops
packets, <em>x</em> and <em>y</em> are always empty, so there is no backpressure to apply
to <em>i</em>.  Unfortunately that&#39;s correct behaviour.  Imagine incoming port
<em>i<sub>1</sub></em> wants to send traffic alternately to ports <em>o<sub>1</sub></em>
and <em>o<sub>2</sub></em>.  It
would be wrong to pause <em>i<sub>1</sub></em> just because <em>o<sub>1</sub></em> is full,
because that will starve <em>o<sub>2</sub></em>.
There is no &#34;correct&#34; solution except adequate buffering (for
transients) on <em>o<sub>1</sub></em> and <em>o<sub>2</sub></em>.</p>
<ul>
<li>
<p><strong>&#34;Pause&#34; frames work when the bottleneck is <em>x</em> or <em>y</em> rather than <em>o</em>.</strong>
For example, we connected the input to a 400 Mbps MoCA chip to one output
port on our switch via gigabit <a href="https://en.wikipedia.org/wiki/Media-independent_interface">RGMII</a>.  The MoCA chip may be connected to
many other MoCA targets, but it is not a demux: all traffic goes out on the
shared MoCA bus, which acts like queue <em>y</em> in our diagram.  The MoCA chip
should apply backpressure so that better decisions can be made at <em>i</em>.</p>
<p>(However, it would be wrong to further propagate backpressure from
individual MoCA targets back to <em>y</em>.  The MoCA bus itself acts as an implicit
zero-queue demux o; individual targets will have to drop packets if they
can&#39;t handle them.)</p>
</li>
</ul>
</li>
<li>
<p><strong>&#34;Fair&#34; queueing is undefinable, but we have to try.</strong>
All of the above helps get you
to an optimal point where you eventually need to drop packets at <em>i</em> or <em>o</em>. 
Unfortunately, deciding which streams to drop is impossible in the general
case.  In the simple example of a server where <em>i<sub>1</sub></em> is very heavy
but <em>i<sub>2</sub></em> has
only a trickle of traffic, and queue space is exhausted, should you drop
traffic from <em>i<sub>1</sub></em>?
<a href="https://www.mcsweeneys.net/articles/lesser-known-trolley-problem-variations">What if</a> <em>i<sub>1</sub></em> has 100 users behind
a NAT but <em>i<sub>2</sub></em> has only one
user?  There is no answer that works in all situations.</p>
</li>
</ol>
<p>(Sorry this is so dense.  I challenged myself to make this into a &#34;two
pager&#34; that I could send to people at work.  But sometimes two pages is harder
to read than five pages...)</p>




</div></div>
  </body>
</html>
