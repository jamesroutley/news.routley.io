<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://openai.com/blog/introducing-chatgpt-and-whisper-apis">Original</a>
    <h1>Introducing ChatGPT and Whisper APIs</h1>
    
    <div id="readability-page-1" class="page"><div id="blog-details-introducing-chatgpt-and-whisper-apis"><!--[--><div><div><div><div><div><!--[--><div><div><p>Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.<br/></p></div><!----></div><div><div><p><img src="https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?fm=auto&amp;q=80&amp;auto=compress,format&amp;fit=min&amp;rect=,,,&amp;w=10&amp;h=10&amp;q=50" width="2048" height="2048" alt="Introducing ChatGPT And Whisper APIs" loading="eager" sizes="(max-width: 744px) 200vw, (max-width: 1280px) 200vw, (max-width: 1440px) 200vw, 200vw" srcset="https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?fm=auto&amp;q=80&amp;auto=compress,format&amp;fit=min&amp;rect=,,,&amp;w=1488&amp;h=1488 1488w, https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?fm=auto&amp;q=80&amp;auto=compress,format&amp;fit=min&amp;rect=,,,&amp;w=2560&amp;h=2560 2560w, https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?fm=auto&amp;q=80&amp;auto=compress,format&amp;fit=min&amp;rect=,,,&amp;w=2880&amp;h=2880 2880w, https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?fm=auto&amp;q=80&amp;auto=compress,format&amp;fit=min&amp;rect=,,,&amp;w=3840&amp;h=3840 3840w" aria-hidden="false"/></p><!----></div></div><!--]--></div></div></div></div></div><div id="content"><!--[--><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p>ChatGPT and Whisper models are now available on our API, giving developers access to cutting-edge language (not just chat!) and speech-to-text capabilities. Through a series of system-wide optimizations, we’ve achieved 90% cost reduction for ChatGPT since December; we’re now passing through those savings to API users. Developers can now use our open-source Whisper large-v2 model in the API with much faster and cost-effective results. ChatGPT API users can expect continuous model improvements and the option to choose dedicated capacity for deeper control over the models. We’ve also listened closely to feedback from our developers and refined our API terms of service to better meet their needs.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div id="early-users-of-chat-gpt-and-whisper-apis" data-heading=""><div><div><p><h2>Early users of ChatGPT and Whisper APIs</h2></p></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p><a href="https://snap.com/en-US" rel="noopener noreferrer" target="_blank"><strong>Snap Inc</strong></a>., the creator of Snapchat, introduced My AI for Snapchat+ this week. The experimental feature is running on ChatGPT API. My AI offers Snapchatters a friendly, customizable chatbot at their fingertips that offers recommendations, and can even write a haiku for friends in seconds. Snapchat, where communication and messaging is a daily behavior, has 750 million monthly Snapchatters.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p><a href="https://quizlet.com/labs/qchat" rel="noopener noreferrer" target="_blank"><strong>Quizlet</strong></a> is a global learning platform with more than 60 million students using it to study, practice and master whatever they’re learning. Quizlet has worked with OpenAI for the last three years, leveraging GPT-3 across multiple use cases, including vocabulary learning and practice tests. With the launch of ChatGPT API, Quizlet is introducing Q-Chat, a fully-adaptive AI tutor that engages students with adaptive questions based on relevant study materials delivered through a fun chat experience.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><p>Instacart’s Ask Instacart<br/></p></div><!----></div></div></div></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p><a href="https://www.instacart.com/" rel="noopener noreferrer" target="_blank"><strong>Instacart</strong></a> is augmenting the Instacart app to enable customers to ask about food and get inspirational, shoppable answers. This uses ChatGPT alongside Instacart’s own AI and product data from their 75,000+ retail partner store locations to help customers discover ideas for open-ended shopping goals, such as “How do I make great fish tacos?” or “What’s a healthy lunch for my kids?” Instacart plans to launch “Ask Instacart” later this year.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p><a href="https://shop.app/" rel="noopener noreferrer" target="_blank"><strong>Shop</strong></a>, Shopify’s consumer app, is used by 100 million shoppers to find and engage with the products and brands they love. ChatGPT API is used to power Shop’s new shopping assistant. When shoppers search for products, the shopping assistant makes personalized recommendations based on their requests. Shop’s new AI-powered shopping assistant will streamline in-app shopping by scanning millions of products to quickly find what buyers are looking for—or help them discover something new.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p><a href="https://www.speak.com/" rel="noopener noreferrer" target="_blank"><strong>Speak</strong></a> is an AI-powered language learning app focused on building the best path to spoken fluency. They’re the fastest-growing English app in South Korea, and are already using the Whisper API to power a new AI speaking companion product, and rapidly bring it to the rest of the globe. Whisper’s human-level accuracy for language learners of every level unlocks true open-ended conversational practice and highly accurate feedback.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><div><p><strong>Model</strong>: The ChatGPT model family we are releasing today, <code>gpt-3.5-turbo</code>, is the same model used in the ChatGPT product. It is priced at $0.002 per 1k tokens, which is 10x cheaper than our existing GPT-3.5 models. It’s also our best model for many non-chat use cases—we’ve seen early testers migrate from <code>text-davinci-003</code> to <code>gpt-3.5-turbo</code> with only a small amount of adjustment needed to their prompts.</p><p><span id="docs-internal-guid-13a30229-7fff-4e00-1fd6-a9ae9908ba47"><br/></span><strong>API</strong>: Traditionally, GPT models consume unstructured text, which is represented to the model as a sequence of “tokens.” ChatGPT models instead consume a sequence of messages together with metadata. (For the curious: under the hood, the input is still rendered to the model as a sequence of “tokens” for the model to consume; the raw format used by the model is a new format called <a href="https://github.com/openai/openai-python/blob/main/chatml.md" rel="noopener noreferrer" target="_blank">Chat Markup Language</a> (“ChatML”).)</p><p>We’ve created a new endpoint to interact with our ChatGPT models:<br/></p></div></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><div><div><div><!--[--><div><!--[--><div><pre><code>curl https://api.openai.com/v1/chat/completions
  -H &#34;Authorization: Bearer $OPENAI_API_KEY&#34;
  -H &#34;Content-Type: application/json&#34;
  -d &#39;{
  &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,
  &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What is the OpenAI mission?&#34;}]
}&#39;</code></pre></div><!--]--></div><!--]--></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><p>We are constantly improving our ChatGPT models, and want to make these enhancements available to developers as well. Developers who use the <code>gpt-3.5-turbo</code> model will always get our recommended stable model, while still having the flexibility to opt for a specific model version. For example, today we’re releasing <code>gpt-3.5-turbo-0301</code>, which will be supported through at least June 1st, and we’ll update <code>gpt-3.5-turbo</code> to a new stable release in April. The <a href="https://platform.openai.com/docs/models" rel="noopener noreferrer" target="_blank">models page</a> will provide switchover updates.<br/></p></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><div><p>We are also now offering dedicated instances for users who want deeper control over the specific model version and system performance. By default, requests are run on compute infrastructure shared with other users, who pay per request. Our API runs on Azure, and with dedicated instances, developers will pay by time period for an allocation of compute infrastructure that’s reserved for serving their requests.</p><p>Developers get full control over the instance’s load (higher load improves throughput but makes each request slower), the option to enable features such as longer context limits, and the ability to pin the model snapshot.</p><p>Dedicated instances can make economic sense for developers running beyond ~450M tokens per day. Additionally, it enables directly optimizing a developer’s workload against hardware performance, which can dramatically reduce costs relative to shared infrastructure. For dedicated instance inquiries, <a href="https://openai.com/contact-sales/" rel="noopener noreferrer" target="_blank">contact us</a>.<br/></p></div></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><div><p><a href="https://openai.com/blog/whisper/" rel="noopener noreferrer" target="_blank">Whisper</a>, the speech-to-text model we open-sourced in September 2022, has received immense praise from the developer community but can also be hard to run. We’ve now made the large-v2 model available through our API, which gives convenient on-demand access priced at $0.006 / minute. In addition, our highly-optimized serving stack ensures faster performance compared to other services.</p><p>Whisper API is available through our <code>transcriptions</code> (transcribes in source language) or <code>translations</code> (transcribes into English) endpoints, and accepts a variety of formats (m4a, mp3, mp4, mpeg, mpga, wav, webm):<br/></p></div></div></div></div></div></div><!----><!----><!----><!----></div><div><!----><!----><!----><!----><div><div><div><!--[--><div><!--[--><div><pre><code>curl https://api.openai.com/v1/audio/transcriptions \
  -H &#34;Authorization: Bearer $OPENAI_API_KEY&#34; \
  -H &#34;Content-Type: multipart/form-data&#34; \
  -F model=&#34;whisper-1&#34; \
  -F file=&#34;@/path/to/file/openai.mp3&#34;</code></pre></div><!--]--></div><!--]--></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div><div><div><div><div><div><p>Over the past six months, we’ve been collecting feedback from our API customers to understand how we can better serve them. We’ve made concrete changes, such as:<br/></p><ul><li>Data submitted through the API is no longer used for service improvements (including model training) unless the organization opts in</li><li>Implementing a default 30-day data retention policy for API users, with options for stricter retention depending on user needs.</li><li>Removing our pre-launch review (unlocked by improving our automated monitoring)</li><li>Improving developer documentation</li><li>Simplifying our <a href="https://platform.openai.com/docs/usage-policies" rel="noopener noreferrer" target="_blank">Terms of Service and Usage Policies</a>, including terms around data ownership: users own the input and output of the models.</li></ul><p>For the past two months our uptime has not met our own expectations nor that of our users. Our engineering team’s top priority is now stability of production use cases—we know that ensuring AI benefits all of humanity requires being a reliable service provider. Please hold us accountable for improved uptime over the upcoming months!</p><p>We believe that AI can provide incredible opportunities and economic empowerment to everyone, and the best way to achieve that is to allow everyone to build with it. We hope that the changes we announced today will lead to numerous applications that everyone can benefit from. Start building next-generation apps powered by ChatGPT &amp; Whisper.<br/></p></div></div></div></div></div></div><!----><!----><!----><!----></div><!--]--></div><!----><!----><div><div><div><p><h3 id="citationBody120Title">Acknowledgments</h3></p><div><div><!----><!--[--><div><h4>Contributors</h4><p>Jeff Belgum, Jake Berdine, Brooke Chan, Che Chang, Derek Chen, Ruby Chen, Thomas Degry, Steve Dowling, Sheila Dunning, Liam Fedus, Vik Goel, Jeff Harris, Angela Jiang, Denny Jin, Jong Wook Kim, Michael Lampe, Rachel Lim, Patricia Lue, Bianca Martin, Christine McLeavey, Luke Metz, Andrey Mishchenko, Vinnie Monaco, Evan Morikawa, Mira Murati, Rohan Nuttall, Ashley Pantuliano, Andrew Peng, Henrique Ponde de Oliveira Pinto, Alec Radford, Kendra Rimbach, Aliisa Rosenthal, Ted Sanders, Heather Schmidt, John Schulman, Zarina Stanik, Peter Welinder, Sherwin Wu, Tao Xu, Barret Zoph<br/></p></div><!----><!--]--></div></div></div></div></div><!----><!--]--><!----></div></div>
  </body>
</html>
