<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://maxhalford.github.io/blog/text-classification-zstd/">Original</a>
    <h1>Text classification with Python 3.14&#39;s ZSTD module</h1>
    
    <div id="readability-page-1" class="page"><div><p>Python 3.14 <a href="https://docs.python.org/3/whatsnew/3.14.html#whatsnew314-zstandard">introduced</a> the <a href="https://docs.python.org/3/library/compression.zstd.html"><code>compression.zstd</code></a> module. It is a standard library implementation of Facebook’s <a href="https://en.wikipedia.org/wiki/Zstd">Zstandard (Zstd)</a> compression algorithm. It was developed a decade ago by Yann Collet, who holds a <a href="https://fastcompression.blogspot.com/">blog</a> devoted to compression algorithms.</p><p>I am not a compression expert, but Zstd caught my eye because it supports incremental compression. You can feed it data to compress in chunks, and it will maintain an internal state. It’s particularly well <a href="https://facebook.github.io/zstd/">suited</a> for compressing small data. It’s perfect for the classify text via compression trick, which I described in <a href="https://maxhalford.github.io/blog/text-classification-by-compression/">a previous blog post</a> 5 years ago.</p><p>My previous blog post was based on a suggestion from <a href="https://www.goodreads.com/book/show/27543.Artificial_Intelligence">Artificial Intelligence: A Modern Approach</a>, and is rooted in the idea that compression length approximates <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogorov complexity</a>. There’s a 2023 paper called <a href="https://aclanthology.org/2023.findings-acl.426.pdf">“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors</a> that revisits this approach with encouraging results.</p><p>The problem with this approach is practical: popular compression algorithms like gzip and LZW don’t support incremental compression. They might algorithmically speaking, but in reality they don’t expose an incremental API. So you have to recompress the training data for each test document, which is very expensive. But Zstd does, which changes everything. The fact Python 3.14 added Zstd to its standard library got me excited.</p><p>Before delving into the machine learning part, I’ll provide a snippet to build some intuition. The main class we’re interested in is <a href="https://docs.python.org/3/library/compression.zstd.html#compression.zstd.ZstdCompressor"><code>ZstdCompressor</code></a>. It has a <code>compress</code> method that takes a chunk of data and returns the compressed output. The data it compresses is then added to its internal state. You can also provide a <code>ZstdDict</code> to the compressor, which is a pre-trained dictionary that gives it a head start.</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>&gt;&gt;&gt;</span> <span>from</span> <span>compression.zstd</span> <span>import</span> <span>ZstdCompressor</span><span>,</span> <span>ZstdDict</span>
</span></span><span><span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>tacos</span> <span>=</span> <span>b</span><span>&#34;taco burrito tortilla salsa guacamole cilantro lime &#34;</span> <span>*</span> <span>50</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>zd_tacos</span> <span>=</span> <span>ZstdDict</span><span>(</span><span>tacos</span><span>,</span> <span>is_raw</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>comp_tacos</span> <span>=</span> <span>ZstdCompressor</span><span>(</span><span>zstd_dict</span><span>=</span><span>zd_tacos</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>padel</span> <span>=</span> <span>b</span><span>&#34;racket court serve volley smash lob match game set &#34;</span> <span>*</span> <span>50</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>zd_padel</span> <span>=</span> <span>ZstdDict</span><span>(</span><span>padel</span><span>,</span> <span>is_raw</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>comp_padel</span> <span>=</span> <span>ZstdCompressor</span><span>(</span><span>zstd_dict</span><span>=</span><span>zd_padel</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>input_text</span> <span>=</span> <span>b</span><span>&#34;I ordered three tacos with extra guacamole&#34;</span>
</span></span><span><span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>len</span><span>(</span><span>comp_tacos</span><span>.</span><span>compress</span><span>(</span><span>input_text</span><span>,</span> <span>mode</span><span>=</span><span>ZstdCompressor</span><span>.</span><span>FLUSH_FRAME</span><span>))</span>
</span></span><span><span><span>43</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>len</span><span>(</span><span>comp_padel</span><span>.</span><span>compress</span><span>(</span><span>input_text</span><span>,</span> <span>mode</span><span>=</span><span>ZstdCompressor</span><span>.</span><span>FLUSH_FRAME</span><span>))</span>
</span></span><span><span><span>51</span>
</span></span></code></pre></div><p>The input text can be classified as “tacos” rather than “padel” because the compressor with the “tacos” dictionary produces a smaller compressed output. This can be turned into a simple classifier by building a compressor for each class, and then classifying a new document by finding the compressor that produces the smallest compressed output for that document.</p><p>Note that the <code>compress</code> method doesn’t only return the compressed output. It also updates the internal state of the compressor. From a machine learning perspective, this means it is corrupting each compressor with data that does not belong to its class. Unfortunately, and there is no public or private method to compress without updating the internal state.</p><p>The trick is to rebuild the compressor every time a new labelled document is received. Thankfully, instantiating a <code>ZstdCompressor</code> with a <code>ZstdDict</code> is very fast – tens of microseconds in my experiments. This makes it affordable to rebuild the compressor very frequently.</p><p>Here are the steps to take to turn this into a learning algorithm:</p><ol><li>For each class, maintain a buffer of text that belongs to that class.</li><li>When a new labelled document is received, append it to the buffer of its class.</li><li>Rebuild the compressor for that class with the updated buffer.</li><li>To classify a new document, find the compressor that produces the smallest compressed output for that document.</li></ol><p>There are several parameters that can be tuned to balance between throughput and correctness:</p><ul><li>Window size: the maximum number of bytes to keep in the buffer for each class. A smaller window means less data to compress, which means faster compressor rebuilding and compression. But it also means less data to learn from, which can hurt accuracy – or not depending on how much the data drifts.</li><li>Compression level: Zstd has 22 levels of compression, from 1 (fastest) to 22 (slowest). The higher the level, the better the compression ratio and thus the accuracy, but the slower the compression.</li><li>Rebuild frequency: how many new documents to receive for a class before rebuilding its compressor. Rebuilding the compressor is cheap but not free, so you don’t necessarily have to rebuild it for every sample. But if you don’t do it often enough, the compressor’s internal state will be too corrupted and not up to date, which can hurt accuracy.</li></ul><p>I picked some sane defaults for these parameters in the implementation below, but they can be tweaked to fit the use case. It’s always handy to have some knobs to turn. Anyway, here is the implementation of the <code>ZstdClassifier</code> class that implements the learning algorithm described above:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> <span>compression.zstd</span> <span>import</span> <span>ZstdCompressor</span><span>,</span> <span>ZstdDict</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>ZstdClassifier</span><span>:</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span>
</span></span><span><span>        <span>self</span><span>,</span>
</span></span><span><span>        <span>window</span><span>:</span> <span>int</span> <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>20</span><span>,</span>
</span></span><span><span>        <span>level</span><span>:</span> <span>int</span> <span>=</span> <span>3</span><span>,</span>
</span></span><span><span>        <span>rebuild_every</span><span>:</span> <span>int</span> <span>=</span> <span>5</span>
</span></span><span><span>    <span>):</span>
</span></span><span><span>        <span>self</span><span>.</span><span>window</span> <span>=</span> <span>window</span>
</span></span><span><span>        <span>self</span><span>.</span><span>level</span> <span>=</span> <span>level</span>
</span></span><span><span>        <span>self</span><span>.</span><span>rebuild_every</span> <span>=</span> <span>rebuild_every</span>
</span></span><span><span>        <span>self</span><span>.</span><span>buffers</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>bytes</span><span>]</span> <span>=</span> <span>{}</span>
</span></span><span><span>        <span>self</span><span>.</span><span>compressors</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>ZstdCompressor</span><span>]</span> <span>=</span> <span>{}</span>
</span></span><span><span>        <span>self</span><span>.</span><span>since_rebuild</span><span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]</span> <span>=</span> <span>{}</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>learn</span><span>(</span><span>self</span><span>,</span> <span>text</span><span>:</span> <span>bytes</span><span>,</span> <span>label</span><span>:</span> <span>str</span><span>):</span>
</span></span><span><span>
</span></span><span><span>        <span># Simply append the text to the buffer for</span>
</span></span><span><span>        <span># this label, and drop the oldest bytes if</span>
</span></span><span><span>        <span># the buffer is full.</span>
</span></span><span><span>        <span>buf</span> <span>=</span> <span>self</span><span>.</span><span>buffers</span><span>.</span><span>get</span><span>(</span><span>label</span><span>,</span> <span>b</span><span>&#34;&#34;</span><span>)</span> <span>+</span> <span>text</span>
</span></span><span><span>        <span>if</span> <span>len</span><span>(</span><span>buf</span><span>)</span> <span>&gt;</span> <span>self</span><span>.</span><span>window</span><span>:</span>
</span></span><span><span>            <span>buf</span> <span>=</span> <span>buf</span><span>[</span><span>-</span><span>self</span><span>.</span><span>window</span><span>:]</span>
</span></span><span><span>        <span>self</span><span>.</span><span>buffers</span><span>[</span><span>label</span><span>]</span> <span>=</span> <span>buf</span>
</span></span><span><span>
</span></span><span><span>        <span># Delete the compressor for this label, if we</span>
</span></span><span><span>        <span># have seen enough new data since the last</span>
</span></span><span><span>        <span># time the compressor was built.</span>
</span></span><span><span>        <span>n</span> <span>=</span> <span>self</span><span>.</span><span>since_rebuild</span><span>.</span><span>get</span><span>(</span><span>label</span><span>,</span> <span>0</span><span>)</span> <span>+</span> <span>1</span>
</span></span><span><span>        <span>if</span> <span>n</span> <span>&gt;=</span> <span>self</span><span>.</span><span>rebuild_every</span><span>:</span>
</span></span><span><span>            <span>self</span><span>.</span><span>compressors</span><span>.</span><span>pop</span><span>(</span><span>label</span><span>,</span> <span>None</span><span>)</span>
</span></span><span><span>            <span>self</span><span>.</span><span>since_rebuild</span><span>[</span><span>label</span><span>]</span> <span>=</span> <span>0</span>
</span></span><span><span>        <span>else</span><span>:</span>
</span></span><span><span>            <span>self</span><span>.</span><span>since_rebuild</span><span>[</span><span>label</span><span>]</span> <span>=</span> <span>n</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>classify</span><span>(</span><span>self</span><span>,</span> <span>text</span><span>:</span> <span>bytes</span><span>)</span> <span>-&gt;</span> <span>str</span> <span>|</span> <span>None</span><span>:</span>
</span></span><span><span>
</span></span><span><span>        <span># Can&#39;t classify if we don&#39;t have at</span>
</span></span><span><span>        <span># least two classes to compare.</span>
</span></span><span><span>        <span>if</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>buffers</span><span>)</span> <span>&lt;</span> <span>2</span><span>:</span>
</span></span><span><span>            <span>return</span> <span>None</span>
</span></span><span><span>
</span></span><span><span>        <span># (Re-)build compressors for all classes.</span>
</span></span><span><span>        <span>for</span> <span>label</span> <span>in</span> <span>self</span><span>.</span><span>buffers</span><span>:</span>
</span></span><span><span>            <span>if</span> <span>label</span> <span>in</span> <span>self</span><span>.</span><span>compressors</span><span>:</span>
</span></span><span><span>                <span>continue</span>
</span></span><span><span>            <span>self</span><span>.</span><span>compressors</span><span>[</span><span>label</span><span>]</span> <span>=</span> <span>ZstdCompressor</span><span>(</span>
</span></span><span><span>                <span>level</span><span>=</span><span>self</span><span>.</span><span>level</span><span>,</span>
</span></span><span><span>                <span>zstd_dict</span><span>=</span><span>ZstdDict</span><span>(</span>
</span></span><span><span>                    <span>self</span><span>.</span><span>buffers</span><span>[</span><span>label</span><span>],</span>
</span></span><span><span>                    <span>is_raw</span><span>=</span><span>True</span>
</span></span><span><span>                <span>)</span>
</span></span><span><span>            <span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># argmin: find the label whose compressor</span>
</span></span><span><span>        <span># produces the smallest compressed</span>
</span></span><span><span>        <span># size for the input text.</span>
</span></span><span><span>        <span>best_label</span> <span>=</span> <span>None</span>
</span></span><span><span>        <span>best_size</span> <span>=</span> <span>0x7FFFFFFF</span>
</span></span><span><span>        <span>mode</span> <span>=</span> <span>ZstdCompressor</span><span>.</span><span>FLUSH_FRAME</span>
</span></span><span><span>        <span>for</span> <span>label</span><span>,</span> <span>comp</span> <span>in</span> <span>self</span><span>.</span><span>compressors</span><span>.</span><span>items</span><span>():</span>
</span></span><span><span>            <span>size</span> <span>=</span> <span>len</span><span>(</span><span>comp</span><span>.</span><span>compress</span><span>(</span><span>text</span><span>,</span> <span>mode</span><span>))</span>
</span></span><span><span>            <span>if</span> <span>size</span> <span>&lt;</span> <span>best_size</span><span>:</span>
</span></span><span><span>                <span>best_size</span> <span>=</span> <span>size</span>
</span></span><span><span>                <span>best_label</span> <span>=</span> <span>label</span>
</span></span><span><span>        <span>return</span> <span>best_label</span>
</span></span></code></pre></div><p>I just love how simple this is. There are no matrices, no gradients, no backpropagation. All the learning is delegated to the compression algorithm. The <code>ZstdClassifier</code> class is just a thin wrapper around it that feeds it the right data and interprets its output.</p><p>Being simple is not enough. Does it learn? Is it accurate? How fast is it? I ran the benchmark script below on the <a href="https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset">20 newsgroups</a> dataset, similar to what I did in my <a href="https://maxhalford.github.io/blog/text-classification-by-compression/">previous blog post</a>.</p><details><summary>Benchmark script</summary><div><pre tabindex="0"><code data-lang="py"><span><span><span>import</span> <span>random</span>
</span></span><span><span><span>import</span> <span>time</span>
</span></span><span><span>
</span></span><span><span><span>from</span> <span>compression.zstd</span> <span>import</span> <span>ZstdCompressor</span><span>,</span> <span>ZstdDict</span>
</span></span><span><span><span>from</span> <span>sklearn.datasets</span> <span>import</span> <span>fetch_20newsgroups</span>
</span></span><span><span><span>from</span> <span>sklearn.metrics</span> <span>import</span> <span>classification_report</span>
</span></span><span><span>
</span></span><span><span><span>CATEGORIES</span> <span>=</span> <span>[</span><span>&#34;alt.atheism&#34;</span><span>,</span> <span>&#34;talk.religion.misc&#34;</span><span>,</span> <span>&#34;comp.graphics&#34;</span><span>,</span> <span>&#34;sci.space&#34;</span><span>]</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>load_docs</span><span>()</span> <span>-&gt;</span> <span>list</span><span>[</span><span>tuple</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]]:</span>
</span></span><span><span>    <span>data</span> <span>=</span> <span>fetch_20newsgroups</span><span>(</span><span>subset</span><span>=</span><span>&#34;all&#34;</span><span>,</span> <span>categories</span><span>=</span><span>CATEGORIES</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>[</span>
</span></span><span><span>        <span>(</span><span>text</span><span>,</span> <span>data</span><span>.</span><span>target_names</span><span>[</span><span>target</span><span>])</span>
</span></span><span><span>        <span>for</span> <span>text</span><span>,</span> <span>target</span> <span>in</span> <span>zip</span><span>(</span><span>data</span><span>.</span><span>data</span><span>,</span> <span>data</span><span>.</span><span>target</span><span>)</span>
</span></span><span><span>    <span>]</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span><span>():</span>
</span></span><span><span>    <span>docs</span> <span>=</span> <span>load_docs</span><span>()</span>
</span></span><span><span>    <span>random</span><span>.</span><span>seed</span><span>(</span><span>42</span><span>)</span>
</span></span><span><span>    <span>random</span><span>.</span><span>shuffle</span><span>(</span><span>docs</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>n</span> <span>=</span> <span>len</span><span>(</span><span>docs</span><span>)</span>
</span></span><span><span>    <span>classes</span> <span>=</span> <span>sorted</span><span>(</span><span>set</span><span>(</span><span>label</span> <span>for</span> <span>_</span><span>,</span> <span>label</span> <span>in</span> <span>docs</span><span>))</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>{</span><span>n</span><span>}</span><span> documents, </span><span>{</span><span>len</span><span>(</span><span>classes</span><span>)</span><span>}</span><span> classes</span><span>\n</span><span>&#34;</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>clf</span> <span>=</span> <span>ZstdClassifier</span><span>()</span>
</span></span><span><span>    <span>all_true</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>all_pred</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>correct</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>total</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>recent_correct</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>recent_total</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>t0</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
</span></span><span><span>    <span>lap</span> <span>=</span> <span>t0</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>i</span><span>,</span> <span>(</span><span>text</span><span>,</span> <span>label</span><span>)</span> <span>in</span> <span>enumerate</span><span>(</span><span>docs</span><span>):</span>
</span></span><span><span>        <span>text_bytes</span> <span>=</span> <span>text</span><span>.</span><span>encode</span><span>(</span><span>&#34;utf-8&#34;</span><span>,</span> <span>errors</span><span>=</span><span>&#34;replace&#34;</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>pred</span> <span>=</span> <span>clf</span><span>.</span><span>classify</span><span>(</span><span>text_bytes</span><span>)</span>
</span></span><span><span>        <span>if</span> <span>pred</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
</span></span><span><span>            <span>hit</span> <span>=</span> <span>pred</span> <span>==</span> <span>label</span>
</span></span><span><span>            <span>total</span> <span>+=</span> <span>1</span>
</span></span><span><span>            <span>correct</span> <span>+=</span> <span>hit</span>
</span></span><span><span>            <span>recent_total</span> <span>+=</span> <span>1</span>
</span></span><span><span>            <span>recent_correct</span> <span>+=</span> <span>hit</span>
</span></span><span><span>            <span>all_true</span><span>.</span><span>append</span><span>(</span><span>label</span><span>)</span>
</span></span><span><span>            <span>all_pred</span><span>.</span><span>append</span><span>(</span><span>pred</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>clf</span><span>.</span><span>learn</span><span>(</span><span>text_bytes</span><span>,</span> <span>label</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>if</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>%</span> <span>1000</span> <span>==</span> <span>0</span><span>:</span>
</span></span><span><span>            <span>now</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
</span></span><span><span>            <span>recent</span> <span>=</span> <span>recent_correct</span> <span>/</span> <span>recent_total</span> <span>if</span> <span>recent_total</span> <span>else</span> <span>0</span>
</span></span><span><span>            <span>print</span><span>(</span>
</span></span><span><span>                <span>f</span><span>&#34;  [</span><span>{</span><span>i</span> <span>+</span> <span>1</span><span>:</span><span>&gt;6</span><span>}</span><span>/</span><span>{</span><span>n</span><span>}</span><span>]&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  cumulative = </span><span>{</span><span>correct</span> <span>/</span> <span>total</span><span>:</span><span>.1%</span><span>}</span><span>&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  last 1k = </span><span>{</span><span>recent</span><span>:</span><span>.1%</span><span>}</span><span>&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  [</span><span>{</span><span>now</span> <span>-</span> <span>lap</span><span>:</span><span>.1f</span><span>}</span><span>s]&#34;</span>
</span></span><span><span>            <span>)</span>
</span></span><span><span>            <span>recent_correct</span> <span>=</span> <span>0</span>
</span></span><span><span>            <span>recent_total</span> <span>=</span> <span>0</span>
</span></span><span><span>            <span>lap</span> <span>=</span> <span>now</span>
</span></span><span><span>
</span></span><span><span>    <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>t0</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>\n</span><span>Final: </span><span>{</span><span>correct</span> <span>/</span> <span>total</span><span>:</span><span>.1%</span><span>}</span><span>  (</span><span>{</span><span>correct</span><span>}</span><span>/</span><span>{</span><span>total</span><span>}</span><span>)  [</span><span>{</span><span>elapsed</span><span>:</span><span>.1f</span><span>}</span><span>s]&#34;</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>\n</span><span>{</span><span>classification_report</span><span>(</span><span>all_true</span><span>,</span> <span>all_pred</span><span>,</span> <span>zero_division</span><span>=</span><span>0</span><span>)</span><span>}</span><span>&#34;</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span><span>:</span>
</span></span><span><span>    <span>main</span><span>()</span>
</span></span></code></pre></div></details><pre tabindex="0"><code>3387 documents, 4 classes

  [  1000/3387]  cumulative = 82.7%  last 1k = 82.7%  [0.3s]
  [  2000/3387]  cumulative = 88.4%  last 1k = 94.1%  [0.6s]
  [  3000/3387]  cumulative = 90.6%  last 1k = 95.0%  [0.7s]

Final: 91.0%  (3076/3382)  [1.9s]

                    precision    recall  f1-score   support

       alt.atheism       0.88      0.92      0.90       799
     comp.graphics       0.96      0.89      0.92       969
         sci.space       0.92      0.96      0.94       986
talk.religion.misc       0.87      0.85      0.86       628

          accuracy                           0.91      3382
         macro avg       0.91      0.90      0.90      3382
      weighted avg       0.91      0.91      0.91      3382
</code></pre><p>The results are good: it reaches 91% accuracy in less than 2 seconds. To put this into perspective, the LZW-based implementation I made 5 years ago reached 89% accuracy in about 32 minutes. So this is a significant improvement, both in terms of accuracy and speed.</p><p>To give another element of comparison, I ran a batch TF-IDF + logistic regression baseline on the same dataset. The model is retrained every 100 iterations, on all previously seen data for the given iteration.</p><details><summary>Batch TF-IDF + logistic regression comparison</summary><div><pre tabindex="0"><code data-lang="py"><span><span><span>import</span> <span>random</span>
</span></span><span><span><span>import</span> <span>time</span>
</span></span><span><span>
</span></span><span><span><span>from</span> <span>sklearn.datasets</span> <span>import</span> <span>fetch_20newsgroups</span>
</span></span><span><span><span>from</span> <span>sklearn.feature_extraction.text</span> <span>import</span> <span>TfidfVectorizer</span>
</span></span><span><span><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>LogisticRegression</span>
</span></span><span><span><span>from</span> <span>sklearn.metrics</span> <span>import</span> <span>classification_report</span>
</span></span><span><span><span>from</span> <span>sklearn.pipeline</span> <span>import</span> <span>make_pipeline</span>
</span></span><span><span>
</span></span><span><span><span>CATEGORIES</span> <span>=</span> <span>[</span><span>&#34;alt.atheism&#34;</span><span>,</span> <span>&#34;talk.religion.misc&#34;</span><span>,</span> <span>&#34;comp.graphics&#34;</span><span>,</span> <span>&#34;sci.space&#34;</span><span>]</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>load_docs</span><span>()</span> <span>-&gt;</span> <span>list</span><span>[</span><span>tuple</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]]:</span>
</span></span><span><span>    <span>data</span> <span>=</span> <span>fetch_20newsgroups</span><span>(</span><span>subset</span><span>=</span><span>&#34;all&#34;</span><span>,</span> <span>categories</span><span>=</span><span>CATEGORIES</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>[</span>
</span></span><span><span>        <span>(</span><span>text</span><span>,</span> <span>data</span><span>.</span><span>target_names</span><span>[</span><span>target</span><span>])</span>
</span></span><span><span>        <span>for</span> <span>text</span><span>,</span> <span>target</span> <span>in</span> <span>zip</span><span>(</span><span>data</span><span>.</span><span>data</span><span>,</span> <span>data</span><span>.</span><span>target</span><span>)</span>
</span></span><span><span>    <span>]</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span><span>():</span>
</span></span><span><span>    <span>docs</span> <span>=</span> <span>load_docs</span><span>()</span>
</span></span><span><span>    <span>random</span><span>.</span><span>seed</span><span>(</span><span>42</span><span>)</span>
</span></span><span><span>    <span>random</span><span>.</span><span>shuffle</span><span>(</span><span>docs</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>n</span> <span>=</span> <span>len</span><span>(</span><span>docs</span><span>)</span>
</span></span><span><span>    <span>classes</span> <span>=</span> <span>sorted</span><span>(</span><span>set</span><span>(</span><span>label</span> <span>for</span> <span>_</span><span>,</span> <span>label</span> <span>in</span> <span>docs</span><span>))</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>{</span><span>n</span><span>}</span><span> documents, </span><span>{</span><span>len</span><span>(</span><span>classes</span><span>)</span><span>}</span><span> classes</span><span>\n</span><span>&#34;</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>retrain_every</span> <span>=</span> <span>100</span>
</span></span><span><span>
</span></span><span><span>    <span>texts_seen</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>labels_seen</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>model</span> <span>=</span> <span>None</span>
</span></span><span><span>
</span></span><span><span>    <span>all_true</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>all_pred</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>correct</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>total</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>recent_correct</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>recent_total</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>t0</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
</span></span><span><span>    <span>lap</span> <span>=</span> <span>t0</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>i</span><span>,</span> <span>(</span><span>text</span><span>,</span> <span>label</span><span>)</span> <span>in</span> <span>enumerate</span><span>(</span><span>docs</span><span>):</span>
</span></span><span><span>        <span># Classify with current model (if one exists)</span>
</span></span><span><span>        <span>if</span> <span>model</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
</span></span><span><span>            <span>pred</span> <span>=</span> <span>model</span><span>.</span><span>predict</span><span>([</span><span>text</span><span>])[</span><span>0</span><span>]</span>
</span></span><span><span>            <span>hit</span> <span>=</span> <span>pred</span> <span>==</span> <span>label</span>
</span></span><span><span>            <span>total</span> <span>+=</span> <span>1</span>
</span></span><span><span>            <span>correct</span> <span>+=</span> <span>hit</span>
</span></span><span><span>            <span>recent_total</span> <span>+=</span> <span>1</span>
</span></span><span><span>            <span>recent_correct</span> <span>+=</span> <span>hit</span>
</span></span><span><span>            <span>all_true</span><span>.</span><span>append</span><span>(</span><span>label</span><span>)</span>
</span></span><span><span>            <span>all_pred</span><span>.</span><span>append</span><span>(</span><span>pred</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># Store example</span>
</span></span><span><span>        <span>texts_seen</span><span>.</span><span>append</span><span>(</span><span>text</span><span>)</span>
</span></span><span><span>        <span>labels_seen</span><span>.</span><span>append</span><span>(</span><span>label</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># Retrain periodically</span>
</span></span><span><span>        <span>if</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>%</span> <span>retrain_every</span> <span>==</span> <span>0</span> <span>and</span> <span>len</span><span>(</span><span>set</span><span>(</span><span>labels_seen</span><span>))</span> <span>&gt;=</span> <span>2</span><span>:</span>
</span></span><span><span>            <span>model</span> <span>=</span> <span>make_pipeline</span><span>(</span>
</span></span><span><span>                <span>TfidfVectorizer</span><span>(</span><span>max_features</span><span>=</span><span>50_000</span><span>,</span> <span>sublinear_tf</span><span>=</span><span>True</span><span>),</span>
</span></span><span><span>                <span>LogisticRegression</span><span>(</span><span>max_iter</span><span>=</span><span>1000</span><span>,</span> <span>solver</span><span>=</span><span>&#34;saga&#34;</span><span>),</span>
</span></span><span><span>            <span>)</span>
</span></span><span><span>            <span>model</span><span>.</span><span>fit</span><span>(</span><span>texts_seen</span><span>,</span> <span>labels_seen</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>if</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>%</span> <span>1000</span> <span>==</span> <span>0</span><span>:</span>
</span></span><span><span>            <span>now</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
</span></span><span><span>            <span>recent</span> <span>=</span> <span>recent_correct</span> <span>/</span> <span>recent_total</span> <span>if</span> <span>recent_total</span> <span>else</span> <span>0</span>
</span></span><span><span>            <span>print</span><span>(</span>
</span></span><span><span>                <span>f</span><span>&#34;  [</span><span>{</span><span>i</span> <span>+</span> <span>1</span><span>:</span><span>&gt;6</span><span>}</span><span>/</span><span>{</span><span>n</span><span>}</span><span>]&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  cumulative = </span><span>{</span><span>correct</span> <span>/</span> <span>total</span><span>:</span><span>.1%</span><span>}</span><span>&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  last 1k = </span><span>{</span><span>recent</span><span>:</span><span>.1%</span><span>}</span><span>&#34;</span>
</span></span><span><span>                <span>f</span><span>&#34;  [</span><span>{</span><span>now</span> <span>-</span> <span>lap</span><span>:</span><span>.1f</span><span>}</span><span>s]&#34;</span>
</span></span><span><span>            <span>)</span>
</span></span><span><span>            <span>recent_correct</span> <span>=</span> <span>0</span>
</span></span><span><span>            <span>recent_total</span> <span>=</span> <span>0</span>
</span></span><span><span>            <span>lap</span> <span>=</span> <span>now</span>
</span></span><span><span>
</span></span><span><span>    <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>t0</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>\n</span><span>Final: </span><span>{</span><span>correct</span> <span>/</span> <span>total</span><span>:</span><span>.1%</span><span>}</span><span>  (</span><span>{</span><span>correct</span><span>}</span><span>/</span><span>{</span><span>total</span><span>}</span><span>)  [</span><span>{</span><span>elapsed</span><span>:</span><span>.1f</span><span>}</span><span>s]&#34;</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>\n</span><span>{</span><span>classification_report</span><span>(</span><span>all_true</span><span>,</span> <span>all_pred</span><span>,</span> <span>zero_division</span><span>=</span><span>0</span><span>)</span><span>}</span><span>&#34;</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span><span>:</span>
</span></span><span><span>    <span>main</span><span>()</span>
</span></span></code></pre></div></details><pre tabindex="0"><code>3387 documents, 4 classes

  [  1000/3387]  cumulative = 86.6%  last 1k = 86.6%  [1.8s]
  [  2000/3387]  cumulative = 89.2%  last 1k = 91.6%  [3.5s]
  [  3000/3387]  cumulative = 91.2%  last 1k = 95.1%  [4.9s]

Final: 91.8%  (3017/3287)  [12.0s]

                    precision    recall  f1-score   support

       alt.atheism       0.87      0.93      0.90       775
     comp.graphics       0.94      0.97      0.95       948
         sci.space       0.93      0.96      0.95       958
talk.religion.misc       0.95      0.74      0.83       606

          accuracy                           0.92      3287
         macro avg       0.92      0.90      0.91      3287
      weighted avg       0.92      0.92      0.92      3287
</code></pre><p>As expected, the batch TF-IDF + logistic regression baseline is (slightly) more accurate than the Zstd-based classifier, but it’s also slower. What’s interesting is that this confirms the Zstd-based classifier is learning something non-trivial, and that it is competitive with a standard machine learning approach.</p><p>Anyway, don’t take my word for it. Try it yourself! I’m not sure I’d advise running this stuff in production, but it does have the merit of being easy to maintain and understand. Now that Zstd is in Python’s standard library, and given the decent throughput, it’s worth benchmarking against some text classification datasets you may have lying around.</p></div></div>
  </body>
</html>
