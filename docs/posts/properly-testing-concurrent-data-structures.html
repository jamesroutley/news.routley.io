<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://matklad.github.io/2024/07/05/properly-testing-concurrent-data-structures.html">Original</a>
    <h1>Properly testing concurrent data structures</h1>
    
    <div id="readability-page-1" class="page"><div>
  <article>


<p><span>There</span>’<span>s a fascinating Rust library, </span><a href="https://github.com/tokio-rs/loom"><span>loom</span></a><span>, which can be used to</span>
<span>thoroughly test lock-free data structures. I always wanted to learn how it works. I still do! But</span>
<span>recently I accidentally implemented a small toy which, I think, contains some of the loom</span>’<span>s ideas,</span>
<span>and it seems worthwhile to write about that. The goal here isn</span>’<span>t to teach you what you should be</span>
<span>using in practice (if you need that, go read loom</span>’<span>s docs), but rather to derive a couple of neat</span>
<span>ideas from first principles.</span></p>
<section id="One-Two-Three-Two">

    <h2>
    <a href="#One-Two-Three-Two"><span>One, Two, Three, Two</span> </a>
    </h2>
<p><span>As usual, we need the simplest possible model program to mess with. The example we use comes from</span>
<a href="https://stevana.github.io/the_sad_state_of_property-based_testing_libraries.html"><span>this excellent article</span></a><span>.</span>
<span>Behold, a humble (and broken) concurrent counter:</span></p>

<figure>


<pre><code><span><span>use</span> std::sync::atomic::{</span>
<span>  AtomicU32,</span>
<span>  Ordering::SeqCst,</span>
<span>};</span>
<span></span>
<span><span>#[derive(Default)]</span></span>
<span><span>pub</span> <span>struct</span> <span>Counter</span> {</span>
<span>  value: AtomicU32,</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>Counter</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>increment</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>value</span> = <span>self</span>.value.<span>load</span>(SeqCst);</span>
<span>    <span>self</span>.value.<span>store</span>(value + <span>1</span>, SeqCst);</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>get</span>(&amp;<span>self</span>) <span>-&gt;</span> <span>u32</span> {</span>
<span>    <span>self</span>.value.<span>load</span>(SeqCst)</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>The bug is obvious here </span>—<span> the increment is not atomic. But what is the best test we can write to</span>
<span>expose it?</span></p>
</section>
<section id="Trivial-Test">

    <h2>
    <a href="#Trivial-Test"><span>Trivial Test</span> </a>
    </h2>
<p><span>The simplest idea that comes to mind is to just hammer the same counter from multiple threads and</span>
<span>check the result at the end;</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>threaded_test</span>() {</span>
<span>  <span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span></span>
<span>  <span>let</span> <span>thread_count</span> = <span>100</span>;</span>
<span>  <span>let</span> <span>increment_count</span> = <span>100</span>;</span>
<span></span>
<span>  std::thread::<span>scope</span>(|scope| {</span>
<span>    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..thread_count {</span>
<span>      scope.<span>spawn</span>(|| {</span>
<span>        <span>for</span> <span>_</span> <span>in</span> <span>0</span>..increment_count {</span>
<span>          counter.<span>increment</span>()</span>
<span>        }</span>
<span>      });</span>
<span>    }</span>
<span>  });</span>
<span></span>
<span>  <span>assert_eq!</span>(counter.<span>get</span>(), thread_count * increment_count);</span>
<span>}</span></code></pre>

</figure>
<p><span>This fails successfully:</span></p>

<figure>


<pre><code><span>thread &#39;counter::trivial&#39; panicked:</span>
<span>assertion `left == right` failed</span>
<span>  left: 9598</span>
<span> right: 10000</span></code></pre>

</figure>
<p><span>But I wouldn</span>’<span>t call this test satisfactory </span>—<span> it very much depends on the timing, so you can</span>’<span>t</span>
<span>reproduce it deterministically and you can</span>’<span>t debug it. You also can</span>’<span>t minimize it </span>—<span> if you reduce</span>
<span>the number of threads and increments, chances are the test passes by luck!</span></p>
</section>
<section id="PBT">

    <h2>
    <a href="#PBT"><span>PBT</span> </a>
    </h2>
<p><span>Of course the temptation is to apply property based testing here! The problem </span><em><span>almost</span></em><span> fits: we have</span>
<span>easy-to-generate input (the sequence of increments spread over several threads), a good property to</span>
<span>check (result of concurrent increments is identical to that of sequential execution) and the desire</span>
<span>to minimize the test.</span></p>
<p><span>But just how can we plug threads into a property-based test?</span></p>
<p><span>PBTs are great for testing state machines. You can run your state machine through a series of steps</span>
<span>where at each step a PBT selects an arbitrary next action to apply to the state:</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>state_machine_test</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    </span>
<span>    <span>let</span> <span>mut </span><span>state</span>: <span>i32</span> = <span>0</span>;</span>
<span></span>
<span>    </span>
<span>    <span>let</span> <span>step_count</span>: <span>usize</span> = rng.<span>int_in_range</span>(<span>0</span>..=<span>100</span>)?;</span>
<span></span>
<span>    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..step_count {</span>
<span>      </span>
<span>      </span>
<span>      <span>match</span> *rng.<span>choose</span>(&amp;[<span>&#34;inc&#34;</span>, <span>&#34;dec&#34;</span>])? {</span>
<span>        <span>&#34;inc&#34;</span> =&gt; state += <span>1</span>,</span>
<span>        <span>&#34;dec&#34;</span> =&gt; state -= <span>1</span>,</span>
<span>        _ =&gt; <span>unreachable!</span>(),</span>
<span>      }</span>
<span>    }</span>
<span>    <span>Ok</span>(())</span>
<span>  });</span>
<span>}</span></code></pre>

</figure>
<p><span>And it </span><em><span>feels</span></em><span> like we should be able to apply the same technique here. At every iteration, pick a</span>
<span>random thread and make it do a single step. If you can step the threads manually, it should be easy</span>
<span>to maneuver one thread in between load&amp;store of a different thread.</span></p>
<p><span>But we can</span>’<span>t step through threads! Or can we?</span></p>
</section>
<section id="Simple-Instrumentation">

    <h2>
    <a href="#Simple-Instrumentation"><span>Simple Instrumentation</span> </a>
    </h2>
<p><span>Ok, let</span>’<span>s fake it until we make it! Let</span>’<span>s take a look at the buggy increment method:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>fn</span> <span>increment</span>(&amp;<span>self</span>) {</span>
<span>  <span>let</span> <span>value</span> = <span>self</span>.value.<span>load</span>(SeqCst);</span>
<span>  <span>self</span>.value.<span>store</span>(value + <span>1</span>, SeqCst);</span>
<span>}</span></code></pre>

</figure>
<p><span>Ideally, we</span>’<span>d love to be able to somehow </span>“<span>pause</span>”<span> the thread in-between atomic operations. Something</span>
<span>like this:</span></p>

<figure>


<pre><code><span><span>pub</span> <span>fn</span> <span>increment</span>(&amp;<span>self</span>) {</span>
<span>  <span>pause</span>();</span>
<span>  <span>let</span> <span>value</span> = <span>self</span>.value.<span>load</span>(SeqCst);</span>
<span>  <span>pause</span>();</span>
<span>  <span>self</span>.value.<span>store</span>(value + <span>1</span>, SeqCst);</span>
<span>  <span>pause</span>();</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>pause</span>() {</span>
<span>    </span>
<span>}</span></code></pre>

</figure>
<p><span>So let</span>’<span>s start with implementing our own wrapper for </span><code>AtomicU32</code><span> which includes calls to pause.</span></p>

<figure>


<pre><code><span><span>use</span> std::sync::atomic::Ordering;</span>
<span></span>
<span><span>struct</span> <span>AtomicU32</span> {</span>
<span>  inner: std::sync::atomic::AtomicU32,</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>AtomicU32</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>load</span>(&amp;<span>self</span>, ordering: Ordering) <span>-&gt;</span> <span>u32</span> {</span>
<span>    <span>pause</span>();</span>
<span>    <span>let</span> <span>result</span> = <span>self</span>.inner.<span>load</span>(ordering);</span>
<span>    <span>pause</span>();</span>
<span>    result</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>store</span>(&amp;<span>self</span>, value: <span>u32</span>, ordering: Ordering) {</span>
<span>    <span>pause</span>();</span>
<span>    <span>self</span>.inner.<span>store</span>(value, ordering);</span>
<span>    <span>pause</span>();</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>pause</span>() {</span>
<span>  </span>
<span>}</span></code></pre>

</figure>
</section>
<section id="Managed-Threads-API">

    <h2>
    <a href="#Managed-Threads-API"><span>Managed Threads API</span> </a>
    </h2>
<p><span>One rule of a great API design is that you start by implement a single </span><em><span>user</span></em><span> of an API, to</span>
<span>understand how the API should </span><em><span>feel</span></em><span>, and only then proceed to the actual implementation.</span></p>
<p><span>So, in the spirit of faking, let</span>’<span>s just write a PBT using these pausable, managed threads, even if</span>
<span>we still have no idea how to actually implement pausing.</span></p>
<p><span>We start with creating a counter and two managed threads. And we probably want to pass a reference</span>
<span>to the counter to each of the threads:</span></p>

<figure>


<pre><code><span><span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span><span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span><span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(&amp;counter);</span></code></pre>

</figure>
<p><span>Now, we want to step through the threads:</span></p>

<figure>


<pre><code><span><span>while</span> !rng.<span>is_empty</span>() {</span>
<span>  <span>let</span> <span>coin_flip</span>: <span>bool</span> = rng.<span>arbitrary</span>()?;</span>
<span>  <span>if</span> t1.<span>is_paused</span>() {</span>
<span>    <span>if</span> coin_flip {</span>
<span>      t1.<span>unpause</span>();</span>
<span>    }</span>
<span>  } <span>else</span> <span>if</span> t2.<span>is_paused</span>() {</span>
<span>    <span>if</span> coin_flip {</span>
<span>      t2.<span>unpause</span>();</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>Or, refactoring this a bit to semantically compress:</span></p>

<figure>


<pre><code><span><span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span><span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span><span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span><span>let</span> <span>threads</span> = [t1, t2];</span>
<span></span>
<span><span>while</span> !rng.<span>is_empty</span>() {</span>
<span>  <span>for</span> <span>t</span> <span>in</span> &amp;<span>mut</span> threads {</span>
<span>    <span>if</span> t.<span>is_paused</span>() &amp;&amp; rng.<span>arbitrary</span>()? {</span>
<span>      t.<span>unpause</span>()</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>That is, on each step of our state machine, we loop through all threads and unpause a random subset</span>
<span>of them.</span></p>
<p><span>But besides pausing and unpausing, we need our threads to actually </span><em><span>do</span></em><span> something, to increment the</span>
<span>counter. One idea is to mirror the </span><code>std::spawn</code><span> API and pass a closure in:</span></p>

<figure>


<pre><code><span><span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>({</span>
<span>  <span>let</span> <span>counter</span> = &amp;counter;</span>
<span>  <span>move</span> || {</span>
<span>    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..<span>100</span> {</span>
<span>      counter.<span>increment</span>();</span>
<span>    }</span>
<span>  }</span>
<span>});</span></code></pre>

</figure>
<p><span>But as these are managed threads, and we want to control them from our tests, lets actually go all</span>
<span>the way there and give the controlling thread an ability to change the code running in a managed</span>
<span>thread. That is, we</span>’<span>ll start managed threads without a </span>“<span>main</span>”<span> function, and provide an API to</span>
<span>execute arbitrary closures in the context of this by-default inert thread (</span><a href="https://joearms.github.io/published/2013-11-21-My-favorite-erlang-program.html"><span>universal</span>
<span>server</span></a><span> anyone?):</span></p>

<figure>


<pre><code><span><span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span></span>
<span></span>
<span><span>let</span> <span>t</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span></span>
<span></span>
<span>t.<span>submit</span>(|thread_state: &amp;Counter| thread_state.<span>increment</span>());</span>
<span>t.<span>submit</span>(|thread_state: &amp;Counter| thread_state.<span>increment</span>());</span></code></pre>

</figure>
<p><span>Putting everything together, we get a nice-looking property test:</span></p>

<figure>


<pre><code><span><span>#[cfg(test)]</span></span>
<span><span>use</span> managed_thread::AtomicU32;</span>
<span><span>#[cfg(not(test))]</span></span>
<span><span>use</span> std::sync::atomic::AtomicU32;</span>
<span></span>
<span><span>#[derive(Default)]</span></span>
<span><span>pub</span> <span>struct</span> <span>Counter</span> {</span>
<span>  value: AtomicU32,</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>Counter</span> {</span>
<span>  </span>
<span>}</span>
<span></span>
<span><span>#[test]</span></span>
<span><span>fn</span> <span>test_counter</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    </span>
<span>    <span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span></span>
<span>    </span>
<span>    <span>let</span> <span>counter_model</span>: <span>u32</span> = <span>0</span>;</span>
<span></span>
<span>    </span>
<span>    </span>
<span>    <span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span>    <span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(&amp;counter);</span>
<span>    <span>let</span> <span>threads</span> = [t1, t2];</span>
<span></span>
<span>    </span>
<span>    </span>
<span>    <span>while</span> !rng.<span>is_empty</span>() {</span>
<span>      <span>for</span> <span>t</span> <span>in</span> &amp;<span>mut</span> [t1, t2] {</span>
<span>        <span>if</span> rng.<span>arbitrary</span>() {</span>
<span>          <span>if</span> t.<span>is_paused</span>() {</span>
<span>            t.<span>unpause</span>()</span>
<span>          } <span>else</span> {</span>
<span>            </span>
<span>            </span>
<span>            t.<span>submit</span>(|c| c.<span>increment</span>());</span>
<span>            counter_model += <span>1</span>;</span>
<span>          }</span>
<span>        }</span>
<span>      }</span>
<span>    }</span>
<span></span>
<span>    <span>for</span> <span>t</span> <span>in</span> threads {</span>
<span>      t.<span>join</span>();</span>
<span>    }</span>
<span></span>
<span>    <span>assert_eq!</span>(counter_model, counter.<span>get</span>());</span>
<span></span>
<span>    <span>Ok</span>(())</span>
<span>  });</span>
<span>}</span></code></pre>

</figure>
<p><span>Now, if only we could make this API work</span>…<span> Remember, our </span><code>pause</code><span> implementation is a shrug emoji!</span></p>
<p><span>At this point, you might be mightily annoyed at me for this rhetorical device where I pretend that I</span>
<span>don</span>’<span>t know the answer. No need for annoyance </span>—<span> when writing this code for the first time, I traced</span>
<span>exactly these steps </span>—<span> I realized that I need a </span>“<span>pausing </span><code>AtomicU32</code>”<span> so I did that (with dummy</span>
<span>pause calls), then I played with the API I </span><em><span>wanted</span></em><span> to have, ending at roughly this spot, without</span>
<span>yet knowing how I would make it work or, indeed, if it is possible at all.</span></p>
<p><span>Well, if I am being honest, there is a bit of up-front knowledge here. I don</span>’<span>t think we can avoid</span>
<span>spawning real threads here, unless we do something really cursed with inline assembly. When</span>
<em><span>something</span></em><span> calls that </span><code>pause()</code><span> function, and we want it to stay paused until further notice, that</span>
<span>just has to happen in a thread which maintains a stack separate from the stack of our test. And, if</span>
<span>we are going to spawn threads, we might as well spawn scoped threads, so that we can freely borrow</span>
<span>stack-local data. And to spawn a scope thread, you need a</span>
<a href="https://doc.rust-lang.org/stable/std/thread/struct.Scope.html"><code>Scope</code></a><span> parameter. So in reality</span>
<span>we</span>’<span>ll need one more level of indentation here:</span></p>

<figure>


<pre><code><span>    std::thread::<span>scope</span>(|scope| {</span>
<span>      <span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span>      <span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span>      <span>let</span> <span>threads</span> = [t1, t2];</span>
<span>      <span>while</span> !rng.<span>is_empty</span>() {</span>
<span>        <span>for</span> <span>t</span> <span>in</span> &amp;<span>mut</span> [t1, t2] {</span>
<span>          </span>
<span>        }</span>
<span>      }</span>
<span>    });</span></code></pre>

</figure>
</section>
<section id="Managed-Threads-Implementation">

    <h2>
    <a href="#Managed-Threads-Implementation"><span>Managed Threads Implementation</span> </a>
    </h2>
<p><span>Now, the fun part: how the heck are we going to make pausing and unpausing work? For starters, there</span>
<span>clearly needs to be some communication between the main thread (</span><code>t.unpause()</code><span>) and the managed</span>
<span>thread (</span><code>pause()</code><span>). And, because we don</span>’<span>t want to change </span><code>Counter</code><span> API to thread some kind of</span>
<span>test-only context, the context needs to be smuggled. So </span><code>thread_local!</code><span> it is. And this context</span>
<span>is going to be shared between two threads, so it must be wrapped in an </span><code>Arc</code><span>.</span></p>

<figure>


<pre><code><span><span>struct</span> <span>SharedContext</span> {</span>
<span>  </span>
<span>}</span>
<span></span>
<span>thread_local! {</span>
<span>  <span>static</span> INSTANCE: RefCell&lt;<span>Option</span>&lt;Arc&lt;SharedContext&gt;&gt;&gt; =</span>
<span>    RefCell::<span>new</span>(<span>None</span>);</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>SharedContext</span> {</span>
<span>  <span>fn</span> <span>set</span>(ctx: Arc&lt;SharedContext&gt;) {</span>
<span>    INSTANCE.<span>with</span>(|it| *it.<span>borrow_mut</span>() = <span>Some</span>(ctx));</span>
<span>  }</span>
<span></span>
<span>  <span>fn</span> <span>get</span>() <span>-&gt;</span> <span>Option</span>&lt;Arc&lt;SharedContext&gt;&gt; {</span>
<span>    INSTANCE.<span>with</span>(|it| it.<span>borrow</span>().<span>clone</span>())</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>As usual when using </span><code>thread_local!</code><span> or </span><code>lazy_static!</code><span>, it is convenient to immediately wrap it into</span>
<span>better typed accessor functions. And, given that we are using an </span><code>Arc</code><span> here anyway, we can</span>
<span>conveniently escape </span><code>thread_local</code>’<span>s </span><code>with</code><span> by cloning the </span><code>Arc</code><span>.</span></p>
<p><span>So now we finally can implement the global </span><code>pause</code><span> function (or at least can kick the proverbial can</span>
<span>a little bit farther):</span></p>

<figure>


<pre><code><span><span>fn</span> <span>pause</span>() {</span>
<span>  <span>if</span> <span>let</span> <span>Some</span>(ctx) = SharedContext::<span>get</span>() {</span>
<span>    ctx.<span>pause</span>()</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>SharedContext</span> {</span>
<span>  <span>fn</span> <span>pause</span>(&amp;<span>self</span>) {</span>
<span>    </span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>Ok, what to do next? We somehow need to coordinate the control thread and the managed thread. And we</span>
<span>need some sort of notification mechanism, so that the managed thread knows when it can continue. The</span>
<span>most brute force solution here is a pair of a mutex protecting some state and a condition variable.</span>
<span>Mutex guards the state that can be manipulated by either of the threads. Condition variable can be</span>
<span>used to signal about the changes.</span></p>

<figure>


<pre><code><span><span>struct</span> <span>SharedContext</span> {</span>
<span>  state: Mutex&lt;State&gt;,</span>
<span>  cv: Condvar,</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>State</span> {</span>
<span>  </span>
<span>}</span></code></pre>

</figure>
<p><span>Okay, it looks like I am running out of emojies here. There</span>’<span>s no more layers of indirection or</span>
<span>infrastructure left, we need to write some real code that actually does do that pausing thing. So</span>
<span>let</span>’<span>s say that the state is tracking, well, the state of our managed thread, which can be either</span>
<span>running or paused:</span></p>

<figure>


<pre><code><span><span>#[derive(PartialEq, Eq, Default)]</span></span>
<span><span>enum</span> <span>State</span> {</span>
<span>  <span>#[default]</span></span>
<span>  Running,</span>
<span>  Paused,</span>
<span>}</span></code></pre>

</figure>
<p><span>And then the logic of the pause function </span>—<span> flip the state from </span><code>Running</code><span> to </span><code>Paused</code><span>, notify the</span>
<span>controlling thread that we are </span><code>Paused</code><span>, and wait until the controlling thread flips our state back</span>
<span>to </span><code>Running</code><span>:</span></p>

<figure>


<pre><code><span><span>impl</span> <span>SharedContext</span> {</span>
<span>  <span>fn</span> <span>pause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Running);</span>
<span>    *guard = State::Paused;</span>
<span>    <span>self</span>.cv.<span>notify_all</span>();</span>
<span>    <span>while</span> *guard == State::Paused {</span>
<span>      guard = <span>self</span>.cv.<span>wait</span>(guard).<span>unwrap</span>();</span>
<span>    }</span>
<span>    <span>assert_eq!</span>(*guard, State::Running);</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>Aside: Rust</span>’<span>s API for condition variables is beautiful. Condvars are tricky, and I didn</span>’<span>t really</span>
<span>understood them until seeing the signatures of Rust functions. Notice how the </span><code>wait</code><span> function</span>
<em><span>takes</span></em><span> a mutex guard as an argument, and returns a mutex guard. This protects you from the logical</span>
<span>races and guides you towards the standard pattern of using condvars:</span></p>
<p><span>First, you lock the mutex around the shared state. Then, you inspect whether the state is what you</span>
<span>need. If that</span>’<span>s the case, great, you do what you wanted to do and unlock the mutex. If not, then,</span>
<em><span>while still holding the mutex</span></em><span>, you </span><em><span>wait</span></em><span> on the condition variable. Which means that the</span>
<span>mutex gets unlocked, and other threads get the chance to change the shared state. When they do</span>
<span>change it, and notify the condvar, your thread wakes up, and it gets the locked mutex back (but the</span>
<span>state now is different). Due to the possibility of spurious wake-ups, you need to double check the</span>
<span>state and be ready to loop back again to waiting.</span></p>
<p><span>Naturally, there</span>’<span>s a helper that encapsulates this whole pattern:</span></p>

<figure>


<pre><code><span><span>impl</span> <span>SharedContext</span> {</span>
<span>  <span>fn</span> <span>pause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Running);</span>
<span>    *guard = State::Paused;</span>
<span>    <span>self</span>.cv.<span>notify_all</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Paused)</span>
<span>      .<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Running)</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>Ok, this actually does look like a reasonable implementation of </span><code>pause</code><span>. Let</span>’<span>s move on to</span>
<code>managed_thread::spawn</code><span>:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>spawn</span>&lt;<span>&#39;scope</span>, T: <span>&#39;scope</span> + <span>Send</span>&gt;(</span>
<span>  scope: &amp;Scope&lt;<span>&#39;scope</span>, <span>&#39;_</span>&gt;,</span>
<span>  state: T,</span>
<span>) {</span>
<span>  </span>
<span>}</span></code></pre>

</figure>
<p><span>There</span>’<span>s a bunch of stuff that needs to happen here:</span></p>
<ul>
<li>
<span>As we have established, we are going to spawn a (scoped) thread, so we need the </span><code>scope</code><span> parameter</span>
<span>with its three lifetimes. I don</span>’<span>t know how it works, so I am just going by the docs here!</span>
</li>
<li>
<span>We are going to return some kind of handle, which we can use to pause and unpause our managed</span>
<span>thread. And that handle is going to be parametrized over the same </span><code>&#39;scope</code><span> lifetime, because it</span>’<span>ll</span>
<span>hold onto the actual join handle.</span>
</li>
<li>
<span>We are going to pass the generic state to our new thread, and that state needs to be </span><code>Send</code><span>, and</span>
<span>bounded by the same lifetime as our scoped thread.</span>
</li>
<li>
<span>Inside, we are going to spawn a thread for sure, and we</span>’<span>ll need to setup the </span><code>INSTANCE</code><span> thread</span>
<span>local on that thread.</span>
</li>
<li>
<span>And it would actually be a good idea to stuff a reference to that </span><code>SharedContext</code><span> into the handle</span>
<span>we return.</span>
</li>
</ul>
<p><span>A bunch of stuff, in other words. Let</span>’<span>s do it:</span></p>

<figure>


<pre><code><span><span>struct</span> <span>ManagedHandle</span>&lt;<span>&#39;scope</span>&gt; {</span>
<span>  inner: std::thread::ScopedJoinHandle&lt;<span>&#39;scope</span>, ()&gt;,</span>
<span>  ctx: Arc&lt;SharedContext&gt;,</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>spawn</span>&lt;<span>&#39;scope</span>, T: <span>&#39;scope</span> + <span>Send</span>&gt;(</span>
<span>  scope: &amp;<span>&#39;scope</span> Scope&lt;<span>&#39;scope</span>, <span>&#39;_</span>&gt;,</span>
<span>  state: T,</span>
<span>) <span>-&gt;</span> ManagedHandle&lt;<span>&#39;scope</span>&gt; {</span>
<span>  <span>let</span> <span>ctx</span>: Arc&lt;SharedContext&gt; = <span>Default</span>::<span>default</span>();</span>
<span>  <span>let</span> <span>inner</span> = scope.<span>spawn</span>({</span>
<span>    <span>let</span> <span>ctx</span> = Arc::<span>clone</span>(&amp;ctx);</span>
<span>    <span>move</span> || {</span>
<span>      SharedContext::<span>set</span>(ctx);</span>
<span>      <span>drop</span>(state); </span>
<span>    }</span>
<span>  });</span>
<span>  ManagedHandle { inner, ctx }</span>
<span>}</span></code></pre>

</figure>
<p><span>The essentially no-op function we spawn looks sus. We</span>’<span>ll fix later! Let</span>’<span>s try to implement</span>
<code>is_paused</code><span> and </span><code>unpause</code><span> first! They should be relatively straightforward. For </span><code>is_paused</code><span>, we just</span>
<span>need to lock the mutex and check the state:</span></p>

<figure>


<pre><code><span><span>impl</span> <span>ManagedHandle</span>&lt;<span>&#39;_</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>is_paused</span>(&amp;<span>self</span>,) <span>-&gt;</span> <span>bool</span> {</span>
<span>    <span>let</span> <span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    *guard == State::Paused</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>For </span><code>unpause</code><span>, we should additionally flip the state back to </span><code>Running</code><span> and notify the other thread:</span></p>

<figure>


<pre><code><span><span>impl</span> <span>ManagedHandle</span>&lt;<span>&#39;_</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>unpause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Paused);</span>
<span>    *guard = State::Running;</span>
<span>    <span>self</span>.ctx.cv.<span>notify_all</span>();</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>But I think that</span>’<span>s not quiet correct. Can you see why?</span></p>
<p><span>With this implementation, after </span><code>unpause</code><span>, the controlling and the managed threads will be running</span>
<span>concurrently. And that can lead to non-determinism, the very problem we are trying to avoid here! In</span>
<span>particular, if you call </span><code>is_paused</code><span> </span><em><span>right</span></em><span> after you </span><code>unpause</code><span> the thread, you</span>’<span>ll most likely get</span>
<code>false</code><span> back, as the other thread will still be running. But it might also hit the </span><em><span>next</span></em><span> </span><code>pause</code>
<span>call, so, depending on timing, you might also get </span><code>true</code><span>.</span></p>
<p><span>What we want is actually completely eliminating all unmanaged concurrency. That means that at any</span>
<span>given point in time, only one thread (controlling or managed) should be running. So the right</span>
<span>semantics for </span><code>unpause</code><span> is to unblock the managed thread, and then block the controlling thread</span>
<span>until the managed one hits the next pause!</span></p>

<figure>


<pre><code><span><span>impl</span> <span>ManagedHandle</span>&lt;<span>&#39;_</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>unpause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Paused);</span>
<span>    *guard = State::Running;</span>
<span>    <span>self</span>.ctx.cv.<span>notify_all</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .ctx</span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Running)</span>
<span>      .<span>unwrap</span>();</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>At this point we can spawn a managed thread, pause it and resume. But right now it doesn</span>’<span>t do</span>
<span>anything. Next step is implementing that idea where the controlling thread can directly send an</span>
<span>arbitrary closure to the managed one to make it do something:</span></p>

<figure>


<pre><code><span><span>impl</span>&lt;<span>&#39;scope</span>&gt; ManagedHandle&lt;<span>&#39;scope</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>submit</span>&lt;F: FnSomething&gt;(&amp;<span>self</span>, f: F)</span>
<span>}</span></code></pre>

</figure>
<p><span>Let</span>’<span>s figure this </span><code>FnSomething</code><span> bound! We are going to yeet this </span><code>f</code><span> over to the managed thread and</span>
<span>run it there once, so it is </span><code>FnOnce</code><span>. It is crossing thread-boundary, so it needs to be </span><code>+ Send</code><span>.</span>
<span>And, because we are using scoped threads, it </span><em><span>doesn</span>’<span>t</span></em><span> have to be </span><code>&#39;static</code><span>, just </span><code>&#39;scope</code><span> is</span>
<span>enough. Moreover, in that managed thread the </span><code>f</code><span> will have exclusive access to thread</span>’<span>s state, </span><code>T</code><span>.</span>
<span>So we have:</span></p>

<figure>


<pre><code><span><span>impl</span>&lt;<span>&#39;scope</span>&gt; ManagedHandle&lt;<span>&#39;scope</span>&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>submit</span>&lt;F: <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>Send</span> + <span>&#39;scope</span>&gt;(<span>self</span>, f: F)</span>
<span>}</span></code></pre>

</figure>
<p><span>Implementing this is a bit tricky. First, we</span>’<span>ll need some sort of the channel to actually move the</span>
<span>function. Then, similarly to the </span><code>unpause</code><span> logic, we</span>’<span>ll need synchronization to make sure that the</span>
<span>control thread doesn</span>’<span>t resume until the managed thread starts running </span><code>f</code><span> and hits a pause (or maybe</span>
<span>completes </span><code>f</code><span>). And we</span>’<span>ll also need a new state, </span><code>Ready</code><span>, because now there are two different</span>
<span>reasons why a managed thread might be blocked </span>—<span> it might wait for an </span><code>unpause</code><span> event, or it might</span>
<span>wait for the next </span><code>f</code><span> to execute. This is the new code:</span></p>

<figure>


<pre><code><span><span>#[derive(Default)]</span></span>
<span><span>enum</span> <span>State</span> {</span>
<span>  <span>#[default]</span></span>
<span>  Ready,</span>
<span>  Running,</span>
<span>  Paused,</span>
<span>}</span>
<span></span>
<span><span>struct</span> <span>ManagedHandle</span>&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  inner: std::thread::ScopedJoinHandle&lt;<span>&#39;scope</span>, ()&gt;,</span>
<span>  ctx: Arc&lt;SharedContext&gt;,</span>
<span>  sender: mpsc::Sender&lt;<span>Box</span>&lt;<span>dyn</span> <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>&#39;scope</span> + <span>Send</span>&gt;&gt;,</span>
<span>}</span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>spawn</span>&lt;<span>&#39;scope</span>, T: <span>&#39;scope</span> + <span>Send</span>&gt;(</span>
<span>  scope: &amp;<span>&#39;scope</span> Scope&lt;<span>&#39;scope</span>, <span>&#39;_</span>&gt;,</span>
<span>  <span>mut</span> state: T,</span>
<span>) <span>-&gt;</span> ManagedHandle&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  <span>let</span> <span>ctx</span>: Arc&lt;SharedContext&gt; = <span>Default</span>::<span>default</span>();</span>
<span>  <span>let</span> (sender, receiver) =</span>
<span>    mpsc::channel::&lt;<span>Box</span>&lt;<span>dyn</span> <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>&#39;scope</span> + <span>Send</span>&gt;&gt;();</span>
<span>  <span>let</span> <span>inner</span> = scope.<span>spawn</span>({</span>
<span>    <span>let</span> <span>ctx</span> = Arc::<span>clone</span>(&amp;ctx);</span>
<span>    <span>move</span> || {</span>
<span>      SharedContext::<span>set</span>(Arc::<span>clone</span>(&amp;ctx));</span>
<span></span>
<span>      <span>for</span> <span>f</span> <span>in</span> receiver {</span>
<span>        <span>f</span>(&amp;<span>mut</span> state);</span>
<span></span>
<span>        <span>let</span> <span>mut </span><span>guard</span> = ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>        <span>assert_eq!</span>(*guard, State::Running);</span>
<span>        *guard = State::Ready;</span>
<span>        ctx.cv.<span>notify_all</span>()</span>
<span>      }</span>
<span>    }</span>
<span>  });</span>
<span>  ManagedHandle { inner, ctx, sender }</span>
<span>}</span>
<span></span>
<span><span>impl</span>&lt;<span>&#39;scope</span>, T&gt; ManagedHandle&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>submit</span>&lt;F: <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>Send</span> + <span>&#39;scope</span>&gt;(&amp;<span>self</span>, f: F) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Ready);</span>
<span>    *guard = State::Running;</span>
<span>    <span>self</span>.sender.<span>send</span>(<span>Box</span>::<span>new</span>(f)).<span>unwrap</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .ctx</span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Running)</span>
<span>      .<span>unwrap</span>();</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>The last small piece of the puzzle is the </span><code>join</code><span> function. It</span>’<span>s </span><em><span>almost</span></em><span> standard! First we close</span>
<span>our side of the channel. This serves as a natural stop signal for the other thread, so it exits.</span>
<span>Which in turn allows us to join it. The small wrinkle here is that the thread might be paused when</span>
<span>we try to join it, so we need to unpause it beforehand:</span></p>

<figure>


<pre><code><span><span>impl</span>&lt;<span>&#39;scope</span>, T&gt; ManagedHandle&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>join</span>(<span>self</span>) {</span>
<span>    <span>while</span> <span>self</span>.<span>is_paused</span>() {</span>
<span>      <span>self</span>.<span>unpause</span>();</span>
<span>    }</span>
<span>    <span>drop</span>(<span>self</span>.sender);</span>
<span>    <span>self</span>.inner.<span>join</span>().<span>unwrap</span>();</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>That</span>’<span>s it! Let</span>’<span>s put everything together!</span></p>
<p><span>Helper library, </span><code>managed_thread.rs</code><span>:</span></p>

<figure>


<pre><code><span><span>use</span> std::{</span>
<span>  cell::RefCell,</span>
<span>  sync::{atomic::Ordering, mpsc, Arc, Condvar, Mutex},</span>
<span>  thread::Scope,</span>
<span>};</span>
<span></span>
<span><span>#[derive(Default)]</span></span>
<span><span>pub</span> <span>struct</span> <span>AtomicU32</span> {</span>
<span>  inner: std::sync::atomic::AtomicU32,</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>AtomicU32</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>load</span>(&amp;<span>self</span>, ordering: Ordering) <span>-&gt;</span> <span>u32</span> {</span>
<span>    <span>pause</span>();</span>
<span>    <span>let</span> <span>result</span> = <span>self</span>.inner.<span>load</span>(ordering);</span>
<span>    <span>pause</span>();</span>
<span>    result</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>store</span>(&amp;<span>self</span>, value: <span>u32</span>, ordering: Ordering) {</span>
<span>    <span>pause</span>();</span>
<span>    <span>self</span>.inner.<span>store</span>(value, ordering);</span>
<span>    <span>pause</span>();</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>fn</span> <span>pause</span>() {</span>
<span>  <span>if</span> <span>let</span> <span>Some</span>(ctx) = SharedContext::<span>get</span>() {</span>
<span>    ctx.<span>pause</span>()</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>#[derive(Default)]</span></span>
<span><span>struct</span> <span>SharedContext</span> {</span>
<span>  state: Mutex&lt;State&gt;,</span>
<span>  cv: Condvar,</span>
<span>}</span>
<span></span>
<span><span>#[derive(Default, PartialEq, Eq, Debug)]</span></span>
<span><span>enum</span> <span>State</span> {</span>
<span>  <span>#[default]</span></span>
<span>  Ready,</span>
<span>  Running,</span>
<span>  Paused,</span>
<span>}</span>
<span></span>
<span>thread_local! {</span>
<span>  <span>static</span> INSTANCE: RefCell&lt;<span>Option</span>&lt;Arc&lt;SharedContext&gt;&gt;&gt; =</span>
<span>    RefCell::<span>new</span>(<span>None</span>);</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>SharedContext</span> {</span>
<span>  <span>fn</span> <span>set</span>(ctx: Arc&lt;SharedContext&gt;) {</span>
<span>    INSTANCE.<span>with</span>(|it| *it.<span>borrow_mut</span>() = <span>Some</span>(ctx));</span>
<span>  }</span>
<span></span>
<span>  <span>fn</span> <span>get</span>() <span>-&gt;</span> <span>Option</span>&lt;Arc&lt;SharedContext&gt;&gt; {</span>
<span>    INSTANCE.<span>with</span>(|it| it.<span>borrow</span>().<span>clone</span>())</span>
<span>  }</span>
<span></span>
<span>  <span>fn</span> <span>pause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Running);</span>
<span>    *guard = State::Paused;</span>
<span>    <span>self</span>.cv.<span>notify_all</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Paused)</span>
<span>      .<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Running)</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>pub</span> <span>struct</span> <span>ManagedHandle</span>&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  inner: std::thread::ScopedJoinHandle&lt;<span>&#39;scope</span>, ()&gt;,</span>
<span>  sender: mpsc::Sender&lt;<span>Box</span>&lt;<span>dyn</span> <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>&#39;scope</span> + <span>Send</span>&gt;&gt;,</span>
<span>  ctx: Arc&lt;SharedContext&gt;,</span>
<span>}</span>
<span></span>
<span><span>pub</span> <span>fn</span> <span>spawn</span>&lt;<span>&#39;scope</span>, T: <span>&#39;scope</span> + <span>Send</span>&gt;(</span>
<span>  scope: &amp;<span>&#39;scope</span> Scope&lt;<span>&#39;scope</span>, <span>&#39;_</span>&gt;,</span>
<span>  <span>mut</span> state: T,</span>
<span>) <span>-&gt;</span> ManagedHandle&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  <span>let</span> <span>ctx</span>: Arc&lt;SharedContext&gt; = <span>Default</span>::<span>default</span>();</span>
<span>  <span>let</span> (sender, receiver) =</span>
<span>    mpsc::channel::&lt;<span>Box</span>&lt;<span>dyn</span> <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>&#39;scope</span> + <span>Send</span>&gt;&gt;();</span>
<span>  <span>let</span> <span>inner</span> = scope.<span>spawn</span>({</span>
<span>    <span>let</span> <span>ctx</span> = Arc::<span>clone</span>(&amp;ctx);</span>
<span>    <span>move</span> || {</span>
<span>      SharedContext::<span>set</span>(Arc::<span>clone</span>(&amp;ctx));</span>
<span>      <span>for</span> <span>f</span> <span>in</span> receiver {</span>
<span>        <span>f</span>(&amp;<span>mut</span> state);</span>
<span>        <span>let</span> <span>mut </span><span>guard</span> = ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>        <span>assert_eq!</span>(*guard, State::Running);</span>
<span>        *guard = State::Ready;</span>
<span>        ctx.cv.<span>notify_all</span>()</span>
<span>      }</span>
<span>    }</span>
<span>  });</span>
<span>  ManagedHandle { inner, ctx, sender }</span>
<span>}</span>
<span></span>
<span><span>impl</span>&lt;<span>&#39;scope</span>, T&gt; ManagedHandle&lt;<span>&#39;scope</span>, T&gt; {</span>
<span>  <span>pub</span> <span>fn</span> <span>is_paused</span>(&amp;<span>self</span>) <span>-&gt;</span> <span>bool</span> {</span>
<span>    <span>let</span> <span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    *guard == State::Paused</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>unpause</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Paused);</span>
<span>    *guard = State::Running;</span>
<span>    <span>self</span>.ctx.cv.<span>notify_all</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .ctx</span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Running)</span>
<span>      .<span>unwrap</span>();</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>submit</span>&lt;F: <span>FnOnce</span>(&amp;<span>mut</span> T) + <span>Send</span> + <span>&#39;scope</span>&gt;(&amp;<span>self</span>, f: F) {</span>
<span>    <span>let</span> <span>mut </span><span>guard</span> = <span>self</span>.ctx.state.<span>lock</span>().<span>unwrap</span>();</span>
<span>    <span>assert_eq!</span>(*guard, State::Ready);</span>
<span>    *guard = State::Running;</span>
<span>    <span>self</span>.sender.<span>send</span>(<span>Box</span>::<span>new</span>(f)).<span>unwrap</span>();</span>
<span>    guard = <span>self</span></span>
<span>      .ctx</span>
<span>      .cv</span>
<span>      .<span>wait_while</span>(guard, |state| *state == State::Running)</span>
<span>      .<span>unwrap</span>();</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>join</span>(<span>self</span>) {</span>
<span>    <span>while</span> <span>self</span>.<span>is_paused</span>() {</span>
<span>      <span>self</span>.<span>unpause</span>();</span>
<span>    }</span>
<span>    <span>drop</span>(<span>self</span>.sender);</span>
<span>    <span>self</span>.inner.<span>join</span>().<span>unwrap</span>();</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>System under test, not-exactly-atomic counter:</span></p>

<figure>


<pre><code><span><span>use</span> std::sync::atomic::Ordering::SeqCst;</span>
<span></span>
<span><span>#[cfg(test)]</span></span>
<span><span>use</span> managed_thread::AtomicU32;</span>
<span><span>#[cfg(not(test))]</span></span>
<span><span>use</span> std::sync::atomic::AtomicU32;</span>
<span></span>
<span><span>#[derive(Default)]</span></span>
<span><span>pub</span> <span>struct</span> <span>Counter</span> {</span>
<span>  value: AtomicU32,</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>Counter</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>increment</span>(&amp;<span>self</span>) {</span>
<span>    <span>let</span> <span>value</span> = <span>self</span>.value.<span>load</span>(SeqCst);</span>
<span>    <span>self</span>.value.<span>store</span>(value + <span>1</span>, SeqCst);</span>
<span>  }</span>
<span></span>
<span>  <span>pub</span> <span>fn</span> <span>get</span>(&amp;<span>self</span>) <span>-&gt;</span> <span>u32</span> {</span>
<span>    <span>self</span>.value.<span>load</span>(SeqCst)</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>And the test itself:</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>test_counter</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    eprintln!(<span>&#34;begin trace&#34;</span>);</span>
<span>    <span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span>    <span>let</span> <span>mut </span><span>counter_model</span>: <span>u32</span> = <span>0</span>;</span>
<span></span>
<span>    std::thread::<span>scope</span>(|scope| {</span>
<span>      <span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span>      <span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span>      <span>let</span> <span>mut </span><span>threads</span> = [t1, t2];</span>
<span></span>
<span>      <span>while</span> !rng.<span>is_empty</span>() {</span>
<span>        <span>for</span> (tid, t) <span>in</span> threads.<span>iter_mut</span>().<span>enumerate</span>() {</span>
<span>          <span>if</span> rng.<span>arbitrary</span>()? {</span>
<span>            <span>if</span> t.<span>is_paused</span>() {</span>
<span>              eprintln!(<span>&#34;{tid}: unpause&#34;</span>);</span>
<span>              t.<span>unpause</span>()</span>
<span>            } <span>else</span> {</span>
<span>              eprintln!(<span>&#34;{tid}: increment&#34;</span>);</span>
<span>              t.<span>submit</span>(|c| c.<span>increment</span>());</span>
<span>              counter_model += <span>1</span>;</span>
<span>            }</span>
<span>          }</span>
<span>        }</span>
<span>      }</span>
<span></span>
<span>      <span>for</span> <span>t</span> <span>in</span> threads {</span>
<span>        t.<span>join</span>();</span>
<span>      }</span>
<span>      <span>assert_eq!</span>(counter_model, counter.<span>get</span>());</span>
<span></span>
<span>      <span>Ok</span>(())</span>
<span>    })</span>
<span>  });</span>
<span>}</span></code></pre>

</figure>
<p><span>Running it identifies a failure:</span></p>

<figure>


<pre><code><span>---- test_counter stdout ----</span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: increment</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>thread &#39;test_counter&#39; panicked at src/lib.rs:56:7:</span>
<span>assertion `left == right` failed</span>
<span>  left: 4</span>
<span> right: 3</span>
<span></span>
<span>arbtest failed!</span>
<span>    Seed: 0x4fd7ddff00000020</span></code></pre>

</figure>
<p><span>Which </span>…<span> is something we got like 5% into this article already, with normal threads! But there</span>’<span>s</span>
<span>more to this failure. First, it is reproducible. If I specify the same seed, I get the </span><em><span>exact</span></em><span> same</span>
<span>interleaving:</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>test_counter</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    eprintln!(<span>&#34;begin trace&#34;</span>);</span>
<span>    ...</span>
<span>  })</span>
<span>    .<span>seed</span>(<span>0x71aafcd900000020</span>);</span>
<span>}</span></code></pre>

</figure>
<p><span>And this is completely machine independent! If </span><em><span>you</span></em><span> specify this seed, you</span>’<span>ll get exact same</span>
<span>interleaving. So, if I am having trouble debugging this, I can DM you this hex in Zulip, and</span>
<span>you</span>’<span>ll be able to help out!</span></p>
<p><span>But there</span>’<span>s more </span>—<span> we don</span>’<span>t need to debug this failure, we can minimize it!</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>test_counter</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    eprintln!(<span>&#34;begin trace&#34;</span>);</span>
<span>    ...</span>
<span>  })</span>
<span>    .<span>seed</span>(<span>0x71aafcd900000020</span>)</span>
<span>    .<span>minimize</span>();</span>
<span>}</span></code></pre>

</figure>
<p><span>This gives me the following minimization trace:</span></p>

<figure>


<pre><code><span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: increment</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>seed 0x4fd7ddff00000020, seed size 32, search time 106.00ns</span>
<span></span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>1: increment</span>
<span>seed 0x540c0c1c00000010, seed size 16, search time 282.16µs</span>
<span></span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>seed 0x084ca71200000008, seed size 8, search time 805.74µs</span>
<span></span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>seed 0x5699b19400000004, seed size 4, search time 1.44ms</span>
<span></span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>seed 0x4bb0ea5c00000002, seed size 2, search time 4.03ms</span>
<span></span>
<span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>seed 0x9c2a13a600000001, seed size 1, search time 4.31ms</span>
<span></span>
<span>minimized</span>
<span>seed 0x9c2a13a600000001, seed size 1, search time 100.03ms</span></code></pre>

</figure>
<p><span>That is, we ended up with this tiny, minimal example:</span></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>test_counter</span>() {</span>
<span>  arbtest::<span>arbtest</span>(|rng| {</span>
<span>    eprintln!(<span>&#34;begin trace&#34;</span>);</span>
<span>    ...</span>
<span>  })</span>
<span>    .<span>seed</span>(<span>0x9c2a13a600000001</span>);</span>
<span>}</span></code></pre>

</figure>

<figure>


<pre><code><span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span></code></pre>

</figure>
<p><span>And </span><em><span>this</span></em><span> is how you properly test concurrent data structures.</span></p>
</section>
<section id="Postscript">

    <h2>
    <a href="#Postscript"><span>Postscript</span> </a>
    </h2>
<p><span>Of course, this is just a toy. But you can see some ways to extend it. For example, right now our</span>
<code>AtomicU32</code><span> just delegates to the real one. But what you </span><em><span>could</span></em><span> do instead is, for each atomic, to</span>
<span>maintain a set of values written and, on read, return an </span><em><span>arbitrary</span></em><span> written value consistent with a</span>
<span>weak memory model.</span></p>
<p><span>You could also be smarter with exploring interleavings. Instead of interleaving threads at random,</span>
<span>like we do here, you can try to apply model checking approaches and prove that you have considered</span>
<span>all meaningfully different interleavings.</span></p>
<p><span>Or you can apply the approach from </span><a href="https://matklad.github.io/2021/11/07/generate-all-the-things.html"><em><span>Generate All The</span>
<span>Things</span></em></a><span> and exhaustively</span>
<span>enumerate </span><em><span>all</span></em><span> interleavings for up to, say, five increments. In fact, why don</span>’<span>t we just do this?</span></p>
<p><code>$ cargo add exhaustigen</code></p>

<figure>


<pre><code><span><span>#[test]</span></span>
<span><span>fn</span> <span>exhaustytest</span>() {</span>
<span>  <span>let</span> <span>mut </span><span>g</span> = exhaustigen::Gen::<span>new</span>();</span>
<span>  <span>let</span> <span>mut </span><span>interleavings_count</span> = <span>0</span>;</span>
<span></span>
<span>  <span>while</span> !g.<span>done</span>() {</span>
<span>    interleavings_count += <span>1</span>;</span>
<span>    <span>let</span> <span>counter</span> = Counter::<span>default</span>();</span>
<span>    <span>let</span> <span>mut </span><span>counter_model</span>: <span>u32</span> = <span>0</span>;</span>
<span></span>
<span>    <span>let</span> <span>increment_count</span> = g.<span>gen</span>(<span>5</span>) <span>as</span> <span>u32</span>;</span>
<span>    std::thread::<span>scope</span>(|scope| {</span>
<span>      <span>let</span> <span>t1</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span>      <span>let</span> <span>t2</span> = managed_thread::<span>spawn</span>(scope, &amp;counter);</span>
<span></span>
<span>      <span>&#39;outer</span>: <span>while</span> t1.<span>is_paused</span>()</span>
<span>        || t2.<span>is_paused</span>()</span>
<span>        || counter_model &lt; increment_count</span>
<span>      {</span>
<span>        <span>for</span> <span>t</span> <span>in</span> [&amp;t1, &amp;t2] {</span>
<span>          <span>if</span> g.<span>flip</span>() {</span>
<span>            <span>if</span> t.<span>is_paused</span>() {</span>
<span>              t.<span>unpause</span>();</span>
<span>              <span>continue</span> <span>&#39;outer</span>;</span>
<span>            }</span>
<span>            <span>if</span> counter_model &lt; increment_count {</span>
<span>              t.<span>submit</span>(|c| c.<span>increment</span>());</span>
<span>              counter_model += <span>1</span>;</span>
<span>              <span>continue</span> <span>&#39;outer</span>;</span>
<span>            }</span>
<span>          }</span>
<span>        }</span>
<span>        <span>return</span> <span>for</span> <span>t</span> <span>in</span> [t1, t2] {</span>
<span>          t.<span>join</span>()</span>
<span>        };</span>
<span>      }</span>
<span></span>
<span>      <span>assert_eq!</span>(counter_model, counter.<span>get</span>());</span>
<span>    });</span>
<span>  }</span>
<span>  eprintln!(<span>&#34;interleavings_count = {:?}&#34;</span>, interleavings_count);</span>
<span>}</span></code></pre>

</figure>
<p><span>The shape of the test is more or less the same, except that we need to make sure that there are no</span>
“<span>dummy</span>”<span> iterations, and that we always either unpause a thread or submit an increment.</span></p>
<p><span>It finds the same bug, naturally:</span></p>

<figure>


<pre><code><span>thread &#39;exhaustytest&#39; panicked at src/lib.rs:103:7:</span>
<span>assertion `left == right` failed</span>
<span>  left: 2</span>
<span> right: 1</span></code></pre>

</figure>
<p><span>But the cool thing is, if we fix the issue by using atomic increment, </span>…</p>

<figure>


<pre><code><span><span>impl</span> <span>AtomicU32</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>fetch_add</span>(</span>
<span>    &amp;<span>self</span>,</span>
<span>    value: <span>u32</span>,</span>
<span>    ordering: Ordering,</span>
<span>  ) <span>-&gt;</span> <span>u32</span> {</span>
<span>    <span>pause</span>();</span>
<span>    <span>let</span> <span>result</span> = <span>self</span>.inner.<span>fetch_add</span>(value, ordering);</span>
<span>    <span>pause</span>();</span>
<span>    result</span>
<span>  }</span>
<span>}</span>
<span></span>
<span><span>impl</span> <span>Counter</span> {</span>
<span>  <span>pub</span> <span>fn</span> <span>increment</span>(&amp;<span>self</span>) {</span>
<span>    <span>self</span>.value.<span>fetch_add</span>(<span>1</span>, SeqCst);</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p>…<span> we can get a rather specific correctness statements out of our test, that </span><em><span>any</span></em><span> sequence of at</span>
<span>most five increments is correct:</span></p>

<figure>


<pre><code><span><span>$</span> t cargo t -r -- exhaustytest --nocapture</span>
<span><span>running 1 test</span></span>
<span><span>all 81133 interleavings are fine!</span></span>
<span><span>test exhaustytest ... ok</span></span>
<span><span></span></span>
<span><span>real 8.65s</span></span>
<span><span>cpu  8.16s (2.22s user + 5.94s sys)</span></span>
<span><span>rss  63.91mb</span></span></code></pre>

</figure>
<p><span>And the last small thing. Recall that our PBT minimized the first sequence it found </span>…<span>:</span></p>

<figure>


<pre><code><span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>0: increment</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>0: unpause</span>
<span>thread &#39;test_counter&#39; panicked at src/lib.rs:56:7:</span>
<span>assertion `left == right` failed</span>
<span>  left: 4</span>
<span> right: 3</span>
<span></span>
<span>arbtest failed!</span>
<span>    Seed: 0x4fd7ddff00000020</span></code></pre>

</figure>
<p>…<span> down to just</span></p>

<figure>


<pre><code><span>begin trace</span>
<span>0: increment</span>
<span>1: increment</span>
<span>0: unpause</span>
<span>1: unpause</span>
<span>thread &#39;test_counter&#39; panicked at src/lib.rs:57:7:</span>
<span>assertion `left == right` failed</span>
<span>  left: 2</span>
<span> right: 1</span>
<span></span>
<span>arbtest failed!</span>
<span>    Seed: 0x9c2a13a600000001</span></code></pre>

</figure>
<p><span>But we never implemented shrinking! How is this possible? Well, strictly speaking, this is out of</span>
<span>scope for this post. And I</span>’<span>ve already described this</span>
<a href="https://tigerbeetle.com/blog/2023-03-28-random-fuzzy-thoughts"><span>elsewhere</span></a><span>. And, at 32k, this is the</span>
<span>third-longest post on this blog. And it</span>’<span>s 3AM here in Lisbon right now. But of course I</span>’<span>ll explain!</span></p>
<p><span>The trick is the simplified </span><a href="https://hypothesis.works/articles/compositional-shrinking/"><span>hypothesis</span>
<span>approach</span></a><span>. The</span>
<a href="https://docs.rs/arbtest/latest/arbtest/"><span>arbtest</span></a><span> PBT library we in this post is based on a</span>
<span>familiar interface of a PRNG:</span></p>

<figure>


<pre><code><span>arbtest::<span>arbtest</span>(|rng| {</span>
<span>  <span>let</span> <span>random_int</span>: <span>usize</span> = rng.<span>int_in_range</span>(<span>0</span>..=<span>100</span>)?;</span>
<span>  <span>let</span> <span>random_bool</span>: <span>bool</span> = rng.<span>arbitrary</span>()?;</span>
<span>  <span>Ok</span>(())</span>
<span>});</span></code></pre>

</figure>
<p><span>But there</span>’<span>s a twist! This is a </span><em><span>finite</span></em><span> PRNG. So, if you ask it to flip a coin it can give you</span>
<span>heads. And next time it might give you tails. But if you continue asking it for more, at some point</span>
<span>it</span>’<span>ll give you </span><span><code>Err(OutOfEntropy)</code><span>.</span></span></p>
<p><span>That</span>’<span>s why all these </span><code>?</code><span> and the outer loop of</span>
<span><code>while !rng.is_empty() {</code><span>.</span></span></p>
<p><span>In other words, as soon as the test runs out of entropy, it short-circuits and completes. And that</span>
<span>means that by reducing the amount of entropy available the test becomes shorter, and this works</span>
<span>irrespective of how complex is the logic inside the test!</span></p>
<p><span>And </span>“<span>entropy</span>”<span> is a big scary word here, what actually happens is that the PRNG is just an </span><code>&amp;mut
&amp;[u8]</code><span> inside. That is, a slice of random bytes, which is shortened every time you ask for a random</span>
<span>number. And the shorter the initial slice, the simpler the test gets. Minimization can be this</span>
<span>simple!</span></p>
<p><span>You can find source code for this article at</span>
<a href="https://github.com/matklad/properly-concurrent">https://github.com/matklad/properly-concurrent</a></p>
</section>
</article>
  </div></div>
  </body>
</html>
