<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://techcrunch.com/2025/04/17/the-latest-viral-chatgpt-trend-is-doing-reverse-location-search-from-photos/">Original</a>
    <h1>Viral ChatGPT trend is doing &#39;reverse location search&#39; from photos</h1>
    
    <div id="readability-page-1" class="page"><div>
<p id="speakable-summary">There’s a somewhat concerning new trend going viral: People are using ChatGPT to figure out the location shown in pictures.</p>

<p>This week, OpenAI released its newest AI models, <a href="https://techcrunch.com/2025/04/16/openai-launches-a-pair-of-ai-reasoning-models-o3-and-o4-mini/">o3 and o4-mini</a>, both of which can uniquely “reason” through uploaded images. In practice, the models can crop, rotate, and zoom in on photos — even blurry and distorted ones — to thoroughly analyze them.</p>







<p>These image-analyzing capabilities, paired with the models’ ability to search the web, make for a potent location-finding tool. Users on X quickly discovered that o3, in particular, is quite good at deducing <a href="https://x.com/k_kohlbrenner/status/1912728015760486626" target="_blank" rel="noreferrer noopener nofollow">cities</a>, <a href="https://x.com/emollick/status/1912726124913623143" target="_blank" rel="noreferrer noopener nofollow">landmarks</a>, and even restaurants and bars from subtle visual clues.</p>

<blockquote>
<p>Wow, nailed it and not even a tree in sight. <a href="https://t.co/bVcoe1fQ0Z" target="_blank" rel="noreferrer noopener nofollow">pic.twitter.com/bVcoe1fQ0Z</a></p>



<p>— swax (@swax) <a href="https://twitter.com/swax/status/1912728143682760934?ref_src=twsrc%5Etfw" target="_blank" rel="noreferrer noopener nofollow">April 17, 2025</a></p>
</blockquote>



<p>In many cases, the models don’t appear to be drawing on “memories” of past ChatGPT conversations, or <a href="https://x.com/datapoint2200/status/1912729205554524495" target="_blank" rel="noreferrer noopener nofollow">EXIF data</a>, which is the metadata attached to photos that reveal details such as where the photo was taken.</p>

<p>X is filled with examples of users giving ChatGPT <a href="https://x.com/deedydas/status/1912607561947230575" target="_blank" rel="noreferrer noopener nofollow">restaurant menus</a>, <a href="https://x.com/swax/status/1912728143682760934" target="_blank" rel="noreferrer noopener nofollow">neighborhood snaps</a>, <a href="https://x.com/izyuuumi/status/1912726186679226451" target="_blank" rel="noreferrer noopener nofollow">facades</a>, and <a rel="nofollow" href="https://x.com/vyrotek/status/1912702767531192392">self-portraits</a>, and instructing o3 to imagine it’s playing “GeoGuessr,” an online game that challenges players to guess locations from Google Street View images.</p>

<blockquote>
<p>this is a fun ChatGPT o3 feature. geoguessr! <a href="https://t.co/HrcMIxS8yD" target="_blank" rel="noreferrer noopener nofollow">pic.twitter.com/HrcMIxS8yD</a></p>



<p>— Jason Barnes (@vyrotek) <a href="https://twitter.com/vyrotek/status/1912702767531192392?ref_src=twsrc%5Etfw" target="_blank" rel="noreferrer noopener nofollow">April 17, 2025</a></p>
</blockquote>




<p>It’s an obvious potential privacy issue. There’s nothing preventing a bad actor from screenshotting, say, a person’s Instagram Story and using ChatGPT to try to doxx them. </p>

<blockquote>
<p>o3 is insane</p>



<p>— Yumi (@izyuuumi) <a href="https://twitter.com/izyuuumi/status/1912726186679226451?ref_src=twsrc%5Etfw" target="_blank" rel="noreferrer noopener nofollow">April 17, 2025</a></p>
</blockquote>



<p>Of course, this could be done even before the launch of o3 and o4-mini. TechCrunch ran a number of photos through o3 and an older model without image-reasoning capabilities, GPT-4o, to compare the models’ location-guessing skills. Surprisingly, GPT-4o arrived at the same, correct answer as o3 more often than not — and took less time.</p>







<p>There was at least one instance during our brief testing when o3 found a place GPT-4o couldn’t. Given a picture of a purple, mounted rhino head in a dimly-lit bar, o3 correctly answered that it was from a Williamsburg speakeasy — not, as GPT-4o guessed, a U.K. pub.</p>

<p>That’s not to suggest o3 is flawless in this regard. Several of our tests failed — o3 got stuck in a loop, unable to arrive at an answer it was reasonably confident about, or volunteered a wrong location. Users on X noted, too, that o3 can be <a href="https://x.com/GrantSlatton/status/1912676624556023985" target="_blank" rel="noreferrer noopener nofollow">pretty</a> <a href="https://x.com/neilsuperduper/status/1912706630459806162" target="_blank" rel="noreferrer noopener nofollow">far off</a> in its location deductions.</p>

<p>But the trend illustrates some of the emerging risks presented by more capable, so-called reasoning AI models. There appear to be few safeguards in place to prevent this sort of “reverse location lookup” in ChatGPT, and OpenAI, the company behind ChatGPT, doesn’t address the issue in its <a href="https://openai.com/index/o3-o4-mini-system-card/" target="_blank" rel="noreferrer noopener nofollow">safety report</a> for o3 and o4-mini.</p>

<p>We’ve reached out to OpenAI for comment. We’ll update our piece if they respond. </p>

<p><em>Updated 10:19 p.m. Pacific: Hours after this story was published, an OpenAI spokesperson sent TechCrunch the following statement: </em></p>

<p><em>“OpenAI o3 and o4-mini bring visual reasoning to ChatGPT, making it more helpful in areas like accessibility, research, or identifying locations in emergency response. We’ve worked to train our models to refuse requests for private or sensitive information, added safeguards intended to prohibit the model from identifying private individuals in images, and actively monitor for and take action against abuse of our usage policies on privacy.”</em></p>
</div><div>
			
<div>
	
	
	
	

	
<div>
	<p>
		Kyle Wiggers is TechCrunch’s AI Editor. His writing has appeared in VentureBeat and Digital Trends, as well as a range of gadget blogs including Android Police, Android Authority, Droid-Life, and XDA-Developers. He lives in Manhattan with his partner, a music therapist.	</p>
</div>


	
	
	
</div>
	</div></div>
  </body>
</html>
