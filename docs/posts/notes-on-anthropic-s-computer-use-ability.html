<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://composio.dev/blog/claude-computer-use/">Original</a>
    <h1>Notes on Anthropic&#39;s Computer Use Ability</h1>
    
    <div id="readability-page-1" class="page"><div id="content">

			<!-- 1.4 uicore_before_content -->
<div id="primary">

	        <main id="main">
			<div>


                				<div>

                    <article id="post-5867">
                            
                            <div>
                            
<p>Anthropic has updated its Haiku and Sonnet lineup. Now, we have Haiku 3.5—a smaller model that outperforms Opus 3, the former state-of-the-art—and Sonnet 3.5, with enhanced coding abilities and a groundbreaking new feature called computer use. This is significant for everyone working in the field of AI agents.</p>



<p>As someone who works at an AI start-up, I wanted to know how good it is and what it holds for the future of AI agents.</p>



<p>I tested the model across several real-world use cases you might encounter, and in this article, I’ll walk you through each of them. </p>



<h3 id="h-table-of-contents">Table of Contents</h3>



<ul>
<li>1. <a href="#h-tl-dr">TL;DR</a></li>



<li>2. <a href="#h-what-is-anthropic-s-computer-use">What is Anthropic’s Computer Use?</a></li>



<li>3. <a href="#h-how-to-set-up-anthropic-s-computer-use">How do you set up Anthropic’s Computer Use?</a></li>



<li>4. <a href="#h-let-s-see-how-computer-use-works">Let’s see how Computer Use works</a>.</li>



<li>5. <a href="#h-what-future-holds-for-agents">What future holds for Agents?</a></li>



<li>6. <a href="#h-final-verdict">Final Verdict</a></li>
</ul>



<h2 id="h-tl-dr">TL;DR</h2>



<p>If you have anywhere else to go, here is the summary of the article.</p>



<ul>
<li>1. Computer Use is Anthropic’s latest LLM capability. It lets Sonnet 3.5 determine the coordinates of components in an image.</li>



<li>2. Equipping the model with tools like a Computer allows it to move cursors and interact with the computer as an actual user.</li>



<li>3. The model could easily handle simple use cases, such as searching the Internet, retrieving results, creating Spreadsheets, etc.</li>



<li>4. It still relies on screenshots, so do not expect it to perform real-time tasks like playing pong or Mario.</li>



<li>5. The model excels at many tasks, from research to filling out simple forms. </li>



<li>6. The model is too expensive and too slow for anything practical. I burnt nearly $30 for this blog.</li>
</ul>



<h2 id="h-what-is-anthropic-s-computer-use">What is Anthropic’s Computer Use?</h2>



<p>The Computer Use feature takes the Sonnet’s image understanding and logical reasoning to the next level, allowing it to interact with the computer directly. It can now understand the image and figure out the display component to move cursors, click, and type text to interact with computers like humans.</p>



<p>The model can understand pixels on the images and figure out how many pixels vertically or horizontally it needs to move a cursor to click in the correct place.</p>



<p>Sonnet is now officially the state-of-the-art model for computer interaction, scoring 14.7% in <a href="https://os-world.github.io/">OSWorld</a>, almost double that of the closest model.</p>



<p>If you want to learn more, check out Anthropic’s official <a href="https://www.anthropic.com/news/developing-computer-use">blog post</a>; though they have not revealed much about their training, it is still a good read.</p>



<h2 id="h-how-to-set-up-anthropic-s-computer-use">How to Set up Anthropic’s Computer Use?</h2>



<p>Anthropic also released a developer cookbook to help you quickly set it up and explore how it works.</p>



<p>You need access to any Anthropic API keys, AWS bedrock, and Vertex to use Sonnet. The README file explains how to do this.</p>



<p>To get started, clone the repository.</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>git clone &lt;https:</span><span>//github.com/anthropics/anthropic-quickstarts&gt;</span></span>
<span></span></code></pre></div>


<p>Move into the Computer Use demo directory.</p>





<p>Now, pull the image and run the container. I used the Bedrock-hosted model; you can use other providers as well.</p>


<p>docker run \ -e API_PROVIDER=bedrock \ -e AWS_PROFILE=$AWS_PROFILE \ -e AWS_REGION=us-west-2 \ -v $HOME/.aws/credentials:/home/computeruse/.aws/credentials \ -v $HOME/.anthropic:/home/computeruse/.anthropic \ -p 5900:5900 \ -p 8501:8501 \ -p 6080:6080 \ -p 8080:8080 \ -it ghcr.io/anthropics/anthropic-quickstarts:computer-use-demo-latest ” style=”color:#D4D4D4;display:none” aria-label=”Copy”&gt;</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>export AWS_PROFILE=&lt;your_aws_profile&gt;</span></span>
<span><span>docker run \</span></span>
<span><span>    -e API_PROVIDER=bedrock \</span></span>
<span><span>    -e AWS_PROFILE=$AWS_PROFILE \</span></span>
<span><span>    -e AWS_REGION=us-west</span><span>-2</span><span> \</span></span>
<span><span>    -v $HOME/.aws/credentials:/home/computeruse/.aws/credentials \</span></span>
<span><span>    -v $HOME/.anthropic:/home/computeruse/.anthropic \</span></span>
<span><span>    -p </span><span>5900</span><span>:</span><span>5900</span><span> \</span></span>
<span><span>    -p </span><span>8501</span><span>:</span><span>8501</span><span> \</span></span>
<span><span>    -p </span><span>6080</span><span>:</span><span>6080</span><span> \</span></span>
<span><span>    -p </span><span>8080</span><span>:</span><span>8080</span><span> \</span></span>
<span><span>    -it ghcr.io/anthropics/anthropic-quickstarts:computer-use-demo-latest</span></span>
<span></span></code></pre></div>


<p>This will take some time; once it is finished, it will spawn a Streamlit server.</p>

<p>You can view the site.</p>

<figure><img decoding="async" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-54-29-1024x516.png" alt="Claude computer use"/></figure>

<p>Send a message to see if everything is up and running.</p>



<figure><img decoding="async" width="1024" height="516" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-1024x516.png.webp" alt="Claude computer use greet" srcset="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-1024x516.png.webp 1024w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-300x151.png.webp 300w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-768x387.png.webp 768w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-1536x774.png.webp 1536w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59-650x328.png.webp 650w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-17-55-59.png.webp 1915w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>By default, it has access to a few apps: Firefox, a Spreadsheet, a Terminal, a PDF viewer, a Calculator, etc.</p>



<h2 id="h-let-s-see-how-computer-use-works">Let’s see how Computer Use works</h2>



<h4 id="h-example-1-find-the-top-5-movies-and-make-a-csv">Example 1: Find the top 5 movies and make a CSV</h4>



<p>I started with a simple internet search. I asked it to find the top five movies of all time. The model has access to the Computer Tool, enabling it to move cursors to click on Computer components.</p>



<p>The model dissects the prompt and develops a step-by-step reasoning to complete the task.</p>



<p>It decided to visit MyAnimeList using Firefox.</p>



<figure><img decoding="async" width="637" height="945" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-10-04.png.webp" alt="Response from Claude 1" srcset="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-10-04.png.webp 637w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-10-04-202x300.png.webp 202w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-10-04-438x650.png.webp 438w" sizes="(max-width: 637px) 100vw, 637px"/></figure>



<p>From every screenshot, it calculates the coordinates of the required component and moves the cursor accordingly.</p>



<figure><img loading="lazy" decoding="async" width="640" height="807" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-15-32.png.webp" alt="response from Claude 2" srcset="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-15-32.png.webp 640w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-15-32-238x300.png 238w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-18-15-32-515x650.png 515w" sizes="(max-width: 640px) 100vw, 640px"/></figure>



<p>Each input corresponds to a specific action that determines what task to perform, and the inputs vary depending on the action type. For instance, if the action type is “type,” there will be a text input, while for a “mouse_move” action, the relevant inputs would be coordinates.</p>



<p>Based on the original prompt, screenshots, and reasoning, the model decides which actions to take.</p>



<p>The model moves the cursor, opens Firefox, finds the address bar, inputs the web page, scrolls down the page, and outputs the answers.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="478" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-1024x478.png.webp" alt="" srcset="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-1024x478.png.webp 1024w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-300x140.png.webp 300w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-768x359.png.webp 768w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-1536x718.png.webp 1536w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45-650x304.png.webp 650w, https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-03-45.png.webp 1920w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>You can observe the model could successfully fetch the movies. Next, I asked it to create a CSV file of the film. (I asked for the top 10 this time)</p>



<figure><img decoding="async" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-23-19-26-12-1024x478.png" alt=""/></figure>



<p>The model created and updated the file using the Shell tool, and it was then opened using Libre Office.</p>



<p>So far, the model has been able to execute the commands successfully. Sometimes, it doesn’t get it right, so it attempts repeatedly until it does. Right now, this can get very expensive for even minor things.</p>



<figure><video controls="" src="https://composio.dev/wp-content/uploads/2024/10/animelist.mp4"></video></figure>



<p>Let’s see another example.</p>



<h4 id="h-example-2-find-the-best-restaurants-based-on-the-city-s-weather">Example 2: Find the best restaurants based on the City’s Weather</h4>



<p>So, this time, I asked it to find me the best restaurants and weather in Bengaluru. It was able to successfully search the web for the best restaurants from the web and get the weather from AccuWeather.</p>







<figure><video controls="" src="https://composio.dev/wp-content/uploads/2024/10/blrrestro.mp4"></video></figure>







<h4 id="h-example-3-ordering-food-online">Example 3: Ordering food online</h4>



<p>I was hungry, so I asked Claude to order me from Wendy’s Burger and gave it the credentials. However, the model refused to move forward.</p>



<figure><img decoding="async" src="https://composio.dev/wp-content/uploads/2024/10/no-removed-1-1024x540.png" alt="Claude response for ordering from amazon 1"/></figure>



<h4 id="h-example-4-purchasing-from-amazon">Example 4: Purchasing from Amazon</h4>



<p>I asked Amazon to order me a pair of shorts, but this time, I asked Amazon to search for the product and add it to the cart, which it accomplished. </p>



<figure><img decoding="async" src="https://composio.dev/wp-content/uploads/2024/10/Screenshot-from-2024-10-24-19-46-01-2-1024x540.png" alt="Claude response for ordering from amazon 2"/></figure>



<p>Next, I asked it to log in and make the purchase, and as expected, it refused. It seems you cannot just ask it to do anything that involves handling critical information.</p>



<h2 id="h-what-future-holds-for-agents">What future holds for Agents?</h2>



<p>The release of Computer Use and the tone of their blog make it clear that Anthropic is betting big on an agentic future. We can expect more labs to release models optimized for computer interaction in the future. It will be interesting to see OpenAI’s response to the Computer model.</p>



<h2 id="h-final-verdict">Final Verdict</h2>



<p>The new Sonnet 3.5 is phenomenal at locating the coordinates of components in a screenshot, and it seems the model has improved its ability to call tools. However, the computer tool itself could need some refinement.</p>



<p>The model needs improvement at the current stage. As the Claude team also pointed out, it is expensive, slow, and can hallucinate during execution.</p>



<p>Running these initial experiments cost me around $30, making it far from production-ready. Nonetheless, the future appears promising. Smaller models like Haiku, which also utilize a computer, could be game-changers. Additionally, we anticipate AI labs like Deepseek and Qwen will release open-source models optimized for computer applications.</p>



<p>Anyway, the future looks exciting, and we will be looking forward to it. </p>




                        </div><!-- .entry-content -->

                                                <!-- .entry-footer -->
                        
                    </article><!-- #post-5867 -->
                                    </div>
                    </div>
            </main>
    	
</div><!-- #primary -->


	</div></div>
  </body>
</html>
