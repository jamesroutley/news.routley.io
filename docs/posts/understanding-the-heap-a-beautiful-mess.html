<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess.html">Original</a>
    <h1>Understanding the heap – a beautiful mess</h1>
    
    <div id="readability-page-1" class="page"><article><p>In this blog, I am going to explain the important concepts of Heap and use the <code>ptmalloc</code> in the Glibc 2.31 library as an example.</p>
<p>The heap is a beautiful mess :)</p>
<span id="more"></span>
<p>I really like the saying shown above. The word <code>Heap</code> we always use refers to the dynamically allocated segment in the virtual memory space of a process, but it actually stands for the implementation of the memory pool(the dynamic memory allocator) behind, which is quite complex and maybe vary on different machines, thus giving us a chance to exploit it. Here I am going to explain the important concepts of Heap and use the <code>ptmalloc</code> in the Glibc 2.31 library as an example.</p>
<p><del>I found that the available online material, while very extensive and detailed, may not be friendly for beginners to learn.</del> I just found the <a target="_blank" rel="noopener" href="https://dojo.pwn.college/software-exploitation/dynamic-allocator-misuse">pwn.college</a> gives a <strong>really really really</strong> great lecture on the heap or dynamic memory allocator. However, I still like to try a different ways to introduce these concepts.</p>
<p>Firstly, I will start from the single-thread case and introduce the following points:</p>
<ol type="1">
<li><p>high-level behavior behind <code>malloc</code>: <code>sbrk</code> and <code>mmap</code></p></li>
<li><p>the overall layout of heap and chunks</p></li>
<li><p>the data structures used for management: <code>malloc_chunk</code>, <code>malloc_state</code> and <code>binning</code></p></li>
<li><p>low-level behavior of <code>malloc</code>: algorithms for allocating and freeing memory chunks (todo: creating, initialing, and deleting heaps)</p></li>
</ol>
<p>Then, I will get multi-threading involved and supplement the following points:</p>
<ol type="1">
<li><p>t-cache</p></li>
<li><p>the overall layout of arenas and heaps</p></li>
<li><p>updating the data structures: <code>malloc_state</code> and <code>heap_info</code></p></li>
</ol>
<pre><code>// comes from https://guyinatuxedo.github.io/25-heap/index.html
+--------------------+----------------------------+-----------------------+
|   Bug Used         |  Bin Attack                |   House               |
+--------------------+----------------------------+-----------------------+
|                    |  Fast Bin Attack           |   House of Spirit     |
|   Double Free      |  tcache attack             |   House of Lore       |
|   Heap Overflow    |  Unsorted Bin Attck        |   House of Force      |
|   Use After Free   |  Small / Large Bin Attck   |   House of Einherjar  |
|                    |  Unsafe Unlink             |   House of Orange     |
+--------------------+----------------------------+-----------------------+</code></pre>
<h3 id="overview-of-heap">Overview of Heap</h3>
<p>Pools are a common design pattern in computing technology, which involves: pre-allocating and keeping a pool of core resources that are frequently used in a program, which are self-managed by the program, in order to improve resource utilization and ensure that the program has a fixed number of resources.</p>
<p>Memory pools are a technique for dynamically allocating and managing memory. Typically, programmers are used to directly using APIs such as new, delete, malloc, and free to allocate and release memory, which can result in a large number of memory fragments over time when the program is run for a long time and the size of the allocated memory blocks is not fixed, reducing the performance of the program and the operating system.</p>
<p>Before actually using memory, a memory pool pre-allocates a large block of memory (the memory pool) as a reserve. When a programmer requests memory, a block is dynamically allocated from the pool. When the programmer releases the memory, it is returned to the pool and can be used again when requested, and is merged with surrounding free memory blocks as much as possible. If the memory pool is not sufficient, the memory pool is automatically expanded and a larger memory pool is requested from the operating system.</p>
<p>The benefits of using memory pools include:</p>
<ul>
<li>Reducing internal fragmentation by using chunk merging to minimize internal fragmentation as much as possible;</li>
<li>Reducing external fragmentation by requesting a large block of memory from memory at once;</li>
<li>Improving the efficiency of memory allocation by requesting a large block of memory from memory at once and using it slowly, avoiding frequent requests to memory for memory operations.</li>
</ul>
<p>In a C program, we always use built-in functions like<code>malloc()</code>, <code>calloc()</code>, and <code>realloc(),</code>which indeed invoke the memory allocator <code>ptmalloc</code>, to get a dynamically allocated memory space. The <code>ptmalloc</code> is the implementation of the memory pool in Glibc library used by default.</p>
<h4 id="system-calls-behind-malloc">System calls behind malloc</h4>
<p>In ptmalloc’s implementation, <code>malloc</code> use <code>(s)brk</code> or <code>mmap</code> system call for memory allocation.</p>
<p>According to the <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man2/sbrk.2.html">man pages of (s)brk</a>:</p>
<blockquote>
<pre><code>brk() and sbrk() change the location of the program break, which
defines the end of the process&#39;s data segment (i.e., the program
break is the first location after the end of the uninitialized
data segment).  Increasing the program break has the effect of
allocating memory to the process; decreasing the break
deallocates memory.</code></pre>
</blockquote>
<p>According to the <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man2/mmap.2.html">man pages of mmap</a>:</p>
<blockquote>
<pre><code>mmap() creates a new mapping in the virtual address space of the
calling process.  The starting address for the new mapping is
specified in addr.  The length argument specifies the length of
the mapping (which must be greater than 0).</code></pre>
</blockquote>
<p>In short, both<code>(s)brk</code>and <code>mmap</code> are the system calls that provide the functionality to create new memory space(with custom permissions). However, <code>(s)brk</code> only can create memory space following the <code>.data</code> segment(change the location of program break);</p>
<p><strong>Calling (s)brk or mmap?</strong></p>
<p>According to <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/30542428/does-malloc-use-brk-or-mmap">this page</a>:</p>
<p><code>mallopt()</code> could set parameters to control behavior of <code>malloc()</code>, and there is a parameter named <code>M_MMAP_THRESHOLD</code>, in general:</p>
<ul>
<li>If the requested memory is less than it, <code>brk()</code> will be used;</li>
<li>If the requested memory is larger than or equal to it, <code>mmap()</code> will be used;</li>
</ul>
<p>The default value of the parameter is <code>128KB</code> (on my system). And what has been mentioned in the <code>pwn.college</code> is that set <code>M_MMAP_THRESHOLD</code> could cause more overhead.</p>
<h4 id="overall-layout-of-heap">Overall layout of Heap</h4>
<p>In <code>ptmalloc</code> memory allocator, chunks of various sizes exist within a larger region of memory (a &#34;heap&#34;). The heap grows up from the lower address. The main heap(the heap initialized by the main thread) starts by following the <code>.BSS</code> segment (the original program breakpoint).</p>
<p><strong>Heap</strong></p>
<p>A contiguous region of memory that is subdivided into chunks to be allocated.</p>
<p><strong>Chunk</strong></p>
<p>A small range of memory that can be allocated (owned by the application), freed (owned by glibc), or combined with adjacent chunks into larger ranges. Note that a chunk is a wrapper around the block of memory that is given to the application.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/layout_of_heap_chunks.png"/>
<h3 id="data-structures-for-heap">Data structures for heap</h3>
<p>The heap metadata is organized with the help of the following three data structures: malloc_chunk(chunk header), malloc_state, and heap_info(introduced later).</p>
<ul>
<li>malloc_chunk: The chunk is the smallest unit allocated by malloc, and each chunk has its own <code>malloc_chunk</code> header structure.</li>
<li>malloc_state: heaps are governed by a single <code>malloc_state</code> header structure. This structure tells the allocator where the top chunk (chunk at the highest address), last remainder chunk, bins, etc. are.</li>
</ul>

<p>The chunk is the smallest unit allocated by malloc. Chunks have two different states: in-use or free.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/chunks.png"/>
<p>An <strong>in-use</strong> chunk consists of 3 parts: the previous chunk size or the previous chunk user data, the chunk size(8 bytes in 64-bit machines), the AMP flag(3-bit), and user data. The user data will be padded to align with 16 bytes on 64-bit machines, which means the last three bits of the size of user data in hex format will always be zero. Therefore, we could take advantage of the alignment and use them as flags.</p>
<p>An <strong>free</strong> chunk consists of 4 parts. The first 16 bytes stay the same. Now that this chunk is free, two new parts (fwd and bkd) will be written into this chunk and one(pre_size) into the next chunk. The forward pointer <code>fwd</code> stores the address of the next free chunk in the list, and the back pointer <code>bkd</code> saves the address of the previous free chunk in the list if any. Lastly, the <code>pre_size</code> of the next chunk will be set to this chunk’s CHUNK SIZE.</p>
<p><strong>the overlapping part</strong></p>
<p>An interesting point here is that the first 8 bytes <strong>might be</strong> the overlapping part of the previous chunk. If the previous chunk is in use, then this part will hold the previous last 8 bytes of data, and if the previous chunk is free, it will hold the previous’ chunk size.</p>
<p>This is because the size of a chunk should be multiple of 0x10, and if the asked memory size ends with 0x8 or round to 0x8, to improve the space usage, ptmalloc would make chunk overlapped. Specifically, for example if we are trying to allocate 0x18 bytes, you would get a total 0x18+0x10(header)+0x8(padding)=0x30 bytes for the current chunk, and the size field would be 0x20 bytes and next chunk pointer would be placed to current <code>mchunptr</code> + 0x30 - 0x8 which indicating the next chunk would overlap with the current chunk. However, it doesn&#39;t matter since the first 8 bytes of next chunk won&#39;t used until the current chunk is freed, this key insight help us saving 8 bytes memory.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overlapped_chunk.png" title="overlapped_chunk"/>
<p><strong>AMP flags</strong></p>
<p><strong>A</strong>, Allocated Arena - the main arena uses the application&#39;s heap. Other arenas use mmap&#39;d heaps. To map a chunk to a heap, you need to know which case applies. If this bit is 0, the chunk comes from the main arena and the main heap. If this bit is 1, the chunk comes from mmap&#39;d memory and the location of the heap can be computed from the chunk&#39;s address.</p>
<p><strong>M</strong>, MMap&#39;d chunk - this chunk was allocated with a single call to <code>mmap</code> and is not part of a heap at all.</p>
<p><strong>P</strong>, Previous chunk is in use - if set, the previous chunk is still being used by the application, and thus the <code>prev_size</code> field is invalid. Note - some chunks, such as those in fastbins (see below) will have this bit set despite being free&#39;d by the application. This bit really means that the previous chunk should not be considered a candidate for coalescing - it&#39;s &#34;in use&#34; by either the application or some other optimization layered atop malloc&#39;s original code.</p>
<p><strong>minimum size of the chunk</strong></p>
<p>In order to ensure that a chunk&#39;s payload area is large enough to hold the overhead needed by malloc, the minimum size of a chunk is <code>4*sizeof(void*)</code> (unless <code>size_t</code> is not the same size as <code>void*</code>). The minimum size may be larger if the ABI of the platform requires additional alignment. Note that <code>prev_size</code> does not increase the minimum chunk size to <code>5*sizeof(void*)</code> because when the chunk is small the <code>bk_nextsize</code> pointer is unused, and when the chunk is large enough to use it there is more than enough space at the end.</p>
<p><strong>the malloc_chunk struct type</strong></p>
<pre><code>/*
  This struct declaration is misleading (but accurate and necessary).
  It declares a &#34;view&#34; into memory allowing access to necessary
  fields at known offsets from a given base. See explanation below.
*/
struct malloc_chunk {

  INTERNAL_SIZE_T      prev_size;  /* Size of previous chunk (if free).  */
  INTERNAL_SIZE_T      size;       /* Size in bytes, including overhead. */

  struct malloc_chunk* fd;         /* double links -- used only if free. */
  struct malloc_chunk* bk;

  /* Only used for large blocks: pointer to next larger size.  */
  struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */
  struct malloc_chunk* bk_nextsize;
};</code></pre>
<h4 id="malloc_state">malloc_state</h4>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/malloc_state.png"/>
<p>Struct <code>malloc_state</code> contains the necessary variables to manage the free memory chunks. The struct <code>malloc_state</code> of the main thread (the main heap) is stored in the memory mapping segment as a global variable.</p>
<pre><code>struct malloc_state
{
  /* Serialize access.  */
  __libc_lock_define (, mutex);
  /* Flags (formerly in max_fast).  */
  int flags;

  /* Fastbins */
  mfastbinptr fastbinsY[NFASTBINS];
  /* Base of the topmost chunk -- not otherwise kept in a bin */
  mchunkptr top;
  /* The remainder from the most recent split of a small request */
  mchunkptr last_remainder;
  /* Normal bins packed as described above */
  mchunkptr bins[NBINS * 2 - 2];

  /* Bitmap of bins */
  unsigned int binmap[BINMAPSIZE];

  /* Linked list */
  struct malloc_state *next;
  /* Linked list for free arenas.  Access to this field is serialized
     by free_list_lock in arena.c.  */
  struct malloc_state *next_free;
  /* Number of threads attached to this arena.  0 if the arena is on
     the free list.  Access to this field is serialized by
     free_list_lock in arena.c.  */

  INTERNAL_SIZE_T attached_threads;
  /* Memory allocated from the system in this arena.  */
  INTERNAL_SIZE_T system_mem;
  INTERNAL_SIZE_T max_system_mem;
};

typedef struct malloc_state *mstate;</code></pre>
<h4 id="binning">binning</h4>
<p>Free chunks are stored in various free lists based on size and history so that the allocator can find suitable chunks to satisfy allocation requests quickly. The free lists are actually called <strong>bins</strong>. Bins are in-memory linked structures that keep track of all the freed chunks.</p>
<p><strong>Fast Bins</strong></p>
<p>Most programs often request and release relatively small chunks of memory. If some smaller chunks are freed, and a free chunk adjacent to them is found and merged, the next time a chunk of the same size is requested, the chunk needs to be partitioned, which greatly reduces the efficiency of heap utilization. Therefore, <code>fastbin</code> has been proposed to keep access fast by keeping minimal logic.</p>
<ul>
<li>7 bins are used by default, however, the number of bins in <code>fastbins</code> is defined by <code>NFASTBINS</code></li>
<li>The fast bins are singly-linked lists, and the chunks in each list are all the same size and chunks in the middle of the list need never be accessed.</li>
<li>On <code>x64</code> machines, the sizes range from <code>0x20</code> - <code>0x80</code> by default. The size of each bin increase by 0x10 bytes. So a chunk of size <code>0x20-0x2f</code> would fit into <code>idx</code> <code>0</code>, a chunk of size <code>0x30-0x3f</code> would fit into <code>idx</code> <code>1</code>, and so on and so forth.</li>
<li>The in-use flag of chunks added to a fast bin is always set to 1 so that they will not combine with adjacent chunks to keep access fast (hence <em>fast</em> bins). However, if the chunks in fast/small bins cannot satisfy, the fast bin would be consolidated.</li>
<li>LIFO manner</li>
</ul>
<p><strong>Unsorted Bin</strong></p>
<p>The <code>bins[]</code> actually contains 3 different kind of bins: <code>unsorted bin</code>, <code>small bins</code> and<code>large bins</code>.</p>
<p>The bins[1] is unsorted bin (bins[0] is unused). When chunks are free, they&#39;re initially stored in a single bin. They&#39;re sorted later, in malloc, in order to give them one chance to be quickly re-used. This also means that the sorting logic only needs to exist at one point - everyone else just puts free chunks into this bin, and they&#39;ll get sorted later. The &#34;unsorted&#34; bin is simply the first of the regular bins.</p>
<p>We would see how <code>unsorted bin</code> be used later in the allocation algorithm.</p>
<p><strong>Small Bins</strong></p>
<ul>
<li>There are 62 small bins (index 2-63), and each bin is a doubly-linked list;</li>
<li>Each bin(list) has an identical size. The bin with index <code>n</code> has a chunk size <code>(16n, 16n+16)</code>;</li>
<li>The max size of small bins is defined by MIN_LARGE_SIZE, which usually be 1024B(1KB);</li>
<li>FIFO manner;</li>
</ul>
<p><strong>Large Bins</strong></p>
<ul>
<li><p>There are 63 small bins (index 64-127), and each bin is a doubly-linked list;</p></li>
<li><p>A particular large bin has chunks of different sizes, sorted in decreasing order (i.e. largest chunk at the &#39;HEAD&#39; and smallest chunk at the &#39;TAIL&#39;).</p></li>
<li><p>Chunk size in large bins is between <code>1024 B</code> and <code>128 KB</code> inclusive (or whatever value <code>M_MMAP_THRESHOLD</code> is set to)</p></li>
<li><p>Insertions and removals happen at any position within the list.</p></li>
</ul>
<h3 id="low-level-behavior-of-malloc">low-level behavior of malloc</h3>
<h4 id="chunk-allocation-algorithm">chunk allocation algorithm</h4>
<ol type="1">
<li>Obtain the lock for the allocation area to prevent multi-threaded conflicts.</li>
<li>Calculate the actual size of the chunk of memory that needs to be allocated.</li>
<li>If the chunk size is less than the max size of fast bins (128 bytes), try to find a suitable chunk in the fast bins. If one is found, allocation is complete. Otherwise, proceed to the next step.</li>
<li>If the chunk size is less than the max size of small bins (1KB), search the small bins for a suitable chunk. If one is found, allocation is complete. Otherwise, proceed to the next step.</li>
<li>Tidy the unsorted memory blocks:
<ol type="1">
<li>Ptmalloc will first iterate through the chunks in the fast bins, merging adjacent chunks and linking them to the unsorted bin.</li>
<li>Then it will iterate through the unsorted bins. If there is a chunk larger than the one being allocated in the unsorted bins, it will be split, and the remaining chunk will be placed back in the unsorted bins. If there is a chunk of the same size as the one being allocated, it will be returned and removed from the unsorted bins. If a chunk in the unsorted bins is within the range of small bins in size, it will be placed at the head of the small bins. If a chunk in the unsorted bins is within the range of large bins in size, it will be placed in a suitable position in the large bins. (The only place in the code base to put chunks in S/L bins) If the allocation is not successful, proceed to the next step.</li>
</ol></li>
<li>Search the large bins for a suitable chunk, then split it, allocating part to the user and placing the remainder in the unsorted bin.</li>
<li>If no suitable chunk is found in the fast bins or bins, the top chunk must be used for allocation. When the top chunk is larger than the memory requested by the user, it will be split into two parts: the user chunk and the remainder chunk. The remainder chunk becomes the new top chunk.</li>
<li>If the top chunk is still not large enough to meet the user&#39;s requested size, we need to extend it through the <code>sbrk</code> (main arena) or <code>mmap</code> (thread arena) system calls.
<ol type="1">
<li>If <code>mmap</code> is used, a new chunk with the requested size aligned to a 4KB will be created and added to the top chunk. The top chunk will then be extended by the requested amount.</li>
<li>If <code>sbrk</code> is used, the top chunk will be extended by the requested amount, and the remainder will be added to the unsorted bin. However, if it is the first time to call <code>malloc</code> in the main thread, a initialization work is needed to allocate a chunk of size (chunk_size + 128KB) align 4KB as the initial heap.</li>
</ol></li>
<li>Release the lock for the allocation area.</li>
</ol>
<p>When the user requests memory allocation using malloc, the chunk found by ptmalloc2 may not be the same size as the requested memory. In this case, the remaining portion after the split is called the last remainder chunk and is also stored in the unsorted bin.</p>
<h4 id="chunk-free-algorithm">chunk free algorithm</h4>
<ol type="1">
<li>Obtain the lock for the allocation area to ensure thread safety.</li>
<li>If the pointer being freed is null, return and do nothing.</li>
<li>If the chunk size falls within the range of fast bins, place it in the fast bins.</li>
<li>Check if the current chunk is a memory mapped by the <code>mmap</code> system call. If it is, release it directly using <code>munmap()</code>. In the data structure of the previously used chunk, we can see that there is an <code>M</code> to indicate whether it is a memory mapped by <code>mmap</code>.</li>
<li>Check if the chunk being freed is adjacent to another free chunk. If it is, merge them and place the merged block in the unsorted bin. If the size of the merged chunk is greater than <code>fastbin_coalsed_threshold</code> (128B), trigger the fastbin merge operation, where adjacent free chunks will be merged and placed in the unsorted bin.</li>
<li>Check if the chunk is adjacent to the top chunk. If it is, merge it directly with the top chunk. Then, check if the size of the top chunk is greater than the mmap shrink threshold (default 128KB). If it is, for the main allocation area, it will try to return part of the top chunk to the operating system. Free is finished.</li>
</ol>
<h3 id="multi-threading">multi-threading</h3>
<h4 id="tcache">tcache</h4>
<p>The <code>tcache</code> mechanism was introduced in version 2.26 of GNU libc&#39;s malloc implementation, which was released on August 2, 2017, to speed up repeated (small) allocations in a single thread. It is implemented as a <strong>singly-linked</strong> list, with each thread having a list header for different-sized allocations.</p>
<pre><code>typedef struct tcache_perthread_struct
{
  char counts[TCACHE_MAX_BINS];
  tcache_entry *entries[TCACHE_MAX_BINS];
} tcache_perthread_struct;

typedef struct tcache_entry
{
  struct tcache_entry *next;
  struct tcache_perthread_struct *key;
} tcache_entry;</code></pre>
<p>It has been described so clear in the <a target="_blank" rel="noopener" href="https://dojo.pwn.college/software-exploitation/dynamic-allocator-misuse">pwn.college</a> on what the t-cache looks like. Basically, the place used to save <code>bk</code>ptr in fast, unsorted, and small bins has been assigned to save the <code>tcache_struct,</code> which is the<code>key</code>.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/t-cache.png" title="t-cache"/>
<p>When an allocation request is made, the malloc implementation first checks the tcache for available chunks of the requested size class. If there is an available chunk, the implementation returns it to the caller. If there are no available chunks in the tcache, the malloc implementation reverts to its standard allocation algorithm to find a suitable chunk of memory.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/tcache-free.png" title="tcache-free"/>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/tcache-allocate.png" title="tcache-allocate"/>
<h4 id="overall-layout-of-arenas-and-heaps">Overall layout of arenas and heaps</h4>
<h4 id="arena-per-thread">Arena per thread</h4>
<p>In ptmalloc’s implementation, an Arena is a large, contiguous piece of memory to store per-thread heaps(a memory pool that is managed by a particular program).</p>
<p>By using the following code, we could better understand the behavior of ptmalloc when multi-threads get involved.</p>
<pre><code>https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/
/* Per thread arena example. */
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;

void* threadFunc(void* arg) {
        printf(&#34;Before malloc in thread 1\n&#34;);
        getchar();
        char* addr = (char*) malloc(1000);
        printf(&#34;After malloc and before free in thread 1\n&#34;);
        getchar();
        free(addr);
        printf(&#34;After free in thread 1\n&#34;);
        getchar();
}

int main() {
        pthread_t t1;
        void* s;
        int ret;
        char* addr;

        printf(&#34;Welcome to per thread arena example::%d\n&#34;,getpid());
        printf(&#34;Before malloc in main thread\n&#34;);
        getchar();
        addr = (char*) malloc(1000);
        printf(&#34;After malloc and before free in main thread\n&#34;);
        getchar();
        free(addr);
        printf(&#34;After free in main thread\n&#34;);
        getchar();
        ret = pthread_create(&amp;t1, NULL, threadFunc, NULL);
        if(ret)
        {
                printf(&#34;Thread creation error\n&#34;);
                return -1;
        }
        ret = pthread_join(t1, &amp;s);
        if(ret)
        {
                printf(&#34;Thread join error\n&#34;);
                return -1;
        }
        return 0;
}</code></pre>
<p>Before calling <code>malloc</code> in the main thread, we could see that there is no heap segment.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-1.png" title="overview-1"/>
<p>A heap segment will be created after calling <code>malloc</code> in the main thread, and the allocated size is often larger than the requested size to reduce switching times between kernel and user modes, thus improving program efficiency. This contiguous region of heap memory is called an <code>Arena</code>. Since this arena is created by the main thread, its called the <code>main arena</code>. Further allocation requests keep using this arena until it runs out of free space.</p>
<p>For example, in the following case, ptmalloc2 creates a segment with size 0x21000(132KB) even though we just request 0x1000(4KB) bytes. The rest memory will be managed by ptmalloc2.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-2.png" title="overview-1"/>
<p>After calling the <code>free</code> function in the main thread, the created memory space (heap segment) won&#39;t be reclaimed directly but will be managed by ptmalloc2 again. When a later program requests memory, ptmalloc2 will allocate the corresponding memory to the program according to the heap allocation algorithm.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-2.png" title="overview-1"/>
<p>After calling <code>pthread_create</code> to create a thread, a size of 8MB of memory has been allocated in the memory mapping segment for the created thread. The thread has its own stack, which is located in this area. However, currently, I have no idea what does the top 4KB with permission <code>---p</code> used for.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-7.png" title="overview-1"/>
<p>After calling <code>malloc</code> in thread 1, we could see the memory space with a size of 21000 bytes(132KB) again has been allocated by the ptmalloc even though we just requested 1000 bytes(4KB). But this time, the heap is in the memory mapping segment rather than following the program breaking point. This contiguous region of memory (132 KB) is called the thread arena.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-3.png" title="overview-1"/>
<p>After calling <code>free</code> in thread 1, we can see that freeing allocated memory region doesnt release heap memory to the operating system. Instead allocated memory region (of size 1000 bytes) is released to ptmolloc, which adds this freed block to its thread arenas bin.</p>
<img src="https://jackfromeast.site/2023-01/understand-the-heap-a-beautiful-mess/overview-5.png" title="overview-1"/>
<p>Another important point here is that it is not exactly one arena per thread, as expected, since it would become expensive when there are many threads. Hence, the application’s <code>arena limit is based on the number of cores</code> present in the system.</p>
<pre><code>For 32 bit systems: Number of arena = 2 * number of cores.
For 64 bit systems: Number of arena = 8 * number of cores.</code></pre>
<p>The actual behavior of ptmalloc when one-to-one mapping between threads and arena doesn&#39;t get enough could become much more complicated, so I would stop here for a starter point. More information could refer to: https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/</p>
<h4 id="heap_info-and-malloc_state">heap_info and malloc_state</h4>
<h3 id="references">References</h3>
<blockquote>
<p>https://sensepost.com/blog/2017/painless-intro-to-the-linux-userland-heap/</p>
<p>https://ctf-wiki.org/pwn/linux/user-mode/heap/ptmalloc2/heap-structure/</p>
<p>https://raydenchia.com/heaps-of-fun-with-glibc-malloc/</p>
<p>https://0x434b.dev/overview-of-glibc-heap-exploitation-techniques/</p>
<p>https://sourceware.org/glibc/wiki/MallocInternals</p>
<p>https://blog.csdn.net/weixin_37921201/article/details/119744197</p>
<p>https://heap-exploitation.dhavalkapil.com/attacks/double_free</p>
</blockquote>
</article></div>
  </body>
</html>
