<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://railsatscale.com/2025-05-21-fast-allocations-in-ruby-3-5/">Original</a>
    <h1>Fast Allocations in Ruby 3.5</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Many Ruby applications allocate objects. What if we could make allocating
objects six times faster?  We can!  Read on to learn more!</p>

<h2 id="speeding-up-allocations-in-ruby">Speeding up allocations in Ruby</h2>

<p>Object allocation in Ruby 3.5 will be much faster than previous versions of Ruby.
I want to start this article with benchmarks and graphs, but if you stick around I’ll also be explaining how we achieved this speedup.</p>

<p>For allocation benchmarks, we’ll compare types of parameters (positional and keyword) with and without YJIT enabled.
We’ll also vary the number of parameters we pass to initialize so that we can see how performance changes as the number of parameters increases.</p>

<p>The full benchmark code can be found expanded below, but it’s basically as follows:</p>

<div><div><pre><code><span>class</span> <span>Foo</span>
  <span># Measure performance as parameters increase</span>
  <span>def</span> <span>initialize</span><span>(</span><span>a1</span><span>,</span> <span>a2</span><span>,</span> <span>aN</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>i</span> <span>=</span> <span>0</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>5_000_000</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>i</span> <span>+=</span> <span>1</span>
  <span>end</span>
<span>end</span>

<span>test</span>
</code></pre></div></div>

<details>

  <summary>Full Benchmark Code</summary>

  <p>Positional parameters benchmark:</p>

  <div><div><pre><code><span>N</span> <span>=</span> <span>(</span><span>ARGV</span><span>[</span><span>0</span><span>]</span> <span>||</span> <span>0</span><span>).</span><span>to_i</span>

<span>class</span> <span>Foo</span>
  <span>class_eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
  def initialize(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
  end
</span><span>  eorb</span>
<span>end</span>

<span>eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
def test
  i = 0
  while i &lt; 5_000_000
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(&#34;, &#34;) })
    i += 1
  end
end
</span><span>eorb</span>

<span>test</span>
</code></pre></div>  </div>

  <p>Keyword parameters benchmark:</p>

  <div><div><pre><code><span>N</span> <span>=</span> <span>(</span><span>ARGV</span><span>[</span><span>0</span><span>]</span> <span>||</span> <span>0</span><span>).</span><span>to_i</span>

<span>class</span> <span>Foo</span>
  <span>class_eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
  def initialize(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>:&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
  end
</span><span>  eorb</span>
<span>end</span>

<span>eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
def test
  i = 0
  while i &lt; 5_000_000
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>&#34;a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>&#34;</span> <span>}</span><span>.join(&#34;, &#34;) })
    i += 1
  end
end
</span><span>eorb</span>

<span>test</span>
</code></pre></div>  </div>
</details>

<p>We want to measure how long this script will take, but change the number and type of parameters we pass.
To emphasize the cost of object allocation while minimizing the impact of loop execution, the benchmark allocates several objects per iteration.</p>

<p>Running the benchmark code with 0 to 8 parameters, varying parameter type and whether or not YJIT is enabled will produce the following graph:</p>

<p><img src="https://push.cx/graph.png" alt="Benchmark results graph"/></p>

<p>The graph illustrates the speedup ratio, calculated by dividing the time spent on Ruby 3.4.2 by that spent on Ruby 3.5.
That means that any values below 1 represent a slowdown, where any values above 1 would represent a speedup.
When we compare Ruby 3.5 to Ruby 3.4.2 we either disable YJIT on both versions or enable YJIT on both versions.
In other words we compare Ruby 3.5 with Ruby 3.4.2 and Ruby 3.5+YJIT with Ruby 3.4.2+YJIT.</p>

<p>The X axis shows the number of parameters passed to initialize, and the Y axis is the speedup ratio.
The blue bars are positional parameters <em>without</em> YJIT, the green bars are positional parameters <em>with</em> YJIT.
The grey bars are keyword parameters <em>without</em> YJIT, and the yellow bars are keyword parameters <em>with</em> YJIT.</p>

<p>First, we can see that all bars are above 1, meaning that every allocation type is faster on Ruby 3.5 than on Ruby 3.4.2.
Positional parameters have a constant speedup ratio regardless of the number of parameters.</p>

<h3 id="positional-parameter-comparison">Positional Parameter Comparison</h3>

<p>For positional parameters the speedup ratio remains constant regardless of the number of parameters.
Without YJIT, Ruby 3.5 is always about 1.8x faster than Ruby 3.4.2.
When we enable YJIT, Ruby 3.5 is always about 2.3x faster.</p>

<h3 id="keyword-parameter-comparison">Keyword Parameter Comparison</h3>

<p>Keyword parameters are a little more interesting.
For both the interpreter and YJIT, as the number of keyword parameters increases, the speedup ratio also increases.
In other words, the more keyword parameters used, the more effective this change is.</p>

<p>With just 3 keyword parameters passed to initialize, Ruby 3.5 is 3x faster than Ruby 3.4.2, and if we enable YJIT it’s over 6.5x faster.</p>

<h2 id="bottlenecks-in-classnew">Bottlenecks in Class#new</h2>

<p>I’ve been interested in speeding up allocations, and thus <code>Class#new</code> for a while.
But what made it slow?</p>

<p><code>Class#new</code> is a very simple method.
All it does is allocate an instance, pass all parameters to <code>initialize</code>, and then return the instance.
If we were to implement <code>Class#new</code> in Ruby, it would look something like this:</p>

<div><div><pre><code><span>class</span> <span>Class</span>
  <span>def</span> <span>self</span><span>.</span><span>new</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span> <span>=</span> <span>allocate</span>
    <span>instance</span><span>.</span><span>initialize</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The implementation has two main parts.
First, it allocates a bare object with <code>allocate</code>,
and second it calls the <code>initialize</code> method, forwarding all parameters <code>new</code> received.
So to speed up this method, we can either speed up object allocation, or speed up calling out to the <code>initialize</code> method.</p>

<p>Speeding up <code>allocate</code> means speeding up the garbage collector, and while there are merits to doing that, I wanted to focus on the runtime side of the equation.
That means trying to decrease the overhead of calling out to another method.
So what makes a method call slow?</p>

<h2 id="calling-ruby-methods-from-ruby">Calling Ruby methods from Ruby</h2>

<p>Ruby’s virtual machine, YARV, uses a stack as a scratch space for processing values.
We can think of this stack as a really large heap allocated array.
Every time we process a YARV instruction, we’ll read or write to this heap allocated array.
This is also true for passing parameters between functions.</p>

<p>When we call a function in Ruby, the caller pushes parameters to the stack before the call is made to the callee.
The callee then reads its parameters from the stack, does any processing it needs, and returns.</p>

<div><div><pre><code><span>def</span> <span>add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
  <span>a</span> <span>+</span> <span>b</span>
<span>end</span>

<span>def</span> <span>call_add</span>
  <span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>For example in the above code, the caller <code>call_add</code> will push the arguments <code>1</code> and <code>2</code> to the stack before calling the <code>add</code> function.
When the <code>add</code> function reads its parameters in order to perform the <code>+</code>, it reads <code>a</code> and <code>b</code> from the stack.
The values pushed by the caller become the parameters for the callee.
You can see this in action in our recent <a href="https://railsatscale.com/2025-05-14-merge-zjit/">post about Launching ZJIT</a>.</p>

<p>This “calling convention” is convenient because the arguments pushed to the stack don’t need to be copied anywhere when they become the parameters to the callee.
If you examine the memory addresses for where 1 and 2 are stored, you’ll see that they are the same addresses used for the values of <code>a</code> and <code>b</code>.</p>

<h2 id="calling-c-methods-from-ruby">Calling C methods from Ruby</h2>

<p>Unfortunately C functions do not use the same calling convention as Ruby functions.
That means when we call a C function from Ruby, or a Ruby function from C, we must convert method parameters to their respective calling convention.</p>

<p>In C, parameters are passed via registers or machine stack.
This means that when we call a C function from Ruby, we need to copy values from the Ruby stack into registers.
Or when we call a Ruby function from C, we must copy register values to the Ruby stack.</p>

<p>This conversion between calling conventions takes some time, so this is a place we can target for optimization.</p>

<p>When calling a C function from Ruby, positional parameters can be directly copied to registers.</p>

<div><div><pre><code><span>static</span> <span>VALUE</span>
<span>foo</span><span>(</span><span>VALUE</span> <span>a</span><span>,</span> <span>VALUE</span> <span>b</span><span>)</span>
<span>{</span>
  <span>return</span> <span>INT2NUM</span><span>(</span><span>NUM2INT</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>NUM2INT</span><span>(</span><span>b</span><span>));</span>
<span>}</span>
</code></pre></div></div>

<div><div><pre><code><span># calls the `foo` C function</span>
<span>foo</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</code></pre></div></div>

<p>In the above example, on ARM64, the parameters <code>a</code> and <code>b</code> will be in the X0 and X1 registers respectively.
When we call the <code>foo</code> function from Ruby, the <a href="https://github.com/ruby/ruby/blob/e0545a02503983e8824d0fb5972c15d51093d927/vm_insnhelper.c#L7252-L7362">parameters can be copied directly to the X0 and X1 registers from the Ruby stack</a>.</p>

<p>Unfortunately the conversion isn’t so simple for keyword parameters.
Since C doesn’t support keyword parameters, we have pass the keyword parameters as a hash to the C function.
This means <a href="https://github.com/ruby/ruby/blob/e0545a02503983e8824d0fb5972c15d51093d927/vm_insnhelper.c#L2724-L2730">allocating a new hash, iterating over the parameters, and setting them in the hash</a>.</p>

<p>We can see this in action with the following program when run on Ruby 3.4.2:</p>

<div><div><pre><code><span>class</span> <span>Foo</span>
  <span>def</span> <span>initialize</span><span>(</span><span>a</span><span>:)</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>measure_allocations</span>
  <span>x</span> <span>=</span> <span>GC</span><span>.</span><span>stat</span><span>(</span><span>:total_allocated_objects</span><span>)</span>
  <span>yield</span>
  <span>GC</span><span>.</span><span>stat</span><span>(</span><span>:total_allocated_objects</span><span>)</span> <span>-</span> <span>x</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>measure_allocations</span> <span>{</span> <span>Foo</span><span>.</span><span>new</span><span>(</span><span>a: </span><span>1</span><span>)</span> <span>}</span>
<span>end</span>

<span># We need to warm the callsite before measurement because inline caches are Ruby</span>
<span># objects, so they will skew our results</span>
<span>test</span> <span># warmup</span>
<span>test</span> <span># warmup</span>
<span>p</span> <span>test</span>
</code></pre></div></div>

<p>If we run the above program with Ruby 3.4.2, we’ll see that the <code>test</code> method allocates 2 objects: and instance of <code>Foo</code>, and a hash for passing the keyword parameters to the C implementation of <code>Class#new</code>.</p>

<h2 id="achieving-an-allocation-speedup">Achieving an allocation speedup</h2>

<p>I want to start first with a little bit of history.</p>

<p>I’ve been interested in speeding up allocations for quite some time.
We know that calling a C function from Ruby incurs some overhead, and that the overhead depends on the type of parameters we pass.
So my initial inclination was to rewrite <code>Class#new</code> in Ruby.
Since <code>Class#new</code> just forwards all of its parameters to <code>initialize</code>, it seemed quite natural to use the triple-dot forwarding syntax (<code>...</code>).
You can find remnants of my initial implementation <a href="https://github.com/ruby/ruby/pull/9289">here</a>.
Unfortunately I found that using <code>...</code> was quite expensive because at the time, it was syntactic sugar for <code>*, **, &amp;</code>, and Ruby would allocate extra objects to represent these splat parameters.</p>

<p><a href="https://github.com/ruby/ruby/pull/10510">This lead me to implement an optimization for <code>...</code></a>.
The optimization for <code>...</code> allowed us to use parameter forwarding without allocating any extra objects.
I think this optimization is useful in general, but what I had in mind was using it for <code>Class#new</code>.
Fast forward some months, and I was able to <a href="https://github.com/ruby/ruby/pull/9289/files#diff-919ef5932e2ffb97a00a90eb06036b733c6d26cf69cc13014a3ac174bd351fde">implement <code>Class#new</code> in Ruby with this new optimization</a>.
The initial benchmarks were decent, it eliminated allocations and decreased the cost of passing parameters from <code>new</code> to <code>initialize</code>.
But I was somewhat worried about inline cache misses <a href="https://github.com/ruby/ruby/pull/9289/files#diff-919ef5932e2ffb97a00a90eb06036b733c6d26cf69cc13014a3ac174bd351fdeR7">at this call site</a>.</p>

<p>The <code>Class#new</code> implementation linked to above is a little complex, but if we boil it down, it’s essentially the same as the <code>Class#new</code> implementation we saw at the beginning of the post:</p>

<div><div><pre><code><span>class</span> <span>Class</span>
  <span>def</span> <span>self</span><span>.</span><span>new</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span> <span>=</span> <span>allocate</span>
    <span>instance</span><span>.</span><span>initialize</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The problem with the above code is the inline cache at the <code>initialize</code> call site.
When we make method calls, Ruby will try to cache the destination of that call.
That way we can speed up subsequent calls on the same type at that call site.</p>

<p>CRuby only has a monomorphic inline cache, meaning it can only store one inline cache at any particular call site.
The inline cache is used to help look up the method we will call, and the key to the cache is the class of the receiver (in this case, the class of the <code>instance</code> local variable).
Each time the type of the receiver changes, the cache misses, and we have to do a slow path lookup of the method.</p>

<p>It’s very rare for code to allocate exactly the same type of object many times in a row, so the class of the <code>instance</code> local variable will change quite frequently.
Meaning we could potentially have very poor cache hit rates.
Even if the call site could support multiple cache entries (a “polymorphic” inline cache), the cardinality at this particular call site would be so high that cache hit rates would still be quite poor.</p>

<p>I showed this PR to <a href="https://github.com/ko1">Koichi Sasada</a> (author of YARV), and he suggested that instead of implementing <code>Class#new</code> in Ruby, we add a new YARV instruction and “inline” the implementation of <code>Class#new</code>.
I worked with <a href="https://github.com/jhawthorn">John Hawthorn</a> to implement it and we had a prototype implementation done within a week.
Fortunately (or unfortunately) this prototype turned out to be <em>much</em> faster than a Ruby implementation of <code>Class#new</code>, so I decided to abandon that effort.</p>

<h3 id="inlining-classnew">Inlining <code>Class#new</code></h3>

<p>So what is inlining?
Inlining is pretty much just copy / pasting code from the callee to the caller.</p>



<p>Any time the compiler sees code like the above, instead of generating a simple method call to <code>new</code>, it generates the instructions that <code>new</code> <em>would have used</em> but at the call site of <code>new</code>.</p>

<p>To make this more concrete, lets look at the instructions for the above code before and after inlining.</p>

<p>Here is the bytecode for <code>Foo.new</code> before inlining:</p>

<div><div><pre><code>&gt; ruby -v --dump=insns -e&#39;Foo.new&#39;
ruby 3.4.2 (2025-02-15 revision d2930f8e7a) +PRISM [arm64-darwin24]
== disasm: #&lt;ISeq:&lt;main&gt;@-e:1 (1,0)-(1,7)&gt;
0000 opt_getconstant_path                   &lt;ic:0 Foo&gt;                (   1)[Li]
0002 opt_send_without_block                 &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;
0004 leave
</code></pre></div></div>

<p>Here is the bytecode for <code>Foo.new</code> after inlining:</p>

<div><div><pre><code>&gt; ./ruby -v --dump=insns -e&#39;Foo.new&#39;
ruby 3.5.0dev (2025-04-29T20:36:06Z master b5426826f9) +PRISM [arm64-darwin24]
== disasm: #&lt;ISeq:&lt;main&gt;@-e:1 (1,0)-(1,7)&gt;
0000 opt_getconstant_path                   &lt;ic:0 Foo&gt;                (   1)[Li]
0002 putnil
0003 swap
0004 opt_new                                &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;, 11
0007 opt_send_without_block                 &lt;calldata!mid:initialize, argc:0, FCALL|ARGS_SIMPLE&gt;
0009 jump                                   14
0011 opt_send_without_block                 &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;
0013 swap
0014 pop
0015 leave
</code></pre></div></div>

<p>Before inlining, the instructions look up the constant <code>Foo</code>, then call the <code>new</code> method.
After inlining, we still look up the constant <code>Foo</code>, but instead of calling the <code>new</code> method, there are a bunch of other instructions.</p>

<p>The most important of these new instructions is the <code>opt_new</code> instruction which allocates a new instance and writes that instance to the stack.
Immediately after the <code>opt_new</code> instruction we see a method call to <code>initialize</code>.
These instructions effectively allocate a new instance and call initialize on that instance, the same thing that <code>Class#new</code> <em>would</em> have done, but without actually calling <code>Class#new</code>.</p>

<p>What’s really nice about this is that any parameters pushed onto the stack <em>are left on the stack</em> for the <code>initialize</code> method to consume.
Where we had to do copies in the C implementation, there are no longer any copies!
Additionally, we no longer push and pop a stack frame for <code>Class#new</code> which further speeds up our code.</p>

<p>Finally, since every call to <code>new</code> includes another call to <code>initialize</code> we have very good cache hit rates compared to the pure Ruby implementation of <code>Class#new</code>.
Rather than <em>one</em> <code>initialize</code> call site, we have an <code>initialize</code> call site at every call to <code>new</code>.</p>

<p>Eliminating a stack frame, eliminating parameter copies, and improving inline cache hits are the major advantages of this optimization.</p>

<h3 id="downsides-to-inlining">Downsides to Inlining</h3>

<p>Of course this optimization is not without downsides.</p>

<p>First, there are more instructions, so it requires more memory usage.
However, this memory increase only grows in proportion to the number of call sites that use <code>new</code>.
We measured this in our monolith and only saw a 0.5% growth in instruction sequence size, which is an even smaller percentage of overall heap size.</p>

<p>Second, this optimization introduces a small backwards incompatibility.
Consider the following code:</p>

<div><div><pre><code><span>class</span> <span>Foo</span>
  <span>def</span> <span>initialize</span>
    <span>puts</span> <span>caller</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>Foo</span><span>.</span><span>new</span>
<span>end</span>

<span>test</span>
</code></pre></div></div>

<p>If we run this code with Ruby 3.4, the output is like this:</p>

<div><div><pre><code>&gt; ruby -v test.rb
ruby 3.4.2 (2025-02-15 revision d2930f8e7a) +PRISM [arm64-darwin24]
test.rb:8:in &#39;Class#new&#39;
test.rb:8:in &#39;Object#test&#39;
test.rb:11:in &#39;&lt;main&gt;&#39;
</code></pre></div></div>

<p>If we run this code with Ruby 3.5, the output is like this:</p>

<div><div><pre><code>&gt; ./ruby -v test.rb
ruby 3.5.0dev (2025-04-29T20:36:06Z master b5426826f9) +PRISM [arm64-darwin24]
test.rb:8:in &#39;Object#test&#39;
test.rb:11:in &#39;&lt;main&gt;&#39;
</code></pre></div></div>

<p>The <code>Class#new</code> frame is missing from Ruby 3.5 and that is because the frame has been eliminated.</p>

<h2 id="conclusion">Conclusion</h2>

<p>If you’ve made it this far, I hope you found the topic interesting.
I’m really excited for Ruby 3.5 to be released later this year, and I hope you are too!
I want to thank Koichi Sasada for suggesting inlining (and the <code>opt_new</code> instruction) and John Hawthorn for helping me with the implementation.</p>

<p>If you’re curious, take a look at the implementation in the <a href="https://github.com/ruby/ruby/pull/13080">pull request</a> and the discussion in the <a href="https://bugs.ruby-lang.org/issues/21254">RedMine ticket</a>.
I didn’t explain every detail of this patch (for example, what happens if you’re calling <code>new</code> on something that isn’t a class?) so if you have questions don’t hesitate to email me or ask on social media.</p>

<p>Have a good day!</p>

  </div>
</article>

      </div>
    </div></div>
  </body>
</html>
