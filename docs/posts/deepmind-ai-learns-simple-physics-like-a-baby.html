<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/d41586-022-01921-7">Original</a>
    <h1>DeepMind AI learns simple physics like a baby</h1>
    
    <div id="readability-page-1" class="page"><div>
                    <figure>
 <div>
  <p><img alt="Baby with building blocks." data-src="//media.nature.com/lw800/magazine-assets/d41586-022-01921-7/d41586-022-01921-7_23255400.jpg"/></p><figcaption>
   <p><span>Even young babies are aware of the basic physics of everyday objects.</span><span>Credit: Getty</span></p>
  </figcaption>
 </div>
</figure><p>Inspired by research into how infants learn, computer scientists have created a program that can learn simple physical rules about the behaviour of objects — and express surprise when they seem to violate those rules. The results were published on 11 July in <i>Nature Human Behaviour</i><sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>.</p><p>Developmental psychologists test how babies follow the motion of objects by tracking their gaze. When shown a video of, for example, a ball that suddenly disappears, the children express surprise, which researchers measure by how long they stare in a particular direction.</p><p>Luis Piloto, a computer scientist at Google-owned company DeepMind in London, and his collaborators wanted to develop a similar test for artificial intelligence (AI). The team trained a neural network — a type of software system that learns by spotting patterns in large amounts of data — with animated videos of simple objects such as cubes and balls.</p><p>The software model, named Physics Learning through Auto-encoding and Tracking Objects (PLATO), was fed the raw images from the videos, but also versions that highlighted each object in the scene. PLATO was designed to develop an internal representation of physical properties of the objects, such as their positions and velocities.</p><p>The system was trained on around 30 hours of videos showing simple mechanisms such as a ball rolling down a slope or two balls bouncing off each other, and developed the ability to predict how those objects would behave in different situations. In particular, it learnt patterns such as continuity, in which an object follows an uninterrupted trajectory rather than magically teleporting from one place to another; solidity, which prevents two objects from penetrating each other; and persistence of the objects’ shape. “At every step of a movie, it makes a prediction” about what will happen next, Piloto says. “As it gets further into the movie, the prediction becomes more accurate.”</p><h2>Surprise!</h2><p>When shown videos with ‘impossible’ events, such as an object suddenly disappearing, PLATO could measure the difference between the video and its own prediction, providing a measure of surprise.</p><p>Piloto says that PLATO is not designed as a model of infant behaviour, but that it could be a first step towards AI that can test hypotheses about how human babies learn. “We’re hoping this can eventually be used by cognitive scientists to seriously model the behaviour of infants.”</p><p>Comparing AI with how human infants learn is “an important research direction”, says Jeff Clune, a computer scientist at the University of British Columbia in Vancouver. “That said, the paper does hand-design much of the prior knowledge that gives these AI models their advantage.”</p><p>Clune and other researchers are working on approaches in which the program develops its own algorithms for understanding the physical world.</p>
                </div><div><p>Read the related News &amp; Views, ‘<a href="https://doi.org/10.1038/s41562-022-01395-7" data-track="click" data-label="https://doi.org/10.1038/s41562-022-01395-7" data-track-category="body text link">Can a computer think like a baby?</a>’</p></div></div>
  </body>
</html>
