<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://typesanitizer.com/blog/complexity-definitions.html">Original</a>
    <h1>Meta-analysis of three different notions of software complexity</h1>
    
    <div id="readability-page-1" class="page"><article>
          <section>
	          
<p>I want to discuss three different notions of software complexity:</p>
<ul>
<li>Rich Hickeyâ€™s notion of complexity, as explained in his talk <a href="https://www.youtube.com/watch?v=SxdOUGdseq4"><em>Simple Made Easy</em></a>.</li>
<li>John Ousterhoutâ€™s notion of complexity, as explained in his book <em>A Philosophy of Software Design</em>.</li>
<li>Zach Tellmanâ€™s notion of complexity, as explained in his newsletter <a href="https://explaining.software/archive/"><em>Explaining Software Design</em></a>.</li>
</ul>
<p>Iâ€™ve picked these three because Iâ€™ve found them to be at least somewhat coherent,
and the former two to be (relatively) well-known;
this blog post is not meant to be exhaustive
of all different definitions of complexity that have been
offered over the years.</p>
<!-- This post has two main parts: -->
<!-- 1. A summary of the different definitions, along with short summaries -->
<!--    of the examples given by the original authors of the definitions. -->
<!-- 2. A series of examples of pairs of software designs A and B, -->
<!--    such that the different definitions potentially disagree on which of A and B is more complex. -->
<h2 id="the-definitions-summarized">The definitions summarized</h2>
<p>(Formatting note: exact quotes are taken from the above-mentioned work.)</p>
<h3 id="hickey-complexity">Hickey complexity</h3>
<p>Hickey defines something as being simple as having some kind of oneness - he uses the phrases â€œone fold/braid, one role, one task, one concept, one dimension.â€ Hickey states, â€œWhen youâ€™re looking for something simple, you want to see it have focus in these areas. You donâ€™t want to see it combining things.â€</p>
<p>Hickey contrasts â€˜easyâ€™ with â€˜simpleâ€™. For â€˜easyâ€™, the central idea is proximity â€“ in terms of access (e.g.Â already having something be installed, being able to easily install something), in terms of existing skills and capabilities, and so on. Hickey points out that â€˜easyâ€™ is subjective, because it is relative to the person making the judgement.</p>
<p>As one example here, Hickey states that the parentheses in Clojure are hard (i.e.Â the opposite of easy) but simple, and that <a href="https://gist.github.com/typesanitizer/e828f909faf22beeeedf208ba58b259b#file-transcript-txt-L267-L292">it is usersâ€™ responsibility</a> to fix this.</p>
<p>On the other hand, Hickey states that this notion of simplicity is objective, â€œwe can probably go and look and see, I donâ€™t see any connections, I donâ€™t see where this twists with something else.â€</p>
<p>Hickey stresses the difference between simplicity and low cardinality (â€œBut not: One instance, one operation.â€). He points out that the important thing is â€œlack of interleaving, not cardinality.â€</p>
<p>Hickey sums up his argument against complexity as follows:</p>
<ul>
<li>â€œWe can only hope to make reliable those things we can understandâ€</li>
<li>â€œWe can only consider a few things at a timeâ€</li>
<li>â€œIntertwined things must be considered togetherâ€</li>
<li>â€œComplexity undermines understandingâ€</li>
</ul>
<p>According to Hickey, simplicity has the following benefits:</p>
<ul>
<li>Ease of understanding</li>
<li>Ease of change</li>
<li>Easier debugging</li>
<li>Flexibility</li>
</ul>
<p>In terms of examples, Hickey has a few slides in his presentation
with some tables. The table below is a more condensed representation
of Hickeyâ€™s tables:<span><label for="sn-0"></label><span>I may have misunderstood something; corrections welcome.</span></span></p>
<table>
<thead>
<tr>
<th>Complexity</th>
<th>Complects</th>
<th>Simpler alternative</th>
</tr>
</thead>
<tbody>
<tr>
<td>State, objects</td>
<td>Everything that touches it</td>
<td>Values</td>
</tr>
<tr>
<td>Objects</td>
<td>State, identity, value</td>
<td>Values</td>
</tr>
<tr>
<td>Methods</td>
<td>Function and state, namespaces</td>
<td>Functions, namespaces</td>
</tr>
<tr>
<td>Variables</td>
<td>Value, time</td>
<td>Managed refs</td>
</tr>
<tr>
<td>Inheritance</td>
<td>Types</td>
<td>Polymorphism a la carte</td>
</tr>
<tr>
<td>Switch/matching</td>
<td>Multiple who/what pairs</td>
<td>Polymorphism a la carte</td>
</tr>
<tr>
<td>Syntax</td>
<td>Meaning, order</td>
<td>Data</td>
</tr>
<tr>
<td>Imperative loops, fold</td>
<td>what/how</td>
<td>Set functions</td>
</tr>
<tr>
<td>Actors</td>
<td>what/who</td>
<td>Queues</td>
</tr>
<tr>
<td>Variables</td>
<td>Value, time</td>
<td>Values</td>
</tr>
<tr>
<td>ORM</td>
<td>OMG</td>
<td>Declarative data manipulation</td>
</tr>
<tr>
<td>Conditionals</td>
<td>Why, rest of program</td>
<td>Rules</td>
</tr>
</tbody>
</table>
<p>As one example, Hickey points out that â€œhaving state in your program is never simpleâ€
and â€œThe only time you can really get rid of it,
is it you present a functional interface on the outside,
a true functional interface, same input, same output.â€</p>
<p>Hickey contrasts the words â€œcomplectâ€ (to intertwine, interleave, braid)
and â€œcomposeâ€ (to place together).</p>
<h3 id="ousterhout-complexity">Ousterhout complexity</h3>
<p>According to Ousterhout, â€œComplexity is anything related to the structure
of a software system that makes it hard to understand
and modify the system.â€ (Sec 2.1)</p>
<!-- [^sn-defn-scope]: Ousterhout prefixes this definition with â€œFor the purposes of this book, I define 'complexity' in a practical way.â€; so it seems reasonable to assume that he would be open to alternate definitions of software complexity in alternate contexts. -->
<p>A closely related aspect is obviousness;
a system is considered to be obvious if
â€œa developer can quickly understand how the existing code works
and what is required to make a changeâ€
and they â€œcan make a quick guess about what to do,
without thinking very hard,
and yet be confident that the guess is correctâ€ (Sec 2.2)
as well as â€œtheir first guesses about the behavior or
meaning of the code will be correctâ€ (Ch. 18)
Ousterhout points out that obviousness is one
of the most important goals for system design;
and that obviousness is the opposite of high cognitive load
and unknown unknowns (see definitions below).
<!-- [^sn-correctness] -->
In Chapter 18, Ousterhout emphasizes the obviousness
is â€œin the mind of the readerâ€ and that
â€œIf someone reading your code says itâ€™s not obvious,
then itâ€™s not obvious, no matter how clear it may seem to you.â€</p>
<!-- [^sn-correctness]: Given that Ousterhout considers obviousness to be opposed to unknown unknowns, what Ousterhout likely means in his definition of "obvious" is that the developer's quick guess ought to be _correct_ (and not merely that they have the _confidence_ that it is correct). This bit about "guesses being correct" is covered in some parts of the book. -->
<p>â€œComplexity is caused by two things: dependencies and obscurityâ€ (Sec 2.3) which are defined as:</p>
<ul>
<li>â€œA dependency exists when a given piece of code cannot be understood and modified in isolation; the code relates in some way to other code, and the other code must be considered and/or modified if the given code is changedâ€.
<ul>
<li><p>According to Ousterhout, dependencies are a â€œfundamental part of software and canâ€™t be completely eliminatedâ€
but â€œone of the goals of software design is to reduce the number of dependencies
and to make the dependencies that remain as simple and obvious as possible.â€</p>
<p>Ousterhout gives an example of a web site design, where specifying the background color
for banners on individual pages creates an implicit dependency across pages.
In that situation, factoring out the background color into a central location
(e.g.Â by referencing a CSS variable) amounts to replacing a
â€œnonobvious and difficult-to-manage dependency with a simpler and more obvious one.â€</p></li>
</ul></li>
<li>â€œObscurity occurs when important information is not obvious.â€ Ousterhout identifies that the following as being associated with obscurity:
<ul>
<li>Generic variable names which donâ€™t carry much useful information</li>
<li>Dependencies whose existence is not obvious
(Ousterhout gives the example of a new error status being added,
which may require modifying a table of strings for messages)</li>
<li>Inconsistency (e.g.Â reusing the same variable name for different purposes)</li>
<li>â€œInadequate documentationâ€ (although, Ousterhout adds a cautionary note
â€œIf a system has a clean and obvious design, then it will need less documentation.
The need for extensive documentation is often a red flag that the design isnâ€™t quite rightâ€)</li>
</ul></li>
</ul>
<p>Ousterhout states that complexity has three different manifestations or symptoms:</p>
<ul>
<li>â€œChange amplification: The first symptom of complexity is that a seemingly simple change
requires code modifications in many different places.â€
<ul>
<li>This is where Ousterhout introduces the web site example,
where the original version of the web site suffers
from change amplification when the bannerâ€™s background color needs to be changed.</li>
</ul></li>
<li>â€œCognitive load [..] which refers to how much a developer needs to know in order to complete a task.
A higher cognitive load means that developers have to spend more time
learning the required information,
and there is a greater risk of bugs because they have missed something importantâ€</li>
<li>â€œUnknown unknowns: it is not obvious which pieces of code must be modified to complete a task,
or what information a developer must have to carry out the task successfullyâ€</li>
</ul>
<hr/>
<p>Commentary:</p>
<p>The somewhat circular nature and similarity of the definitions makes it hard to understand what the differences between the various terms are. In particular:</p>
<ul>
<li>Non-obviousness is considered to comprise of two aspects â€“ high cognitive load and unknown unknowns.</li>
<li>When discussing the two causes of complexity:
<ul>
<li>The discussion on dependencies itself reuses the terms â€œsimpleâ€ (opp. complex) and â€œobviousâ€.</li>
<li>The definition of obscurity uses â€œnot obviousâ€.</li>
</ul></li>
<li>Out of the three manifestations of complexity:
<ul>
<li>The definition of change amplification uses the phrase â€œseemingly simpleâ€</li>
<li>The definition of unknown unknowns refers to non-obviousness.</li>
</ul></li>
</ul>
<p>In visual form:</p>
<p><img src="https://typesanitizer.com/blog/assets/aposd-definitions.svg" alt="Dependencies between definitions in &#39;A Philosophy of Software Design&#39;"/></p>
<p>As one specific thing, itâ€™s weird for one of the purported <em>causes</em> of complexity to be
<em>defined</em> in terms of one of the <em>symptoms</em> of complexity.
For example, if we think about diseases,
it would be weird for one of the potential causes for a disease to be defined in
terms of one of the symptoms of the same disease.</p>
<p>Of course, this doesnâ€™t mean that Ousterhoutâ€™s points are wrong or meaningless.
If youâ€™d said the same things to me in a conversation, I could probably understand what youâ€™re getting at.
But from the point of view of defining things, or as a framework,
I think these points could be better organized
to make operationalizing them easier.</p>
<!-- If we attempt to be more precise about what Ousterhout is trying to express, -->
<!-- and break things down into smaller components, perhaps we arrive at: -->
<!-- - Awareness: Knowledge about the existence of the piece of information. -->
<!-- - Connectability: The ability to determine whether the information is relevant to the current task. -->
<!-- - Velocity: Speed of accessing the piece of information. -->
<!-- - Quantity: How much information (e.g. how much documentation one has to read). -->
<!-- - Guessability: The speed and correctness of guessing the information. -->
<!-- - Understandability: The speed and correctness of understanding the information, after having obtained it. -->
<!-- Framing Ousterhout's terms using these: -->
<!-- - 'high cognitive load' corresponds to high quantity and low understandability. -->
<!-- - 'unknown unknowns' corresponds to low awareness -->
<!-- - 'obviousness' corresponds to low guessability -->
<!-- If the amount of task-relevant information  -->
<!-- If we unpack this a bit, the more "basic" things of interest are: -->
<!-- - Task-relevance of information -->
<!-- - Amount of information that is task-relevant,  -->
<!-- -  -->
<!-- - If obviousness is _one aspect_ (sub-part) of simplicity, then calling a dependency "simple and obvious" is redundant. -->
<!-- - If by definition, obviousness is the opposite of "high cognitive load" and "unknown unknowns", -->
<!--   then the lack of obviousness (in dependencies or important information) cannot be the _cause_ for the latter. -->
<!--   If the sun is shining and the curtains in a room have been drawn, the sunlight coming in causes the room to be -->
<!--   well-lit, not the absence of darkness. -->
<!-- - Are dependencies "important information"? If yes, is the aspect of dependencies not being "simple and obvious" merely a subset of obscurity ("important information is not non-obvious")? -->
<!-- - Is it possible to have a system with dependencies that are not "simple and obvious" and yet the system is not "obscure" (i.e. does complexity and ) -->
<!-- -  -->
<!-- For example: if  -->
<!-- It is a bit hard to understand what exactly  -->
<!-- If the quantity of task-relevant information you need to known is low, then the system cannot be said to have "high cognitive load". -->
<!-- then the system can be said to be "obvious." -->
<!-- - Amount of information needed to understand -->
<!-- - Time to understand the information -->
<!-- - Task-relevance of information -->
<!-- Dependencies exist on a spectrum. -->
<!-- - Dependencies can have varying levels of being "quickly understandable [..]" -->
<!-- - Dependencies can have varying levels of complexity -->
<!-- Information about a system can have: -->
<!-- - Varying levels of importance -->
<!-- Out of this, if important information is not "quickly understandable [..]", then the system is said to be non-obvious. -->
<!-- Non-obviousness can be categorized into two types: -->
<!-- High cognitive load but low unknown unknowns -- is that possible? -->
<!-- Low cognitive load but high unknown unknowns -- is that possible? -->
<!-- System design can be divided into two buckets: -->
<!-- - Obvious -->
<!-- - Non-obvious - Two ways: "High cognitive load" (quantity of information needed) and "Unknown unknowns" (unclear what information is needed) -->
<!-- > â€œOf the three manifestations of complexity, unknown unknowns are the worst. An unknown unknown means that there is something you need to know, but there is no way for you to find out what it is, or even whether there is an issue. You wonâ€™t find out about it until bugs appear after you make a change. Change amplification is annoying, but as long as it is clear which code needs to be modified, the system will work once the change has been completed. Similarly, a high cognitive load will increase the cost of a change, but if it is clear which information to read, the change is still likely to be correct. With unknown unknowns, it is unclear what to do or whether a proposed solution will even work. The only way to be certain is to read every line of code in the system, which is impossible for systems of any size. Even this may not be sufficient, because a change may depend on a subtle design decision that was never documentedâ€ -->
<!-- â€œthe greatest limitation in writing software is our ability to understand the systems we are creating. As a program evolves and acquires more features, it becomes complicated, with subtle dependencies between its components. Over time, complexity accumulates, and it becomes harder and harder for programmers to keep all of the relevant factors in their minds as they modify the system. This slows down development and leads to bugs, which slow development even more and add to its cost. Complexity increases inevitably over the life of any program. The larger the program, and the more people that work on it, the more difficult it is to manage complexityâ€ -->
<!-- â€œGood development tools can help us deal with complexity, and many great tools have been created over the last several decades. But there is a limit to what we can do with tools aloneâ€ -->
<!-- â€œComplexity will still increase over time, in spite of our best efforts, but simpler designs allow us to build larger and more powerful systems before complexity becomes overwhelmingâ€ -->
<h3 id="tellman-complexity">Tellman complexity</h3>
<p>Tellman offers the following definition of complexity: â€œThe sum of every explanation. Weighted heavily towards future explanations. Measured in bits, but only relative to your audienceâ€™s expectations.â€</p>
<p>Here, â€˜explanationâ€™ is defined as: â€œThe core task of software development. When we try to understand software, we explain it to ourselves. When we change software, we explain it to others.â€</p>
<p>So the word â€˜explanationâ€™ is used in both a concrete and somewhat more abstract sense â€“ the concrete sense applies to things like pull request descriptions, code comments, and commit messages, whereas the more abstract sense applies to actions such as reading and debugging.</p>
<p>Tellman also uses a distinct term â€˜surprisalâ€™ across several posts, such as this phrasing in the newsletterâ€™s original post: â€œthe information conveyed by a message, its surprisal, depends on its audience. For something to be surprising, it must be unexpected. And so, simplicity is not intrinsic; it does not arise from our codeâ€™s size or syntax. Simplicity is a fitness between software and our expectations.â€</p>
<p>Tellman also introduces several other concepts in his newsletter,
such as the three different parts of an explanation:</p>
<ol type="1">
<li>The prefix is what your audience already knows, and is unstated.</li>
<li>The content is the code, diagrams etc. that comprise your explanation in the now.</li>
<li>The suffix is what you expect youâ€™ll explain in the future.</li>
</ol>
<p>Tellman defines coupling as
â€œthe degree to which two things tend to be explained togetherâ€,
and that coupling has both costs and benefits â€“
the cost being that the coupled concepts need to be explained together,
and the benefit being that each concept offers some explanatory power
for the other.</p>
<hr/>
<p>Commentary:</p>
<p>I reached out to Tellman before writing this post for some clarifications.
According to him, his definition of complexity largely coincides with Ousterhoutâ€™s.
I technically agree with this point, but I believe that there is a noticeable
difference in the overall notion if you consider the entirety of the published work.
I cover this in more detail in the next section.</p>
<h2 id="comparing-the-three-different-notions-of-complexity">Comparing the three different notions of complexity</h2>
<h3 id="subjectivity">Subjectivity</h3>
<p>The first obvious thing that sticks out it is that Hickeyâ€™s definition of â€˜complexâ€™
is put forward as being objective,
whereas both of Ousterhoutâ€™s and Tellmanâ€™s definitions
have more subjectivity to them.</p>
<p>To me, this makes Ousterhoutâ€™s and Tellmanâ€™s definitions more in line
with colloquial usage, where we expect developers being on-boarded to find
things â€œmore complexâ€ but we expect this perception to reduce
as they gain more familiarity.</p>
<p>Although Ousterhout does mention subjectivity in a few parts of the book
(e.g.Â the mentions about code review),
Iâ€™d argue that multiple parts of the book run counter to this point
â€“ in particular, when criticizing (or praising) existing APIs, Ousterhout
spends little-to-no time seriously discussing alternate viewpoints.</p>
<p>For example, when praising the Unix I/O APIs,
there is no discussion of the flaws in the APIs,
or the complexities imposed by the API on applications,
such as when debugging issues.</p>
<p>So the message comes across as a bit muddled.</p>
<p>Tellmanâ€™s writing doesnâ€™t have a lot of concrete code examples,
but given the overall definitions, Iâ€™d consider Tellmanâ€™s notion
of complexity as maximizing the importance of considering
different interpretations of the same artifacts.</p>
<p>Hickey does define â€œeasyâ€ as being subjective,
but according to him,
attempting to maximize that is a non-goal,
and sometimes even counter-productive
â€“ the primary goal should be to minimize the objective
notion of complexity.
Consistent with that, the features he lists as being â€œsimpleâ€
(opp. complex) are notably all features supported by Clojure.
He even goes so far as to point out that it is usersâ€™ responsibility
for fixing issues involving lack of familiarity.<span><label for="sn-1"></label><span>For alternate approaches, see <a href="https://pyret.org/">Pyret</a> and <a href="https://dl.acm.org/doi/pdf/10.1145/3622818">Rhombus</a>, which have come out of the Racket community.</span></span></p>
<h3 id="different-perspectives-on-coupling">Different perspectives on coupling</h3>
<p>Hickey considers â€œcompositionâ€ as good, but â€œcomplectingâ€ as (unconditionally) bad.
However, his framing does not really clarify the distinction
with sufficient substance to be able to apply it to examples outside
of the ones he provides in his presentation.</p>
<p>For example, consider foreign keys in a relational database.
In a sense, using foreign keys across tables â€œcomplectsâ€ the tables
â€“ suddenly, code performing write operations on one table potentially
needs to worry about another table at the same time.
Does that mean that using foreign key relationships is a bad idea
per Hickeyâ€™s definition?</p>
<p>If we apply the same example to Ousterhoutâ€™s notion of complexity,
a foreign key relationship enforced by the database would be
considered a dependency (which generally should be avoided).
However, Ousterhout points out that â€œobviousâ€ dependencies are
better than â€œnon-obviousâ€ ones, so per that, an explicit
foreign key relationship would be better than an implicit one
(if those are the intended semantics).</p>
<p>Tellman on the other hand, doesnâ€™t really ascribe any intrinsic
value judgement to coupling. Rather, he treats it as another tool
in oneâ€™s toolbox. According to Tellmanâ€™s definition of coupling
as co-explanation, the foreign key relationship should be added
if the two tables often need to be explained together
(e.g.Â if the two tables are meant to be joined together,
or data in one needs to be deleted when a row is deleted in the
other table).</p>
<p>As another example, consider <a href="https://www.dynatrace.com/news/blog/what-is-distributed-tracing/">distributed tracing</a>.
Distributed tracing introduces coupling across different parts
of a distributed system, because you need to propagate trace IDs,
collect spans somewhere, be able to query the spans in a flexible way,
etc.</p>
<p>Letâ€™s say you have a system with structured logging, and the question
is under what circumstances does it make sense to also have distributed
tracing.</p>
<p>By its essence, distributed tracing (and generally any kind of observability tooling)
involves a kind of â€œintertwiningâ€ of application code with instrumentation
code. You can make this explicit, such as by passing a â€œtracerâ€ as a parameter
to all the functions which are to be traced, or you can make it implicit
by somehow having tooling which does that for you (e.g.Â by using thread-local
variables, code rewriting tools etc.). But itâ€™s still there.
So per Hickey, should we always avoid adding tracing if we can get away with it?</p>
<p>A Philosophy of Software Design doesnâ€™t talk about debugging much at all.
If we try to extrapolate the ideas on reducing dependencies and preferring
simplicity of implementation, then it also seems like according to Ousterhout,
we should avoid having distributed tracing if we can get away without having it.
OTOH, the original request is in some sense a â€œdependencyâ€ for all subsequent
work it triggers,
so perhaps itâ€™s worth making it explicit (e.g.Â by using distributed tracing
with a unique trace ID per request)?</p>
<p>In contrast, Tellmanâ€™s definition of coupling offers a clear answer in the form
of a question: how often are you finding yourself trying to explain disparate parts of the system
â€“ potentially running on different machines â€“ at the same time?
If youâ€™re doing that often (e.g.Â as part of debugging issues),
then it makes sense to couple the two using the available mechanisms
such as distributed tracing.</p>
<h3 id="competence-floors">Competence floors</h3>
<p>Letâ€™s say you have a team of 4-5 software engineers at work with varying levels of tenure
between 1-7 years and things are going alright
in terms of shipping velocity.</p>
<p>Say thereâ€™s a new engineer who has been hired recently,
and has been assigned tasks of varying levels of difficulty
based on the level they were hired at,
in one subsystem that is under active development/maintenance.</p>
<p>The new programmer has not been able to accomplish many of the tasks assigned to them.
It is near the end of the probationary period,
and a decision needs to be made whether this person should be kept on the team,
or if they should be let go.</p>
<p>Say you are the engineering manager.
You ask the new person why they believe they havenâ€™t able to accomplish many of their assigned tasks.
The new engineer cites the difficulty of understanding and modifying the existing code
as the primary barrier. They state that they would have been able to succeed if:</p>
<ul>
<li>They had received more thorough task descriptions.</li>
<li>They had received more detailed answers to questions posted in the
teamâ€™s Slack channel.</li>
<li>If the code had been written in a simpler way.</li>
</ul>
<p>So in a sense, their response is tied with a notion of software complexity.</p>
<p>How should you, as the engineering manager, factor this perspective into your final decision?</p>
<p>Hickeyâ€™s notion of complexity as an objective thing doesnâ€™t really offer much here.
According to Hickey, either the subsystem the person was assigned to work on
is highly â€œcomplectedâ€ or not, and that should be unambiguous.</p>
<ul>
<li>If the subsystem is highly â€œcomplectedâ€, then according to Hickey,
you should go and simplify it, regardless of whether you decide to keep this person.
But given that other people have been able to work on the same
subsystems just fine, does it make business sense to go
and simplify the subsystem?</li>
<li>If the subsystem is not highly â€œcomplectedâ€, then you have a mismatch
between perceptions and expectations.
Hickeyâ€™s notion of ease captures the subjective experience of unfamiliarity,
such as that during on-boarding. But unfamiliarity can be fixed over time.
So should you chalk down the struggles to unfamiliarity (and hence not think
that they are too important)?</li>
</ul>
<p>On the other hand, I think itâ€™s fair to argue that
Ousterhoutâ€™s description of complexity offers a clearer answer.
If the code is hard to understand and modify,
that means the code is complex, and that is not good.
And the main goal of software design is to reduce complexity.
So this person is a blessing in disguise, because they have
surfaced this complexity to you, and the onus is on you to go
and try to reduce it.</p>
<p>Finally, coming to Tellmanâ€™s ideas about complexity being a measure
of future explanations, I think itâ€™s reasonable to interpret
them as offering you two main choices:</p>
<ul>
<li>You retain the new person and try to make them succeed. In that case:
<ul>
<li>Other engineers will likely have to write more thorough task descriptions,
write longer comments in Slack explaining more details/concepts,
potentially delegate smaller tasks etc.</li>
<li>The code may need additional docs for things which are obvious to
the existing programmers but not to the new programmer
(i.e.Â the unstated â€˜prefixâ€™ needs to become part of the on-going
explanations).</li>
</ul></li>
<li>You let the new person go. In that case:
<ul>
<li>Existing engineers can likely move faster, as they need to do less
hand-holding for the new colleague.</li>
<li>The code will not need additional docs that are useful only to
the new colleague, but not to other people.</li>
<li>You should probably go and reflect on your interview processes to
understand what you couldâ€™ve done to better judge the skills
necessary to succeed at the job.</li>
</ul></li>
</ul>
<p>In essence, this difficult situation is forcing you to better articulate
a competence floor â€“ yes, our system has this minimum baseline of complexity
because of XYZ reasons, and ABC details need to be understood by people
who join the team, because otherwise, the sum of future explanations that
the team needs to make to on-board this person is beyond our â€œexplanation budget.â€
(Yes, I just made up that term.)</p>
<!-- For example, Ousterhout gives an example of how the Java `substring` method -->
<!-- throws an `IndexOutOfBoundsException` if the parameters aren't within the -->
<!-- appropriate bounds. According to Ousterhout, -->
<!-- "This exception is unnecessary and complicates the use" of the method, -->
<!-- and this adds complexity for callers. -->
<!-- He also grounds this suggestion in his personal experience -- -->
<!-- where he often finds that he wants the "clip to end" semantics, -->
<!-- and has to write more code for the edge cases. -->
<h2 id="closing-thoughts">Closing thoughts</h2>
<p>In my mind, the goodness of a conceptâ€™s definition depends on three things:</p>
<ol type="1">
<li>To what extent does the definition line up against the conceptâ€™s instantiation in reality.</li>
<li>To what extent can different people agree on whether something falls under that definition or not.</li>
<li>To what extent can the definition be tested against examples and situations
which were not articulated by the definitionâ€™s author.</li>
</ol>
<p>I think Tellmanâ€™s notion of complexity in terms of explanations is probably
one of the best definitions of software complexity we have today.</p>
<p>It captures the subjective experience of attempting to write software,
both by oneself and with other people.</p>
<p>It is precise, without being over-prescriptive. The related definitions for various terms
â€“ coupling, surprisal, prefix and suffix â€“ crisply capture closely related ideas.</p>
<p>When applied to situations outside of those discussed in the newsletter,
it is not only able to provide a concrete way of thinking,
it is able to illuminate a garden of forking paths,
which is more representative of how real-world decision-making works.</p>
<p>Having a good shared definition for software complexity is essential
if we as an industry are to move beyond the simplistic â€œcomplexity bad, simplicity goodâ€ meme
or the slightly more refined â€œaccidental complexity bad, essential complexity inevitableâ€ meme.<span><label for="sn-2"></label><span>See also: Dan Luu on <a href="https://danluu.com/essential-complexity/"><em>Against essential and accidental complexity</em></a> and Lorin Hochsteinâ€™s more provocatively titled <a href="https://surfingcomplexity.blog/2025/05/31/dijkstra-never-took-a-biology-course/"><em>Dijkstra never took a biology course</em></a>.</span></span></p>
<p>Next time youâ€™re having a discussion with a colleague about complexity,
I encourage you to frame the discussion in terms of what future explanations
you expect to provide, and I suspect youâ€™ll likely end up with a better conversation
than the ones youâ€™ve been having so far. âœŒğŸ½</p>
<!-- I would argue that this is the strength of a good definition, -->
<!-- It offers concrete  -->
<!-- to situations outside of the ones discussed by Tellman -->
<!-- is able to "scale gracefully" -->
<!-- It can be applied to situations outside of the ones discussed by  -->
<!-- The strength of a definition  -->
<!-- ## The  -->
<!-- ## The distinctions -->
<!-- ## Three definitions walk into a bar -->
<!-- A definition is useful iff: -->
<!-- - Different people can understand it, and a -->
<!-- When trying to understand similar-but-distinct definitions, I find it is a useful exercise to try to come up with different examples which do/do not satisfy different definitions. -->
<!-- I'll try to summarize each of these in my own words, and then try to provide examples of pairs of software designs A and B such that these notions would likely be in disagreement. -->
          </section>
        </article></div>
  </body>
</html>
