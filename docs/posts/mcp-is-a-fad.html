<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tombedor.dev/mcp-is-a-fad/">Original</a>
    <h1>MCP is a fad</h1>
    
    <div id="readability-page-1" class="page"><div id="__blog-post-container"><h2 id="overview">Overview<a href="#overview" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>MCP has taken off as the standardized platform for AI integrations, and it&#39;s difficult to justify <em>not</em> supporting it. However, this popularity will be short-lived.</p>
<p>Some of this popularity stems from misconceptions about what MCP uniquely accomplishes, but the majority is due to the fact that it&#39;s <em>very easy</em> to add an MCP server. For a brief period, it seemed like adding an MCP server was a nice avenue for getting attention to your project, which is why so many projects have added support.</p>
<h2 id="what-is-mcp">What is MCP?<a href="#what-is-mcp" aria-label="Direct link to What is MCP?" title="Direct link to What is MCP?" translate="no">​</a></h2>
<p>MCP claims to solve the &#34;NxM problem&#34;: with N agents and M toolsets, users would otherwise need many bespoke connectors.</p>
<h3 id="the-nxm-problem">The NxM problem<a href="#the-nxm-problem" aria-label="Direct link to The NxM problem" title="Direct link to The NxM problem" translate="no">​</a></h3>
<p>A common misconception is that MCP is <em>required</em> for function calling. It&#39;s not. With tool-calling models, a list of available tools is provided to the LLM with each request. If the LLM wants to call a tool, it returns JSON-formatted parameters:</p>
<p><img decoding="async" loading="lazy" alt="function_calling_no_mcp" src="https://tombedor.dev/assets/images/function_calling_no_mcp-3f3ed851f1398f52c8cb7d71d853261f.png" width="3499" height="749"/></p>
<p>The application is responsible for providing tool schemas, parsing parameters, and executing calls. The problem arises when users want to reuse toolsets across different agents, since each has slightly different APIs.</p>
<p>For example, tools are exposed to <a href="https://ai.google.dev/gemini-api/docs/function-calling?example=meeting#rest_2" target="_blank" rel="noopener noreferrer">Gemini&#39;s API</a> via <code>functionDeclarations</code> nested inside a <code>tools</code> array:</p>
<div><div><pre tabindex="0"><code><span><span>curl &#34;https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent&#34; \</span><br/></span><span><span>  -d &#39;{</span><br/></span><span><span>    &#34;contents&#34;: [...],</span><br/></span><span><span>    &#34;tools&#34;: [</span><br/></span><span><span>      {</span><br/></span><span><span>        &#34;functionDeclarations&#34;: [</span><br/></span><span><span>          {</span><br/></span><span><span>            &#34;name&#34;: &#34;set_meeting&#34;,</span><br/></span><span><span>            &#34;description&#34;: &#34;...&#34;,</span><br/></span><span><span>...</span><br/></span></code></pre></div></div>
<p>In <a href="https://platform.openai.com/docs/guides/text?lang=curl" target="_blank" rel="noopener noreferrer">OpenAI&#39;s API</a>, tool schemas use a flat <code>tools</code> array with <code>type: &#34;function&#34;</code>:</p>
<div><div><pre tabindex="0"><code><span><span>curl -X POST https://api.openai.com/v1/responses \</span><br/></span><span><span>  -d &#39;{</span><br/></span><span><span>    &#34;model&#34;: &#34;gpt-4o&#34;,</span><br/></span><span><span>    &#34;input&#34;: [...],</span><br/></span><span><span>    &#34;tools&#34;: [</span><br/></span><span><span>      {</span><br/></span><span><span>        &#34;type&#34;: &#34;function&#34;,</span><br/></span><span><span>        &#34;name&#34;: &#34;get_weather&#34;,</span><br/></span><span><span>...</span><br/></span></code></pre></div></div>
<p>This is the &#34;NxM&#34; problem. In theory, users must build N × M connectors. In practice, the differences are minor (same semantics, slightly different JSON shape), and frameworks like <a href="https://python.langchain.com/docs/how_to/function_calling/" target="_blank" rel="noopener noreferrer">LangChain</a>, <a href="https://docs.litellm.ai/docs/completion/function_call" target="_blank" rel="noopener noreferrer">LiteLLM</a>, and <a href="https://huggingface.co/learn/cookbook/en/agents" target="_blank" rel="noopener noreferrer">SmolAgents</a> already abstract them away. Crucially, these options <em>execute tool calls in the same runtime as the agent</em>.</p>
<h3 id="how-mcp-addresses-it">How MCP addresses it<a href="#how-mcp-addresses-it" aria-label="Direct link to How MCP addresses it" title="Direct link to How MCP addresses it" translate="no">​</a></h3>
<p>MCP handles exposing and invoking tools via separate processes:</p>
<p><img decoding="async" loading="lazy" alt="function_calling_mcp" src="https://tombedor.dev/assets/images/function_calling_mcp-7ddac7e9d3439168d21fdd812a16c8b6.png" width="3633" height="1163"/></p>
<p>A JSON configuration controls which MCP servers to start. Each server runs in its own long-lived process, handling tool invocations independently. The application still orchestrates the agent loop and presents results to users.</p>
<p>This abstracts away schema generation and invocation, but at a cost. Tool logic runs in a separate process, making resource management opaque. The application loses control over tool instructions, logging, and error handling. And every tool call crosses a process boundary.</p>
<h3 id="scope-tools-dominate">Scope: tools dominate<a href="#scope-tools-dominate" aria-label="Direct link to Scope: tools dominate" title="Direct link to Scope: tools dominate" translate="no">​</a></h3>
<p>MCP also defines primitives for prompts and resources, but adoption of these is much smaller than tools<sup><a href="#user-content-fn-1-e0bb36" id="user-content-fnref-1-e0bb36" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>:</p>
<p><img decoding="async" loading="lazy" alt="code_references" src="https://tombedor.dev/assets/images/code_references-4bea4400fa382dec1d99d50df013aa6b.png" width="919" height="908"/></p>
<p>Given this, the rest of this post focuses on tool calling, which is MCP&#39;s primary use case in practice.</p>
<h2 id="problems">Problems<a href="#problems" aria-label="Direct link to Problems" title="Direct link to Problems" translate="no">​</a></h2>
<p>The convenience of MCP comes with a price, stemming from two architectural attributes of an MCP-driven application:</p>
<p><img decoding="async" loading="lazy" alt="issues" src="https://tombedor.dev/assets/images/issues-aacc03230cf0cf8fc4fc94f2ba3c5876.png" width="1851" height="971"/></p>
<p>Since tools are drawn from arbitrary sources, they are not aware of what other tools are available to the agent. Their instructions can&#39;t account for the rest of the toolbox.</p>
<p>The second issue stems from different toolsets having their own runtimes. This introduces a variety of problems I&#39;ll discuss below.</p>
<h3 id="incoherent-toolbox">Incoherent toolbox<a href="#incoherent-toolbox" aria-label="Direct link to Incoherent toolbox" title="Direct link to Incoherent toolbox" translate="no">​</a></h3>
<p><a href="https://www.microsoft.com/en-us/research/video/tool-space-interference-an-emerging-problem-for-llm-agents/" target="_blank" rel="noopener noreferrer">Agents tend to be less effective at tool use as the number of tools grows</a>. With a well-organized, coherent toolset, agents do well. With a larger, disorganized toolset, they struggle. <a href="https://platform.openai.com/docs/guides/function-calling" target="_blank" rel="noopener noreferrer">OpenAI recommends keeping tools well below 20</a>, yet many MCP servers exceed this threshold.</p>
<p>Why does this happen? Consider a workflow in which an agent should send a notification after doing work:</p>
<p><img decoding="async" loading="lazy" alt="confusion" src="https://tombedor.dev/assets/images/confusion-00fa7e3d04a2eae3855e414829b16e58.png" width="2005" height="1001"/></p>
<p>A tool&#39;s fit for a task depends not just on the job at hand, but also on what else is in the toolbox. Pliers can pull a nail, but if a hammer is available it&#39;s probably the better choice. When tools ship in isolation, their instructions can&#39;t say &#34;use me only when you don&#39;t have a hammer,&#34; so agents don&#39;t get cohesive guidance.</p>
<p>If the toolset is controlled by the same authors as the application, they can add prompting to the toolsets to disambiguate when to use which tool. If not, the problem must be solved by system prompts or user guidance.</p>
<p>Looking through #mcp channels of open source coding agents, you&#39;ll invariably find users who struggle to get the agent to use the tools in the way they want<sup><a href="#user-content-fn-2-e0bb36" id="user-content-fnref-2-e0bb36" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>:</p>
<p><img decoding="async" loading="lazy" alt="trouble" src="https://tombedor.dev/assets/images/trouble-e4382a8d6ae0564086624162693e61b6.png" width="3314" height="328"/></p>
<p>Or, users complaining of how many tokens are burned by tool instructions:</p>
<p><img decoding="async" loading="lazy" alt="inefficient" src="https://tombedor.dev/assets/images/inefficient-1abf3d1cad9bdcf5648d9677f6f8c6e1.png" width="2400" height="232"/></p>
<h3 id="arbitrary-separate-runtimes">Arbitrary, separate runtimes<a href="#arbitrary-separate-runtimes" aria-label="Direct link to Arbitrary, separate runtimes" title="Direct link to Arbitrary, separate runtimes" translate="no">​</a></h3>
<p>Each MCP server <a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/lifecycle" target="_blank" rel="noopener noreferrer">starts a separate process</a> that survives for the length of the agent session.</p>
<p>Even in the healthy state, this introduces a collection of processes that remain mostly idle, aside from serving occasional requests from an agent. In an error state, we get all the usual headaches: dangling subprocesses, memory leaks, resource contention.</p>
<p>Users have these issues, if they are able to get the servers running at all: in support channels, the most common complaint is difficulty getting the servers to run:</p>
<p><img decoding="async" loading="lazy" alt="connection_problems" src="https://tombedor.dev/assets/images/connection_problem-7c5e6ede95ca4d7790b0caa5dd27d976.png" width="3196" height="668"/></p>
<p>MCP offers no way for servers to declare their runtime/dependency needs. Some authors work around it by baking installation into the launch command (e.g., <code>uv run some_tool mcp</code>), which only succeeds if the user already has the right tooling installed.</p>
<p>Even if the relevant package is there, the MCP server might not start it successfully. MCP servers only inherit <a href="https://modelcontextprotocol.io/legacy/tools/debugging#environment-variables" target="_blank" rel="noopener noreferrer">a subset of parent ENV variables</a> (<code>USER</code>, <code>HOME</code>, and <code>PATH</code>). This is particularly problematic for <code>nvm</code> or users leveraging virtual environments.</p>
<p>Python or Node developers might be comfortable debugging environment issues, (although MCP&#39;s subprocess orchestration makes this more difficult), but are likely less comfortable debugging Node issues <em>and</em> Python <em>and</em> other runtimes. MCP seems to assert that I as the user should not really care which of these are used, or how many.</p>
<p>Even if toolsets are in one given runtime, MCP potentially spins up many instances of it, obviating efficiencies from caching, connection pooling, and shared in-memory state. MCP&#39;s HTTP transport mode doesn&#39;t help; it&#39;s just another HTTP API, but with MCP&#39;s protocol overhead instead of battle-tested REST/OpenAPI patterns.</p>
<h3 id="security">Security<a href="#security" aria-label="Direct link to Security" title="Direct link to Security" translate="no">​</a></h3>
<p>MCP pushes users to install servers from npm, pip, or GitHub. This inherits the usual supply-chain risk, but without even the minimal guardrails those ecosystems provide. There&#39;s no central publisher or signing; anyone can ship a daemon that runs on your machine and MCP offers no provenance check.</p>
<p>MCP&#39;s specification <a href="https://www.trendmicro.com/vinfo/us/security/news/cybercrime-and-digital-threats/mcp-security-network-exposed-servers-are-backdoors-to-your-private-data" target="_blank" rel="noopener noreferrer">doesn&#39;t mandate authentication</a>, leaving security decisions to individual server authors. The result: <a href="https://www.darkreading.com/vulnerabilities-threats/2000-mcp-servers-security" target="_blank" rel="noopener noreferrer">one scan found 492 MCP servers</a> running without any client authentication or traffic encryption. Even Anthropic&#39;s own Filesystem MCP Server had a sandbox escape via directory traversal (<a href="https://strobes.co/blog/mcp-model-context-protocol-and-its-critical-vulnerabilities/" target="_blank" rel="noopener noreferrer">CVE-2025-53110</a>).</p>

<table><thead><tr><th>Issue</th><th>CVSS / Impact</th></tr></thead><tbody><tr><td><strong><a href="https://jfrog.com/blog/2025-6514-critical-mcp-remote-rce-vulnerability/" target="_blank" rel="noopener noreferrer">CVE-2025-6514</a></strong></td><td>9.6 (RCE in mcp-remote; 437,000+ downloads)</td></tr><tr><td><strong><a href="https://thehackernews.com/2025/07/critical-vulnerability-in-anthropics.html" target="_blank" rel="noopener noreferrer">CVE-2025-49596</a></strong></td><td>9.4 (RCE in Anthropic&#39;s MCP Inspector)</td></tr><tr><td><strong><a href="https://www.imperva.com/blog/another-critical-rce-discovered-in-a-popular-mcp-server/" target="_blank" rel="noopener noreferrer">CVE-2025-53967</a></strong></td><td>RCE in Figma MCP Server; 600,000+ downloads</td></tr><tr><td><strong><a href="https://www.bleepingcomputer.com/news/security/asana-warns-mcp-ai-feature-exposed-customer-data-to-other-orgs/" target="_blank" rel="noopener noreferrer">Asana data exposure</a></strong></td><td>Tenant isolation flaw exposed ~1,000 customers&#39; data</td></tr></tbody></table>
<p>Unlike a human carefully clicking through an API, agents can be manipulated via prompt injection to call tools in unintended ways. The <a href="https://www.generalanalysis.com/blog/supabase-mcp-blog" target="_blank" rel="noopener noreferrer">Supabase MCP leak</a> demonstrated this &#34;lethal trifecta&#34;: prompt injection → tool call → data exfiltration, extracting entire SQL databases including OAuth tokens. Again, this risk isn&#39;t unique to MCP. But the best mitigations are existing security infrastructure: scoped OAuth tokens, service identities with minimal permissions, and audit logging. MCP sidesteps this infrastructure rather than building on it.</p>
<p>A common defense is that MCP isolates credentials—the agent talks to a socket, never seeing your API tokens. But this threat model is narrow: an agent that can invoke <code>mcp.github.delete_repo()</code> doesn&#39;t need your token to cause damage. You&#39;re not eliminating trust; you&#39;re redirecting it to third-party code that, as the CVEs demonstrate, is often unaudited and vulnerable.</p>
<h3 id="the-cost-benefit-doesnt-add-up">The cost-benefit doesn&#39;t add up<a href="#the-cost-benefit-doesnt-add-up" aria-label="Direct link to The cost-benefit doesn&#39;t add up" title="Direct link to The cost-benefit doesn&#39;t add up" translate="no">​</a></h3>
<p>These problems could be worth the cost, if we were to gain significantly. But comparing tool calling with MCP to tool calling without it, MCP handles remarkably little. MCP is, more or less, handling serializing function call schemas and responses.</p>
<p>The tools developers are saving themselves from having to write are, overwhelmingly, <a href="https://mcp.alphavantage.co/?utm_source=mcp.so&amp;utm_medium=referral&amp;utm_campaign=202508&amp;utm_id=000001&amp;utm_term=web_project&amp;utm_content=v2" target="_blank" rel="noopener noreferrer">relatively thin wrappers around API clients</a>, or <a href="https://mcp.so/server/time/modelcontextprotocol" target="_blank" rel="noopener noreferrer">utility scripts</a>. In the former case, users must still obtain API keys, billing accounts, and so on.</p>
<p>This code <em>was</em> a hassle to write, prior to the advent of coding agents. But these small utility scripts are the precise thing that coding agents excel most at! A technical user of MCP tools will be hard-pressed to find a tool an agent could not one-shot in the programming language they are most comfortable in.</p>
<h2 id="why-it-took-off">Why it took off<a href="#why-it-took-off" aria-label="Direct link to Why it took off" title="Direct link to Why it took off" translate="no">​</a></h2>
<p>With these issues, it&#39;s fair to wonder why MCP has gained the popularity it has. It has had lots of support from Anthropic, and no trouble gaining traction with toolset publishers, agent providers, and enterprises. Why? It helps narratives:</p>

<p>It&#39;s quite easy to publish an MCP server. The lack of startup requirements means you don&#39;t even need to publish to <code>npm</code> or <code>pip</code>: you can drop an <code>@mcp.server</code> annotation in your repo and host a small manifest JSON that points to your entry command (e.g., <code>node server.js</code>) and lists the tools.</p>
<p>This provides a nice narrative to gain attention to AI projects: A user can, in theory, easily add some MCP tools from a project, gain value, and follow interest in learning more about the project. Support overhead will, in the main, fall to agent maintainers.</p>
<p>Once publishers started appearing, it became difficult to justify <em>not</em> supporting MCP. Your project could be perceived as being against open standards.</p>
<h3 id="enterprise-ai-credibility">Enterprise: AI credibility<a href="#enterprise-ai-credibility" aria-label="Direct link to Enterprise: AI credibility" title="Direct link to Enterprise: AI credibility" translate="no">​</a></h3>
<p>Over the last few years, anyone watching San Francisco billboards has witnessed enterprise tools rebranding toward AI. MCP support provided an easy way to make your e.g. project management tool be AI. The branding of MCP as an &#34;open standard&#34; increased pressure to adopt - lack of MCP support could signal a lack of willingness to adopt open standards.</p>
<h3 id="anthropic-open-source-credibility">Anthropic: Open source credibility<a href="#anthropic-open-source-credibility" aria-label="Direct link to Anthropic: Open source credibility" title="Direct link to Anthropic: Open source credibility" translate="no">​</a></h3>
<p>MCP&#39;s status as <em>the</em> open standard for AI and the enterprise adoption greatly benefited Anthropic. The big fear of investors is that enterprise adoption doesn&#39;t persist - adoption of Anthropic&#39;s open standard helped this.</p>
<h2 id="alternatives">Alternatives<a href="#alternatives" aria-label="Direct link to Alternatives" title="Direct link to Alternatives" translate="no">​</a></h2>
<h3 id="who-benefits-from-mcp">Who benefits from MCP?<a href="#who-benefits-from-mcp" aria-label="Direct link to Who benefits from MCP?" title="Direct link to Who benefits from MCP?" translate="no">​</a></h3>
<p>There are a few different possible users who interact with MCP:</p>
<p><img decoding="async" loading="lazy" alt="users" src="https://tombedor.dev/assets/images/users-e233d38824dd614cca76cbe6a8e983f0.png" width="1077" height="722"/></p>
<ul>
<li>
<p><em>Technical end users</em> want to create tools and share them between different agents they might want to use.</p>
</li>
<li>
<p><em>Non-technical end users</em> want to use different tools while using agents. Note that this user group for MCP is, at present, largely theoretical. Exposing toolsets to MCP involves editing JSON, making it out of reach for non-technical users.</p>
</li>
<li>
<p><em>Internal app devs</em> run production AI applications.</p>
</li>
<li>
<p><em>Agent devs</em> create agents for external users. They wish to enable their end users to swap in whatever toolsets they like.</p>
</li>
<li>
<p><em>Tool authors</em> create toolsets they wish to expose to users. MCP provides a way to easily share their work to users of different agents.</p>
</li>
</ul>
<p>Notice that the supposed beneficiaries are overwhelmingly technical. The &#34;app store for AI&#34; vision that would serve non-technical users remains unfulfilled.</p>
<p>For each user type, there&#39;s a simpler approach that avoids MCP&#39;s overhead:</p>
<table><thead><tr><th>User Type</th><th>MCP Promise</th><th>Better Alternative</th><th>Why</th></tr></thead><tbody><tr><td><strong>Technical end users</strong></td><td>Share tools between agents</td><td>Local scripts + command runner</td><td>AI can one-shot these scripts; works with any agent via shell; exposes tools to humans too</td></tr><tr><td><strong>Non-technical end users</strong></td><td>Easy tool installation</td><td><em>(MCP doesn&#39;t deliver)</em></td><td>MCP requires JSON editing—this group remains underserved regardless</td></tr><tr><td><strong>Internal app devs</strong></td><td>Standard tool interface</td><td>1st party tools</td><td>Same codebase, existing auth/logging/tracing, no process overhead, coherent toolbox</td></tr><tr><td><strong>Agent devs</strong></td><td>Let users swap toolsets</td><td>SDK abstraction (LangChain, LiteLLM)</td><td>Handles model API differences without separate processes</td></tr><tr><td><strong>Tool authors</strong></td><td>Distribute to all agents</td><td>OpenAPI specs or libraries</td><td>Existing distribution (npm, pip), decades of tooling, no new protocol</td></tr></tbody></table>
<h3 id="local-scripts-with-command-runner">Local scripts with command runner<a href="#local-scripts-with-command-runner" aria-label="Direct link to Local scripts with command runner" title="Direct link to Local scripts with command runner" translate="no">​</a></h3>
<p>For a technical user, letting an agent invoke scripts directly is very difficult to beat. Useful 50-100 line scripts are <em>extremely</em> easy to write with AI coding agents. Care needs to be taken to filter output - raw build scripts can stream verbose logs into agent context, eating up tokens.</p>
<p><img decoding="async" loading="lazy" alt="just" src="https://tombedor.dev/assets/images/just-c9e8594a50331d5b095b35a059dae448.png" width="1352" height="1171"/></p>
<p>Robust security against agent actions going haywire can be achieved via command runners like <a href="https://github.com/casey/just" target="_blank" rel="noopener noreferrer">just</a> or <a href="https://en.wikipedia.org/wiki/Make_(software)" target="_blank" rel="noopener noreferrer">make</a>. These tools provide everything that MCP does - command specifications, descriptions, arguments. Agents allow you to specify what command prefixes can be invoked without approval - put your agent commands in a <code>justfile</code>, and only auto-allow shell commands prefixed with <code>just</code>.</p>
<p>This approach also exposes tools to humans, and is a nice approach for improving dev environments for humans and AI agents at the same time. (See <a href="https://tombedor.dev/make-it-easy-for-humans/">Make It Easy for Humans First, Then AI</a> for more on this).</p>
<h3 id="1st-party-tools">1st party tools<a href="#1st-party-tools" aria-label="Direct link to 1st party tools" title="Direct link to 1st party tools" translate="no">​</a></h3>
<p>For a self contained application, there is little reason to separate tool codebases from the codebase for the rest of the application. Tools can be dynamically exposed to the agent based on application context.</p>
<p>In a first party context, any code that devs wish to reuse can be exposed as libraries, just like any other code they wish to share. An AI tool is really nothing more than a function, and the fact that it&#39;s invoked by AI does not warrant special handling.</p>
<p>An enterprise context should have robust infrastructure for authenticating, authorizing, provisioning service identities, and tracing call chains for service to service calls. That some of these calls are now <em>AI</em> service to service calls does not warrant a rebuilt security posture.</p>
<h3 id="openapi--rest">OpenAPI / REST<a href="#openapi--rest" aria-label="Direct link to OpenAPI / REST" title="Direct link to OpenAPI / REST" translate="no">​</a></h3>
<p>OpenAPI specs are already self-describing enough for agents—they include operation descriptions, parameter schemas, examples, and enums. LLMs understand them well; GPT Actions are literally OpenAPI specs. The glue needed between an OpenAPI endpoint and an agent (output filtering, context, auth) is the same glue MCP requires. MCP doesn&#39;t provide meaningfully better tool descriptions; it just reinvents a schema format that already exists, without the decades of tooling, validation, and battle-testing.</p>
<h2 id="a-prediction">A prediction<a href="#a-prediction" aria-label="Direct link to A prediction" title="Direct link to A prediction" translate="no">​</a></h2>
<p>MCP&#39;s popularity will be relatively short-lived. The cost benefit does not add up, and there are readily available alternatives. The introduction of <a href="https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview" target="_blank" rel="noopener noreferrer">Claude Skills</a> and <a href="https://simonwillison.net/2025/Dec/12/openai-skills/" target="_blank" rel="noopener noreferrer">OpenAI&#39;s quick adoption</a> signal that even model providers agree.</p>
<p>Claude Skills is an incremental improvement over MCP, but is similarly overengineered. Longstanding tools and techniques for collaboration amongst human devs remain compelling, and these options will chip away at more AI-centric techniques which reinvent the wheel.</p>
<!-- -->
</div></div>
  </body>
</html>
