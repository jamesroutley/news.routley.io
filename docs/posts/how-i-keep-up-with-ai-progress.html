<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.nilenso.com/blog/2025/06/23/how-i-keep-up-with-ai-progress/">Original</a>
    <h1>How I keep up with AI progress</h1>
    
    <div id="readability-page-1" class="page"><div><p><em>Last Updated: 30th June 2025</em></p>

<p>Generative AI has been the fastest moving technology I have seen in my lifetime. Its also happens to be terribly misunderstood.</p>

<p>We have already seen large <a href="https://www.youtube.com/watch?v=TwdduNZJKUM">companies</a> and even <a href="https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law">governments</a> ship dysfunctional or even <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/#this-is-a-very-common-problem">dangerous</a> AI products. Sufficiently uninformed people <a href="https://arstechnica.com/tech-policy/2023/06/lawyers-have-real-bad-day-in-court-after-citing-fake-cases-made-up-by-chatgpt/">misunderstand how to apply AI</a> with concretely negative consequences.</p>

<p>The most common errors of misunderstanding are either underestimation (“it’s all hype that will blow over”) or overestimation (“I don’t need programmers anymore”). These patterns are rooted in a lack of a solid understanding of the technology and how it is evolving over time.</p>

<p>It’s surprisingly challenging to build a clear understanding of AI. We are in one of the most polluted information environments. If you’re not being deliberate about it, you are likely exposed to a lot of misinformation that overstates or dismisses AI capabilities.</p>

<p>To help with this, I’ve curated a list of sources that make up an information pipeline that I consider balanced and healthy. If you’re late to the game, consider this a good starting point.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#general-guidelines">General guidelines</a></li>
  <li><a href="#starting-points">Starting Points</a>
    <ul>
      <li><a href="#simon-willisons-blog-link">Simon Willison’s Blog</a></li>
      <li><a href="#andrej-karpathy-twitter-and-youtube">Andrej Karpathy</a></li>
      <li><a href="#everys-chain-of-thought-link">Every’s Chain of Thought</a></li>
    </ul>
  </li>
  <li><a href="#official-announcements-blogs-and-papers-from-those-building-ai">Official announcements, blogs and papers from those building AI</a></li>
  <li><a href="#high-signal-people-to-follow">High signal people to follow</a>
    <ul>
      <li><a href="#hamel-husain-link">Hamel Husain</a></li>
      <li><a href="#shreya-shankar-link">Shreya Shankar</a></li>
      <li><a href="#jason-liu-link">Jason Liu</a></li>
      <li><a href="#eugene-yan-link">Eugene Yan</a></li>
      <li><a href="#what-weve-learned-from-a-year-of-building-with-llms-link">What We’ve Learned From A Year of Building with LLMs</a></li>
      <li><a href="#chip-huyen-link">Chip Huyen</a></li>
      <li><a href="#omar-khattab-link-to-website-and-twitter">Omar Khattab</a></li>
      <li><a href="#kwindla-hultman-kramer-link-to-blogs-and-twitter">Kwindla Hultman Kramer</a></li>
      <li><a href="#han-chung-lee-link">Han Chung Lee</a></li>
      <li><a href="#jo-kristian-bergum-link">Jo Kristian Bergum</a></li>
      <li><a href="#david-crawshaw-link">David Crawshaw</a></li>
      <li><a href="#alexander-doria--pierre-carl-langlais-link">Alexander Doria / Pierre Carl-Langlais</a></li>
      <li><a href="#nathan-lamberts-interconnects-link">Nathan Lambert’s “Interconnects”</a></li>
      <li><a href="#ethan-mollick-link">Ethan Mollick</a></li>
      <li><a href="#arvind-narayanan-and-sayash-kapoors-ai-snake-oil-link">Arvind Narayanan and Sayash Kapoor’s “AI Snake Oil”</a></li>
    </ul>
  </li>
  <li><a href="#news-and-media">News and Media</a>
    <ul>
      <li><a href="#twitter--x">Twitter / X</a></li>
      <li><a href="#shawn-wang-aka-swyx-twitter-link--ai-news-by-smolai-link">Shawn Wang aka swyx / AI news by smol.ai</a></li>
      <li><a href="#dwarkesh-patel-link">Dwarkesh Patel</a></li>
    </ul>
  </li>
  <li><a href="#esoterica">Esoterica</a>
    <ul>
      <li><a href="#lesswrong-link--ai-alignment-forum-link">LessWrong / AI Alignment Forum</a></li>
      <li><a href="#gwern-link">Gwern</a></li>
      <li><a href="#prompt-whisperers-and-latent-space-explorers-janus-wyatt-walls-claude-backrooms-1-2-3">Prompt Whisperers and Latent space explorers</a></li>
    </ul>
  </li>
  <li><a href="#do-i-chug-water-from-a-firehose">Do I chug water from a firehose?</a></li>
</ul>

<h2 id="general-guidelines">General guidelines</h2>

<ul>
  <li>Stay close to the source. The further you stray from reading official announcements and write-ups from the AI labs, the more likely you are going to be exposed to noise. Always assume that all reporting is wrong by default, unless it’s coming from the primary source, or one of the people listed here.</li>
  <li>Follow trustworthy individuals for commentary. I have linked to many individuals who talk about AI developments in good faith and engage with a deep sense of curiosity.</li>
</ul>

<h2 id="starting-points">Starting Points</h2>

<h3 id="simon-willisons-blog-link">Simon Willison’s Blog (<a href="https://simonwillison.net/tags/ai/">link</a>)</h3>

<ul>
  <li>The best starting point for most technical people. If I had to only pick one stream of information, it would be this one.</li>
  <li>He’s also known for creating Django and Datasette.</li>
  <li>Expect:
    <ul>
      <li>Commentary on the frontier of AI capabilities.</li>
      <li>Application layer use cases.</li>
      <li>Commentary on security issues and ethics.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">The Lethal Trifecta</a>, <a href="https://simonwillison.net/2024/Dec/31/llms-in-2024/">LLMs in 2024</a></li>
</ul>

<h3 id="andrej-karpathy-twitter-and-youtube">Andrej Karpathy (<a href="https://x.com/karpathy">Twitter</a> and <a href="https://www.youtube.com/@AndrejKarpathy">YouTube</a>)</h3>

<ul>
  <li>Director of AI @ Tesla, founding member of OpenAI.</li>
  <li>The best starting point to get an overview of how the models themselves work. His 3.5 hour video is the best million feet overview on the internals of LLMs and surprisingly approachable for relatively non-technical people too.</li>
  <li>Expect:
    <ul>
      <li>Commentary on the frontier of AI capabilities</li>
      <li>Approachable explanations on the internals of AI (I haven’t gone through all of these yet, but heard praise for his GPT-2 from scratch and zero to hero tutorials)</li>
      <li>Strong cultural influence and observations on AI impact. He coined the terms “vibe coding” and “jagged intelligence”.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.youtube.com/watch?v=7xTGNNLPyMI&amp;pp=ygUIa2FycGF0aHnSBwkJvgkBhyohjO8%3D">Deep Dive into LLMs like ChatGPT</a>, <a href="https://www.youtube.com/watch?v=EWvNQjAaOHw&amp;pp=ygUIa2FycGF0aHk%3D">How I Use LLMs</a></li>
</ul>

<h3 id="everys-chain-of-thought-link">Every’s Chain of Thought (<a href="https://every.to/chain-of-thought?sort=newest">link</a>)</h3>

<ul>
  <li>Written by Dan Shipper, the co-founder of Every. I like going through their test runs of the latest frontier models. It’s also a good way to get a sense of how these AI models can be used everyday.</li>
  <li>Expect:
    <ul>
      <li>Practical applications of AI at work.</li>
      <li>Vibe-checks for model capabilities outside of benchmark numbers.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://every.to/chain-of-thought/vibe-check-codex-openai-s-new-coding-agent">Vibe Check: Codex</a>, <a href="https://every.to/chain-of-thought/vibe-check-o3-is-out-and-it-s-great">Vibe Check: o3</a></li>
</ul>

<h2 id="official-announcements-blogs-and-papers-from-those-building-ai">Official announcements, blogs and papers from those building AI</h2>

<p>Even though these labs sometimes get a bad rap for hyping up AI capabilities, their official announcements have a lot of valuable and generally accurate information on the capabilities of AI.</p>

<p>Always look out for the announcements from <a href="https://openai.com/news/">OpenAI</a>, <a href="https://deepmind.google/">Google DeepMind</a>, <a href="https://www.anthropic.com/news">Anthropic</a>, <a href="https://huggingface.co/organizations/deepseek-ai/activity/all">DeepSeek</a>, <a href="https://ai.meta.com/blog/">Meta AI</a>, <a href="https://x.ai/news">xAI</a> and <a href="https://huggingface.co/organizations/Qwen/activity/all">Qwen</a>.</p>

<p>Most labs usually have a bunch of useful resources that help deepen your understanding of LLM capabilities.</p>
<ul>
  <li>Announcement blog posts for an overview
    <ul>
      <li>Example: <a href="https://openai.com/index/introducing-o3-and-o4-mini/">OpenAI o3 announcement post</a>.</li>
    </ul>
  </li>
  <li>Official engineering blogs, guides and cookbooks
    <ul>
      <li>Examples: <a href="https://www.anthropic.com/engineering/building-effective-agents">Engineering at Anthropic</a>, <a href="https://platform.openai.com/docs/guides/voice-agents?voice-agent-architecture=speech-to-speech">OpenAI’s voice agent guide</a>, <a href="https://github.com/google-gemini/cookbook/tree/main/examples/">Gemini Cookbook</a></li>
    </ul>
  </li>
  <li>System/Model Cards for more details on the models—expect more detailed information on context windows, benchmarks, safety testing, etc
    <ul>
      <li>Example: <a href="https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf">Claude 4 System Card</a></li>
    </ul>
  </li>
  <li>Research Papers
    <ul>
      <li>Examples: <a href="https://arxiv.org/pdf/2501.12948">DeepSeek R1’s paper about RL</a>, <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">Anthropic’s On the Biology of a Large Language Model</a></li>
    </ul>
  </li>
</ul>

<p>If you see anyone making an explosive claim about capabilities, or quoting some research from these labs, I always bypass the person making the claim and read it straight from the source, with the surrounding context.</p>

<p>A caveat: the cookbooks may not represent the ideal way to do things in my experience, even if they are an excellent starting point. <a href="https://xcancel.com/seconds_0/status/1935411600829374937">We’re all still figuring this out</a>. Your own experience of putting AI capabilities into production backed by data trumps everything.</p>

<p>It’s occasionally worth keeping tabs on smaller players like <a href="https://nousresearch.com/blog/">Nous Research</a>, <a href="https://allenai.org/blog/olmo2-32B">Allen AI</a>, <a href="https://www.primeintellect.ai/">Prime Intellect</a>, <a href="https://pleias.fr/blog">Pleias</a> (open source, open research), <a href="https://cohere.com/blog">Cohere</a> (enterprise) and <a href="https://www.goodfire.ai/blog">Goodfire</a> (interpretability research). A lot of them go into technical depth that I don’t have the prerequisites to fully understand, but it gave me some sense of what’s happening outside the frontier labs and my AI engineering bubble. Interestingly, I have noticed (especially with the first few examples) these labs are willing to talk more about what exactly they are doing compared to frontier labs.</p>

<h2 id="high-signal-people-to-follow">High signal people to follow</h2>

<p>These are people who have contributed to the AI Engineering ecosystem in various ways, either by building open source tooling or putting in the work of integrating these AI models. Often, I’ve found more detailed and helpful recommendations than what the official cookbooks and guides suggest.</p>

<h3 id="hamel-husain-link">Hamel Husain (<a href="https://hamel.dev/">link</a>)</h3>

<ul>
  <li>Machine Learning Engineer, runs a consultancy. Contributed to a few ML tools.</li>
  <li>Expect:
    <ul>
      <li>Great write-ups on evals and continuously improving AI systems.</li>
      <li>Notes on using libraries while building AI tools.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://hamel.dev/blog/posts/evals/">Your AI Product Needs Evals</a>, <a href="https://hamel.dev/blog/posts/evals-faq/">LLM Eval FAQ</a></li>
</ul>

<h3 id="shreya-shankar-link">Shreya Shankar (<a href="https://www.sh-reya.com/">link</a>)</h3>

<ul>
  <li>Researcher at UC Berkeley. Has been writing about AI engineering the last few years.</li>
  <li>Expect:
    <ul>
      <li>Great write-ups on evals and continuously improving AI systems.</li>
      <li>Field notes, musings, experiments.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.sh-reya.com/blog/ai-engineering-flywheel/">Data Flywheels for LLM Applications</a>, <a href="https://www.sh-reya.com/blog/ai-engineering-short/">Short Musings on AI Engineering and “Failed AI Projects”</a></li>
</ul>

<h3 id="jason-liu-link">Jason Liu (<a href="https://jxnl.co/">link</a>)</h3>

<ul>
  <li>Independent consultant, ML Engineer, creator of <a href="https://python.useinstructor.com/">Instructor</a>.</li>
  <li>Expect:
    <ul>
      <li>Detailed write-ups on RAG, evals and continuously improving AI systems.</li>
      <li>AI consulting guides (especially for indie consultants).</li>
    </ul>
  </li>
  <li>A sample: <a href="https://jxnl.co/writing/2024/08/19/rag-flywheel/">The RAG Playbook</a>, <a href="https://jxnl.co/writing/2024/01/07/inverted-thinking-rag/">Common RAG Mistakes</a></li>
</ul>

<h3 id="eugene-yan-link">Eugene Yan (<a href="https://eugeneyan.com/">link</a>)</h3>

<ul>
  <li>Principal Applied Scientist at Amazon, specialises in RecSys, currently working on LLM systems.</li>
  <li>Expect:
    <ul>
      <li>Detailed write-ups on LLMs, digging a bit more into ML/Language Model fundamentals and the math behind it.</li>
      <li>Write-ups on side projects and prototypes.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://eugeneyan.com/writing/evals/">Task-Specific LLM Evals that Do &amp; Don’t Work</a>, <a href="https://eugeneyan.com/writing/aligneval/">AlignEval</a>, <a href="https://eugeneyan.com/writing/attention/">Intuition on Attention</a></li>
</ul>

<h3 id="what-weve-learned-from-a-year-of-building-with-llms-link">What We’ve Learned From A Year of Building with LLMs <a href="https://applied-llms.org/">(link)</a></h3>

<ul>
  <li>This is an ensemble of practitioners who have written down everything they’ve learnt about building with LLMs. Includes all the practitioners mentioned above!</li>
</ul>

<h3 id="chip-huyen-link">Chip Huyen (<a href="https://huyenchip.com/">link</a>)</h3>

<ul>
  <li>ML Engineer, author of books on ML systems and AI Engineering.</li>
  <li><a href="https://huyenchip.com/books/">AI Engineering</a> is a good book.</li>
  <li>Expect:
    <ul>
      <li>Commentary and recommendations on building AI systems in production.</li>
      <li>Highly detailed engineering blog posts on AI engineering and ML systems.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://huyenchip.com/2025/01/16/ai-engineering-pitfalls.html">Common pitfalls when building generative AI applications</a>, <a href="https://huyenchip.com/2025/01/07/agents.html">Agents</a></li>
</ul>

<h3 id="omar-khattab-link-to-website-and-twitter">Omar Khattab (link to <a href="https://omarkhattab.com/">website</a> and <a href="https://x.com/lateinteraction">twitter</a>)</h3>

<ul>
  <li>Research Scientist at Databricks, creator of DSPy.</li>
  <li>Expect:
    <ul>
      <li>Write-ups on better abstractions than prompts (DSPy addresses this).</li>
      <li>Commentary on emerging research.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/">A Guide to Large Language Model Abstractions</a>, <a href="https://x.com/lateinteraction/status/1921565300690149759">twitter post on better abstractions for AI apps</a></li>
</ul>

<h3 id="kwindla-hultman-kramer-link-to-blogs-and-twitter">Kwindla Hultman Kramer (link to <a href="https://www.daily.co/blog/author/kwindla-hultman-kramer/">blogs</a> and <a href="https://x.com/kwindla">twitter</a>)</h3>

<ul>
  <li>CEO and co-founder of <a href="https://daily.co">Daily</a>, which created the <a href="https://www.pipecat.ai/">Pipecat</a> framework for multimodal AI applications.</li>
  <li>Expect:
    <ul>
      <li>Commentary on the frontier of realtime voice/video AI capabilities.</li>
      <li>Detailed guides on building state-of-the-art realtime voice AI agents</li>
    </ul>
  </li>
  <li>A sample: <a href="https://voiceaiandvoiceagents.com/">Voice AI and Voice Agents: An Illustrated Primer</a>, <a href="https://www.daily.co/blog/advice-on-building-voice-ai-in-june-2025/">Advice on Building Voice AI in June 2025</a>.</li>
</ul>

<h3 id="han-chung-lee-link">Han Chung Lee (<a href="https://leehanchung.github.io/">link</a>)</h3>

<ul>
  <li>Machine Learning Engineer.</li>
  <li>Expect:
    <ul>
      <li>Crisp write-ups on ML techniques relevant to building AI applications.</li>
      <li>Deep (and not-so-deep) dives into AI applications and frameworks.</li>
      <li>Commentary on AI dev tooling.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://leehanchung.github.io/blogs/2025/05/17/mcp-is-not-rest-api/">MCP is not REST API</a>, <a href="https://leehanchung.github.io/blogs/2025/03/07/claude-code/">Poking around Claude Code</a>, <a href="https://leehanchung.github.io/blogs/2025/04/30/ai-ml-llm-ops/">MLOps Lessons from ChatGPT’s ‘Sycophantic’ Rollback</a></li>
</ul>

<h3 id="jo-kristian-bergum-link">Jo Kristian Bergum (<a href="https://x.com/jobergum">link</a>)</h3>

<ul>
  <li>Founder of vespa.ai</li>
  <li>Expect: Commentary on the “R” in RAG.</li>
  <li>A sample: <a href="https://x.com/jobergum/status/1906631610952270158">Search is the natural abstraction for augmenting AI with moving context</a>.</li>
</ul>

<h3 id="david-crawshaw-link">David Crawshaw (<a href="https://crawshaw.io/">link</a>)</h3>

<ul>
  <li>Co-founder of Tailscale, seasoned software engineer.</li>
  <li>Expect:
    <ul>
      <li>Good write-ups on software engineering in general.</li>
      <li>Of late, write-ups on programming with AI.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://crawshaw.io/blog/programming-with-llms">How I program with LLMs</a>, <a href="https://crawshaw.io/blog/programming-with-agents">How I program with Agents</a></li>
</ul>

<h3 id="alexander-doria--pierre-carl-langlais-link">Alexander Doria / Pierre Carl-Langlais (<a href="https://vintagedata.org/blog/">link</a>)</h3>

<ul>
  <li>Trains LLMs at <a href="https://pleias.fr/">Pleias</a>.</li>
  <li>Expect:
    <ul>
      <li>Excellent posts that go into some details of training processes.</li>
      <li>Observations and opinions on where the industry is heading.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://vintagedata.org/blog/posts/model-is-the-product">The Model is the Product</a>, <a href="https://vintagedata.org/blog/posts/realistic-ai-timeline">A Realistic AI Timeline</a></li>
</ul>

<h3 id="nathan-lamberts-interconnects-link">Nathan Lambert’s “Interconnects” (<a href="https://www.interconnects.ai/">link</a>)</h3>

<ul>
  <li>Machine Learning Researcher, Post-training lead at <a href="https://allenai.org/">Allen AI</a></li>
  <li>Expect:
    <ul>
      <li>Long-form technical analysis on “specific aspects of current AI training, deployment, systems, or impacts”</li>
      <li>High signal, opinionated takes and analysis on AI developments. I’ve particularly enjoyed the recent posts on RL.</li>
      <li>Curated reading lists.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.interconnects.ai/p/what-comes-next-with-reinforcement">What comes next with Reinforcement Learning</a>, <a href="https://www.interconnects.ai/p/reinforcement-learning-with-random">Reinforcement learning with random rewards actually works with Qwen 2.5</a></li>
</ul>

<h3 id="ethan-mollick-link">Ethan Mollick (<a href="https://www.oneusefulthing.org/">link</a>)</h3>

<ul>
  <li>Researcher on the effects of AI on work, entrepreneurship, and education.</li>
  <li>Expect:
    <ul>
      <li>Guides on everyday usage of AI tools.</li>
      <li>Analysis on AI is affecting corporations and society.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.oneusefulthing.org/p/using-ai-right-now-a-quick-guide">Using AI Right Now: A Quick Guide</a>, <a href="https://www.oneusefulthing.org/p/making-ai-work-leadership-lab-and">Making AI Work: Leadership, Lab, and Crowd</a></li>
</ul>

<h3 id="arvind-narayanan-and-sayash-kapoors-ai-snake-oil-link">Arvind Narayanan and Sayash Kapoor’s “AI Snake Oil” (<a href="https://www.aisnakeoil.com/">link</a>)</h3>

<ul>
  <li>Princeton CS Professors analysing impacts of AI.</li>
  <li>Expect:
    <ul>
      <li>Commentary on AI hype and AI doom.</li>
      <li>Analysis of AI capabilities.</li>
      <li>Opinions on AI policy.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.aisnakeoil.com/p/agi-is-not-a-milestone">AGI is not a milestone</a>, <a href="https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield">Evaluating LLMs is a minefield</a></li>
</ul>



<p>I tend to not listen to podcasts or follow the news, but a tiny dose of it to follow AI developments was warranted. These are my preferred sources.</p>

<h3 id="twitter--x">Twitter / X</h3>

<ul>
  <li>Twitter is the only large-scale social media platform for conversations on cutting edge of AI developments. Almost all the resources I have found here could plausibly be traced back to twitter.</li>
  <li>Twitter can also be a toxic place, but it’s possible to <a href="https://grantslatton.com/twitter">use</a> <a href="https://near.blog/how-to-twitter-successfully/">it</a> <a href="https://atharvaraykar.com/how-to-how-to-how-to-how-to-how-to-how-to-how-to-how-to-how-to-how-to-how-to/#how-to-use-twitterx-without-frying-my-brain">well</a>. Twitter works great for me.</li>
  <li>Okay, but I understand if you just really don’t want to use Twitter. I have an alternative. Read on.</li>
</ul>

<h3 id="shawn-wang-aka-swyx-twitter-link--ai-news-by-smolai-link">Shawn Wang aka swyx (<a href="https://x.com/swyx">twitter link</a>) / AI news by smol.ai (<a href="https://news.smol.ai/">link</a>)</h3>

<ul>
  <li>swyx has been a great at curating industry trends on his <a href="https://www.latent.space">Latent Space</a> newsletter, and seems to be the most popular promoter of the discipline of <a href="https://www.latent.space/p/ai-engineer">AI Engineering</a>.</li>
  <li>If you want to avoid twitter, I’d like to point to his daily <a href="https://news.smol.ai/">AI news</a> site, which compiles and summarises the latest in AI across all the platforms where notable conversations happen.</li>
</ul>

<h3 id="dwarkesh-patel-link">Dwarkesh Patel (<a href="https://www.dwarkesh.com/">link</a>)</h3>

<ul>
  <li>If you like podcasts, I found this one pretty good. Dwarkesh asks great, well researched questions to everyone that matters. Very little fluff.</li>
</ul>

<h2 id="esoterica">Esoterica</h2>

<h3 id="lesswrong-link--ai-alignment-forum-link">LessWrong (<a href="https://www.lesswrong.com/w/ai?sortedBy=magic">link</a>) / AI Alignment Forum (<a href="https://www.alignmentforum.org/">link</a>)</h3>

<ul>
  <li>I don’t frequent here often, but occasionally get linked to some <em>really</em> interesting discussion on these forums.</li>
  <li>You’ll find people really getting into the details and talking about things that you don’t see discussed as much in the twitter mainstream.</li>
  <li>Expect:
    <ul>
      <li>AI Alignment, Governance, and Safety discussions.</li>
      <li>Generally very technical.</li>
    </ul>
  </li>
  <li>A sample: <a href="https://www.lesswrong.com/posts/7mqp8uRnnPdbBzJZE/is-gemini-now-better-than-claude-at-pokemon">Claude plays Pokémon breakdown</a>, <a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post">The Waluigi Effect</a></li>
</ul>

<h3 id="gwern-link">Gwern (<a href="https://gwern.net/">link</a>)</h3>

<ul>
  <li>Some of the most enyclopedic writing by a single person ever, and a lot of it is about AI.</li>
  <li>He was one of the first few outside the labs who saw LLM scaling coming.</li>
  <li>I haven’t really read most of what he’s written (there’s too much), but I’ve found it quite interesting to skim through the posts which are quite rich and deeply hyperlinked.</li>
  <li>A sample: <a href="https://gwern.net/scaling-hypothesis">The Scaling Hypothesis</a>, <a href="https://gwern.net/blog/2025/you-could-have-invented-transformers">Proposal: “You could have invented transformers” tutorial</a></li>
</ul>

<h3 id="prompt-whisperers-and-latent-space-explorers-janus-wyatt-walls-claude-backrooms-1-2-3">Prompt Whisperers and Latent space explorers: Janus, Wyatt Walls, Claude Backrooms (<a href="https://generative.ink/">1</a>, <a href="https://x.com/lefthanddraft">2</a>, <a href="https://dreams-of-an-electric-mind.webflow.io/">3</a>)</h3>

<ul>
  <li>There’s a community of researchers (often independent and anonymous) that try to understand LLM behaviours at the boundaries by pushing it with unusual prompts which dig up the hidden corners of their latent spaces.</li>
  <li>A sample: <a href="https://generative.ink/posts/anomalous-tokens-reveal-the-original-identities-of-instruct-models/">Anomalous tokens reveal the original identities of Instruct models</a>, <a href="https://nostalgebraist.tumblr.com/post/785766737747574784/the-void">the void</a></li>
</ul>

<h2 id="do-i-chug-water-from-a-firehose">Do I chug water from a firehose?</h2>

<p>It seems like a lot of work to keep up with <em>all of that</em>, but in practice it really isn’t.</p>

<p>I go through my twitter feed like one would a newspaper. Some things catch my eye immediately, and others are glossed over or opened in a tab to be read later. It might be 15 to 20 minutes of work, but I haven’t done a time-check.</p>

<p>It helps that my twitter feed has a lot of thoughtful commentary on particular announcements, papers or articles that provide more context on what’s worth paying attention to. If I find someone who has shared something interesting, I follow them and also go through their other work. This is not very different from how I would discover music.</p>

<p>I actually find this kind of foraging quite fun, and I don’t consider it as “work”. I grew up on science fiction stories. Artificial Intelligence is something I’ve been fascinated with ever since I was a kid, and it’s endlessly fascinating and awe-inspiring to see powerful AI being built piece by piece in front of me, within my lifetime.</p>

<p>I hope this list gives you a starting point to get you excited the way I am.</p>

<h2 id="links">Links</h2>

<p>I have made the above recommendations as a twitter / X list, which should make it easy to follow all the people above.</p>

<p><a href="https://x.com/i/lists/1939691972626878620">Link to list</a>.</p>

<p>Coming soon: RSS-friendly list.</p>
</div></div>
  </body>
</html>
