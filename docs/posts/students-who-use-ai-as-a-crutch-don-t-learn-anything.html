<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://english.elpais.com/technology/2024-10-03/ethan-mollick-analyst-students-who-use-ai-as-a-crutch-dont-learn-anything.html">Original</a>
    <h1>&#39;Students who use AI as a crutch don&#39;t learn anything&#39;</h1>
    
    <div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>“I don’t have any help or anything. I organize myself and I get like 800 messages a day. I’m scared to look at my to-do list,” says Ethan Mollick, 49, a professor at the Wharton School of Business at the University of Pennsylvania. He has just published <i>Co-Intelligence: Living and Working with AI</i>, a book on how to make the most of <a href="https://english.elpais.com/science-tech/2023-01-31/chatgpt-is-just-the-beginning-artificial-intelligence-is-ready-to-transform-the-world.html" target="_blank">artificial intelligence in everyday life</a>. Despite this, managing his schedule remains extremely complicated. Although he recommends using AI as a companion for almost everything, he also believes that we should be careful. Thanks to his social media presence, newsletter and candid comments, Mollick has become one of the most popular analysts and testers of the new generative AI tools.</p><p><b>Question: </b>How does it feel to be an AI influencer?</p><p><b>Answer.</b> I hate that description. I’ve been on social media for a long time, and I’m a compulsive sharer. But I don’t take money from any of these AI companies or do sponsorship deals. I talk to them because it’s interesting. I’m a tenured professor, I can say whatever I want. It’s strange to see companies trying to manipulate me by showing me their stuff, but I don’t have the infrastructure of an influencer. I worry that that influencer title smears everything together. There’s a difference between public intellectuals, researchers, and critics. It would be better if we had more classes of thinking.</p><p><b>Q.</b> You recommend spending three sleepless nights to master AI.</p><p><b>A.</b> The best advice from the book is to spend 10 hours with AI and apply it to everything you do. For whatever reason, very few people are actually spending the time they need to really understand these systems.</p><p><b>Q. </b>You don’t like to call AI a crutch.</p><p><b>A.</b> The crutch is a dangerous approach because if we use a crutch, <a href="https://english.elpais.com/technology/2024-04-14/melanie-mitchell-the-big-leap-in-artificial-intelligence-will-come-when-it-is-inserted-into-robots-that-experience-the-world-like-a-child.html" target="_blank">we stop thinking</a>. Students who use AI as a crutch don’t learn anything. It prevents them from thinking. Instead, using AI as co-intelligence is important because it increases your capabilities and also keeps you in the loop.</p><p><b>Q.</b> Isn’t it inevitable that AI will make us lazier?</p><p><b>A.</b> Calculators also made us lazier. Why aren’t we doing math by hand anymore? You should be taking notes by hand now instead of recording me. We use technology to take shortcuts, but we have to be <a href="https://english.elpais.com/opinion/2024-03-03/a-more-humane-education-in-the-era-of-artificial-intelligence.html" target="_blank">strategic in how we take those shortcuts</a>.</p><p><b>Q.</b> Why should we approach artificial intelligence with a strategy?</p><p><b>A. </b>AI does so many things that we need to set guardrails on what we don’t want to give up. It’s a very weird, general-purpose technology, which means it will affect all kinds of things, and we’ll have to adjust socially. We did a very bad job with the last major social adjustment, social media. This time we need to be more deliberate.</p><p><b>Q. </b>Will we be able to better socially adjust to AI?</p><p><b>A. </b>What gives me some hope with this technology is that because it’s so human-like, it’s more natural to work with. Humans used to work with smart team members to solve problems. It’s one thing if this becomes an all-intelligent God machine, but at the current level, where you’re interacting with this thing, and it’s flawed, that’s where it can be useful to be human-like.</p><p><b>Q. </b>In your book, you talk about “just me tasks” in reference to raising children and values. Can we do those things better without AI?</p><p><b>A. </b>There are a lot of moral and ethical decisions. I can’t help with that much, but I think we have to making those choices. With social media, we didn’t make enough decisions about how we wanted to use it. People and a lot of books view AI as something that’s being forced on us, and companies are creating AI, but they don’t really know how it’s being used or what it’s good for. We can make some decisions about that, and I think people tend to view it as a government or corporate decision, but it’s not just that.</p><p><b>Q. </b>People already have AI-made partners and psychological advisors.</p><p><b>A.</b> We have lived with a general-purpose technology for many years: the internet. Social media is just one sharp edge of what the internet has done to society. It is just one application. Other applications have been dating apps or how we shop. The implications are deep and wide. For example, with AI’s voice mode, I don’t want to be friends with it, but at the same time, I find myself being apologetic and careful when I talk to it. We will have to adjust. I trust that we can, but people already have connections to AI. Some will have almost religious connections to AI, and others will be manipulated. We have to recognize that at a bunch of stuff is all going to happen at once, good and bad, and the more we’re kind of ready for that set of change the better off we are.</p><p><b>Q. </b>You’ve written that “much of the value of AI use comes from people not knowing you are using it.” Why are we afraid of others knowing we’re using AI?</p><p><b>A.</b> There are several layers in organizations that prevent people from using AI. One of them is that if I use AI to do work, others will think I’m brilliant. You don’t want people to know that you’re not actually that brilliant, especially since AI is very good at things like writing empathetic emails, and it would be weird for them to know that that empathy was coming from an AI. They also don’t want to show it because they’re afraid that you’ll realize their job is redundant, or that they’ll be asked to do more work.</p><p><b>Q.</b> You recently wrote that something is starting to change with OpenAI’s new model, ChatGPT-o1.</p><p><b>A. </b>I finished the book a year ago. I had to have enough foresight to see where things were going. Predictions for six years in the future and if AI will kill or save us all wasn’t my interest. My interest was: how do you work with this thing? One of the things I mention that wasn’t as important in the previous generation of AI and that I think will be key in the next year or two is this idea of autonomy and AI agents. It’s the beginning of AI that will perform processes autonomously, without our help. I don’t think that will fundamentally change how we work with AI, but we may move to models that come back and ask you questions when they have problems. There’s something valuable about being questioned. It’s something we do in all the AI tools we build for learning: there has to be a back-and-forth, and the o1 model doesn’t really do that. It doesn’t ask. That’s what’s unnerving.</p><p><b>Q. </b>You like the idea of AI-powered one-on-one tutoring for education. Is that where we’re headed, after what you call the “homework apocalypse”?</p><p><b>A.</b> The AI tutor is one piece of the puzzle in the <a href="https://english.elpais.com/science-tech/2023-02-24/ai-in-the-classroom-i-require-my-students-to-use-chatgpt.html" target="_blank">transformation of education</a>. I worked in interactive education long before generative AI, and there are things about classrooms that we know for sure are changing, independent of AI: lectures are no longer a good idea. Active learning is better, where students have to participate. You want personalization. In the classroom, a small group of students usually participate and others are lost. We are not teaching correctly. In some ways, lectures have value, they are not a disaster. We have a way of teaching that has evolved over 200 years, and that’s alright. The homework apocalypse gives us a chance that we won’t all take advantage of, but we should rethink learning.</p><p><b>Q. </b>How can we take advantage of this opportunity?</p><p><b>A.</b> Active learning classrooms instead of lecture halls are a better way to learn. We haven’t adopted them because it’s easier to keep giving lectures and homework. We have the opportunity to be more thoughtful, and AI tutors are part of being thoughtful, because they help fill in knowledge gaps. Class time should be used to work together on problems. We can’t keep doing what we were doing before.</p><p><b>Q. </b>What are some of the biggest misconceptions about AI?</p><p><b>A. </b>People are divided between those who are excited about AI and those who are nervous or anxious. Each group has its own myths. For non-adopters, one of the biggest myths is that AI doesn’t do anything original and all you get is pasted together content from others. And that’s not true. AI is built as an elaborate physical model for <a href="https://english.elpais.com/science-tech/2023-08-29/language-schools-in-the-metaverse-and-conversation-classes-with-chatgpt-ai-comes-to-online-teaching.html" target="_blank">every human language </a>and uses those rules to create new material based on its training. There is an originality there. That’s one of the big misconceptions. The other is comparing it to Google. It’s worse at the things that Google does well, but better at many other things that Google doesn’t do.</p><p><b>Q. </b>You say that the best experts of the future will be those who make the most use of AI. Are people who are waiting to use AI making a mistake?</p><p><b>A.</b> I get it, it’s an unnerving technology. People are freaking out. They’re getting a sense of three sleepless nights and running away screaming. It feels like an essential threat to a lot of careers. I think if you’re a good journalist, the first time you think, “oh no.” But then you start to see how this could help you do things better than before. And at least for the next few generations, it’s not going to replace you, even though the technologists say it is. We need to separate from the Silicon Valley noise. On one hand they’re completely right: this is a miraculous incredible technology that emulates thinking, but the other is it doesn’t understand our jobs.</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en" target="_blank"><i>our weekly newsletter</i></a><i> to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>
  </body>
</html>
