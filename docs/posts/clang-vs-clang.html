<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.cr.yp.to/20240803-clang.html">Original</a>
    <h1>Clang vs. Clang</h1>
    
    <div id="readability-page-1" class="page">

<hr/>
<div>

<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2024.08.03: Clang vs. Clang:</b> You&#39;re making Clang angry. You wouldn&#39;t like Clang when it&#39;s angry. #compilers #optimization #bugs #timing #security #codescans</td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20240612-bibkeys.html"><b>2024.06.12: Bibliography keys:</b></a> <span>It&#39;s as easy as [1], [2], [3]. #bibliographies #citations #bibtex #votemanipulation #paperwriting</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20240102-hybrid.html"><b>2024.01.02: Double encryption:</b></a> <span>Analyzing the NSA/GCHQ arguments against hybrids. #nsa #quantification #risks #complexity #costs</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20231125-kyber.html"><b>2023.11.25: Another way to botch the security analysis of Kyber-512:</b></a> <span>Responding to a recent blog post. #nist #uncertainty #errorbars #quantification</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20231023-clumping.html"><b>2023.10.23: Reducing &#34;gate&#34; counts for Kyber-512:</b></a> <span>Two algorithm analyses, from first principles, contradicting NIST&#39;s calculation. #xor #popcount #gates #memory #clumping</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20231003-countcorrectly.html"><b>2023.10.03: The inability to count correctly:</b></a> <span>Debunking NIST&#39;s calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20230609-turboboost.html"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20220805-nsa.html"><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b></a> <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of &#34;An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development&#34; by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe&#39;s &#34;Quantum Manifesto&#34;:</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac&#39;s marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140411-nist.html"><b>2014.04.11: NIST&#39;s cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don&#39;t care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="https://www.bryanbraun.com/2024/08/02/links-10/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can&#39;t be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr/>
<h2>2024.08.03: Clang vs. Clang: <span>You&#39;re making Clang angry. You wouldn&#39;t like Clang when it&#39;s angry. #compilers #optimization #bugs #timing #security #codescans</span></h2>
<p>This is a blog post about an experiment with Clang.
I need to explain some context first.</p>
<p><strong><a name="optimizations"></a>Compiler &#34;optimizations&#34;.</strong>
Try skimming through recent changes to
<a href="https://github.com/llvm/llvm-project">LLVM</a>
and
<a href="https://github.com/gcc-mirror/gcc">GCC</a>.
You&#39;ll find &#34;optimizations&#34;,
and tests for &#34;optimizations&#34;,
and fixes to tests for &#34;optimizations&#34;,
and fixes to bugs in &#34;optimizations&#34;.</p>
<p>The bugs <em>admitted</em> in the compiler changelogs
are just the tip of the iceberg.
Whenever possible,
compiler writers refuse to take responsibility for
<a href="https://lwn.net/Articles/342330/">the</a>
<a href="https://blog.pkh.me/p/37-gcc-undefined-behaviors-are-getting-wild.html">bugs</a>
<a href="https://research.swtch.com/ub">they</a>
<a href="https://gavinhoward.com/2023/08/the-scourge-of-00ub/">introduced</a>,
even though the compiled code worked fine before the &#34;optimizations&#34;.
[2024.08.03 edit: Added more links here.]
The excuse for not taking responsibility is that
there are &#34;language standards&#34;
saying that these bugs should be blamed on millions of programmers
writing code that bumps into &#34;undefined behavior&#34;,
rather than being blamed on the much smaller group of compiler writers
subsequently changing how this code behaves.
These &#34;language standards&#34; are written by the compiler writers.</p>
<p>Evidently the compiler writers find it more important to continue developing &#34;optimizations&#34;
than to have computer systems functioning as expected.
Developing &#34;optimizations&#34; seems to be
a very large part of what compiler writers are paid to do.</p>
<p>I&#39;m putting &#34;optimizations&#34; in quotes
because compiler &#34;optimizations&#34;
are generally nowhere near the performance
that competent programmers can achieve.
As a cryptographic example,
benchmarks across
<a href="https://bench.cr.yp.to/impl-kem/kyber768.html">many CPUs</a>
show that the <code>avx2</code> implementation of <code>kyber768</code>
is about 4 times faster than portable code compiled with an &#34;optimizing&#34; compiler.
There are
<a href="https://bench.cr.yp.to">many more examples</a>
like this.</p>
<p>Compiler writers measure an &#34;optimization&#34; as successful
if they can find any example where the &#34;optimization&#34; saves time.
Does this matter for the overall user experience?
The typical debate runs as follows:</p>
<ul>
<li>
<p>In <a href="https://web.archive.org/web/20000824013718/http://www.research.microsoft.com/~toddpro/papers/law.htm">2000</a>,
  Todd A. Proebsting
  introduced &#34;Proebsting&#39;s Law: Compiler Advances Double Computing Power Every 18 <em>Years</em>&#34; (emphasis in original)
  and concluded that &#34;compiler optimization work makes only marginal contributions&#34;.
  Proebsting commented
  <a href="https://proebsting.cs.arizona.edu/">later</a> that
  &#34;The law probably would have gone unnoticed had it not been for the protests by those receiving funds to do compiler optimization research.&#34;</p>
</li>
<li>
<p>Arseny Kapoulkine ran various
  <a href="https://zeux.io/2022/01/08/on-proebstings-law/">benchmarks</a>
  in 2022 and concluded that the gains were even smaller:
  &#34;LLVM 11 tends to take 2x longer to compile code with optimizations, and as a
  result produces code that runs 10-20% faster (with occasional outliers in
  either direction), compared to LLVM 2.7 which is more than 10 years old.&#34;</p>
</li>
<li>
<p>Compiler writers typically respond with arguments like this:
  &#34;10-20% is gazillions of dollars of computer time saved!
  What a triumph from a decade of work!&#34;</p>
</li>
</ul>
<p>But both sides of this debate are founded upon an invalid measurement methodology.
The actual speedup produced by compilers is smaller, and shrinking,
as explained in my talk
<a href="https://cr.yp.to/talks.html#2015.04.16">&#34;The death of optimizing compilers&#34;</a>
in 2015.</p>
<p>If you look at the hot spots in a software system,
the code running often enough for the user to care about performance,
then you find tons of intrinsics and assembly language.
There are 160000 lines of assembly (<code>.asm</code> and <code>.S</code> files) in 
<a href="https://ffmpeg.org/download.html">FFmpeg</a>,
for example.
Faster computers and faster networks are handling more and more data
(e.g., bigger videos for FFmpeg),
putting more and more load on the hot spots.
Benchmarks selected to show the effect of compiler &#34;optimizations&#34;
are not representative of how CPU time is actually being spent.</p>
<p>Meanwhile there are more and more bugs produced by these &#34;optimizations&#34;,
and one has to ask how many gazillions of dollars have been lost because of that.
Consider, for example, security.
Deloitte
<a href="https://web.archive.org/web/20240803112553/https://www.deloitte.com/content/dam/assets-shared/docs/services/risk-advisory/2024/cybersecurity-insights-2023-budgets-benchmarks-financial-services-institutions.pdf">reported</a>
that 2023 IT security budgets were half a percent of corporate revenue,
which sounds like hundreds of billions of dollars overall
given that total corporate revenues worldwide were above
<a href="https://www.bu.edu/eci/files/2023/09/Corporate-Power-Module.pdf">$48 trillion</a>
in 2022.
(Some caveats: perhaps Deloitte&#39;s half percent was an unweighted average over corporations;
not all corporations respond to surveys.)
It would be interesting to study
what percentage of security failures can be partly or entirely attributed to compiler &#34;optimizations&#34;.</p>
<p><strong><a name="timing"></a>Timing leakage.</strong>
The security problems caused by &#34;optimizing&#34; compilers
aren&#39;t just traditional bugs,
but also unintentional leakage of secret information into timings,
often allowing those secrets to be reconstructed by
<a href="https://timing.attacks.cr.yp.to">timing attacks</a>.
To quote a
<a href="https://www.cl.cam.ac.uk/~rja14/Papers/whatyouc.pdf">EuroS&amp;P 2018 paper</a>
by Laurent Simon, David Chisnall, and Ross Anderson:
&#34;A compiler upgrade can suddenly and without warning open a
timing channel in previously secure code.
This arms race is pointless and has to stop.&#34;</p>
<p>Is there actually an arms race?
Let&#39;s look at the evidence.</p>
<p>The example highlighted in the 2018 paper used a <code>bool</code>
to select between two values.
Obviously <code>bool</code> was triggering the compiler to create conditional jumps.
The paper continued by acknowledging common practice of eliminating <code>bool</code>:</p>
<blockquote>
<p>So an extra layer of obfuscation used by cryptographers
is to eradicate <code>bool</code> completely in critical code;
and to have specially-crafted functions to compare integers
in constant time too. OpenSSL currently declares 37
different functions to support this. Unfortunately, compilers
offer no guarantees to such code; the next version of the
same compiler may silently understand it and optimize
the constant-timeness away. Examples of such failures
include the carefully-crafted constant-time implementation of
curve25519 which was broken by Microsoft’s compiler in
2015 [30].</p>
</blockquote>
<p>The one example claimed at the end of this quote
is a misunderstanding triggered by the title of the cited 2015 paper, namely
&#34;When constant-time source yields variable-time binary: Exploiting
curve25519-donna built with MSVC 2015&#34;.
What was actually happening in the 2015 paper
was that the <code>int64</code> operations in curve25519-donna
were,
<a href="https://research.kudelskisecurity.com/2017/01/16/when-constant-time-source-may-not-save-you/">when compiled for 32-bit x86</a>,
converted into calls to Microsoft&#39;s 32-bit <code>int64</code> library,
specifically <code>llmul.asm</code>,
where Microsoft had made the mistake of using data-dependent branches.
Any reasonable concept of source code should include this variable-time library:
that&#39;s where the timing leak was created, and it&#39;s where the timing leak should be fixed.</p>
<p>Later examples in an
<a href="https://leslyann-daniel.fr/ressources/papers/2020_SP_binsecrel.pdf">S&amp;P 2020 paper</a>
also used <code>bool</code>.
So, hmmm,
could it be that avoiding secret comparisons and secret <code>bool</code> in source code
stops compilers from producing secret conditional branches?
(The reason for listing comparisons separately here
is that, technically, C comparisons produce <code>int</code> rather than <code>bool</code>,
even if the compiler thinks of them as producing <code>bool</code> internally.)</p>
<p>Unfortunately, no, there really is an arms race here.
Never underestimate the ability of &#34;optimizing&#34; compilers to screw things up.</p>
<p>In <a href="https://pqshield.com/pqshield-plugs-timing-leaks-in-kyber-ml-kem-to-improve-pqc-implementation-maturity/">June 2024</a>,
Antoon Purnal reported
a successful timing attack against the Kyber reference code
compiled with some of the &#34;optimization&#34; options
for Clang 15 (released in 2022) or newer.
The reference code had a computation of the form <code>(-((x&gt;&gt;j)&amp;1))&amp;y</code>,
which is <code>y</code> if bit <code>j</code> of <code>x</code> is set, else <code>0</code>.
See the problem?
<SPAN color="0d372c"><strong>CLANG SMASH!</strong></SPAN>
The compiler used a bit-test instruction
to convert bit <code>j</code> of <code>x</code> into a <code>bool</code>,
and then performed a conditional branch based on this <code>bool</code>.</p>
<p>(As a side note,
I would expect this conditional branch to slow down more code than it speeds up.
But remember that compiler writers measure an &#34;optimization&#34; as successful
if they can find <em>any</em> example where the &#34;optimization&#34; saves time.)</p>
<p>Inside LLVM,
this &#34;optimization&#34; is handled by
<code>combineShiftAnd1ToBitTest</code>
in
<code>lib/CodeGen/SelectionDAG/DAGCombiner.cpp</code>.
The function
<code>combineShiftAnd1ToBitTest</code>
was added by Sanjay Patel in
<a href="https://github.com/llvm/llvm-project/commit/4e54cf3e0e71b38b2fde1a815e8460b14026762a">September 2019</a>,
and was tweaked by various people later.
I wonder whether anyone has found earlier examples
of compiler &#34;optimizations&#34; crossing the line into introducing <code>bool</code>.</p>
<p>A subsequent compiler patch crossing the same line
was a GCC patch by ARM in
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commit;f=gcc/match.pd;h=d70720c2382e687e192a9d666e80acb41bfda856">November 2021</a>
to convert <code>(-x)&gt;&gt;31</code> into <code>-(x&gt;0)</code>.
I issued a warning about this in
<a href="https://microblog.cr.yp.to/1713627640/index.html">April 2024</a>.</p>
<p>TIMECOP 2,
which is built into the
<a href="https://bench.cr.yp.to">SUPERCOP</a>
cryptographic test framework,
automatically scans compiled code for conditional branches derived from secrets,
if the code was declared to be constant-time.
(It also scans code for array indices derived from secrets,
and the
<a href="https://kyberslash.cr.yp.to/papers.html">KyberSlash paper</a>
describes a patch to scan for divisions derived from secrets.)
Checking TIMECOP results is what led to my April 2024 warning.</p>
<p>The original
<a href="https://www.post-apocalyptic-crypto.org/timecop/">TIMECOP 1</a>
from Moritz Neikes
was also a modification to SUPERCOP,
automating an approach taken by Adam Langley&#39;s
<a href="https://www.imperialviolet.org/2010/04/01/ctgrind.html">ctgrind</a>.
Some differences between TIMECOP 1 and TIMECOP 2:
TIMECOP 2 automatically marks RNG output as secret;
TIMECOP 2 supports &#34;declassification&#34;;
TIMECOP 2 supports designation of &#34;public inputs&#34;;
TIMECOP 2 runs on multiple cores.
(This last difference is also a contribution from the KyberSlash paper.)</p>
<p>TIMECOP has limitations:
it supports only instructions supported by Valgrind
(e.g., it gives up on AMD XOP instructions),
and the data flow that it checks
is only the data flow
visible in the test runs that it carries out.
There&#39;s continued work on
<a href="https://crocs-muni.github.io/ct-tools/">tools</a>
for checking constant-time behavior.
But I&#39;m happy to report that the equivalent of TIMECOP
is now built into the test suite for
<a href="https://lib.mceliece.org">libmceliece</a>,
and I hope this spreads to other libraries.</p>
<p>If you&#39;ve identified a variable-time code snippet,
how do you rewrite it to run in constant time,
while making sure that the rewrite doesn&#39;t introduce any bugs?
I gave a talk about this in
<a href="https://cr.yp.to/talks.html#2024.07.22">July 2024</a>.
Part of the talk was explaining some constant-time functions
provided by libmceliece and SUPERCOP;
these functions are provided by files <code>crypto_{int,uint}{8,16,32,64}.h</code>
that you&#39;re free to copy into your own projects.
As one example,
the function
<code>crypto_uint32_bitmod_mask(x,j)</code>
has the same effect as <code>-((x&gt;&gt;(j&amp;31))&amp;1)</code>,
but stops the compiler from seeing that there&#39;s a 1-bit result.
A fancier example is
<code>crypto_uint32_max(x,y)</code>.</p>
<p>For comparison,
the 2018 paper reported a
<a href="https://github.com/lmrs2/ct_choose">tweak</a>
to Clang/LLVM
to add language support for a constant-time function
<code>__builtin_ct_choose(bool cond, x, y)</code>.
The 2018 paper also incorrectly suggested
that this was the only such function needed.
Maybe this function will get into compilers someday,
but clearly it&#39;ll be a long time before you can rely on this function being present for your projects,
and the way it&#39;s implemented strikes me as more fragile
than the way <code>crypto_{int,uint}{8,16,32,64}.h</code> are implemented.</p>
<p><strong><a name="proactive"></a>Proactively avoiding problems.</strong>
To the extent that timing leaks introduced by compilers
are detected by pre-deployment test suites for compiled libraries,
we can revert to an older compiler version for deployment
while we&#39;re rewriting the code,
so the users stay safe at each moment.
But can we prevent compilers from introducing timing leaks in the first place?</p>
<p>One attractive answer is to distribute the libraries as assembly language.
If your reaction is &#34;Yikes, this makes software correctness hard to audit&#34;:
The RWC 2024 talk
<a href="https://iacr.org/submit/files/slides/2024/rwc/rwc2024/38/slides.pdf">&#34;Adoption of high-assurance and highly performant cryptographic algorithms at AWS&#34;</a>
presented fast X25519 software
proven to correctly compute X25519 on all inputs.
The software is written in assembly language
(two versions targeting different 64-bit Intel/AMD CPUs,
and two versions targeting different 64-bit ARM CPUs);
the correctness statement is a theorem about the machine code, the same code that users are running;
the proof is verified by the
<a href="https://www.cl.cam.ac.uk/~jrh13/hol-light/">HOL Light</a> theorem prover.</p>
<p>However,
the argument against assembly is valid
for cryptographic software
that hasn&#39;t reached this gold standard yet.
So I&#39;ve also been looking at ways to rapidly introduce anti-timing-leak vaccinations
into code written in C, C++, etc.</p>
<p>The shared feature of <code>x&amp;1</code> and <code>x&gt;&gt;31</code>
is that there are just two possibilities for the result:
<code>x&amp;1</code> is <code>0</code> or <code>1</code>;
<code>x&gt;&gt;31</code> is <code>0</code> or <code>1</code> if <code>x</code> is <code>uint32</code>;
<code>x&gt;&gt;31</code> is <code>0</code> or <code>-1</code> if <code>x</code> is <code>int32</code>.
(Side note: always compile with <code>-fwrapv</code> so that GCC and Clang assume twos-complement arithmetic.)
In each case,
someone writing a compiler &#34;optimization&#34; can easily say &#34;Hey, I can stick that 1-bit result into a <code>bool</code>&#34;.
There are more possibilities to think about
(what about <code>x&amp;2</code>? what about <code>x&lt;&lt;31</code>? what about 2-bit results?),
but let&#39;s focus on these examples as case studies.</p>
<p>Simply scanning source code for <code>&amp;1</code>, <code>1&amp;</code>, <code>&gt;&gt;31</code>, and so on finds many examples,
but I&#39;ve also tried a quick experiment with another type of scanning,
which is what the title of this blog post is referring to.
I&#39;m not sure this second type is better overall,
but it does seem to have some interesting capabilities.</p>
<p>I wrote a simple
<a href="https://www.bryanbraun.com/2024/08/02/links-10/20240803-patch.txt">patch</a>
for the LLVM &#34;optimizer&#34; (starting from commit 68df06a0b2998765cb0a41353fcf0919bbf57ddb)
to scan for <code>&amp;1</code> and <code>&gt;&gt;31</code>,
and to issue remarks saying
&#34;please take this away before clang does something bad&#34;.
Here&#39;s an example of compiling a test function with
<code>clang -Rpass-analysis=clang-vs-clang -O -c x.c</code>
after the patch:</p>
<pre><code>    x.c:3:5: remark: clang-vs-clang: clang sees signed&gt;&gt;(bits-1); please take this away before clang does something bad [-Rpass-analysis=clang-vs-clang]
        3 |   x &gt;&gt;= 31;
          |     ^
    x.c:3:5: remark: clang-vs-clang: clang sees signed&gt;&gt;(bits-1); please take this away before clang does something bad [-Rpass-analysis=clang-vs-clang]
</code></pre>
<p>This is the test function:</p>
<pre><code>    int sra31(int x)
    {
      x &gt;&gt;= 31;
      return x;
    }
</code></pre>
<p>Repetitions of the remark are unsurprising:
compilers will keep trying to apply &#34;optimizations&#34;
until they stop making progress.</p>
<p>The <code>clang-vs-clang</code> output distinguishes <code>signed</code> from <code>unsigned</code> for shifts.
This distinction matters for a (manual or automatic) rewrite in terms of <code>crypto_{int,uint}{8,16,32,64}.h</code>.
(One way to automate source transformations is via <code>clang-tidy</code>.)
Of course,
code omitted because of <code>#ifdef</code>,
or otherwise eliminated before this &#34;optimization&#34; step,
won&#39;t trigger any remarks from <code>clang-vs-clang</code>.
[2024.08.03 edit: Fixed typo.]</p>
<p>I then ran SUPERCOP 20240716 (<code>./data-do-biglittle</code> on a dual EPYC 7742
<a href="https://www.bryanbraun.com/2024/08/02/links-10/20230609-turboboost.html">with overclocking disabled</a>),
after adjusting SUPERCOP&#39;s compiler list to use <code>clang-vs-clang</code> (adding <code>-Rpass-analysis=clang-vs-clang</code>
to the <code>clang</code> lines in <code>okcompilers/{c,cpp}</code>).</p>
<p>Results were ready three hours later.
There were 675752 lines from Clang,
in total 210786494 bytes,
compressing to 3595199 bytes in
<a href="https://www.bryanbraun.com/2024/08/02/links-10/20240803-fromclang.txt.gz"><code>20240803-fromclang.txt.gz</code></a>.
There&#39;s quite a bit of noise in the output
because various source-code branches on public data
trigger Clang to internally generate <code>&amp;1</code> for the branch conditions.
Skipping past those finds more interesting examples.</p>
<p>Here&#39;s an example that had also been found by simpler source-code scans
and that is clearly good to proactively change:</p>
<pre><code>    a0 += (a0&gt;&gt;15)&amp;106;
</code></pre>
<p>Here&#39;s an example where a source-code scan would have required some effort at C parsing.
The macro <code>ONE8</code> is defined as <code>((uint8_t)1)</code>:</p>
<pre><code>    *pk2^=(((*pk_cp)&gt;&gt;ir)&amp;ONE8)&lt;&lt;jr;
</code></pre>
<p>Here&#39;s another example that&#39;s even harder to find by simpler scans:</p>
<pre><code>    mask = signmask_x16(sub_x16(x,const_x16((q+1)/2)));
</code></pre>
<p>The macro <code>signmask_x16(x)</code> is defined as <code>_mm256_srai_epi16((x),15)</code>,
an AVX2 intrinsic to shift each signed 16-bit piece in a 256-bit vector right by 15 bits.</p>
<p>This last one isn&#39;t high on my priority list to rewrite.
The easiest way I could imagine the vector operation turning into a conditional branch
is to compile for AVX-512, which has vectorized <code>bool</code>,
and to have the compiler decide for some strange reason to convert those into serial <code>bool</code> for a conditional branch.
For the moment,
given that TIMECOP uses Valgrind and that
<a href="https://bugs.kde.org/show_bug.cgi?id=383010">Valgrind doesn&#39;t support AVX-512</a>,
I don&#39;t recommend compiling for AVX-512 anyway.</p>
<p>The examples I found most interesting were 
64-bit right-shifts of <code>int128</code> triggering the <code>&gt;&gt;</code> warning.
Sure, makes sense that the implementation of <code>int128</code>
is internally using a 63-bit right shift of the top 64-bit word
to figure out the sign;
but what happens if Clang adds GCC-like support
for converting 63-bit right shifts into <code>bool</code> and then into conditional branches?
Suddenly all sorts of <code>int128</code> code will be variable-time,
much like what the 2015 paper was claiming but this time really with no <code>bool</code> in the source.
I think the easiest way to protect against this at the source level
is to avoid the compiler&#39;s existing implementation of <code>int128</code>
in favor of some <code>crypto_int128</code> functions.
A side advantage of writing those functions is that <code>crypto_int128</code>,
unlike the <code>int128</code> in GCC and Clang,
will work on small 32-bit platforms.</p>
<p>Beyond these scans,
there are some other ideas I should mention.
Adding support to GCC and Clang for secret data types
<em>sounds</em> great,
but I don&#39;t see how to make this robust
given how GCC and Clang are structured.
I have more hope for compilers
that are built for security in the first place.
Security-focused compilers
that require new input languages,
such as
<a href="https://github.com/plsyssec/fact">FaCT</a>
and the actively developed
<a href="https://github.com/jasmin-lang/jasmin">Jasmin</a>,
raise concerns about code-rewriting time,
but, c&#39;mon, is this really so scary?
We have to be taking some sort of action anyway,
given how compilers are handling current code.
<SPAN color="0d372c"><strong>CLANG SMASH!</strong></SPAN></p><hr/><SPAN size="1"><b>Version:</b>
This is version 2024.08.03 of the 20240803-clang.html web page.
</SPAN>

</div>
  </body>
</html>
