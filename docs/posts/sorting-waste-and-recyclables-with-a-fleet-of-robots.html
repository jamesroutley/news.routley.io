<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ai.googleblog.com/2023/04/robotic-deep-rl-at-scale-sorting-waste.html">Original</a>
    <h1>Sorting waste and recyclables with a fleet of robots</h1>
    
    <div id="readability-page-1" class="page"><div>
<div id="post-body-8521407697493439122">
<p><span>Posted by Sergey Levine, Research Scientist, and Alexander Herzog, Staff Research Software Engineer, Google Research, Brain Team</span></p><div>

  
<p>Reinforcement learning (RL) can enable robots to learn complex behaviors through trial-and-error interaction, getting better and better over time. Several of our prior works explored how RL can enable intricate robotic skills, such as <a href="https://ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html">robotic grasping</a>, <a href="https://ai.googleblog.com/2021/04/multi-task-robotic-reinforcement.html">multi-task learning</a>, and even playing <a href="https://ai.googleblog.com/2022/10/table-tennis-research-platform-for.html">table tennis</a>. Although robotic RL has come a long way, we still don&#39;t see RL-enabled robots in everyday settings. The real world is complex, diverse, and changes over time, presenting a major challenge for robotic systems. However, we believe that RL should offer us an excellent tool for tackling precisely these challenges: by continually practicing, getting better, and learning on the job, robots should be able to <a href="https://sites.google.com/corp/view/efficient-ft/home">adapt to the world as it changes around them</a>.</p>
<p>
In “<a href="https://rl-at-scale.github.io/assets/rl_at_scale.pdf">Deep RL at Scale: Sorting Waste in Office Buildings with a Fleet of Mobile Manipulators</a>”, we discuss how we studied this problem through a recent large-scale experiment, where we deployed a fleet of 23 RL-enabled robots over two years in Google office buildings to sort waste and recycling. Our robotic system combines scalable deep RL from real-world data with bootstrapping from training in simulation and auxiliary object perception inputs to boost generalization, while retaining the benefits of end-to-end training, which we validate with 4,800 evaluation trials across 240 waste station configurations.</p>



<h2>Problem setup</h2>
<p>
When people don’t sort their trash properly, batches of recyclables can become contaminated and compost can be improperly discarded into landfills. In our experiment, a robot roamed around an office building searching for “waste stations” (bins for recyclables, compost, and trash). The robot was tasked with approaching each waste station to sort it, moving items between the bins so that all recyclables (cans, bottles) were placed in the recyclable bin, all the compostable items (cardboard containers, paper cups) were placed in the compost bin, and everything else was placed in the landfill trash bin. Here is what that looks like:
</p>
</div>
</div>
</div></div>
  </body>
</html>
