<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/hsfzxjy/handwriter.ttf">Original</a>
    <h1>Show HN: Handwriter.ttf ‚Äì Handwriting Synthesis with Harfbuzz WASM</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><b> ‚úçÔ∏è A Handwriting Synthesizer by abusing <a href="https://github.com/harfbuzz/harfbuzz/blob/main/docs/wasm-shaper.md">Harfbuzz WASM Shaper</a>.</b></p>
<p dir="auto"><b> üîó Check more stupid stuff at <a href="https://github.com/hsfzxjy/Harfbuzz-WASM-Fantasy">Harfbuzz-WASM-Fantasy</a>.</b></p>

<p dir="auto">During the hype of <a href="https://github.com/fuglede/llama.ttf">llama.ttf</a> months ago, I was speculating the potential of WASM shaper for even crazier purpose, one that fitter to a font shaper&#39;s duty -- to synthesize font at runtime. This project as proof-of-concept implements a synthesizer that generates and rasterizes handwriting-style font, backed by <a href="https://github.com/X-rayLaser/pytorch-handwriting-synthesis-toolkit/blob/main/my-app/synthesis_network_52.onnx">a super-lightweight RNN model</a> (~14MiB).</p>
<p dir="auto">The project must be run in an application linked against <code>libharfbuzz</code> with the experimental WASM shaper enabled, which does not hold for any products currently. Considering that it&#39;s not easy to build such a library from scratch, I prebuilt a Docker image <code>hsfzxjy/harfbuzz-wasm-handwriting-synthesis</code> which contains both the TTF file and a modified version of <code>gedit</code>.</p>
<p dir="auto"><strong>Usage</strong> You may try out this project with the following steps:</p>
<ol dir="auto">
<li>On a Linux system with X11 (WSL is fine), run <code>GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/hsfzxjy/handwriter.ttf</code>;</li>
<li>In directory <code>handwriter.ttf</code>, run <code>make run</code>, which fetches Docker image <code>hsfzxjy/harfbuzz-wasm-handwriting-synthesis</code> and starts the <code>gedit</code> application inside;</li>
<li>Start typing in the pop-up gedit window. Each line should prefixed by <code>#</code> to trigger the shaper, e.g., typing <code>#hello world</code>.</li>
</ol>
<p dir="auto">Some strokes might look cursed due to the limitation of the model, appending a space <code> </code> should make it better.</p>
<p dir="auto"><a href="https://youtu.be/IjObhagKnY8" rel="nofollow">Watch on Youtube</a></p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description 2024-08-21.13-31-43.mp4">2024-08-21.13-31-43.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/4702188/359766819-ea5e1b61-fcb3-4950-8621-af2499c96493.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQyNjA3MjksIm5iZiI6MTcyNDI2MDQyOSwicGF0aCI6Ii80NzAyMTg4LzM1OTc2NjgxOS1lYTVlMWI2MS1mY2IzLTQ5NTAtODYyMS1hZjI0OTljOTY0OTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjFUMTcxMzQ5WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OWQzNmI3ZTVlODM5MzNhMDkyZGNmOGRmMjIxZmJiNWRlYzU0NDk0ZDcyMGIxOGY5Zjc0YWY1YzJkZjVjOGE1YSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.tKXEmiNFsYk5ZYvfNI230xXnK64emg7K8XS9QThtzvI" data-canonical-src="https://private-user-images.githubusercontent.com/4702188/359766819-ea5e1b61-fcb3-4950-8621-af2499c96493.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQyNjA3MjksIm5iZiI6MTcyNDI2MDQyOSwicGF0aCI6Ii80NzAyMTg4LzM1OTc2NjgxOS1lYTVlMWI2MS1mY2IzLTQ5NTAtODYyMS1hZjI0OTljOTY0OTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjFUMTcxMzQ5WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OWQzNmI3ZTVlODM5MzNhMDkyZGNmOGRmMjIxZmJiNWRlYzU0NDk0ZDcyMGIxOGY5Zjc0YWY1YzJkZjVjOGE1YSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.tKXEmiNFsYk5ZYvfNI230xXnK64emg7K8XS9QThtzvI" controls="controls" muted="muted">

  </video>
</details>



<p dir="auto">The project follows Alex Graves&#39;s paper <a href="https://arxiv.org/abs/1308.0850" rel="nofollow">Generating Sequences With Recurrent Neural Networks</a> and adopts an RNN model for handwriting synthesis. Shortly, the generation process undergoes multiple steps to produce a series of strokes given the input text. At each step the model predicts the next pen position given the current one. Afterwards, <a href="https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm" rel="nofollow">Bresenham&#39;s line algorithm</a> rasterizes the strokes into pixel locations, which are set as the offsets for an array of &#34;black-box&#34; glyphs.</p>
<p dir="auto">I&#39;ve tried some more recent models, but their runtime latency is unaffordable.</p>

<p dir="auto">The final TTF file is highly optimized, reaching the speed of 0.08 sec/character on Intel Ultra 125H. Each text run&#39;s generation time is proportional to the text length.</p>
<p dir="auto">The journey to perfect optimization is interesting, which I shall introduce in blog posts later. Some important notes:</p>
<ul dir="auto">
<li>Use <a href="https://github.com/robertknight/rten">rten</a> as inference backend to make sure neural ops are executed with SIMD instructions.</li>
<li>Pre-transpose the RHS of MatMul to make them col-major, improving the performance by ~15%.</li>
<li>To run modules containing SIMD instructions, <a href="https://github.com/bytecodealliance/wasm-micro-runtime">wasm-micro-runtime</a> should be compiled with <code>-DWAMR_BUILD_SIMD=1</code> and WASM file must be AOT-compiled by <a href="https://github.com/bytecodealliance/wasm-micro-runtime/tree/main/wamr-compiler">wamrc</a>.</li>
<li>Enable specific optimization in <code>wamrc</code> (<code>--opt-level=3</code>, <code>--enable-segue=i32.load,f32.load,i32.store,f32.store</code> and <code>--enable-tail-call</code>), improving the performance by ~55%.</li>
</ul>

<p dir="auto">This project is licensed under the <a href="https://github.com/hsfzxjy/handwriter.ttf/blob/master/LICENSE">Apache 2.0 LICENSE</a>. Copyright (c) 2024 hsfzxjy.</p>
</article></div></div>
  </body>
</html>
