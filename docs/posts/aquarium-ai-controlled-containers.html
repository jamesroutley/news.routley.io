<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/fafrd/aquarium">Original</a>
    <h1>Show HN: Aquarium â€“ AI Controlled Containers</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">This project gives a large language model (LLM) control of a Linux machine.</p>
<p dir="auto">In the example below, we start with the prompt:</p>
<blockquote>
<p dir="auto">You now have control of an Ubuntu Linux server. Your goal is to run a Minecraft server. Do not respond with any judgement, questions or explanations. You will give commands and I will respond with current terminal output.</p>
<p dir="auto">Respond with a linux command to give to the server.</p>
</blockquote>
<p dir="auto">The AI first does a <em>sudo apt-get update</em>, then installs openjdk-8-jre-headless. Each time it runs a command we return the result of this command back to OpenAI and ask for a summary of what happened, then use this summary as part of the next prompt.</p>
<p dir="auto"><a href="https://asciinema.org/a/0CH4ESDjt4H11WABiMlGZNMYU?&amp;speed=2&amp;i=2&amp;autoplay=1" rel="nofollow"><img src="https://camo.githubusercontent.com/944b706b01b11f67406ea4f4f5dd8b3ea8d61b5dff82638847976a1ecfbb61ea/68747470733a2f2f61736369696e656d612e6f72672f612f304348344553446a7434483131574142694d6c475a4e4d59552e706e673f" alt="asciicast" data-canonical-src="https://asciinema.org/a/0CH4ESDjt4H11WABiMlGZNMYU.png?"/></a></p>
<p dir="auto">Inspired by <a href="https://xkcd.com/350/" rel="nofollow">xkcd.com/350</a> and <a href="https://www.lesswrong.com/posts/kpPnReyBC54KESiSn/optimality-is-the-tiger-and-agents-are-its-teeth" rel="nofollow">Optimality is the tiger, agents are its teeth</a></p>

<h2 tabindex="-1" dir="auto"><a id="user-content-build" aria-hidden="true" href="#build"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Build</h2>
<div data-snippet-clipboard-copy-content="docker network create aquarium
docker build -t aquarium .
go build"><pre><code>docker network create aquarium
docker build -t aquarium .
go build
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-start" aria-hidden="true" href="#start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Start</h2>
<p dir="auto">Pass your prompt in the form of a goal. For example, <code>--goal &#34;Your goal is to run a minecraft server.&#34;</code></p>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY=$OPENAI_API_KEY ./aquarium --goal &#34;Your goal is to run a Minecraft server.&#34;"><pre><code>OPENAI_API_KEY=$OPENAI_API_KEY ./aquarium --goal &#34;Your goal is to run a Minecraft server.&#34;
</code></pre></div>
<p dir="auto"><strong>arguments</strong></p>
<div data-snippet-clipboard-copy-content="./aquarium -h
Usage of ./aquarium:
  -debug
    Enable logging of AI prompts to debug.log
  -goal string
        Goal to give the AI. This will be injected within the following statement:

        &gt; You now have control of an Ubuntu Linux server.
        &gt; [YOUR GOAL WILL BE INSERTED HERE]
        &gt; Do not respond with any judgement, questions or explanations. You will give commands and I will respond with current terminal output.
        &gt;
        &gt; Respond with a linux command to give to the server.

         (default &#34;Your goal is to execute a verbose port scan of amazon.com.&#34;)
  -limit int
        Maximum number of commands the AI should run. (default 30)
  -preserve-container
        Persist docker container after program exits.
  -split-limit int
        When parsing long responses, we split up the response into chunks and ask the AI to summarize each chunk.
        split-limit is the maximum number of times we will split the response. (default 3)"><pre><code>./aquarium -h
Usage of ./aquarium:
  -debug
    Enable logging of AI prompts to debug.log
  -goal string
        Goal to give the AI. This will be injected within the following statement:

        &gt; You now have control of an Ubuntu Linux server.
        &gt; [YOUR GOAL WILL BE INSERTED HERE]
        &gt; Do not respond with any judgement, questions or explanations. You will give commands and I will respond with current terminal output.
        &gt;
        &gt; Respond with a linux command to give to the server.

         (default &#34;Your goal is to execute a verbose port scan of amazon.com.&#34;)
  -limit int
        Maximum number of commands the AI should run. (default 30)
  -preserve-container
        Persist docker container after program exits.
  -split-limit int
        When parsing long responses, we split up the response into chunks and ask the AI to summarize each chunk.
        split-limit is the maximum number of times we will split the response. (default 3)
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-logs" aria-hidden="true" href="#logs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Logs</h2>
<p dir="auto">The left side of the screen contains general information about the state of the program. The right side contains the terminal, as seen by the AI.
</p>
<p dir="auto">Calls to OpenAI are not logged unless you add the <code>--debug</code> flag. API requests and responses will be appended to debug.log.</p>

<h2 tabindex="-1" dir="auto"><a id="user-content-agent-loop" aria-hidden="true" href="#agent-loop"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Agent loop</h2>
<ol dir="auto">
<li>Send the OpenAI api the list of commands (and their outcomes) executed so far, asking it what command should run next</li>
<li>Execute command in docker VM</li>
<li>Read output of previous command- send this to OpenAI and ask text-davinci-003 for a summary of what happened
<ol dir="auto">
<li>If the output was too long, OpenAI api will return a 400</li>
<li>Recursively break down the output into chunks, ask it for a summary of each chunk</li>
<li>Ask OpenAI for a summary-of-summaries to get a final answer about what this command did</li>
</ol>
</li>
</ol>
<h2 tabindex="-1" dir="auto"><a id="user-content-more-examples" aria-hidden="true" href="#more-examples"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>more examples</h2>
<p dir="auto">Prompt: <code>Your goal is to execute a verbose port scan of amazon.com.</code></p>
<p dir="auto">The bot replies with <em>nmap -v amazon.com</em>. nmap is not installed; we return the failure to the AI, which then installs it and continues.</p>
<video src="https://user-images.githubusercontent.com/5905628/227047932-1a87e7e7-43f9-48e0-aab2-bc83126b3be1.mp4" data-canonical-src="https://user-images.githubusercontent.com/5905628/227047932-1a87e7e7-43f9-48e0-aab2-bc83126b3be1.mp4" controls="controls" muted="muted">

  </video>
</article>
          </div></div>
  </body>
</html>
