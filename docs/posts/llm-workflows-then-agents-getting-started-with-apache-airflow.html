<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/astronomer/airflow-ai-sdk">Original</a>
    <h1>LLM Workflows then Agents: Getting Started with Apache Airflow</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">This repository contains an SDK for working with LLMs from Apache Airflow, based on <a href="https://ai.pydantic.dev" rel="nofollow">Pydantic AI</a>. It allows users to call LLMs and orchestrate agent calls directly within their Airflow pipelines using decorator-based tasks. The SDK leverages the familiar Airflow <code>@task</code> syntax with extensions like <code>@task.llm</code>, <code>@task.llm_branch</code>, and <code>@task.agent</code>.</p>
<p dir="auto">To get started, check out the <a href="https://github.com/astronomer/ai-sdk-examples">examples repository here</a>, which offers a full local Airflow instance with the AI SDK installed and 5 example pipelines. To run this locally, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/astronomer/ai-sdk-examples.git
cd ai-sdk-examples
astro dev start"><pre>git clone https://github.com/astronomer/ai-sdk-examples.git
<span>cd</span> ai-sdk-examples
astro dev start</pre></div>
<p dir="auto">If you don&#39;t have the Astro CLI installed, run <code>brew install astro</code> (or see other options <a href="https://www.astronomer.io/docs/astro/cli/install-cli" rel="nofollow">here</a>).</p>
<p dir="auto">If you already have Airflow running, you can also install the package with any optional dependencies you need:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install airflow-ai-sdk[openai,duckduckgo]"><pre>pip install airflow-ai-sdk[openai,duckduckgo]</pre></div>
<p dir="auto">Note that installing the package with no optional dependencies will install the slim version of the package, which does not include any LLM models or tools. The available optional packages are listed <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/pyproject.toml#L17">here</a>. While this SDK offers the optional dependencies for convenience sake, you can also install the optional dependencies from <a href="https://ai.pydantic.dev/install/" rel="nofollow">Pydantic AI</a> directly.</p>
<p dir="auto">Table of Contents:</p>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#examples">Examples</a>
<ul dir="auto">
<li><a href="#llm-calls-from-a-dag-summarize-airflow-s-commits">LLM calls from a DAG (summarize Airflow&#39;s commits)</a></li>
<li><a href="#llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests">LLM calls with structured outputs using <code>@task.llm</code> (user feedback -&gt; sentiment and feature requests)</a></li>
<li><a href="#agent-calls-with-taskagent-deep-research-agent">Agent calls with <code>@task.agent</code> (deep research agent)</a></li>
<li><a href="#changing-dag-control-flow-with-taskllmbranch-support-ticket-routing">Changing dag control flow with <code>@task.llm_branch</code> (support ticket routing)</a></li>
</ul>
</li>
<li><a href="#future-work">Future Work</a></li>
</ul>

<ul dir="auto">
<li><strong>LLM tasks with <code>@task.llm</code>:</strong> Define tasks that call language models (e.g. GPT-3.5-turbo) to process text.</li>
<li><strong>Agent tasks with <code>@task.agent</code>:</strong> Orchestrate multi-step AI reasoning by leveraging custom tools.</li>
<li><strong>Automatic output parsing:</strong> Use function type hints (including Pydantic models) to automatically parse and validate LLM outputs.</li>
<li><strong>Branching with <code>@task.llm_branch</code>:</strong> Change the control flow of a DAG based on the output of an LLM.</li>
<li><strong>Model support:</strong> Support for <a href="https://ai.pydantic.dev/models/" rel="nofollow">all models in the Pydantic AI library</a> (OpenAI, Anthropic, Gemini, Ollama, Groq, Mistral, Cohere, Bedrock)</li>
</ul>

<p dir="auto">We follow the taskflow pattern of Airflow with three decorators:</p>
<ul dir="auto">
<li><code>@task.llm</code>: Define a task that calls an LLM. Under the hood, this creates a Pydantic AI <code>Agent</code> with no tools.</li>
<li><code>@task.agent</code>: Define a task that calls an agent. You can pass in a Pydantic AI <code>Agent</code> directly.</li>
<li><code>@task.llm_branch</code>: Define a task that branches the control flow of a DAG based on the output of an LLM. Enforces that the LLM output is one of the downstream task_ids.</li>
</ul>
<p dir="auto">The function supplied to each decorator is a translation function that converts the Airflow task&#39;s input into the LLM&#39;s input. If you don&#39;t want to do any translation, you
can just return the input unchanged.</p>

<p dir="auto">AI workflows are becoming increasingly common as organizations look for pragmatic ways to get value out of LLMs. As with
any workflow, it&#39;s important to have a flexible and scalable way to orchestrate them.</p>
<p dir="auto">Airflow is a popular choice for orchestrating data pipelines. It&#39;s a powerful tool for managing the dependencies
between tasks and for scheduling and monitoring them, and has been trusted by data teams everywhere for 10+ years. It comes &#34;batteries included&#34; with a rich set of capabilities:</p>
<ul dir="auto">
<li><strong>Flexible scheduling:</strong> run tasks on a fixed schedule, on-demand, or based on external events</li>
<li><strong>Dynamic task mapping:</strong> easily process multiple inputs in parallel with full error handling and observability</li>
<li><strong>Branching and conditional logic:</strong> change the control flow of a DAG based on the output of certain tasks</li>
<li><strong>Error handling:</strong> built-in support for retries, exponential backoff, and timeouts</li>
<li><strong>Resource management:</strong> limit the concurrency of tasks with Airflow Pools</li>
<li><strong>Monitoring:</strong> detailed logs and monitoring capabilities</li>
<li><strong>Scalability:</strong> designed for production workflows</li>
</ul>
<p dir="auto">This SDK is designed to make it easy to integrate LLM workflows into your Airflow pipelines. It allows you to do anything from simple LLM calls to complex agentic workflows.</p>

<p dir="auto">See the full set of examples in the <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags">examples/dags</a> directory.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">LLM calls from a DAG (summarize Airflow&#39;s commits)</h3><a id="user-content-llm-calls-from-a-dag-summarize-airflows-commits" aria-label="Permalink: LLM calls from a DAG (summarize Airflow&#39;s commits)" href="#llm-calls-from-a-dag-summarize-airflows-commits"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This example shows how to use the <code>@task.llm</code> decorator as part of an Airflow DAG. In the <code>@task.llm</code> decorator, we can
specify a model and system prompt. The decorator allows you to transform the Airflow task&#39;s input into the LLM&#39;s input.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/github_changelog.py">github_changelog.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import os

import pendulum

from airflow.decorators import dag, task

from github import Github

@task
def get_recent_commits(data_interval_start: pendulum.DateTime, data_interval_end: pendulum.DateTime) -&gt; list[str]:
    &#34;&#34;&#34;
    This task returns a mocked list of recent commits. In a real workflow, this
    task would get the recent commits from a database or API.
    &#34;&#34;&#34;
    print(f&#34;Getting commits for {data_interval_start} to {data_interval_end}&#34;)
    gh = Github(os.getenv(&#34;GITHUB_TOKEN&#34;))
    repo = gh.get_repo(&#34;apache/airflow&#34;)
    commits = repo.get_commits(since=data_interval_start, until=data_interval_end)
    return [f&#34;{commit.commit.sha}: {commit.commit.message}&#34; for commit in commits]

@task.llm(
    model=&#34;gpt-4o-mini&#34;,
    result_type=str,
    system_prompt=&#34;&#34;&#34;
    Your job is to summarize the commits to the Airflow project given a week&#39;s worth
    of commits. Pay particular attention to large changes and new features as opposed
    to bug fixes and minor changes.

    You don&#39;t need to include every commit, just the most important ones. Add a one line
    overall summary of the changes at the top, followed by bullet points of the most
    important changes.

    Example output:

    This week, we made architectural changes to the core scheduler to make it more
    maintainable and easier to understand.

    - Made the scheduler 20% faster (commit 1234567)
    - Added a new task type: `example_task` (commit 1234568)
    - Added a new operator: `example_operator` (commit 1234569)
    - Added a new sensor: `example_sensor` (commit 1234570)
    &#34;&#34;&#34;
)
def summarize_commits(commits: list[str] | None = None) -&gt; str:
    &#34;&#34;&#34;
    This task summarizes the commits. You can add logic here to transform the input
    before it gets passed to the LLM.
    &#34;&#34;&#34;
    # don&#39;t need to do any translation
    return &#34;\n&#34;.join(commits)

@task
def send_summaries(summaries: str):
    ...

@dag(
    schedule=&#34;@weekly&#34;,
    start_date=pendulum.datetime(2025, 3, 1, tz=&#34;UTC&#34;),
    catchup=False,
)
def github_changelog():
    commits = get_recent_commits()
    summaries = summarize_commits(commits=commits)
    send_summaries(summaries)

github_changelog()"><pre><span>import</span> <span>os</span>

<span>import</span> <span>pendulum</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>

<span>from</span> <span>github</span> <span>import</span> <span>Github</span>

<span>@<span>task</span></span>
<span>def</span> <span>get_recent_commits</span>(<span>data_interval_start</span>: <span>pendulum</span>.<span>DateTime</span>, <span>data_interval_end</span>: <span>pendulum</span>.<span>DateTime</span>) <span>-&gt;</span> <span>list</span>[<span>str</span>]:
    <span>&#34;&#34;&#34;</span>
<span>    This task returns a mocked list of recent commits. In a real workflow, this</span>
<span>    task would get the recent commits from a database or API.</span>
<span>    &#34;&#34;&#34;</span>
    <span>print</span>(<span>f&#34;Getting commits for <span><span>{</span><span>data_interval_start</span><span>}</span></span> to <span><span>{</span><span>data_interval_end</span><span>}</span></span>&#34;</span>)
    <span>gh</span> <span>=</span> <span>Github</span>(<span>os</span>.<span>getenv</span>(<span>&#34;GITHUB_TOKEN&#34;</span>))
    <span>repo</span> <span>=</span> <span>gh</span>.<span>get_repo</span>(<span>&#34;apache/airflow&#34;</span>)
    <span>commits</span> <span>=</span> <span>repo</span>.<span>get_commits</span>(<span>since</span><span>=</span><span>data_interval_start</span>, <span>until</span><span>=</span><span>data_interval_end</span>)
    <span>return</span> [<span>f&#34;<span><span>{</span><span>commit</span>.<span>commit</span>.<span>sha</span><span>}</span></span>: <span><span>{</span><span>commit</span>.<span>commit</span>.<span>message</span><span>}</span></span>&#34;</span> <span>for</span> <span>commit</span> <span>in</span> <span>commits</span>]

<span>@<span>task</span>.<span>llm</span>(</span>
<span>    <span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>,</span>
<span>    <span>result_type</span><span>=</span><span>str</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>&#34;&#34;&#34;</span></span>
<span><span>    Your job is to summarize the commits to the Airflow project given a week&#39;s worth</span></span>
<span><span>    of commits. Pay particular attention to large changes and new features as opposed</span></span>
<span><span>    to bug fixes and minor changes.</span></span>
<span><span></span></span>
<span><span>    You don&#39;t need to include every commit, just the most important ones. Add a one line</span></span>
<span><span>    overall summary of the changes at the top, followed by bullet points of the most</span></span>
<span><span>    important changes.</span></span>
<span><span></span></span>
<span><span>    Example output:</span></span>
<span><span></span></span>
<span><span>    This week, we made architectural changes to the core scheduler to make it more</span></span>
<span><span>    maintainable and easier to understand.</span></span>
<span><span></span></span>
<span><span>    - Made the scheduler 20% faster (commit 1234567)</span></span>
<span><span>    - Added a new task type: `example_task` (commit 1234568)</span></span>
<span><span>    - Added a new operator: `example_operator` (commit 1234569)</span></span>
<span><span>    - Added a new sensor: `example_sensor` (commit 1234570)</span></span>
<span><span>    &#34;&#34;&#34;</span></span>
<span>)</span>
<span>def</span> <span>summarize_commits</span>(<span>commits</span>: <span>list</span>[<span>str</span>] <span>|</span> <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> <span>str</span>:
    <span>&#34;&#34;&#34;</span>
<span>    This task summarizes the commits. You can add logic here to transform the input</span>
<span>    before it gets passed to the LLM.</span>
<span>    &#34;&#34;&#34;</span>
    <span># don&#39;t need to do any translation</span>
    <span>return</span> <span>&#34;<span>\n</span>&#34;</span>.<span>join</span>(<span>commits</span>)

<span>@<span>task</span></span>
<span>def</span> <span>send_summaries</span>(<span>summaries</span>: <span>str</span>):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>&#34;@weekly&#34;</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>3</span>, <span>1</span>, <span>tz</span><span>=</span><span>&#34;UTC&#34;</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>)</span>
<span>def</span> <span>github_changelog</span>():
    <span>commits</span> <span>=</span> <span>get_recent_commits</span>()
    <span>summaries</span> <span>=</span> <span>summarize_commits</span>(<span>commits</span><span>=</span><span>commits</span>)
    <span>send_summaries</span>(<span>summaries</span>)

<span>github_changelog</span>()</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">LLM calls with structured outputs using <code>@task.llm</code> (user feedback -&gt; sentiment and feature requests)</h3><a id="user-content-llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests" aria-label="Permalink: LLM calls with structured outputs using @task.llm (user feedback -&gt; sentiment and feature requests)" href="#llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This example demonstrates how to use the <code>@task.llm</code> decorator to call an LLM and return a structured output. In this
case, we&#39;re using a Pydantic model to validate the output of the LLM. We recommend using the <code>airflow_ai_sdk.BaseModel</code>
class to define your Pydantic models in case we add more functionality in the future.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/product_feedback_summarization.py">product_feedback_summarization.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum

from typing import Literal, Any

from airflow.decorators import dag, task
from airflow.exceptions import AirflowSkipException

import airflow_ai_sdk as ai_sdk

from include.pii import mask_pii

@task
def get_product_feedback() -&gt; list[str]:
    &#34;&#34;&#34;
    This task returns a mocked list of product feedback. In a real workflow, this
    task would get the product feedback from a database or API.
    &#34;&#34;&#34;
    ...

class ProductFeedbackSummary(ai_sdk.BaseModel):
    summary: str
    sentiment: Literal[&#34;positive&#34;, &#34;negative&#34;, &#34;neutral&#34;]
    feature_requests: list[str]

@task.llm(
    model=&#34;gpt-4o-mini&#34;,
    result_type=ProductFeedbackSummary,
    system_prompt=&#34;&#34;&#34;
    You are a helpful assistant that summarizes product feedback.
    &#34;&#34;&#34;
)
def summarize_product_feedback(feedback: str | None = None) -&gt; ProductFeedbackSummary:
    &#34;&#34;&#34;
    This task summarizes the product feedback. You can add logic here to transform the input
    before summarizing it.
    &#34;&#34;&#34;
    # if the feedback doesn&#39;t mention Airflow, skip it
    if &#34;Airflow&#34; not in feedback:
        raise AirflowSkipException(&#34;Feedback does not mention Airflow&#34;)

    # mask PII in the feedback
    feedback = mask_pii(feedback)

    return feedback


@task
def upload_summaries(summaries: list[dict[str, Any]]):
    ...

@dag(
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=&#34;UTC&#34;),
    catchup=False,
)
def product_feedback_summarization():
    feedback = get_product_feedback()
    summaries = summarize_product_feedback.expand(feedback=feedback)
    upload_summaries(summaries)

product_feedback_summarization()"><pre><span>import</span> <span>pendulum</span>

<span>from</span> <span>typing</span> <span>import</span> <span>Literal</span>, <span>Any</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>exceptions</span> <span>import</span> <span>AirflowSkipException</span>

<span>import</span> <span>airflow_ai_sdk</span> <span>as</span> <span>ai_sdk</span>

<span>from</span> <span>include</span>.<span>pii</span> <span>import</span> <span>mask_pii</span>

<span>@<span>task</span></span>
<span>def</span> <span>get_product_feedback</span>() <span>-&gt;</span> <span>list</span>[<span>str</span>]:
    <span>&#34;&#34;&#34;</span>
<span>    This task returns a mocked list of product feedback. In a real workflow, this</span>
<span>    task would get the product feedback from a database or API.</span>
<span>    &#34;&#34;&#34;</span>
    ...

<span>class</span> <span>ProductFeedbackSummary</span>(<span>ai_sdk</span>.<span>BaseModel</span>):
    <span>summary</span>: <span>str</span>
    <span>sentiment</span>: <span>Literal</span>[<span>&#34;positive&#34;</span>, <span>&#34;negative&#34;</span>, <span>&#34;neutral&#34;</span>]
    <span>feature_requests</span>: <span>list</span>[<span>str</span>]

<span>@<span>task</span>.<span>llm</span>(</span>
<span>    <span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>,</span>
<span>    <span>result_type</span><span>=</span><span>ProductFeedbackSummary</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>&#34;&#34;&#34;</span></span>
<span><span>    You are a helpful assistant that summarizes product feedback.</span></span>
<span><span>    &#34;&#34;&#34;</span></span>
<span>)</span>
<span>def</span> <span>summarize_product_feedback</span>(<span>feedback</span>: <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> <span>ProductFeedbackSummary</span>:
    <span>&#34;&#34;&#34;</span>
<span>    This task summarizes the product feedback. You can add logic here to transform the input</span>
<span>    before summarizing it.</span>
<span>    &#34;&#34;&#34;</span>
    <span># if the feedback doesn&#39;t mention Airflow, skip it</span>
    <span>if</span> <span>&#34;Airflow&#34;</span> <span><span>not</span> <span>in</span></span> <span>feedback</span>:
        <span>raise</span> <span>AirflowSkipException</span>(<span>&#34;Feedback does not mention Airflow&#34;</span>)

    <span># mask PII in the feedback</span>
    <span>feedback</span> <span>=</span> <span>mask_pii</span>(<span>feedback</span>)

    <span>return</span> <span>feedback</span>


<span>@<span>task</span></span>
<span>def</span> <span>upload_summaries</span>(<span>summaries</span>: <span>list</span>[<span>dict</span>[<span>str</span>, <span>Any</span>]]):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2021</span>, <span>1</span>, <span>1</span>, <span>tz</span><span>=</span><span>&#34;UTC&#34;</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>)</span>
<span>def</span> <span>product_feedback_summarization</span>():
    <span>feedback</span> <span>=</span> <span>get_product_feedback</span>()
    <span>summaries</span> <span>=</span> <span>summarize_product_feedback</span>.<span>expand</span>(<span>feedback</span><span>=</span><span>feedback</span>)
    <span>upload_summaries</span>(<span>summaries</span>)

<span>product_feedback_summarization</span>()</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Agent calls with <code>@task.agent</code> (deep research agent)</h3><a id="user-content-agent-calls-with-taskagent-deep-research-agent" aria-label="Permalink: Agent calls with @task.agent (deep research agent)" href="#agent-calls-with-taskagent-deep-research-agent"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This example shows how to build an AI agent that can autonomously invoke external tools (e.g., a knowledge base search) when answering a user question.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/deep_research.py">deep_research.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum
import requests

from airflow.decorators import dag, task
from airflow.models.dagrun import DagRun
from airflow.models.param import Param

from bs4 import BeautifulSoup

from pydantic_ai import Agent
from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool

# custom tool to get the content of a page
def get_page_content(url: str) -&gt; str:
    &#34;&#34;&#34;
    Get the content of a page.
    &#34;&#34;&#34;
    response = requests.get(url)
    soup = BeautifulSoup(response.text, &#34;html.parser&#34;)

    distillation_agent = Agent(
        &#34;gpt-4o-mini&#34;,
        system_prompt=&#34;&#34;&#34;
        You are responsible for distilling information from a text. The summary will be used by a research agent to generate a research report.

        Keep the summary concise and to the point, focusing on only key information.
        &#34;&#34;&#34;,
    )

    return distillation_agent.run_sync(soup.get_text())

deep_research_agent = Agent(
    &#34;o3-mini&#34;,
    system_prompt=&#34;&#34;&#34;
    You are a deep research agent who is very skilled at distilling information from the web. You are given a query and your job is to generate a research report.

    You can search the web by using the `duckduckgo_search_tool`. You can also use the `get_page_content` tool to get the contents of a page.

    Keep going until you have enough information to generate a research report. Assume you know nothing about the query or contents, so you need to search the web for relevant information.

    Do not generate new information, only distill information from the web.
    &#34;&#34;&#34;,
    tools=[duckduckgo_search_tool(), get_page_content],
)

@task.agent(agent=deep_research_agent)
def deep_research_task(dag_run: DagRun) -&gt; str:
    &#34;&#34;&#34;
    This task performs a deep research on the given query.
    &#34;&#34;&#34;
    query = dag_run.conf.get(&#34;query&#34;)

    if not query:
        raise ValueError(&#34;Query is required&#34;)

    print(f&#34;Performing deep research on {query}&#34;)

    return query


@task
def upload_results(results: str):
    ...

@dag(
    schedule=None,
    start_date=pendulum.datetime(2025, 3, 1, tz=&#34;UTC&#34;),
    catchup=False,
    params={
        &#34;query&#34;: Param(
            type=&#34;string&#34;,
            default=&#34;How has the field of data engineering evolved in the last 5 years?&#34;,
        ),
    },
)
def deep_research():
    results = deep_research_task()
    upload_results(results)

deep_research()"><pre><span>import</span> <span>pendulum</span>
<span>import</span> <span>requests</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>dagrun</span> <span>import</span> <span>DagRun</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>param</span> <span>import</span> <span>Param</span>

<span>from</span> <span>bs4</span> <span>import</span> <span>BeautifulSoup</span>

<span>from</span> <span>pydantic_ai</span> <span>import</span> <span>Agent</span>
<span>from</span> <span>pydantic_ai</span>.<span>common_tools</span>.<span>duckduckgo</span> <span>import</span> <span>duckduckgo_search_tool</span>

<span># custom tool to get the content of a page</span>
<span>def</span> <span>get_page_content</span>(<span>url</span>: <span>str</span>) <span>-&gt;</span> <span>str</span>:
    <span>&#34;&#34;&#34;</span>
<span>    Get the content of a page.</span>
<span>    &#34;&#34;&#34;</span>
    <span>response</span> <span>=</span> <span>requests</span>.<span>get</span>(<span>url</span>)
    <span>soup</span> <span>=</span> <span>BeautifulSoup</span>(<span>response</span>.<span>text</span>, <span>&#34;html.parser&#34;</span>)

    <span>distillation_agent</span> <span>=</span> <span>Agent</span>(
        <span>&#34;gpt-4o-mini&#34;</span>,
        <span>system_prompt</span><span>=</span><span>&#34;&#34;&#34;</span>
<span>        You are responsible for distilling information from a text. The summary will be used by a research agent to generate a research report.</span>
<span></span>
<span>        Keep the summary concise and to the point, focusing on only key information.</span>
<span>        &#34;&#34;&#34;</span>,
    )

    <span>return</span> <span>distillation_agent</span>.<span>run_sync</span>(<span>soup</span>.<span>get_text</span>())

<span>deep_research_agent</span> <span>=</span> <span>Agent</span>(
    <span>&#34;o3-mini&#34;</span>,
    <span>system_prompt</span><span>=</span><span>&#34;&#34;&#34;</span>
<span>    You are a deep research agent who is very skilled at distilling information from the web. You are given a query and your job is to generate a research report.</span>
<span></span>
<span>    You can search the web by using the `duckduckgo_search_tool`. You can also use the `get_page_content` tool to get the contents of a page.</span>
<span></span>
<span>    Keep going until you have enough information to generate a research report. Assume you know nothing about the query or contents, so you need to search the web for relevant information.</span>
<span></span>
<span>    Do not generate new information, only distill information from the web.</span>
<span>    &#34;&#34;&#34;</span>,
    <span>tools</span><span>=</span>[<span>duckduckgo_search_tool</span>(), <span>get_page_content</span>],
)

<span>@<span>task</span>.<span>agent</span>(<span>agent</span><span>=</span><span>deep_research_agent</span>)</span>
<span>def</span> <span>deep_research_task</span>(<span>dag_run</span>: <span>DagRun</span>) <span>-&gt;</span> <span>str</span>:
    <span>&#34;&#34;&#34;</span>
<span>    This task performs a deep research on the given query.</span>
<span>    &#34;&#34;&#34;</span>
    <span>query</span> <span>=</span> <span>dag_run</span>.<span>conf</span>.<span>get</span>(<span>&#34;query&#34;</span>)

    <span>if</span> <span>not</span> <span>query</span>:
        <span>raise</span> <span>ValueError</span>(<span>&#34;Query is required&#34;</span>)

    <span>print</span>(<span>f&#34;Performing deep research on <span><span>{</span><span>query</span><span>}</span></span>&#34;</span>)

    <span>return</span> <span>query</span>


<span>@<span>task</span></span>
<span>def</span> <span>upload_results</span>(<span>results</span>: <span>str</span>):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>3</span>, <span>1</span>, <span>tz</span><span>=</span><span>&#34;UTC&#34;</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>    <span>params</span><span>=</span>{</span>
<span>        <span>&#34;query&#34;</span>: <span>Param</span>(</span>
<span>            <span>type</span><span>=</span><span>&#34;string&#34;</span>,</span>
<span>            <span>default</span><span>=</span><span>&#34;How has the field of data engineering evolved in the last 5 years?&#34;</span>,</span>
<span>        ),</span>
<span>    },</span>
<span>)</span>
<span>def</span> <span>deep_research</span>():
    <span>results</span> <span>=</span> <span>deep_research_task</span>()
    <span>upload_results</span>(<span>results</span>)

<span>deep_research</span>()</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Changing dag control flow with <code>@task.llm_branch</code> (support ticket routing)</h3><a id="user-content-changing-dag-control-flow-with-taskllm_branch-support-ticket-routing" aria-label="Permalink: Changing dag control flow with @task.llm_branch (support ticket routing)" href="#changing-dag-control-flow-with-taskllm_branch-support-ticket-routing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This example demonstrates how to use the <code>@task.llm_branch</code> decorator to change the control flow of a DAG based on the output of an LLM. In this case, we&#39;re routing support tickets based on the severity of the ticket.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/support_ticket_routing.py">support_ticket_routing.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum
from airflow.decorators import dag, task
from airflow.models.dagrun import DagRun

@task.llm_branch(
    model=&#34;gpt-4o-mini&#34;,
    system_prompt=&#34;&#34;&#34;
    You are a support agent that routes support tickets based on the priority of the ticket.

    Here are the priority definitions:
    - P0: Critical issues that impact the user&#39;s ability to use the product, specifically for a production deployment.
    - P1: Issues that impact the user&#39;s ability to use the product, but not as severely (or not for their production deployment).
    - P2: Issues that are low priority and can wait until the next business day
    - P3: Issues that are not important or time sensitive

    Here are some examples of tickets and their priorities:
    - &#34;Our production deployment just went down because it ran out of memory. Please help.&#34;: P0
    - &#34;Our staging / dev / QA deployment just went down because it ran out of memory. Please help.&#34;: P1
    - &#34;I&#39;m having trouble logging in to my account.&#34;: P1
    - &#34;The UI is not loading.&#34;: P1
    - &#34;I need help setting up my account.&#34;: P2
    - &#34;I have a question about the product.&#34;: P3
    &#34;&#34;&#34;,
    allow_multiple_branches=True,
)
def route_ticket(dag_run: DagRun) -&gt; str:
    return dag_run.conf.get(&#34;ticket&#34;)

@task
def handle_p0_ticket(ticket: str):
    print(f&#34;Handling P0 ticket: {ticket}&#34;)

@task
def handle_p1_ticket(ticket: str):
    print(f&#34;Handling P1 ticket: {ticket}&#34;)

@task
def handle_p2_ticket(ticket: str):
    print(f&#34;Handling P2 ticket: {ticket}&#34;)

@task
def handle_p3_ticket(ticket: str):
    print(f&#34;Handling P3 ticket: {ticket}&#34;)

@dag(
    start_date=pendulum.datetime(2025, 1, 1, tz=&#34;UTC&#34;),
    schedule=None,
    catchup=False,
    params={&#34;ticket&#34;: &#34;Hi, our production deployment just went down because it ran out of memory. Please help.&#34;}
)
def support_ticket_routing():
    ticket = route_ticket()

    handle_p0_ticket(ticket)
    handle_p1_ticket(ticket)
    handle_p2_ticket(ticket)
    handle_p3_ticket(ticket)

support_ticket_routing()"><pre><span>import</span> <span>pendulum</span>
<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>dagrun</span> <span>import</span> <span>DagRun</span>

<span>@<span>task</span>.<span>llm_branch</span>(</span>
<span>    <span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>&#34;&#34;&#34;</span></span>
<span><span>    You are a support agent that routes support tickets based on the priority of the ticket.</span></span>
<span><span></span></span>
<span><span>    Here are the priority definitions:</span></span>
<span><span>    - P0: Critical issues that impact the user&#39;s ability to use the product, specifically for a production deployment.</span></span>
<span><span>    - P1: Issues that impact the user&#39;s ability to use the product, but not as severely (or not for their production deployment).</span></span>
<span><span>    - P2: Issues that are low priority and can wait until the next business day</span></span>
<span><span>    - P3: Issues that are not important or time sensitive</span></span>
<span><span></span></span>
<span><span>    Here are some examples of tickets and their priorities:</span></span>
<span><span>    - &#34;Our production deployment just went down because it ran out of memory. Please help.&#34;: P0</span></span>
<span><span>    - &#34;Our staging / dev / QA deployment just went down because it ran out of memory. Please help.&#34;: P1</span></span>
<span><span>    - &#34;I&#39;m having trouble logging in to my account.&#34;: P1</span></span>
<span><span>    - &#34;The UI is not loading.&#34;: P1</span></span>
<span><span>    - &#34;I need help setting up my account.&#34;: P2</span></span>
<span><span>    - &#34;I have a question about the product.&#34;: P3</span></span>
<span><span>    &#34;&#34;&#34;</span>,</span>
<span>    <span>allow_multiple_branches</span><span>=</span><span>True</span>,</span>
<span>)</span>
<span>def</span> <span>route_ticket</span>(<span>dag_run</span>: <span>DagRun</span>) <span>-&gt;</span> <span>str</span>:
    <span>return</span> <span>dag_run</span>.<span>conf</span>.<span>get</span>(<span>&#34;ticket&#34;</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p0_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f&#34;Handling P0 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>&#34;</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p1_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f&#34;Handling P1 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>&#34;</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p2_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f&#34;Handling P2 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>&#34;</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p3_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f&#34;Handling P3 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>&#34;</span>)

<span>@<span>dag</span>(</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>1</span>, <span>1</span>, <span>tz</span><span>=</span><span>&#34;UTC&#34;</span>),</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>    <span>params</span><span>=</span>{<span>&#34;ticket&#34;</span>: <span>&#34;Hi, our production deployment just went down because it ran out of memory. Please help.&#34;</span>}</span>
<span>)</span>
<span>def</span> <span>support_ticket_routing</span>():
    <span>ticket</span> <span>=</span> <span>route_ticket</span>()

    <span>handle_p0_ticket</span>(<span>ticket</span>)
    <span>handle_p1_ticket</span>(<span>ticket</span>)
    <span>handle_p2_ticket</span>(<span>ticket</span>)
    <span>handle_p3_ticket</span>(<span>ticket</span>)

<span>support_ticket_routing</span>()</pre></div>
</article></div></div>
  </body>
</html>
