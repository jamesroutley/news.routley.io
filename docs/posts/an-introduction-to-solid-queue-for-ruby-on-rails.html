<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.appsignal.com/2025/05/07/an-introduction-to-solid-queue-for-ruby-on-rails.html">Original</a>
    <h1>An Introduction to Solid Queue for Ruby on Rails</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>One of the most exciting additions to Rails 8 is undoubtedly Solid Queue, a new
library for processing background jobs.</p>
<p>You might not think it&#39;s that big of a deal. After all, there are plenty of
other queuing systems out there. If you work with Rails, you&#39;ll likely know about Sidekiq and Resque — both are exceptionally performant and reliable. There is also GoodJob and the venerable DelayedJob.
With all those options available, do we really need another queuing system?</p>
<p>Let&#39;s find out together. In this two-part series, we&#39;ll dig deep into Solid Queue&#39;s internals, discover what makes it unique, and learn more
about why it was created in the first place.</p>
<h2 id="why-solid-queue-for-ruby-on-rails">Why Solid Queue for Ruby on Rails?</h2>
<p>Since Rails 7, the team at 37Signals has been on a quest to reduce the operational overhead needed to launch a new Rails
application. As part of this, they made SQLite the new default database for Rails apps - even in production.
Furthermore, they started an effort to eliminate additional infrastructure dependencies to take full advantage of this
new default.</p>
<p>37Signals had used <a href="https://github.com/resque/resque">Resque</a> until then, and Resque requires Redis to function. So does <a href="https://github.com/sidekiq/sidekiq">Sidekiq</a>, for that matter. To get rid of
Redis, they had to create a queuing system that relies only on your database — and that queuing system turned out to be
<a href="https://github.com/rails/solid_queue">Solid Queue</a>.</p>
<p>So that&#39;s its main selling point: No additional dependencies; just use your database. Very nice! However, as with any queuing
system — and especially one that is the new Rails default — Solid Queue needs to satisfy some stringent requirements.</p>
<p>It must provide all the features Rails developers are used to from other background job systems. As the Rails
default, it must support all databases that Rails works with. Obviously, it needs to satisfy standard safety
requirements — as in, it must never, ever lose jobs. Last but not least, it must be fast enough to be a viable
option for large production systems.</p>
<p>That&#39;s quite a tall order! So, how does Solid Queue address all those requirements?</p>
<h2 id="solid-queue-from-the-top">Solid Queue From The Top</h2>
<p>There are many details to consider, but let&#39;s start with a high-level architectural overview. You need to be aware of
two significant components: Jobs and Workers.</p>
<p><code>Job</code> is an <code>ActiveRecord</code> model, and what the user interacts with. Note that that&#39;s not
necessarily true for other <code>ActiveJob</code> backends — it&#39;s just how SolidQueue implements background jobs. If you need to
create a new background job, this is the class that you inherit from. <code>Job</code> also defines methods that enable you to
enqueue work, such as <code>Job.perform_later</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# app/jobs/my_job.rb
class MyJob &lt; ApplicationJob
  queue_as :default

  def perform
    # Do something later
  end
end
"></pre></div></figure>
<p>Workers, as the name suggests, are the elements that perform the actual work. These are generally not directly created
by the programmer but automatically created based on how you configure your application. For example, to have your
application spawn two workers listening to all and two specific queues respectively, you&#39;d use the following
configuration file:</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="yaml" data-theme="github-dark" data-raw="# config/queue.yml
production:
  workers:
    - queues: &#34;*&#34;
    - queues: [default, critical]
"></pre></div></figure>
<p>Workers are spawned as processes, running in the background, waiting for jobs to be assigned to them. As you may have guessed,
your database is the missing link between jobs and workers. Whenever Solid Queue does anything, one database table or
other is involved. SolidQueue does a lot of things, so
<a href="https://github.com/rails/solid_queue/blob/main/lib/generators/solid_queue/install/templates/db/queue_schema.rb">a lot of tables</a>
are needed.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/generators/solid_queue/install/templates/db/queue_schema.rb
ActiveRecord::Schema[7.1].define(version: 1) do
  create_table &#34;solid_queue_jobs&#34;, force: :cascade do |t|
    # ...
  end

  create_table &#34;solid_queue_ready_executions&#34;, force: :cascade do |t|
    # ...
  end

  create_table &#34;solid_queue_scheduled_executions&#34;, force: :cascade do |t|
    # ...
  end

  create_table &#34;solid_queue_claimed_executions&#34;, force: :cascade do |t|
    # ...
  end

  create_table &#34;solid_queue_blocked_executions&#34;, force: :cascade do |t|
    # ...
  end

  create_table &#34;solid_queue_failed_executions&#34;, force: :cascade do |t|
    #...
  end

  # Lots more tables below...
end
"></pre></div></figure>

<h2 id="the-life-and-death-of-a-solid-job">The Life and Death of a SOLID Job</h2>
<p>To understand what all those tables do and how they relate to the various features of Solid Queue, let&#39;s look at the
life cycle of a job. When a user enqueues a job to be executed later — let&#39;s say MyJob — a record is created in the
<code>solid_queue_jobs</code> table. The record contains all the data required to execute the job — arguments, its name, the queue
it is put in, and so forth. If the job is enqueued to run as soon as possible (rather than scheduled to run at some
later point in time), an additional record is written to <code>solid_queue_ready_executions</code>.</p>
<p>For example, running
<code>MyJob.perform_later</code> results in the following SQL:</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="sql" data-theme="github-dark" data-raw="INSERT INTO &#34;solid_queue_jobs&#34; (&#34;queue_name&#34;, &#34;class_name&#34;, &#34;arguments&#34;, &#34;priority&#34;, &#34;active_job_id&#34;, &#34;scheduled_at&#34;, &#34;finished_at&#34;, &#34;concurrency_key&#34;, &#34;created_at&#34;, &#34;updated_at&#34;)
  VALUES (&#39;default&#39;, &#39;MyJob&#39;, &#39;{&#34;job_class&#34;: &#34;MyJob&#34;,&#34;...&#34;,}&#39;, 0, &#39;...&#39;, &#39;2024-12-01 14:00:00&#39;, NULL, NULL, &#39;2024-12-01 14:00:00&#39;, &#39;2024-12-01 14:00:00&#39;)
  RETURNING &#34;id&#34;
INSERT INTO &#34;solid_queue_ready_executions&#34; (&#34;job_id&#34;, &#34;queue_name&#34;, &#34;priority&#34;, &#34;created_at&#34;)
  VALUES (1, &#39;default&#39;, 0, &#39;2024-12-01 14:00:00&#39;)
  RETURNING &#34;id&#34;
"></pre></div></figure>
<p>Your workers poll this table for new records. A worker process that finds a new record will first claim it by writing
another record to the <code>solid_queue_claimed_executions</code> table — we&#39;ll learn why that is necessary later. Only then will
the worker actually execute the job. Below is some heavily edited code to illustrate what is happening (much more is
happening in the actual code). If you are curious about the nitty-gritty details, I highly recommend you <a href="https://github.com/rails/solid_queue/blob/main/lib/solid_queue/worker.rb">check out the original source code</a>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="class Worker
  def run
    loop do
      break if shutting_down?

      unless poll &gt; 0
        # Polling interval is configurable and defaults to 1ms
        sleep(polling_interval)
      end
    end
  end

  def poll
    # Claim jobs and then execute claimed jobs.
    claim_executions.then do |executions|
      executions.each do |execution|
        # Actually execute the job
      end
    end
  end

  def claim_executions
    # Query the ready executions table and claim a job for execution.
    with_polling_volume do
      SolidQueue::ReadyExecution.claim
    end
  end
end
"></pre></div></figure>
<p>Once a worker finishes a job, it removes the corresponding records from the <code>solid_queue_jobs,</code>
<code>solid_queue_ready_executions</code>, and <code>solid_queue_claimed_executions</code> tables. That&#39;s all there is to it — just polling
some tables, creating and removing records. Not so tricky, right? It would be if there weren&#39;t critical
non-functional requirements to consider, too.</p>
<h2 id="on-performance">On Performance</h2>
<p>To achieve production-ready performance, Solid Queue uses ingenious database design. You may have wondered why
workers poll <code>solid_queue_ready_executions</code> rather than <code>solid_queue_jobs</code>. The additional table seems redundant at
first glance.</p>
<p>Consider that <code>solid_queue_jobs</code> may contain thousands or millions of records, and querying that pile of data takes
time. In comparison, <code>solid_queue_ready_executions</code> is tiny, as it only contains records for jobs that must be executed
right now! That leads to some serious speedup.</p>
<p>The introduction of additional tables also simplifies queries. Workers only use two different queries for polling. They either
poll all queues or specific ones. That, in turn, allows for some nice
<a href="https://en.wikipedia.org/wiki/Database_index#Covering_index">covering</a> indices.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="sql" data-theme="github-dark" data-raw="SELECT job_id
  FROM solid_queue_ready_executions
  WHERE queue_name = &#34;default&#34;
  ORDER BY priority ASC, job_id ASC
  LIMIT 4
  FOR UPDATE SKIP LOCKED
"></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# Indices for polling solid queue ready executions
create_table &#34;solid_queue_ready_executions&#34;, force: :cascade do |t|
  t.index [ &#34;priority&#34;, &#34;job_id&#34; ], name: &#34;index_solid_queue_poll_all&#34;
  t.index [ &#34;queue_name&#34;, &#34;priority&#34;, &#34;job_id&#34; ], name: &#34;index_solid_queue_poll_by_queue&#34;
end
"></pre></div></figure>
<p>All that still wouldn&#39;t be enough to achieve truly outstanding performance. Traditionally, queuing systems that rely on
polling tables have had a significant problem. One worker would block all others while querying and updating the polling
table.</p>
<p>Let&#39;s take a look at why. Consider the following query:</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="sql" data-theme="github-dark" data-raw="SELECT id
  FROM jobs
  WHERE queue = &#34;default&#34;
  AND claimed = 0
  ORDER_BY priority, id
  LIMIT 2
  FOR UPDATE;
"></pre></div></figure>
<p>The <code>FOR UPDATE</code> statement locks the rows selected by the query. This is necessary to avoid nasty race conditions, such as
multiple workers grabbing the same job. But that also means that any worker running this query would block read access
to the table. Thus, other workers would have to wait for that query to finish. The polling table becomes a bottleneck
that hinders rapid job execution.</p>
<p>Luckily, modern databases (PostgreSQL &gt;= 9.5, MySQL &gt;= 8.0) solve this problem. The <code>SKIP LOCKED</code> statement allows the
database to lock only the records that are being updated. The rest of the table remains unlocked and free to be polled
concurrently.</p>
<p>SQLite does not support <code>SKIP LOCKED</code>, so worker processes must queue up. In most cases, this shouldn&#39;t be an
issue. SQLite writes are fast as the database is present on disk. Even so, this is a limitation that you should
be aware of.</p>
<p>Whether you&#39;re using SQLite or another database, <a href="https://www.appsignal.com/ruby/solid-queue-monitoring">AppSignal provides Solid Queue performance monitoring</a> out of the box! We&#39;ll talk more about this in part two of this series.</p>
<h2 id="safety-first">Safety First</h2>
<p>We&#39;ve spent some time discussing <code>solid_queue_ready_executions</code>, but another table is instrumental for
ensuring that Solid Queue functions reliably. A key requirement of any queuing system is that any job being
enqueued is executed at least once. In other words, jobs must never be lost—we already alluded to this in the
introduction.</p>
<p>Without additional safety measures, this could quickly happen. Imagine that a worker starts working on a job and, in
doing so, updates the corresponding job record to claim it. Of course, this is necessary to avoid multiple workers
running a job simultaneously.</p>
<p>Imagine that suddenly, this worker process dies without finishing execution. Your machine might crash, and the OS may kill the worker for consuming too much memory — accidents happen, you know. The job it claimed will remain stuck
forever because no other workers can grab it. Thus, it will never be executed, and your users will be sad and
angry. The end.</p>
<p>That is, unless we add additional safety measures. Solid Queue solves this problem by introducing yet more tables —
<code>solid_queue_claimed_executions</code> and <code>solid_queue_processes</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="ActiveRecord::Schema[7.1].define(version: 1) do
  create_table &#34;solid_queue_claimed_executions&#34;, force: :cascade do |t|
    t.bigint &#34;job_id&#34;, null: false
    t.bigint &#34;process_id&#34;
    # ...
  end

  create_table &#34;solid_queue_processes&#34;, force: :cascade do |t|
    t.datetime &#34;last_heartbeat_at&#34;, null: false
    t.integer &#34;pid&#34;, null: false
    #  ...
  end
  # ...
end
"></pre></div></figure>
<p>We&#39;ve already mentioned <code>solid_queue_claimed_executions</code>. Let&#39;s look at what happens when a worker claims
a job. For one, it sets the <code>claimed</code> flag in the <code>solid_queue_jobs</code> table. Additionally, a record is created in
<code>solid_queue_claimed_executions</code>. This record contains the <code>job_id</code> of the job being claimed and the id of the worker
process that makes the claim.</p>
<p>So, what is the <code>solid_queue_processes</code> table good for? Any worker process will create and periodically update a record
in this table by setting <code>last_heartbeat_at</code>. Of course, that alone wouldn&#39;t solve our problem.</p>
<p>We need another process to keep track of running processes: the so-called supervisor. This process runs in the background
and periodically checks <code>solid_queue_processes</code>. A record with a <code>last_heartbeat_at</code> older than a threshold — which
defaults to 5 minutes — indicates that the corresponding worker has met a tragic fate.</p>
<p>If such a record is found, the supervisor jumps into action. First, it removes the record from <code>solid_queue_processes</code>.
Then, it marks any jobs previously claimed by the now-deceased worker as up-for-grabs. Thus, other workers can claim
them, avoiding the stuck-job situation.</p>
<h2 id="more-to-discover-in-solid-queue">More to Discover in Solid Queue</h2>
<p>In this post, we covered a fair bit of Solid Queue&#39;s internals. We looked at its high-level architecture and how its most
essential feature—enqueuing and executing a job—works under the hood. We also learned the critical role of
<code>FOR UPDATE SKIP LOCKED</code> in performance. Finally, we learned how the supervisor process helps avoid stuck
jobs.</p>
<p>But there is more to discover. Solid Queue offers many more features we haven&#39;t touched on, such as scheduling
recurring and sequential jobs. Stay tuned as we continue our deep dive in part two of this series.</p></div></div></div>
  </body>
</html>
