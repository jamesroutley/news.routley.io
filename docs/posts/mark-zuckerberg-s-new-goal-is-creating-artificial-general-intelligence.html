<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theverge.com/2024/1/18/24042354/mark-zuckerberg-meta-agi-reorg-interview">Original</a>
    <h1>Mark Zuckerberg’s new goal is creating artificial general intelligence</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p>Fueling the generative AI craze is a belief that the tech industry is on a path to achieving superhuman, god-like intelligence.</p><p>OpenAI’s stated mission is to create this artificial general intelligence, or AGI. Demis Hassabis, the leader of Google’s AI efforts, <a href="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks">has the same goal</a>.</p><p>Now, Meta CEO Mark Zuckerberg is entering the race. While he doesn’t have a timeline for when AGI will be reached, or even an exact definition for it, he wants to build it. At the same time, <a href="https://www.theverge.com/e/23807588">he’s shaking things up by moving Meta’s AI research group</a>, FAIR, to the same part of the company as the team building generative AI products across Meta’s apps. The goal is for Meta’s AI breakthroughs to more directly reach its billions of users. </p><p>“We’ve come to this view that, in order to build the products that we want to build, we need to build for general intelligence,” Zuckerberg tells me in an exclusive interview. “I think that’s important to convey because a lot of the best researchers want to work on the more ambitious problems.”</p><div><form action="#"><div><div><h2>Command Line</h2><p> / <span>A newsletter from Alex Heath about the tech industry’s inside conversation.</span></p></div></div></form></div><p>Here, Zuckerberg is saying the quiet part aloud. The battle for AI talent has never been more fierce, with every company in the space vying for an extremely small pool of researchers and engineers. Those with the needed expertise can command eye-popping compensation packages to the tune of over $1 million a year. CEOs like Zuckerberg are routinely pulled in to try to win over a key recruit or keep a researcher from defecting to a competitor.</p><p>“We’re used to there being pretty intense talent wars,” he says. “But there are different dynamics here with multiple companies going for the same profile, [and] a lot of VCs and folks throwing money at different projects, making it easy for people to start different things externally.”</p><p>After talent, the scarcest resource in the AI field is the computing power needed to train and run large models. On this topic, Zuckerberg is ready to flex. He tells me that, by the end of this year, Meta will own more than 340,000 of Nvidia’s H100 GPUs — the industry’s <a href="https://www.theverge.com/2023/8/11/23828874/inside-the-hunt-for-ai-chips-command-line">chip of choice for building generative AI</a>. </p><div><div><p>“We have built up the capacity to do this at a scale that may be larger than any other individual company”</p></div></div><p><a href="https://www.theverge.com/2023/12/4/23987953/the-gpu-haves-and-have-nots">External research has pegged</a> Meta’s H100 shipments for 2023 at 150,000, a number that is tied only with Microsoft’s shipments and at least three times larger than everyone else’s. When its Nvidia A100s and other AI chips are accounted for, Meta will have a stockpile of almost 600,000 GPUs by the end of 2024, according to Zuckerberg. </p><p>“We have built up the capacity to do this at a scale that may be larger than any other individual company,” he says. “I think a lot of people may not appreciate that.”</p><p><h3>The realization</h3></p><p>No one working on AI, including Zuckerberg, seems to have a clear definition for AGI or an idea of when it will arrive.</p><p>“I don’t have a one-sentence, pithy definition,” he tells me. “You can quibble about if general intelligence is akin to human level intelligence, or is it like human-plus, or is it some far-future super intelligence. But to me, the important part is actually the breadth of it, which is that intelligence has all these different capabilities where you have to be able to reason and have intuition.”</p><p>He sees its eventual arrival as being a gradual process, rather than a single moment. “I’m not actually that sure that some specific threshold will feel that profound.”</p><p>As Zuckerberg explains it, Meta’s new, broader focus on AGI was influenced by <a href="https://www.theverge.com/2023/7/21/23803234/the-biggest-ai-release-since-chatgpt">the release of Llama 2</a>, its latest large language model, last year. The company didn’t think that the ability for it to generate code made sense for how people would use a LLM in Meta’s apps. But it’s still an important skill to develop for building smarter AI, so Meta built it anyway.</p><p>“One hypothesis was that coding isn’t that important because it’s not like a lot of people are going to ask coding questions in WhatsApp,” he says. “It turns out that coding is actually really important structurally for having the LLMs be able to understand the rigor and hierarchical structure of knowledge, and just generally have more of an intuitive sense of logic.”</p><div><div><p>“Our ambition is to build things that are at the state of the art and eventually the leading models in the industry”</p></div></div><p>Meta is training Llama 3 now, and it will have code-generating capabilities, he says. Like <a href="https://www.theverge.com/2023/12/6/23990466/google-gemini-llm-ai-model">Google’s new Gemini model</a>, another focus is on more advanced reasoning and planning abilities. </p><p>“Llama 2 wasn’t an industry-leading model, but it was the best open-source model,” he says. “With Llama 3 and beyond, our ambition is to build things that are at the state of the art and eventually the leading models in the industry.”</p><p><h3>Open versus closed</h3></p><p>The question of who gets to eventually control AGI is a hotly debated one, as the <a href="https://www.theverge.com/23966325/openai-sam-altman-fired-turmoil-chatgpt">near implosion of OpenAI</a> recently showed the world.</p><p>Zuckerberg wields total power at Meta thanks to his voting control over the company’s stock. That puts him in a uniquely powerful position that could be dangerously amplified if AGI is ever achieved. His answer is the <a href="https://www.theverge.com/2023/7/18/23799025/meta-ai-llama-2-open-source-microsoft">playbook that Meta has followed so far for Llama</a>, which can — at least <a href="https://www.theverge.com/2023/10/30/23935587/meta-generative-ai-models-open-source">for most use cases</a> — be considered open source.</p><p>“I tend to think that one of the bigger challenges here will be that if you build something that’s really valuable, then it ends up getting very concentrated,” Zuckerberg says. “Whereas, if you make it more open, then that addresses a large class of issues that might come about from unequal access to opportunity and value. So that’s a big part of the whole open-source vision.”</p><p>Without naming names, he contrasts Meta’s approach to that of OpenAI’s, which began with the intention of open sourcing its models but has becoming increasingly less transparent. “There were all these companies that used to be open, used to publish all their work, and used to talk about how they were going to open source all their work. I think you see the dynamic of people just realizing, ‘Hey, this is going to be a really valuable thing, let’s not share it.’”</p><p>While Sam Altman and others espouse the safety benefits of a more closed approach to AI development, Zuckerberg sees a shrewd business play. Meanwhile, the models that have been deployed so far have yet to cause catastrophic damage, he argues.</p><p>“The biggest companies that started off with the biggest leads are also, in a lot of cases, the ones calling the most for saying you need to put in place all these guardrails on how everyone else builds AI,” he tells me. “I’m sure some of them are legitimately concerned about safety, but it’s a hell of a thing how much it lines up with the strategy.”</p><div><div><p>“I’m sure some of them are legitimately concerned about safety, but it’s a hell of a thing how much it lines up with the strategy”</p></div></div><p>Zuckerberg has his own motivations, of course. The end result of his open vision for AI is <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4543807">still a concentration of power</a>, just in a different shape. Meta already has more users than almost any company on Earth and a wildly profitable social media business. AI features can arguably make his platforms even stickier and more useful. And if Meta can effectively standardize the development of AI by releasing its models openly, its influence over the ecosystem will only grow.</p><p>There’s another wrinkle: If AGI is ever achieved at Meta, the call to open source it or not is ultimately Zuckerberg’s. He’s not ready to commit either way. </p><p>“For as long as it makes sense and is the safe and responsible thing to do, then I think we will generally want to lean towards open source,” he says. “Obviously, you don’t want to be locked into doing something because you said you would.”</p><p><h3>Don’t call it a pivot</h3></p><p>In the broader context of Meta, the timing of Zuckerberg’s new AGI push is a bit awkward. </p><p>It has been only two years since he <a href="https://www.theverge.com/22749919/mark-zuckerberg-facebook-meta-company-rebrand">changed the company name</a> to focus on the metaverse. Meta’s latest smart glasses with Ray-Ban are <a href="https://www.theverge.com/23922425/ray-ban-meta-smart-glasses-review">showing early traction</a>, but full-fledged AR glasses feel increasingly further out. Apple, meanwhile, has recently validated his bet on headsets with the <a href="https://www.theverge.com/2024/1/8/24001858/apple-vision-pro-release-date-availability-price">launch of the Vision Pro</a>, even though VR is still a niche industry.</p><p>Zuckerberg, of course, disagrees with the characterization of his focus on AI being a pivot. </p><p>“I don’t know how to more unequivocally state that we’re continuing to focus on Reality Labs and the metaverse,” he tells me, pointing to the fact that Meta is still spending north of $15 billion a year on the initiative. Its Ray-Ban smart glasses <a href="https://www.theverge.com/2023/12/12/23998780/ray-ban-smart-glasses-hey-meta-multimodal-ai-features">recently added a visual AI assistant that can identify objects</a> and translate languages. He sees generative AI playing a more critical role in Meta’s hardware efforts going forward.</p><div><div><p>“I don’t know how to more unequivocally state that we’re continuing to focus on Reality Labs and the metaverse”</p></div></div><p>He sees a future in which virtual worlds are generated by AI and filled with AI characters that accompany real people. He says a new platform is coming this year to let anyone create their own AI characters and distribute them across Meta’s social apps. Perhaps, he suggests, these AIs will even be able to post their own content to the feeds of Facebook, Instagram, and Threads.</p><p>Meta is still a metaverse company. It’s the biggest social media company in the world. It’s now trying to build AGI. Zuckerberg frames all this around the overarching mission of “building the future of connection.” </p><p>To date, that connection has been mostly humans interacting with each other. Talking to Zuckerberg, it’s clear that, going forward, it’s increasingly going to be about humans talking to AIs, too. It’s obvious that he views this future as inevitable and exciting, whether the rest of us are ready for it or not.</p></div></div>
  </body>
</html>
