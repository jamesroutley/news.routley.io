<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://incident.io/blog/festive-macbooks">Original</a>
    <h1>Tracking developer build times to decide if the M3 MacBook is worth upgrading</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>All <a href="http://incident.io">incident.io</a> developers are given a MacBook which they use for their development work.</p><p>That meant when Apple released the M3 MacBook Pros in October, people naturally started asking questions like ‚Äúwow, how much more productive might I be if my laptop looked <em>that</em> good?‚Äù and ‚Äúperhaps we‚Äôd be more secure if our machines were Space Black ü§î‚Äù</p><p>Pete‚Äôs (our CTO) response to this was ‚Äúif you can prove it‚Äôs worthwhile, we‚Äôll do it‚Äù:</p><figure><span><img alt="" loading="lazy" width="2956" height="990" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F610e8248852f774c964ad24c8619b758b5876bc8-2956x990.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F610e8248852f774c964ad24c8619b758b5876bc8-2956x990.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>So with an upgrade to a machine that Apple itself describes as ‚Äòunmistakably pro‚Äô hanging in the balance and a personal challenge from Pete (our CTO) to find data to prove it was worthwhile, we set off on a journey that included:</p><ul><li>Hacking together a custom Go hot-reloader.</li><li>Using said hot-reloader to track build telemetry from developer laptops.</li><li>Loading this data into OpenAI‚Äôs latest models and jumping head-first into an extremely nerdy (and overkill) analysis.</li></ul><p>With this, we had everything (and more!) needed to conclusively decide if the M3 was worth the upgrade, or if our team would be getting coal in their stockings this Christmas.</p><h2 id="what-does-worth-the-upgrade-mean">What does ‚Äúworth the upgrade‚Äù mean?</h2><p>We want to know if it‚Äôs worth upgrading existing developer machines from M1/M2 chips to M3.</p><p>Quantifying developer productivity is difficult (see <a href="https://newsletter.pragmaticengineer.com/p/measuring-developer-productivity" target="_blank">Measuring developer productivity</a>), but we know (intuitively, and through research such as <a href="https://martinfowler.com/articles/developer-effectiveness.html" target="_blank">Maximising Developer Effectiveness</a>) that faster feedback loops make developers more effective.</p><p>For our team, the most common feedback loops in local development are:</p><ul><li>Compiling our Go monolith.</li><li>Running code-generation: API clients, interfaces, and more.</li><li>Hot-reloading the frontend/mobile app.</li></ul><p>All developers work with a fully fledged <a href="http://incident.io">incident.io</a> environment locally on their laptops: it allows for a &lt;30s feedback loop between changing code and running it, which is a key factor in how productively you can work with our codebase.</p><p>For that reason, compiling the Go app is one of the most frequent of these loops and one of the most expensive, with the codebase nearing 1M lines-of-code. As the most resource hungry of those tasks (in terms of system resources) it would likely benefit most from more powerful hardware, too.</p><p>For that reason we picked speed of Go compilation as the key metric of MacBook performance; now we just need to measure it.</p><h2 id="collecting-build-telemetry">Collecting build telemetry</h2><p>We‚Äôve used <a href="https://github.com/codegangsta/gin" target="_blank">codegangsta/gin</a> as a hot-reloader for Go since first creating the <a href="http://incident.io">incident.io</a> GitHub repo. It worked well ‚Äì its job being to compile and then restart the new version of the app whenever code files change ‚Äì but we‚Äôd recently hit issues that had made us consider moving.</p><p>When we looked at alternative hot-reloaders, though, we didn‚Äôt find any that would provide the telemetry we‚Äôd want to track our build times.</p><p>What we wanted to track¬†‚Äì for each build ‚Äì was:</p><ul><li>System dimensions: your platform (M1/M2/M3), total memory, etc.</li><li>Runtime metrics: OS, memory usage, power source, battery level, etc.</li><li>Build telemetry: total duration, Go build stages, which files triggered build, etc.</li></ul><p>In absence of a ready-made alternative, we decided to build our own that we could tailor to our needs. As our primary motivator is to produce build telemetry, this process began as a modest <code>main.go</code> that we tweaked until it could extract what we needed from the host.</p><p>Mac machines have a number of binaries that can help you with this ‚Äì <code>memory_pressure</code>, <code>docker</code>, <code>sysctl</code> and <code>pmset</code> ‚Äì and <a href="https://gist.github.com/lawrencejones/c576e6f4521458be7f5442f762e82e12" target="_blank">the code</a> is mostly exec‚Äôing and parsing the output of them:</p><pre><code>memoryFreeRegex <span>:=</span> regexp<span>.</span>
  <span>MustCompile</span><span>(</span><span>`^System-wide memory free percentage:\s+(\d+)%`</span><span>)</span>


memoryPressure<span>,</span> <span>_</span> <span>:=</span> exec<span>.</span><span>Command</span><span>(</span><span>&#34;memory_pressure&#34;</span><span>)</span><span>.</span><span>Output</span><span>(</span><span>)</span>
<span>for</span> <span>_</span><span>,</span> line <span>:=</span> <span>range</span> strings<span>.</span><span>Split</span><span>(</span><span>string</span><span>(</span>memoryPressure<span>)</span><span>,</span> <span>&#34;\n&#34;</span><span>)</span> <span>{</span>
	<span>if</span> memoryFreeRegex<span>.</span><span>MatchString</span><span>(</span>line<span>)</span> <span>{</span>
		
		ev<span>.</span>MemoryFree <span>=</span> memoryFreeRegex<span>.</span><span>FindStringSubmatch</span><span>(</span>line<span>)</span><span>[</span><span>1</span><span>]</span>
	<span>}</span>
<span>}</span></code></pre><p>Once we‚Äôd built the system + runtime collectors, it was simple to wrap a Go build command so we could extract build-specific measures like time in stage (linker, compile, etc) and track which files had caused us to trigger a build (more on why this is useful later).</p><p>The end result was hot-reloader we ran from our existing <code>make run</code> target:</p><p>This is an invisible change to our engineering team, but meant that now ‚Äì on completion of every build ‚Äì we‚Äôll send telemetry events to an HTTP endpoint of our choosing. We setup a Fivetran webhook endpoint receiver (our ETL tool, see <a href="https://incident.io/blog/data-stack">Modern data stack for startups</a>) that could push the events into our data warehouse, and that was it!</p><figure><span><img alt="" loading="lazy" width="2450" height="1716" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F596785933c211b5f4981fbb4ad42af7469986693-2450x1716.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F596785933c211b5f4981fbb4ad42af7469986693-2450x1716.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><figure><span><img alt="" loading="lazy" width="6845" height="3966" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F4a8322aade4997021a83f833bbd8b4499ccba438-6845x3966.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F4a8322aade4997021a83f833bbd8b4499ccba438-6845x3966.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Finally, we have the data we need to judge our Mac-battle.</p><h2 id="analysing-the-data">Analysing the data</h2><p>This is the part we were most excited about: having done the work to produce high-quality data and (impatiently) waited several weeks to build a large enough dataset, now was time to nerd-out and see what it can tell us.</p><p>It was particularly exciting because of the type of analysis it would require: most developers will know that build time is highly variable even on the same system. The Go compiler especially does a lot to cache builds, so even the most powerful M3 Max be much slower to build with no cache than an old Intel MacBook will with cache.</p><p>All this means we can‚Äôt just average the build times across platforms and straight up compare.</p><p>Instead, we‚Äôll need to really dig into the underlying data, presenting a great opportunity (excuse?) to play with OpenAI‚Äôs fancy new code interpreter.</p><p>It‚Äôs almost a perfect use case for it, after all!</p><h3 id="creating-an-openai-assistant">Creating an OpenAI assistant</h3><p>We use OpenAI to power features like <a href="https://incident.io/changelog/incident-summaries-with-ai">auto-generating incident summaries</a> and (soon!) a chat interface to your incident data, so we have experience analysing data with AI tools.</p><p>Generally, the process includes:</p><ul><li>Exporting your data to a CSV: we used BigQuery to export the results of <code>select * except(payload) from developer__build_events</code></li><li>Create an ‚Äò<a href="https://platform.openai.com/docs/assistants/overview" target="_blank">Assistant</a>‚Äô with a prompt explaining your purpose, and provide it the CSV file with your data.</li></ul><p>We‚Äôre using the experimental <code>gpt-4-1106-preview</code> model to power our assistant, and enabled code interpreter to power the data analysis. It only took a few minutes before we had the assistant ready and responding to our questions in the playground.</p><figure><span><img alt="" loading="lazy" width="3104" height="2108" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F8bf6cd2503c3796d6905661f1e276988c1e8f1c5-3104x2108.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F8bf6cd2503c3796d6905661f1e276988c1e8f1c5-3104x2108.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>This is the interface we‚Äôll use to query our data, simply by asking the assistant questions.</p><h3 id="cleaning-data-power-source-cancellations-etc">Cleaning data (power source, cancellations, etc)</h3><p>We have about 25k builds in our dataset taken from all times of the day, a variety of laptops, and many different conditions.</p><p>For us to make good comparisons between platforms, we‚Äôd want to establish as fair a comparison as possible for those builds, which means removing builds that have confounding factors.</p><ul><li>Failed or cancelled builds: if someone quits a build before it completes, we shouldn‚Äôt use that when examining build speed (it‚Äôs a job half-done).</li><li>Running on battery power: OS X will throttle performance to preserve battery life.</li></ul><p>Let‚Äôs get a picture of how many of our build events are unsuccessful, along with a sense of how many builds were for each platform.</p><p>Asking:</p><blockquote>Show me the distribution of builds by machine platform, where the platforms are ordered by M1 to M3, and within the platform class Pro comes before Max.</blockquote><p>Feels weird to be talking to a machine like this but‚Ä¶</p><figure><span><img alt="" loading="lazy" width="1674" height="1142" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fa9847b6a0cc30c2f36611b195831b999d6a7b840-1674x1142.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fa9847b6a0cc30c2f36611b195831b999d6a7b840-1674x1142.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fa9847b6a0cc30c2f36611b195831b999d6a7b840-1674x1142.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>This is exactly what we asked for. Pretty wild, right?</p><p>Failed builds are almost never what we want, so we can instruct the assistant to drop these builds:</p><blockquote>From this moment on, please exclude failed builds from the dataset.</blockquote><p>We have this assumption that machines on battery power would be throttled, causing the build times to be poorly representative of general performance. I‚Äôd love to confirm this by comparing performance of of the same platform across power sources.</p><p>Asking:</p><blockquote>Focusing only on successful builds with the Apple M1 Pro and Apple M2 Max platforms, can you visually compare the build duration across different power sources please?</blockquote><figure><span><img alt="" loading="lazy" width="1604" height="968" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F00c493fbd51992724341425d531a5b0d76cb70b5-1604x968.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F00c493fbd51992724341425d531a5b0d76cb70b5-1604x968.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F00c493fbd51992724341425d531a5b0d76cb70b5-1604x968.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>We can see that AC power is generally faster, even if we have longer builds in each AC power category (due to us doing many more builds on AC than on battery, thus finding more build outliers).</p><p>The cool thing about having an assistant, though, is you can ask it directly what it thinks:</p><blockquote>In your opinion, does being on AC or battery power impact build performance?</blockquote><p>That clears it up: we‚Äôll consider only successful and AC powered builds from now on!</p><h3 id="not-all-builds-are-equal">Not all builds are equal</h3><p>We keep a close eye on build performance for our Go monolith: while buying hardware is one way to speed things up, nothing beats removing or fine-tuning the build process itself.</p><p>For this reason, we‚Äôre well aware that depending on what you try to build, you might get very different build times.</p><p>That‚Äôs because Go projects comprise of many ‚Äòpackages‚Äô (code modules) that the Go compiler will cache and only recompile if it thinks something has changed. Our app is deliberately architected for a wide dependency graph with few modules at the base to avoid most changes having to recompile the entire graph, but some level of dependency nesting is unavoidable.</p><p>This means builds tend to be either:</p><p><strong>Instant (&lt;3s)</strong></p><p>Your change is not relevant to the Go compiler, in that you haven‚Äôt done anything to modify package symbols and can get away with providing a binary directly from cache, no compilation or expensive linking necessary.</p><figure><span><img alt="" loading="lazy" width="3382" height="1190" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F20eca08e4dbd669d2cf52e7c37f6aa1edf965732-3382x1190.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F20eca08e4dbd669d2cf52e7c37f6aa1edf965732-3382x1190.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span><figcaption>1s build from adding a function comment, where no packages were compiled and everything comes from cache.</figcaption></figure><p><strong>Fast (&lt;30s)</strong></p><p>You‚Äôre changing a single package with few dependents, so much of the app is cached and only your package needs compiling. The majority of the time is spent on linking the newly compiled package against the existing cache.</p><figure><span><img alt="" loading="lazy" width="3392" height="1198" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F8cb88897eda031d2f2f80a77ba8db2ebfc2385f8-3392x1198.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F8cb88897eda031d2f2f80a77ba8db2ebfc2385f8-3392x1198.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span><figcaption>28s build where we compiled a single package and spent most of the time (24s) waiting on the linker.</figcaption></figure><p><strong>Medium (30s-1m)</strong></p><p>You‚Äôve modified a feature package with a few sub-package dependencies, but the majority of the app remains unchanged and Go can reuse the cache.</p><figure><span><img alt="" loading="lazy" width="3380" height="1142" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F1f0545b95e3aba00987ab69142fea48f03fb5b57-3380x1142.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F1f0545b95e3aba00987ab69142fea48f03fb5b57-3380x1142.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span><figcaption>38s build from modifying app/catalog/cache which is used by any of our product features that leverage our Catalog, requiring us to rebuild both the cache and any of those features.</figcaption></figure><p><strong>Slow (1m+)</strong></p><p>You‚Äôve added a type to our base <code>domain</code> package and now every package in the app needs recompiling.</p><figure><span><img alt="" loading="lazy" width="3376" height="1110" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F10f13b6c735ed5e4a0964640601400cfb234711e-3376x1110.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F10f13b6c735ed5e4a0964640601400cfb234711e-3376x1110.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span><figcaption>1m 20s build where pkg/domain blocks all other packages that consume it, which is most of the rest of the app, preventing us from using any of our cache.</figcaption></figure><p>Whatever measurements we use to draw comparisons, we need to be aware of these variations so we can avoid an apples-oranges situation.</p><h3 id="comparing-m1-and-m2">Comparing M1 and M2</h3><p>Now we‚Äôve cleaned our data to be just AC powered + successful builds and understand a bit more about how build times might vary, we can begin comparing platforms to one another.</p><p>Let‚Äôs start by asking:</p><blockquote>Focusing on just the M1 Pro and M2 Max (as these are the platforms we have the most data on) can you chart two histograms showing successful build durations, removing extreme outliers.</blockquote><figure><span><img alt="" loading="lazy" width="1614" height="818" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F20c7264cd19538b65b952c54f8a1d7dad27acf77-1614x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F20c7264cd19538b65b952c54f8a1d7dad27acf77-1614x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F20c7264cd19538b65b952c54f8a1d7dad27acf77-1614x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Overall, it‚Äôs clear the M2 Max totally destroys the M1 Pro in terms of build speed. But what we haven‚Äôt shared so far is that these machines differ in more than just chipset‚Ä¶</p><blockquote>Can you show me how the build events split by machine platform and memory configuration please?</blockquote><ul><li><strong>Apple M1 Pro</strong>¬†with 16GB: 5,235 build events</li><li><strong>Apple M2 Pro</strong>¬†with 16GB: 1,927 build events</li><li><strong>Apple M2 Max</strong>¬†with 32GB: 3,842 build events</li><li><strong>Apple M3 Pro</strong>¬†with 18GB: 321 build events</li><li><strong>Apple M3 Pro</strong>¬†with 36GB: 899 build events</li><li><strong>Apple M3 Max</strong>¬†with 36GB: 301 build events</li></ul><p>Hmm, interesting. So the comparison between our M1 Pros and M2 Max is somewhat unfair as the M2s all have 32GB of memory which is twice that of the M1s (16GB).</p><p>That could be the reason the performance is so different (despite claims that Apple machines need little RAM‚Ä¶) and would be useful to know when deciding what specification of M3 we should upgrade to.</p><p>Thankfully we have 2k build events from an M2 Pro with 16GB of memory, so‚Ä¶</p><blockquote>Can you redraw the histogram comparison of build durations, this time for the Apple M2 Pro 16GB and the Apple M2 Max 32GB normalised, please?</blockquote><figure><span><img alt="" loading="lazy" width="1596" height="818" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F3fcee16ddc4218c2fb1aca70c4a0c2bc46e6fd1d-1596x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F3fcee16ddc4218c2fb1aca70c4a0c2bc46e6fd1d-1596x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F3fcee16ddc4218c2fb1aca70c4a0c2bc46e6fd1d-1596x818.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>As a primer: M2 Pro and M2 Max are mostly the same chip, with the main difference being that the Max has two additional ‚Äòenergy efficient‚Äô cores. Those cores are ~1/5th as powerful as the performance cores and will contribute minimally to compiling a Go program, and therefore our build durations.</p><p>This comparison, then, is quite useful: it implies the 32GB is making little impact, perhaps only contributing to the higher density of fast build times, but overall not very noticeable.</p><h3 id="comparing-within-m3">Comparing within M3</h3><p>From what we‚Äôve seen so far, the M2 Pro at 16GB memory seems the best value for money, almost twice as fast as the M1 and minimally slower than the M2 Max (even when the Max has twice the memory).</p><p>Now we need to figure out if the M3 is a meaningful improvement over the M2, and for that we needed to buy some laptops.</p><p>We purchased:</p><ul><li>M3 Pros, 12 cores (6 performance, 6 energy-efficiency)<ul><li>1x 18GB memory</li><li>1x 36GB memory</li></ul></li><li>M3 Max, 14 cores (10 performance, 4 energy-efficiency)<ul><li>1x 36GB</li></ul></li></ul><p>Three laptops in total, with the Pros differing in memory, while the Max is an attempt to measure if we‚Äôll see much difference for those extra 4 P-cores.</p><p>If we begin with the Pros:</p><blockquote>Show me histograms of build duration for the M3 Pro 18GB and M3 Pro 36GB.</blockquote><figure><span><img alt="" loading="lazy" width="1608" height="834" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fc8d95c71304e90f555b6402cbacb67b0ef10b314-1608x834.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fc8d95c71304e90f555b6402cbacb67b0ef10b314-1608x834.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fc8d95c71304e90f555b6402cbacb67b0ef10b314-1608x834.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>We‚Äôve previously concluded that memory makes little difference to build performance, so it‚Äôs unsurprising these graphs look similar.</p><p>In fact, I‚Äôd expect them to look even closer than they do, but we‚Äôre suffering from a lack of data with far fewer builds for the M3s than we have for other platforms.</p><p>As we‚Äôre low on data, let‚Äôs combine the results for both M3 Pros, especially as we think they‚Äôre quite similar.</p><blockquote>Show me histograms of build duration for the M3 Pro 18GB and 36GB combined vs the M3 Max, removing very quick builds (&lt;3s).</blockquote><figure><span><img alt="" loading="lazy" width="3202" height="1620" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fa7bf892735d4a716e155c4b8bbf8d620cdc0ff1d-3202x1620.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Fa7bf892735d4a716e155c4b8bbf8d620cdc0ff1d-3202x1620.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Again, we‚Äôre suffering from much less data here, but even so it‚Äôs not looking like the M3 Max is doing anything truly remarkable beyond the already-fast M3 Pro.</p><p>At least, not enough to justify the 60% price increase over the base M3 Pro.</p><h3 id="putting-it-all-together-m1-m2-m3">Putting it all together: M1, M2, M3</h3><p>By now, we‚Äôve:</p><ul><li>Established a baseline for M1 machines.</li><li>Determined that M2 machines are fairly equal, irrespective of memory or additional cores.</li><li>M3 is also similar across Pro and Max.</li></ul><p>It‚Äôs time to get a full picture of how these platforms compare‚Ä¶</p><blockquote>Show me histograms comparing build duration across all platform and memory combinations, excluding builds that complete in &lt;3s.</blockquote><figure><span><img alt="" loading="lazy" width="2400" height="2370" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F99317fae9c4e937f1f0030e92adfca9c6051d7cd-2400x2370.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F99317fae9c4e937f1f0030e92adfca9c6051d7cd-2400x2370.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>It‚Äôs clear that variation within platforms (coloured) is minimal, so for the purposes of our comparison‚Ä¶</p><blockquote>Please repeat the above but with one histogram per-row and combining the M1, M2 and M3 platforms.</blockquote><figure><span><img alt="" loading="lazy" width="2370" height="2938" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F493c09138af48635181674b6db43b865d0686a6f-2370x2938.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F493c09138af48635181674b6db43b865d0686a6f-2370x2938.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Which makes it clear that:</p><ul><li>People with the M1 laptops are frequently waiting almost 2m for their builds to complete.</li><li>M2 is a <em>significant</em> upgrade on the M1 machines.</li><li>M3 is an incremental improvement on M2.</li></ul><p>Suggesting that:</p><ul><li>We should upgrade anyone on an M1 to a base M3 Pro model.</li><li>M2 users don‚Äôt need upgrading.</li></ul><p>Done!</p><h3 id="one-more-thing-does-memory-really-make-no-difference">One more thing‚Ä¶ does memory really make no difference?</h3><p>We‚Äôve done the comparisons of machines with different memory and couldn‚Äôt see meaningful improvements from ~16GB ‚Üí 32GB, at least not in the build durations we‚Äôre measuring.</p><p>But this was surprising. When guessing how this experiment might pan out, we really thought the extra memory would make a big difference. It feels weird we can‚Äôt see that in our graphs, or at least not very much.</p><p>After thinking a bit, we wondered if you could see the impact of more memory anywhere in what we measured, and that perhaps it was less consequential to builds overall than it might be to other things.</p><p>So what might we measure that could help determine this?</p><p>Well, if you remember our categorisation of fast/medium/slow builds, a consistently large part of each build was time spent in the linker, where the compiled Go packages are joined together into one executable binary.</p><p>This process is (from memory of <a href="https://docs.google.com/document/d/1D13QhciikbdLtaI67U6Ble5d_1nsI4befEd6_k1z91U/view#heading=h.g4m43nddv64t">this doc</a>) minimally concurrent, and spends a lot of time building structures in memory to perform symbol resolution and check each of the compiled modules are compatible with one another.</p><p>It‚Äôs very possible that additional memory could help here.</p><blockquote>In our dataset is a build_stages column. Can we add a new column to the dataset which is called &#34;linker_time&#34; which is derived from¬†<code>build_stages.link.duration_seconds</code>.</blockquote><p>That‚Äôs nice: our telemetry events contain durations of linking/compiling, so we can tell our assistant to build a new column for <code>linker_time</code> into our build events.</p><blockquote>Please graph histograms of <code>linker_time</code> for each platform and memory combination running in order specified previously, colouring each histogram differently depending on whether the machine has 16-18GB or 32-36GB of memory.</blockquote><figure><span><img alt="" loading="lazy" width="2498" height="2290" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F6a8043c47db457da658787f781056cfb49d46a1d-2498x2290.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2F6a8043c47db457da658787f781056cfb49d46a1d-2498x2290.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Well, that looks quite different! Which is to say every machine ‚Äì M1, M2 or M3 ‚Äì that has &gt;30GB of memory almost always completes linking &lt;20s, and only machines with 18GB or less memory routinely take &gt;20s to link.</p><p>This is cool because:</p><ul><li>Extra memory does have its uses, and I‚Äôd have been sad if we couldn‚Äôt see at least some impact of that in our build data.</li><li>We‚Äôre considering dropping docker from our development machines. These results suggest people with low memory machines can improve their link times by increasing available system memory, which they can do by going docker-less.</li><li>We‚Äôve began working on a mobile app (and are <a href="https://boards.eu.greenhouse.io/incidentio/jobs/4207387101">hiring for mobile engineers!</a>) where the simulators take a lot of system memory.</li></ul><p>All this means for the nominal cost of the memory bump, it makes sense to buy the 36GB even if you consider it just ‚Äòfuture proofing‚Äô.</p><h3 id="the-m3s-are-on-their-way">The M3‚Äôs are on their way!</h3><p>In the face of irrefutable evidence that new Space Black M3 Pro laptops would dramatically improve not only how cool we look on our commute, but also how fast we can ship changes and delight customers, the decision was an easy one and the new laptops are now on their way!</p><figure><span><img alt="" loading="lazy" width="2496" height="1224" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Ff0fcdd5e2adfde8ba5c3fc5556c93b0b5ce75d32-2496x1224.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://incident.io/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Foqy5aexb%2Fproduction%2Ff0fcdd5e2adfde8ba5c3fc5556c93b0b5ce75d32-2496x1224.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></span></figure><p>Specifically, we‚Äôll upgrade our M1s to the base M3 Pro with 36GB of memory but wait a while for the M2s, as they seem to be performing really well already.</p><p>Besides the laptops, this was a really fun journey that helped us improve our tooling and get a much better understanding of our developer environment.</p><p>Along the way we:</p><ul><li>Found a great benchmark measurement for performance of developer machines.</li><li>Built our own Go hot-reloader that can track the metrics (which came with other QoL improvements too).</li><li>Learned a load about Go builds and what makes them fast or slow.</li><li>Used OpenAI‚Äôs latest tech (Assistants) to examine the data, something you can easily use for similar analysis problems of your own.</li><li>Dug into Apple‚Äôs chip line-up and quantified the improvements for your average Go developer upgrading between machines.</li><li>Saw that memory matters, but perhaps not as obviously as you may expect.</li></ul><p>I hope you enjoyed following along, and perhaps the conclusions we‚Äôve drawn can be useful to you, too.</p></div></div></div>
  </body>
</html>
