<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://calmatters.org/economy/technology/2025/09/chatgpt-lawyer-fine-ai-regulation/">Original</a>
    <h1>California issues historic fine over lawyer&#39;s ChatGPT fabrications</h1>
    
    <div id="readability-page-1" class="page"><div>

		
				
		<div>
			<div>
				
				<p><strong>In summary</strong></p>
				

				
				<p>The court of appeals said 21 of 23 quotes in an opening brief were fake. State authorities are scrambling to grapple with widespread use of artificial intelligence.</p>
				
							</div>
		</div>
		
		

<p>A California attorney must pay a $10,000 fine for filing a state court appeal full of fake quotations generated by the artificial intelligence tool ChatGPT.</p>

<p>The fine appears to be the largest issued over AI fabrications by a California court and came with a <a href="https://www4.courts.ca.gov/opinions/documents/B331918.PDF" target="_blank" rel="noreferrer noopener">blistering opinion</a> stating that 21 of 23 quotes from cases cited in the attorney’s opening brief were made up. It also noted that numerous out-of-state and federal courts have confronted attorneys for citing fake legal authority.</p>

<p>“We therefore publish this opinion as a warning,” it continued. “Simply stated, no brief, pleading, motion, or any other paper filed in any court should contain any citations— whether provided by generative AI or any other source—that the attorney responsible for submitting the pleading has not personally read and verified.”</p>

<p>The opinion, issued 10 days ago in California’s 2nd District Court of Appeal, is a clear example of why the state’s legal authorities are scrambling to regulate the use of AI in the judiciary. The state’s Judicial Council two weeks ago <a href="https://courts.ca.gov/cms/rules/index/standards/Standard10_80" target="_blank" rel="noreferrer noopener">issued guidelines requiring judges and court staff</a> to either ban generative AI or adopt a generative AI use policy by Dec. 15. Meanwhile, the California Bar Association is considering whether to strengthen its code of conduct to account for various forms of AI following a request by the California Supreme Court last month.</p>


<p>The Los Angeles-area attorney fined last week, Amir Mostafavi, told the court that he did not read text generated by the AI model before submitting the appeal in July 2023, months after OpenAI marketed ChatGPT as capable of <a href="https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/" target="_blank" rel="noreferrer noopener">passing the bar exam</a>. A three-judge panel fined him for filing a frivolous appeal, violating court rules, citing fake cases, and wasting the court’s time and the taxpayers money, according to the opinion.</p>

<p>Mostafavi told CalMatters he wrote the appeal and then used ChatGPT to try and improve it. He said that he didn’t know it would add case citations or make things up. </p>

<p>He thinks it is unrealistic to expect lawyers to stop using AI. It’s become an important tool just as online databases largely replaced law libraries and, until AI systems stop hallucinating fake information, he suggests lawyers who use AI to proceed with caution.</p>

<p>“In the meantime we’re going to have some victims, we’re going to have some damages, we’re going to have some wreckages,” he said. “I hope this example will help others not fall into the hole. I’m paying the price.”</p>


<p>The fine issued to Mostafavi is the most costly penalty issued to an attorney by a California state court and one of the highest fines ever issued over attorney use of  AI, according to Damien Charlotin, who teaches a class on AI and the law at a business school in Paris. He <a href="https://www.damiencharlotin.com/hallucinations/">tracks</a> instances of attorneys citing fake cases, primarily in Australia, Canada, the United States, and the United Kingdom.</p>

<p>In a widely-publicized case in May, a U.S. district court judge in California <a href="https://websitedc.s3.amazonaws.com/documents/Lacey_v._State_Farm_General_Insurances_Co._D._Cal._May_6_2025.pdf">ordered two law firms to pay</a> $31,100 in fees to defense counsel and the court for costs associated with using “bogus AI-generated research.” In that ruling, the judge described feeling misled, said they almost cited fake material in a judicial order and said “Strong deterrence is needed to make sure that attorneys don’t succumb to this easy shortcut.”</p>

<figure><blockquote><p>“We’re going to have some wreckages.”</p><cite>Amir Mostafavi, lawyer fined $10,000 after submitting opening brief filled with quotes fabricated by ChatGPT</cite></blockquote></figure>

<p>Charlotin thinks courts and the public should expect to see an exponential rise in these cases in the future. When he started tracking court filings involving AI and fake cases earlier this year, he encountered a few cases a month. Now he sees a few cases a day. Large language models confidently state falsehoods as facts, particularly when there are no supporting facts.</p>

<p>“The harder your legal argument is to make, the more the model will tend to hallucinate, because they will try to please you,” he said. “That’s where the confirmation bias kicks in.”</p>

<p>A <a href="https://hai.stanford.edu/news/ai-trial-legal-models-hallucinate-1-out-6-or-more-benchmarking-queries">May 2024 analysis</a> by Stanford University’s RegLab found that although three out of four lawyers plan to use generative AI in their practice, some forms of AI generate hallucinations in one out of three queries. Detecting fake material cited in legal filings <a href="https://www.nytimes.com/2025/05/05/technology/ai-hallucinations-chatgpt-google.html">could get harder as models grow in size</a>.</p>

<p><a href="https://www.ailawlibrarians.com/2025/08/10/coming-soon-the-interactive-genai-legal-hallucination-tracker-sneak-peek-today/">Another tracker</a> of cases where lawyers cite nonexistent legal authority due to use of AI identifies 52 such cases in California and more than 600 nationwide.<strong> </strong>That amount is expected to increase in the near future because AI innovation is outpacing the education of attorneys, said Nicholas Sanctis, a law student at Capital University Law School in Ohio.</p>
	<div>
		<div data-posts="" data-current-post-id="476080">
							<h2>
					<span>More on AI in government</span>
				</h2>
						
	<article data-post-id="466445">
							<figure>
								<a href="https://calmatters.org/economy/technology/2025/05/california-somehow-finds-no-ai-risks/" rel="bookmark" tabindex="-1" aria-hidden="true">
												<img decoding="async" width="1200" height="900" src="https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=1200%2C900&amp;ssl=1" alt="State claims there’s zero high-risk AI in California government—despite ample evidence to the contrary" data-hero-candidate="1" srcset="https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/calmatters.org/wp-content/uploads/2025/05/HIGH-RISK-AI_AH_CM_02.jpg?resize=1200%2C900&amp;ssl=1&amp;w=370 370w" sizes="(min-width: 782px) 600px, (min-width: 600px) 42.5vw, 90vw"/>												</a>
				
							</figure><!-- .featured-image -->
		
		<!-- .entry-wrapper -->
	</article>

				</div>
		
	</div>
	
<p>Jenny Wondracek, who leads the tracker project, said she expects this trend to get worse because she still regularly encounters lawyers who don’t know that AI makes things up or believe that legal tech tools can eliminate all fake or false material generated by language models. </p>

<p>“I think we’d see a reduction if (lawyers) just understood the basics of the technology,” she said.</p>

<p>Like Charlotin, she suspects there are more instances of made up cases generated by AI in state court filings than in federal courts, but a lack of standard filing methods makes it difficult to verify that. She said she encounters fake cases most often among overburdened attorneys or people who choose to represent themselves in family court.</p>

<p>She suspects the number of arguments filed by attorneys that use AI and cite fake cases will continue to go up, but added that not just attorneys engage in the practice. In recent weeks, she’s documented three <a href="https://www.ailawlibrarians.com/2025/07/03/first-known-court-order-with-fabricated-cases-and-a-test-run-of-citecheck-ai/">instances of judges</a> citing fake legal authority in their decisions.</p>

<figure><blockquote><p>She’s documented three judges citing fake legal authority in their decisions.</p></blockquote></figure>

<p>As California considers how to treat generative AI and fake case citations, Wondracek said they can consider approaches taken by other states, such as temporary suspensions, requiring attorneys who get caught to take courses to better understand how to ethically use AI, or requiring them to <a href="https://www.lawnext.com/2025/09/nevada-judge-takes-creative-and-unusual-approach-to-combat-ai-generated-fictitious-citations.html">teach law students how they can avoid making the same mistake</a>.</p>

<p>Mark McKenna, codirector of the UCLA Institute of Technology, Law &amp; Policy praised fines like the one against Mostafavi as punishing lawyers for “an abdication of your responsibility as a party representing someone.” He thinks the problem “will get worse before it gets better,” because there’s been a rush among law schools and private firms to adopt AI without thinking through the appropriate way to use them.</p>

<p>UCLA School of Law professor Andrew Selbst agrees, pointing out that clerks that work for judges are recent law school graduates, and students are getting bombarded with the message that they must use AI or get left behind. Educators and other professionals <a href="https://calmatters.org/economy/technology/2024/06/teachers-ai-grading/">report feeling similar pressures</a>.</p>

<p>“This is getting shoved down all our throats,” he said. “It’s being pushed in firms and schools and a lot of places and we have not yet grappled with the consequences of that.”</p>

<p><strong>For the record</strong>: The fine issued to Mostafavi was for $10,000. Due to an editing error, an earlier version of this article had an incorrect figure.</p>
	
	<section id="block-5"><!-- wp:shortcode --><!-- /wp:shortcode --></section>	</div></div>
  </body>
</html>
