<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.datagubbe.se/hcg/">Original</a>
    <h1>The Home Computer Generation</h1>
    
    <div id="readability-page-1" class="page"><div>



<p><b>On experiences lost in user-friendliness</b></p><blockquote>
the Tandy 2000 runs MS-DOS but</blockquote>


<h3>I, user</h3>
<p>
A seemingly frightening realization regularly dawns on various pundits these days: Being a <i>digital native</i> doesn&#39;t automatically mean you&#39;re computer savvy. Due to a gradual transformation from general purpose tools to digital appliances, computers are now more than ever perceived as magical boxes by their users. Many computers aren&#39;t even recognizable as such and users are perfectly content with this, sticking to their phones or tablets except for very specific uses cases. And why not? All of the conveniences envisioned by tech utopianists of yore can be accessed with a smartphone: entertainment, shopping, banking, travel reservations, chatting, news and so on. Today, using a computer implies either office work or the curious activity of using a computer for the sake of using a computer.
</p>

<p>
The latter was something I grew up with: it took almost ten years from me buying my first computer until it was economically viable to keep it constantly online. Instead, when I tired of playing games, I explored the intricacies of the operating system and learned the ins and outs of Deluxe Paint in minute detail.
</p>

<p>
I was in no way unique. Scores of people owned what was then called a <i>home computer</i> - those <a href="https://www.datagubbe.se/relive1994/">very special machines</a> produced between the late 1970s and late 1990s aimed specifically at the consumer market: ZX Spectrum, C64, Amiga, Atari, and, overlapping with the business side of things, PC:s and Macs. A lot of us used our machines for little more than playing video games, but even in doing so, many of us developed a very special relationship to our machine in particular and digital technology in general. I believe this relationship to be unique to this particular period in time and that it resulted in a very particular kind of computer user.
</p>


<h3>The Generation Game</h3>
<p>
We love naming generations and ascribing vices and virtues to them. Boomers. Millenials. Zoomers. I propose that in the overlap between Generation X and Millenials, there is a <i>home computer generation</i>. If you&#39;ve ever found yourself muttering &#34;But where are the damn files stored?&#34;, wondered why you can&#39;t change the font in Windows anymore or been frustrated by how many modern <i>apps</i> seem to lack advanced features for power users, chances are you&#39;re part of it. We (for I belong to it) are most notably characterized by having had technology thrust upon us in a way that made many of us more computer literate than the generations both preceding and, to the confusion of the aforementioned pundits, succeeding us. We were forced to learn certain aspects of computing that was and is, by any other generation of computer users, commonly considered to be expertise best left to professionals.
</p>

<p>
That&#39;s not to say that there aren&#39;t any highly skilled young computer geeks today. Thanks to the current ubiquity of computers, there&#39;s probably more of them now than at any previous point in time. It also doesn&#39;t mean that, say, a then sixty-something career alcoholic turned poet couldn&#39;t also become a competent home computer user - as exemplified by the Bukowski quote above.
</p>

<p>
The generation before the home computer generation used computers, too. Plenty of bank tellers, supermarket cashiers, librarians, car salesmen and travel agents used (and are sometimes still using) various mainframe applications. Last time I checked, Bloomberg terminals are <i>still</i> a thing. More widespread use of such machines may have coincided with the home computer boom, but is a decidedly different phenomenon: They were mostly operated by the parents of home computer owners, and the mainframe/terminal paradigm was what differentiated those professional computers from their colorful, beepy counterparts for home use.
</p>

<p>
The terminal operator rarely saw anything more than one or two simple interfaces for domain specific applications and they didn&#39;t have to know anything about the inner workings of computers. Sometimes they became flustered by a spurious error message or the intricacies of correctly formatted data entry, but other than that, the only computer training needed was how to use the specific application in question.
</p>

<p>
If this sounds eerily familiar, it&#39;s perhaps because much of today&#39;s computing works the same. It either takes place in a web browser or in a phone - via the cloud - and the end user doesn&#39;t have to care or even know about things like storage media, file systems, command lines and hardware drivers. Increasingly simplified operating systems and programs continually <a href="https://www.datagubbe.se/noconf/">rob the user of agency and control</a>. This makes them easier to use for novices, but unlike home computers, they also make it much harder for said novices to gain meaningful knowledge and rise above the level of novice.
</p>

<h3>Presenting Anecdata</h3>
<p>
Consider, for example, a neurologist friend of mine: on his spare time, he&#39;s the SysOp of a BBS running on a bona fide Commodore 64 connected to the internet. Another friend is a social worker. On evenings and weekends he creates music using old 8-bit era sound chips - and writes his own music replayers in 6502 assembly. The same CPU is favored for assembly coding by another friend - he&#39;s a lawyer by trade. I&#39;m not saying this just to brag about having <a href="http://www.armory.com/tests/hacker.html">more than two friends</a>: albeit anecdotal, it serves as evidence of people from my generation who, while far from working professionally with IT, have computer skills widely exceeding today&#39;s average smartphone user. The long and short of it is that to use an Amiga, C64 or DOS PC, you had know a thing or two about how they actually worked.
</p>

<p>
Even if playing games on an Amiga 500 was usually as simple as inserting a floppy into the disk drive, you still had to learn about copying and formatting disks. This meant, at the very least, using tools that imbued you with strange and highly technical terms about the Amiga&#39;s disk handling hardware. If you used your expensive Amiga for school work - which you probably did, considering what you (or your parents) paid for it - you also had to learn about desktop GUI:s, hierarchical file systems and configuring the OS. Programs couldn&#39;t just be downloaded online from a convenient app store, so you read specialized computer magazines to inform yourself about local dealers and available software. In the process, you were sure to pick up some extracurricular computer knowledge from the articles or, indeed, even the advertisements. If you eventually graduated to become a hard drive owner, even more knowledge had to be amassed to format, install and use it.
</p>

<p>
Owners of DOS PC:s were probably those best (or perhaps worst) off in this respect. They had to learn some pretty intricate stuff about the DOS memory model and startup process if they wanted to play certain finicky or resource hungry games on a limited machine. Many a DOS gamer will, I&#39;m sure, remember editing AUTOEXEC.BAT, CONFIG.SYS and struggling with bizarre pre-game setup menus. And that was <i>after</i> installing and starting the game - all of it from a mysterious, monochrome command line interface.
</p>

<h3>It can print <i>what</i>?</h3>
<p>
This experience is of course still available today. The difference is that the contemporary Arch Linux aficionado has made an informed choice, whereas the casual gamer of yesteryear was brutally dragged into computer literacy. For users of old 8-bit machines, that meant being greeted with a BASIC prompt. I&#39;m sure nearly all of them at some point wrote some version of what is probably the most reproduced BASIC program of all time:
</p>

<pre>10 PRINT &#34;FUCK&#34;
20 GOTO 10</pre>

<p>
It doesn&#39;t <i>have</i> to print a profanity, but let&#39;s be realistic - in most cases it probably did. Many a youngster likely just typed it in and giggled for a bit when watching it run. But, if reflecting on it a bit, writing this program was in fact a great learning experience. In many ways it can represent the particular way the home computer generation reasons about technology:
</p>

<ul>
<li>
Programs are sequences of instructions executed in a predetermined order.
</li>
<li>
A human writes these instructions and the computer carries them out without question. It doesn&#39;t even censor profanities - in fact, it happily repeats them until a human decides to halt the program.
</li>
<li>
Hence, a computer is a tool which in every aspect can - and should - be controlled by a human.
</li>
<li>
Using a computer simply for the sake of using a computer can be fun and rewarding.
</li>
</ul>

<h3>Boomers and Zoomers</h3>
<p>
It&#39;s worth repeating that there are plenty of competent young programmers and kids with a passionate interest in computers today. The big difference is that the slight resistance forcing someone to learn has to be sought out, whether you&#39;re an aspiring coder or a gamer. For the gamer, pre-built machines with Windows preinstalled are readily available. It&#39;s just a matter of downloading Steam and leaning back - you don&#39;t even have to navigate the file system if you don&#39;t want to. The home computer generation, meanwhile, had little choice but to gradually absorb computer literacy during years of trying to get their damn games and programs to run.
</p>

<p>
This generational divide is, I think, noticeable in the workforce. Before the era of the home computer, computer programmers were oftentimes professionals trained specifically for writing financial, governmental or scientific programs on mainframes. While some of them may have had an interest in computers, many were simply white-collar workers who considered it a job like any other.
</p>

<p>
Then, suddenly, computers where everywhere. Video games were selling like hotcakes, home users needed affordable programs and internet usage exploded. The timing was perfect for a generation of more or less involuntary autodidacts to enter the job market. By sheer luck, they could turn skills gained from a hobby during their most formative years into gainful employment. Their notion that computers were personal tools was combined with historical knowledge accumulated from advanced computer usage since an early age, and unorthodox methods picked up outside academia. This resulted in a particular brand of competence that&#39;s hard to gain from a few years in college, however esteemed it may be.
</p>

<p>
The continued growth of the software market combined with the disappearance of home computers seems to have put a stop to this. Just like before the home computer generation, people in the generation succeeding it consider a job in IT little more than a career path among others. Effort, cost and payout are key factors affecting their choice, just like when becoming an accountant or plumber. As far as personal decisions go, there&#39;s absolutely nothing wrong with this. I do, however, think it risks negatively affecting the way program functionality and <a href="https://www.datagubbe.se/decusab/">interfaces</a> are designed - even more than what we&#39;re already seeing.
</p>

<p>
This is because of the specific mentality home computers fostered - one I fear is lost today. The disappearance of OS and program configurability, for example, isn&#39;t something you notice or even think about if you&#39;re not coming from a place where everything once used to be configurable. The benefits of running programs locally, with a native GUI, aren&#39;t immediately obvious if you&#39;ve grown up with mollycoddling cloud apps in which surveillance capitalists decide what&#39;s good and bad for you. The power of complex professional programs, command lines and hierarchical file systems can be overwhelming if you&#39;re used to instant gratification after a few seconds of swiping and searching.
</p>

<h3>Conclusion</h3>
<p>
I don&#39;t think this is detrimental to the profitability of the software business, but I do believe it makes the world a little worse for us all as individuals. If you&#39;ve never jumped through certain hoops, it&#39;s not apparent that some of them were there to empower the user. If you&#39;re not familiar with the benefits of configurability, chances are you&#39;re not going to implement them. If the machines you&#39;ve grown up with never offered options and freedom of choice, will you spend energy on championing that in a professional setting?
</p>

<p>
And, more importantly: If you&#39;ve never experienced the raw speed of IRC, why complain about the sluggishness of Microsoft Teams? If you&#39;ve never been able to truly configure your working environment to your personal preference, why request such features at all? The longer the path becomes to knowledge, the harder it becomes to demand certain qualities in the software we use. In the end, we risk losing much more than we gain.
</p>

<p>
This leaves me feeling like I&#39;m part of an anomaly, an anarchic blip on the radar of orderly computer use.
I suppose that, in part, is why I so often come across as old and grumpy.
</p>


</div></div>
  </body>
</html>
