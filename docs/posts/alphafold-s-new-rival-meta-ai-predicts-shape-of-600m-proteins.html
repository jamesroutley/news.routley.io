<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/d41586-022-03539-1">Original</a>
    <h1>AlphaFold’s new rival? Meta AI predicts shape of 600M proteins</h1>
    
    <div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-022-03539-1/d41586-022-03539-1_23662838.jpg?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-022-03539-1/d41586-022-03539-1_23662838.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/>
  <img alt="Exploring 1 million out of 617M proteins on the ESM Metagenomic Atlas website." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-022-03539-1/d41586-022-03539-1_23662838.jpg"/>
  <figcaption>
   <p><span>The ESM Metagenomic Atlas database contains structure predictions for 617 million proteins.</span><span>Credit: ESM Metagenomic Atlas (CC BY 4.0)</span></p>
  </figcaption>
 </picture>
</figure><p>When London-based Deep Mind unveiled predicted structures for some 220 million proteins this year, it covered nearly every protein from known organisms in DNA databases. Now, another tech giant is filling in the dark matter of our protein universe.</p><p>Researchers at Meta (formerly Facebook, headquartered in Menlo Park, California) have used artificial intelligence (AI) to predict the structures of some 600 million proteins from bacteria, viruses and other microbes that haven’t been characterized.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-020-03348-4" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-022-03539-1/d41586-022-03539-1_18745984.jpg"/><p>‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures</p></a>
 </article><p>“These are the structures we know the least about. These are incredibly mysterious proteins. I think they offer the potential for great insight into biology,” says Alexander Rives, the research lead for Meta AI’s protein team.</p><p>The team generated the predictions — described in a 1 November <a href="https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2" data-track="click" data-label="https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2" data-track-category="body text link">preprint</a><sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> — using a ‘large language model’, a type of AI that are the basis for tools that can predict text from just a few letters or words.</p><p>Normally language models are trained on large volumes of text. To apply them to proteins, Rives and his colleagues fed them sequences to known proteins, which can be expressed by a chains of 20 different amino acids, each represented by a letter. The network then learned to ‘autocomplete’ proteins with a proportion of amino acids obscured.</p><h2>Protein ‘autocomplete’</h2><p>This training imbued the network with an intuitive understanding of protein sequences, which hold information about their shapes, says Rives. A second step — inspired by DeepMind’s pioneering protein structure AI AlphaFold — combines such insights with information about the relationships between known protein structures and sequences, to generate predicted structures from protein sequences.</p><p>Meta’s network, called ESMFold, isn’t quite as accurate as AlphaFold, Rives’ team reported earlier this summer<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>, but it is about 60 times faster at predicting structures, he says. “What this means is that we can scale structure prediction to much larger databases.”</p><p>As a test case, they decided to wield their model on a database of bulk-sequenced ‘metagenomic’ DNA from environmental sources including soil, seawater, the human gut, skin and other microbial habitats. The vast majority of the DNA entries — which encode potential proteins — come from organisms that have never been cultured and are unknown to science.</p><p>In total, the Meta team predicted the structures of more than 617 million proteins. The effort took just 2 weeks (AlphaFold can take minutes to generate a single prediction). The predictions are freely available for anyone to use, as is the code underlying the model, says Rives.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-022-00997-5" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-022-03539-1/d41586-022-03539-1_20323140.png"/><p>What&#39;s next for AlphaFold and the AI protein-folding revolution</p></a>
 </article><p>Of these 617 million predictions, the model deemed more than one-third to be high quality, such that researchers can have confidence that the overall protein shape is correct and, in some cases, can discern finer atomic-level details. Millions of these structures are entirely novel, and unlike anything in databases of protein structures determined experimentally or in the AlphaFold database of predictions from known organisms.</p><p>A good chunk of the AlphaFold database is made of structures that are nearly identical to each other, and ‘metagenomic’ databases “should cover a large part of the previously unseen protein universe”, says Martin Steinegger, a computational biologist at Seoul National University. “There’s a big opportunity now to unravel more of the darkness.”</p><p>Sergey Ovchinnikov, an evolutionary biologist at Harvard University in Cambridge, Massachusetts, wonders about the hundreds of millions of predictions that ESMFold made with low-confidence. Some might lack a defined structure, at least in isolation, whereas others might be non-coding DNA mistaken as a protein-coding material. “It seems there is still more than half of protein space we know nothing about,” he says.</p><h2>Leaner, simpler, cheaper</h2><p>Burkhard Rost, a computational biologist at the Technical University of Munich in Germany, is impressed with the combination of speed and accuracy of Meta’s model. But he questions whether it really offers an advantage over AlphaFold’s precision, when it comes to predicting proteins from metagenomic databases. Language model-based prediction methods — including one developed by his team<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup> — are better suited to quickly determine how mutations alter protein structure, which is not possible with AlphaFold. “We will see structure prediction become leaner, simpler cheaper and that will open the door for new things,” he says.</p><p>DeepMind doesn’t currently have plans to include metagenomic structure predictions in its database, but hasn’t ruled this out for future releases, according to a company representative. But Steinegger and his collaborators have used a version of AlphaFold to predict the structures of some 30 million metagenomic proteins. They are hoping to find new kinds of RNA viruses by looking for novel forms of their genome-copying enzymes.</p><p>Steinegger sees trawling biology’s dark matter as obvious next step for such tools. “I do think we will quite soon have an explosion in the analysis of these metagenomic structures.”</p>
                </div></div>
  </body>
</html>
