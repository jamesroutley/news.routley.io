<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.quantamagazine.org/an-easy-sounding-problem-yields-numbers-too-big-for-our-universe-20231204">Original</a>
    <h1>An easy-sounding problem yields numbers too big for our universe</h1>
    
    <div id="readability-page-1" class="page"><div><p>Most researchers thought Lipton had cooked up the most complex possible vector addition systems, meaning he’d raised the lower bound as high as it could go. The only thing missing, in that case, would be an upper bound to go with it — that is, a proof that there could be no system in which determining reachability was even harder. But nobody knew how to prove that. The computer scientist Ernst Mayr came closest when he <a href="https://dl.acm.org/doi/10.1145/800076.802477">proved</a> in 1981 that it’s always possible, in principle, to determine reachability in any vector addition system. But his proof didn’t put any quantitative upper bound on how hard the problem could be. There was a floor, but no ceiling in sight.</p>
<p>“I certainly thought about it on and off,” Lipton said. “But after a while I gave up, and as far as I could tell no one made any progress for what was like 40 years.”</p>
<p>In 2015, the computer scientists <a href="https://www.labri.fr/perso/leroux/">Jérôme Leroux</a> and <a href="https://www.irif.fr/en/users/schmitz/index">Sylvain Schmitz</a> finally established <a href="https://dl.acm.org/doi/10.1109/LICS.2015.16">a quantitative upper bound</a> — one so high that researchers assumed it was just a first step that could be pushed down to meet Lipton’s lower bound.</p>
<p>But that’s not what happened. In 2019, researchers discovered a lower bound far higher than Lipton’s, upending decades of conventional wisdom. The VAS reachability problem was far more complex than anyone had anticipated.</p>
<h2><strong>A Tower of Powers</strong></h2>
<p>The shocking 2019 result grew out of failure. In 2018, Czerwiński disproved a conjecture, by Leroux and <a href="https://fmazowiecki.github.io/">Filip Mazowiecki</a>, a computer scientist now at the University of Warsaw, that would have helped to make progress on a related problem. In subsequent discussions, the researchers hit upon a promising new way to construct extra-complex vector addition systems, which could imply a new lower bound on the VAS reachability problem, where progress had stalled for so long.</p>
<p>“Everything connected in my mind to VAS reachability,” Czerwiński recalled. During a semester with a light teaching load, he decided to focus exclusively on that problem, together with Leroux, Mazowiecki and two other researchers — <a href="https://www.mimuw.edu.pl/~sl/">Sławomir Lasota</a> of the University of Warsaw and <a href="https://warwick.ac.uk/fac/sci/dcs/people/ranko_lazic/">Ranko Lazić</a> of the University of Warwick.</p>

<p>After a few months, their efforts paid off. Czerwiński and his colleagues <a href="https://dl.acm.org/doi/10.1145/3313276.3316369">demonstrated</a> that they could construct vector addition systems in which the shortest path between two states was related to the size of the system by a mathematical operation called tetration that makes even nightmarish double exponential growth seem tame.</p>
<p>Tetration is a straightforward extension of a pattern connecting the most familiar operations in mathematics, beginning with addition. Add together <em>n </em>copies of a number, and the result is equivalent to multiplying that number by <em>n</em>. If you multiply together <em>n</em> copies of a number, that’s equivalent to exponentiation, or raising the number to the <em>n</em>th power. Tetration, often represented by a pair of arrows pointing up, is the next step in this sequence: Tetrating a number by <em>n </em>means exponentiating it <em>n</em> times to produce a tower of powers <em>n</em> stories high.</p>
<p>It’s hard to wrap your head around just how quickly tetration gets out of hand: $latex 2 \uparrow\uparrow 3$, or $latex 2^{2^2}$, is 16, $latex 2 ­\uparrow\uparrow ­ 4$ is just over 65,000, and $latex 2 ­\uparrow\uparrow ­5$ is a number with nearly 20,000 digits. It’s physically impossible to write down all the digits of $latex 2 \uparrow\uparrow ­­6$ — a liability of living in such a small universe.</p>
<p>In their landmark result, Czerwiński and his colleagues proved that there exist vector addition systems of size <em>n </em>where the best way to determine reachability is to map out a path involving more than $latex 2 \uparrow\uparrow ­­n$ ­­ transitions, implying a new lower bound that dwarfed Lipton’s. But as head-spinning as tetration is, it still wasn’t the final word on the complexity of the problem.</p>
<h2><strong>To Quinquagintillion and Beyond  </strong></h2>
<p>Just a few months after the shocking new lower bound on the complexity of VAS reachability, Leroux and Schmitz <a href="https://dl.acm.org/doi/abs/10.5555/3470152.3470202">pushed down</a> the upper bound they’d established three years earlier, but they didn’t get all the way down to tetration. Instead, they proved that the complexity of the reachability problem can’t grow faster than a mathematical monstrosity called the Ackermann function.</p>
<p>To understand that function, take the pattern used to define tetration to its grim conclusion. The next operation in the sequence, called pentation, represents repeated tetration; it’s followed by yet another operation (hexation) for repeated pentation, and so on.</p>
<p>The Ackermann function, denoted $latex A(n)$, is what you get when you move one step up this ladder of operations with each stop on the number line: $latex A(1) = 1 + 1$, $latex A(2) = 2 × 2$, $latex A(3) = 3^3$, $latex A(4)=4 \uparrow\uparrow 4=4^{4^{4^4}}$, and so on. The number of digits in $latex A(4)$ is itself a colossal number approximately equal to 1 quinquagintillion — that’s the whimsical and rarely needed name for a 1 followed by 153 zeros. “Don’t worry about Ackermann of 5,” advised <a href="https://www7.in.tum.de/~esparza/">Javier Esparza</a>, a computer scientist at the Technical University of Munich.</p>
</div></div>
  </body>
</html>
