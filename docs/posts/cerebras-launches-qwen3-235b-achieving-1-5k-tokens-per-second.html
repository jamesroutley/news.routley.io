<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.cerebras.ai/press-release/cerebras-launches-qwen3-235b-world-s-fastest-frontier-ai-model-with-full-131k-context-support">Original</a>
    <h1>Cerebras launches Qwen3-235B, achieving 1.5k tokens per second</h1>
    
    <div id="readability-page-1" class="page"><div data-sanity="id=1daca92e-d85d-4c17-8a94-37ebe135a75e;type=pressRelease;path=slices;base=https%3A%2F%2Fwww.cerebras.ai"><section data-slicetype="articleText" data-sanity="id=1daca92e-d85d-4c17-8a94-37ebe135a75e;type=pressRelease;path=slices:7b606ec892f1;base=https%3A%2F%2Fwww.cerebras.ai"><div><div><div><div><div><div><p><em>World&#39;s fastest frontier AI reasoning model now available on Cerebras Inference Cloud</em></p><p><em>Delivers production-grade code generation at 30x the speed and 1/10th the cost of closed-source alternatives</em></p><p><strong>Paris, July 8, 2025</strong> – Cerebras Systemstoday announced the launch of Qwen3-235B with full 131K context support on its inference cloud platform. This milestone represents a breakthrough in AI model performance, combining frontier-level intelligence with unprecedented speed at one-tenth the cost of closed-source models, fundamentally transforming enterprise AI deployment.</p><h3>Frontier Intelligence on Cerebras</h3><p>Alibaba’s Qwen3-235B delivers model intelligence that rivals frontier models such as Claude 4 Sonnet, Gemini 2.5 Flash, and DeepSeek R1across a range of science, coding, and general knowledge benchmarks according to independent tests by Artificial Analysis.</p><p>Qwen3-235B uses an efficient mixture-of-experts architecture that delivers exceptional compute efficiency, enabling Cerebras to offer the model at $0.60 per million input tokens and $1.20 per million output tokens—less than one-tenth the cost of comparable closed-source models. </p><h3>Cut Reasoning Time from Minutes to Seconds</h3><p>Reasoning models are notoriously slow, often taking minutes to answer a simple question. By leveraging the Wafer Scale Engine, Cerebrasaccelerates Qwen3-235B to an unprecedented 1,500 tokens per second, reducing response times from 1-2 minutes to 0.6 seconds, making coding, reasoning, and deep-RAG workflows nearly instantaneous.</p><p>Based on Artificial Analysis measurements, Cerebras is the only company globally offering a frontier AI model capable of generating output at over 1,000 tokens per second, setting a new standard for real-time AI performance.</p><h3>131K Context Enables Production-grade Code Generation</h3><p>Concurrent with this launch, Cerebras has quadrupled its context length support from 32K to 131K tokens—the maximum supported by Qwen3-235B. This expansion directly impacts the model&#39;s ability to reason over large codebases and complex documents. While 32K context is sufficient for simple code generation use cases, 131K context allows the model to process dozens of files and tens of thousands of lines of code simultaneously, enabling production-grade application development.</p><p>This enhanced context length means Cerebras now directly addresses the enterprise code generation market, which is one of the largest and fastest-growing segments for generative AI.</p><h3>Strategic Partnership with Cline</h3><p>To showcase these new capabilities, Cerebras has partnered with Cline, the leading agentic coding agent for Microsoft VS Code with over 1.8 million installations. Cline users can now access Cerebras Qwen models directly within the editor—starting with Qwen3-32B at 64K contexton the free tier. This rollout will expand to include Qwen3-235B with 131K context, delivering 10–20x faster code generation speeds compared to alternatives like DeepSeek R1.</p><p>&#34;With Cerebras&#39; inference, developers using Cline are getting a glimpse of the future, as Cline reasons through problems, reads codebases, and writes code in near real-time. Everything happens so fast that developers stay in flow, iterating at the speed of thought. This kind of fast inference isn&#39;t just nice to have -- it shows us what&#39;s possible when AI truly keeps pace with developers,” said Saoud Rizwan, CEO of Cline.</p><h3>Frontier Intelligence at 30x the Speed and 1/10th the Cost</h3><p>With today&#39;s launch, Cerebras has significantly expanded its inference offering, providing developers looking for an open alternative to OpenAI and Anthropic with comparable levels of model intelligence and code generation capabilities. Moreover, Cerebras delivers something that no other AI provider in the world—closed or open—can do: instant reasoning speed at over 1,500 tokens per second, increasing developer productivity by an order of magnitude vs. GPU solutions. All of this is delivered at one-tenth the token cost of leading closed-source models.</p><p><strong>About Cerebras Systems</strong></p><p>Media Contact</p><p><a href="mailto:PR@zmcommunications.com">PR@zmcommunications.com</a></p></div></div></div></div></div></div></section></div></div>
  </body>
</html>
