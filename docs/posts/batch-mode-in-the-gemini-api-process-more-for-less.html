<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/scale-your-ai-workloads-batch-mode-gemini-api/">Original</a>
    <h1>Batch Mode in the Gemini API: Process More for Less</h1>
    
    <div id="readability-page-1" class="page">
        <!-- Google Tag Manager (noscript) -->
        
        <!-- End Google Tag Manager (noscript) -->

        

				
        

<!-- HTML -->






        
  <div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          
        
          
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <h2 data-block-key="11hqd" id="gemini-models-are-now-available-in-batch-mode"><b>Gemini models are now available in Batch Mode</b></h2><h2 data-block-key="tk6g8" id="process-more-for-less"><b><br/></b>Process more for less</h2><p data-block-key="cvt5u">Batch Mode is the perfect tool for any task where you have your data ready upfront and don’t need an immediate response. By separating these large jobs from your real-time traffic, you unlock three key benefits:</p><ul><li data-block-key="el71r"><b>Cost savings:</b> Batch jobs are priced at 50% less than the standard rate for a given model</li></ul><ul><li data-block-key="46go3"><b>Higher throughput:</b> Batch Mode has even higher <a href="https://ai.google.dev/gemini-api/docs/rate-limits">rate limits</a></li></ul><ul><li data-block-key="ce5lq"><b>Easy API calls:</b> No need to manage complex client-side queuing or retry logic. Available results are returned within a 24-hour window.</li></ul><h2 data-block-key="qlyrk" id="a-simple-workflow-for-large-jobs"><b><br/></b>A simple workflow for large jobs</h2><p data-block-key="1eaf2">We’ve designed the API to be simple and intuitive. You package all your requests into a single file, submit it, and retrieve your results once the job is complete. Here are some ways developers are leveraging Batch Mode for tasks today:</p><ul><li data-block-key="1d2m2"><b>Bulk content generation and processing:</b> Specializing in deep video understanding, <a href="https://reforgedlabs.com/">Reforged Labs</a> uses Gemini 2.5 Pro to analyze and label vast quantities of video ads monthly. Implementing Batch Mode has revolutionized their operations by significantly cutting costs, accelerating client deliverables, and enabling the massive scalability needed for meaningful market insights.</li></ul>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_qhTloW2.original.png" alt="Bulk content generation and processing"/>
            
            
        </p>
    </div>
  <div>
    <ul><li data-block-key="yd7th"><b>Model evaluations:</b> <a href="https://www.vals.ai/home">Vals AI</a> benchmarks foundation models on real-world use cases, including legal, finance, tax and healthcare. They’re using Batch Mode to submit large volumes of evaluation queries without being constrained by rate limits.</li></ul>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_uvTbuTT.original.png" alt="Model evaluations"/>
            
            
        </p>
    </div>
  <div>
    <h2 data-block-key="qj374" id="get-started-in-just-a-few-lines-of-code">Get started in just a few lines of code</h2><p data-block-key="ac011">You can start using Batch Mode today with the Google GenAI Python SDK:</p>
</div>  <div>
    <pre><code># Create a JSONL that contains these lines:
# {&#34;key&#34;: &#34;request_1&#34;, &#34;request&#34;: {&#34;contents&#34;: [{&#34;parts&#34;: [{&#34;text&#34;: &#34;Explain how AI works in a few words&#34;}]}]}},
# {&#34;key&#34;: &#34;request_2&#34;, &#34;request&#34;: {&#34;contents&#34;: [{&#34;parts&#34;: [{&#34;text&#34;: &#34;Explain how quantum computing works in a few words&#34;}]}]}}

uploaded_batch_requests = client.files.upload(file=&#34;batch_requests.json&#34;)

batch_job = client.batches.create(
    model=&#34;gemini-2.5-flash&#34;,
    src=uploaded_batch_requests.name,
    config={
        &#39;display_name&#39;: &#34;batch_job-1&#34;,
    },
)

print(f&#34;Created batch job: {batch_job.name}&#34;)

# Wait for up to 24 hours

if batch_job.state.name == &#39;JOB_STATE_SUCCEEDED&#39;:
    result_file_name = batch_job.dest.file_name
    file_content_bytes = client.files.download(file=result_file_name)
    file_content = file_content_bytes.decode(&#39;utf-8&#39;)

    for line in file_content.splitlines():
      print(line)</code></pre>
    <p>
        Python
    </p>
    <p><span>Copied</span>
        
    </p>
    
    
</div>  <div>
    <p data-block-key="avai1">To learn more, check out the official documentation and pricing pages.</p><ul><li data-block-key="4m96u"><a href="https://ai.google.dev/gemini-api/docs/batch-mode"><b>Read the documentation</b></a></li></ul><ul><li data-block-key="2tvt0"><a href="https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Batch_mode.ipynb"><b>Check the cookbook guide</b></a></li></ul><ul><li data-block-key="2of9k"><a href="https://ai.google.dev/pricing"><b>View pricing</b></a></li></ul>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div>


				
				





        
				

        
        
        
        

        

        
  
  

    

</div>
  </body>
</html>
