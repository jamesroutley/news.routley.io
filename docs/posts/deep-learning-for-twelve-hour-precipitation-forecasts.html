<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41467-022-32483-x">Original</a>
    <h1>Deep learning for twelve hour precipitation forecasts</h1>
    
    <div id="readability-page-1" class="page"><div>
                <section data-title="Introduction"><div id="Sec1-section"><h2 id="Sec1">Introduction</h2><div id="Sec1-content"><p>Probabilistic forecasts predict the likelihood of weather conditions at a given time and location. Weather conditions of interest can range from core atmospheric variables such as rate of rain and snow, wind velocity and direction, temperature, pressure levels, and solar coverage to weather patterns such as hurricanes, wildfires, and floods<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Alléon, A., Jauvion, G., Quennehen, B. &amp; Lissmyr, D. Plumenet: large-scale air quality forecasting using a convolutional LSTM network. Preprint at 
                  https://arxiv.org/abs/2006.09204
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR1" id="ref-link-section-d234671850e484">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Trebing, K. &amp; Mehrkanoon, S. Wind speed prediction using multidimensional convolutional neural networks. In 2020 IEEE Symposium Series on Computational Intelligence (SSCI), 713–720, (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR2" id="ref-link-section-d234671850e487">2</a></sup>. For the case of precipitation, a probabilistic forecast answers the question, “What is the current probability of a given amount of precipitation occurring at a location and time in the future?”</p><p>Short-term forecasting up to twelve hours in advance allows for predicting weather conditions with higher spatial and temporal precision than longer time ranges. This makes it possible for these forecasts to have substantial impact on society by helping with daily planning, energy management, transportation, and the mitigation of extreme weather events, among others<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Rothfusz, L. P. et al. Facets: a proposed next-generation paradigm for high-impact weather forecasting. Bull. Am. Meteorological Soc. 99, 2025–2043 (2018)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR3" id="ref-link-section-d234671850e494">3</a></sup>. Short-term forecasting is also a longstanding scientific challenge that combines our best understanding of the physics of the atmosphere with our most advanced computational capabilities. Current operational models for short-term forecasting are Numerical Weather Prediction (NWP) models that rely on physics-based simulations. The atmospheric simulations make use of supercomputers with heterogeneous hardware that run virtually continuously in data centers around the globe and update the forecasts based on the latest observations. The weather conditions that the models predict include hundreds of atmospheric and oceanic features. The forecasts usually have a frequency of one or more hours and a grid resolution of 3–12 km. NWP methods obtain a probabilistic forecast by ensembling or post-processing the output of multiple individual physics-based models, each in turn requiring atmospheric simulation at the supercomputer scale. The accuracy of a physics-based forecast is tied to the grid resolution as more precise physics simulations require a finer representation of the state of the atmosphere. This relationship creates a computational bottleneck inherent to physics-based models that has proven challenging to overcome<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Bauer, P., Thorpe, A. &amp; Brunet, G. The quiet revolution of numerical weather prediction. Nature 525, 47–55 (2015)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR4" id="ref-link-section-d234671850e498">4</a></sup>. Besides resolution, the accuracy of the forecasts also depends on how well the physical models used in NWP describe the atmosphere at the various relevant scales; improving these models is a substantial scientific challenge by itself<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Yano, J.-I. et al. Scientific challenges of convective-scale numerical weather prediction. Bull. Am. Meteorological Soc. 99, 699–710 (2018)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR5" id="ref-link-section-d234671850e502">5</a></sup>.</p><p>Due to the computational bottleneck, the large computational resources, and the time lag that physics-based models incur when making a forecast, efficient models based on deep neural networks represent a promising alternative framework for weather modeling<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Agrawal, S. et al. Machine learning for precipitation nowcasting from radar images. In Machine Learning and the Physical Sciences Workshop, Neural Information Processing Systems, arXiv [preprint], arXiv:1912.12132, 2019 (2019)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR6" id="ref-link-section-d234671850e509">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e512">7</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig1">1</a>). Instead of explicitly simulating the physics of the atmosphere, neural models learn the relationships between input observations and output variables directly from data. Neural networks can run in a matter of seconds on parallel hardware and can thus generate forecasts more frequently and with higher spatial resolution. The networks are also notably simple and can be specified with generic modules in a few dozens of lines of code without hand-tuned routines for a specific task. The prediction of a neural network can also naturally be made probabilistic, learning to capture all the possible variability of the forecast from the data itself. These properties can not only offer improved forecasts, but also frequent and personalized forecasts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Rothfusz, L. P. et al. Facets: a proposed next-generation paradigm for high-impact weather forecasting. Bull. Am. Meteorological Soc. 99, 2025–2043 (2018)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR3" id="ref-link-section-d234671850e519">3</a></sup> and open avenues of new applications that rely on the models’ efficiency and flexibility. However, showing that the neural networks are able to learn to emulate the physics of the atmosphere sufficiently well to make skillful high-resolution forecasts for up to twelve hours ahead—a period that requires an advanced understanding of atmospheric physics and is well beyond the skill of extrapolation and short-term nowcasting methods<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Agrawal, S. et al. Machine learning for precipitation nowcasting from radar images. In Machine Learning and the Physical Sciences Workshop, Neural Information Processing Systems, arXiv [preprint], arXiv:1912.12132, 2019 (2019)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR6" id="ref-link-section-d234671850e523">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Prudden, R. et al. A review of radar-based nowcasting of precipitation and applicable machine learning techniques, arXiv preprint arXiv:2005.04988 (2020)." href="#ref-CR8" id="ref-link-section-d234671850e526">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ravuri, S. V. et al Skillful precipitation nowcasting using deep generative models of radar. CoRR, abs/2104.00954 (2021)." href="#ref-CR9" id="ref-link-section-d234671850e526_1">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Xingjian, S. et al. Convolutional lstm network: a machine learning approach for precipitation nowcasting. In Advances in Neural Information Processing Systems, 802–810 (2015)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR10" id="ref-link-section-d234671850e529">10</a></sup>—is a substantial open challenge at the core of the neural modeling approach.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Types of Weather Models."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Types of Weather Models.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="315"/></picture></a></div><p>Computation stages in a physics-based non-probabilistic NWP model (HRRR), a probabilistic ensemble NWP model (HREF), MetNet-2 and the two MetNet-2 variants. MetNet-2 does not rely on atmospheric simulation, whereas the other models do. The observation and assimilation phases prepare a representation of the current state of the atmosphere. Evaluation proceeds via categorical metrics such as CSI that require calculating decision thresholds or via probabilistic metrics such as CRPS.</p></div></figure></div><p>In this work, we present MetNet-2, a probabilistic weather model based on deep neural networks that is a successor to MetNet<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e555">7</a></sup>. MetNet-2 features a forecasting range of up to 12 h of lead time at a frequency of 2 min and a spatial resolution of 1 km. In order to capture sufficient input context, MetNet-2 uses input observations from a 2048 km × 2048 km region and adopts novel neural network architectural elements in order to effectively process the large context. Such elements are (a) a context-aggregating module that enables the receptive field of the network to double after every layer, (b) a strong lead time conditioning scheme and (c) a model parallel training setup utilizing multiple chips for increased memory and parallel computation.</p></div></div></section><section data-title="Results"><div id="Sec2-section"><h2 id="Sec2">Results</h2><div id="Sec2-content"><p>We train MetNet-2 to forecast precipitation, a fast-changing weather variable, over a 7000 km × 2500 km region of the Continental United States (CONUS). We find that MetNet-2 outperforms the probabilistic ensemble High-Resolution Ensemble Forecast (HREF) for the entire lead time range of 12 h according to the probabilistic metric Cumulative Ranked Probability Score (CRPS). When both MetNet-2 and HREF are thresholded to produce a categorical forecast, MetNet-2 outperforms HREF up to at least 9 h of lead time for both low and high rates of precipitation, according to the categorical Critical Success Index (CSI) metric. These results hold despite the key difference that MetNet-2 has an output resolution of 1 km and does not rely on forward atmospheric simulation, whereas HREF has a resolution of 3 km and relies on the results of five different forward atmospheric simulations from respective physics-based models, including those from the High-Resolution Rapid Refresh (HRRR) model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Benjamin, S. G. et al. A north American hourly assimilation and model forecast cycle: the rapid refresh. Monthly Weather Rev. 144, 1669–1694 (2016)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR11" id="ref-link-section-d234671850e567">11</a></sup>.</p><p>We also study the performance of MetNet-2 in a hybrid mode where the physics-based forecast is used as an additional input to MetNet-2 itself. We find that Hybrid MetNet-2 is able to outperform a MetNet2-postprocessed HRRR forecast up to the entire range of 12 h, according to both CRPS and CSI. This shows the ability of MetNet-2 to extract and relay unique information that is not available in the atmospheric simulation even for longer lead times. MetNet-2’s performance represents a step forward towards skillful forecasts with neural networks and suggests that MetNet-2 may be learning to emulate aspects of atmospheric physics. We perform an analysis into what MetNet-2 has learnt using state-of-the-art interpretation methods. The analysis reveals that MetNet-2 appears to make use of advanced physics principles when making its forecasts, which the model learns directly from the data.</p><h3 id="Sec3">Comparison with HREF</h3><p>Although MetNet-2 uses the assimilation features that come from HRRR in order to gain a more complete picture of the initial state of the atmosphere, MetNet-2 does not rely on the atmospheric simulation itself that is the most computationally intensive part of an NWP model. The ensemble HREF model relies on 10 such simulations coming from five different NWP models each running on a supercomputer. The first result on dataset A is that MetNet-2 obtains a better CRPS than HREF over the entire lead time range of 12 h (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig2">2</a>). This metric is particularly appropriate in this evaluation as both CRPS and HREF are probabilistic. CRPS also takes into account the entire distribution across all precipitation rates; in other words, the result incorporates the performance from low to high rates of precipitation. When thresholding both MetNet-2 and HREF, optimized based on the categorical metric CSI, MetNet-2 outperforms HREF for at least the first 9 h of lead time for low (0.2 mm/h) and high rates of precipitation up to 20 mm/h (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig2">2</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">3</a>). MetNet-2 and HREF both outperform HRRR on these metrics across the whole 12 h range (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig2">2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig3">3</a>). The skill gap between MetNet-2 and HREF is greatest in relative terms at the earliest hours and decreases gradually over time. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig4">4</a> represents two case studies of MetNet-2 and HREF forecasts. Both the uncertainty of the prediction and the variability grow over time and these aspects are evident in MetNet2’s and HREF’s forecasts. The probability of precipitation that MetNet-2 assigns to a given location tends to decrease on average over time as the probability mass is spread over a growing region of likely precipitation. The expected amount of precipitation that MetNet-2 forecasts in a patch closely matches the ground truth amount of precipitation.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Evaluation of the models’ performance (dataset A)."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Evaluation of the models’ performance (dataset A).</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="210"/></picture></a></div><p>Performance comparison on test dataset A between the probabilistic MetNet-2 and HREF. Non-probabilistic HRRR results as reference. a Evaluation based on probabilistic CRPS that includes all rates of gauge-corrected hourly cumulative precipitation. <b>b</b> Evaluation based on the categorical CSI for the 2 mm/h rate (see Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">E</a> for other rates).</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Numerical results for the models (datasets A and B)."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Numerical results for the models (datasets A and B).</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="184"/></picture></a></div><p>Critical Success Index scores of HRRR, HREF and MetNet-2 for cumulative precipitation on dataset A (first three rows) and of NWP (HRRR) and MetNet-2 variants for instantaneous precipitation of ≥2 mm/h on dataset B (last four rows). Scores are given for each of the 12 h of lead time. The best score for each set of results and each lead time is high-lighted in bold-face.</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Case studies for the models’ forecasts of cumulative precipitation."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Case studies for the models’ forecasts of cumulative precipitation.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="994"/></picture></a></div><p>Forecasts for gauge-corrected hourly cumulative precipitation ≥1 mm/h. Each contour region corresponds to the band of probability of precipitation ≥1 mm/h that the respective model assigns to that region. <b>a</b> Case study for Thu Jan 03 2019 12:00 UTC of the North West coast of the US. <b>b</b> Case study of Hurricane Isaias, a Category 1 hurricane, that caused widespread destruction and economic damage. The forecast time is Mon Aug 03 2020 20:00 UTC on the East coast of the United States.</p></div></figure></div><h3 id="Sec4">Hybrid results</h3><p>A second core result is the performance comparison of MetNet-2 in a hybrid setting that uses the prediction of an NWP model, in this case HRRR. We compare MetNet-2 Postprocess with MetNet-2 Hybrid on test dataset B for both instantaneous and cumulative precipitation targets. MetNet-2 Postprocess maps HRRR’s forecast to a probabilistic one. MetNet-2 Hybrid maps both MetNet-2’s default inputs as well as HRRR’s forecasts to a probabilistic forecast. Remarkably, the MetNet-2 architecture is able to add value to HRRR’s postprocessed forecast all the way up to 12 h of lead time. That is, the performance of MetNet-2 Hybrid is higher than that of MetNet-2 Postprocess across the whole range based on both CRPS and CSI scores and for both low and high rates of precipitation (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig5">5</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig6">6</a> shows a case study with these models and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig7">7a</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig7">b</a> visualize, respectively, the probabilistic error based on the Brier score achieved by the models, and the prediction regions for various rates of precipitation based on the CSI thresholds.</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Evaluation of the models’ performance on low and high rates of precipitation (dataset B)."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Evaluation of the models’ performance on low and high rates of precipitation (dataset B).</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig5_HTML.png?as=webp"/><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="405"/></picture></a></div><p>Tables for the second main comparison between the MetNet-2 variant Hybrid and Postprocessing using CSI and Cumulative Ranked Probability Skill Score (CRPSS). HRRR and MetNet-2 included for reference. <b>a</b> Critical Success Index metric for instantaneous precipitation of 2, 8, and 20 mm/h on test dataset B. <b>b</b> Continuous Ranked Probability Score Skill for instantaneous precipitation. The score tracks the relative improvement of MetNet-2, MetNet-2 Postprocess and MetNet-2 Hybrid over the HRRR reference.</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-6" data-title="Case study for the models’ forecasts of instantaneous precipitation."><figure><figcaption><b id="Fig6" data-test="figure-caption-text">Fig. 6: Case study for the models’ forecasts of instantaneous precipitation.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig6_HTML.png?as=webp"/><img aria-describedby="Fig6" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="780"/></picture></a></div><p>Case study for Thu Jan 03 2019 12:00 UTC of the North West coast of the US with forecasts of instantaneous precipitation. Forecasts that use MetNet-2 are visualized as 3D-like contour plots. Each contour region corresponds to one of the visualised rates of precipitation of 0.2, 1.0, 2.0, 4.0, and 8.0 mm/h. The color intensity within the contour region that corresponds to rate <i>r</i> is the probability of precipitation P(≥<i>r</i>) that the respective model predicts. Only probabilities above the corresponding CSI threshold are represented; these determine the contours. Contour regions are depicted overlapping one over the other starting from the lowest rate 0.2. We can observe in MetNet-2 models that the forecasted variability and the associated uncertainty grow with lead time. MetNet-2 Hybrid forecasts combine elements from both MetNet-2 and MetNet-2 Postprocess forecasts. The indicated percentage values denote forecast probabilities for the respective precipitation rate.</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-7" data-title="Error analysis and additional rates in case study predictions."><figure><figcaption><b id="Fig7" data-test="figure-caption-text">Fig. 7: Error analysis and additional rates in case study predictions.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig7_HTML.png?as=webp"/><img aria-describedby="Fig7" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="492"/></picture></a></div><p>Case study for Thu Jan 03 2019 12:00 UTC of the North West coast of the US with forecasts of instantaneous precipitation (same as Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig6">6</a>). <b>a</b> Brier score maps that quantify the error of the probabilistic prediction. Lower error is better. The best scores are highlighted in bold-face. NWP’s forecast is assigned probability 1 everywhere. Scores are computed only over the region of high quality radar signal (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">1</a>). <b>b</b> Decision boundaries based on thresholds optimally chosen for CSI. The numbers in each graphic correspond to the CSI score for the respective rate. Best scores are highlighted in bold face.</p></div></figure></div><h3 id="Sec5">Ablations</h3><p>We perform various ablations on the default MetNet-2 in order to shed further light on the model’s performance. A regional evaluation of MetNet-2 shows that the model performs well across diverse regions that see varying levels of annual precipitation (Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">H</a>). On the architectural front, we find that the size of the input context of 2048 km × 2048 km improves performance over context sizes of 1536 km × 1536 km, 1024 km × 1024 km and 512 km × 512 km (see “Methods” and Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">F.1</a>). The additional observations of the atmosphere that the assimilation process incorporates also have an impact on MetNet-2’s performance, especially at later hours (see “Methods” and Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">F.2</a>). MetNet-2 is able to extract information from a broad range of observations and any additional observations are likely to improve MetNet-2’s performance. Furthermore, both removing the special conditioning scheme for the lead time index (see “Methods” and Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">F.4</a>) and limiting the maximum dilation factor to 16 or below also impact MetNet-2’s performance negatively (see “Methods” and Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">F.5</a>).</p><h3 id="Sec6">Interpretation</h3><p>MetNet-2’s remarkable performance makes it important to understand what the physics-free neural network is learning. This can help researchers gain new insight about interactions between different meteorological variables and ensure that the model conforms to our prior knowledge about weather physics. We adopt a state-of-the-art neural interpretation technique called Integrated Gradients to attribute predictions to the input variables<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In International Conference on Machine Learning, pages 3319–3328. PMLR (2017)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR12" id="ref-link-section-d234671850e811">12</a></sup>. Among the notable findings, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig8">8b</a> shows that the relative importance of absolute vorticity is small for near-term forecasts, but grows in importance as lead time increases all the way up to 12 h. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig8">8a</a>, the importance of upper-level vorticity for a twelve hour forecast is consistent with what is known as quasi-geostrophic theory, a non-trivial set of simplifications and filtering of the equations of motion. A key result in the theory is that positive vorticity in the upper-troposphere is consistent with upward motion in the lower-troposphere<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Howard B Bluestein. Synoptic-Dynamic Meteorology in Midlatitudes: Observations and Theory of Weather Systems, volume 1. (Oxford University Press, New York, 1992)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR13" id="ref-link-section-d234671850e821">13</a></sup>. This upward motion does not directly trigger precipitation, but prepares the atmosphere for convection. See Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">G</a> for other key findings.</p><div data-test="figure" data-container-section="figure" id="figure-8" data-title="Attribution analysis for MetNet-2."><figure><figcaption><b id="Fig8" data-test="figure-caption-text">Fig. 8: Attribution analysis for MetNet-2.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig8_HTML.png?as=webp"/><img aria-describedby="Fig8" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="187"/></picture></a></div><p>Attribution of Absolute Vorticity, i.e., the amount a single input pixel contributes to a single pixel probability prediction. <b>a</b> Attribution of absolute vorticity at pressure levels 50hPa to 1013hPa on the 12 h lead time prediction. The solid line is a 100hPa moving average over the attributions. <b>b</b> Attribution of absolute vorticity at 250 hPa on 1–12 h lead time predictions. The solid line is a 3 h moving average.</p></div></figure></div></div></div></section><section data-title="Discussion"><div id="Sec7-section"><h2 id="Sec7">Discussion</h2><p>MetNet-2’s strong performance for both low and high levels of precipitation and for both instantaneous and cumulative measures, its ability to estimate uncertainty and capture variation, its independence from atmospheric simulation, its design simplicity and the rapid and different nature of MetNet-2’s computation represent a step towards a fundamental shift in forecasting from physics-based models to learning-based ones. The results also show how neural networks can learn to emulate complex and large-scale physics paving the way for ever more ambitious applications of neural nets in the physical sciences. Direct sensor data, although not readily available, can likely be used in place of the assimilation state to further reduce MetNet-2’s total latency to essentially just the time required for observing the atmosphere while removing any remaining reliance on NWP’s initial state. Though designed for geo-spatial prediction, little in MetNet-2’s architecture is specific to precipitation. This raises hopes that MetNet-2 could work well for many other weather variables possibly at once and even learn to transfer from one variable to the next and improve overall performance.</p></div></section><section data-title="Methods"><div id="Sec8-section"><h2 id="Sec8">Methods</h2><div id="Sec8-content"><h3 id="Sec9">Framework</h3><p>MetNet-2 and NWP models gather empirical observations in order to obtain an initial state of the atmosphere as a basis for their forecasts. Observations come from a variety of sensors that are located on the ground in weather stations, on satellites, on airplanes and balloons, and on ocean buoys, among others. An important source of observations in our framework are those coming from ground radars that densely populate the Continental United States. The reflectivity, measured by these radars, estimates the amount of precipitation at a given time and location. The estimates are made every few minutes and have a relatively high spatial resolution of 1 km × 1 km. In our framework, we use two types of precipitation measures: instantaneous precipitation that comes from the radar reflectivity at a temporal frequency of two minutes; and hourly cumulative precipitation that represents the amount of precipitation over the preceding hour. In the latter, rain gauges at weather stations are used to further corroborate the radar measurements improving the data reliability. The Multi-Radar Multi-System (MRMS) provides both of these measures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="MRMS. Multi-radar/multi-sensor system (mrms). 
                  https://www.nssl.noaa.gov/projects/mrms/
                  
                , (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR14" id="ref-link-section-d234671850e876">14</a></sup>. While radar measurements provide information about the measures of precipitation, they do not describe the many other variables of the atmosphere, such as pressure, temperature and wind velocity and direction. Since the latter are not readily available, in order to incorporate them in our framework, we use the available set of atmospheric observations that result from the data assimilation process in the NWP model HRRR. This process uses various statistical and physics-based techniques to incorporate observations from the atmospheric sensors including those coming from the radars themselves. The resulting state is the starting point for HRRR’s simulation and we also adopt that state as an input for MetNet-2 to provide the model with more detailed information about the initial state of the atmosphere (for a full list of assimilation features, see ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="HRRR. Hrrr state variables. 
                  https://home.chpc.utah.edu/~u0553130/BrianBlaylock/HRRRarchive/hrrrprstablef00-f01.html
                  
                , (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR15" id="ref-link-section-d234671850e879">15</a>). In addition to radar and assimilation features, MetNet-2 also receives space-time coordinates for longitude, latitude, elevation, and forecast time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e883">7</a></sup> as well as optical satellite imagery; see Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">B</a> for a full description of data inputs.</p><h3 id="Sec10">Ground truth</h3><p>The radar precipitation measures are especially important for our task as they also serve as the ground truth training targets for MetNet-2. The instantaneous measures and the hourly cumulated measures are produced at 2 and 60 min intervals respectively. The measures range from a rate of 0–102.4 mm/h, with the higher and more extreme rates of precipitation becoming increasingly rare in the data; see Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">B.2</a> summarizing how often various rates occur in the data.</p><h3 id="Sec11">Dataset creation and splits</h3><p>The data for MetNet-2 comes in input-output pairs where the inputs include radar, satellite, and weather state and outputs, the ground truth, correspond to the radar precipitation estimates. The available data spans a period from July 2017 to August 2020. The training, validation and test data sets are generated without overlap from periods in sequence. Successive periods of 400, 12, 40, 40 and 12 h are used to sample, respectively, training, validation, and test data, with the two 12 h periods inserted as hiatus. Spatially, the target patches are sampled randomly from intersections on a grid over the CONUS region spaced at .5 degrees in longitude and latitude. We sample two different test datasets, A and B, the former for our main comparison with HREF and the latter to compare the various MetNet-2 variants. Test dataset A covers only cumulative precipitation as HREF doesn’t forecast instantaneous precipitation and the available HREF data over CONUS overlaps at 953 timestamps with the rest of the data, from which the test dataset A is sampled. Test dataset B covers both cumulative and instantaneous precipitation and overlaps with the rest of the data at all timestamps. Both datasets contain 39,841 patches each.</p><h3 id="Sec12">MetNet-2 postprocess and hybrid</h3><p>To study MetNet-2’s performance in hybrid settings, we consider other training modes for MetNet-2 that, contrary to the default MetNet-2, make use of the outcome of NWP’s atmospheric simulation. MetNet-2 Postprocess takes as an input HRRR’s forecast for a given lead time along with static location, altitude, and time features and learns to map HRRR’s forecast as closely as possible to the ground truth. It also learns to correct for any systematic biases in HRRR’s forecast and makes the forecast probabilistic. MetNet-2.</p><p>Hybrid learns to extract information from all the available inputs, including the twelve hourly forecasts from HRRR, as well as the radar and assimilation inputs used in the default MetNet-2. Whereas HRRR produces individual non-probabilistic rollouts, MetNet-2 and the variants are probabilistic at their core. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig1">1</a> summarizes the types of models and the respective steps.</p><h3 id="Sec13">Model and architecture</h3><p>A probabilistic forecast captures the combined uncertainty of both the measurements and the model:</p><div id="Equ1"><p><span>$$P({{{{\bf{r}}}}}_{x,y,t}{{{{{\rm{|}}}}}}t_0)=f({{{{{\bf{c}}}}}}_{x,y,t_0},L)$$</span></p><p>
                    (1)
                </p></div><p>where <b>r</b> are rates of precipitation, <i>x,y,t</i> are the location and target time of the forecast, <i>t</i><sub>0</sub> is the time at which the forecast is made, <b>c</b><sub><i>x,y,t</i>0</sub> is the atmospheric context at time <i>t</i><sub>0</sub> relevant for location <i>x,y</i> and <i>L</i> = <i>t</i> − <i>t</i><sub>0</sub> is the lead time of the forecast. MetNet-2 bins the precipitation rates into 512 categories that allow the model to forecast arbitrary discrete probability distributions over the categories<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e1087">7</a></sup>.</p><p>The size of the input context plays a key role in the design of MetNet-2’s architecture. Due to fast-changing nature of the atmosphere, the longer the lead time of the forecast for a location <i>x,y</i> the more context the model needs around <i>x,y</i> in order to have sufficient information for a skillful forecast. The context grows spatially in both dimensions and hence the total number of locations to attend grows quadratically in the length of the lead time. For a target patch of size 512 km × 512 km and forecast lead times of up to 12 h, MetNet-2 uses an input context size of 2048 km × 2048 km. This amounts to between 64 and 85 km of context per hour of lead time in each spatial dimension.</p><p>Besides making a large context available to the network, the network must be able to process and attend to the key parts of the context with its architecture. It is a special feature of the weather forecasting task that these key parts vary as a function of lead time: for the same input patch of data as lead time increases, the network must attend to key parts of an ever-growing potential region. These variable range dependencies present a challenge for the design of the neural architecture.</p><h3 id="Sec14">Input encoder</h3><p>The input to MetNet-2 captures 2048 km × 2048 km of weather context for each input feature, but it is downsampled via averaging by a factor of 4 in each spatial dimension, resulting in an input patch of 512 × 512 positions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig9">9a</a>). The downsampling provides a trade-off between maintaining a sufficient amount of information in the context while substantially reducing the amount of computation required to encode this information.</p><div data-test="figure" data-container-section="figure" id="figure-9" data-title="MetNet-2 context aggregation and architecture."><figure><figcaption><b id="Fig9" data-test="figure-caption-text">Fig. 9: MetNet-2 context aggregation and architecture.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://ntietz.com/articles/s41467-022-32483-x/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig9_HTML.png?as=webp"/><img aria-describedby="Fig9" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-022-32483-x/MediaObjects/41467_2022_32483_Fig9_HTML.png" alt="figure 9" loading="lazy" width="685" height="497"/></picture></a></div><p>Diagrams of various aspects of the MetNet-2 model. <b>a</b> MetNet-2 captures increasing amounts of context around the target patch. The figure shows the effects of the orthographic projection for the context and target, onto Earth with an equirectangular projection. <b>b</b> MetNet-2 layers are spread over 4 × 4 TPU cores. The figure represents a convolution with dilation factor 128 reaching out to neighboring TPUs to retrieve the relevant parts of the layer. <b>c</b> Pattern of connectivity when using convolutions with dilation factors that double at each layer. The total receptive field grows exponentially in the number of layers. <b>d</b> MetNet-2 architecture. Radar, Assimilation, and Geo-spatial features enter the network along a time dimension. A convolutional recurrent network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Xingjian, S. et al. Convolutional lstm network: a machine learning approach for precipitation nowcasting. In Advances in Neural Information Processing Systems, 802–810 (2015)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR10" id="ref-link-section-d234671850e1138">10</a></sup> embeds the input step by step. A stack of convolutional blocks with increasing dilation captures the large context of the embedded input. After a center crop corresponding to the target patch area and a tiling operation that restores the 1 km × 1 km resolution, a final stack of convolutional blocks produces a distribution over precipitation levels for each target patch position. A rich embedding of the lead time index conditions each convolutional layer of the network.</p></div></figure></div><p>In addition to the input patches having spatial dimensions, they also have a time dimension in the form of multiple time slices (see Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">B.1</a> for details). This is to ensure that the network has access to the temporal dynamics in the input features. After padding and concatenation together along the depth axis, the input sets are embedded using a convolutional recurrent network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Xingjian, S. et al. Convolutional lstm network: a machine learning approach for precipitation nowcasting. In Advances in Neural Information Processing Systems, 802–810 (2015)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR10" id="ref-link-section-d234671850e1156">10</a></sup> in the time dimension<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e1160">7</a></sup>.</p><h3 id="Sec15">Exponentially dilated convolutions</h3><p>The next part of MetNet-2’s architecture aims at connecting each position in the layer representing the encoded context with every other position in order to capture the full context. MetNet-2 uses two-dimensional convolutional residual blocks with a sequence of exponentially increasing dilation factors of size 1, 2, 4,…, 128<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Kalchbrenner, N. et al. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099, 
                  https://arxiv.org/pdf/1610.10099.pdf
                  
                 (2017)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR16" id="ref-link-section-d234671850e1172">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="van den Oord, A. et al. Wavenet: a generative model for raw audio. CoRR abs/1609.03499 (2016)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR17" id="ref-link-section-d234671850e1175">17</a></sup>. Dilation factors increase the receptive field of the convolution by skipping positions without increasing the number of parameters (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig9">9c</a>). Each position connects in this manner to all of the other 512 × 512 positions of the encoded tensor. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">2</a> illustrates the exact residual block with the dilated convolutions. Three stacks of 8 residual blocks form this context aggregating part of MetNet-2’s architecture. The target patch of precipitation that MetNet-2 predicts corresponds to 512 km × 512 km and is centered in the middle of the 2048 km × 2048 km of the input patch. Because of that, the 512 × 512 positions from the context aggregation in the input encoder, are cropped to 128 × 128 positions. To obtain a prediction for the full size target patch, we upsample four times in each dimension, effectively creating another layer of 512 × 512 positions. This is processed with another shallow network and ends with a categorical prediction over 512 precipitation levels for each target position. See Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig9">9d</a> for a full depiction of the architecture and Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">D</a> for additional architectural details.</p><h3 id="Sec16">Conditioning with lead time</h3><p>MetNet-2 encodes the lead time as a one-hot embedding with indices from 0 to 359 representing the range between 2 and 720 min<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at 
                  https://arxiv.org/abs/2003.12140
                  
                 (2020)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR7" id="ref-link-section-d234671850e1199">7</a></sup> and mapped into a continuous representation. Instead of feeding the lead time embedding only at the input of MetNet-2, the embedding is applied both an additive and multiplicative factor to each of the two convolutional layers in the residual blocks of MetNet-2<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Perez, E., Strub, F., De Vries, H., Dumoulin, V. &amp; Courville, A. Film: visual reasoning with a general conditioning layer. In Proc. AAAI Conference on Artificial Intelligence, volume 32, (2018)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR18" id="ref-link-section-d234671850e1203">18</a></sup>. This ensures that the output of each convolutional layer now depends directly on lead time.</p><h3 id="Sec17">Neural network parallelism</h3><p>Due to the large input context, the 512 × 512 × <i>d</i> input/internal representations and the 512 × 512 target patch, the network does not fit on a single TPU core. Instead of reducing the dimensions of the target patch, which will cause redundant computation since each smaller target patch will have overlapping input context, or reducing the dimensions of the internal representations, we use model parallelism. The input and the target is split into a four by four grid and processed by 16 interconnected TPU cores, with each TPU core responsible for a 128 × 128 area of the target, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://ntietz.com/articles/s41467-022-32483-x#Fig9">9b</a>. The necessary communication at each layer is handled automatically and efficiently<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Bradbury, J. et al. JAX: composable transformations of Python+NumPy programs, (2018)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR19" id="ref-link-section-d234671850e1221">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Xu, Y. et al. GSPMD: general and scalable parallelization for ML computation graphs. CoRR, abs/2105.04663, (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR20" id="ref-link-section-d234671850e1224">20</a></sup>. This scheme that can be scaled further if needed makes it efficient to compute very large contexts for each target position.</p></div></div></section>
                </div><div>
            <section data-title="Data availability"><div id="data-availability-section"><h2 id="data-availability">Data availability</h2><p>The data sources used in this study—the MRMS<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="MRMS. Multi-radar/multi-sensor system (mrms). 
                  https://www.nssl.noaa.gov/projects/mrms/
                  
                , (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR14" id="ref-link-section-d234671850e1298">14</a></sup>, GOES<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="GOES. Noaa geostationary satellite (goes). 
                  https://www.goes.noaa.gov/index.html
                  
                , (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR21" id="ref-link-section-d234671850e1302">21</a></sup> and HRRR<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="HRRR. Hrrr state variables. 
                  https://home.chpc.utah.edu/~u0553130/BrianBlaylock/HRRRarchive/hrrrprstablef00-f01.html
                  
                , (2021)." href="https://ntietz.com/articles/s41467-022-32483-x#ref-CR15" id="ref-link-section-d234671850e1306">15</a></sup> data—are publicly available for research use and can be accessed at the respective links.</p></div></section><section data-title="Code availability"><div id="code-availability-section"><h2 id="code-availability">Code availability</h2><div id="code-availability-content">
              
              <p>We provide code for the MetNet-2 model and architecture that can be run with dummy inputs at <a href="https://colab.research.google.com/github/google/ai-weather-climate/blob/main/metnet2/colab.ipynb">https://colab.research.google.com/github/google/ai-weather-climate/blob/main/metnet2/colab.ipynb</a>. See also pseudocode in Supplement <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM1">D</a>.</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Alléon, A., Jauvion, G., Quennehen, B. &amp; Lissmyr, D. Plumenet: large-scale air quality forecasting using a convolutional LSTM network. Preprint at <a href="https://arxiv.org/abs/2006.09204">https://arxiv.org/abs/2006.09204</a> (2020).</p></li><li data-counter="2."><p id="ref-CR2">Trebing, K. &amp; Mehrkanoon, S. Wind speed prediction using multidimensional convolutional neural networks. In <i>2020 IEEE Symposium Series on Computational Intelligence (SSCI)</i>, 713–720, (2020).</p></li><li data-counter="3."><p id="ref-CR3">Rothfusz, L. P. et al. Facets: a proposed next-generation paradigm for high-impact weather forecasting. <i>Bull. Am. Meteorological Soc.</i> <b>99</b>, 2025–2043 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1175/BAMS-D-16-0100.1" data-track-action="article reference" href="https://doi.org/10.1175%2FBAMS-D-16-0100.1" aria-label="Article reference 3" data-doi="10.1175/BAMS-D-16-0100.1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018BAMS...99.2025R" aria-label="ADS reference 3">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Facets%3A%20a%20proposed%20next-generation%20paradigm%20for%20high-impact%20weather%20forecasting&amp;journal=Bull.%20Am.%20Meteorological%20Soc.&amp;doi=10.1175%2FBAMS-D-16-0100.1&amp;volume=99&amp;pages=2025-2043&amp;publication_year=2018&amp;author=Rothfusz%2CL%20P">
                    Google Scholar</a> 
                </p></li><li data-counter="4."><p id="ref-CR4">Bauer, P., Thorpe, A. &amp; Brunet, G. The quiet revolution of numerical weather prediction. <i>Nature</i> <b>525</b>, 47–55 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature14956" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature14956" aria-label="Article reference 4" data-doi="10.1038/nature14956">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.525...47B" aria-label="ADS reference 4">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://ntietz.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhsVCis7vE" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20quiet%20revolution%20of%20numerical%20weather%20prediction&amp;journal=Nature&amp;doi=10.1038%2Fnature14956&amp;volume=525&amp;pages=47-55&amp;publication_year=2015&amp;author=Bauer%2CP&amp;author=Thorpe%2CA&amp;author=Brunet%2CG">
                    Google Scholar</a> 
                </p></li><li data-counter="5."><p id="ref-CR5">Yano, J.-I. et al. Scientific challenges of convective-scale numerical weather prediction. <i>Bull. Am. Meteorological Soc.</i> <b>99</b>, 699–710 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1175/BAMS-D-17-0125.1" data-track-action="article reference" href="https://doi.org/10.1175%2FBAMS-D-17-0125.1" aria-label="Article reference 5" data-doi="10.1175/BAMS-D-17-0125.1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018BAMS...99..699Y" aria-label="ADS reference 5">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Scientific%20challenges%20of%20convective-scale%20numerical%20weather%20prediction&amp;journal=Bull.%20Am.%20Meteorological%20Soc.&amp;doi=10.1175%2FBAMS-D-17-0125.1&amp;volume=99&amp;pages=699-710&amp;publication_year=2018&amp;author=Yano%2CJ-I">
                    Google Scholar</a> 
                </p></li><li data-counter="6."><p id="ref-CR6">Agrawal, S. et al. Machine learning for precipitation nowcasting from radar images. In <i>Machine Learning and the Physical Sciences Workshop, Neural Information Processing Systems</i>, arXiv [preprint], arXiv:1912.12132, 2019 (2019).</p></li><li data-counter="7."><p id="ref-CR7">Sønderby, C. K. et al. Metnet: a neural weather model for precipitation forecasting. Preprint at <a href="https://arxiv.org/abs/2003.12140">https://arxiv.org/abs/2003.12140</a> (2020).</p></li><li data-counter="8."><p id="ref-CR8">Prudden, R. et al. A review of radar-based nowcasting of precipitation and applicable machine learning techniques, arXiv preprint arXiv:2005.04988 (2020).</p></li><li data-counter="9."><p id="ref-CR9">Ravuri, S. V. et al Skillful precipitation nowcasting using deep generative models of radar. <i>CoRR</i>, abs/2104.00954 (2021).</p></li><li data-counter="10."><p id="ref-CR10">Xingjian, S. et al. Convolutional lstm network: a machine learning approach for precipitation nowcasting. In <i>Advances in Neural Information Processing Systems</i>, 802–810 (2015).</p></li><li data-counter="11."><p id="ref-CR11">Benjamin, S. G. et al. A north American hourly assimilation and model forecast cycle: the rapid refresh. <i>Monthly Weather Rev.</i> <b>144</b>, 1669–1694 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1175/MWR-D-15-0242.1" data-track-action="article reference" href="https://doi.org/10.1175%2FMWR-D-15-0242.1" aria-label="Article reference 11" data-doi="10.1175/MWR-D-15-0242.1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016MWRv..144.1669B" aria-label="ADS reference 11">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20north%20American%20hourly%20assimilation%20and%20model%20forecast%20cycle%3A%20the%20rapid%20refresh&amp;journal=Monthly%20Weather%20Rev.&amp;doi=10.1175%2FMWR-D-15-0242.1&amp;volume=144&amp;pages=1669-1694&amp;publication_year=2016&amp;author=Benjamin%2CSG">
                    Google Scholar</a> 
                </p></li><li data-counter="12."><p id="ref-CR12">Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In <i>International Conference on Machine Learning</i>, pages 3319–3328. PMLR (2017).</p></li><li data-counter="13."><p id="ref-CR13">Howard B Bluestein. <i>Synoptic-Dynamic Meteorology in Midlatitudes: Observations and Theory of Weather Systems</i>, volume 1. (Oxford University Press, New York, 1992).</p></li><li data-counter="14."><p id="ref-CR14">MRMS. Multi-radar/multi-sensor system (mrms). <a href="https://www.nssl.noaa.gov/projects/mrms/">https://www.nssl.noaa.gov/projects/mrms/</a>, (2021).</p></li><li data-counter="15."><p id="ref-CR15">HRRR. Hrrr state variables. <a href="https://home.chpc.utah.edu/~u0553130/BrianBlaylock/HRRRarchive/hrrrprstablef00-f01.html">https://home.chpc.utah.edu/~u0553130/BrianBlaylock/HRRRarchive/hrrrprstablef00-f01.html</a>, (2021).</p></li><li data-counter="16."><p id="ref-CR16">Kalchbrenner, N. et al. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099, <a href="https://arxiv.org/pdf/1610.10099.pdf">https://arxiv.org/pdf/1610.10099.pdf</a> (2017).</p></li><li data-counter="17."><p id="ref-CR17">van den Oord, A. et al. Wavenet: a generative model for raw audio. CoRR abs/1609.03499 (2016).</p></li><li data-counter="18."><p id="ref-CR18">Perez, E., Strub, F., De Vries, H., Dumoulin, V. &amp; Courville, A. Film: visual reasoning with a general conditioning layer. In <i>Proc. AAAI Conference on Artificial Intelligence</i>, volume 32, (2018).</p></li><li data-counter="19."><p id="ref-CR19">Bradbury, J. et al. JAX: composable transformations of Python+NumPy programs, (2018).</p></li><li data-counter="20."><p id="ref-CR20">Xu, Y. et al. GSPMD: general and scalable parallelization for ML computation graphs. <i>CoRR</i>, abs/2105.04663, (2021).</p></li><li data-counter="21."><p id="ref-CR21">GOES. Noaa geostationary satellite (goes). <a href="https://www.goes.noaa.gov/index.html">https://www.goes.noaa.gov/index.html</a>, (2021).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41467-022-32483-x?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div id="Ack1-section"><h2 id="Ack1">Acknowledgements</h2><p>We would like to thank Amy McGovern and Stephan Hoyer for insightful discussions and comments on the draft of the paper, and Zack Ontiveros, David McPeek, Ian Gonzalez, Claudio Martella, Samier Merchant, Fred Zyda, and Daniel Furrer for project and technical contributions.</p></div></section><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><p><span id="author-notes">Author notes</span></p><ol><li id="na1"><p>These authors contributed equally: Lasse Espeholt, Nal Kalchbrenner.</p></li></ol><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Google Research, Google Inc, 1600 Amphitheatre Pkwy, Mountain View, CA, 94043, USA</p><p>Lasse Espeholt, Shreya Agrawal, Casper Sønderby, Manoj Kumar, Jonathan Heek, Carla Bromberg, Cenk Gazen, Rob Carver, Marcin Andrychowicz, Jason Hickey, Aaron Bell &amp; Nal Kalchbrenner</p></li></ol><h3 id="contributions">Contributions</h3><p>Research lead: N.K. Engineering lead: L.E. Data ingestion and dataset creation: L.E., S.A., C.G., and C.S. Model architecture: N.K., L.E., and M.K. Model training: N.K., L.E., J.H., M.K., C.S., and M.A. Model evaluation: L.E., N.K., and S.A. Model interpretation: S.A. Visualization: L.E., N.K., and S.A. Paper and revisions: N.K., L.E., and S.A. Technical advising and domain expertise: J.H., C.B., A.B., R.C., and M.A. Project and resource management: C.B., N.K., L.E., and A.B.</p><h3 id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:lespeholt@google.com">Lasse Espeholt</a> or <a id="corresp-c2" href="mailto:nalk@google.com">Nal Kalchbrenner</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar2">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div id="peer-review-section"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar1">Peer review information</h3>
                <p><i>Nature Communications</i> thanks Luca Massidda, Stephan Rasp and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://ntietz.com/articles/s41467-022-32483-x#MOESM2">Peer reviewer reports</a> are available.</p>
              
            </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section><section data-title="Supplementary information"><div id="Sec18-section"><h2 id="Sec18">Supplementary information</h2></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Deep%20learning%20for%20twelve%20hour%20precipitation%20forecasts&amp;author=Lasse%20Espeholt%20et%20al&amp;contentID=10.1038%2Fs41467-022-32483-x&amp;copyright=The%20Author%28s%29&amp;publication=2041-1723&amp;publicationDate=2022-09-01&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s41467-022-32483-x" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41467-022-32483-x" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Espeholt, L., Agrawal, S., Sønderby, C. <i>et al.</i> Deep learning for twelve hour precipitation forecasts.
                    <i>Nat Commun</i> <b>13</b>, 5145 (2022). https://doi.org/10.1038/s41467-022-32483-x</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41467-022-32483-x?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2021-08-30">30 August 2021</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2022-06-28">28 June 2022</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2022-09-01">01 September 2022</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41467-022-32483-x</span></p></li></ul></div></div></div></div></section>
            </div></div>
  </body>
</html>
