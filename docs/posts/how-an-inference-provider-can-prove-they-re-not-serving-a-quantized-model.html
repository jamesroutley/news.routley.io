<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tinfoil.sh/blog/2026-02-03-proving-model-identity">Original</a>
    <h1>How an inference provider can prove they&#39;re not serving a quantized model</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><article><a href="https://tinfoil.sh/blog">← Back to Posts</a><p><img src="https://tinfoil.sh/blog-images/2026-02-03-proving-model-identity.jpg" alt="How Tinfoil Proves Exactly What Model Is Running"/></p><div><div><div><p><span>Feb 3, 2026</span><span>•</span><span>12 min read</span></p><p>Tinfoil Team</p></div></div></div><p>When you call an inference API, how do you know which model you&#39;re actually
served? Sure you can specify the name of the model you <em>expect</em>
to process your request, but ultimately you have no guarantee that the provider
is actually serving it.</p>
<p>When talking to an open-source model, are you being served the exact weights that the
model publisher released on Hugging Face? Or is it a silently quantized version,
or a version with a smaller context window that changes based on how much
traffic the provider is experiencing?</p>
<p>The situation gets even murkier when using a closed-source model provider.
How do you know that you are getting the same model each time?</p>
<p>People routinely report wide variation in evals across providers (and sometimes
across time within the same provider, see
<a href="http://marginlab.ai/trackers/claude-code/">Claude Opus performance tracking</a>).
And sometimes, accidental misconfigurations can silently
<a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">degrade quality</a>.</p>
<div><div><p><img src="https://tinfoil.sh/blog-images/2026-02-03-reddit-localllama.png" alt="Reddit post from LocalLLaMA community discussing the challenge of verifying whether third-party API providers are serving the advertised models or secretly using lower-quality quantizations to cut costs."/></p></div><div><p><img src="https://tinfoil.sh/blog-images/andon-labs-tweet.jpg" alt="Andon Labs tweet showing that using the Kimi K2.5 model through different API providers results in significantly different performance in their vending machine evals."/></p></div></div>
<h3>Verifiable Inference with Modelwrap</h3>
<p>At Tinfoil, we built <a href="https://github.com/tinfoilsh/modelwrap">Modelwrap</a>, which is a way to cryptographically guarantee that we are
serving a specific, untampered set of weights that our clients can verify
on each request. This is a <em>very strong</em> guarantee that so far we have not
seen any other inference provider offer. At its core, Modelwrap consists of the following components:</p>
<ol>
<li>A public commitment to model weights</li>
<li>A mechanism to bind the public commitment to the inference server</li>
<li>A process to verify, client-side, that the inference server is using the
committed model weights</li>
</ol>
<p>In this post, we go into the technical details of how we built Modelwrap.</p>
<h2>Why is this harder than just vanilla attestation?</h2>
<p>We run models in secure hardware enclaves, which already allow us to prove
which code we&#39;re running inside the enclave through <a href="https://tinfoil.sh/blog/2025-01-13-how-tinfoil-builds-trust">attestation</a>.
In a nutshell, the way that attestation works is by measuring the initial state
of the machine at launch time. When you boot an enclave with a given
binary, the hardware produces a signed report that proves
exactly what binary was loaded.</p>
<p><strong>But attestation measures launch state, not runtime state.</strong>
Weights are loaded from disk storage after the enclave has already booted.
If you rely on basic attestation, the attestation report will not include
this post-boot loading from disk storage. So the real problem becomes:</p>
<blockquote>
<p>How do we make attestation meaningfully bind to data that is fetched later?</p>
</blockquote>
<p><strong>The trick is to attest that the enclave includes both the expected hash of
the data and some code that will check that hash after it&#39;s loaded.</strong>
With Modelwrap we end up attesting two things:</p>
<ol>
<li>The cryptographic commitment to the model weights (a single root hash via a Merkle tree)</li>
<li>The enforcement mechanism that checks the commitment (kernel-level
verification on every read via dm-verity)</li>
</ol>
<p>We&#39;re still using boot-time attestation, but now the attestation process proves
that &#34;the system is configured so that it <em>cannot read bytes that don&#39;t
match the committed hash,</em>&#34; which provides a <em>runtime</em> guarantee. The
enforcement mechanism we use under-the-hood is called <strong>dm-verity</strong>, a
kernel-level system for verifying cryptographic commitments of read-only
filesystems.</p>
<h2>Building Blocks</h2>
<p>Before diving in, we need to explain the building blocks that make up Modelwrap.</p>
<h3>Merkle Tree</h3>
<p>Suppose the model weights are 140GB. We would like to prove that &#34;these
are <em>exactly</em> the weights we publicly committed to&#34;. A Merkle tree lets
you authenticate large amounts of data (140GB) with a small commitment (32 bytes).
The idea is to split the data into fixed-size blocks of 4KB each, then
hash pairs of those hashes together, and keep going until you&#39;re left with a
single root hash. If any part of the data changes anywhere, the root hash also
changes. Such a hash tree makes it easy to verify any single block corresponds
to the commitment at read time: all we need is to check hashes along the path
from the block to that root.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-merkle-tree.jpg" alt="Merkle tree structure for model weights"/></p>
<p>Merkle trees are commonly used in situations where large amounts of data must be verified piecewise such as in Certificate Transparency and Sigstore.</p>
<h3>dm-verity</h3>
<p>The Merkle tree gives us a way to verify any block with one root hash.
But that alone won&#39;t stop anyone from reading bad data. Something needs to
actually enforce verification on every read. This is where dm-verity comes in.
dm-verity is a Linux kernel subsystem that verifies disk reads using a Merkle
tree. When the inference server (such as vLLM) calls <code>read()</code> to load model
weights, dm-verity automatically intercepts the request, fetches the block,
hashes it, walks the Merkle tree to the root, and compares against the provided
root hash. If there&#39;s a match, it returns the data. If there is no match, it
returns an I/O error and the application never receives the corrupted block.</p>
<p>We want to emphasize that the magic of dm-verity is that vLLM (or any
application doing the reads) has <em>no idea</em> this verification is happening!
This means there is no need for code changes or special APIs. Everything
happens transparently at the kernel level. If the weights don&#39;t match the
committed root hash, it simply becomes impossible to read from disk and the
application gets an I/O error.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-dm-verity.jpg" alt="dm-verity comparison"/></p>
<p>This is how Android verified boot has worked since 2013. The bootloader
passes a trusted root hash to the kernel. Every block read from the system
partition gets checked against the hash tree. Billions of devices use this
to catch any disk tampering today.</p>
<h2>Modelwrap Architecture</h2>
<p>Modelwrap uses a combination of dm-verity and read-only filesystems to create
what&#39;s called an &#34;attested disk&#34;. This is a standard technique used in
confidential computing for OS image integrity. For instance, this pattern
was used by <a href="https://confidentialcontainers.org/blog/2024/03/01/building-trust-into-os-images-for-confidential-containers/">Confidential Containers</a>
for OS and <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/al2023-isolated-compute-recipe.html">Amazon Linux attestable AMIs</a>.</p>
<p>Our main <strong>insight behind Modelwrap is that model weights have the same
properties as OS images because (1) they&#39;re large, (2) read-only at
inference time, and (3)
in our case need strong integrity guarantees</strong>.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-modelwrap-architecture.jpg" alt="Modelwrap Architecture"/></p>
<p>Modelwrap proceeds in three phases:</p>
<h3>1. Computing the model weight commitment</h3>
<p>Modelwrap first downloads the model weights at a specific version.
It then computes a Merkle hash tree (using dm-verity) and outputs the
root hash as the public commitment. Anyone can run Modelwrap themselves
to ensure that the root hash corresponds to the right model weights.</p>
<p>This commitment is provided to the kernel when booting a new secure enclave.</p>
<h4>Deterministic download</h4>
<p>Modelwrap takes a Hugging Face model with an explicit commit hash:</p>
<!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$-->
<p>Modelwrap downloads the model files, verifies them against Hugging Face&#39;s
checksums, and normalizes the directory structure so rebuilds are reproducible.</p>
<h4>Build the image</h4>
<p>The downloaded weights become an <a href="https://docs.kernel.org/filesystems/erofs.html">EROFS</a>
image—a Linux filesystem optimized for read-only, immutable data
(dm-verity requires read-only).</p>
<h4>Compute the root hash</h4>
<p>Modelwrap uses <code>veritysetup</code>, a dm-verity utility, to build a Merkle tree over
the EROFS image, and compute the root hash. This is bundled together with the
image into a single modelwrap (.mpk) file for distribution.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-mpk-layout.jpg" alt="model.mpk layout"/></p>
<h3>2. Bind the commitment to the kernel</h3>
<p>The Merkle tree root hash computed in the previous step is supplied to dm-verity
via the kernel command line. Since the enclave measurement includes the
kernel command line, the enclave attestation now covers the hash tree and,
transitively, all model weights and configurations.</p>
<p>Even though the weights haven&#39;t actually loaded yet, the enclave has been
committed to the weights that will be loaded, as dm-verity will ensure only
the right model weights pass verification at runtime.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-hardware-measurement.jpg" alt="Hardware measurement"/></p>
<h3>3. Enforcing this commitment</h3>
<p>When vLLM loads the model, it reads the weights from disk. During this process,
dm-verity intercepts every disk read, verifies the block against the attested
root hash, throwing an error if even a single bit of the disk does not
correspond to the committed weights. Importantly, this is all done automatically
without requiring any changes to vLLM or the inference server code. This means
Tinfoil can use unmodified upstream software rather than maintaining forks or
patches that would have to be independently verified.</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-enforcement-flow.jpg" alt="vLLM enforcement flow"/></p>
<h2>Verifying Public vs Private Models</h2>
<p>For public models, anyone can verify. This is because anyone can download the
same Hugging Face commit, run Modelwrap, check that your root hash matches
the one in the attestation report. If it matches, you know the enclave
is running exactly those weights.</p>
<p>If you&#39;ve fine-tuned a model or trained something proprietary, you probably
don&#39;t want to publish the weights. But you might still want to run it in a
verifiable enclave.</p>
<p>Modelwrap handles this case too! You build the image yourself from your private
weights. The root hash goes into your enclave config and shows up in the
attestation report. If you swap weights, the hash changes. If the infrastructure
tampers with the image, verification fails. Your users can verify that they&#39;re
getting the <em>same</em> model every time, even without seeing the weights themselves.
If you also want to keep the weights private from Tinfoil, you can encrypt the
disk with <a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/dm-crypt.html">dm-crypt</a>
and only give the key to the attested enclave at runtime.</p>
<h3>Alternative Approaches</h3>
<p>It&#39;s helpful to contextualize Modelwrap relative to other solutions we could
have used to provide verifiability. Here we cover some natural approaches we
considered and why we found them lacking in our use cases.</p>
<p><strong>Why not bake weights into the VM image?</strong></p>
<p>Modelwrap allows us to achieve the same result but with added flexibility!
Much of the VM image contains infrastructure for booting the enclave and
serving data which is common across different models. Using Modelwrap, we
can take a more modular approach by maintaining a single VM image for the
infrastructure stack and plugging in many different models.</p>
<p>Additionally, beyond creating the disk image, Modelwrap reproducibly
packages weights and configurations such that public models can be independently
verified.</p>
<p><strong>Why not just sign the model files?</strong></p>
<p>Tools like <a href="https://github.com/sigstore/model-transparency">Sigstore Model Transparency</a>
let you cryptographically sign model weights and verify the signature after
downloading. While this is useful for proving authenticity at the moment the
data is checked, signature verification does not protect the data while it
is in use.</p>
<p>Tinfoil adopts a stronger threat model where a malicious hypervisor can tamper
with the disk contents after the signature is verified. Modelwrap&#39;s approach
with dm-verity checks the data&#39;s integrity as it is loaded into the enclave
by verifying every read operation.</p>
<h2>Performance</h2>
<p>How much does verification cost? We benchmarked Modelwrap on three models
ranging from 549 MB to 554 GB.</p>
<p><strong>Storage overhead</strong> is minimal: the <code>dm-verity</code> hash tree adds about 0.8% to
the image size regardless of model (in our benchmarks). dm-verity computes a
Merkle hash tree of arity 128, creating little variance in storage overhead
across realistic model sizes.</p>
<p><strong>Build time</strong> scales with model size. Most of the time is spent writing the
EROFS image and computing hashes. We note that this is a one-time cost.</p>
<table><thead><tr><th>Model</th><th>Size</th><th>Build time</th></tr></thead><tbody><tr><td>Gemma 3 270M</td><td>549 MB</td><td>5s</td></tr><tr><td>GPT-OSS-120B</td><td>183 GB</td><td>4m 5s</td></tr><tr><td>Kimi K2</td><td>554 GB</td><td>13m 25s</td></tr></tbody></table>
<p><strong>Model loading overhead</strong> is what matters at runtime. We measured cold-cache
reads of all model files—the worst case, where every block hits disk and
gets verified:</p>
<p><img src="https://tinfoil.sh/blog-images/2026-02-03-modelwrap-performance.svg" alt="Modelwrap Performance"/></p>
<p>On fast NVMe, cold-cache loading takes ~80% longer with verification—but this
only affects initial model loading (typically once at server start). Once the
model is loaded into GPU memory, dm-verity is out of the path and inference
runs at full speed. Linux 6.19 also includes
<a href="https://www.phoronix.com/news/Linux-6.19-dm-verity-Perf">dm-verity optimizations</a>
that provide a roughly 35% improvement in cold-cache reads which we are
planning to leverage soon.</p>
<h2>Try It Yourself</h2>
<p>Modelwrap is open source: <a href="https://github.com/tinfoilsh/modelwrap">github.com/tinfoilsh/modelwrap</a>.</p>
<!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$-->
<p>The root hash in the <code>.info</code> file is your cryptographic commitment to exactly
which model runs in your Tinfoil enclave. This maps to the same commitment
in the corresponding Tinfoil model config file, so you can be sure you&#39;re
talking to the right model. You can use this to verify a Tinfoil deployment,
or to generate a commitment for private weights to use in your own enclave.</p></article></div></div></div></div>
  </body>
</html>
