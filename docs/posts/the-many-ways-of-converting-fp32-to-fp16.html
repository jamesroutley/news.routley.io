<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.corsix.org/content/converting-fp32-to-fp16">Original</a>
    <h1>The many ways of converting FP32 to FP16</h1>
    
    <div id="readability-page-1" class="page"><div>

<div>
<p data-sourcepos="1:1-1:149">An IEEE 754 <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">single-precision</a> 32-bit binary float (henceforth FP32) can store:</p>
<ul data-sourcepos="2:3-7:0">
<li data-sourcepos="2:3-4:156"><code>(-1)<sup>s</sup> × 2<sup>e</sup> × m<sub>0</sub>.m<sub>1</sub>m<sub>2</sub>m<sub>3</sub>m<sub>4</sub>m<sub>5</sub>m<sub>6</sub>m<sub>7</sub>m<sub>8</sub>m<sub>9</sub>m<sub>10</sub>m<sub>11</sub>m<sub>12</sub>⋯m<sub>21</sub>m<sub>22</sub>m<sub>23</sub></code> with either:
<ul data-sourcepos="3:5-4:156">
<li data-sourcepos="3:5-3:156"><code>m<sub>0</sub> = 1</code>, other <code>m<sub>i</sub></code> either <code>0</code> or <code>1</code>, and <code>-126 ≤ e ≤ 127</code> (normalised)</li>
<li data-sourcepos="4:5-4:156"><code>m<sub>0</sub> = 0</code>, other <code>m<sub>i</sub></code> either <code>0</code> or <code>1</code>, and <code>-126 = e</code> (denormal or zero)</li>
</ul>
</li>
<li data-sourcepos="5:3-5:50"><code>(-1)<sup>s</sup> × ∞</code> (± infinity)</li>
<li data-sourcepos="6:3-7:0">NaN (with a sign bit, and 23 bits of almost-arbitrary payload)</li>
</ul>
<p data-sourcepos="8:1-8:145">An IEEE 754 <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">half-precision</a> 16-bit binary float (henceforth FP16) can store:</p>
<ul data-sourcepos="9:3-14:0">
<li data-sourcepos="9:3-11:155"><code>(-1)<sup>s</sup> × 2<sup>e</sup> × m<sub>0</sub>.m<sub>1</sub>m<sub>2</sub>m<sub>3</sub>m<sub>4</sub>m<sub>5</sub>m<sub>6</sub>m<sub>7</sub>m<sub>8</sub>m<sub>9</sub>m<sub>10</sub></code> with either:
<ul data-sourcepos="10:5-11:155">
<li data-sourcepos="10:5-10:154"><code>m<sub>0</sub> = 1</code>, other <code>m<sub>i</sub></code> either <code>0</code> or <code>1</code>, and <code>-14 ≤ e ≤ 15</code> (normalised)</li>
<li data-sourcepos="11:5-11:155"><code>m<sub>0</sub> = 0</code>, other <code>m<sub>i</sub></code> either <code>0</code> or <code>1</code>, and <code>-14 = e</code> (denormal or zero)</li>
</ul>
</li>
<li data-sourcepos="12:3-12:50"><code>(-1)<sup>s</sup> × ∞</code> (± infinity)</li>
<li data-sourcepos="13:3-14:0">NaN (with a sign bit, and 10 bits of almost-arbitrary payload)</li>
</ul>
<p data-sourcepos="15:1-15:536">Converting from FP32 to FP16 thus involves getting rid of <code>m<sub>11</sub></code> through <code>m<sub>23</sub></code>, and dealing with the reduced range of <code>e</code>. If <code>e</code> starts in the range <code>-14 ≤ e ≤ 15</code> and <code>m<sub>11</sub></code> through <code>m<sub>23</sub></code> are all <code>0</code>, then this conversion is trivial. If <em>any</em> of <code>m<sub>11</sub></code> through <code>m<sub>23</sub></code> are <code>1</code> then a rounding decision has to be made, typical options for which include:</p>
<ul data-sourcepos="16:3-20:0">
<li data-sourcepos="16:3-16:107">Round toward zero (i.e. discard all of <code>m<sub>11</sub></code> through <code>m<sub>23</sub></code>)</li>
<li data-sourcepos="17:3-17:78">Round toward +∞ or toward -∞ (i.e. add one or not based on <code>s</code>)</li>
<li data-sourcepos="18:3-18:109">Round to nearest with ties away from zero (i.e. add one if <code>m<sub>11</sub></code> is <code>1</code>)</li>
<li data-sourcepos="19:3-20:0">Round to nearest with ties toward even (i.e. add one if <code>m<sub>11</sub></code> is <code>1</code> and at least one other of <code>m<sub>10</sub></code> through <code>m<sub>23</sub></code> is <code>1</code>)</li>
</ul>
<p data-sourcepos="21:1-21:597">If <code>e</code> starts in the range <code>e &lt; -14</code> (i.e. underflow), then the resultant FP16 has to end up with <code>e = -14</code>, as it cannot go any smaller. Some number of <code>m<sub>i</sub></code> will be discarded, and so a rounding decision again has to be made. A fun bonus decision crops up when rounding toward ±∞ and the starting FP32 is denormal: should denormals be treated as zero? (for other rounding modes, denormal inputs will naturally round to zero) Regardless of rounding mode, if the resultant FP16 is denormal, then there&#39;s the decision of whether to flush to zero.</p>
<p data-sourcepos="23:1-23:142">If <code>e</code> starts in the range <code>15 &lt; e</code> (i.e. overflow), then there&#39;s no particularly great FP16 to convert to, with the options being:</p>
<ul data-sourcepos="24:3-27:0">
<li data-sourcepos="24:3-24:39">Infinity (with an appropriate sign)</li>
<li data-sourcepos="25:3-25:94"><code>e = 15</code>, all <code>m<sub>i</sub> = 1</code> (i.e. a value of +65504 or -65504)</li>
<li data-sourcepos="26:3-27:0">Throw an exception</li>
</ul>
<p data-sourcepos="28:1-28:163">Choosing between infinity and 65504 is yet again a rounding decision, with the <em>unintuitive</em> quirk that 65520 is considered to be nearer to infinity than to 65504.</p>
<p data-sourcepos="30:1-30:281">If the starting FP32 is NaN, then there&#39;s choice about what to do with the sign bit (either preserve it, or force it to a particular value), and again a choice about what to do with the payload bits (either preserve <em>some</em> of them, or force them to a particular canonical pattern).</p>
<p data-sourcepos="32:1-32:299">All said, there are clearly lots of decision points in the conversion process, so it is no surprise that different implementations make different choices. We&#39;ll look at a bunch of software and hardware implementations, and the choices that they make (as they don&#39;t always advertise their decisions).</p>
<p data-sourcepos="34:1-34:61">The summary of implementations and most important choices is:</p>
<table><tbody><tr><th>Implementation</th><th>Rounding</th><th>NaNs</th></tr>
<tr><td><a href="https://github.com/numpy/numpy/blob/13a5c4e569269aa4da6784e2ba83107b53f73bc9/numpy/core/src/npymath/halffloat.c#L244-L365">numpy</a></td><td>Toward nearest, ties toward even</td><td>Preserve (1)</td></tr>
<tr><td><a href="https://github.com/python/cpython/blob/5f7d68e48de19c5c3a241d7126fc2af227c2f74a/Objects/floatobject.c#L2071-L2173">CPython</a></td><td>Toward nearest, ties toward even (†)</td><td>±Canonical</td></tr>
<tr><td><a href="https://github.com/nomovok-opensource/wrath/blob/3a8d8ee92f845ed96e95b3736a2a9deef4ac5e4c/src/3rd_party/ieeehalfprecision/ieeehalfprecision.c#L118-L156">James Tursa</a> (<a href="https://uk.mathworks.com/matlabcentral/fileexchange/23173-ieee-754r-half-precision-floating-point-converter">Matlab</a>)</td><td>Toward nearest, ties away from zero</td><td>-Canonical</td></tr>
<tr><td><a href="https://gist.github.com/rygorous/2156668">Fabian &#34;ryg&#34; Giesen</a></td><td>Toward nearest, details vary</td><td>±Canonical</td></tr>
<tr><td><a href="https://github.com/Maratyszcza/FP16/blob/0a92994d729ff76a58f692d3028ca1b64b145d91/include/fp16/fp16.h#L223-L247">Maratyszcza</a></td><td>Toward nearest, ties toward even</td><td>±Canonical</td></tr>
<tr><td><a href="https://www.felixcloutier.com/x86/vcvtps2ph">VCVTPS2PH</a> (x86)</td><td>Configurable</td><td>Preserve (2)</td></tr>
<tr><td>FCVT / FCVTN (ARM)</td><td>Configurable</td><td>Configurable</td></tr>
</tbody></table><p>
(†) Except that overflows throw an exception</p></div>
</div></div>
  </body>
</html>
