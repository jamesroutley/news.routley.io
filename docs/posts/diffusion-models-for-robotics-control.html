<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://diffusion-policy.cs.columbia.edu/">Original</a>
    <h1>Diffusion Models for Robotics Control</h1>
    
    <div id="readability-page-1" class="page"><div id="main">
					<section id="four">
						

						
						

						<span>
							<img src="https://diffusion-policy.cs.columbia.edu/images/teaser.svg" alt=""/>
						</span>

						<p> 
						This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot&#39;s visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 12 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9%. Diffusion Policy learns the gradient of the action-distribution score function and iteratively optimizes with respect to this gradient field during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models.
						</p>

						<hr/>
						<h3>Highlights</h3>
						<div>
							<div>
								<p><span>
										<img src="https://diffusion-policy.cs.columbia.edu/images/multimodal_sim.svg" alt=""/>
									</span>
									Diffusion Policy learns multi-modal behavior and commits to only one mode within each rollout.
									<a href="https://robomimic.github.io/">LSTM-GMM</a> 
									and 
									<a href="https://implicitbc.github.io/">IBC</a> 
									are biased toward one mode, while 
									<a href="https://mahis.life/bet/">BET</a>
									failed to commit.
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/highlight_pusht_process.mp4" type="video/mp4"/> </video>
									</span>
									Diffusion Policy predicts a sequence of action for receding-horizon control.
								</p>
							</div>
							<div>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/highlight_mug.mp4" type="video/mp4"/> </video>
									</span>
									The <a href="#mug">Mug Flipping</a> task requires the policy to predict smooth 6 DoF actions while operating close to kinetmatic limits.
								</p>
								
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/highlight_pusht.mp4" type="video/mp4"/> </video>
									</span>
									In our <a href="#pusht">Push-T</a> experiments, Diffusion Policy is highly robust against purturbations and visual distractions.
								</p>
							</div>
						</div>
						<hr/>

						<h3>Simulation Benchmarks</h3>

						<p>
						Diffusion Policy outperforms prior state-of-the-art on 12 tasks across 4 benchmarks with an average success-rate improvement of 46.9%. 
						Check out our <a href="#paper">paper</a> for further details!
						</p>
						<div>
							<div>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/lift.mp4" type="video/mp4"/> </video>
									</span>
									Lift <sup>1</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/can.mp4" type="video/mp4"/> </video>
									</span>
									Can <sup>1</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/square.mp4" type="video/mp4"/> </video>
									</span>
									Square <sup>1</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/tool_hang.mp4" type="video/mp4"/> </video>
									</span>
									Tool Hang <sup>1</sup>
								</p>
							</div>
							<div>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/transport.mp4" type="video/mp4"/> </video>
									</span>
									Transport <sup>1</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/pusht.mp4" type="video/mp4"/> </video>
									</span>
									Push-T <sup>2</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/block_push.mp4" type="video/mp4"/> </video>
									</span>
									Block Pushing <sup>2,3</sup>
								</p>
								<p><span>
										<video autoplay="" loop="" muted="" playsinline=""><source src="videos/kitchen.mp4" type="video/mp4"/> </video>
									</span>
									Franka Kitchen <sup>3,4</sup>
								</p>
							</div>
						</div>

						<p>
						Standarized simulation benchmarks are essential for this project&#39;s development.
						</p>
						
						<hr/>

						<h3><a id="paper">Paper</a></h3>

						<p>
							Latest version: <a href="https://arxiv.org/abs/2303.04137">arXiv:2303.04137 [cs.RO]</a> or <a href="https://diffusion-policy.cs.columbia.edu/diffusion_policy_2023.pdf">here</a>.
							<!-- 
							<font color="4e79a7">★ Best Paper Award, RSS ★</font>
							<br>
							<font color="4e79a7">★ Best Student Paper Award Finalist, RSS★ </font> -->
						</p>

						<p><a href="https://diffusion-policy.cs.columbia.edu/diffusion_policy_2023.pdf">
								<span>
									<img src="https://diffusion-policy.cs.columbia.edu/images/paper_thumbnail.png" alt=""/>
								</span>
							</a>
						</p>

						<hr/>
						<h3>Code and Data</h3>
						
						
						<hr/>

						<h3>Team</h3>

						<section>
							
						</section>
						<sup>1</sup> Columbia University             
						<sup>2</sup> Toyota Research Institute             
						<sup>3</sup> MIT
						<div>
							<div>
<h3>Bibtex</h3>
<pre><code>@inproceedings{chi2023diffusionpolicy,
	title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
	booktitle={Proceedings of Robotics: Science and Systems (RSS)},
	year={2023}
}</code>
</pre>
							</div>
						</div>

						<!-- <hr style="margin-top: 1em"> -->
						<!-- <div class="row">
							<div class="12u$ 12u$(xsmall)" style="text-align: center;">
								<h3>Technical Summary Video (with audio)</h3>
								<iframe width="640" height="360" src="https://www.youtube.com/embed/WLH3Cr_HL-c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
							</div>
						</div> -->

						<hr/>

						<h3><a id="pusht">Real World Push-T Task</a></h3>
						<p>
						In this task, the robot needs to 
						</p>

						<div>
							<div>
								<p>
									Diffusion Policy End-to-end
									<span>
										<img src="https://diffusion-policy.cs.columbia.edu/images/pusht_ep6_overlay_diffusion.png" alt=""/>
									</span>
									<span>
										<video controls="" autoplay="" loop="" muted="" playsinline=""><source src="videos/pusht_ep6_diffusion.mp4" type="video/mp4"/> </video>
									</span>
									Success.
								</p>
								<p>
									Diffusion Policy R3M
									<span>
										<img src="https://diffusion-policy.cs.columbia.edu/images/pusht_ep6_overlay_r3m.png" alt=""/>
									</span>
									<span>
										<video controls="" autoplay="" loop="" muted="" playsinline=""><source src="videos/pusht_ep6_r3m.mp4" type="video/mp4"/> </video>
									</span>
									Success after stuck near the T block initially.
								</p>
								<p>
									LSTM-GMM End-to-end
									<span>
										<img src="https://diffusion-policy.cs.columbia.edu/images/pusht_ep6_overlay_bcrnn.png" alt=""/>
									</span>
									<span>
										<video controls="" autoplay="" loop="" muted="" playsinline=""><source src="videos/pusht_ep6_bcrnn.mp4" type="video/mp4"/> </video>
									</span>
									Common failure mode: stuck near the T block.
								</p>
								<p>
									IBC End-to-end
									<span>
										<img src="https://diffusion-policy.cs.columbia.edu/images/pusht_ep6_overlay_ibc.png" alt=""/>
									</span>
									<span>
										<video controls="" autoplay="" loop="" muted="" playsinline=""><source src="videos/pusht_ep6_ibc.mp4" type="video/mp4"/> </video>
									</span>
									Common failure mode: entering the end-zone repmaturely.
								</p>
							</div>
						</div>

						<a href="https://diffusion-policy.cs.columbia.edu/pusht_results.html">
							Click to see all Push-T results.
							<video autoplay="" loop="" muted="" playsinline=""><source src="videos/all_pusht_wide_web.mp4" type="video/mp4"/> </video>
						</a>

						<div><p>
							Diffusion Policy remains robust against:
							</p></div>
						
						<hr/>

						<h3><a id="mug">Real World Mug Flipping Task</a></h3>
						<p>
						In this task, the robot needs to 
						</p>
						<video controls="" muted="" preload="metadata"><source src="videos/mug_flipping_20_web.mp4" type="video/mp4"/> </video>
						<div>
							<div>
								<p><span>
										<video controls="" muted="" preload="metadata"><source src="videos/mug_hard_diffusion_video_wall_web.mp4" type="video/mp4"/> </video>
									</span>
									Diffusion Policy
								</p>
								<p><span>
										<video controls="" muted="" preload="metadata"><source src="videos/mug_hard_bcrnn_video_wall_web.mp4" type="video/mp4"/> </video>
									</span>
									LSTM-GMM
								</p>
							</div>
						</div>
						<hr/>

						<h3><a id="sauce">Realworld Sauce Pouring and Spreading Task</a></h3>
						<p>
						In the sauce pouring task, the robot needs to:
						① Dip the ladle to scoop sauce from the bowl, ② approach the center of the pizza dough, ③ pour sauce, and ④ lift the ladle to finish the task.
						</p>

						<video controls="" muted="" preload="metadata"><source src="videos/sauce_pour_spread_web.mp4" type="video/mp4"/> </video>
						<div>
							<div>
								<p><span>
										<video controls="" muted="" preload="metadata"><source src="videos/pour_diffusion_video_wall.mp4" type="video/mp4"/> </video>
									</span>
									<span>
										<video controls="" muted="" preload="metadata"><source src="videos/spread_diffusion_video_wall.mp4" type="video/mp4"/> </video>
									</span>
									Diffusion Policy
								</p>
								<p><span>
										<video controls="" muted="" preload="metadata"><source src="videos/pour_bcrnn_video_wall.mp4" type="video/mp4"/> </video>
									</span>
									<span>
										<video controls="" muted="" preload="metadata"><source src="videos/spread_bcrnn_video_wall.mp4" type="video/mp4"/> </video>
									</span>
									LSTM-GMM
								</p>
							</div>
						</div>

						<hr/>

				        <h3>Acknowledgements</h3>
				        <p> 
						This work was supported in part by  NSF Awards 2037101, 2132519, 2037101, and Toyota Research Institute. We would like to thank Google for the UR5 robot hardware. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the sponsors.
						</p>

						<hr/>
				        <h3>Contact</h3>
				        <p>If you have any questions, please feel free to contact <a href="http://cheng-chi.github.io/">Cheng Chi</a></p>
						<hr/>
					</section>
			</div></div>
  </body>
</html>
