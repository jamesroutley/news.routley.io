<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/adaline/gateway">Original</a>
    <h1>Local TypeScript Super SDK to Call 200 LLMs</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="https://npmjs.com/package/@adaline/gateway" rel="nofollow"><img src="https://camo.githubusercontent.com/9899091cdc1d4cc9f0a2b2c24ef547e2fe56c8dd01128d78ca78d870d35b7385/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f406164616c696e652f67617465776179" alt="npm" data-canonical-src="https://img.shields.io/npm/v/@adaline/gateway"/></a>
<a href="https://npmjs.com/package/@adaline/gateway" rel="nofollow"><img src="https://camo.githubusercontent.com/21c3f14ebc0d2e730ff2492627ad58869c48a704e5f95d73dc02982702e349b1/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f406164616c696e652f67617465776179" alt="npm" data-canonical-src="https://img.shields.io/npm/dm/@adaline/gateway"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b3637012f89d56c4614b9ce662ccd917ee2175727021b1c3b524854039fee486/68747470733a2f2f696d672e736869656c64732e696f2f62756e646c6570686f6269612f6d696e7a69702f406164616c696e652f67617465776179"><img src="https://camo.githubusercontent.com/b3637012f89d56c4614b9ce662ccd917ee2175727021b1c3b524854039fee486/68747470733a2f2f696d672e736869656c64732e696f2f62756e646c6570686f6269612f6d696e7a69702f406164616c696e652f67617465776179" alt="npm bundle size" data-canonical-src="https://img.shields.io/bundlephobia/minzip/@adaline/gateway"/></a>
<a href="https://github.com/adaline/gateway/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/6b8b645aa0622fce4b2de658a06950de8b3b1af4e0ecea561582a02ffd59b7fe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f496c65726961796f2f6d61726b646f776e2d626164676573" alt="License" data-canonical-src="https://img.shields.io/github/license/Ileriayo/markdown-badges"/></a></p>
<p dir="auto">The only fully local production-grade Super SDK that provides a simple, unified, and powerful interface for calling more than 200+ LLMs.</p>
<ul dir="auto">
<li>Production-ready and used by enterprises.</li>
<li>Fully local and <em>NOT</em> a proxy. You can deploy it anywhere.</li>
<li>Comes with batching, retries, caching, callbacks, and OpenTelemetry support.</li>
<li>Supports custom plugins for caching, logging, HTTP client, and more. You can use it like LEGOs and make it work with your infrastructure.</li>
<li>Supports plug-and-play providers. You can run fully custom providers and still leverage all the benefits of Adaline Gateway.</li>
</ul>

<ul dir="auto">
<li>üîß Strongly typed in TypeScript</li>
<li>üì¶ Isomorphic - works everywhere</li>
<li>üîí 100% local and private and <em>NOT</em> a proxy</li>
<li>üõ†Ô∏è Tool calling support across all compatible LLMs</li>
<li>üìä Batching for all requests with custom queue support</li>
<li>üîÑ Automatic retries with exponential backoff</li>
<li>‚è≥ Caching with custom cache plug-in support</li>
<li>üìû Callbacks for full custom instrumentation and hooks</li>
<li>üîç OpenTelemetry to plug tracing into your existing infrastructure</li>
<li>üîå Plug-and-play custom providers for local and custom models</li>
</ul>


<div dir="auto" data-snippet-clipboard-copy-content="npm install @adaline/gateway @adaline/types @adaline/openai @adaline/anthropic"><pre>npm install @adaline/gateway @adaline/types @adaline/openai @adaline/anthropic</pre></div>

<p dir="auto">Gateway object maintains the queue, cache, callbacks, implements OpenTelemetry, etc. You should use the same Gateway object everywhere to get the benefits of all the features.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Gateway } from &#34;@adaline/gateway&#34;;

const gateway = new Gateway();"><pre><span>import</span> <span>{</span> <span>Gateway</span> <span>}</span> <span>from</span> <span>&#34;@adaline/gateway&#34;</span><span>;</span>

<span>const</span> <span>gateway</span> <span>=</span> <span>new</span> <span>Gateway</span><span>(</span><span>)</span><span>;</span></pre></div>

<p dir="auto">Provider object stores the types/information about all the models within that provider. It exposes the list of all the chat <code>openai.chatModelLiterals()</code> and embedding <code>openai.embeddingModelLiterals()</code> models.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Anthropic } from &#34;@adaline/anthropic&#34;;
import { OpenAI } from &#34;@adaline/openai&#34;;

const openai = new OpenAI();
const anthropic = new Anthropic();"><pre><span>import</span> <span>{</span> <span>Anthropic</span> <span>}</span> <span>from</span> <span>&#34;@adaline/anthropic&#34;</span><span>;</span>
<span>import</span> <span>{</span> <span>OpenAI</span> <span>}</span> <span>from</span> <span>&#34;@adaline/openai&#34;</span><span>;</span>

<span>const</span> <span>openai</span> <span>=</span> <span>new</span> <span>OpenAI</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>anthropic</span> <span>=</span> <span>new</span> <span>Anthropic</span><span>(</span><span>)</span><span>;</span></pre></div>

<p dir="auto">Model object enforces the types from roles, to config, to different modalities that are supported by that model. You can also provide other keys like <code>baseUrl</code>, <code>organization</code>, etc.</p>
<p dir="auto">Model object also exposes functions:</p>
<ul dir="auto">
<li><code>transformModelRequest</code> that takes a request formatted for the provider and converts it into the Adaline super-types.</li>
<li><code>getStreamChatData</code> that is then used to compose other provider calls. For example, calling an Anthropic model from Bedrock.</li>
<li>and many more to enable deep composability and provide runtime validations.</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="const gpt4o = openai.chatModel({
  modelName: &#34;gpt-4o&#34;,
  apiKey: &#34;your-api-key&#34;,
});

const haiku = anthropic.chatModel({
  modelName: &#34;claude-3-haiku-20240307&#34;,
  apiKey: &#34;your-api-key&#34;,
});"><pre><span>const</span> <span>gpt4o</span> <span>=</span> <span>openai</span><span>.</span><span>chatModel</span><span>(</span><span>{</span>
  <span>modelName</span>: <span>&#34;gpt-4o&#34;</span><span>,</span>
  <span>apiKey</span>: <span>&#34;your-api-key&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>const</span> <span>haiku</span> <span>=</span> <span>anthropic</span><span>.</span><span>chatModel</span><span>(</span><span>{</span>
  <span>modelName</span>: <span>&#34;claude-3-haiku-20240307&#34;</span><span>,</span>
  <span>apiKey</span>: <span>&#34;your-api-key&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>

<p dir="auto">Config object provides type checks and also accepts generics that can be used to add max, min, and other validation checks per model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Config } from &#34;@adaline/types&#34;;

const config = Config().parse({
  maxTokens: 200,
  temperature: 0.9,
});"><pre><span>import</span> <span>{</span> <span>Config</span> <span>}</span> <span>from</span> <span>&#34;@adaline/types&#34;</span><span>;</span>

<span>const</span> <span>config</span> <span>=</span> <span>Config</span><span>(</span><span>)</span><span>.</span><span>parse</span><span>(</span><span>{</span>
  <span>maxTokens</span>: <span>200</span><span>,</span>
  <span>temperature</span>: <span>0.9</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Create the messages object</h3><a id="user-content-create-the-messages-object" aria-label="Permalink: Create the messages object" href="#create-the-messages-object"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Message object is the Adaline super-type that supports all the roles and modalities across 200+ LLMs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { MessageType } from &#34;@adaline/types&#34;;

const messages: MessageType[] = [
  {
    role: &#34;system&#34;,
    content: [{
      modality: &#34;text&#34;,
      value: &#34;You are a helpful assistant. You are extremely concise.
    }],
  },
  {
    role: &#34;user&#34;,
    content: [{
      modality: &#34;text&#34;,
      value: `What is ${Math.floor(Math.random() * 100) + 1} + ${Math.floor(Math.random() * 100) + 1}?`,
    }],
  },
];"><pre><span>import</span> <span>{</span> <span>MessageType</span> <span>}</span> <span>from</span> <span>&#34;@adaline/types&#34;</span><span>;</span>

<span>const</span> <span>messages</span>: <span>MessageType</span><span>[</span><span>]</span> <span>=</span> <span>[</span>
  <span>{</span>
    <span>role</span>: <span>&#34;system&#34;</span><span>,</span>
    <span>content</span>: <span>[</span><span>{</span>
      <span>modality</span>: <span>&#34;text&#34;</span><span>,</span>
      <span>value</span>: <span>&#34;You are a helpful assistant. You are extremely concise.</span>
<span>    }],</span>
<span>  },</span>
<span>  {</span>
<span>    role: &#34;</span><span>user</span>&#34;<span>,</span>
    <span>content</span>: <span>[</span><span>{</span>
      <span>modality</span>: <span>&#34;text&#34;</span><span>,</span>
      <span>value</span>: <span>`What is <span><span>${</span><span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>*</span> <span>100</span><span>)</span> <span>+</span> <span>1</span><span>}</span></span> + <span><span>${</span><span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>*</span> <span>100</span><span>)</span> <span>+</span> <span>1</span><span>}</span></span>?`</span><span>,</span>
    <span>}</span><span>]</span><span>,</span>
  <span>}</span><span>,</span>
<span>]</span><span>;</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Stream chat using Gateway</h3><a id="user-content-stream-chat-using-gateway" aria-label="Permalink: Stream chat using Gateway" href="#stream-chat-using-gateway"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="await gateway.streamChat({
  model: gpt4o,
  config: config,
  messages: messages,
});"><pre><span>await</span> <span>gateway</span><span>.</span><span>streamChat</span><span>(</span><span>{</span>
  <span>model</span>: <span>gpt4o</span><span>,</span>
  <span>config</span>: <span>config</span><span>,</span>
  <span>messages</span>: <span>messages</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Complete chat using Gateway</h3><a id="user-content-complete-chat-using-gateway" aria-label="Permalink: Complete chat using Gateway" href="#complete-chat-using-gateway"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="await gateway.completeChat({
  model: haiku,
  config: config,
  messages: messages,
});"><pre><span>await</span> <span>gateway</span><span>.</span><span>completeChat</span><span>(</span><span>{</span>
  <span>model</span>: <span>haiku</span><span>,</span>
  <span>config</span>: <span>config</span><span>,</span>
  <span>messages</span>: <span>messages</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</article></div></div>
  </body>
</html>
