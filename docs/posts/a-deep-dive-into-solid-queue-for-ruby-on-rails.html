<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.appsignal.com/2025/06/18/a-deep-dive-into-solid-queue-for-ruby-on-rails.html">Original</a>
    <h1>A Deep Dive into Solid Queue for Ruby on Rails</h1>
    
    <div id="readability-page-1" class="page"><div><p>Our previous article in this series established that Solid Queue is an excellent choice if you need a system for processing background jobs. It minimizes external dependencies — no need for Redis! — by storing all jobs in your database. Despite that, it is incredibly performant.</p>
<p>But just being performant is not enough for a production-ready background job system. Rails developers have come to expect a lot over the years. We don&#39;t just want to enqueue jobs to run in the background. We want to schedule jobs, run them on a recurring schedule, and we might even want to limit how many jobs can run concurrently. We want more features!</p>
<p>Amazingly, Solid Queue provides all of those features out of the box. Let&#39;s dive deeper into Solid Queue and learn how that&#39;s possible!</p>
<h2 id="scheduling-jobs-with-solid-queue-for-ruby-on-rails">Scheduling Jobs with Solid Queue for Ruby on Rails</h2>
<p>First, it&#39;s time for a small recap. Solid Queue uses your database — and only your database — to store job data. Everything it does is backed by one database table or another. Scheduling jobs — that is, designating jobs to run at some specific point in the future — is no different. Any scheduled job is stored in <code>solid_queue_scheduled_executions</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/generators/solid_queue/install/templates/db/queue_schema.rb
create_table &#34;solid_queue_scheduled_executions&#34;, force: :cascade do |t|
  t.bigint &#34;job_id&#34;, null: false
  t.string &#34;queue_name&#34;, null: false
  t.integer &#34;priority&#34;, default: 0, null: false
  t.datetime &#34;scheduled_at&#34;, null: false
  t.datetime &#34;created_at&#34;, null: false
  t.index [ &#34;job_id&#34; ], name: &#34;index_solid_queue_scheduled_executions_on_job_id&#34;, unique: true
  t.index [ &#34;scheduled_at&#34;, &#34;priority&#34;, &#34;job_id&#34; ], name: &#34;index_solid_queue_dispatch_all&#34;
end
"></pre></div></figure>
<p>This table is almost identical to the <code>solid_queue_ready_executions</code> table. The only difference is the addition of the <code>scheduled_at</code> column, which tells us when a scheduled job is supposed to be executed. Let&#39;s confirm that by looking at what happens when we schedule a job.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="MyJob.set(wait_until: Date.tomorrow.noon).perform_later
"></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="sql" data-theme="github-dark" data-raw="INSERT
  INTO &#34;solid_queue_scheduled_executions&#34; (&#34;job_id&#34;, &#34;queue_name&#34;, &#34;priority&#34;, &#34;scheduled_at&#34;, &#34;created_at&#34;)
  VALUES (1, &#39;default&#39;, 0, &#39;2025-04-02 12:00:00.000000&#39;, &#39;2025-04-01 12:00:00.000000&#39;)
  RETURNING &#34;id&#34;
"></pre></div></figure>
<p>There are no surprises there. Solid Queue adds a new row to the <code>solid_queue_scheduled_executions</code> table, which contains the data that we&#39;d expect. But how do we go from such a record existing to actually running a job at the right time?</p>
<p>We need a process that continuously polls the <code>solid_queue_scheduled_executions</code> table. That process is called the Dispatcher, and it is responsible for executing scheduled jobs on time. It begins when Solid Queue starts — no additional configuration is required. However, if needed you can start only the dispatcher process by running Solid Queue with a specific configuration.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="yaml" data-theme="github-dark" data-raw="# Start Solid Queue with this configuration, for example, with bin/jobs -c config/only_dispatcher.yml
production:
  dispatchers:
    - polling_interval: 1
      batch_size: 500
      concurrency_maintenance_interval: 300
"></pre></div></figure>
<p>In case you were wondering how the Dispatcher process is supervised, that is the responsibility of the aptly named <code>Supervisor</code>. It keeps track of any running processes within Solid Queue, including worker processes and Dispatchers.</p>
<p>So, how does the Dispatcher actually work? It defines a <code>poll</code> method called within a loop to continuously check for scheduled jobs. The polling code is spread over several classes and modules, but in a heavily simplified form, it looks like this:</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/solid_queue/dispatcher.rb
class Dispatcher &lt; Processes::Poller
  # Batch size and polling interval are based on your configuration
  def poll
    job_ids = ScheduledExecution.due.ordered.limit(batch_size).pluck(:job_id)
    jobs = Job.where(id: job_ids)
    Job.dispatch_all(jobs).map(&amp;:id).then do |dispatched_job_ids|
      ScheduledExecution.where(job_id: dispatched_job_ids).delete_all
    end
  end
end
"></pre></div></figure>
<p>The query to retrieve &#39;ready&#39; scheduled executions is straightforward.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="sql" data-theme="github-dark" data-raw="SELECT &#34;solid_queue_scheduled_executions&#34;.*
  FROM &#34;solid_queue_scheduled_executions&#34;
  WHERE &#34;solid_queue_scheduled_executions&#34;.&#34;scheduled_at&#34; &lt;= &#39;2025-04-02 12:00:01.000000&#39;
  ORDER BY &#34;solid_queue_scheduled_executions&#34;.&#34;scheduled_at&#34; ASC,
    &#34;solid_queue_scheduled_executions&#34;.&#34;priority&#34; ASC,
    &#34;solid_queue_scheduled_executions&#34;.&#34;job_id&#34; ASC
  LIMIT 500
"></pre></div></figure>
<p>So, any scheduled job with <code>scheduled_at</code> in the past is ready to be dispatched. As we covered in part one of this series, when Solid Queue dispatches a job, it creates a <code>ReadyExecution</code> record and destroys the corresponding <code>ScheduledExecution</code> record. The <code>ReadyExecution</code> record is then picked up by regular worker processes, and the corresponding job runs.</p>
<p>So far, so good. Scheduled jobs are really not that complicated! Let&#39;s look at something more complex: recurring tasks.</p>
<h2 id="recurring-tasks">Recurring Tasks</h2>
<p>Recurring tasks are an oft-requested feature for background job processors. Simply put, they are background jobs that should run on a recurring schedule. They are similar to <a href="https://en.wikipedia.org/wiki/Cron">Cron jobs</a> in that you define a schedule (such as every five minutes, every day at noon, and so on) for when work should occur.</p>
<p>In Solid Queue, you configure your recurring jobs using the <code>config/recurring.yml</code> file. For example, if we wanted to run a <code>CleanupData</code> job every day at noon, this is how we would do it.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="yaml" data-theme="github-dark" data-raw="production:
  cleanup_data:
    class: CleanupData
    args: []
    schedule: every day at noon
"></pre></div></figure>

<p>Solid Queue uses <a href="https://github.com/floraison/fugit">Fugit</a> to parse schedule expressions, which is why human-readable schedules such as &#39;every day at noon&#39; are permitted. When using scheduled tasks, you define the class of the job to be run and any job arguments. The excellent <a href="https://github.com/rails/solid_queue?tab=readme-ov-file#recurring-tasks">SolidQueue recurring tasks ReadMe</a> provides more details. We&#39;re here to learn how it works, so let&#39;s look under the hood.</p>
<p>Recurring tasks are represented by the <code>RecurringTask</code> model, which is backed by a corresponding <code>solid_queue_recurring_tasks</code> table. The columns therein correspond to the fields available in the configuration file.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/generators/solid_queue/install/templates/db/queue_schema.rb
create_table &#34;solid_queue_recurring_tasks&#34;, force: :cascade do |t|
  t.string &#34;key&#34;, null: false
  t.string &#34;schedule&#34;, null: false
  t.string &#34;command&#34;, limit: 2048
  t.string &#34;class_name&#34;
  t.text &#34;arguments&#34;
  t.string &#34;queue_name&#34;
  t.integer &#34;priority&#34;, default: 0
  t.boolean &#34;static&#34;, default: true, null: false
  t.text &#34;description&#34;
# ...
end
"></pre></div></figure>
<p>When you start SolidQueue, recurring task records are created according to your recurring tasks configuration file. To create jobs at the right time, we once again need a new process — this time called the Scheduler. The Scheduler is a sibling to the Dispatcher, which we already know about. It works in almost the same way: A new process is spun up when Solid Queue starts, and this process runs an endless loop. The difference between the Scheduler and the Dispatcher is what happens within that loop. Where the Dispatcher queries the <code>solid_queue_scheduled_executions</code> table, the Scheduler queries <code>solid_queue_recurring_tasks</code> — and schedules jobs at the right time. So, how exactly does the Scheduler know what the right time is, and when to schedule the right jobs?</p>
<p>To answer that question, we have to examine the implementation closely. The scheduler class creates a new <code>RecurringSchedule</code> object that defines a <code>schedule</code> method. That method is repeatedly called for each scheduled task. Here&#39;s a simplified version:</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/solid_queue/scheduler/recurring_schedule.rb
def schedule(task)
  scheduled_task = Concurrent::ScheduledTask.new(task.delay_from_now, args: [ self, task, task.next_time ]) do |thread_schedule, thread_task, thread_task_run_at|
    thread_schedule.schedule(thread_task)
    thread_task.enqueue(at: thread_task_run_at)
  end
  scheduled_task.tap(&amp;:execute)
end
"></pre></div></figure>
<p>Let&#39;s untangle this code. Solid Queue uses <a href="https://ruby-concurrency.github.io/concurrent-ruby/master/Concurrent/ScheduledTask.html"><code>Concurrent::ScheduledTask</code></a> (from the <a href="https://github.com/ruby-concurrency/concurrent-ruby">concurrent-ruby library</a>) to spawn a new thread. That thread is scheduled to run at the time specified by the recurring task&#39;s schedule. When that thread runs, it first recursively spawns another thread to schedule the next recurring task. Then, it enqueues the &#39;current&#39; scheduled job.</p>
<p>Let&#39;s look at an example of a simple recurring task to get a handle on things.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="yaml" data-theme="github-dark" data-raw="production:
  my_periodic_task:
    class: CleanupData
    args: []
    schedule: every hour
"></pre></div></figure>
<p>If we start Solid Queue at 8:30, the variables within the schedule method are assigned the following values. Not verbatim, mind you. We&#39;re greatly simplifying here.</p>

<p>So, our background thread is scheduled to run thirty minutes from now, which is 9:00. When that time rolls around, the background thread is executed. It runs <code>thread_task.enqueue(at: 9:00)</code> — so an instance of <code>CleanupData</code> is queued for execution. It also calls itself recursively via <code>thread_schedule.schedule</code>. Because it is now 9:00, the variables for this invocation have changed.</p>

<p>So, the background thread is scheduled to run again at 10:00, and the cycle continues. You may be wondering what happens if the scheduling thread is killed, for example during a re-deploy or system crash. Won&#39;t that upset your schedules? Luckily, the answer is no. Cron schedules are static. An expression like &#39;Every Hour&#39; always resolves to 10:00, 11:00, 12:00, and so on, regardless of when Solid Queue starts. Any interruptions to the scheduling thread don&#39;t change that.</p>
<p>Here are some other implementation details to be aware of. First, this pattern of scheduling the next occurrence of a recurring task before executing it is inspired by <a href="https://github.com/bensheldon/good_job/blob/994ecff5323bf0337e10464841128fda100750e6/lib/good_job/cron_manager.rb#L84">GoodJob</a>. Second, <code>RecurringTask.enqueue</code> does not create a new <code>Job</code> and <code>ReadyExecution</code> record as you might expect. Instead, it creates yet another record, namely <code>RecurringExecution</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/generators/solid_queue/install/templates/db/queue_schema.rb
create_table &#34;solid_queue_recurring_executions&#34;, force: :cascade do |t|
  t.bigint &#34;job_id&#34;, null: false
  t.string &#34;task_key&#34;, null: false
  t.datetime &#34;run_at&#34;, null: false
  # ...
  t.index [ &#34;job_id&#34; ], name: &#34;index_solid_queue_recurring_executions_on_job_id&#34;, unique: true
  t.index [ &#34;task_key&#34;, &#34;run_at&#34; ], name: &#34;index_solid_queue_recurring_executions_on_task_key_and_run_at&#34;, unique: true
end
"></pre></div></figure>
<p>This record is solely to avoid executing recurring jobs multiple times. It has an index on <code>task_key</code> and <code>run_at</code> with unique constraints to serve that purpose. A <code>RecurringTask</code> is only queued if there is no prior <code>RecurringExecution</code> for the same time and the same job.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# app/models/solid_queue/recurring_task.rb
def enqueue(at:)
  active_job = if using_solid_queue_adapter?
    # Create a RecurringExecution and enqueues the job
    enqueue_and_record(run_at: at)
  else
    # ...
  end
  rescue RecurringExecution::AlreadyRecorded
    payload[:skipped] = true
    false
end
"></pre></div></figure>
<p>Attentive readers will notice that this code snippet points to a limitation in Solid Queue. That is, if you are not using Solid Queue as a backend to run your cron-style tasks — yes, you can do that — Solid Queue can&#39;t guarantee that recurring jobs are enqueued only once. If you find yourself in such a situation, you should be aware of that.</p>
<p>You may also be wondering what happens if the Scheduler process dies or is killed — for example, during a deployment. Since recurrences are managed by a thread, won&#39;t killing the thread break schedules? Luckily, the answer to that is no.</p>
<h2 id="concurrency-controls">Concurrency Controls</h2>
<p>Let&#39;s look at one final feature of Solid Queue, namely concurrency controls. Sometimes, you want to limit how many jobs of a certain kind can run simultaneously. You can do so using Solid Queue with <code>limits_concurrency</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="class MyJob &lt; ApplicationJob
  limits_concurrency to: 1, key: -&gt;(user) { user.id }, duration: 15.minutes, group: &#39;UserOnboarding&#39;
  # ...
"></pre></div></figure>
<p>Here, we are telling SolidQueue to run a maximum of one instance of <code>MyJob</code> for each user. Let&#39;s examine the configuration in more detail.</p>
<ul>
<li><code>to</code>: The maximum number of jobs you want running concurrently.</li>
<li><code>key</code>: A required argument to designate which jobs should be limited together. In our example, jobs with the same User ID are limited to a single concurrent execution. You may use any job arguments as <code>key</code>, but constants such as strings or symbols are also allowed.</li>
<li><code>duration</code>: The maximum time for which Solid Queue can guarantee concurrency after a job is enqueued. If your jobs run longer than that, concurrency controls will not apply and jobs may overlap. We&#39;ll learn why later!</li>
<li><code>group</code>: You can use this option to limit concurrency across different job classes.</li>
</ul>
<p>If you want to learn more, I refer you to <a href="https://github.com/rails/solid_queue/?tab=readme-ov-file#concurrency-controls">the concurrency control documentation</a>. Concurrency controls are easily Solid Queue&#39;s most sophisticated feature. If scheduled tasks didn&#39;t already make your head spin, learning how this feature works surely will.</p>
<p>Let&#39;s start with the basics. Like other Solid Queue features, concurrency controls are backed by various models and their corresponding database tables. Two that you need to be particularly aware of are <code>Semaphore</code> and <code>BlockedExecution</code>.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# lib/generators/solid_queue/install/templates/db/queue_schema.rb
create_table &#34;solid_queue_semaphores&#34;, force: :cascade do |t|
  t.string &#34;key&#34;, null: false
  t.integer &#34;value&#34;, default: 1, null: false
  t.datetime &#34;expires_at&#34;, null: false
  # ...
end

create_table &#34;solid_queue_blocked_executions&#34;, force: :cascade do |t|
  t.bigint &#34;job_id&#34;, null: false
  t.string &#34;queue_name&#34;, null: false
  t.integer &#34;priority&#34;, default: 0, null: false
  t.string &#34;concurrency_key&#34;, null: false
  t.datetime &#34;expires_at&#34;, null: false
  # ...
end
"></pre></div></figure>
<p>Let&#39;s look at <code>Semaphore</code> first. As the name suggests, this is an implementation of the <a href="https://en.wikipedia.org/wiki/Semaphore_(programming)">counting semaphore pattern</a>. Whenever Solid Queue enqueues a job with <code>limits_concurrency</code>, it first tries to acquire a semaphore lock based on a concurrency key. This concurrency key is based on the arguments passed to <code>limits_concurrency</code>, namely the job class, the key, and the group name — if any was provided. If the semaphore is available, the job is enqueued. If it is not, a <code>BlockedExecution</code> record is created instead.</p>
<p>Semaphores have a <code>value</code> to support multiple concurrent jobs. You can think of it as the remaining capacity of the semaphore. Acquiring a semaphore means decrementing that value, and releasing it means incrementing it. A semaphore is considered unavailable once its value is zero. Let&#39;s look at an example of how the locking mechanism works for a simple job.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="class MyJob &lt; ApplicationJob
  # Only three jobs of &#39;MyJob&#39; should run at the same time
  limits_concurrency to: 3, key: -&gt; { &#39;MyJob&#39; }, duration: 15.minutes
  # ...
end
"></pre></div></figure>
<p>Let&#39;s see what happens if we try to enqueue this job multiple times in succession.</p>
<ol>
<li>The first instance of <code>MyJob</code> is enqueued. There is no semaphore yet, so one is created. Its initial value is <code>limit - 1</code>. Because your limit is three, the initial value of the semaphore is two.</li>
<li>The second instance of <code>MyJob</code> is enqueued. Solid Queue attempts to acquire a lock for that job. The job can be enqueued because the value is two, which is greater than zero. The value of the semaphore is decremented to one.</li>
<li>A third instance of our job is enqueued. We repeat the same procedure as before. The value of the semaphore is now zero.</li>
<li>A fourth instance of <code>MyJob</code> is enqueued. Acquiring the semaphore fails because its value is now zero. A <code>BlockedExecution</code> record is created for the job.</li>
<li>The first instance of our job finishes. When it finishes, it releases the semaphore, so the semaphore value is once again one.</li>
<li>On finishing, the first job instance also calls a method to release any blocked jobs.</li>
<li>The fourth instance of <code>MyJob</code> is released and again tries to acquire a lock. The semaphore value is one, so the lock can be acquired and the blocked job queued. The semaphore value is now zero.</li>
</ol>
<p>The code for releasing a semaphore when a job finishes is straightforward.</p>
<figure data-rehype-pretty-code-figure=""><div data-rehype-pretty-code-fragment="true"><pre tabindex="0" data-language="ruby" data-theme="github-dark" data-raw="# app/models/solid_queue/claimed_execution.rb
def perform
  result = execute
  # ...
ensure
  # This method releases the Semaphore and makes it available for the next blocked job.
  job.unblock_next_blocked_job
end
"></pre></div></figure>
<p>There is one more detail that we haven&#39;t touched on yet. Why do semaphores have an expiry date, and why do we need to set a duration when using <code>limits_concurrency</code>?</p>
<p>Let&#39;s consider what happens when a job crashes without releasing its semaphore — for example, when a worker processing that job dies. Unless we add some mechanism to clean up semaphores, the lock held by that job will be retained forever. In the worst case, this would forever block other jobs from being processed.</p>
<p>Semaphores have an expiry that corresponds to the duration given in the job definition to avoid that situation. If a semaphore expires — which happens if no jobs are enqueued — the semaphore will be destroyed. We already know the process responsible for that — it&#39;s our friend, the <em>Dispatcher</em>. It instantiates the <code>ConcurrencyMaintenance</code> class, which does two things:</p>
<ul>
<li>First, it removes any expired semaphores.</li>
<li>Second, it will check if there are any blocked jobs and release them.</li>
</ul>
<p>Jobs are released one by one, so concurrency limits will still hold. Consider, however, what happens if your job runs longer than the given duration. In that case, the semaphore will be cleaned up, although the job will still run. If another job is then enqueued, those jobs will overlap.</p>
<h2 id="monitoring-solid-queue-for-rails-with-appsignal">Monitoring Solid Queue for Rails with AppSignal</h2>
<p>As we&#39;ve established, Solid Queue can do a lot. However, with all these moving parts, monitoring becomes crucial. Luckily, <a href="https://www.appsignal.com/ruby/solid-queue-monitoring">AppSignal provides built-in support for Solid Queue</a>, with ready-made dashboards for job execution times, throughput, and failure rates. Simply <a href="https://appsignal.com/users/sign_up">install AppSignal</a> in your Rails application, and you&#39;re good to go.</p>
<p>AppSignal will automatically detect your usage of Solid Queue and create an active job dashboard that contains graphs for important metrics, such as error rate and throughput.</p>
<figure><p><img alt="Solid Queue Job Dashboard" loading="lazy" width="1923" height="1202" decoding="async" data-nimg="1" sizes="sizes=&#34;(min-width: 768px) 1600px, 100vw" srcset="/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=640&amp;q=90 640w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=750&amp;q=90 750w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=828&amp;q=90 828w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=1080&amp;q=90 1080w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=1200&amp;q=90 1200w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=1920&amp;q=90 1920w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=2048&amp;q=90 2048w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=3840&amp;q=90 3840w" src="https://blog.appsignal.com/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-dashboard.png&amp;w=3840&amp;q=90"/></p></figure>
<p>If you ever see jobs that misbehave — either because they run slowly or have too many errors — assign them a status and assignee to effectively resolve the issue.</p>
<figure><p><img alt="Solid Queue Job Details" loading="lazy" width="1542" height="617" decoding="async" data-nimg="1" sizes="sizes=&#34;(min-width: 768px) 1600px, 100vw" srcset="/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=640&amp;q=90 640w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=750&amp;q=90 750w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=828&amp;q=90 828w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=1080&amp;q=90 1080w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=1200&amp;q=90 1200w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=1920&amp;q=90 1920w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=2048&amp;q=90 2048w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=3840&amp;q=90 3840w" src="https://blog.appsignal.com/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-jobs.png&amp;w=3840&amp;q=90"/></p></figure>
<p>Obviously, you shouldn&#39;t have to look at dashboards all day to figure out if there is a problem. AppSignal Alerts has your back. Simply create a new alert for job metrics, such as failure rate and job duration, and you&#39;re all set.</p>
<figure><p><img alt="Solid Queue Alerts" loading="lazy" width="1412" height="743" decoding="async" data-nimg="1" sizes="sizes=&#34;(min-width: 768px) 1600px, 100vw" srcset="/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=640&amp;q=90 640w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=750&amp;q=90 750w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=828&amp;q=90 828w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=1080&amp;q=90 1080w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=1200&amp;q=90 1200w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=1920&amp;q=90 1920w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=2048&amp;q=90 2048w, /_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=3840&amp;q=90 3840w" src="https://blog.appsignal.com/_next/image?url=%2Fimages%2Fblog%2F2025-06%2Fsolid-queue-trigger.png&amp;w=3840&amp;q=90"/></p></figure>
<p>Solid Queue is amazing for adding powerful job processing to your application without hassle. AppSignal does the same when it comes to monitoring!</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>We&#39;ve covered a lot of ground in our exploration of Solid Queue&#39;s advanced features. From scheduled jobs to complex dependency chains, each feature builds on the solid foundation we discussed in part one. As we&#39;ve seen, it&#39;s not easy to build a job processing backend. But by diving deep into the Solid Queue source code and its workings, we&#39;ve gained an understanding and some appreciation for the challenges involved.</p>
<p>In any case, Solid Queue is a wonderful addition to the Rails ecosystem, due to its excellent database design and process coordination. It provides the tools you need while maintaining its core promise: simplicity and reliability, without external dependencies.</p>
<p>Happy coding!</p></div></div>
  </body>
</html>
