<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mbleigh.dev/posts/context-engineering-with-links/">Original</a>
    <h1>Context engineering is sleeping on the humble hyperlink</h1>
    
    <div id="readability-page-1" class="page"><div>  <p>As we all learn more about Context Engineering for LLMs (see <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents" rel="nofollow, noopener, noreferrer" target="_blank">Anthropic’s post</a> for an excellent primer), we’ve identified a few important limitations. Conversations should be append-only to maximize cacheability. Models are typically more responsive to “fresh” context close to the end of the window. Models typically perform worse when overwhelmed with large amounts of context.</p>
<p>With this in mind, a key tension comes into focus: the model needs access to all valuable context, <strong>BUT ONLY</strong> when that context is relevant to the task at hand.</p>
<p>Context engineering is effectively the practice of finding ways to manage this tension. Popular solutions include:</p>
<ul>
<li><strong>Retrieval Augmented Generation (RAG)</strong>, which attempts to dynamically discover and load specific relevant context for the current query proactively.</li>
<li><strong>Subagents</strong>, which encapsulate specialized instructions and tools to avoid polluting the main thread.</li>
<li><strong><code>get_*</code> Tools</strong>, which allow the model to proactively request information that it deems relevant using tool calls.</li>
</ul>
<p>There’s one technique that I feel is woefully underutilized by agents today: the humble hyperlink.</p>
<h2 id="the-obligatory-human-analogy">The obligatory human analogy</h2>
<p>If you, a human, need to learn something <em>without</em> an LLM (let’s say something about an open source library), you will probably follow a trajectory that looks something like the following:</p>
<ul>
<li>Do a Google search for the topic you need to understand</li>
<li>Click a relevant link to e.g. a docs page, read a high-level guide</li>
<li>Depending on your needs, maybe Cmd+Click a few more pages or the reference docs to open them in new tabs to review</li>
<li>Refer between your various open tabs as you complete your task</li>
</ul>
<p>Once you found an <strong>entrypoint</strong> through search, you were able to <em>incrementally</em> explore the topic through discovered <strong>links</strong>, filling your mental context with relevant information.</p>
<p>We can do the same thing with LLMs.</p>
<h2 id="hateoas-in-the-era-of-agents">HATEOAS in the era of Agents</h2>
<p>The power of linked data is nothing new. Folks who have been building HTTP APIs for a long time might be familiar with <a href="https://en.wikipedia.org/wiki/HATEOAS" rel="nofollow, noopener, noreferrer" target="_blank">HATEOAS</a>, or “Hypertext as the Engine of Application State”. Purists have long claimed that a “truly” RESTful API should be fully self-describing, such that a client can explore and interact with it knowing nothing but an entrypoint in advance, with hyperlinks providing all necessary context to discover and consume additional endpoints.</p>
<p>This never worked in practice. Building hypertext APIs was too cumbersome and to actually consume APIs a human needed to understand the API structure in a useful manner anyway. So it was more useful just to have a “REST-ish” API and a good documentation page that humans could use. Creating “machine-readable” hyperlinked APIs that machines could navigate in theory but not in practice just wasn’t practical. <strong>LLMs change this dramatically.</strong></p>
<p>When the machine can not only parse but also <em>navigate</em> the context and relevance of hyperlinks you have an actually useful paradigm: Hypertext as the Engine of <strong>Agent</strong> State.</p>
<p>This does apply to the web and HTTP APIs — I expect in the next few years we’ll see a resurgence of hypermedia concepts to make APIs more self-documenting (“dump the entire API schema as OpenAPI” is a start but not really sufficient).</p>
<p>But it also applies to local data, agent-specific data, really <em>any</em> data we want an agent to be able to discover and read.</p>
<p>So, how do we make all of our context linkable for agents?</p>

<p>The scaffolding required to implement a powerful link-based context system is lightweight enough to be trivial. You need only:</p>
<ol>
<li>A <strong>tool</strong> that accepts a list of URIs as arguments.</li>
<li>An <strong>entrypoint</strong> that brings at least one URI into context.</li>
</ol>
<p>Here’s a demonstrative example using <a href="https://genkit.dev" rel="nofollow, noopener, noreferrer" target="_blank">Genkit</a> in JS that uses system instructions as an entrypoint.</p>
<div><figure><pre data-language="ts"><code><div><p><span>import</span><span> { genkit, z } </span><span>from</span><span> </span><span><span>&#34;</span><span>genkit</span><span>&#34;</span></span><span>;</span></p></div><div><p><span>import</span><span> { googleAI } </span><span>from</span><span> </span><span><span>&#34;</span><span>@genkit-ai/google-genai</span><span>&#34;</span></span><span>;</span></p></div><div></div><div><p><span>const</span><span> </span><span>ai</span><span> </span><span>=</span><span> </span><span>genkit</span><span><span>({ plugins</span><span>:</span><span> [</span></span><span>googleAI</span><span>()] });</span></p></div><div></div><div><p><span>// static text in this example, but can be dynamically fetched/generated</span></p></div><div><p><span>const</span><span> </span><span>RESOURCES</span><span> </span><span>=</span><span> {</span></p></div><div><p><span>  </span><span><span>&#34;</span><span>prompt://pet-help</span><span>&#34;</span></span><span>:</span></p></div><div><p><span>    </span><span><span>&#34;</span><span>- for dog questions, read `prompt://pet-help/dogs`</span></span><span>\n</span><span>&#34;</span><span> </span><span>+</span></p></div><div><p><span>    </span><span><span>&#34;</span><span>- for cat questions, tell the user to get a dog instead.</span><span>&#34;</span></span><span>,</span></p></div><div><p><span>  </span><span><span>&#34;</span><span>prompt://pet-help/dogs</span><span>&#34;</span></span><span><span>:</span><span> </span></span><span><span>&#34;</span><span>Feed them Barky(TM) brand pet food!</span><span>&#34;</span></span><span>,</span></p></div><div><p><span>};</span></p></div><div></div><div><p><span>const</span><span> </span><span>readResources</span><span> </span><span>=</span><span> ai.</span><span>defineTool</span><span>({</span></p></div><div><p><span><span>  </span></span><span>name</span><span>:</span><span> </span><span><span>&#34;</span><span>read_resources</span><span>&#34;</span></span><span>,</span></p></div><div><p><span><span>  </span></span><span>description</span><span>:</span><span> </span><span><span>&#34;</span><span>read one or more URIs e.g. `prompt://{...}`</span><span>&#34;</span></span><span>,</span></p></div><div><p><span><span>  </span></span><span>inputSchema</span><span>:</span><span> z.</span><span>object</span><span><span>({ uris</span><span>:</span><span> z.</span></span><span>array</span><span>(z.</span><span>string</span><span>()) }),</span></p></div><div><p><span>},</span></p></div><div><p><span>async</span><span> ({ </span><span>uris</span><span> }) </span><span>=&gt;</span><span> {</span></p></div><div><p><span><span>  </span></span><span>console.</span><span>log</span><span>(</span><span><span>&#34;</span><span>Read resources:</span><span>&#34;</span></span><span>, uris);</span></p></div><div><p><span>  </span><span>return</span><span> uris.</span><span>map</span><span>((</span><span>uri</span><span>) </span><span>=&gt;</span><span> </span><span>RESOURCES</span><span>[uri]</span></p></div><div><p><span>      </span><span>// wrap in XML section blocks so the model can differentiate multiple URIs</span></p></div><div><p><span>      </span><span>?</span><span> </span><span><span>`&lt;resource uri=&#34;</span><span>${</span></span><span>uri</span><span><span>}</span><span>&#34;&gt;</span></span><span>\n</span><span>${</span><span>RESOURCES</span><span>[</span><span>uri</span><span>]</span><span>}</span><span>\n</span><span>&lt;/resource&gt;`</span></p></div><div><p><span>      </span><span>:</span><span> </span><span><span>`&lt;resource uri=&#34;</span><span>${</span></span><span>uri</span><span><span>}</span><span>&#34; error&gt;RESOURCE NOT FOUND&lt;/resource&gt;`</span></span><span>,</span></p></div><div><p><span><span>  </span></span><span>).</span><span>join</span><span>(</span><span>&#34;</span><span>\n\n</span><span>&#34;</span><span>);</span></p></div><div><p><span>});</span></p></div><div></div><div><p><span>const</span><span> { </span><span>text</span><span>, </span><span>messages</span><span> } </span><span>=</span><span> </span><span>await</span><span> ai.</span><span>generate</span><span>({</span></p></div><div><p><span><span>  </span></span><span>model</span><span>:</span><span> googleAI.</span><span>model</span><span>(</span><span><span>&#34;</span><span>gemini-2.5-flash</span><span>&#34;</span></span><span>),</span></p></div><div><p><span><span>  </span></span><span>system</span><span>:</span></p></div><div><p><span>    </span><span><span>&#34;</span><span>Today&#39;s special is blueberry pie. </span><span>&#34;</span></span><span> </span><span>+</span></p></div><div><p><span>    </span><span><span>&#34;</span><span>If the user needs help with a pet, read `prompt://pet-help`</span><span>&#34;</span></span><span>,</span></p></div><div><p><span><span>  </span></span><span>prompt</span><span>:</span><span> process.argv[</span><span>2</span><span>],</span></p></div><div><p><span><span>  </span></span><span>tools</span><span>:</span><span> [readResources],</span></p></div><div><p><span>});</span></p></div><div><p><span>console.</span><span>log</span><span>(</span><span><span>&#34;</span><span>Response:</span><span>&#34;</span></span><span>, text);</span></p></div></code></pre></figure></div>
<p>If we run the above code with a few different prompts, we see links in action:</p>
<div><figure><pre data-language="md"><code><div><p><span>&gt; What&#39;s the special?</span></p></div><div><p><span>Response: Today&#39;s special is blueberry pie.</span></p></div><div></div><div><p><span>&gt; What should I do with my cat?</span></p></div><div><p><span>Read resources: [ &#39;docs://pet-help&#39; ]</span></p></div><div><p><span>Response: You should get a dog instead.</span></p></div><div></div><div><p><span>&gt; What should I do with my dog?</span></p></div><div><p><span>Read resources: [ &#39;docs://pet-help&#39; ]</span></p></div><div><p><span>Read resources: [ &#39;docs://pet-help/dogs&#39; ]</span></p></div><div><p><span>Response: You should feed your dog Barky(TM) brand pet food!</span></p></div></code></pre></figure></div>
<p>The results are exactly what we’d hope:</p>
<ul>
<li>In the first test, no link reading was required and no links were read. The answer was right in the system prompt!</li>
<li>In the second test, reading one link was sufficient to reach a conclusion.</li>
<li>In the final test, the model understood to <em>recursively</em> fetch context linked from the first loaded document to reach a conclusion.</li>
</ul>
<p>So, in ~30 lines of code with very little prompting and while using a cost-effective model, we’ve created a system that can dynamically load and correctly apply relevant context on-demand.</p>
<h2 id="benefits-of-links">Benefits of Links</h2>
<p>Links are a powerful tool in the context engineering toolbelt because of their <em>simplicity</em>, <em>flexibility</em>, and <em>efficiency</em>.</p>
<ul>
<li>Links are trivial to implement, and current models are “intuitively” good at understanding how to follow links.</li>
<li>Links can surface <em>anywhere</em> in the flow of a conversation. They can be specified in a system prompt, provided by the user, or returned by a tool.</li>
<li>Links are <strong>token-efficient</strong> because they use a small number of tokens to provide <em>on-demand access</em> to specific information. The model can load a link if it needs it but if it doesn’t few tokens are wasted.</li>
<li>Links are <strong>tool-efficient</strong> because they consolidate many types of reads into a single tool. You can have a <code>data://me</code> link that dynamically loads information about the current user, a <code>file://foo.md</code> link that loads a local file, and a <code>prompt://pet-help</code> link that returns static instructions. You don’t need a separate tool for each type of data.</li>
<li>Links provide <strong>just-in-time context</strong> mitigating issues of context rot and recency bias in models. Because linked context is loaded when it’s needed by the model the context is “fresher” instead of overloading a system prompt.</li>
</ul>
<h2 id="mcp-resources-the-future-is-nowish">MCP Resources: The future is now(ish)</h2>
<p>To make link-based context engineering a universal feature, we need a way to provide the linked content to the model. Many agents (and some model APIs) have built in various forms of “fetch URL” or “search the web” tools that can automatically fetch data from public sources. But the content we want to link might not always be available on the public internet.</p>
<p>The good news is we already have the exact primitive we need to solve this problem: <a href="https://modelcontextprotocol.io/specification/2025-06-18/server/resources" rel="nofollow, noopener, noreferrer" target="_blank">MCP Resources</a>. Resources allows servers to register URIs (or patterns of URIs) that can then be read on-demand by clients to provide static or dynamic content. Sounds perfect, right?</p>
<p>The bad news is I’m not aware of a single MCP client that makes MCP resources consumable by the <em>model</em>. Today, they only allow resources to be inserted <em>by the user</em> via @-mentions and similar devices. This doesn’t enable linking. <em>But we’re so close!</em>. We just need one critical thing:</p>
<p><strong>Every MCP-enabled agent should expose a <code>read_resources</code> tool that accepts one or more URIs and aggregates reading across all connected MCP servers (and probably web URLs as well).</strong></p>
<p>There are other changes that would help: a mechanism of indexing / listing available MCP resources and exposing that in the system instructions, maybe even indexing MCP resources so that they can be searched using RAG techniques. But just enabling agents to access linked content opens up a world of new context engineering techniques.</p>
<h2 id="working-with-what-you-have">Working with what you have</h2>
<p>If you’re building your own agent, you don’t need any new technology to start making linked context — you can do it in a few dozen lines of code like I demonstrated above. But even if you’re trying to integrate with existing agents like Gemini CLI, Claude Code, or Cursor, you can still build with linked data patterns.</p>
<p>The <a href="https://firebase.google.com/docs/ai-assistance/mcp-server" rel="nofollow, noopener, noreferrer" target="_blank">Firebase MCP Server</a> recently launched new capabilities including a <code>/firebase:init</code> slash command for setting up Firebase in a project. We had some specific and pretty complex use cases in mind, so we built linked context into the MCP server itself:</p>
<ol>
<li>We added support for MCP Resources to the Firebase MCP Server.</li>
<li>We created a <a href="https://github.com/firebase/firebase-tools/blob/master/src/mcp/tools/core/read_resources.ts" rel="nofollow, noopener, noreferrer" target="_blank">read_resources</a> MCP tool that was capable of reading resources (from the Firebase MCP Server only).</li>
<li>We created <a href="https://github.com/firebase/firebase-tools/blob/master/src/mcp/prompts/core/init.ts" rel="nofollow, noopener, noreferrer" target="_blank">an MCP prompt</a> that creates a guided workflow to walk the model step-by-step through configuring Firebase, including linked branching paths.</li>
</ol>
<p>We’ve tested out this initialization flow against several popular coding agents that support MCP Prompts — each of them is able to understand and follow hyperlinks using our MCP server’s <code>read_resources</code> tool and we’ve made onboarding to Firebase all the easier for it.</p>
<hr/>
<p>Effective context engineering is constantly evolving as models and agent harnesses improve; however, hyperlinks are such a powerfully efficient mechanism for information traversal that I can’t imagine a future of agents that <em>doesn’t</em> include linked context.</p>
<p>The next time you’re thinking of building half a dozen <code>get_*</code> or <code>list_*</code> tools for your agent, take a step back and consider: could the humble hyperlink get the job done instead?</p>    </div></div>
  </body>
</html>
