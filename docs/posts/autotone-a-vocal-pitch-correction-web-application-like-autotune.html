<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/alexcrist/autotone">Original</a>
    <h1>Autotone â€“ A vocal pitch correction web application, like Autotune</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<blockquote>
<p dir="auto">A vocal pitch correction web application (like Autotune): <a href="https://alexcrist.github.io/autotone/" rel="nofollow">https://alexcrist.github.io/autotone/</a></p>
</blockquote>
<p dir="auto">This project works using CREPE&#39;s pitch detection model and Stephan Bernsee&#39;s approach to Fourier-transform based pitch shifting:</p>
<ul dir="auto">
<li><a href="https://github.com/marl/crepe">CREPE: A Convolutional REpresentation for Pitch Estimation -- pre-trained model (ICASSP 2018)</a></li>
<li><a href="http://blogs.zynaptiq.com/bernsee/pitch-shifting-using-the-ft/" rel="nofollow">Pitch Shifting Using The Fourier Transform by Stephan Bernsee</a></li>
</ul>
<h2 dir="auto"><a id="user-content--how-it-works" aria-hidden="true" href="#-how-it-works"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><g-emoji alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png">ðŸ¤–</g-emoji> How it works</h2>
<p dir="auto">To perform vocal pitch correction, the input audio goes through two stages: pitch detection and pitch shifting.</p>
<p dir="auto">To detect pitches, one of CREPE&#39;s pre-trained models is run using TensorFlowJS. To pitch shift, WebAssembly is used to run a C library that performs Fourier-based pitch shifting according to Stephan Bernsee&#39;s blog post above. Additionally, the audio processing algorithms are run in the background on web workers to prevent the browser from becoming unresponsive.</p>
<h2 dir="auto"><a id="user-content--development" aria-hidden="true" href="#-development"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><g-emoji alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">ðŸ’»</g-emoji> Development</h2>
<h4 dir="auto"><a id="user-content-dependencies" aria-hidden="true" href="#dependencies"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dependencies</h4>
<ul dir="auto">
<li>Node v14.18.2</li>
<li>NPM v6.14.15</li>
<li>Emscripten v3.1.29</li>
</ul>
<h4 dir="auto"><a id="user-content-developing" aria-hidden="true" href="#developing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Developing</h4>
<ol dir="auto">
<li>Clone this repo</li>
<li>Init the <code>crepe</code> submodule with <code>git submodule init</code></li>
<li>Build the C pitch-shifting library to WebAssembly by entering the <code>tuner</code> directory and running <code>make</code></li>
<li>Install the web dependencies by entering the <code>react</code> directory and running <code>npm install</code></li>
<li>Start the development server by entering the <code>react</code> directory and running <code>npm start</code></li>
<li>View the app at <code>http://localhost:8080</code></li>
</ol>
<h4 dir="auto"><a id="user-content-deploying" aria-hidden="true" href="#deploying"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deploying</h4>
<p dir="auto">Deploy the app to GitHub Pages using <code>scripts/deploy.sh</code></p>
<h2 dir="auto"><a id="user-content--technologies-used" aria-hidden="true" href="#-technologies-used"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><g-emoji alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png">ðŸ“š</g-emoji> Technologies used</h2>
<ul dir="auto">
<li>TensorFlow.js</li>
<li>WebAssembly (Emscripten)</li>
<li>Web audio API</li>
<li>Web workers</li>
<li>React</li>
<li>Webpack</li>
</ul>
<h2 dir="auto"><a id="user-content--future-work" aria-hidden="true" href="#-future-work"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><g-emoji alias="telescope" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52d.png">ðŸ”­</g-emoji> Future work</h2>
<ul dir="auto">
<li>Allow user to set pitch detection over-sampling factor
<ul dir="auto">
<li>This will involve moving audio window/buffer building
logic out of BufferNode/Processor and into Autotoner</li>
</ul>
</li>
<li>Add export functionality</li>
<li>Add more types of scales</li>
<li>Allow user to pitch correct according to a separate target audio or MIDI input</li>
</ul>
</article>
          </div></div>
  </body>
</html>
