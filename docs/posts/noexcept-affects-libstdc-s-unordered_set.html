<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://quuxplusone.github.io/blog/2024/08/16/libstdcxx-noexcept-hash/">Original</a>
    <h1>`noexcept` affects libstdc&#43;&#43;&#39;s `unordered_set`</h1>
    
    <div id="readability-page-1" class="page"><div>
    <p>The other day I learned a new place where adding or removing <code>noexcept</code> can
change the performance of your program: GNU libstdc++’s
hash-based associative containers change the struct layout of their nodes
depending on the noexceptness of your hash function.
This is laid out fairly clearly
<a href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/unordered_associative.html">in the docs</a>;
it’s simply bizarre enough that I’d never thought to look for such a thing <em>in</em> the docs!</p>

<p>In C++, a <code>std::unordered_set</code> is basically a vector of “buckets,” where each bucket is
a linked list of “nodes,” and each node stores a single element of the <code>unordered_set</code>.
(This makes <code>unordered_set</code> a “node-based container”; it supports the full
<a href="https://en.cppreference.com/w/cpp/container/unordered_set/extract">C++17 node-handle API</a>.)
Erasing an element from the <code>unordered_set</code> goes something like this:</p>

<div><div><pre><code>template&lt;class T, class Hash, class KeyEqual&gt;
struct unordered_set {
  struct Node {
    T t_;
  };
  vector&lt;list&lt;Node&gt;&gt; buckets_;
  Hash hash_;
  KeyEqual eq_;

  void erase(const T&amp; key) {
    size_t h = hash_(key);
    size_t bc = buckets_.size();
    auto&amp; bucket = buckets_[h % bc];
    for (auto it = bucket.begin(); it != bucket.end(); ++it) {
      if (eq_(it-&gt;t_, key)) {
        bucket.erase(it);
        return;
      }
    }
  }
};
</code></pre></div></div>

<p>(Some details omitted, e.g. the <code>Allocator</code> parameter and the return type of <code>erase</code>.)</p>

<p>Above, the <code>for</code>-loop is iterating over everything in the bucket — that is, every item
<code>t</code> such that <code>hash_(t) % bc == hash_(key) % bc</code> — and invoking <code>eq_</code> for each of
those items. If equivalence is expensive, then maybe we could do better by comparing
hashes first:</p>

<div><div><pre><code>    for (auto it = bucket.begin(); it != bucket.end(); ++it) {
      if ((hash_(it-&gt;t_) == h) &amp;&amp; eq_(it-&gt;t_, key)) {
        bucket.erase(it);
        return;
      }
    }
</code></pre></div></div>

<p>Now we invoke <code>eq_</code> for only those items <code>t</code> such that <code>hash_(t) == hash_(key)</code>, period.
But if <code>hash_</code> is <em>slower</em> than <code>eq_</code>, that’s a pessimization.</p>

<h2 id="store-a-hash-per-node">Store a hash per node</h2>

<p>We can keep it fast by precomputing <code>hash_(it-&gt;t_)</code> and storing it in the node directly:</p>

<div><div><pre><code>  struct Node {
    T t_;
    size_t h_;
  };

  void erase(const T&amp; key) {
    size_t h = hash_(key);
    size_t bc = buckets_.size();
    auto&amp; bucket = buckets_[h % bc];
    for (auto it = bucket.begin(); it != bucket.end(); ++it) {
      if ((it-&gt;h_ == h) &amp;&amp; eq_(it-&gt;t_, key)) {
        bucket.erase(it);
        return;
      }
    }
  }
</code></pre></div></div>

<p>Now we have the best of both worlds, at the piddling cost of 8 bytes per element.
(Sure, in some domains that’s a lot! But <code>unordered_set</code> is already spending at least that much
on prev/next pointers, not to mention the lower-level bookkeeping associated with each
element’s having its own separate heap-allocation. In the grand scheme of <code>unordered_set</code>
inefficiencies, another 8 bytes won’t be missed.)</p>

<p>Secondly: The libstdc++ docs <a href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/unordered_associative.html">go on to say</a> that
“<code>erase</code> and <code>swap</code> operations […] might need an element’s hash code.” I’m not sure why they
mention <code>swap</code>, but I see how <code>erase</code> needs an element’s hash code. We’re no longer talking about
<code>erase(const T&amp;)</code>; now we’re talking about <code>erase(const_iterator)</code>. That looks something like this:</p>

<div><div><pre><code>void erase(list&lt;Node&gt;::const_iterator it) {
  size_t h = it-&gt;h_;
  size_t bc = buckets_.size();
  buckets_[h % bc].erase(it);
}
</code></pre></div></div>

<p>Here we need <code>h</code> so that we can figure out which bucket to modify.</p>

<blockquote>
  <p>“Can’t we just hook our <code>prev</code> pointer up to our <code>next</code> pointer?”
Well, it turns out that I lied about the data structure being basically a <code>list</code>.
Microsoft’s <code>unordered_set</code> has bidirectional iterators, but libc++ and libstdc++
allow only forward iteration. libstdc++ actually
<a href="https://github.com/gcc-mirror/gcc/blob/cc38bdf/libstdc%2B%2B-v3/include/bits/hashtable.h#L2123-L2130">has code</a>
that re-iterates the bucket looking for this node’s predecessor. “Isn’t that slow?”
Sure, if you have a high <a href="https://en.cppreference.com/w/cpp/container/unordered_set/load_factor">load factor</a>;
but the whole point of a hash table is that the load factor <em>must</em> remain low
as <code>size()</code> increases, or else you have a bad time (in more ways than this).</p>
</blockquote>

<p>In practice, if we’re the first node in our bucket, we also need to update
the <code>h</code>’th bucket pointer to point to our successor — the thing slightly automated
above by <code>buckets_[...].erase(it)</code>. Even if we had a “prev” pointer, we’d still have
to know which bucket to touch for that part.</p>

<p>Thirdly: Suppose we insert so many elements that we need to expand the <code>buckets_</code> vector —
we need to “rehash.” Each element <code>t</code> is currently part of bucket number <code>hash_(t) % bc</code>;
but we’ll need to place it into the expanded vector at index <code>hash_(t) % new_bc</code>,
which can’t be computed without knowing <code>hash_(t)</code> itself.</p>

<p>So it seems like we have at least three reasons to want to store those extra 8 bytes
in each node: It can save us O(k) time during <code>erase(const T&amp;)</code>; we have to compute it
once anyway during <code>erase(const_iterator)</code>; and we have to compute it O(n) times
during rehashing.</p>

<p>Clearly we should just pay those 8 bytes to cache <code>hash_(t)</code>, and everyone’ll be happy, right?</p>

<h2 id="but-sometimes-the-hash-is-trivial">But sometimes the hash is trivial</h2>

<p>Well, what about <code>unordered_set&lt;int&gt;</code>? In that case, the hash function is <code>std::hash&lt;int&gt;</code>,
which on libstdc++ <a href="https://github.com/gcc-mirror/gcc/blob/cc38bdf093c44918edff819ae6c73d03c726b341/libstdc%2B%2B-v3/include/bits/functional_hash.h#L114-L122">is trivial</a>:
<code>hash_(t)</code> is just a copy of <code>t</code> itself. It does seem pretty silly to store that!
So, what we really want is to store the hash by default, and omit it only when <code>Hash</code>
is a trivial hash function.</p>

<p>Unfortunately, libstdc++ essentially reverses that logic: By default,
they’ll <em>never</em> pay the extra 8 bytes to store the hash. They’ll assume that
recomputing the hash is cheap, so that <code>it-&gt;h_</code> can be replaced with <code>hash_(it-&gt;t_)</code>.
But there are two things that can make libstdc++ reconsider that decision:</p>

<ul>
  <li>
    <p>If <code>Hash</code> is on a fixed blacklist of “expensive hash functions,” i.e., if
  <a href="https://github.com/gcc-mirror/gcc/blob/cc38bdf093c44918edff819ae6c73d03c726b341/libstdc%2B%2B-v3/include/bits/functional_hash.h#L283-L300"><code>std::__is_fast_hash&lt;Hash&gt;::value</code></a>
  is false. That tells us that it would be prohibitively expensive to
  recompute <code>hash_(t)</code> during rehashing, so we’d better cache it.</p>
  </li>
  <li>
    <p>If <code>Hash::operator()</code> is non-noexcept. That tells us that when we recompute
  <code>hash_(t)</code> during <code>erase</code>, it might throw an exception — and the Standard
  guarantees that <code>erase(const_iterator)</code> <em>won’t</em> throw any exceptions!
  So <code>erase(const_iterator)</code> isn’t allowed to call the hash function at all,
  in this case.</p>
  </li>
</ul>

<blockquote>
  <p><a href="https://eel.is/c++draft/container.requirements#container.reqmts-66.3">[container.reqmts]/66.3</a>
specifies that “No <code>erase</code>, <code>clear</code>, <code>pop_back</code>, or <code>pop_front</code> function throws an exception.”
This is amended by <a href="https://eel.is/c++draft/unord.req.except#1">[unord.req.except]/1</a>,
which permits <code>erase(const T&amp; key)</code> to throw if hashing <code>key</code> throws (because we need to hash <code>key</code>
in order to look it up in the first place), but still doesn’t permit <code>erase(const_iterator)</code> to throw
for any reason.</p>
</blockquote>

<p>The outcome is that libstdc++’s <code>unordered_set</code> has performance characteristics
that subtly depend on the true name and noexceptness of the hash function.</p>

<ul>
  <li>
    <p>A user-defined <code>struct H : std::hash&lt;std::string&gt; {}</code>
  will see smaller allocations and more calls to the hash function, than if you
  had just used <code>std::hash&lt;std::string&gt;</code> directly. (Because <code>std::hash&lt;std::string&gt;</code>
  is on the blacklist and <code>H</code> is not.)</p>
  </li>
  <li>
    <p>A user-defined hasher with <code>size_t operator() const noexcept</code>
  will see smaller allocations and more calls to the hash function (especially during rehashing).
  One with <code>size_t operator() const</code> will see larger allocations and fewer calls to the hash function.</p>
  </li>
</ul>

<h2 id="benchmark">Benchmark</h2>

<p><a href="https://quuxplusone.github.io/blog/code/2024-08-16-hash-benchmark.cpp">This benchmark</a> (<a href="https://godbolt.org/z/cP8hscaEW">on Godbolt, with smaller numbers</a>)
demonstrates some of the consequences of libstdc++’s heuristic.
For each of three types, we print the node size and the amount of time it takes to rehash the table 14 times.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><code>int*</code></th>
      <th><code>string</code></th>
      <th><code>vector&lt;bool&gt;</code></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>std::hash</code> is:</td>
      <td>trivial (fast)</td>
      <td>blacklisted (known slow)</td>
      <td>normal (incorrectly assumed fast)</td>
    </tr>
    <tr>
      <td>non-<code>noexcept</code></td>
      <td>24 bytes, 15ms</td>
      <td>48 bytes, 275ms</td>
      <td>56 bytes, 259ms</td>
    </tr>
    <tr>
      <td><code>noexcept</code></td>
      <td>16 bytes, 13ms</td>
      <td>40 bytes, 951ms</td>
      <td>48 bytes, 945ms</td>
    </tr>
    <tr>
      <td><code>std::hash</code></td>
      <td>16 bytes, 13ms</td>
      <td>48 bytes, 264ms</td>
      <td>48 bytes, 946ms</td>
    </tr>
  </tbody>
</table>

<p>The first column is really cool: it shows that <code>unordered_set</code> is smart enough not to cache <code>hash_(t)</code>
when <code>hash_</code> is the trivial <code>std::hash&lt;int*&gt;</code>. Recomputing the hash (a no-op) is actually faster than
loading the cached value from memory!</p>

<p>The second column, bottom cell, illustrates that <code>unordered_set</code> correctly pays the 8 bytes to avoid expensively
recomputing <code>std::hash&lt;string&gt;</code> over and over. You can replicate that good
behavior by defining your own <code>YourHash::operator() const</code>. But woe betide the hapless programmer
who defines <code>YourHash::operator() const noexcept</code> — their hash function will be called many more times
than it should, resulting in a massive slowdown (on this workload, anyway).</p>

<p>The third column illustrates the reverse effect: libstdc++ does <em>not</em> recognize that hashing a
<code>vector&lt;bool&gt;</code> is expensive, so they save 8 bytes and take a massive slowdown by default.
You can replicate that bad behavior with <code>YourHash::operator() const noexcept</code>, or cleverly
define your own <code>YourHash::operator() const</code> for a speedup (on this workload).</p>

<h2 id="conclusion">Conclusion</h2>

<p>I think this whole thing is mostly irrelevant to real programming. I wouldn’t go out of my way to audit
your codebase for hashers that are (or aren’t) <code>noexcept</code>; if hashing is your bottleneck then your first
step should be to stop using the node-based, pointer-chasing <code>std::unordered_set</code> entirely!</p>

<p>Also, I hope that if you’re reading this post in a year or two (say, December 2025), these specific
examples won’t even reproduce anymore. I hope libstdc++ gets on the ball and eliminates some of
this weirdness. (In short: They should get rid of the blacklist; pay the 8 bytes by default;
introduce a whitelist for <em>trivial</em> hashers specifically; stop checking noexceptness for any reason.)</p>

<p>But if you must take one sound bite from this post, maybe it’s this: <strong>libstdc++ makes it a pessimization
to mark any non-trivial hash function as <code>noexcept</code>.</strong> You must put the <code>noexcept</code> keyword on non-defaulted move-constructors
(to avoid the <a href="https://quuxplusone.github.io/blog/2022/08/26/vector-pessimization/">vector pessimization</a>); there are a few other ad-hoc places
you might want it; but you certainly do <em>not</em> want <code>noexcept</code> “everywhere,” as this surprising libstdc++ behavior
illustrates.</p>

<hr/>

<p>See also:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2022/08/26/vector-pessimization/">“What is the vector pessimization?”</a> (2022-08-26)</li>
  <li><a href="https://quuxplusone.github.io/blog/2022/07/30/type-erased-inplace-printable/">“Type-erased <code>InplaceUniquePrintable</code> benefits from <code>noexcept</code>”</a> (2022-07-30)</li>
  <li><a href="https://quuxplusone.github.io/blog/2022/06/23/unordered-multiset-equal-range/">“<code>unordered_multiset</code>’s API affects its big-O”</a> (2022-06-23)</li>
</ul>

  </div></div>
  </body>
</html>
