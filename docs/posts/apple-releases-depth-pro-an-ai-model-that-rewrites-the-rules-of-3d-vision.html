<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://venturebeat.com/ai/apple-releases-depth-pro-an-ai-model-that-rewrites-the-rules-of-3d-vision/">Original</a>
    <h1>Apple releases Depth Pro, an AI model that rewrites the rules of 3D vision</h1>
    
    <div id="readability-page-1" class="page"><div>
		
		<section>
			
			<p><time title="2024-10-04T18:52:31+00:00" datetime="2024-10-04T18:52:31+00:00">October 4, 2024 11:52 AM</time>
			</p>
			
		</section>
		<div>
					<p><img width="750" height="421" src="https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Flat_vector_design_of_the_Apple_logo_integrated_into__6d245237-c107-4fb8-b31c-e089bfd3f5f2-1.webp?w=750" alt="Credit: VentureBeat made with Midjourney"/></p><p><span>Credit: VentureBeat made with Midjourney</span></p>		</div><!-- .article-media-header -->
	</div><div id="primary">

		<article id="content">
			<div>
				<div id="boilerplate_2682874"><!-- wp:paragraph -->
<p><em>Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. <a href="https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=desktopNav" data-type="link" data-id="https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=desktopNav">Learn More</a></em></p>
<!-- /wp:paragraph -->

<!-- wp:separator {"opacity":"css","className":"is-style-wide"} -->
<hr/>
<!-- /wp:separator --></div><p><a href="https://machinelearning.apple.com/">Apple’s AI research team</a> has developed a new model that could significantly advance how machines perceive depth, potentially transforming industries ranging from augmented reality to autonomous vehicles.</p>



<p>The system, called <a href="https://arxiv.org/pdf/2410.02073">Depth Pro</a>, is able to generate detailed 3D depth maps from single 2D images in a fraction of a second—without relying on the camera data traditionally needed to make such predictions.</p>



<p>The technology, detailed in a research paper titled <em>“<a href="https://arxiv.org/pdf/2410.02073">Depth Pro: Sharp Monocular Metric Depth in Less Than a Second</a>,”</em> is a major leap forward in the field of monocular depth estimation, a process that uses just one image to infer depth.</p>



<p>This could have far-reaching applications across sectors where real-time spatial awareness is key. The model’s creators, led by Aleksei Bochkovskii and Vladlen Koltun, describe Depth Pro as one of the fastest and most accurate systems of its kind.</p>



<figure><img fetchpriority="high" decoding="async" width="830" height="853" src="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12%E2%80%AFAM.png?w=584" alt="" srcset="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png 830w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=300,308 300w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=768,789 768w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=584,600 584w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=52,52 52w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=400,411 400w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=750,771 750w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.26.12 AM.png?resize=578,594 578w" sizes="(max-width: 830px) 100vw, 830px"/><figcaption>A comparison of depth maps from Apple’s Depth Pro, Marigold, Depth Anything v2, and Metric3D v2. Depth Pro excels in capturing fine details like fur and birdcage wires, producing sharp, high-resolution depth maps in just 0.3 seconds, outperforming other models in accuracy and detail. (credit: arxiv.org)</figcaption></figure>







<p>Monocular depth estimation has long been a challenging task, requiring either multiple images or metadata like focal lengths to accurately gauge depth.</p>



<p>But Depth Pro bypasses these requirements, producing high-resolution depth maps in just 0.3 seconds on a standard GPU. The model can create 2.25-megapixel maps with exceptional sharpness, capturing even minute details like hair and vegetation that are often overlooked by other methods.</p>



<p>“These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction,” the researchers explain in their paper. This architecture allows the model to process both the overall context of an image and its finer details simultaneously—an enormous leap from slower, less precise models that came before it.</p>



<figure><img decoding="async" width="846" height="953" src="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18%E2%80%AFAM.png?w=533" alt="" srcset="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png 846w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=300,338 300w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=768,865 768w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=533,600 533w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=400,451 400w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=750,845 750w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.34.18 AM.png?resize=578,651 578w" sizes="(max-width: 846px) 100vw, 846px"/><figcaption>A comparison of depth maps from Apple’s Depth Pro, Depth Anything v2, Marigold, and Metric3D v2. Depth Pro excels in capturing fine details like the deer’s fur, windmill blades, and zebra’s stripes, delivering sharp, high-resolution depth maps in 0.3 seconds. (credit: arxiv.org)</figcaption></figure>



<h2 id="h-metric-depth-zero-shot-learning">Metric depth, zero-shot learning</h2>



<p>What truly sets Depth Pro apart is its ability to estimate both relative and absolute depth, a capability called “metric depth.”</p>



<p>This means that the model can provide real-world measurements, which is essential for applications like augmented reality (AR), where virtual objects need to be placed in precise locations within physical spaces.</p>



<p>And Depth Pro doesn’t require extensive training on domain-specific datasets to make accurate predictions—a feature known as “zero-shot learning.” This makes the model highly versatile. It can be applied to a wide range of images, without the need for the camera-specific data usually required in depth estimation models.</p>



<p>“Depth Pro produces metric depth maps with absolute scale on arbitrary images ‘in the wild’ without requiring metadata such as camera intrinsics,” the authors explain. This flexibility opens up a world of possibilities, from enhancing AR experiences to improving autonomous vehicles’ ability to detect and navigate obstacles.</p>



<p>For those curious to experience Depth Pro firsthand, a <a href="https://huggingface.co/spaces/akhaliq/depth-pro">live demo</a> is available on the Hugging Face platform.</p>



<figure><img decoding="async" width="1387" height="375" src="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50%E2%80%AFAM.png?w=800" alt="" srcset="https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png 1387w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=300,81 300w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=768,208 768w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=800,216 800w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=400,108 400w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=750,203 750w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=578,156 578w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-04-at-11.35.50 AM.png?resize=930,251 930w" sizes="(max-width: 1387px) 100vw, 1387px"/><figcaption>A comparison of depth estimation models across multiple datasets. Apple’s Depth Pro ranks highest overall with an average rank of 2.5, outperforming models like Depth Anything v2 and Metric3D in accuracy across diverse scenarios. (credit: arxiv.org)</figcaption></figure>



<h2 id="h-real-world-applications-from-e-commerce-to-autonomous-vehicles">Real-world applications: From e-commerce to autonomous vehicles</h2>



<p>This versatility has significant implications for various industries. In e-commerce, for example, Depth Pro could allow consumers to see how furniture fits in their home by simply pointing their phone’s camera at the room. In the automotive industry, the ability to generate real-time, high-resolution depth maps from a single camera could improve how self-driving cars perceive their environment, boosting navigation and safety.</p>



<p>“The method should ideally produce metric depth maps in this zero-shot regime to accurately reproduce object shapes, scene layouts, and absolute scales,” the researchers write, emphasizing the model’s potential to reduce the time and cost associated with training more conventional AI models.</p>



<h2 id="h-tackling-the-challenges-of-depth-estimation">Tackling the challenges of depth estimation</h2>



<p>One of the toughest challenges in depth estimation is handling what are known as “flying pixels”—pixels that appear to float in mid-air due to errors in depth mapping. Depth Pro tackles this issue head-on, making it particularly effective for applications like 3D reconstruction and virtual environments, where accuracy is paramount.</p>



<p>Additionally, Depth Pro excels in boundary tracing, outperforming previous models in sharply delineating objects and their edges. The researchers claim it surpasses other systems “by a multiplicative factor in boundary accuracy,” which is key for applications that require precise object segmentation, such as image matting and medical imaging.</p>



<h2 id="h-open-source-and-ready-to-scale">Open-source and ready to scale</h2>



<p>In a move that could accelerate its adoption, Apple has made Depth Pro open-source. The code, along with pre-trained model weights, is <a href="https://github.com/apple/ml-depth-pro" target="_blank" rel="noreferrer noopener">available on GitHub</a>, allowing developers and researchers to experiment with and further refine the technology. The repository includes everything from the model’s architecture to pretrained checkpoints, making it easy for others to build on Apple’s work.</p>



<p>The research team is also encouraging further exploration of Depth Pro’s potential in fields like robotics, manufacturing, and healthcare. “We release code and weights at <a href="https://github.com/apple/ml-depth-pro" target="_blank" rel="noreferrer noopener">https://github.com/apple/ml-depth-pro</a>,” the authors write, signaling this as just the beginning for the model.</p>



<h2 id="h-what-s-next-for-ai-depth-perception">What’s next for AI depth perception</h2>



<p>As artificial intelligence continues to push the boundaries of what’s possible, <em>Depth Pro</em> sets a new standard in speed and accuracy for monocular depth estimation. Its ability to generate high-quality, real-time depth maps from a single image could have wide-ranging effects across industries that rely on spatial awareness.</p>



<p>In a world where AI is increasingly central to decision-making and product development, <em>Depth Pro</em> exemplifies how cutting-edge research can translate into practical, real-world solutions. Whether it’s improving how machines perceive their surroundings or enhancing consumer experiences, the potential uses for <em>Depth Pro</em> are broad and varied.</p>



<p>As the researchers conclude, “Depth Pro dramatically outperforms all prior work in sharp delineation of object boundaries, including fine structures such as hair, fur, and vegetation.” With its open-source release, <em>Depth Pro</em> could soon become integral to industries ranging from autonomous driving to augmented reality—transforming how machines and people interact with 3D environments.</p>
<div id="boilerplate_2660155"><!-- wp:shortcode -->
		<div>
			<div>
				<p><strong>VB Daily</strong></p>
				<p>Stay in the know! Get the latest news in your inbox daily</p>
				
				<p>By subscribing, you agree to VentureBeat&#39;s <a href="https://venturebeat.com/terms-of-service/">Terms of Service.</a></p>
				<p id="boilerplateNewsletterConfirmation">
					Thanks for subscribing. Check out more <a href="https://venturebeat.com/newsletters/">VB newsletters here</a>.
				</p>
				<p>An error occured.</p>
			</div>
		</div>
		
<!-- /wp:shortcode --></div>			</div><!-- .article-content -->

							
			
		</article><!-- #content .article-wrapper -->

	</div></div>
  </body>
</html>
