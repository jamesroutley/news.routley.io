<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Forethought-Technologies/AutoChain">Original</a>
    <h1>AutoChain, lightweight and testable alternative to LangChain</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">Large language models (LLMs) have shown huge success in different text generation tasks and
enable developers to build generative agents based on objectives expressed in natural language.</p>
<p dir="auto">However, most generative agents require heavy customization for specific purposes, and
supporting different use cases can sometimes be overwhelming using existing tools
and frameworks. As a result, it is still very challenging to build a custom generative agent.</p>
<p dir="auto">In addition, evaluating such generative agents, which is usually done by manually trying different scenarios, is a very manual, repetitive, and expensive task.</p>
<p dir="auto">AutoChain takes inspiration from LangChain and AutoGPT and aims to solve
both problems by providing a lightweight and extensible framework
for developers to build their own agents using LLMs with custom tools and
<a href="#workflow-evaluation">automatically evaluating</a> different user scenarios with simulated
conversations. Experienced user of LangChain would find AutoChain is easy to navigate since
they share similar but simpler concepts.</p>
<p dir="auto">The goal is to enable rapid iteration on generative agents, both by simplifying agent customization and evaluation.</p>
<p dir="auto">If you have any questions, please feel free to reach out to Yi Lu <a href="mailto:yi.lu@forethought.ai">yi.lu@forethought.ai</a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-features" aria-hidden="true" href="#features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li><g-emoji alias="rocket" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png">ðŸš€</g-emoji> lightweight and extensible generative agent pipeline.</li>
<li><g-emoji alias="link" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f517.png">ðŸ”—</g-emoji> agent that can use different custom tools and
support OpenAI <a href="https://platform.openai.com/docs/guides/gpt/function-calling" rel="nofollow">function calling</a></li>
<li><g-emoji alias="floppy_disk" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4be.png">ðŸ’¾</g-emoji> simple memory tracking for conversation history and tools&#39; outputs</li>
<li><g-emoji alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png">ðŸ¤–</g-emoji> automated agent multi-turn conversation evaluation with simulated conversations</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-setup" aria-hidden="true" href="#setup"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setup</h2>
<p dir="auto">Quick install</p>

<p dir="auto">Or install from source after cloning this repository</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd autochain
pyenv virtualenv 3.10.11 venv
pyenv local venv

pip install ."><pre><span>cd</span> autochain
pyenv virtualenv 3.10.11 venv
pyenv <span>local</span> venv

pip install <span>.</span></pre></div>
<p dir="auto">Set <code>PYTHONPATH</code> and <code>OPENAI_API_KEY</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=
export PYTHONPATH=`pwd`"><pre><span>export</span> OPENAI_API_KEY=
<span>export</span> PYTHONPATH=<span><span>`</span>pwd<span>`</span></span></pre></div>
<p dir="auto">Run your first conversation with agent interactively</p>
<div dir="auto" data-snippet-clipboard-copy-content="python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py -i"><pre>python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py -i</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-how-does-autochain-simplify-building-agents" aria-hidden="true" href="#how-does-autochain-simplify-building-agents"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How does AutoChain simplify building agents?</h2>
<p dir="auto">AutoChain aims to provide a lightweight framework and simplifies the agent building process in a few
ways, as compared to existing frameworks</p>
<ol dir="auto">
<li>Easy prompt update</li>
<li>Up to 2 layers of abstraction</li>
<li>Automated multi-turn evaluation</li>
</ol>
<h2 tabindex="-1" dir="auto"><a id="user-content-example-usage" aria-hidden="true" href="#example-usage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example usage</h2>
<p dir="auto">If you have experience with LangChain, you already know 80% of the AutoChain interfaces.</p>
<p dir="auto">AutoChain aims to make building custom generative agents as straightforward as possible, with as little abstractions as possible.</p>
<p dir="auto">The most basic example uses the default chain and <code>ConversationalAgent</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from autochain.chain.chain import Chain
from autochain.memory.buffer_memory import BufferMemory
from autochain.models.chat_openai import ChatOpenAI
from autochain.agent.conversational_agent.conversational_agent import ConversationalAgent

llm = ChatOpenAI(temperature=0)
memory = BufferMemory()
agent = ConversationalAgent.from_llm_and_tools(llm=llm)
chain = Chain(agent=agent, memory=memory)

print(chain.run(&#34;Write me a poem about AI&#34;)[&#39;message&#39;])"><pre><span>from</span> <span>autochain</span>.<span>chain</span>.<span>chain</span> <span>import</span> <span>Chain</span>
<span>from</span> <span>autochain</span>.<span>memory</span>.<span>buffer_memory</span> <span>import</span> <span>BufferMemory</span>
<span>from</span> <span>autochain</span>.<span>models</span>.<span>chat_openai</span> <span>import</span> <span>ChatOpenAI</span>
<span>from</span> <span>autochain</span>.<span>agent</span>.<span>conversational_agent</span>.<span>conversational_agent</span> <span>import</span> <span>ConversationalAgent</span>

<span>llm</span> <span>=</span> <span>ChatOpenAI</span>(<span>temperature</span><span>=</span><span>0</span>)
<span>memory</span> <span>=</span> <span>BufferMemory</span>()
<span>agent</span> <span>=</span> <span>ConversationalAgent</span>.<span>from_llm_and_tools</span>(<span>llm</span><span>=</span><span>llm</span>)
<span>chain</span> <span>=</span> <span>Chain</span>(<span>agent</span><span>=</span><span>agent</span>, <span>memory</span><span>=</span><span>memory</span>)

<span>print</span>(<span>chain</span>.<span>run</span>(<span>&#34;Write me a poem about AI&#34;</span>)[<span>&#39;message&#39;</span>])</pre></div>
<p dir="auto">Just like in LangChain, you can add a list of tools to the agent</p>
<div dir="auto" data-snippet-clipboard-copy-content="tools = [
   Tool(
    name=&#34;Get weather&#34;,
    func=lambda *args, **kwargs: &#34;Today is a sunny day&#34;,
    description=&#34;&#34;&#34;This function returns the weather information&#34;&#34;&#34;
   )
]

memory = BufferMemory()
agent = ConversationalAgent.from_llm_and_tools(llm=llm, tools=tools)
chain = Chain(agent=agent, memory=memory)
print(chain.run(&#34;What is the weather today&#34;)[&#39;message&#39;])"><pre><span>tools</span> <span>=</span> [
   <span>Tool</span>(
    <span>name</span><span>=</span><span>&#34;Get weather&#34;</span>,
    <span>func</span><span>=</span><span>lambda</span> <span>*</span><span>args</span>, <span>**</span><span>kwargs</span>: <span>&#34;Today is a sunny day&#34;</span>,
    <span>description</span><span>=</span><span>&#34;&#34;&#34;This function returns the weather information&#34;&#34;&#34;</span>
   )
]

<span>memory</span> <span>=</span> <span>BufferMemory</span>()
<span>agent</span> <span>=</span> <span>ConversationalAgent</span>.<span>from_llm_and_tools</span>(<span>llm</span><span>=</span><span>llm</span>, <span>tools</span><span>=</span><span>tools</span>)
<span>chain</span> <span>=</span> <span>Chain</span>(<span>agent</span><span>=</span><span>agent</span>, <span>memory</span><span>=</span><span>memory</span>)
<span>print</span>(<span>chain</span>.<span>run</span>(<span>&#34;What is the weather today&#34;</span>)[<span>&#39;message&#39;</span>])</pre></div>
<p dir="auto">AutoChain also added support for <a href="https://platform.openai.com/docs/guides/gpt/function-calling" rel="nofollow">function calling</a>
in OpenAI models. Behind the scenes, it turns the function spec into OpenAI format without explicit
instruction, so you can keep following the same <code>Tool</code> interface you are familiar with.</p>
<div dir="auto" data-snippet-clipboard-copy-content="llm = ChatOpenAI(temperature=0)
agent = OpenAIFunctionsAgent.from_llm_and_tools(llm=llm, tools=tools)"><pre><span>llm</span> <span>=</span> <span>ChatOpenAI</span>(<span>temperature</span><span>=</span><span>0</span>)
<span>agent</span> <span>=</span> <span>OpenAIFunctionsAgent</span>.<span>from_llm_and_tools</span>(<span>llm</span><span>=</span><span>llm</span>, <span>tools</span><span>=</span><span>tools</span>)</pre></div>
<p dir="auto">See <a href="https://github.com/Forethought-Technologies/AutoChain/blob/main/docs/examples.md">more examples</a> under <code>autochain/examples</code> and <a href="https://github.com/Forethought-Technologies/AutoChain/blob/main/docs/workflow-evaluation.md">workflow
evaluation</a> test cases which can also be run interactively.</p>
<p dir="auto">Read more about detailed <a href="https://github.com/Forethought-Technologies/AutoChain/blob/main/docs/components_overview.md">components overview</a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-workflow-evaluation" aria-hidden="true" href="#workflow-evaluation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Workflow Evaluation</h2>
<p dir="auto">It is notoriously hard to evaluate generative agents in LangChain or AutoGPT. An agent&#39;s behavior
is nondeterministic and susceptible to small changes to the prompt or model. As such, it is
hard to know what effects an update to the agent will have on all relevant use cases.</p>
<p dir="auto">The current path for
evaluation is running the agent through a large number of preset queries and evaluate the
generated responses. However, that is limited to single turn conversation, general and not
specific to tasks and expensive to verify.</p>
<p dir="auto">To effectively evaluate agents, AutoChain introduces the workflow evaluation framework
which simulates the conversation between a generative agent and simulated users with LLM under
different user contexts and desired outcomes of the conversation. This way, we could add test
cases for different user scenarios and use LLMs to evaluate if multi-turn conversations reached
the desired outcome.</p>
<p dir="auto">To facilitate agent evaluation, AutoChain introduces the workflow evaluation framework. This framework runs conversations between a generative agent and LLM-simulated test users. The test users incorporate various user contexts and desired conversation outcomes, which enables easy addition of test cases for new user scenarios and fast evaluation. The framework leverages LLMs to evaluate whether a given multi-turn conversation has achieved the intended outcome.</p>
<p dir="auto">Read more about our <a href="https://github.com/Forethought-Technologies/AutoChain/blob/main/docs/workflow-evaluation.md">evaluation strategy</a>.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-how-to-run-workflow-evaluations" aria-hidden="true" href="#how-to-run-workflow-evaluations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to run workflow evaluations</h3>
<p dir="auto">You can either run your tests in interactive mode, or run the full suite of test cases at once.
<code>autochain/workflows_evaluation/conversational_agent_eval /change_shipping_address_test.py</code> contains a few example test cases.</p>
<p dir="auto">To run all the cases defined in a test file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py"><pre>python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py</pre></div>
<p dir="auto">To run your tests interactively <code>-i</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py -i"><pre>python autochain/workflows_evaluation/conversational_agent_eval/change_shipping_address_test.py -i</pre></div>
<p dir="auto">Looking for more details on how AutoChain works? See our <a href="https://github.com/Forethought-Technologies/AutoChain/blob/main/docs/components_overview.md">components overview</a></p>
</article>
          </div></div>
  </body>
</html>
