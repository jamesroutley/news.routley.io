<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/nat/openplayground">Original</a>
    <h1>An LLM playground you can run on your laptop</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">An LLM playground you can run on your laptop.</p>
<video src="https://user-images.githubusercontent.com/111631/227399583-39b23f48-9823-4571-a906-985dbe282b20.mp4" data-canonical-src="https://user-images.githubusercontent.com/111631/227399583-39b23f48-9823-4571-a906-985dbe282b20.mp4" controls="controls" muted="muted">

  </video>
<h4 tabindex="-1" dir="auto"><a id="user-content-features" aria-hidden="true" href="#features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h4>
<ul dir="auto">
<li>Use any model from <a href="https://reserialised.routley.io/nat/openplayground/blob/main">OpenAI</a>, <a href="https://reserialised.routley.io/nat/openplayground/blob/main">Anthropic</a>, <a href="https://reserialised.routley.io/nat/openplayground/blob/main">Cohere</a>, <a href="https://reserialised.routley.io/nat/openplayground/blob/main">Forefront</a>, <a href="https://reserialised.routley.io/nat/openplayground/blob/main">HuggingFace</a>, <a href="https://reserialised.routley.io/nat/openplayground/blob/main">Aleph Alpha</a>, and <a href="https://reserialised.routley.io/nat/openplayground/blob/main">llama.cpp</a>.</li>
<li>Full playground UI, including history, parameter tuning, keyboard shortcuts, and logprops.</li>
<li>Compare models side-by-side with the same prompt, individually tune model parameters, and retry with different paramaters.</li>
<li>Automatically detects local models in your HuggingFace cache, and lets you install new ones.</li>
<li>Works OK on your phone.</li>
<li>Probably won&#39;t kill everyone.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-try-on-natdev" aria-hidden="true" href="#try-on-natdev"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Try on nat.dev</h2>
<p dir="auto">Try the hosted version: <a href="https://nat.dev" rel="nofollow">nat.dev</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-how-to-install-and-run" aria-hidden="true" href="#how-to-install-and-run"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to install and run</h2>
<div dir="auto" data-snippet-clipboard-copy-content="$ pip install openplayground
$ openplayground run"><pre>$ pip install openplayground
$ openplayground run</pre></div>
<p dir="auto">This runs a Flask process, so you can add the typical flags such as setting a different port <code>openplayground run -p 1235</code> and others.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-how-to-run-for-development" aria-hidden="true" href="#how-to-run-for-development"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to run for development</h2>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone https://github.com/nat/openplayground
$ cd app &amp;&amp; npm install &amp;&amp; npx parcel watch src/index.html --no-cache
$ cd server &amp;&amp; pip3 install -r requirements.txt &amp;&amp; python app.py"><pre>$ git clone https://github.com/nat/openplayground
$ <span>cd</span> app <span>&amp;&amp;</span> npm install <span>&amp;&amp;</span> npx parcel watch src/index.html --no-cache
$ <span>cd</span> server <span>&amp;&amp;</span> pip3 install -r requirements.txt <span>&amp;&amp;</span> python app.py</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-ideas-for-contributions" aria-hidden="true" href="#ideas-for-contributions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Ideas for contributions</h2>
<ul dir="auto">
<li>Add a token counter to the playground</li>
<li>Add a cost counter to the playground and the compare page</li>
<li>Measure and display time to first token</li>
<li>Setup automatic builds with GitHub Actions</li>
<li>The default parameters for each model are configured in the <code>server/models.json</code> file. If you find better default parameters for a model, please submit a pull request!</li>
<li>Someone can help us make a homebrew package, and a dockerfile</li>
<li>Easier way to install open source models directly from openplayground, with <code>openplayground install &lt;model&gt;</code> or in the UI.</li>
<li>Find and fix bugs</li>
<li>ChatGPT UI, with turn-by-turn, markdown rendering, chatgpt plugin support, etc.</li>
<li>We will probably need multimodal inputs and outputs at some point in 2023</li>
</ul>
<h3 tabindex="-1" dir="auto"><a id="user-content-llamacpp" aria-hidden="true" href="#llamacpp"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>llama.cpp</h3>
<h2 tabindex="-1" dir="auto"><a id="user-content-adding-models-to-openplayground" aria-hidden="true" href="#adding-models-to-openplayground"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Adding models to openplayground</h2>
<p dir="auto">Models and providers have three types in openplayground:</p>
<ul dir="auto">
<li>Searchable</li>
<li>Local inference</li>
<li>API</li>
</ul>
<p dir="auto">You can add models in <code>server/models.json</code> with the following schema:</p>
<h4 tabindex="-1" dir="auto"><a id="user-content-local-inference" aria-hidden="true" href="#local-inference"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Local inference</h4>
<p dir="auto">For models running locally on your device you can add them to openplayground like the following (a minimal example):</p>
<div dir="auto" data-snippet-clipboard-copy-content="&#34;llama&#34;: {
    &#34;api_key&#34; : false,
    &#34;models&#34; : {
        &#34;llama-70b&#34;: {
            &#34;parameters&#34;: {
                &#34;temperature&#34;: {
                    &#34;value&#34;: 0.5,
                    &#34;range&#34;: [
                        0.1,
                        1.0
                    ]
                },
            }
        }
    }
}"><pre><span>&#34;llama&#34;</span>: {
    <span>&#34;api_key&#34;</span> : <span>false</span>,
    <span>&#34;models&#34;</span> : {
        <span>&#34;llama-70b&#34;</span>: {
            <span>&#34;parameters&#34;</span>: {
                <span>&#34;temperature&#34;</span>: {
                    <span>&#34;value&#34;</span>: <span>0.5</span>,
                    <span>&#34;range&#34;</span>: [
                        <span>0.1</span>,
                        <span>1.0</span>
                    ]
                },
            }
        }
    }
}</pre></div>
<p dir="auto">Keep in mind you will need to add a generation method for your model in <code>server/app.py</code>. Take a look at <code>local_text_generation()</code> as an example.</p>
<h4 tabindex="-1" dir="auto"><a id="user-content-api-provider-inference" aria-hidden="true" href="#api-provider-inference"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>API Provider Inference</h4>
<p dir="auto">This is for model providers like OpenAI, cohere, forefront, and more. You can connect them easily into openplayground (a minimal example):</p>
<div dir="auto" data-snippet-clipboard-copy-content="&#34;cohere&#34;: {
    &#34;api_key&#34; : true,
    &#34;models&#34; : {
        &#34;xlarge&#34;: {
            &#34;parameters&#34;: {
                &#34;temperature&#34;: {
                    &#34;value&#34;: 0.5,
                    &#34;range&#34;: [
                        0.1,
                        1.0
                    ]
                },
            }
        }
    }
}"><pre><span>&#34;cohere&#34;</span>: {
    <span>&#34;api_key&#34;</span> : <span>true</span>,
    <span>&#34;models&#34;</span> : {
        <span>&#34;xlarge&#34;</span>: {
            <span>&#34;parameters&#34;</span>: {
                <span>&#34;temperature&#34;</span>: {
                    <span>&#34;value&#34;</span>: <span>0.5</span>,
                    <span>&#34;range&#34;</span>: [
                        <span>0.1</span>,
                        <span>1.0</span>
                    ]
                },
            }
        }
    }
}</pre></div>
<p dir="auto">Keep in mind you will need to add a generation method for your model in <code>server/app.py</code>. Take a look at <code>openai_text_generation()</code> or <code>cohere_text_generation()</code> as an example.</p>
<h4 tabindex="-1" dir="auto"><a id="user-content-searchable-models" aria-hidden="true" href="#searchable-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Searchable models</h4>
<p dir="auto">We use this for Huggingface Remote Inference models, the search endpoint is useful for scaling to N models in the settings page.</p>
<div dir="auto" data-snippet-clipboard-copy-content="&#34;provider_name&#34;: {
    &#34;api_key&#34;: true,
    &#34;search&#34;: {
        &#34;endpoint&#34;: &#34;ENDPOINT_URL&#34;
    },
    &#34;parameters&#34;: {
        &#34;parameter&#34;: {
            &#34;value&#34;: 1.0,
            &#34;range&#34;: [
                0.1,
                1.0
            ]
        },
    }
}"><pre><span>&#34;provider_name&#34;</span>: {
    <span>&#34;api_key&#34;</span>: <span>true</span>,
    <span>&#34;search&#34;</span>: {
        <span>&#34;endpoint&#34;</span>: <span><span>&#34;</span>ENDPOINT_URL<span>&#34;</span></span>
    },
    <span>&#34;parameters&#34;</span>: {
        <span>&#34;parameter&#34;</span>: {
            <span>&#34;value&#34;</span>: <span>1.0</span>,
            <span>&#34;range&#34;</span>: [
                <span>0.1</span>,
                <span>1.0</span>
            ]
        },
    }
}</pre></div>
<h4 tabindex="-1" dir="auto"><a id="user-content-credits" aria-hidden="true" href="#credits"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Credits</h4>
<p dir="auto">Instigated by Nat Friedman. Initial implementation by <a href="https://github.com/zainhuda">Zain Huda</a> as a repl.it bounty. Many features and extensive refactoring by Alex Lourenco.</p>
</article>
          </div></div>
  </body>
</html>
