<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2023/Mar/27/ai-enhanced-development/">Original</a>
    <h1>AI-enhanced development makes me more ambitious with my projects</h1>
    
    <div id="readability-page-1" class="page"><div>




<p>The thing I’m most excited about in our weird new AI-enhanced reality is the way it allows me to be more <em>ambitious</em> with my projects.</p>
<p>As an experienced developer, ChatGPT (and GitHub Copilot) save me an enormous amount of “figuring things out” time. For everything from writing a for loop in Bash to remembering how to make a cross-domain CORS request in JavaScript—I don’t need to even look things up any more, I can just prompt it and get the right answer 80% of the time.</p>
<p>This doesn’t just make me more productive: it lowers my bar for when a project is worth investing time in at all.</p>
<p>In the past I’ve had plenty of ideas for projects which I’ve ruled out because they would take a day—or days—of work to get to a point where they’re useful. I have enough other stuff to build already!</p>
<p>But if ChatGPT can drop that down to an hour or less, those projects can suddenly become viable.</p>
<p>Which means I’m building all sorts of weird and interesting little things that previously I wouldn’t have invested the time in.</p>
<p>I’ll describe my latest one of these mini-projects in detail.</p>
<h4>Using ChatGPT to build a system to archive ChatGPT messages</h4>
<p>I use ChatGPT a lot, and I want my own archive of conversations I’ve had with it.</p>
<p>There’s no API for retrieving previous conversations at the moment, but if you open up the browser DevTools and watch the network tab you can see it loading JSON any time you navigate to an older conversation.</p>
<p><img src="https://static.simonwillison.net/static/2023/chatgpt-chrome-inspector-cropped.jpg" alt="ChatGPT with the Chrome inspector open. On the left is a conversation, on the right the Chrome inspector is showing the underlying JSON that was fetched for that conversation in the Network pane."/></p>
<p>This gave me an idea for a solution...</p>
<p>What if I could run some JavaScript on the ChatGPT site that grabbed that JSON data and sent it off to my own server?</p>
<p>I couldn’t find the raw data in JavaScript variables available to the console, so I came up with an alternative approach: could I patch the default <code>fetch()</code> function to intercept calls made by the ChatGPT code to that endpoint, and intercept the data that way?</p>
<p>Normally this is where the project would end. Figuring out how to patch <code>fetch()</code> like that is non-trivial—where I’m using the software engineer’s definition of “non-trivial” as meaning “I don’t know how to do that off the top of my head”. I’d have to do some thinking and research! I’m already tempted to drop this idea and work on something else.</p>
<p>But now I have ChatGPT... so I prompted it:</p>
<blockquote>
<p>Write a new JavaScript fetch() function which calls the old one but also saves the JSON that is retrieved—if it is used to retrieve JSON—in a window.fetchedData object</p>
</blockquote>
<p>It gave me some code, but it wasn’t quite what I wanted. So I added a follow-up prompt:</p>
<blockquote>
<p>No I need to replace the old window.fetch() function entirely—I want to patch it so that I can intercept calls made by other existing code</p>
</blockquote>
<p>And it produced the following:</p>
<div><pre><span>// Define a global object to store fetched JSON data</span>
<span>window</span><span>.</span><span>fetchedData</span> <span>=</span> <span>{</span><span>}</span><span>;</span>

<span>// Store a reference to the original fetch function</span>
<span>const</span> <span>originalFetch</span> <span>=</span> <span>window</span><span>.</span><span>fetch</span><span>;</span>

<span>// Define a new fetch function that wraps the original fetch</span>
<span>window</span><span>.</span><span>fetch</span> <span>=</span> <span>async</span> <span>function</span><span>(</span><span>url</span><span>,</span> <span>options</span><span>)</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>// Call the original fetch function</span>
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>originalFetch</span><span>(</span><span>url</span><span>,</span> <span>options</span><span>)</span><span>;</span>

    <span>// Check if the response has a JSON content type</span>
    <span>const</span> <span>contentType</span> <span>=</span> <span>response</span><span>.</span><span>headers</span><span>.</span><span>get</span><span>(</span><span>&#39;content-type&#39;</span><span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>contentType</span> <span>&amp;&amp;</span> <span>contentType</span><span>.</span><span>includes</span><span>(</span><span>&#39;application/json&#39;</span><span>)</span><span>)</span> <span>{</span>
      <span>// If the response is JSON, clone the response so we can read it twice</span>
      <span>const</span> <span>responseClone</span> <span>=</span> <span>response</span><span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
      <span>// Parse the JSON data and save it to the fetchedData object</span>
      <span>const</span> <span>jsonData</span> <span>=</span> <span>await</span> <span>responseClone</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span>
      <span>window</span><span>.</span><span>fetchedData</span><span>[</span><span>url</span><span>]</span> <span>=</span> <span>jsonData</span><span>;</span>
    <span>}</span>

    <span>// Return the original response</span>
    <span>return</span> <span>response</span><span>;</span>
  <span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    <span>// Handle any errors that occur during the fetch</span>
    <span>console</span><span>.</span><span>error</span><span>(</span><span>&#39;Error fetching and saving JSON:&#39;</span><span>,</span> <span>error</span><span>)</span><span>;</span>
    <span>throw</span> <span>error</span><span>;</span>
  <span>}</span>
<span>}</span><span>;</span></pre></div>
<p>That’s exactly what I wanted!</p>
<p>I pasted it into the DevTools console on the ChatGPT site and clicked on some links. It worked as intended.</p>
<p>Here’s <a href="https://gist.github.com/simonw/8fbade64a3606645243b3438930b8159">that full ChatGPT transcript</a> that got me to this point.</p>
<p>So now I have a prototype! I’ve proved to myself that I can intercept the JSON data fetched by ChatGPT’s own web application code.</p>
<p>I only wanted to run my code on requests that matched <code>https://chat.openai.com/backend-api/conversation/...</code>—I could write a regex for that, but I’d have to remember to escape the necessary characters. ChatGPT <a href="https://gist.github.com/simonw/103972b7eb0c1f45d536d0a0c04cb508">did that for me</a> too:</p>
<div><pre><span>const</span> <span>pattern</span> <span>=</span> <span><span>/</span><span>^</span>https:<span>\/</span><span>\/</span>chat<span>\.</span>openai<span>\.</span>com<span>\/</span>backend-api<span>\/</span>conversation<span>\/</span><span>/</span></span><span>;</span></pre></div>
<p>So now I have the key building blocks I need for my solution: I can intercept JSON fetches and then filter to just the data from the endpoint I care about.</p>
<h4>But I need CORS support</h4>
<p>My plan was to have my intercepting <code>fetch()</code> call POST the JSON data to my own <a href="https://datasette.cloud/">Datasette Cloud</a> instance, similar to how I record scraped Hacker News listings as described in <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">this post about Datasette’s new write API</a>.</p>
<p>One big problem: this means that code running on the <code>chat.openai.com</code> domain needs to POST JSON to another server. And that means the other server needs to be serving <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS headers</a>.</p>
<p>Datasette Cloud doesn’t (yet) support CORS—and I wasn’t about to implement a new production feature there just so I could solve a problem for this prototype.</p>
<p>What I really needed was some kind of CORS proxy... a URL running somewhere which forwards traffic on to Datasette Cloud but adds CORS headers to enable it to be called from elsewhere.</p>
<p>This represents another potential blocking point: do I really want to implement an entire proxy web application just for this little project?</p>
<p>Here’s my next ChatGPT prompt:</p>
<blockquote>
<p>Write a web app in python Starlette which has CORS enabled—including for the auth header—and forwards all incoming requests to any path to another server host specified in an environment variable</p>
</blockquote>
<p>I like <a href="https://www.starlette.io/">Starlette</a> and I know it has CORS support and is great for writing proxies. I was hopeful that GPT-4 had seen its documentation before the September 2021 cut-off date.</p>
<p>ChatGPT wrote me some very solid code! It used the <code>python-dotenv</code> package though, and I didn’t feel like using that dependency. So I added:</p>
<blockquote>
<p>Rewrite that to use os.environ</p>
</blockquote>
<p>The exception handling looked wrong to me, so I said:</p>
<blockquote>
<p>Catch httpx.HTTPError as the only exception you care about</p>
</blockquote>
<p>And after just those three prompts it produced the following:</p>
<pre><span>import</span> <span>os</span>
<span>from</span> <span>starlette</span>.<span>applications</span> <span>import</span> <span>Starlette</span>
<span>from</span> <span>starlette</span>.<span>middleware</span> <span>import</span> <span>Middleware</span>
<span>from</span> <span>starlette</span>.<span>middleware</span>.<span>cors</span> <span>import</span> <span>CORSMiddleware</span>
<span>from</span> <span>starlette</span>.<span>routing</span> <span>import</span> <span>Route</span>
<span>from</span> <span>starlette</span>.<span>requests</span> <span>import</span> <span>Request</span>
<span>from</span> <span>starlette</span>.<span>responses</span> <span>import</span> <span>JSONResponse</span>
<span>import</span> <span>httpx</span>

<span>TARGET_SERVER_HOST</span> <span>=</span> <span>os</span>.<span>environ</span>.<span>get</span>(<span>&#34;TARGET_SERVER_HOST&#34;</span>)

<span>middleware</span> <span>=</span> [
    <span>Middleware</span>(
        <span>CORSMiddleware</span>,
        <span>allow_origins</span><span>=</span>[<span>&#34;*&#34;</span>],
        <span>allow_credentials</span><span>=</span><span>True</span>,
        <span>allow_methods</span><span>=</span>[<span>&#34;*&#34;</span>],
        <span>allow_headers</span><span>=</span>[<span>&#34;*&#34;</span>],
    )
]

<span>app</span> <span>=</span> <span>Starlette</span>(<span>middleware</span><span>=</span><span>middleware</span>)

<span>async</span> <span>def</span> <span>forward_request</span>(<span>request</span>: <span>Request</span>):
    <span>try</span>:
        <span>async</span> <span>with</span> <span>httpx</span>.<span>AsyncClient</span>() <span>as</span> <span>client</span>:
            <span>target_url</span> <span>=</span> <span>f&#34;<span><span>{</span><span>TARGET_SERVER_HOST</span><span>}</span></span><span><span>{</span><span>request</span>.<span>url</span>.<span>path</span><span>}</span></span>&#34;</span>
            <span>method</span> <span>=</span> <span>request</span>.<span>method</span>
            <span>headers</span> <span>=</span> <span>dict</span>(<span>request</span>.<span>headers</span>)
            <span>if</span> <span>&#34;host&#34;</span> <span>in</span> <span>headers</span>:
                <span>del</span> <span>headers</span>[<span>&#34;host&#34;</span>]
            <span>if</span> <span>request</span>.<span>method</span> <span>in</span> [<span>&#34;POST&#34;</span>, <span>&#34;PUT&#34;</span>, <span>&#34;PATCH&#34;</span>]:
                <span>request_body</span> <span>=</span> <span>await</span> <span>request</span>.<span>json</span>()
            <span>else</span>:
                <span>request_body</span> <span>=</span> <span>None</span>

            <span>response</span> <span>=</span> <span>await</span> <span>client</span>.<span>request</span>(
                <span>method</span>, <span>target_url</span>, <span>headers</span><span>=</span><span>headers</span>, <span>json</span><span>=</span><span>request_body</span>
            )
            <span>return</span> <span>JSONResponse</span>(<span>response</span>.<span>json</span>(), <span>status_code</span><span>=</span><span>response</span>.<span>status_code</span>)
    <span>except</span> <span>httpx</span>.<span>HTTPError</span> <span>as</span> <span>e</span>:
        <span>return</span> <span>JSONResponse</span>({<span>&#34;error&#34;</span>: <span>str</span>(<span>e</span>)}, <span>status_code</span><span>=</span><span>500</span>)

<span>app</span>.<span>add_route</span>(<span>&#34;/{path:path}&#34;</span>, <span>forward_request</span>, <span>methods</span><span>=</span>[<span>&#34;GET&#34;</span>, <span>&#34;POST&#34;</span>, <span>&#34;PUT&#34;</span>, <span>&#34;PATCH&#34;</span>, <span>&#34;DELETE&#34;</span>])

<span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span>:
    <span>import</span> <span>uvicorn</span>

    <span>uvicorn</span>.<span>run</span>(<span>app</span>, <span>host</span><span>=</span><span>&#34;0.0.0.0&#34;</span>, <span>port</span><span>=</span><span>8000</span>)</pre>
<p>I tested this locally... and spotted a bug. It would fail with a 500 error if the incoming request included a <code>content-length</code> header. I fixed that myself by adding this code:</p>
<pre><span>if</span> <span>&#34;content-length&#34;</span> <span>in</span> <span>headers</span>:
    <span>del</span> <span>headers</span>[<span>&#34;content-length&#34;</span>]</pre>
<p>My <a href="https://gist.github.com/simonw/e0a5368d8b465febefe6d4ae6f47f2da">finished code is here</a>. Here’s <a href="https://gist.github.com/simonw/d95809e5a5c1441281cd5585270ab834">the ChatGPT transcript</a>.</p>
<p>I deployed this to Vercel using the method <a href="https://til.simonwillison.net/zeit-now/python-asgi-on-now-v2">described in this TIL</a>—and now I had a working proxy server.</p>
<h4>Creating the tables and a token</h4>
<p>ChatGPT had got me a long way. The rest of my implementation was now a small enough lift that I could quickly finish it by myself.</p>
<p>I created two tables in my Datasette Cloud instance by executing the following SQL (using the <a href="https://datasette.io/plugins/datasette-write">datasette-write</a> plugin):</p>
<div><pre><span>create</span> <span>table</span> <span>chatgpt_conversation</span> (
  id <span>text</span> <span>primary key</span>,
  title <span>text</span>,
  create_time float,
  moderation_results <span>text</span>,
  current_node <span>text</span>,
  plugin_ids <span>text</span>
);
<span>create</span> <span>table</span> <span>chatgpt_message</span> (
  id <span>text</span> <span>primary key</span>,
  conversation_id <span>text</span> <span>references</span> chatgpt_conversation(id),
  author_role <span>text</span>,
  author_metadata <span>text</span>,
  create_time float,
  content <span>text</span>,
  end_turn <span>integer</span>,
  weight float,
  metadata <span>text</span>,
  recipient <span>text</span>
);</pre></div>
<p>Then I made myself a Datasette API token with permission to <code>insert-row</code> and <code>update-row</code> just for those two tables, using the new <a href="https://simonwillison.net/2022/Dec/15/datasette-1a2/#finely-grained-permissions">finely grained permissions feature</a> in the 1.0 alpha series.</p>
<p>The last step was to combine this all together into a <code>fetch()</code> function that did the right thing. I wrote this code by hand, using the ChatGPT prototype as a starting point:</p>
<div><pre><span>const</span> <span>TOKEN</span> <span>=</span> <span>&#34;dstok_my-token-here&#34;</span><span>;</span>

<span>// Store a reference to the original fetch function</span>
<span>window</span><span>.</span><span>originalFetch</span> <span>=</span> <span>window</span><span>.</span><span>fetch</span><span>;</span>

<span>// Define a new fetch function that wraps the original fetch</span>

<span>window</span><span>.</span><span>fetch</span> <span>=</span> <span>async</span> <span>function</span> <span>(</span><span>url</span><span>,</span> <span>options</span><span>)</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>// Call the original fetch function</span>
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>originalFetch</span><span>(</span><span>url</span><span>,</span> <span>options</span><span>)</span><span>;</span>

    <span>// Check if the response has a JSON content type</span>
    <span>const</span> <span>contentType</span> <span>=</span> <span>response</span><span>.</span><span>headers</span><span>.</span><span>get</span><span>(</span><span>&#34;content-type&#34;</span><span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>contentType</span> <span>&amp;&amp;</span> <span>contentType</span><span>.</span><span>includes</span><span>(</span><span>&#34;application/json&#34;</span><span>)</span><span>)</span> <span>{</span>
      <span>// If the response is JSON, clone the response so we can read it twice</span>
      <span>const</span> <span>responseClone</span> <span>=</span> <span>response</span><span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
      <span>// Parse the JSON data and save it to the fetchedData object</span>
      <span>const</span> <span>jsonData</span> <span>=</span> <span>await</span> <span>responseClone</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span>
      <span>// NOW: if url for https://chat.openai.com/backend-api/conversation/...</span>
      <span>// do something very special with it</span>
      <span>const</span> <span>pattern</span> <span>=</span>
        <span><span>/</span><span>^</span>https:<span>\/</span><span>\/</span>chat<span>\.</span>openai<span>\.</span>com<span>\/</span>backend-api<span>\/</span>conversation<span>\/</span><span>(</span>.<span>*</span><span>)</span><span>/</span></span><span>;</span>
      <span>const</span> <span>match</span> <span>=</span> <span>url</span><span>.</span><span>match</span><span>(</span><span>pattern</span><span>)</span><span>;</span>
      <span>if</span> <span>(</span><span>match</span><span>)</span> <span>{</span>
        <span>const</span> <span>conversationId</span> <span>=</span> <span>match</span><span>[</span><span>1</span><span>]</span><span>;</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>&#34;conversationId&#34;</span><span>,</span> <span>conversationId</span><span>)</span><span>;</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>&#34;jsonData&#34;</span><span>,</span> <span>jsonData</span><span>)</span><span>;</span>
        <span>const</span> <span>conversation</span> <span>=</span> <span>{</span>
          <span>id</span>: <span>conversationId</span><span>,</span>
          <span>title</span>: <span>jsonData</span><span>.</span><span>title</span><span>,</span>
          <span>create_time</span>: <span>jsonData</span><span>.</span><span>create_time</span><span>,</span>
          <span>moderation_results</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>jsonData</span><span>.</span><span>moderation_results</span><span>)</span><span>,</span>
          <span>current_node</span>: <span>jsonData</span><span>.</span><span>current_node</span><span>,</span>
          <span>plugin_ids</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>jsonData</span><span>.</span><span>plugin_ids</span><span>)</span><span>,</span>
        <span>}</span><span>;</span>
        <span>fetch</span><span>(</span>
          <span>&#34;https://starlette-cors-proxy-simonw-datasette.vercel.app/data/chatgpt_conversation/-/insert&#34;</span><span>,</span>
          <span>{</span>
            <span>method</span>: <span>&#34;POST&#34;</span><span>,</span>
            <span>headers</span>: <span>{</span>
              <span>&#34;Content-Type&#34;</span>: <span>&#34;application/json&#34;</span><span>,</span>
              <span>Authorization</span>: <span>`Bearer <span><span>${</span><span>TOKEN</span><span>}</span></span>`</span><span>,</span>
            <span>}</span><span>,</span>
            <span>mode</span>: <span>&#34;cors&#34;</span><span>,</span>
            <span>body</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
              <span>row</span>: <span>conversation</span><span>,</span>
              <span>replace</span>: <span>true</span><span>,</span>
            <span>}</span><span>)</span><span>,</span>
          <span>}</span>
        <span>)</span>
          <span>.</span><span>then</span><span>(</span><span>(</span><span>d</span><span>)</span> <span>=&gt;</span> <span>d</span><span>.</span><span>json</span><span>(</span><span>)</span><span>)</span>
          <span>.</span><span>then</span><span>(</span><span>(</span><span>d</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>&#34;d&#34;</span><span>,</span> <span>d</span><span>)</span><span>)</span><span>;</span>
        <span>const</span> <span>messages</span> <span>=</span> <span>Object</span><span>.</span><span>values</span><span>(</span><span>jsonData</span><span>.</span><span>mapping</span><span>)</span>
          <span>.</span><span>filter</span><span>(</span><span>(</span><span>m</span><span>)</span> <span>=&gt;</span> <span>m</span><span>.</span><span>message</span><span>)</span>
          <span>.</span><span>map</span><span>(</span><span>(</span><span>message</span><span>)</span> <span>=&gt;</span> <span>{</span>
            <span>m</span> <span>=</span> <span>message</span><span>.</span><span>message</span><span>;</span>
            <span>let</span> <span>content</span> <span>=</span> <span>&#34;&#34;</span><span>;</span>
            <span>if</span> <span>(</span><span>m</span><span>.</span><span>content</span><span>)</span> <span>{</span>
              <span>if</span> <span>(</span><span>m</span><span>.</span><span>content</span><span>.</span><span>text</span><span>)</span> <span>{</span>
                <span>content</span> <span>=</span> <span>m</span><span>.</span><span>content</span><span>.</span><span>text</span><span>;</span>
              <span>}</span> <span>else</span> <span>{</span>
                <span>content</span> <span>=</span> <span>m</span><span>.</span><span>content</span><span>.</span><span>parts</span><span>.</span><span>join</span><span>(</span><span>&#34;\n&#34;</span><span>)</span><span>;</span>
              <span>}</span>
            <span>}</span>
            <span>return</span> <span>{</span>
              <span>id</span>: <span>m</span><span>.</span><span>id</span><span>,</span>
              <span>conversation_id</span>: <span>conversationId</span><span>,</span>
              <span>author_role</span>: <span>m</span><span>.</span><span>author</span> ? <span>m</span><span>.</span><span>author</span><span>.</span><span>role</span> : <span>null</span><span>,</span>
              <span>author_metadata</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span>
                <span>m</span><span>.</span><span>author</span> ? <span>m</span><span>.</span><span>author</span><span>.</span><span>metadata</span> : <span>{</span><span>}</span>
              <span>)</span><span>,</span>
              <span>create_time</span>: <span>m</span><span>.</span><span>create_time</span><span>,</span>
              <span>content</span>: <span>content</span><span>,</span>
              <span>end_turn</span>: <span>m</span><span>.</span><span>end_turn</span><span>,</span>
              <span>weight</span>: <span>m</span><span>.</span><span>weight</span><span>,</span>
              <span>metadata</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>m</span><span>.</span><span>metadata</span><span>)</span><span>,</span>
              <span>recipient</span>: <span>m</span><span>.</span><span>recipient</span><span>,</span>
            <span>}</span><span>;</span>
          <span>}</span><span>)</span><span>;</span>
        <span>fetch</span><span>(</span>
          <span>&#34;https://starlette-cors-proxy-simonw-datasette.vercel.app/data/chatgpt_message/-/insert&#34;</span><span>,</span>
          <span>{</span>
            <span>method</span>: <span>&#34;POST&#34;</span><span>,</span>
            <span>headers</span>: <span>{</span>
              <span>&#34;Content-Type&#34;</span>: <span>&#34;application/json&#34;</span><span>,</span>
              <span>Authorization</span>: <span>`Bearer <span><span>${</span><span>TOKEN</span><span>}</span></span>`</span><span>,</span>
            <span>}</span><span>,</span>
            <span>mode</span>: <span>&#34;cors&#34;</span><span>,</span>
            <span>body</span>: <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
              <span>rows</span>: <span>messages</span><span>,</span>
              <span>replace</span>: <span>true</span><span>,</span>
            <span>}</span><span>)</span><span>,</span>
          <span>}</span>
        <span>)</span>
          <span>.</span><span>then</span><span>(</span><span>(</span><span>d</span><span>)</span> <span>=&gt;</span> <span>d</span><span>.</span><span>json</span><span>(</span><span>)</span><span>)</span>
          <span>.</span><span>then</span><span>(</span><span>(</span><span>d</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>&#34;d&#34;</span><span>,</span> <span>d</span><span>)</span><span>)</span><span>;</span>
      <span>}</span>
    <span>}</span>

    <span>// Return the original response</span>
    <span>return</span> <span>response</span><span>;</span>
  <span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    <span>// Handle any errors that occur during the fetch</span>
    <span>console</span><span>.</span><span>error</span><span>(</span><span>&#34;Error fetching and saving JSON:&#34;</span><span>,</span> <span>error</span><span>)</span><span>;</span>
    <span>throw</span> <span>error</span><span>;</span>
  <span>}</span>
<span>}</span><span>;</span></pre></div>
<p>The fiddly bit here was writing the JavaScript that reshaped the ChatGPT JSON into the <code>rows: [array-of-objects]</code> format needed by the <a href="https://docs.datasette.io/en/1.0a2/json_api.html#the-json-write-api">Datasette JSON APIs</a>. I could probably have gotten ChatGPT to help with that—but in this case I pasted the SQL schema into a comment and let GitHub Copilot auto-complete parts of the JavaScript for me as I typed it.</p>
<h4>And it works</h4>
<p>Now I can paste the above block of code into the browser console on <code>chat.openai.com</code> and any time I click on one of my older conversations in the sidebar the <code>fetch()</code> will be intercepted and the JSON data will be saved to my Datasette Cloud instance.</p>
<h4>A public demo</h4>
<p>I’ve set up a public demo exposing messages from selected conversations here:</p>
<p><a href="https://simon.datasette.cloud/data/chatgpt_public_messages?_facet=conversation">simon.datasette.cloud/data/chatgpt_public_messages</a></p>
<p>The demo itself is powered by an extra table (listing the conversations that should be public) and a SQL view.</p>
<p>I used the <code>datasette-write</code> plugin again to create these:</p>
<div><pre><span>create</span> <span>table</span> <span>chatgpt_public</span> (id <span>text</span> <span>primary key</span>);

<span>create</span> <span>view</span> <span>chatgpt_public_messages</span> <span>as</span> <span>select</span>
  <span>chatgpt_message</span>.<span>id</span>,
  <span>chatgpt_conversation</span>.<span>title</span> <span>||</span> <span>char</span>(<span>10</span>) <span>||</span> <span>chatgpt_conversation</span>.<span>id</span> <span>as</span> conversation,
  <span>chatgpt_message</span>.<span>author_role</span>,
  <span>chatgpt_message</span>.<span>content</span>,
  datetime(<span>chatgpt_message</span>.<span>create_time</span>, <span><span>&#39;</span>unixepoch<span>&#39;</span></span>) <span>as</span> create_time
<span>from</span>
  chatgpt_message <span>join</span> chatgpt_conversation <span>on</span> conversation_id <span>=</span> <span>chatgpt_conversation</span>.<span>id</span>
<span>where</span>
  <span>chatgpt_message</span>.<span>create_time</span> <span>is not null</span>
  <span>and</span> conversation_id <span>in</span> (<span>select</span> id <span>from</span> chatgpt_public)
<span>order by</span>
  <span>chatgpt_message</span>.<span>create_time</span></pre></div>
<p>Then I set the <code>chatgpt_public_messages</code> view to be public (using <a href="https://datasette.io/plugins/datasette-public">datasette-public</a>).</p>
<p>Now I can insert conversation IDs into that <code>chatgpt_public</code> table to expose their messages in the public view.</p>
<p>This is the first time I’ve used a SQL view like this to selectively publish data from a private larger table, and I think it’s a really neat pattern. I’d like to make it easier to do without writing custom SQL though!</p>
<h4>It’s a lot more than just this project</h4>
<p>This ChatGPT archiving problem is just one example from the past few months of things I’ve built that I wouldn’t have tackled without AI-assistance.</p>
<p>It took me longer to write this up than it did to implement the entire project from start to finish!</p>
<p>When evaluating if a new technology is worth learning and adopting, I have two criteria:</p>
<ol>
<li>Does this let me build things that would have been impossible to build without it?</li>
<li>Can this reduce the effort required for some projects such that they tip over from “not worth it” to “worth it” and I end up building them?</li>
</ol>
<p>Large language models like GPT3/4/LLaMA/Claude etc clearly meet both of those criteria—and their impact on point two keeps on getting stronger for me.</p>
<h4>Some more examples</h4>
<p>Here are a few more examples of projects I’ve worked on recently that wouldn’t have happened without at least some level of AI assistance:</p>
<ul>
<li>I used ChatGPT to <a href="https://simonwillison.net/2023/Mar/24/datasette-chatgpt-plugin/">generate me the OpenAI schema</a> I needed to build the <a href="https://datasette.io/plugins/datasette-chatgpt-plugin">datasette-chatgpt-plugin</a> plugin, allowing human language questions in ChatGPT to be answered by SQL queries executed against Datasette.</li>
<li>
<a href="https://til.simonwillison.net/gpt3/chatgpt-applescript">Using ChatGPT to write AppleScript</a> describes how I used ChatGPT to finally figure out enough AppleScript to liberate my notes data, resulting in building <a href="https://datasette.io/tools/apple-notes-to-sqlite">apple-notes-to-sqlite</a>.</li>
<li>
<code>datasette-paste-table</code> isn’t in a usable state yet, but I built the first interactive prototype for that <a href="https://github.com/simonw/datasette-paste-table/issues/1">using ChatGPT</a>.</li>
<li>
<a href="https://til.simonwillison.net/jq/git-log-json">Convert git log output to JSON using jq</a> is something I figured out using ChatGPT—<a href="https://gist.github.com/simonw/c3b486fa90d7c32a0e8dfb47e151090a">transcript here</a>.</li>
<li>
<a href="https://simonwillison.net/2022/Dec/5/rust-chatgpt-copilot/">Learning Rust with ChatGPT, Copilot and Advent of Code</a> describes one of my earlier efforts to use ChatGPT to help learn a completely new (to me) programming language.</li>
</ul>




</div></div>
  </body>
</html>
