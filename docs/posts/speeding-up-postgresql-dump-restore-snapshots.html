<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://xata.io/blog/behind-the-scenes-speeding-up-pgstream-snapshots-for-postgresql">Original</a>
    <h1>Speeding up PostgreSQL dump/restore snapshots</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p>The last few <a href="https://github.com/xataio/pgstream"><code>pgstream</code></a> releases have focused on optimizing snapshot performance, specifically for PostgreSQL targets. In this blog post, we‚Äôll walk through the key improvements we made, share the lessons we learnt, and explain how they led to significant performance gains. But first, some context!</p><h2><strong>What is pgstream?</strong></h2><p><code>pgstream</code> is an open source CDC(Change Data Capture) tool and library that offers Postgres replication support with DDL changes. Some of its key features include:</p><ul><li value="1"><strong>Replication of DDL changes</strong>: schema changes are tracked and seamlessly replicated downstream alongside the data, avoiding manual intervention and data loss.</li><li value="2"><strong>Modular deployment configuration</strong>: pgstream modular implementation allows it to be configured for simple use cases, removing unnecessary complexity and deployment challenges. However, it can also easily integrate with Kafka for more complex use cases.</li><li value="3"><strong>Out of the box supported targets</strong>:</li><li value="4"><ul><li value="1">Postgres: replication to Postgres databases with support for schema changes and batch processing.</li><li value="2">Elasticsearch/Opensearch: replication to search stores with special handling of field IDs to minimise re-indexing.</li><li value="3">Webhooks: subscribe and receive webhook notifications whenever your source data changes.</li></ul></li><li value="4"><strong>Snapshots</strong>: capture a consistent view of your Postgres database at a specific point in time, either as an initial snapshot before starting replication or as a standalone process when replication is not needed.</li><li value="5"><strong>Column transformations</strong>: modify column values during replication or snapshots, which is particularly useful for anonymizing sensitive data.</li></ul><p>For more details on how pgstream works under the hood, check out the full <a href="https://github.com/xataio/pgstream/blob/main/docs/README.md">documentation</a>.</p><h2>üîç The Original Implementation</h2><p>The snapshot phase is a critical part of logical replication. It captures a consistent view of the source database to initialize the target and needs to complete reasonably fast without putting too much strain on the source. Otherwise, onboarding existing databases, especially large or busy ones, becomes slow, disruptive, or outright unfeasible.</p><p>The snapshot process involves four main steps:</p><ul><li value="1">Capturing the source PostgreSQL database schema</li><li value="2">Restoring the source schema into the target PostgreSQL database</li><li value="3">Reading data from the source PostgreSQL database</li><li value="4">Writing that data into the target PostgreSQL database</li></ul><p>Let‚Äôs take a closer look at how we originally implemented each part.</p><h3>Schema</h3><p>PostgreSQL schemas can get pretty complex, with lots of different elements to account for. While <code>pgstream</code> captures a simplified version of the schema to support DDL replication, that view isn‚Äôt detailed enough to rely on for full database snapshots. Instead of reinventing the wheel, we decided to lean on <a href="https://www.postgresql.org/docs/current/app-pgdump.html"><code>pg_dump</code></a>/<a href="https://www.postgresql.org/docs/current/app-pgrestore.html"><code>pg_restore</code></a>, the trusted native tools that already handle this job well. Their flexible options let us fine-tune exactly what kind of schema dump we need, depending on the situation.</p><h3>Reads</h3><p><code>pgstream</code> uses PostgreSQL‚Äôs <a href="https://www.postgresql.org/docs/current/sql-set-transaction.html">transaction snapshot</a> mechanism to get a consistent, read-only view of the database. This stable snapshot allows for parallelism at multiple levels: it enables concurrent table snapshots and even intra-table parallelism by scanning partitions or row ranges via the <a href="https://www.postgresql.org/docs/current/ddl-system-columns.html#DDL-SYSTEM-COLUMNS-CTID"><code>ctid</code></a>. Since <code>ctid</code> reflects a row‚Äôs physical location, we can use it to perform efficient and deterministic range queries, no indexes needed.</p><p>The level of parallelism is configurable, so users can tune the trade-off between speed and resource usage to suit their environment. This design takes inspiration from systems like <a href="https://duckdb.org/2022/09/30/postgres-scanner.html#parallel">DuckDB</a> and <a href="https://blog.peerdb.io/parallelized-initial-load-for-cdc-based-streaming-from-postgres">PeerDB</a>, which use similar techniques to achieve fast, low-impact snapshots.</p><h3>Writes</h3><p>The initial implementation of the PostgreSQL writer batched multiple row events (i.e., <code>INSERT</code> queries) into transactions. It would flush a batch either when a configured batch size was reached or after a timeout. Maintaining the order of operations is important in a replication scenario, so batching helped reduce I/O while preserving that order.</p><div><div><picture><img alt="" loading="lazy" width="1548" height="1092" decoding="async" data-nimg="1" sizes="(max-width: 1920px) 3840w, (max-width: 1536px) 3072w, (max-width: 1280px) 2560w, (max-width: 1024px) 2048w, (max-width: 768px) 1536w, (max-width: 640px) 1280w" srcset="/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=16&amp;q=100 16w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=32&amp;q=100 32w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=48&amp;q=100 48w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=64&amp;q=100 64w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=96&amp;q=100 96w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=128&amp;q=100 128w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=256&amp;q=100 256w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=384&amp;q=100 384w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=640&amp;q=100 640w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=750&amp;q=100 750w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=828&amp;q=100 828w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=1080&amp;q=100 1080w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=1200&amp;q=100 1200w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=1920&amp;q=100 1920w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=2048&amp;q=100 2048w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=3840&amp;q=100 3840w" src="https://xata.io/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_replication_sequence_diagram.png&amp;w=3840&amp;q=100"/></picture></div></div><h2>‚ö†Ô∏è The Problem</h2><p>We quickly saw that snapshot performance was lagging, especially compared to how effortlessly <a href="https://www.postgresql.org/docs/current/app-pgdump.html"><code>pg_dump</code></a>/<a href="https://www.postgresql.org/docs/current/app-pgrestore.html"><code>pg_restore</code></a> handled the same databases. While those tools are finely tuned for PostgreSQL, our goal was for <code>pgstream</code> to be a real contender: just as fast, but with bonus features like column transformations and built-in schema replication. So, we rolled up our sleeves and went performance hunting. üèπ</p><p>After releasing better observability tools in <a href="https://xata.io/blog/pgstream-v060-update">v0.6.0</a> üî≠, the culprit became obvious: the bottleneck was in the write path.</p><p>The read side was already following a tried-and-tested model for performance, but the write logic was initially geared toward low-throughput replication - not bulk data loads.</p><h2>‚öôÔ∏è The Solution</h2><p>Once we confirmed that writes were slowing us down, we started looking at ways to improve write performance <em>just</em> for snapshots, without impacting the replication writer.</p><h3>Bulk Ingest</h3><p>During a snapshot, we‚Äôre only issuing <code>INSERT</code> statements, and we disable triggers to prevent foreign key checks, so we don&#39;t need to worry about row order. That gave us some flexibility to explore better write strategies for insert-heavy loads.</p><p>PostgreSQL supports several ways to insert data:</p><ul><li value="1">Individual <code>INSERT</code> statements (original approach)</li></ul><ul><li value="1">Batch <code>INSERT</code> statements</li></ul><ul><li value="1"><code>COPY FROM</code> (supports formats like CSV and binary)</li></ul><p>This <a href="https://www.tigerdata.com/learn/testing-postgres-ingest-insert-vs-batch-insert-vs-copy">TigerData blog post</a> benchmarks these methods and‚Äîspoiler alert‚Äî<code>COPY FROM</code> is by far the fastest for bulk inserts.</p><p>We implemented both batch <code>INSERT</code> and binary <code>COPY FROM</code>, then tested them against the <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2QYZBT">IMDb dataset</a> (21 tables, ~9GB). Using 4 tables in parallel with 4 workers each, the results clearly showed that binary <code>COPY FROM</code> was the way to go.</p><div><div><picture><img alt="" loading="lazy" width="994" height="1072" decoding="async" data-nimg="1" sizes="(max-width: 1920px) 3840w, (max-width: 1536px) 3072w, (max-width: 1280px) 2560w, (max-width: 1024px) 2048w, (max-width: 768px) 1536w, (max-width: 640px) 1280w" srcset="/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=16&amp;q=100 16w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=32&amp;q=100 32w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=48&amp;q=100 48w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=64&amp;q=100 64w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=96&amp;q=100 96w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=128&amp;q=100 128w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=256&amp;q=100 256w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=384&amp;q=100 384w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=640&amp;q=100 640w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=750&amp;q=100 750w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=828&amp;q=100 828w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=1080&amp;q=100 1080w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=1200&amp;q=100 1200w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=1920&amp;q=100 1920w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=2048&amp;q=100 2048w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=3840&amp;q=100 3840w" src="https://xata.io/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_ingest.png&amp;w=3840&amp;q=100"/></picture></div></div><h3>Deferred index creation</h3><p>With faster inserts in place, we ran tests on more complex schemas. That‚Äôs when we noticed something: the gains were less impressive on databases with lots of indexes and foreign key constraints. In fact, we were still a bit slower than <code>pg_dump</code>/<code>pg_restore</code>, although getting close.</p><p>The reason? <code>pg_dump</code>/<code>pg_restore</code> postpones index and constraint creation until after the data load. This avoids the overhead of updating indexes and validating constraints during inserts.</p><p>Since the snapshot process doesn‚Äôt require validating foreign keys or check constraints mid-import, we borrowed this pattern. We isolated index/constraint/trigger creation and moved it to after the data load. Testing against the same IMDb dataset showed a significant win; <code>pgstream</code> snapshots were now faster than <code>pg_dump</code>/<code>pg_restore</code>!</p><div><div><picture><img alt="" loading="lazy" width="996" height="1096" decoding="async" data-nimg="1" sizes="(max-width: 1920px) 3840w, (max-width: 1536px) 3072w, (max-width: 1280px) 2560w, (max-width: 1024px) 2048w, (max-width: 768px) 1536w, (max-width: 640px) 1280w" srcset="/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=16&amp;q=100 16w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=32&amp;q=100 32w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=48&amp;q=100 48w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=64&amp;q=100 64w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=96&amp;q=100 96w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=128&amp;q=100 128w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=256&amp;q=100 256w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=384&amp;q=100 384w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=640&amp;q=100 640w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=750&amp;q=100 750w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=828&amp;q=100 828w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=1080&amp;q=100 1080w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=1200&amp;q=100 1200w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=1920&amp;q=100 1920w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=2048&amp;q=100 2048w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=3840&amp;q=100 3840w" src="https://xata.io/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_perf_comparison_deferred_index.png&amp;w=3840&amp;q=100"/></picture></div></div><h3>Automatic Batch Configuration</h3><p>Now that we had solid ingest performance, we turned to improving the snapshot configuration itself.</p><p>Originally, the read side partitioned tables using a configurable number of rows per batch. But that approach has a problem: not all pages (which are relied upon for the ctid range scan described above) have the same number of rows. For example, if one table has 10 rows per page and another has 1000 rows per page, a batch size of 10000 rows per batch would retrieve 1000 pages for the first table and 10 for the second. That leads to wildly inconsistent memory usage and performance.</p><p>To fix this, we changed the config to specify <em>data size per batch</em> instead of <em>number of rows per batch</em>. Internally, we compute the average page count for each table and adjust the batch size accordingly, so every batch reads a consistent amount of data.</p><p>While this tweak didn‚Äôt lead to massive performance gains, it made snapshots more predictable and better at handling mixed workloads with different table shapes.</p><p>We considered doing something similar on the writer side, but since we‚Äôd already met our performance goals, we decided to pause there and revisit if needed.</p><h2>üìä Benchmarks</h2><p>With all the improvements in place, let&#39;s review the results for a couple of different sized datasets, using <code>pg_dump</code>/<code>pg_restore</code> as baseline.</p><div><div><picture><img alt="" loading="lazy" width="1048" height="952" decoding="async" data-nimg="1" sizes="(max-width: 1920px) 3840w, (max-width: 1536px) 3072w, (max-width: 1280px) 2560w, (max-width: 1024px) 2048w, (max-width: 768px) 1536w, (max-width: 640px) 1280w" srcset="/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=16&amp;q=100 16w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=32&amp;q=100 32w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=48&amp;q=100 48w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=64&amp;q=100 64w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=96&amp;q=100 96w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=128&amp;q=100 128w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=256&amp;q=100 256w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=384&amp;q=100 384w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=640&amp;q=100 640w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=750&amp;q=100 750w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=828&amp;q=100 828w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=1080&amp;q=100 1080w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=1200&amp;q=100 1200w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=1920&amp;q=100 1920w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=2048&amp;q=100 2048w, /_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=3840&amp;q=100 3840w" src="https://xata.io/_next/image?url=https%3A%2F%2Fxata.io%2Fapi%2Fmedia%2Ffile%2Fpgstream_snapshot_final_bench.png&amp;w=3840&amp;q=100"/></picture></div></div><p>Datasets used: <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2QYZBT">IMDB database</a>, <a href="https://musicbrainz.org/doc/MusicBrainz_Database">MusicBrainz database</a>, <a href="https://github.com/PeerDB-io/ab-scale-testing/tree/main">Firenibble database</a>.</p><h2>‚úÖ Conclusion</h2><p>As with most performance wins, they can seem obvious once you know the answer - but it‚Äôs funny how often small, simple changes make a big difference when applied in the right context. For us, it came down to having good visibility into what was happening, spotting specific workload patterns, and tuning for those instead of trying to force a one-size-fits-all solution.</p><p>The result? <code>pgstream</code> is now faster, smarter, and more robust when it comes to onboarding large or complex PostgreSQL databases, while still offering the flexibility of logical replication.</p><p>If you have ideas or suggestions on how we can make pgstream snapshots even faster, we‚Äôd love to hear from you! üöÄ </p><p>You can reach out to us on <a href="https://xata.io/discord">Discord</a> or follow us on <a href="https://twitter.com/xata">X / Twitter</a> or <a href="https://bsky.app/profile/xata.io">Bluesky</a>. We welcome any feedback in <a href="https://github.com/xataio/pgstream/issues">issues</a>, or contributions via <a href="https://github.com/xataio/pgstream/pulls">pull requests</a>! üíú</p><p>Ready to get started? Check out the <a href="https://github.com/xataio/pgstream">pgstream documentation</a> for more details.</p></div></div></div></div>
  </body>
</html>
