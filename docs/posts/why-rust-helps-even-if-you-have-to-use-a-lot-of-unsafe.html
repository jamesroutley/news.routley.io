<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://v5.chriskrycho.com/journal/unsafe/">Original</a>
    <h1>Why Rust helps even if you have to use a lot of `unsafe`</h1>
    
    <div id="readability-page-1" class="page"><div>
      


<p>
      <b><a href="https://v4.chriskrycho.com/2018/assumed-audiences.html">Assumed audience</a>:</b>
      People at least vaguely familiar with the tradeoffs around memory safety in “systems” languages like Rust, C++, Zig, Odin, etc.

   </p><p>I semi-regularly hear from developers who claim that using Rust for their systems-level code would not gain them anything because they would have to use <code>unsafe</code> extensively in their code base. But this is not true. Even in software which makes extensive use of Rust’s <code>unsafe</code> keyword and features, including for <abbr title="foreign function interface">FFI</abbr>, low-level bit-twiddling, and so on, the ability to distinguish between safe and unsafe code comes with non-trivial benefits.</p>
<section aria-role="note"><p>This is not a<span></span> <span>“</span>Rust is always the best” manifesto. There may be other ways to achieve Rust’s goals of memory safety with lower cognitive load than Rust imposes. If so, that will be great, because Rust’s cognitive load is significant. <a href="https://www.val-lang.dev">Val</a> and <a href="https://vale.dev">Vale</a> (no relation to each other!) both look interesting here, for example, and so does <a href="https://www.swift.org">Swift</a><span></span><span>’</span>s still-<abbr title="work-in-progress">WIP</abbr> <a href="https://github.com/apple/swift/blob/main/docs/OwnershipManifesto.md">ownership system</a>. I do not take Rust to be remotely the final word in this space. It is the <em>first</em> memory safe systems language to be successful at industrial scale — not the last!</p>
<p>Rather, this is a critique of one very specific misunderstanding I see floating around — even from some really sharp developers. Please read it as such!</p>
</section>
<h2 id="1" tabindex="-1"><a href="#1">1</a></h2>
<p>The motivating intuition behind the claim that<span></span> <span>“</span>we would have to use tons of <code>unsafe</code> anyway, so Rust would not help us” is simple and reasonable: Rust comes with significant mental overhead as the price of getting memory safety, so if you are not getting those benefits, why pay the costs?</p>
<p>Having <em>any</em> meaningful chunk of your code be reliably<span></span> <span>“</span>safe” is useful, though. When trying to learn a system, and especially when trying to understand where things went wrong in a system, it is incredibly helpful to be able to know where you should start looking — and where you do not have to waste time looking. Assume 70% of your code base is wrapped in <code>unsafe</code>: That is still 30% of your code base where you do not have to think about memory safety! This is no small thing; C, C++, Zig, Odin, etc. offer no such guarantees. In those languages, all memory safety invariants are upheld implicitly; all isolation is done by choice alone.</p>
<p>Put another way: Some safety is better than no safety. The question is: <em>How much better? When does it pay for the cognitive overhead of using a language which slows you down up front when dealing with <code>unsafe</code>?</em> Is it 30:70 safe:unsafe? Maybe not (though I personally would take that trade every time!). Is it 50:50? I think most developers would admit that the trade is worth it: that is a <em>lot</em> of increased safety. What about 70:30 — inverting the original proportions? Certainly: the vast majority of the program is safe at that point. And even the programs I hear discussed in this vein are much closer to the 70:30 safe:unsafe ratio (indeed: likely <em>even less</em> unsafe code than that).</p>
<p>Granted that people do sometimes manage memory safety (mostly-)effectively in memory-unsafe languages. In practice, that seems to work when:</p>
<ul>
<li>There is only person, or only a <em>very</em> small group, working on it — likely not more than 3 or 4.</li>
<li>All maintainers have very high continuity with the software over time, neither stepping away from it nor seeing significant changes in the group membership.</li>
<li>All maintainers are expert enough to keep the whole program in their heads at all times.</li>
<li>The code base has an incredibly extensive (and always-growing) test suite, and is required to be valid through multiple layers of static analysis.</li>
</ul>
<p>While maybe <em>just</em> possible in those contexts, this is very difficult to sustain over time. Most importantly: Our ability to keep a program in our head degrades both as the program grows and with any time spent away from it, and providing that same level of understanding to another person is <a href="https://cdn.chriskrycho.com/file/chriskrycho-com/resources/naur1985programming.pdf">difficult at best</a>. The larger a program grows, the longer we work on it, and the more people who are working on it, the more valuable any improvement in program-level safety becomes.</p>
<p>The value of the safety even in that 30:70 safe:unsafe split is obvious in the context of a team with half a dozen non-expert developers, especially if there is any amount of turnover. Even for a long-running solo project, though, I think Rust’s safety guarantees, and its distinction between safe and unsafe code in particular, is valuable: because it makes the program as a whole far easier to understand — to which I now turn.</p>
<h2 id="2" tabindex="-1"><a href="#2">2</a></h2>
<p>By providing the safe-<code>unsafe</code> distinction, Rust enables us to provide genuinely safe <abbr title="application programming interface">API</abbr>s which themselves <em>wrap</em> unsafe code. As a result, in practice, few if any idiomatic Rust libraries or programs would have a 30:70 ratio of safe:unsafe code. (The practice of wrapping <code>unsafe</code> code in safe abstractions is a learned habit, though, so I can see how people who have not internalized this mechanic could fairly readily end up there.) Those safe wrappers both <em>uphold</em> and <em>isolate</em> the key invariants for memory safety. Upholding and isolating invariants are both important, and they are closely related to each other.</p>
<p>When dealing in unsafe code — whether in Rust <code>unsafe</code> blocks or in all the code in languages like C and C++ — the responsibility falls to the programmer to write code which is still safe. This is possible! It is simply very difficult. They key is that if we want to have memory safety, some place in our code must actually <em>check</em> that safety. Best of all is when that can be done by the compiler (think of bounds checks on arrays/vectors <em>&amp;c</em>.). A close second is explicitly encoding those checks into the types in our system (<a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, Don’t Validate</a>). A third runner-up is dynamically checking the invariants at runtime and crashing noisily and eagerly if they are violated: this is always better than the kinds of problems that come from memory corruption. A safe wrapper around an unsafe <abbr title="application programming interface">API</abbr> can follow either of the latter two approaches, and both are significant improvements over <em>not</em> explicitly upholding the contract.</p>
<p>The dynamic here is similar to providing a pure functional interface in a language which is implemented with mutable data under the hood (which pattern is particularly common in languages like OCaml and F<sup>♯</sup>, but available in nearly any language). Mutating a new array in place can be far more efficient than using even a well-optimized persistent data structure, but providing a purely functional interface means callers do not have to care about the implementation details and still get the benefits of referential transparency.</p>
<p>Granted, again, that Rust’s memory safety benefits do not come for free. There remains no free lunch! But unless <em>every line</em> of the program in wrapped in <code>unsafe</code> — which would be extraordinary! — Rust’s distinction between safe and unsafe code is still valuable, and the more so as you isolate your enforcement of memory safety behind safe wrapping <abbr title="application programming interface">API</abbr>s. Why? Because it significantly improves your ability to <em>reason locally</em>: When in non-<code>unsafe</code> blocks, you do not have to think about memory safety bugs. When in <code>unsafe</code> blocks you <em>do</em>, but with a clear idea of where the boundary is.</p>
<p>Having only one place in the code base which must uphold a given invariant means it is far easier to test and to debug when there are failures. It means the code base does not rely on people fully internalizing the rules for each <abbr title="application programming interface">API</abbr> by reading all of its comments (and those comments being correct and exhaustive!) and then being sufficiently careful everywhere they use that <abbr title="application programming interface">API</abbr>.<span></span> <span>“</span>Don’t Repeat Yourself” is most important, and most applicable, when it comes to upholding the invariants in a program.</p>
<p>That goes for memory safety most of all.</p>
<section aria-role="note"><p>Thoughts, comments, or questions? <a href="mailto:hello@chriskrycho.com?subject=Re%3A%20Unsafe">Shoot me an email</a>, or leave a comment on <a href="https://news.ycombinator.com/item?id=36970305">Hacker News</a> or <a href="https://lobste.rs/s/kuq1ha/unsafe_on_rust_still_being_helpful_even">lobste.rs</a>.</p>
</section>



   </div></div>
  </body>
</html>
