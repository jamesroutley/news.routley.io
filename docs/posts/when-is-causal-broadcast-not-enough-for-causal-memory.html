<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://decomposition.al/blog/2024/09/22/when-is-causal-broadcast-not-enough-for-causal-memory/">Original</a>
    <h1>When is causal broadcast not enough for causal memory?</h1>
    
    <div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        <i aria-hidden="true"></i>
        
        <time datetime="2024-09-22T19:57:00+00:00">September 22, 2024</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
        



<p>While getting ready to teach my <a href="https://decomposition.al/CSE232-2024-09/">grad distributed systems course this fall</a>, I found myself once again flipping through Cheriton and Skeen’s <a href="https://dl.acm.org/doi/10.1145/173668.168623">rather scathing 1993 article “Understanding the limitations of causally and totally ordered communication”</a>.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>  One of Cheriton and Skeen’s complaints about causally ordered that it does not enforce the ordering constraints that they care about.  They write:</p>

<blockquote>
  <p>[T]he correct behavior of an application requires ordering constraints over operations on its state, and these constraints are typically stronger than or distinct from the ordering constraints imposed by the happens-before relationship. Such ordering constraints, referred to as “semantic” ordering constraints, run the gamut from weak to strong, and they may or may not require grouping as well. Example constraints include causal memory [1], linearizability [12], and, of course, serializability. Even the weakest of these semantic ordering constraints, causal memory, can not be enforced through the use of causal multicast [1].</p>
</blockquote>

<p>While it’s a good point that there are many important application-level ordering relationships that are not captured by the happens-before order, The last quoted sentence above caught my attention because it seems counterintuitive.  Causal memory is a distributed shared memory abstraction in which “reads respect the order of causally related writes”, and it certainly <em>seems</em> like it ought to be the kind of thing you can implement using causal-order-enforcing communication primitives.  So, why can’t you?</p>

<p>The paper that Cheriton and Skeen cite as “[1]” there is <a href="https://ieeexplore.ieee.org/document/148677">“Implementing and programming causal distributed shared memory”</a>, published in 1991 by Ahamad, Hutto, and John.  The more often cited paper for “causal memory” is actually not this 1991 paper, but rather, <a href="https://link.springer.com/article/10.1007/BF01784241">“Causal memory: definitions, implementation, and programming”</a>, a 1995 follow-up with some of the same authors.  (Of course, Cheriton and Skeen didn’t cite the 1995 paper, because it did not exist yet when they wrote theirs.) I had seen the 1995 paper before, but not the earlier 1991 one.  Unfortunately, the 1991 paper is not open access; <a href="https://decomposition.al/CSE232-2024-09/readings/extra/implementing-causal-memory.pdf">here’s a copy</a></p>

<p>In the 1991 paper, Ahamad et al. explain that while causal memory is indeed “closely related” to causal message ordering (which is a <a href="https://decomposition.al/blog/categories/#causal-delivery">perennial topic</a> around here), broadcasting writes and delivering them in causal order doesn’t quite get us causal memory.  They write (emphasis mine):</p>

<blockquote>
  <p>As we hae said, causal memory is closely related to the ISIS causal broadcast and, thereby, to the notion of causally order messages.  But causal memory is more than a collection of “locations” udpated by causal broadcasts.  There are significant differences in the two models.</p>

  <p>One way to relate the two models is to assume that each processor has a copy of the memory (a cache) and writes are sent as broadcast messages to all processors.  When a message arrives at a processor, it updates its memory by storing the value contained in the message into the appropriate location.  A read by the processor returns the value in its memory.  <strong>It may seem that when the message delivery order preserves causality (for example by using the causal broadcast protocol of ISIS) the values returned by read operations will satisfy the requirements of causal memory.  This, however, is not true.</strong></p>
</blockquote>

<p>They then give an example of an execution of this collection-of-locations-updated-by-causal-broadcast-based model that would <em>not</em> be allowed by the causal memory model.  For me, a Lamport diagram makes their example execution easier to understand, so here’s one, showing broadcasts for writes and the contents of each process’s cache:</p>

<figure>
  <img src="https://decomposition.al/assets/images/not-causal-memory.png" alt="A Lamport diagram of the execution in Figure 3 of Ahamad et al., &#34;Implementing and programming causal distributed shared memory&#34;"/>
  <figcaption>A Lamport diagram of the execution in Figure 3 of Ahamad et al., &#34;Implementing and programming causal distributed shared memory&#34;</figcaption>
</figure>

<p>So, we have three processes, \(P_1\), \(P_2\), and \(P_3\), each of which has carried out a sequence of <em>read</em> and <em>write</em> operations.  I’ve borrowed Ahamad et al.’s notation for these: A write operation \(w(x)v\) write the value \(v\) to location \(x\), and a read operation \(r(x)v\) reads the value \(v\) from location \(x\).</p>

<p>The boxes in dashed lines are each process’s local memory, and the messages are causal broadcasts.  The part that violates causal memory is the read of \(x\) on \(P_3\): \(r(x)2\).  From what I can tell, this wouldn’t happen under causal memory, for a subtle reason described in section 2 of the paper:</p>

<blockquote>
  <p>However, an intervening read operation \(r(x)v&#39;\) serves notice that \(v\) has been overwritten and is sufficient to eliminate \(v\) from \(\alpha(o)\) as well.</p>
</blockquote>

<p>Here, “\(\alpha(o)\)” is what Ahamad et al. call the <em>live set</em> for \(r(x)2\). Under causal memory, every read has to return a value from the live set for that read.  Because there could be multiple writes that causally precede a read, in general there might be multiple values in the live set for a read, and under causal memory it’s fine to choose <em>any</em> of them!</p>

<p>In this particular execution, both the write \(w(x)5\) on \(P_1\) and the write \(w(x)2\) on \(P_2\) causally precede the read \(r(x)2\) on \(P_3\).  So it seems as though \(5\) and \(2\) should both be in the live set. But! There’s an <em>intervening read</em> on \(P_2\) that reads \(5\). That means that \(2\) is eliminated from the live set, and so under causal memory, the read of \(2\) on \(P_3\) would actually be wrong.</p>

<p>So the causal memory model therefore admits fewer executions than the set-of-locations-updated-by-causal-broadcasts model.  I had read the 1995 causal memory paper, but I didn’t realize that this “intervening read operation” thing was a thing – it didn’t sink in for me until looking at this 1991 paper.  It’s interesting how a <em>read</em> – not a write, just an innocent little read! – on one process can have an effect on what a different process is allowed to read.  My student Jonathan Castello remarked that these so-called reads should really be thought of as just another flavor of write.</p>



        
      </section>

      

      

      
  

    </div></div>
  </body>
</html>
