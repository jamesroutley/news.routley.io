<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/Articles/907685/">Original</a>
    <h1>A pair of Rust kernel modules</h1>
    
    <div id="readability-page-1" class="page"><div>
<center>
           <div><b>This article brought to you by LWN subscribers</b><p>Subscribers to LWN.net made this article — and everything that
       surrounds it — possible.  If you appreciate our content, please
       <a href="https://mytimeatrecurse.substack.com/subscribe/">buy a subscription</a> and make the next
       set of articles possible.</p></div>
           </center>
           <p>
The idea of being able to write kernel code in the Rust language has a
certain appeal, but it is hard to judge how well that would actually work
in the absence of examples to look at.  Those examples, especially for
modules beyond the &#34;hello world&#34; level of complexity, have been somewhat
scarce, but that is beginning to change.  At the 2022 Kangrejos gathering
in Oviedo, Spain, two developers presented the modules they have developed
and some lessons that have been learned from this exercise.
</p><h4>An NVMe driver</h4>
<p>
Andreas Hindborg was up first to talk about <a href="https://github.com/metaspace/rust-linux/commit/3446d310d9082c00eecb4b396a167e3f19b3b2f1">an
NVM Express driver</a> written
in Rust.  The primary reason for this project, he said, was to take
advantage of the
memory-safety guarantees that Rust offers and to gain some
real-world experience with the language.  His conclusions from this project
include that Rust comes with a lot of nice tooling and that its type
system is helpful for writing correct code.  It is, he said, easier to
write a kernel driver in Rust than in C.
</p><p>
<a href="https://mytimeatrecurse.substack.com/Articles/907716/"><img src="https://static.lwn.net/images/conf/2022/kang/AndreasHindborg-sm.png" alt="[Andreas
Hindborg]" title="Andreas Hindborg"/></a>

Why write an NVMe driver when the kernel already has one that works well?
There are no problems with the existing driver, he said, but NVMe is a good
target for experiments with driver abstractions.  NVMe itself is relatively
simple, but it has high performance requirements.  It is widely deployed,
and the existing driver provides a mature reference implementation to
compare against.
</p><p>
Hindborg talked for a while about the internals of the NVMe interface; in
short, communications between the interface and the computer go through a
set of queues.  Often the driver will configure an I/O queue for each core
in the system if the interface can handle it. Creating data structures in
Rust to model these queues is a relatively straightforward task.  In the
end, the Rust driver, when tested with the <a href="https://fio.readthedocs.io/en/latest/fio_doc.html#">FIO</a> tool,
performs <i>almost</i> as well as the existing C driver.  The difference,
Hindborg said, is that the C driver has already been highly tuned, while
the Rust driver has not; it should be able to get to the same level of
performance eventually.
</p><p>
He concluded by saying that the Rust NVMe driver is still &#34;a playground&#34;
and not 
production-ready at this point.  To move things forward, he would like to
create more abstractions that would allow the removal of the remaining
<tt>unsafe</tt> blocks in the driver.  It doesn&#39;t yet support device
removal or the sysfs knobs for the <tt>nvme-cli</tt> tool.  He would also
like to look into using the Rust async model, which would &#34;simplify a lot
of things&#34; in the driver, but possibly at the cost of performance.
</p><p>
At the end of Hindborg&#39;s talk, Paul McKenney asked if there was any
available information on the relative bug rates between the C and Rust
drivers.  Hindborg answered that there have certainly been some bugs;
building Rust abstractions around existing C code can be hard to do
correctly.  That work needs a lot of care and review, but once it works,
drivers built on it tend to show few problems.
</p><h4>A 9P filesystem server</h4>
<p>
Last year, Linus Walleij <a href="https://mytimeatrecurse.substack.com/ml/linux-kernel/CACRpkdat-4BbKHMBerdxXBseMb9O3PiDRZmMLP_OWFE2ctSgEg@mail.gmail.com/">suggested</a>
that, rather than writing drivers in Rust, developers should target areas
with a higher attack surface — network protocols, for example.  Wedson
Almeida Filho has taken that advice and written <a href="https://github.com/wedsonaf/linux/commits/9p">an in-kernel server</a>
for the
<a href="https://en.wikipedia.org/wiki/9P_(protocol)">9P</a> filesystem
protocol in the hopes that this project would demonstrate the productivity
gains and security benefits that Rust can provide.  Initially, he had
started trying to replace the <tt>ksmbd</tt> server, but that turned out to
not be an ideal project.  The SMB protocol is too complex and the server
needs some significant user-space components to work.  He wanted something
simpler; 9P fit the bill.
</p><p>

<a href="https://mytimeatrecurse.substack.com/Articles/907717/"><img src="https://static.lwn.net/images/conf/2022/kang/WedsonAlmeidaFilho-sm.png" alt="[Wedson Almeida
Filho]" title="Wedson Almeida Filho"/></a>

The 9P file protocol, he said, comes from the <a href="https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs">Plan 9</a>
operating system.  The kernel has a 9P client, but no 9P server.  There is
a 9P server in <a href="https://www.qemu.org">QEMU </a>
that can be used to export host filesystems into a guest.  The protocol is
simple, Almeida said, defining a set of only ten operations.  His 9P server
implementation works now, in a read-only mode, and required just over 1,000
lines of code.
</p><p>
Almeida was also looking for a way to experiment with <a href="https://rust-lang.github.io/async-book/">async Rust</a> in the
kernel.  In the async model, the compiler takes thread-like code and turns
it into a state machine that can be implemented with &#34;executors&#34; and
&#34;reactors&#34;, which are implemented in the kernel crate.  He created an
executor that can run async code in a kernel workqueue; anywhere such code
would block, it will release the workqueue thread for another task.  There
is also a socket reactor that is called for socket-state changes; it will
call <tt>Waker::wake()</tt> from the Rust kernel crate to get the appropriate
executor going again.
</p><p>
There is, of course, plenty of work yet to be done.  He would like to
implement reactors for other I/O submission paths, including KIOCBs
(asynchronous I/O), URBs (USB devices), and BIOs (block devices).  Memory
allocation can still use some work; it would be good if a
<tt>GFP_KERNEL</tt> could give up its thread while waiting for the
memory-management subsystem to do complicated things.
</p><p>
At the end, I asked whether the objective of demonstrating the security
benefits of Rust had been achieved; has there been, for example, any
fuzz testing of the server?  Almeida answered that the Rust-based parsing
interface makes a lot of mistakes impossible.  No fuzz testing has
been done — the server has only been working for a couple of weeks — but he
will do it.  He concluded that he will be interested to see how his server
fares in such testing relative to the QEMU implementation.
</p><p>
[Thanks to LWN subscribers for supporting my travel to this event.]</p><hr/><p>
           (<a href="https://lwn.net/Login/?target=/Articles/907685/">Log in</a> to post comments)
           </p></div></div>
  </body>
</html>
