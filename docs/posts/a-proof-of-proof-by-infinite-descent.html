<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://relatedwork.blogspot.com/2024/07/a-proof-of-proof-by-infinite-descent.html">Original</a>
    <h1>A proof of proof by infinite descent</h1>
    
    <div id="readability-page-1" class="page"><div id="post-body-3124261924762160653" itemprop="description articleBody">
<p>WARNING: the following contains a whole lot of pedantry about proving
theorems at a level of detail such that you could likely convince a
computer proof assistant of their correctness. I teach a course where
students learn to write such proofs without computer assistance, because
doing so can profoundly affect how one perceives the possibilities for
formal definition and proof. Sometimes the default reasoning principles
provided by a proof assistant can restrict one’s perspective of what
reasoning principles are acceptable, how and why they might be judged
acceptable, and how to devise and validate new ones.</p>
<p>More relevant to the present post is that even the literature and
pedagogy of writing paper proofs is rife with defaults. I spend a lot of
time teaching about proof by induction, and I find that my students,
most of whom have learned something about proving stuff in the past,
often arrive constrained by a very regimented approach to induction,
involving mandatory “base cases” and “induction cases” and these
nebulous “induction hypotheses” which seem to descend from the sky when
invoked by arcane ceremony. I have some strong feelings about this,
mostly due to my own struggles with gaining comfort with induction as a
student, so I try to help students evade those struggles.</p>
<p>Taken at face value, this post is about some other proof principle,
proof by infinite descent, but at its heart it’s really about induction.
Ideally by the end of this post, I will have challenged, but also shed
light on, the nature of inductive proof cases and induction hypotheses.
As a bonus, you might see how induction can be used to explain another
proof principle that intuitively seems valid, but for which it may not
be obvious how to justify it formally.</p>

<p>In an excellent <a href="https://math.andrej.com/2010/03/29/proof-of-negation-and-proof-by-contradiction/">blog
post</a> about the difference between proof of negation and proof by
contradiction, Andrej Bauer gives as an example a proof that <span>\(\sqrt{2}\)</span> is not a rational number. The
article is worth a read, but I would note in particular that in a
technical sense, his proof is not a proof that it <em>is an irrational
number</em>, just that it is not a rational number. I imagine that one
could also prove that <span>\(\sqrt{-1}\)</span> is
not rational, but that had better not count as a proof that it is
irrational! However, if we also prove that <span>\(\sqrt{2}\)</span> is a real number, which could be
done using Dedekind cuts for instance, then we can deduce that <span>\(\sqrt{2}\)</span> is indeed irrational. And to no
one’s surprise, we can prove that <span>\(\sqrt{-1}\)</span> is not a real number.</p>
<blockquote>
<p><strong>Theorem:</strong><span>\(\sqrt{2}\)</span> is not rational.</p>
</blockquote>
<p>This is a proof of the negation of some proposition, i.e., that
assuming the truth of the proposition implies a contradiction. Let’s
consider some of its details.</p>
<p>First, the proof assumes that <span>\(\sqrt{2}\)</span> is equal to a fraction <span>\(\frac{a}{b}\)</span>, which implicitly implies
that <span>\(a\)</span> and <span>\(b\)</span> are integers and that <span>\(b\)</span> is not 0. We <em>could</em> limit the
two numbers to be naturals, by which I mean non-negative integers,
applying the convention that <span>\(\sqrt{2}\)</span> denotes specifically the
positive root, but since there exists a negative number that when
squared equals 2, and since generalizing the claim plays into my overall
story, let’s make no commitment to whether <span>\(a\)</span> and <span>\(b\)</span> are positive or negative.</p>
<p>Next, the proof uses the fact that every rational number can be
represented by a fraction <span>\(\frac{a}{b}\)</span> such that <span>\(a\)</span> and <span>\(b\)</span> are relatively prime, in other words
that no positive integer other than 1 divides them evenly, which is a
precise way of saying that <span>\(\frac{a}{b}\)</span> is in reduced form. This is a
fact that needs to be proved separately and prior to this proof. We
could instead ntegrate this reasoning directly into the proof: omit the
relative primality assumption, and then let <span>\(a&#39; = a/\gcd(a,b)\)</span> and <span>\(b&#39; = b/\gcd(a,b)\)</span> where <span>\(gcd(a,b)\)</span> is the greatest common divisor
of both. It then follows from some proof effort that <span>\(a&#39;\)</span> and <span>\(b&#39;\)</span> are relatively prime and <span>\(\frac{a&#39;}{b&#39;} = \frac{a}{b}\)</span>, thus
completing the general proof. However, we’re still using an auxiliary
fact that can be proven by induction: that <span>\(a\)</span> and <span>\(b\)</span> have a unique greatest common divisor.
More on that below.</p>
<p>From these assumptions and facts, the proof deduces that both <span>\(a\)</span> and <span>\(b\)</span> are even, which means that <span>\(2\)</span> divides both of them, which contradicts
the assumption that among positive integers only 1 can do this. So
assuming that <span>\(\sqrt{2}\)</span> is rational
leads to contradiction.</p>
<p>Now to drive the topic of this post, here’s a more annoying proof of
the same fact:</p>
<blockquote>
<p><em>Proof.</em> Suppose <span>\(\sqrt{2}\)</span>
were equal to a fraction <span>\(\frac{a}{b}\)</span>. Then we would get <span>\(a^2 = 2b^2\)</span>, hence <span>\(a^2\)</span> is even and so is <span>\(a\)</span>. Write <span>\(a =
2c\)</span> and plug it back in to get <span>\(2c^2
= b^2\)</span>, from which we conclude that <span>\(b\)</span> is even as well. Write <span>\(b = 2d\)</span> and plug it back in to get <span>\(c^2 = 2d^2\)</span>. This yields a contradiction
because we could divide our integers by <span>\(2\)</span> forever, which is impossible. QED.</p>
</blockquote>
<p>On the upside, this proof gets to omit the assumption that <span>\(a\)</span> and <span>\(b\)</span> are relatively prime, which in turn
means we don’t need to consult Wikipedia to remind ourselves what the
heck “relatively prime” means anyway. But on the other hand...what just
happened?!? Intuitively this makes sense, but is this legit?</p>
<p>While Andrej’s proof is a direct proof of negation, this annoying one
is an example of <em>proof by infinite descent</em>, which according to
Wikipedia is a particular kind of proof by contradiction, and relies on
something called the <a href="https://en.wikipedia.org/wiki/Proof_by_infinite_descent">the
well-ordering principle</a>. By the end of this post, I hope to convince
you that: a) it is not a kind of proof by contradiction: rather it’s a
technique for proving negation, so this claim deserves some
finger-wagging from Andrej. b) it does not rely on the well-ordering
principle, and good thing that because if it did, then the annoying
proof would be broken, but it’s not.</p>
<p>We should be able to ascertain from a formal statement of the
principle that it is simply a proof of negation. Andrej’s post
elaborates on the source of confusion. And what is the problem with the
claim that proof by infinite descent relies on well-ordering, whatever
that is? To explain, let’s first pinpoint a more fundamental and general
property, called <em>well-foundedness</em>, and reasoning principle,
<em>well-founded induction</em>, that the principle of infinite descent
can be based upon and even generalized, and use that to explain the
confusion. Along the way, we’ll produce a different explanation of proof
by infinite descent in terms of induction: an explanation that suits my
induction-happy brain better. Also, we’ll get the opportunity to
investigate induction itself: in particular, I want to demonstrate that
the common “base case/induction case” recipe for induction is a useful
but limiting view of how induction can be applied.</p>

<p>As you might guess from the above two proofs, they depend on some
notion of “getting smaller”, and in the case of natural numbers the
default notion is the less-than relation <span>\(&lt;\)</span>, but less-than-ness is just an
example of a more general phenomenon. So first, let’s isolate the
property of <span>\(&lt;\)</span> on natural numbers
that really powers induction. A binary relation <span>\(\sqsubset\)</span> is called <em>well-founded</em>
if all leftward chains of the form <span>\(\dots
\sqsubset x_3 \sqsubset x_2 \sqsubset x_1\)</span> must be finite in
length, so there cannot exist any <em>infinite descending chains</em>.
The <span>\(&lt;\)</span> relation on natural
numbers has this property, because starting from any <span>\(n\)</span> and producing smaller numbers and
stopping whenever you want, you will always have to stop, either
necessarily at <span>\(0\)</span> or earlier by
choice. On the other hand, <span>\(&lt;\)</span>
extended to integers does not have this property because you can go
forever down the negative numbers, e.g., <span>\(\dots -16 &lt; -8 &lt; -4 &lt; -2\)</span>.
Luckily, <span>\(&lt;\)</span> isn’t the only binary
relation on integers! Here’s a different one that <em>is</em>
well-founded: if <span>\(z_1,z_2 \in
\mathbb{Z}\)</span>, say <span>\(z_1
\mathbin{\mathbin{\lvert&lt;\rvert}}z_2\)</span> if and only if <span>\(\lvert z_1\rvert &lt; \lvert z_2\rvert\)</span>,
where <span>\(\lvert z\rvert\)</span> denotes the
absolute value of <span>\(z\)</span> and <span>\(&lt;\)</span> is restricted to natural numbers.
Then <span>\(2
\mathbin{\mathbin{\lvert&lt;\rvert}}3\)</span> but also <span>\(-2 \mathbin{\mathbin{\lvert&lt;\rvert}}3\)</span>,
<span>\(2
\mathbin{\mathbin{\lvert&lt;\rvert}}{-3}\)</span>, and <span>\(-2
\mathbin{\mathbin{\lvert&lt;\rvert}}-3\)</span>: the sign of the integer
is ignored! Notice, though, that <span>\(2\)</span>
and <span>\(-2\)</span> are not related by <span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span> in
either direction. Since every leftward chain of the <span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span>
relation works its way toward <span>\(0\)</span>,
the center of the number line, we can see that all such chains must be
finite.</p>
<p>Since “well-ordering” and “well-founded” both start with “well-”, you
might suspect that there’s a relationship between them, and you’d be
right. Well-orderedness is described a variety of ways in the
literature, but for our purposes the following is the most relevant
formulation: a well-founded relation <span>\(\sqsubset\)</span> is a well-ordering if and only
if it relates every distinct pair of elements, i.e. <span>\(x_1 \neq x_2\)</span> implies either <span>\(x_1 \sqsubset x_2\)</span> or <span>\(x_2 \sqsubset x_1\)</span>. So based on what we’ve
observed, <span>\(&lt;\)</span> is well-ordered, but
<span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span> is
not (remember <span>\(2\)</span> and <span>\(-2\)</span>?).</p>
<p>To tie up a loose terminological end, consider the “-ordering” and
“-founded” suffixes. Well-orderings must be transitive: if <span>\(x_1 \sqsubset x_2\)</span> and <span>\(x_2 \sqsubset x_3\)</span> then <span>\(x_1 \sqsubset x_3\)</span>. The consequent must
hold because if it didn’t, then totality would force <span>\(x_3 \sqsubset x_1\)</span>, but that would
introduce a three-element cycle <span>\(\dots
\sqsubset x_3 \sqsubset x_1 \sqsubset x_2 \sqsubset x_3\)</span> and
break well-foundedness. Then, given some well-ordering <span>\(\sqsubset\)</span>, extending it to the relation
<span>\(\sqsubseteq\)</span>, which extends <span>\(\sqsubset\)</span> to be reflexive, is a <em>total
order</em>, i.e., a partial order (reflexive, transitive, antisymmetric
relation) that is also total. On the other hand, a well-founded relation
does not have to be transitive, let alone total, so extending one in
this manner is not even guaranteed to get you a partial order, let alone
a total one. Hence the suffix “-founded”.</p>

<p>Now that we have some grasp of well-foundedness, and why
well-orderedness is a red herring, Let’s use it to state the Principle
of Proof by Infinite Descent precisely and generally.</p>
<blockquote>
<p><strong>Theorem: Principle of Infinite Descent</strong></p>
<p>Stated in formal logical notation: <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \sqsubset x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span></p>
</blockquote>
<p>The premise of the principle formalizes the idea that “no matter
where you are (which x), you can still make a ’descending’ step.”, and
the conclusion is that “well, if so then your property can’t apply to
any x: it leads to contradiction.” Arguably a better name for the
principle would be Proof by <em>No</em> Infinite Descent (thanks to
Andrej for this observation!).</p>
<p>Our proof that <span>\(\sqrt{2}\)</span> is not
rational implicitly applies this principle: Let <span>\(X\)</span> be the integers <span>\(\mathbb{Z}\)</span>; for integers <span>\(a,b\)</span>, let <span>\(a
\sqsubset b\)</span> be <span>\(a
\mathbin{\mathbin{\lvert&lt;\rvert}}b\)</span>; and let the property
<span>\(\Phi(a)\)</span> be “<span>\(a^2 = 2b^2\)</span> for some integer <span>\(b\)</span>” (formally, <span>\(\exists b\in \mathbb{Z}.\,a^2 = 2b^2\)</span>).
Assuming <span>\(a\)</span> and taking <span>\(b\)</span>, the proof uses division by <span>\(2\)</span> to produce a <span>\(c \mathbin{\mathbin{\lvert&lt;\rvert}}a\)</span>
for which some <span>\(d\)</span> satisfies the
equation. Having satisfied the premises of the principle, we use it to
deduce that no <span>\(a\)</span> satisfies the
property (though admittedly the prose proof shrouds this use of the
principle in squishy “forever is impossible” terminology).</p>
<p>The intuition for the principle is pretty straightforward: if the
premises hold, then in principle we can build an infinite descending
<span>\(\mathbin{\mathbin{\lvert&lt;\rvert}}\)</span>-sequence
of integers that satisfy the property. But there are no such infinite
sequences, because we assumed that all of them must be finite, so a
contradiction must follow.</p>
<p>But let’s buttress this intuition with rigour. We can <em>prove</em>
this principle as a consequence of:</p>
<blockquote>
<p><strong>The Principle of Well-founded Induction</strong>: Let <span>\(X\)</span> be a set and <span>\(\sqsubset\)</span> a <em>well-founded
relation</em> on <span>\(X\)</span>. Then let <span>\(\Psi(x)\)</span> be some property of elements
<span>\(x\)</span> of <span>\(X\)</span>. Then if for every <span>\(x\)</span> in <span>\(X\)</span>, <span>\(\Psi(y)\)</span> holding for every <span>\(y \sqsubset x\)</span> suffices to prove <span>\(\Psi(x)\)</span>, it follows that <span>\(\Psi(x)\)</span> holds for every <span>\(x\)</span> in <span>\(X\)</span>.</p>
<p>Stated in formal logical notation: <span>\[(\forall x\in X.\, (\forall y \in X.\, y
\sqsubset x \implies \Psi(y)) \implies \Psi(x)) \implies  \forall x\in
X.\, \Psi(x).\]</span></p>
</blockquote>
<p>This principle is quite abstract, since it’s stated in terms of a
general principle. To clarify, let’s instantiate it with particular
well-founded relations that lead to principles with which we are
familiar. We already observed that <span>\(&lt;\)</span> is a well-founded relation on
natural numbers (because all well-orderings are also well-founded), we
can specialize well-founded induction to get what is often called
<em>strong mathematical induction</em> or <em>course-of-values
induction</em> on natural numbers: <span>\[(\forall
n\in \mathbb{N}.\, ((\forall m \in \mathbb{N}.\, m &lt;  n \implies
\Psi(m)) \implies \Psi(n)) \implies  \forall n\in \mathbb{N}.\,
\Psi(n).\]</span></p>
<p>The general structure of a proof by course-of-values induction is to
assume some natural number <span>\(n\)</span>, then
prove that assuming that <span>\(\Psi(m)\)</span>
holds for every number less than <span>\(n\)</span>
suffices to prove <span>\(\Psi(n)\)</span>.
Achieving that suffices to prove that <span>\(\Psi\)</span> holds for every natural number <span>\(n\)</span>. Observe that the assumption “<span>\(\Psi(m)\)</span> holds for every number less than
<span>\(n\)</span>” is what gets called an
“induction hypothesis”. In the common style of prose proofs, the
“induction hypothesis” often gets evoked in the middle of an argument,
and for a specific value, rather than explicitly assumed at the
beginning of the argument in full generality. To me this always seemed
to me to be some magical thing that got pulled out of the air in the
middle of the proof, leaving me unsure and about what kind of thing
induction even was. But in fact the induction hypothesis is just an
assumption that you make as you attempt to prove <span>\(\Psi(n)\)</span>, and its justification is hidden
in the proof of the principle of well-founded induction. Surprise: you
can prove induction principles correct, and devise and prove correct new
ones: they need not be taken as axioms!</p>
<p>Though students have often seen strong mathematical induction, they
are more familiar with plain ole’ mathematical induction, where the
“induction hypothesis” is to assume that a property holds for a natural
number one less than the current one. We can get this by using the
well-founded relation <span>\(n_1 &lt;_1
n_2\)</span> which holds if and only if <span>\(n_2
= n_1 + 1\)</span>. This relation is neither total nor an order since it
only ever relates abutting natural numbers. But, curiously enough, we
can still plug it into the Principle of Proof by Infinite Descent if we
want, and get something meaningful, albeit more restrictive, than using
<span>\(&lt;\)</span>.</p>
<p>Advertisement: I first learned about this perspective on induction
from Glynn Winskel’s excellent textbook, The Formal Semantics of
Programming Languages. I highly recommend it.</p>

<p>A common structure used in proofs that proceed by either mathematical
induction or course-of-values induction, or at least in teaching such
proofs, is to assume <span>\(n\)</span>, assume the
induction hypothesis, and then proceed by cases on whether <span>\(n = 0\)</span> or whether <span>\(n &gt; 0\)</span>. The first case gets called the
“base case” and is proven outright, and the second case gets called the
“inductive case” which exploits “the induction hypothesis” to complete
that case. When using induction more generally, as is common in PL
theory, this notion of base cases and induction cases gets emphasized as
well. However, it’s worth looking back at the principle of well-founded
induction and observing that nothing about that theorem forces a
particular case analysis, or restricts the availability of the premise
that gets called “the induction hypothesis”. The funny thing is that the
“base case” also has a perfectly fine induction hypothesis, but
typically it is useless because most of the time the proof in question
is not equipped to conjure an <span>\(m &lt;
n\)</span> with which to exploit it.</p>
<p>This template for applying the proof by course-of-values induction is
so common that often the split into base case vs. inductive case, where
the base case does not appeal to induction, gets baked right into the
explanation of the proof principle, as if it were part of the approach.
I find this categorical specialization to be unfortunate for two
reasons.</p>
<p>The first reason is that sometimes a proof needs a case split, but
this particular case split is <em>the wrong one</em>: in that it does
not help push the proof through. My favourite demonstration of this
phenomenon is a proof that any two positive natural numbers have a
greatest common divisor. This proof could be extended to integers, and
thus apply to Andrej’s proof as discussed above, but doing so would
deviate more from my main point than I would like. The proof involves a
helper lemma followed by a main theorem.</p>
<blockquote>
<p><strong>Lemma.</strong> For all positive natural numbers <span>\(a\)</span> and for all positive natural numbers
<span>\(b\)</span>, if <span>\(a
\geq b\)</span> then there exists a positive natural number <span>\(c\)</span> such that <span>\(xc = a\)</span> for some positive natural <span>\(x\)</span> and <span>\(yc =
b\)</span> for some positive natural <span>\(y\)</span>, and furthermore if <span>\(d\)</span> is a positive natural number that
satisfies these properties, then <span>\(c \geq
d\)</span>.</p>
</blockquote>
<p>This lemma can be proven by course-of-values induction. Then the
statement of the main theorem has the same structure, but does not
assume <span>\(a \geq b\)</span>. It can be proven
by splitting cases on whether <span>\(a \geq
b\)</span> or <span>\(b \geq a\)</span> and then
applying the lemma with the two numbers appropriately ordered (either
order will work if the numbers are equal).</p>
<p>I’m only going to give a sketch of the lemma’s proof, since it
suffices to make the relevant point. It proceeds by course-of-values
induction on <span>\(a\)</span> where the relevant
property of a is the substatement : “for all positive natural numbers
<span>\(b\)</span> ...” (now you know why I
explicitly separated the two variable quantifications in the prose
statement of the lemma). After assuming the induction hypothesis,
assuming <span>\(b\)</span> and assuming <span>\(a \geq b\)</span>, we proceed by cases on whether
<span>\(a = b\)</span> or <span>\(a &gt; b\)</span>. If <span>\(a = b\)</span> then we can show that the greatest
common divisor is the number itself, so <span>\(a\)</span>. If <span>\(a &gt;
b\)</span>, then we can show that the greatest common divisor of <span>\(a-b\)</span> and <span>\(b\)</span> is also the greatest common divisor of
<span>\(a\)</span> and <span>\(b\)</span>. However, to appropriately apply the
induction hypothesis, we must first determine which of <span>\(a-b\)</span> and <span>\(b\)</span> is larger: since <span>\(b\)</span> is positive, we know that <span>\(a-b &lt; a\)</span>, and we previously assumed
<span>\(b &lt; a\)</span>, so either can play the
role of “smaller <span>\(a\)</span>”, but to make
sufficient progress with the induction hypothesis, we need “next <span>\(b\)</span>” to be less than “smaller <span>\(a\)</span>”, so we split cases on whether <span>\(a-b &lt; a\)</span> or not, arbitrarily letting
the alternate case also handle <span>\(a-b =
a\)</span>.</p>
<p>The interesting part of the above proof is that two cases are
considered, and only one of them appeals to the induction hypothesis.
But the case that does not is not an <span>\(a=0\)</span> case as per the default template. In
fact <span>\(a = 0\)</span> could never apply since
we assumed that <span>\(a\)</span> is positive.</p>
<p>For exactness sake, it’s worth pointing out that one can perfectly
well devise a principle of course-of-values induction that applies to
just the positive integers, such that <span>\(a =
1\)</span> would be viewed as the “base case”. If we were to separate
out that case, we could deduce that <span>\(b =
1\)</span> because it must be a positive integer, and it must be less
than or equal <span>\(a\)</span>. So in practice,
the <span>\(a = 1\)</span> case can get handled
using the exact same reasoning as the other <span>\(a = b\)</span> cases, which happen to circumscribe
those situations where no appeal to an “induction hypothesis” is
required.</p>
<p>So the lesson to be drawn from my first gripe is that when performing
induction, if we reconceive of “base cases” to mean those cases that do
not appeal to an induction hypothesis, then such cases need not coincide
with the cases that involve the minimal elements of the well-founded
relation (or the unique minimum element of a well-ordered relation). For
many proofs the default heuristic helps, but that default is not a
universal law of induction.</p>

<p>To reiterate, my first problem with how course-of-values induction is
taught is that the default base-case/inductive-case split may not be the
most fruitful one. The second problem I have is that <em>you may not
even need such a split</em>. Usually it is assumed that there must be
some “base case”, that does not get to exploit the induction hypothesis,
for how could it ever apply? But in some proofs <em>you can always
exploit the induction hypothesis</em>. This is exactly the case in the
following proof of the Principle of Infinite Descent that uses the
Principle of Well-founded Induction.</p>
<p><strong>Theorem: Principle of Infinite Descent</strong> <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \sqsubset x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span></p>
<p><strong>Proof.</strong> Suppose <span>\((\forall
x\in X.\, \Phi(x) \implies \exists y \in X.\, y \sqsubset x \land
\Phi(y))\)</span>. Now we prove <span>\(\forall x\in
X.\, \neg\Phi(x)\)</span> by well-founded induction on <span>\(x\in X\)</span>. We will use as our predicate
<span>\(\Psi(x) := \neg\Phi(x)\)</span>, which is
synonymous with <span>\(\Phi(x) \implies
\bot\)</span>, i.e. <span>\(\Phi(x)\)</span> implies
contradiction. Suppose <span>\(x \in X\)</span>, and
suppose <span>\(((\forall y \in X.\, y \sqsubset x
\implies \neg\Phi(y))\)</span> At this point it suffices to show <span>\(\neg\Phi(x)\)</span>, for which it suffices to
assume <span>\(\Phi(x)\)</span> and deduce a
contradiction. So suppose <span>\(\Phi(x)\)</span>.
Now, applying our first assumption to this particular <span>\(x\)</span>, we learn <span>\(\Phi(x) \implies \exists y \in X.\, y \sqsubset x
\land \Phi(y))\)</span>, and combining this with our most recent
assumption, we learn that <span>\(\exists y \in X.\,
y \sqsubset x \land \Phi(y)\)</span>, so consider that <span>\(y \in X\)</span>. Since <span>\(y \sqsubset x\)</span>, we can use the induction
hypothesis to prove <span>\(\neg\Phi(y)\)</span>.
But we also have <span>\(\Phi(y)\)</span>, to which
we can apply <span>\(\neg\Phi(y)\)</span> to deduce
a contradiction. QED.</p>
<p>This proof of proof by infinite descent used course of values
induction, but did not need to consider distinct cases related to <span>\(x \in X\)</span>. There is no “base case” here, in
the sense that no part of the proof must be separately completed without
the help of an induction hypothesis. Now, when specialized to natural
numbers, one <em>could</em> do so, breaking out the <span>\(0\)</span> case and arguing directly that there is
no smaller number, without reference at all to <span>\(\Phi(x)\)</span>. Or more nebulously, we can split
on “minimal elements” versus “non-minimal elements”, but to what
end?</p>

<p>The following is a bonus: thanks to Andrej who made the observation
that inspired it.</p>
<p>We’ve proven that if <span>\(\sqsubset\)</span>
is well-founded, then principle of infinite descent applies. What about
the reverse? The answer is “it depends.” In particular, if you prefer to
work without proof by contradiction (i.e. constructively), then you can
only get part way there. But with some use of proof by contradiction,
you can get all the way there. In particular, we can prove that for an
arbitrary binary relation <span>\(R\)</span> on a
set <span>\(X\)</span>, if it satisfies the
statement of the principle of infinite descent, then it has no infinite
descending chains. Wait, isn’t that enough? Well, no, not in a world
where you want to work constructively, without proof by contradiction. I
sneakily defined well-foundedness as the assertion that all chains are
finite, which is a stronger statement than the assertion that there can
be no infinite descending chains, so long as you avoid proof by
contradiction. The positive conception is nice because it works in both
contexts, whereas “no infinite descending chains”, which is often taken
as the definition of well-foundedness in classical logic, does not.</p>
<p>Ok on to the proof. First, let’s get precise about descending chains.
Define a descending chain of a binary relation <span>\(R\)</span> to be a partial function <span>\(f : \mathbb{N} \rightharpoonup X\)</span> such
that for all natural numbers <span>\(n\)</span>, if
<span>\(f(n+1)\)</span> is defined, then so is <span>\(f(n)\)</span>, and furthermore <span>\(f(n+1) \mathrel{R} f(n)\)</span>. Then an infinite
descending chain is a descending chain that is defined for every natural
number <span>\(n\)</span>.</p>
<p>Now, we can prove that if <span>\(R\)</span> is
an arbitrary binary relation (rather than a well-founded onw) that
nonetheless satisfies the letter of the principle of infinite descent,
then <span>\(R\)</span> has no infinite descending
chains.</p>
<p><strong>Proof</strong>. Suppose <span>\(R
\subseteq X\times X\)</span>, and suppose that for any property <span>\(\Phi(x)\)</span>: <span>\[(\forall x\in X.\, \Phi(x) \implies \exists y \in
X.\, y \mathrel{R} x \land \Phi(y)) \implies \forall x\in X.\,
\neg\Phi(x).\]</span> Then it suffices to assume <span>\(f : \mathbb{N} \to X\)</span> is an infinite
descending chain and then deduce a contradiction. To do so, it further
suffices to let <span>\(\Phi(x) := \exists
n\in\mathbb{N}.f(n)=x\)</span> and prove the premise of the
proof-by-infinite-descent-shaped assumption, because from that we can
deduce that <span>\(\forall x\in X.\neg\exists n\in
N.\,f(n)=x\)</span>, (i.e. <span>\(f\)</span> is
totally undefined, the empty partial function) which combined with <span>\(x = f(0)\)</span> and <span>\(n = 0\)</span> suffices to deduce a
contradiction.</p>
<p>Let’s prove the sufficient condition: suppose <span>\(x \in X\)</span> and <span>\(\Phi(x)\)</span>, i.e. that <span>\(f(n) = x\)</span> for some <span>\(n \in \mathbb{N}\)</span>. Then <span>\(\Phi(f(n+1)\)</span> holds, and by assumption
<span>\(f(n+1) \mathrel{R} f(n)\)</span>, which can
be combined to prove the existential conclusion. QED.</p>

<p>According to John Stillwell’s Elements of Algebra (Section 2.10),
Blaise Pascal was “the first to use induction in the ’base case,
induction step’ format” in a paper from 1654. But our modern
understanding of induction has it’s origins in Richard Dedekind’s
seminal 1888 book “Was sind und was sollen die Zahlen?” (sometimes
translated “What are the numbers and what are they for?”). Many
defaults—be they notation, techniques, and explanations—in mathematics
have historical origins that precede a more sophisticated understanding
of phenomena, and sometimes an impedance mismatch between the historical
and the modern can limit our understanding (treatment of variables and
functions by mathematical texts is one of my standard whipping horses,
but that’s a topic for another day). Those perspectives persist because
they were useful, and are still useful today, but it also helps to
consider how they might best be incorporated with those refined
conceptions we’ve gained since their inception.</p>
<p>As for the <em>use</em> of proof by infinite descent versus a proof
like Andrej’s that argues directly from minimality, one could reasonably
argue that explicitly calling out the existence of a minimal case is
more intuitively graspable for some arguments. It’s not clear to me
whether arguing from the perspective of “there must be one or more
minimal cases” versus “you can’t go down this way forever” is more
generally clear, especially once you have come to understand proof by
infinite descent. Furthermore, in the case of general well-foundedness,
there may not be <em>a</em> single smallest case, but rather a
(possibly) infinite number of minimal cases, in which case calling all
of them out abstractly may be less compelling than calling out a
singular minimum as was the case (pun intended) for the natural numbers.
Which argument is most enlightening probably depends on personal
taste.</p>

<p>Many thanks to Andrej Bauer for feedback on this post!</p>


</div></div>
  </body>
</html>
