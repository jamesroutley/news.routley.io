<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/sedthh/pyxelate">Original</a>
    <h1>Super Pyxelate converts images to 8-bit pixel art</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/logo.png"><img width="450" height="110" src="https://github.com/sedthh/pyxelate/raw/master/examples/logo.png"/></a>
</p>
<p dir="auto">Super Pyxelate converts images to 8-bit pixel art. It is an improved, faster implementation of the <a href="https://github.com/sedthh/pyxelate/releases/tag/1.2.1">original Pyxelate</a> algorithm with palette transfer support and enhanced dithering.</p>
<p dir="auto"><em>Super Pyxelate is currently in beta.</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_corgi.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_corgi.png" alt="Pixel art corgi"/></a></p>

<div data-snippet-clipboard-copy-content="from skimage import io
from pyxelate import Pyx, Pal

# load image with &#39;skimage.io.imread()&#39;
image = io.imread(&#34;examples/blazkowicz.jpg&#34;)  

downsample_by = 14  # new image will be 1/14th of the original in size
palette = 7  # find 7 colors

# 1) Instantiate Pyx transformer
pyx = Pyx(factor=downsample_by, palette=palette)

# 2) fit an image, allow Pyxelate to learn the color palette
pyx.fit(image)

# 3) transform image to pixel art using the learned color palette
new_image = pyx.transform(image)

# save new image with &#39;skimage.io.imsave()&#39;
io.imsave(&#34;pixel.png&#34;, new_image)
"><pre><span>from</span> <span>skimage</span> <span>import</span> <span>io</span>
<span>from</span> <span>pyxelate</span> <span>import</span> <span>Pyx</span>, <span>Pal</span>

<span># load image with &#39;skimage.io.imread()&#39;</span>
<span>image</span> <span>=</span> <span>io</span>.<span>imread</span>(<span>&#34;examples/blazkowicz.jpg&#34;</span>)  

<span>downsample_by</span> <span>=</span> <span>14</span>  <span># new image will be 1/14th of the original in size</span>
<span>palette</span> <span>=</span> <span>7</span>  <span># find 7 colors</span>

<span># 1) Instantiate Pyx transformer</span>
<span>pyx</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>downsample_by</span>, <span>palette</span><span>=</span><span>palette</span>)

<span># 2) fit an image, allow Pyxelate to learn the color palette</span>
<span>pyx</span>.<span>fit</span>(<span>image</span>)

<span># 3) transform image to pixel art using the learned color palette</span>
<span>new_image</span> <span>=</span> <span>pyx</span>.<span>transform</span>(<span>image</span>)

<span># save new image with &#39;skimage.io.imsave()&#39;</span>
<span>io</span>.<span>imsave</span>(<span>&#34;pixel.png&#34;</span>, <span>new_image</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_blazkowicz.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_blazkowicz.png" alt="Definitely not cherry picking"/></a></p>
<p dir="auto">Pyxelate extends scikit-learn transformers, allowing the same learned palette to be reused on other, aesthetically <strong>similar</strong> images (so it&#39;s somewhat like an 8-bit style transfer):</p>
<div data-snippet-clipboard-copy-content="car = io.imread(&#34;examples/f1.jpg&#34;)
robocop = io.imread(&#34;examples/robocop.jpg&#34;)

# fit a model on each
pyx_car = Pyx(factor=5, palette=8, dither=&#34;none&#34;).fit(car)
pyx_robocop = Pyx(factor=6, palette=7, dither=&#34;naive&#34;).fit(robocop)

&#34;&#34;&#34;
pyx_car.transform(car)
pyx_car.transform(robocop)
pyx_robocop.transform(car)
pyx_robocop.transform(robocop)
&#34;&#34;&#34;
"><pre><span>car</span> <span>=</span> <span>io</span>.<span>imread</span>(<span>&#34;examples/f1.jpg&#34;</span>)
<span>robocop</span> <span>=</span> <span>io</span>.<span>imread</span>(<span>&#34;examples/robocop.jpg&#34;</span>)

<span># fit a model on each</span>
<span>pyx_car</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>5</span>, <span>palette</span><span>=</span><span>8</span>, <span>dither</span><span>=</span><span>&#34;none&#34;</span>).<span>fit</span>(<span>car</span>)
<span>pyx_robocop</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>6</span>, <span>palette</span><span>=</span><span>7</span>, <span>dither</span><span>=</span><span>&#34;naive&#34;</span>).<span>fit</span>(<span>robocop</span>)

<span>&#34;&#34;&#34;</span>
<span>pyx_car.transform(car)</span>
<span>pyx_car.transform(robocop)</span>
<span>pyx_robocop.transform(car)</span>
<span>pyx_robocop.transform(robocop)</span>
<span>&#34;&#34;&#34;</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_fit_transform.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_fit_transform.png" alt="Fit Transform Palette"/></a></p>
<p dir="auto">For a single image, it is possible to call both fit() and transform() at the same time:</p>
<div data-snippet-clipboard-copy-content="# fit() and transform() on image with alpha channel
trex = io.imread(&#34;examples/trex.png&#34;)
trex_p = Pyx(factor=9, palette=4, dither=&#34;naive&#34;, alpha=.6).fit_transform(trex)
"><pre><span># fit() and transform() on image with alpha channel</span>
<span>trex</span> <span>=</span> <span>io</span>.<span>imread</span>(<span>&#34;examples/trex.png&#34;</span>)
<span>trex_p</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>9</span>, <span>palette</span><span>=</span><span>4</span>, <span>dither</span><span>=</span><span>&#34;naive&#34;</span>, <span>alpha</span><span>=</span><span>.6</span>).<span>fit_transform</span>(<span>trex</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_trex.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_trex.png" alt="Transparency for sprites"/></a></p>
<h2 dir="auto"><a id="user-content-hyperparameters-for-pyx" aria-hidden="true" href="#hyperparameters-for-pyx"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hyperparameters for Pyx()</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>height</td>
<td>The height of the transformed image. If only height is set, the width of the transofmed image will be calculated to maintain the aspect ratio of the original.</td>
</tr>
<tr>
<td>width</td>
<td>The width of the transformed image. If only width is set, the height of the transofmed image will be calculated to maintain the aspect ratio of the original.</td>
</tr>
<tr>
<td>factor</td>
<td>The size of the transformed image will be <code>1. / factor</code> of the original. <strong>Can be used instead of setting width or height.</strong></td>
</tr>
<tr>
<td>upscale</td>
<td>Resizes the pixels of the transformed image by upscale. Can be a positive <code>int</code> or a tuple of ints for <code>(h, w)</code>. Default is <code>1</code>.</td>
</tr>
<tr>
<td>palette</td>
<td>The number of colors in the transformed image. </td>
</tr>
<tr>
<td>dither</td>
<td>The type of dithering to use on the  transformed image (see more exampels below):</td>
</tr>
<tr>
<td>alpha</td>
<td>For images with transparency, the transformed image&#39;s pixel will be either visible/invisible above/below this threshold. Default is <code>0.6</code>.</td>
</tr>
<tr>
<td>sobel</td>
<td>The size of the sobel operator (N*N area to calculate the gradients for downsampling), must be an <code>int</code> larger than 1. Default is <code>3</code>, try <code>2</code> for a much faster but less accurate output.</td>
</tr>
<tr>
<td>depth</td>
<td>How many times should the Pyxelate algorithm be applied to downsample the image. More iteratrions will result in blockier aesthatics. Must be a positive <code>int</code>, although it is really time consuming and should never be more than 3. Raise it only for really small images. Default is <code>1</code>.</td>
</tr>
<tr>
<td>boost</td>
<td>Adjust contrast and apply preprocessing on the image before transformation for better results. In case you see unwanted dark pixels in your image set this to <code>False</code>. Default is <code>True</code>.</td>
</tr>
</tbody>
</table>
<p dir="auto">Showcase of available dithering methods:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_palms.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_palms.png" alt="Dithering methods"/></a></p>
<p dir="auto">See more examples in <a href="https://github.com/sedthh/pyxelate/blob/master/examples.ipynb">the example Jupyter Notebook</a>.</p>
<h2 dir="auto"><a id="user-content-assigning-existing-palette" aria-hidden="true" href="#assigning-existing-palette"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Assigning existing palette</h2>
<p dir="auto">Common retro palettes are available in <code>Pal</code>:</p>
<div data-snippet-clipboard-copy-content="from pyxelate import Pyx, Pal

vangogh = io.imread(&#34;examples/vangogh.jpg&#34;)

vangogh_apple = Pyx(factor=12, palette=Pal.APPLE_II_HI, dither=&#34;atkinson&#34;).fit_transform(vangogh)
vangogh_mspaint = Pyx(factor=6, palette=Pal.MICROSOFT_WINDOWS_PAINT, dither=&#34;none&#34;).fit_transform(vangogh)
"><pre><span>from</span> <span>pyxelate</span> <span>import</span> <span>Pyx</span>, <span>Pal</span>

<span>vangogh</span> <span>=</span> <span>io</span>.<span>imread</span>(<span>&#34;examples/vangogh.jpg&#34;</span>)

<span>vangogh_apple</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>12</span>, <span>palette</span><span>=</span><span>Pal</span>.<span>APPLE_II_HI</span>, <span>dither</span><span>=</span><span>&#34;atkinson&#34;</span>).<span>fit_transform</span>(<span>vangogh</span>)
<span>vangogh_mspaint</span> <span>=</span> <span>Pyx</span>(<span>factor</span><span>=</span><span>6</span>, <span>palette</span><span>=</span><span>Pal</span>.<span>MICROSOFT_WINDOWS_PAINT</span>, <span>dither</span><span>=</span><span>&#34;none&#34;</span>).<span>fit_transform</span>(<span>vangogh</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_vangogh.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_vangogh.png" alt="Ever wondered how classical paintings would look like in MS Paint?"/></a>
Assign your own palette:</p>
<div data-snippet-clipboard-copy-content="my_pal = Pal.from_hex([&#34;#FFFFFF&#34;, &#34;#000000&#34;])

# same but defined with RGB values
my_pal = Pal.from_rgb([[255, 255, 255], [0, 0, 0]])
"><pre><span>my_pal</span> <span>=</span> <span>Pal</span>.<span>from_hex</span>([<span>&#34;#FFFFFF&#34;</span>, <span>&#34;#000000&#34;</span>])

<span># same but defined with RGB values</span>
<span>my_pal</span> <span>=</span> <span>Pal</span>.<span>from_rgb</span>([[<span>255</span>, <span>255</span>, <span>255</span>], [<span>0</span>, <span>0</span>, <span>0</span>]])</pre></div>
<p dir="auto">Fitting existing palettes on different images will also have different results for <code>transform()</code>.</p>

<div data-snippet-clipboard-copy-content="pip install git+https://github.com/sedthh/pyxelate.git --upgrade
"><pre><code>pip install git+https://github.com/sedthh/pyxelate.git --upgrade
</code></pre></div>
<p dir="auto">Pyxelate relies on the following libraries to run (included in <em>requirements.txt</em>):</p>
<ul dir="auto">
<li><a href="https://scikit-learn.org/stable/" rel="nofollow">sklearn 0.24.1</a></li>
<li><a href="https://scikit-image.org/" rel="nofollow">skimage 0.18.1</a></li>
<li><a href="https://numba.pydata.org/" rel="nofollow">numba 0.53.1</a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_br.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_br.png" alt="The cathode that burns twice as bright, burns half the resolution"/></a></li>
</ul>

<p dir="auto">The source code is available under the <strong>MIT license</strong>
but I would appreciate the credit if your work uses Pyxelate (for instance you may add me in the Special Thanks section in the credits of your videogame)!</p>
<h2 dir="auto"><a id="user-content-how-does-it-work" aria-hidden="true" href="#how-does-it-work"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>How does it work?</h2>
<p dir="auto">Pyxelate downsamples images by (iteratively) dividing it to 3x3 tiles and calculating the orientation of edges inside them. Each tile is downsampled to a single pixel value based on the angle the magnitude of these gradients, resulting in the approximation of a pixel art. This method was inspired by the <a href="https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html" rel="nofollow">Histogram of Oriented Gradients</a> computer vision technique.</p>
<p dir="auto">Then an unsupervised machine learning method, a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html" rel="nofollow">Bayesian Gaussian Mixture</a> model is fitted (instead of conventional K-means) to find a reduced palette. The tied gaussians give a better estimate (than  Euclidean distance) and allow smaller centroids to appear and then lose importance to larger ones further away. The probability mass function returned by the uncalibrated model is then used as a basis for different dithering techniques.</p>
<p dir="auto">Preprocessing and color space conversion tricks are also applied for better results.</p>
<h2 dir="auto"><a id="user-content-protips" aria-hidden="true" href="#protips"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PROTIPs</h2>
<ul dir="auto">
<li>There is <strong>no one setting fits all</strong>, try experimenting with different parameters for better results! A setting that generates visually pleasing result on one image might not work well for another.</li>
<li>The bigger the resulting image, the longer the process will take. Note that most parts of the algorithm are <strong>O(H*W)</strong> so an image that is twice the size will take 4 times longer to compute.</li>
<li>Assigning existing palettes will take longer for larger palettes, because <a href="https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.deltaE_ciede2000" rel="nofollow">LAB color distance</a> has to be calculated between each color separately.</li>
<li>Dithering takes time (especially <em>atkinson</em>) as they are mostly implemented in plain python with loops.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sedthh/pyxelate/blob/master/examples/p_br2.png"><img src="https://github.com/sedthh/pyxelate/raw/master/examples/p_br2.png" alt="You look like a good pixel"/></a></li>
</ul>
<h2 dir="auto"><a id="user-content-todos" aria-hidden="true" href="#todos"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TODOs</h2>
<ul dir="auto">
<li>Add CLI tool for Pyxelate so images can be batch converted from command line.</li>
<li>Re-implement Pyxelate for animations / sequence of frames in video.</li>
<li>Include PIPENV python environment files instead of just setup.py.</li>
<li>Implement Yliluoma&#39;s ordered dithering algorithm and experiment with improving visuals through gamma correction.</li>
<li>Write a whitepaper on the Pyxelate algorithm.</li>
</ul>
</article>
        </div></div>
  </body>
</html>
