<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://netflixtechblog.medium.com/cache-warming-leveraging-ebs-for-moving-petabytes-of-data-adcf7a4a78c3">Original</a>
    <h1>Cache warming at Netflix: Leveraging EBS for moving petabytes of data</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><div><div><div><p><a rel="noopener follow" href="https://netflixtechblog.medium.com/?source=post_page-----adcf7a4a78c3-----------------------------------"><img alt="Netflix Technology Blog" src="https://miro.medium.com/fit/c/56/56/1*BJWRqfSMf9Da9vsXG9EBRQ.jpeg" width="28" height="28"/></a></p></div></div></div></div><p id="deb2">by<a href="https://www.linkedin.com/in/saileshmukil" target="_blank" rel="noopener ugc nofollow"> Sailesh Mukil</a>,<a href="https://www.linkedin.com/in/prudhviraj9" target="_blank" rel="noopener ugc nofollow"> Prudhviraj Karumanchi</a>,<a href="https://www.linkedin.com/in/tgamaethige" target="_blank" rel="noopener ugc nofollow"> Tharanga Gamaethige</a>,<a href="https://www.linkedin.com/in/shashishekar" target="_blank" rel="noopener ugc nofollow"> Shashi Madappa</a></p><p id="2200"><a href="https://medium.com/netflix-techblog/announcing-evcache-distributed-in-memory-datastore-for-cloud-c26a698c27f7" rel="noopener">EVCache</a> is a distributed in-memory caching solution based on memcached. It is a Tier-0 system at Netflix with its footprint across ~18,000 servers holding ~14 petabytes of data, and still rapidly growing.</p><p id="82c9">We had previously given an overview of how we perform <a href="https://netflixtechblog.com/cache-warming-agility-for-a-stateful-service-2d3b1da82642" target="_blank" rel="noopener ugc nofollow">cache<span id="rmm"><span id="rmm"> </span></span>warming</a> on our EVCache clusters and why it’s needed. The architecture mentioned in the original cache warming article worked great for a vast majority of our use cases. However, as Netflix’s subscriber base grew over the years, the footprint of the data stored in EVCache has increased multiple fold and will continue to increase to meet new and additional demand. As the scale and sensitivity of the clusters increased, the architecture needed to evolve to keep up.</p><p id="4743">In this post we discuss the various bottlenecks encountered and we will present an improved architecture with a much higher throughput suited for petabyte scale datasets by addressing the bottlenecks we faced. We will share results from our production environment which show our <strong>total warm up times reduced by ~90% </strong>as compared to our previous architecture.</p><p id="32a2">We are thrilled to open-source the memcached dumper part of this project for use in the broader community, called <a href="https://github.com/Netflix/cachemover" target="_blank" rel="noopener ugc nofollow">Cachemover</a>, which allows one to dump memcached data to disk as fast as possible.</p><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/1*Z2md1Mcv34i7hCS9B9tkZg.png?q=20" width="700" height="691" role="presentation"/></p><p><img alt="" width="700" height="691" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.1 EVCache data path for new deployments (from </em><a href="https://netflixtechblog.com/cache-warming-agility-for-a-stateful-service-2d3b1da82642" target="_blank" rel="noopener ugc nofollow">cache warming</a><em>)</em></figcaption></figure><p id="1ae9"><em>Figure 1</em> shows a high level view of what EVCache cache warming looks like</p><p id="b6f2">Figure 2 below shows the architectural overview of our original cache warming system. It has three main blocks — <em>Controller</em>, <em>Dumper</em> and <em>Populator</em>.</p><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/0*KFvyQp7cAgcgiI60?q=20" width="700" height="333" role="presentation"/></p><p><img alt="" width="700" height="333" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.2 Cache Warmer Architecture (previous architecture)</em></figcaption></figure><p id="10c3">To give a quick overview of how the previous cache warming process worked, the <em>Controller</em> creates a SQS queue for metadata, and then instructs all instances in the existing source replica to dump and upload data to S3. The dumping and uploading processes are performed by a Java based <em>sidecar process</em> on each source instance. It also continually publishes metadata updates to SQS as it uploads data to S3. A distributed <em>Populator</em> service is spun up to download the metadata and data from SQS and S3 respectively and writes it to the new target EVCache replica/cluster.</p><p id="b132">Note that from S3’s point of view the dumper is the writer and the populator is the reader.</p><p id="776f">The previous blog post on <a href="https://netflixtechblog.com/cache-warming-agility-for-a-stateful-service-2d3b1da82642" target="_blank" rel="noopener ugc nofollow">cache warming</a> delves into further details of this architecture if readers are interested. Next, we will highlight the challenges that arose from this architecture and how we modified the architecture to address those challenges.</p><p id="8a2e">The primary challenges we identified with the above architecture are:</p><ol><li id="f64c">The dumping process is handled by the Java based sidecar <em>(the “Cache Dumper” component in Fig. 2)</em> and if the instances are running low on memory, we would see OutOfMemory errors.</li><li id="7855">As mentioned in the future enhancements sections of <a href="https://netflixtechblog.com/cache-warming-agility-for-a-stateful-service-2d3b1da82642" target="_blank" rel="noopener ugc nofollow">cache warming</a>, another bottleneck with the current approach is uploading and downloading data-chunks to and from S3. We observe that the S3 network bandwidth gets throttled after a certain period which slows down the end-to-end warming process and hence implicitly increases the likelihood of unrecoverable errors like OOM and potentially affects live traffic (<em>see next point</em>) due to the longer runtime of the cache warming process.</li><li id="8fed">A further problem with S3 is that the upload path uses the same network as the live traffic; hence the latency and throughput of live traffic is affected during the cache warming process. To make matters worse, the longer the cache warming process takes, the longer is the live traffic affected.</li></ol><p id="7875">The first challenge is addressed by moving to a C++ based dumper (<a href="https://github.com/Netflix/cachemover" target="_blank" rel="noopener ugc nofollow">cachemover</a>) which can be controlled to use as few memory resources as possible or use higher memory depending on the memory available on a given instance. The second and third challenges are addressed by leveraging the <a href="https://aws.amazon.com/about-aws/whats-new/2020/02/ebs-multi-attach-available-provisioned-iops-ssd-volumes/" target="_blank" rel="noopener ugc nofollow">multi-attach EBS volumes</a>. Making these two improvements reduced the total warm up time by ~90%. We will present the data from our production environments in the results section.</p><p id="17df">The design goals for the cache warming system were same as the original post with some additional ones</p><ul><li id="51cf">Limit network impact on current EVCache clients</li><li id="ff62">Minimize the memory and disk usage on EVCache nodes</li><li id="4c25">Shorten the warm up time</li><li id="e1a7">Have no restrictions on when (Peak/Non-peak periods) to warm up</li><li id="4fb7">Make the system configurable enough so that it can maximize the resources available to it</li></ul><p id="60b2">When we published our previous cache warmer post, AWS did not offer multi-attach EBS volumes. Without multi-attach, the dumping stage and the population stage would need to be serialized, since an EBS volume can only be attached to either a source instance or a target instance but not both at the same time. This would effectively at least double the end-to-end warming times.</p><p id="e85b">The biggest motivations for using multi-attach EBS volumes were to address Challenges #2 and #3:</p><ul><li id="864b">With EBS, we get additional network bandwidth which is dedicated for just serving EBS traffic.We didn’t want the cache warmer to eat into the network bandwidth available on the instance.</li><li id="4631">We avoid S3 throttling due to the dedicated bandwidth to EBS.</li><li id="fce9">Also the writers and readers can work in-parallel consuming the entire EBS bandwidth due to the multi-attached functionality.</li></ul><p id="0d10">The diagram below shows the architectural overview of our new cache warming system. The main differences are the introduction of C++ cache dumper (called <a href="https://github.com/Netflix/cachemover" target="_blank" rel="noopener ugc nofollow">cachemover</a>), in place of the old cache dumper and moving to amazon EBS instead of S3.</p><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/0*ywuC5tqg_euprSaP?q=20" width="700" height="329" role="presentation"/></p><p><img alt="" width="700" height="329" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.3 Cache Warmer Architecture (new)</em></figcaption></figure><p id="9f6d">The higher level functionality of all the components is very much the same as the old architecture, but there are changes with respect to the implementation itself. Each critical component in the system is explained below.</p><p id="575c">The Cache Warmer controller is the control plane for cache warming. It orchestrates the entire process of bringing up the new clusters, making sure that the data has been copied from old clusters to the new clusters and tearing down all the old artifacts.</p><p id="3ca1">As seen on Fig.3, here are the sequence of operations that take place -</p><ol><li id="3a9e">Cache warmer controller creates EBS volumes depending on the size of the source cluster.</li><li id="e191">Cache warmer controller also creates the Cache Populator cluster which is responsible for reading the data from the old cluster and writing it to the destination cluster.</li><li id="1770">Once the EBS volumes all come online/are available, the controller attaches each unique EBS volume to both a source instance and to a Cache Populator instance.</li><li id="0fb8">From the source instance, the EBS volume is mounted with RW (Read-Write) permissions. The dumper (details of which are mentioned in the next section) writes the contents of the cache to EBS volume directly.</li><li id="9ec6">On the destination instance, the EBS volume is mounted with RO (Read-Only) permissions. But the caveat to this is — we do not use a clustered file system on top of EBS. So the destination side can’t see the changes made to EBS volume instantaneously. Instead, the Cache Populator instance will unmount and mount the EBS volume to see the latest changes that happened to the file system. This allows both writers and readers to work concurrently, thereby speeding up the entire warming process.</li><li id="fbec">Steps 4 and 5 are replicated for each source instance and the process of warming is complete when there is no more data to be written to the destination cluster.</li><li id="2e0a">Cache warmer controller will monitor all erroneous conditions and take necessary action to fix the process -</li><li id="8d4b">If at any time during the above steps, we run into a failure path, the controller does a best-effort attempt to revive and continue the process. If not, the controller tears down all the resources it had created to facilitate the cache warming process.</li><li id="6ebb">Once the dumping and population processes complete successfully, we tear down the cache populator instances and release EBS volumes.</li></ol><p id="571f">The source of the data, i.e. the replica from where the data needs to be copied, can be either provided by the user or the <em>Controller</em> will select the replica with the highest number of items.</p><p id="eeec">The <a href="https://github.com/Netflix/cachemover" target="_blank" rel="noopener ugc nofollow">dumper</a> is an on demand process that is a part of the cachemover project, that runs on EVCache nodes. When requested, it dumps data from a Memcached process in two pipelined steps:</p><ol><li id="5481">Key dump (or <em>“meta-dump”</em> in memcached lingo)</li><li id="1136">Data dump (or dumping the values)</li></ol><p id="b151">The first step, the key dump (or meta-dump), is performed using memcached’s <a href="https://github.com/memcached/memcached/wiki/ReleaseNotes1431" target="_blank" rel="noopener ugc nofollow">LRU crawler utility</a> or <a href="https://github.com/memcached/memcached/commit/b2cee81823ba32adf09a6666d92aee56a8d98056" target="_blank" rel="noopener ugc nofollow">hash crawler utility</a>. Note that it cannot be parallelized as Memcached provides them as a single threaded operation. In practice this is not an issue as the key dump elapses only a small fraction of the total dumping time.</p><p id="1e07">Additionally, the key dump is pipelined with the data dump. The key dump outputs the keys to disk in chunked files; we refer to them as “key files”. The data dumper threads can start dumping as soon as the first key file chunk is available. The data dump also dumps “data files” in chunks to the target storage layer (EBS or S3). The Populator service can start populating the target cluster as soon as the first data file is available. Hence, this second layer of pipelining helps reduce the end-to-end warming time drastically.</p><h2 id="e8f3">High Level Architecture</h2><p id="11c8">The cachemover dumper is implemented in C++ as a simple multi-threaded task scheduler where every stage listed above is broken down into an independent task.</p><ul><li id="e76f">There exists a <strong>task queue</strong> which has a queue of tasks waiting to be executed.</li><li id="c9af">There are <em>“N”</em> <strong>task threads </strong>that each execute one task at a time.</li><li id="0d93">A <strong>task scheduler </strong>dequeues a task from the <em>task queue</em> and assigns it to a free <em>task thread</em>.</li><li id="9abc">There are “M” <strong>fixed size buffers </strong>which are allocated on startup and used throughout the lifetime of the process to handle all the data.</li><li id="48a3">The dumper tries to stick to a <strong>memory limit</strong>; which is =&gt;</li><li id="37bb">Each <em>task thread</em><strong> </strong>has 2 dedicated <em>fixed size buffers</em>. (i.e. M = N * 2)</li><li id="d003">The dumper exits once the last task is completed.</li></ul></div></div><div><div><ol><li id="03b9">On startup, one task gets enqueued by default which is the <strong><em>meta-dump task</em> </strong>which does a key dump to disk.</li><li id="8256">The key dump contains only key metadata and is chunked into <em>key files</em>. This task does the entire first stage.</li><li id="68b2">For every <em>key file</em> produced, the <em>meta-dump task</em> enqueues a <strong><em>data-dump task</em></strong><em>.</em></li><li id="1ef0">Each <em>data-dump task</em> looks into the key file assigned to it and requests the values from memcached for all the keys it sees.</li><li id="1f81">It then dumps the data for every key into one or more <em>data files</em>. A checksum is calculated for each data file as it’s written and the final file has it as part of its file name. Checksums are used by Cache Populators to validate the file integrity.</li></ol><p id="3792">Once we process all the <em>key files</em> and have dumped all the <em>data files</em>, the dumper finally outputs a file named “DONE” to indicate that it has completed successfully.</p><p id="3d66">The dumper can fit into an EBS architecture or can fit into using a SQS/S3 architecture. There is no tight dependency on either of the components.</p><h2 id="dd1c">Cachemover’s dumper optimizations and how they helped</h2><ul><li id="9e75"><strong>Fixed memory usage:</strong></li><li id="d984"><strong>Zero-copy on hot paths:<br/></strong>The dumper internally avoids copying bytes from buffers of data we read from Memcached. Since we’re talking about the order of hundreds of millions of keys per memcached instance, any extra work per key in the dumper can slow down the process as a whole. For this reason, we do not attempt to modify or copy keys or values from memcached within the dumper.</li><li id="4913"><strong>Checkpoint support:<br/></strong>If for any reason the dumper fails to run to completion (eg: kernel kills it due to OOM), we can skip over all the previously dumped keys and restart from where we left off.</li></ul><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/0*L8eh7LoFiJTKAbog?q=20" width="700" height="597" role="presentation"/></p><p><img alt="" width="700" height="597" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.5 Cache Populators read completed data files from EBS and write to new clusters, pipelining data dumping with data populating</em></figcaption></figure><p id="f476">Cache populator clusters are deployed on demand by the Cache Warmer Controller for a specific warming activity. Once deployed, the controller attaches an EBS volume each to every populator node. Note that the controller ensures there’s 1-to-1 mapping between a source EVCache server node to a populator node. The multi-attached EBS volume is attached to both these nodes so that populators can read data written by a dumper in a pipelined manner.</p><p id="ee97">The Populator is a worker that is tasked with populating the destination replicas. It gets the information about the mount path and destination/new replica through a dynamic property which is set by the Controller.</p><p id="35f2">A populator workflow iterates files in a volume as follows. Note that in Steps 6 and 8, it reports metrics back to the controller so we can monitor the progress.</p><ol><li id="43f6">It will mount the EBS volume in “Read Only” / “No Recovery” mode, and list data file chunks written by the dumper.</li><li id="4d56">It ignores files with partial file system metadata. Cache populators can see incomplete file system metadata due to the way it mounts the filesystem, with “No Recovery” option. It proceeds with complete files, leaving incomplete files to be processed by a subsequent iteration. This is explained further in step 7.</li><li id="a5e8">It also excludes files that are already processed by a previous iteration (Step 6)</li><li id="919e">Files with complete metadata are queued and a populator worker pool is created to process files from the queue</li><li id="b7fb">Each populator worker thread dequeues file name, verifies the checksum, reads key-values from the data file and writes them to the destination replica. The checksum verification process is important as we could see partial files though metadata is complete. We ignore files where checksums don’t match as a subsequent iteration can process them.</li><li id="6c90">Upon completion, a data file is marked as completed, so a future iteration will not reprocess that file.</li><li id="8c2c">Main thread waits until all workers are done — unmount the EBS volume, and sleep a few seconds before going back to Step 1. Note that this unmount and mount is necessary to see newly written files and to resynchronize the metadata of files where it saw partial metadata.</li><li id="75bf">Once the populator sees the DONE file which demarcates an end of a node dump, it exits the workflow and makes the activity complete.</li></ol><p id="14d1">Cache populators are short lived and will get torn down once the warm up activity is completed.</p><p id="7ead">The largest cache that we have warmed up is about 1.7 PB and has about 95 billion items. This cluster has 270 nodes per replica. Hence each instance in the replica carries ~6.5 TB of data. The cache copy took about 9 hours with 270 populator instances.</p><p id="57f0">In contrast, the previous architecture’s benchmark showed warming 700 TB and 46 billion items across 380 nodes per replica took about 24 hours with 570 populator instances. Note that the cluster used for the previous architecture’s benchmark used smaller instance types, each instance having carried ~1.8 TB of data, hence it had more nodes per replica.</p><p id="a897">To compare the true improvement between both the architectures, we need to compare the throughput of data movement at an instance level, as opposed to comparing the end-to-end warming times. This is because the number of instances in the clusters in both benchmarks are different, hence the level of parallelism also changes. So using the benchmark numbers above, we’ll see how much data a single instance moved per hour in both architectures.</p><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/0*j8s7-qlwdI5VB7iq?q=20" width="700" height="433" role="presentation"/></p><p><img alt="" width="700" height="433" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.6 Throughput comparison between old and new architectures</em></figcaption></figure><p id="1106">We see that there is <strong>~9–10x improvement in the per-instance warming throughput</strong> in our new architecture which in turn indicates that every 1TB of data moves ~9–10x faster per instance through the new architecture. Moving the data faster provides better data quality and reduces the likelihood of system errors like OOMs, etc. An additional benefit is the reduced cost of using ephemeral hardware like the populator instances, since they are torn down much faster.</p><p id="f875">The charts below show the warming activity in action.</p></div></div><div><div><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*lXqZDQlwK1BHjp0o" width="700" height="280" role="presentation"/></p></div><figcaption><em>Fig.9 Number of keys written from the populator service to new replica</em></figcaption></figure><p id="200d"><em>EBS Volume Type:</em></p><p id="dc2e">We use the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html#solid-state-drives" target="_blank" rel="noopener ugc nofollow">EBS IO2 volume type</a> which provides sustained IOPS (I/O Operations per second) performance since our workload is I/O intensive. We also make sure to use the <em>multi-attach enabled</em> drives so that we can connect the drive to the source and target instance at the same time. Lastly, we provision drives with 5000 IOPS as that’s in line with how frequent our cachemover dumper and populator processes write to and read from disk.</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*S5FZZHzy1PU0nX8A" width="700" height="248" role="presentation"/></p></div><figcaption><em>Fig.10 EBS Drive type — IO2 w/ Multi-attached at 5000 IOPS</em></figcaption></figure><p id="383e"><em>EBS Throughput and Bandwidth:</em></p><p id="e16c">We were able to obtain write bandwidths of up to 350 MBps, and read bandwidths of up to 300 MBps. You can also see in the throughput charts in Figure 11 that read and write throughput collectively hovers slightly below 5000 IOPS, which is exactly how much we have provisioned.</p><figure><div role="button" tabindex="0"><div><div><div><p><img alt="" src="https://miro.medium.com/max/60/0*hmvpEsrN34pfvAdO?q=20" width="700" height="322" role="presentation"/></p><p><img alt="" width="700" height="322" role="presentation"/></p></div></div></div></div><figcaption><em>Fig.11 EBS Metrics during cache warming</em></figcaption></figure><p id="9842"><em>EBS latencies:</em></p><p id="41a7">The read and write latencies averaged around 5 ms and 3 ms respectively using EBS, which is much faster than uploading to or downloading from S3. While the upload bandwidth to S3 is arguably higher, we’ve empirically found that the cachemover dumper cannot write faster than ~350 MBps. This is because it retrieves values from memcached in real time and so can only write as fast as memcached responds to it. Also, the dumper runs in a resource-constrained environment where it’s only given a limited amount of memory to work with. Therefore, it cannot take advantage of S3’s increased upload bandwidth as it cannot hold that much data in memory. Due to this, with S3, we have to follow a 2 step process: We first need to stage the data on a local disk and then upload it to S3. There is additional write overhead and S3 latencies can also go up to several hundreds of milliseconds contributing to degraded performance when moving very large datasets. We could upload to S3 directly from memory using multipart uploads, but since the dumper process may have less memory to work with, it would warrant multiple high-latency round trips to S3. Whereas with EBS we only have to write a file to the volume before it’s ready for consumption. Hence, the low latency provided by EBS is a great added benefit.</p><p id="8602">In this blog, we discussed the architecture of our new cache warming infrastructure and showed how we overcame architectural bottlenecks of our previous architecture for significant performance wins.</p><p id="4fdd">There’s still much to do and if you want to help work on problems of a similar scale and scope,<a href="https://jobs.netflix.com/" target="_blank" rel="noopener ugc nofollow"> join us</a> at the Core Data Platform Team at Netflix.</p><p id="e0a8">This work could not have been completed without the help of <a href="https://www.linkedin.com/in/arun-agrawal-93083920" target="_blank" rel="noopener ugc nofollow">Arun Agrawal</a> on behalf of the Core Data Platform Team at Netflix. It also builds on the foundational work of <a href="https://www.linkedin.com/in/devananda-jayaraman-4991a02" target="_blank" rel="noopener ugc nofollow">Deva Jayaraman</a>.</p></div></div></div>
  </body>
</html>
