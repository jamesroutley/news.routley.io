<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://randomascii.wordpress.com/2023/10/01/32-mib-working-sets-on-a-64-gib-machine/#more-4032">Original</a>
    <h1>32 MiB Working Sets on a 64 GiB machine</h1>
    
    <div id="readability-page-1" class="page"><div>
						<p>Memory is a relatively scarce resource on many consumer computers, so a feature to limit how much memory a process uses seems like a good idea, and Microsoft did indeed implement such a feature. However:</p>
<ul>
<li>They didn’t document this (!)</li>
<li>Their implementation doesn’t actually save memory</li>
<li>The implementation can have a prohibitively high CPU cost</li>
</ul>
<p>This feature works by limiting the working set of a process – the amount of memory mapped into the address-space of the process – to 32 MiB. Before reading any farther take a moment to guess what the maximum slowdown might be from this feature. That is, if a process repeatedly touched more than 32 MiB of memory – let’s say 64 MiB of memory – then how much longer could these memory operations take compared to if the working set was not limited? Take a moment and write down your guess. The answer is later in this post.</p>

<p>This exploration started when a <a href="https://twitter.com/leidegre/status/1678424440437186563">Chrome user</a> tweeted at me that they kept seeing Chrome’s setup.exe hogging the CPU. Investigating weird Chrome performance problems is literally my job so we started chatting. Eventually they used <a href="https://randomascii.wordpress.com/2015/09/01/xperf-basics-recording-a-trace-the-ultimate-easy-way/">UIforETW</a>’s circular-buffer recording mode (leave tracing running, save the buffers when the problem happens) to capture an ETW trace. They <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1475179">filed a Chromium bug</a> and shared the trace and I took a look.</p>
<p>The trace did indeed show lots of CPU time being spent in setup.exe (the sampling rate is 1 kHz so each sample represents approximately 1 ms of CPU time), but there was nothing obviously out of order:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image.png"><img width="601" height="464" title="WPA CPU Usage (Sampled) screenshot showing setup.exe spending its time applying a patch" alt="WPA CPU Usage (Sampled) screenshot showing setup.exe spending its time applying a patch" src="https://randomascii.files.wordpress.com/2023/10/image_thumb.png?w=601&amp;h=464"/></a></p>
<p>That is, at a first glance there was nothing obviously out of order, however as soon as I drilled down into the hottest call stack I saw something peculiar:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-1.png"><img width="601" height="548" title="WPA CPU Usage (Sampled) screenshot showing setup.exe spending its time applying a patch, but mostly in KiPageFault" alt="WPA CPU Usage (Sampled) screenshot showing setup.exe spending its time applying a patch, but mostly in KiPageFault" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-1.png?w=601&amp;h=548"/></a></p>
<p>A few hundred samples spent in <em>KiPageFault</em> seemed maybe plausible, but more than 20,000 samples is definitely weird.</p>
<p><em>KiPageFault</em> is triggered whenever a process touches memory that is not currently in the working set of the process. The memory faulted in might be a zeroed page (first use of an allocated page), a page from the standby list (pages in memory that contain data), a compressed page, or a page that is backed by a file (a memory mapped file or the page file). Whatever the source, this function adjusts the page tables to make the page visible inside the process, and then restarts the faulting instruction.</p>
<p>Since <em>KiPageFault</em> is showing up on multiple call stacks (memory can get paged in from almost anywhere, after all) I needed to use a butterfly view to find out the total cost, and get some hints as to why so much time was being spent there. So, I right-clicked on <em>KiPageFault</em> and selected <em>View Callees</em>, <em>By Function</em>. This showed me two very interesting details:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-2.png"><img width="602" height="253" title="WPA CPU Usage (Sampled) screenshot showing setup.exe spending 99% of its time in KiPageFault" alt="WPA CPU Usage (Sampled) screenshot showing setup.exe spending 99% of its time in KiPageFault" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-2.png?w=602&amp;h=253"/></a></p>
<p>The first detail is that of the 46,912 CPU samples taken from this process fully 46,444 of them (99%!) were inside <em>KiPageFault</em>. That is remarkable. In a steady-state process (not allocating excessively) on a system with sufficient memory (this system had 64 GiB of RAM and roughly 47 GiB of that was available) the number of page faults should be close to zero, and this was a long way from that.</p>
<p>The other detail is that most of the time inside of <em>KiPageFault</em> was spent in <em>MiTrimWorkingSet</em>. This makes sense. But at the same time it is, actually, pretty weird. It looks like every time a page is faulted in to the process the system immediately trims the working set, presumably removing another page from the working set. Doing this is expensive, and increases the odds of future page faults. So, it makes sense in that it explains why the process is spending so much time in <em>KiPageFault</em>, but it is weird because I don’t know why Windows would be doing this.</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-3.png"><img width="293" height="70" title="WPA Total Commit table showing setup.exe with 47.418 of commit" alt="WPA Total Commit table showing setup.exe with 47.418 of commit" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-3.png?w=293&amp;h=70"/></a>ETW traces contain a wealth of information so I looked at the “Total Commit” table and found that setup.exe only had 47.418 MiB of commit. This measures the total amount of allocated memory in this process, plus a few other types of memory such as stack, and modified global variables. 47.418 MB is a pretty tiny amount and should take less than 10 ms to fault in (see <a href="https://randomascii.wordpress.com/2014/12/10/hidden-costs-of-memory-allocation/">Hidden Costs of Memory Allocation</a> for details), and there were no new allocations during the trace, so the <em>KiPageFault</em> overhead was definitely excessive.</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-4.png"><img width="296" height="229" title="WPA Virtual Memory Snapshots table showing the working set varying but always staying around 32 MiB" alt="WPA Virtual Memory Snapshots table showing the working set varying but always staying around 32 MiB" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-4.png?w=296&amp;h=229"/></a>I then looked in the “Virtual Memory Snapshots” table at the Working Set column. This column contains working-set information sampled occasionally – 19 times during the 48 seconds I looked at. These samples showed the working set varying between 31.922 MiB and 32.004 MiB. That is, the sampled working set went as low as 80 KiB below 32 MiB, and as high as 4 KiB above 32 MiB. That is a very tight range.</p>
<h2>Procrastination</h2>
<p>I thought that <em>SetProcessWorkingSetSize</em> might be involved in triggering this behavior, and a coworker suggested <em>SetPriorityClass</em> with <em>PROCESS_MODE_BACKGROUND_BEGIN</em> could be a factor, so I thought about doing some experimentation with these functions. But, the issue was reported on Windows 11 and I assumed that there must be some odd-ball configuration triggering this edge case behavior so I didn’t think my tests would be fruitful so I did nothing for three weeks.</p>
<p>I finally got back to the bug and decided to start by doing the simplest possible test. I wrote code that allocated 64 MiB of RAM, touched all of it, then used <em>EmptyWorkingSet</em>, <em>SetProcessWorkingSetSize</em>, and<em> SetPriorityClass</em> with <em>PROCESS_MODE_BACKGROUND_BEGIN</em>, then touched the memory again. I used some Sleep(5000) calls and Task Manager to monitor the working set. I was not expecting the simplest possible test to reveal the problem.</p>
<p>My tests showed that <em>EmptyWorkingSet</em> and <em>SetProcessWorkingSetSize</em> both emptied the working set almost to nothing, but the working set “refilled” when the memory was touched again. So, the <a href="https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-setprocessworkingsetsize">documentation for these functions</a> (as crazy and archaic as it sounds) seems to be mostly accurate. And, unless they were called extremely frequently these functions could not cause the problem.</p>
<p>On the other hand, my tests showed that <a href="https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setpriorityclass">SetPriorityClass</a><em></em> with <em>PROCESS_MODE_BACKGROUND_BEGIN</em> caused the working set to be trimmed to 32 MiB, and kept it there when I touched all the memory again. That is, while touching 64 MiB of memory would normally fault those pages in and push the working set to 64 MiB or higher, instead the working set stayed capped.</p>
<p>Whoa. That’s crazy. It wasn’t supposed to be that simple. I refined the test code more but it’s still fairly simple. In its <a href="https://github.com/randomascii/blogstuff/blob/main/BackgroundBegin/BackgroundBegin.cpp">final form</a> the code allocates 64 MiB of memory and then repeatedly walks over that memory (writing once to each page) to see how many times it can walk over the memory in a second. Then it does the same thing with the process set to background mode. The difference is dramatic:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-5.png"><img width="685" height="116" title="Screenshot of command-prompt output from BackgroundBegin.exe showing normal mode scanning memory ~4400 times per second, while background mode does it 6-17 times" alt="Screenshot of command-prompt output from BackgroundBegin.exe showing normal mode scanning memory ~4400 times per second, while background mode does it 6-17 times" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-5.png?w=685&amp;h=116"/></a></p>
<p>The performance of scanning the memory in the normal mode is quite consistent, taking about 0.2 ms per scan. Scanning in background mode normally takes about 250 times as long per scan (<em>two hundred and fifty times as long!!!</em>). Sometimes the background-mode scanning goes dramatically slower – up to about 800 times as long per scan, 160 ms for 64 MiB.</p>
<p>This dramatic increase in CPU time is not a great way to reduce the impact of background processes.</p>
<h2>Limiting the Working Set Doesn’t Save Memory!</h2>
<p>Okay, so <em>PROCESS_MODE_BACKGROUND_BEGIN</em> makes some operations take more than 250 times as long to run, but at least it saves memory. Right? Right?</p>
<p>Well, no. Not really. Not in any situation I can imagine.</p>
<p>Trimming the working set of a process doesn’t actually save memory. It just moves the memory from the working set of the process to the standby list. Then, if the system is under memory pressure the pages in the standby list are eligible to be compressed, or discarded (if unmodified and backed by a file), or written to the page file. But “eligible” is doing a lot of heavy lifting in that sentence. The OS doesn’t immediately do anything with the page, generally speaking. And, if the system has gobs of free and available memory then it may never do anything with the page, making the trimming pointless. The memory isn’t “saved”, it’s just moved from one list to another. It’s the digital equivalent of paper shuffling.</p>
<p>Another reason this trimming is pointless is because the system already has a (much more efficient) mechanism for managing working sets. Every second the system process wakes up and runs <em>KeBalanceSetManager</em>. Among other things this function calls <em>MiProcessWorkingSets</em> which calls <em>MiTrimOrAgeWorkingSet</em>:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-6.png"><img width="597" height="349" title="Screenshot of WPA&#39;s CPU Usage (Sampled) graph showing the system process running KeBalanceSetManager" alt="Screenshot of WPA&#39;s CPU Usage (Sampled) graph showing the system process running KeBalanceSetManager" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-6.png?w=597&amp;h=349"/></a></p>
<p>All I know about this system is the names of the functions and the frequency of its operation, but I feel pretty confident in speculating about roughly what it’s doing, and it seems like a strictly better solution to the problem. Here’s why <em>MiTrimOrAgeWorkingSet</em> is better than <em>PROCESS_MODE_BACKGROUND_BEGIN:</em></p>
<ul>
<li>Trimming the working set once per second is far more efficient (uses less CPU time) than trimming it after every page fault, and it greatly reduces the odds of trimming a page just before it is needed</li>
<li>Trimming the working set once per second is just as memory efficient as trimming after every page fault because trimming doesn’t immediately save memory anyway</li>
<li>Trimming the working set every second can more easily respond to changes in memory pressure, doing nothing when there is lots of free memory, and then aggressively trimming rarely-touched pages from idle processes when conditions change.</li>
</ul>
<h2>Resolution</h2>
<p>As far as Chrome is concerned the solution to this problem was simple – <a href="https://chromium-review.googlesource.com/c/chromium/src/+/4894757">don’t call this function</a>, and therefore don’t put Chrome’s setup process into this mode. We still run in low-priority mode, but not the problematic “background” mode.</p>
<p>But this function remains, waiting to snare some future developer. The easiest thing that Microsoft could do would be to change the documentation to acknowledge this behavior. I have in mind a large, red, bold-faced label saying “<strong><SPAN color="#ff0000">if your process uses more than 32 MiB of memory then this may make your program run 250 times slower and it won’t really save memory so maybe use </SPAN></strong><a href="https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setthreadpriority"><strong><SPAN color="#ff0000">THREAD_MODE_BACKGROUND_BEGIN</SPAN></strong></a><strong><SPAN color="#ff0000"> instead</SPAN></strong>.” But fixing the documentation would not be as valuable as fixing the background mode. I have trouble imagining any scenario where capping the working set would be better than the working-set trimming implemented in the system process, so removing this functionality seems like a pure win.</p>
<p>And fixing the background mode would avoid the need for the ugly large, red, bold-faced warning label.</p>
<p>Ironically the impetus for using <em>PROCESS_MODE_BACKGROUND_BEGIN</em> in Chrome was a <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=167622">2012 Chrome bug</a> (predating my time on the team, and I’ve been there a while) complaining that the updater was using too much CPU time.</p>
<p>This recent issue was reported on Windows 11, but I found a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1476365">Mozilla bug discussing this flag</a> that linked to a <a href="https://stackoverflow.com/questions/13631644/setthreadpriority-and-setpriorityclass/30509372#30509372">Stack Overflow answer from 2015</a> that pointed out that <em>PROCESS_MODE_BACKGROUND_BEGIN </em>limited the working set to 32 MiB on Windows 7. This issue has been known for eight years, on many versions of Windows, and it still hasn’t been corrected or even documented. I hope that changes now.</p>
<h2>Addendums</h2>
<p>To clarify, it is the working-set that is trimmed to 32 MiB, not the private working set. So, the 32 MiB number includes code as well as data, for what it’s worth.</p>
<p>Also, after posting this I was playing around and found that when I reset the process with <em>PROCESS_MODE_BACKGROUND_END</em> this causes the working set to be trimmed. That’s harmless, but weird. Why would taking the process <em>out</em> of background mode cause the working set to be trimmed as if the process had called <em>EmptyWorkingSet</em>?</p>
<p>A <a href="https://twitter.com/guyrleech/status/1709101970575782321">twitter user posted a bit of history</a> and a tool (untested!) to list working-set state for processes on the system.</p>
<h2>Socials media and links</h2>
<ul>
<li><a href="https://twitter.com/leidegre/status/1678424440437186563">Original twitter discussion</a></li>
<li><a href="https://twitter.com/BruceDawson0xB/status/1708693872522702913">Twitter blog-post announce thread</a></li>
<li><a href="https://news.ycombinator.com/item?id=37734531">Hacker news discussion</a></li>
<li><a href="https://www.reddit.com/r/programming/comments/16xmykx/32_mib_working_sets_on_a_64_gib_machine_random/">Reddit programming discussion</a></li>
<li><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1475179">Chromium bug</a></li>
<li><a href="https://github.com/randomascii/blogstuff/blob/main/BackgroundBegin/BackgroundBegin.cpp">Sample code</a></li>
</ul>
											</div></div>
  </body>
</html>
