<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.felixge.de/reducing-gos-execution-tracer-overhead-with-frame-pointer-unwinding/">Original</a>
    <h1>Reducing Go execution tracer overhead with frame pointer unwinding</h1>
    
    <div id="readability-page-1" class="page"><div>
        <p>The Go Execution Tracer (aka runtime/trace) was <a href="https://docs.google.com/document/u/1/d/1FP5apqzBgr7ahCCgFO-yoVhk4YZrNIDNf9RybngBc14/pub">designed</a> to achieve low enough overhead to be usable on &#34;a server in production serving live traffic&#34;. This is achieved by writing events into per-P buffers, using RDTSC for timestamps, and encoding into a relatively efficient binary format.</p><p>However, one achilles heel has remained since 2014:</p><blockquote>... 75% of the overhead is stack unwinding.</blockquote><p>Stack unwinding (aka stack walking) is part of the process for taking a stack trace. It involves iterating over all stack frames and collecting the return addresses (program counters) in each frame. It may also involve expanding this list if some of the program counters are part of inlined function calls.</p><p>The other part of taking a stack trace is converting these program counters to function names, file names and line numbers. This is usually called symbolization and you can read more about it <a href="https://github.com/DataDog/go-profiler-notes/blob/main/stack-traces.md">here</a>.</p><p>So why is stack unwinding so expensive in Go? The short answer is because Go uses a form of asynchronous unwinding tables called gopclntab that require a relatively expensive lookup in order to traverse the stack frames. The gnarly details of this mechanism can be found in the <a href="https://github.com/golang/go/blob/6b8b7823c7fd9f3f2317f657120dc2e965d97b77/src/runtime/traceback.go#L32">gentraceback</a> function.</p><p>It might be possible to optimize the implementation, but it&#39;s an uphill battle that we will not investigate today. Instead we&#39;ll take a look at another approach: The forgotten art of frame pointer unwinding. It&#39;s a technique that has been around for decades, but has fallen victim to relentless compiler optimizations in recent times.</p><p>The best way to explain frame pointer unwinding is using a diagram (Fig 1) that shows how to unwind a stack consisting of 3 frames.</p><figure><img src="https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-16.22.47@2x.png" alt="Fig. 1 Traversing a stack of depth 3 using frame pointer unwinding." loading="lazy" width="1522" height="1090" srcset="https://blog.felixge.de/content/images/size/w600/2023/01/CleanShot-2023-01-27-at-16.22.47@2x.png 600w, https://blog.felixge.de/content/images/size/w1000/2023/01/CleanShot-2023-01-27-at-16.22.47@2x.png 1000w, https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-16.22.47@2x.png 1522w" sizes="(min-width: 720px) 720px"/><figcaption>Fig. 1 <em>Traversing a stack of depth 3 using frame pointer unwinding.</em></figcaption></figure><p>The process starts by reading the value of the <code>rbp</code> (amd64) or <code>r29</code> (arm64) register (aka base pointer). This takes us to the frame pointer of <code>frame 2</code>. One word (8 bytes) above this value sits the return address of the caller, which is the first program counter that we need to collect. After this we follow the value of the frame pointer that takes us to <code>frame 1</code>, allowing us to discover the second return address. Repeating this process one more time leads us to <code>frame 0</code>, which we realize is the root frame because it contains a frame pointer holding the value <code>0</code>. So at this point we collect the last return address and stop the process.</p><p>If you&#39;ve paid close attention, you may realize that we have just traversed a linked list outside of a tech interview (Fig 2).</p><figure><img src="https://blog.felixge.de/content/images/2023/01/image.png" alt="Fig 2 Meme: Wait, it&#39;s all Linked Lists? Always has been." loading="lazy" width="888" height="499" srcset="https://blog.felixge.de/content/images/size/w600/2023/01/image.png 600w, https://blog.felixge.de/content/images/2023/01/image.png 888w" sizes="(min-width: 720px) 720px"/><figcaption>Fig 2 <em>CS101 finally gets its revenge.</em></figcaption></figure><p>As you can imagine, it&#39;s not very difficult to implement this, so I decided to turn it into a <a href="https://go-review.googlesource.com/c/go/+/463835">small experimental patch</a> for the Go runtime. Which brings us back to our original motivation: Can this reduce the overhead of the Go execution tracer?</p><p>To answer this question, we&#39;ll evaluate the performance of a benchmark called <a href="https://github.com/golang/go/blob/a106defddac515db4d70e1cad162b88dd026deee/src/runtime/proc_test.go#L491">BenchmarkPingPongHog</a>. As the name implies, it essentially measures the performance of two goroutines ping-ponging messages between each other over a pair of unbuffered channels. This is an absolute worst-case for the execution tracer, because each channel operation ends up recording an event with a stack trace.</p><p>Exact numbers will vary between different machines, but here is what I usually get when running this benchmark on a beefy <code>c5n.metal</code> EC2 machine with tracing disabled vs enabled (Fig 3).</p><figure><pre><code>goos: linux
goarch: amd64
pkg: runtime
cpu: Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz
               │ baseline.txt │           gentraceback.txt            │
               │    sec/op    │    sec/op     vs base                 │
PingPongHog-72    642.8n ± 4%   5616.5n ± 3%  +773.82% (p=0.000 n=10)</code></pre><figcaption>Fig 3 <em>Execution tracer overhead for BenchmarkPingPongHog with gentraceback.</em></figcaption></figure><p>774% overhead, yikes. But let&#39;s dig in. This data was captured while also running the CPU profiler, so we can easily see that <code>gentraceback</code> was responsible for 94% (!) of this overhead (Fig 4).</p><figure><img src="https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-21.55.10@2x.png" alt="Fig 4 CPU profile showing 94% of execution tracer overhead in gentraceback." loading="lazy" width="1864" height="972" srcset="https://blog.felixge.de/content/images/size/w600/2023/01/CleanShot-2023-01-27-at-21.55.10@2x.png 600w, https://blog.felixge.de/content/images/size/w1000/2023/01/CleanShot-2023-01-27-at-21.55.10@2x.png 1000w, https://blog.felixge.de/content/images/size/w1600/2023/01/CleanShot-2023-01-27-at-21.55.10@2x.png 1600w, https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-21.55.10@2x.png 1864w" sizes="(min-width: 720px) 720px"/><figcaption>Fig 4 <em>CPU profile showing 94% of execution tracer overhead in gentraceback.</em></figcaption></figure><p>Now that we&#39;ve established this baseline, let&#39;s see how frame pointer unwinding performs by comparison (Fig 5).</p><figure><pre><code>goos: linux
goarch: amd64
pkg: runtime
cpu: Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz
               │ baseline.txt │               fp.txt                │
               │    sec/op    │   sec/op     vs base                │
PingPongHog-72    642.8n ± 4%   834.8n ± 1%  +29.87% (p=0.000 n=10)</code></pre><figcaption>Fig 5 <em>Execution tracer overhead for BenchmarkPingPongHog with frame pointer unwinding.</em></figcaption></figure><p>30% overhead, that&#39;s 26 times less overhead than <code>gentraceback</code>! I, for one, welcome our new linked list overlords. But before we get ahead of ourselves, let&#39;s take a look at the new CPU profile (Fig 6).</p><figure><img src="https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-21.57.24@2x-2.png" alt="Fig 6 CPU profile showing 9% of execution tracer overhead in fpcallers." loading="lazy" width="1850" height="864" srcset="https://blog.felixge.de/content/images/size/w600/2023/01/CleanShot-2023-01-27-at-21.57.24@2x-2.png 600w, https://blog.felixge.de/content/images/size/w1000/2023/01/CleanShot-2023-01-27-at-21.57.24@2x-2.png 1000w, https://blog.felixge.de/content/images/size/w1600/2023/01/CleanShot-2023-01-27-at-21.57.24@2x-2.png 1600w, https://blog.felixge.de/content/images/2023/01/CleanShot-2023-01-27-at-21.57.24@2x-2.png 1850w" sizes="(min-width: 720px) 720px"/><figcaption>Fig 6 <em>CPU profile showing 9% of execution tracer overhead in fpcallers.</em></figcaption></figure><p>As we can see, <code>fpcallers</code> is now down to 9% of the tracer&#39;s overhead, which means unwinding is no longer the achilles heel of the execution tracer. But of course new bottlenecks such as <code>cputicks</code> (28%) and <code>(*traceStackTable).put</code> (21%) are starting to emerge. You can take a look for yourself by <a href="https://drive.google.com/drive/folders/10VRje2xPWB6SdXXpK8cWCiZtPpjqUHo7?usp=sharing">downloading the pprofs</a>.</p><p>That being said, even without any further optimization, frame pointer unwinding seems to have the potential to take execution trace overhead from <a href="https://gist.github.com/felixge/7ad83a76852b703b4adb5e4afefa1d42#file-1-baseline-vs-gentraceback-txt">up to 20%</a> to <a href="https://gist.github.com/felixge/7ad83a76852b703b4adb5e4afefa1d42#file-2-baseline-vs-fpcallers-txt">around 1%</a> for realistic workloads which I&#39;m hoping to explore in a follow-up post.</p><p>This raises a final question. If this is so easy, why wasn&#39;t the tracer designed to use frame pointers to begin with? The short answer is that the tracer was <a href="https://blog.felixge.de/history-of-gos-execution-tracer/">added</a> in go1.5, but the Go compiler did not emit frame pointer instructions until <a href="https://go.dev/doc/go1.7">go1.7</a>.</p><p>Of course the potential for using frame pointers to optimize the tracer became obvious right away, so there is an <a href="https://github.com/golang/go/issues/16638">open issue</a> (and <a href="https://go-review.googlesource.com/c/go/+/33809">CL 33809</a>, <a href="https://go-review.googlesource.com/c/go/+/212301">CL 212301</a>) for it from 2016. However, it kind of stalled, partially because getting a frame pointer unwinder to behave exactly like <code>gentraceback</code> is difficult, and partially because no decision was made on whether or not that&#39;s a reasonable requirement. Another issue is that frame pointers are only <a href="https://github.com/golang/go/blob/c8c646d31bec3cbe56ecf5a26fbbd235c97cfb21/src/internal/buildcfg/exp.go#L44-L51">enabled for amd64 and arm64</a>, so <code>gentraceback</code> will continue to be needed for other platforms regardless. That being said, I&#39;m cautiously optimistic that these hurdles can be overcome by the newly formed <a href="https://github.com/golang/go/issues/57175">runtime diagnostics working group</a>.</p><p>Last but not least, there seems to be renewed <a href="https://lwn.net/Articles/919940/">momentum</a> behind enabling frame pointers for C/C++ applications on Linux where compilers historically disabled them for performance reasons. Those arguments made a lot of sense for 32bit CPUs with limited registers, but they are now being reevaluated. So hopefully the forgotten art of frame pointer unwinding will make a comeback, not just in the tracer, but across the industry as whole. The simplicity and observability benefits would be immense.</p>
    </div></div>
  </body>
</html>
