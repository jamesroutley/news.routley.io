<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://spectrum.ieee.org/openai-not-open">Original</a>
    <h1>Llama and ChatGPT Are Not Open-Source</h1>
    
    <div id="readability-page-1" class="page"><div data-elid="2662333149" data-post-url="https://spectrum.ieee.org/openai-not-open" data-authors="Michael Nolan" data-headline="Llama and ChatGPT Are Not Open-Source" data-page-title="Llama and ChatGPT Are Not Open-Source - IEEE Spectrum"><div><p>Social media and advertising-technology company <a href="https://spectrum.ieee.org/tag/meta">Meta</a> recently <a href="https://spectrum.ieee.org/llama-2-llm" rel="noopener noreferrer" target="_blank">released an update</a> to its <a href="https://spectrum.ieee.org/tag/llms" target="_blank">large language model</a> Llama. <a href="https://ai.meta.com/llama/">Llama 2</a> was released as <a href="https://spectrum.ieee.org/search/?q=open-source" target="_self"><u>open source</u></a>, providing users access to the model’s weights, evaluation code, and documentation. <a href="https://ai.meta.com/resources/models-and-libraries/llama/" rel="noopener noreferrer" target="_blank"><u>Meta states</u></a> the open-source release was intended to make the model “accessible to individuals, creators, researchers, and businesses so they can experiment, innovate, and scale their ideas responsibly.”</p><p>However, compared to other open-source LLMs and open-source software packages more generally, Llama 2 is considerably closed off. Though Meta has made the trained model available, it is not sharing the model’s training data or the code used to train it. While <a href="https://labs.perplexity.ai/" rel="noopener noreferrer" target="_blank"><u>third</u></a><a href="https://huggingface.co/NousResearch/Redmond-Puffin-13B?text=Fish+are+made+of+wood+and+blood%3B+their+offensive+smell+is+not+their+own+fault." rel="noopener noreferrer" target="_blank"><u>parties</u></a> have been able to create applications that extend on the base model, aspiring developers and researchers have a limited ability to pick apart the model as is.</p><p>In a recent <a href="https://arxiv.org/abs/2307.05532" rel="noopener noreferrer" target="_blank"><u>preprint</u></a> in arXiv, a group of AI researchers at <a href="https://www.ru.nl/en" target="_blank">Radboud University</a>, in Nijmegen, Netherlands, argue that Llama 2 is not the only LLM to be questionably labeled as “open source.” In the paper, the scientists present a multidimensional assessment of model openness. They use this rubric to score 15 different nominally open-source LLMs on different aspects of their availability, documentation, and methods of access. The researchers have collected these assessments in an <a href="https://opening-up-chatgpt.github.io/" rel="noopener noreferrer" target="_blank"><u>online table</u></a> that they have since expanded to include 21 different open-source models. Smaller, research-focused models were included in the assessment if they were deemed, as stated in the preprint, “open, sufficiently documented, and released under an open source license.”</p><p>“Meta using the term ‘open source’ for this is positively misleading.” —Mark Dingemanse, Radboud University</p><p>The scientists started the project when looking for AI models to use in their own teaching and research. “If you write a research paper, you want the results to be reproducible for as long as possible,” says <a href="https://www.ru.nl/en/people/liesenfeld-a" target="_blank">Andreas Liesenfeld</a>, one of the preprint’s authors and an assistant professor at Radboud. “That’s something you would specifically value if you do research using these technologies, right? That’s something we did not see, for instance, from ChatGPT”—the chat-bot interface built off of OpenAI’s <a href="https://openai.com/research/gpt-4" rel="noopener noreferrer" target="_blank"><u>Generative Pretrained Transformer (GPT)</u></a> LLM series. Despite what may be inferred from its name, <a href="https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview" target="_blank">OpenAI closed access</a> to much of its research code after launching <a href="https://spectrum.ieee.org/tag/gpt-4">GPT-4</a> and receiving a <a href="https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/?sh=5ec5240d3624" target="_blank">substantial investment from Microsoft</a> earlier this year.</p><p><img alt="text on the left with green, yellow and orange boxes on the right" data-rm-shortcode-id="adc541926c705b8e849abba709e8a928" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/text-on-the-left-with-green-yellow-and-orange-boxes-on-the-right.jpg?id=34681681&amp;width=980" height="896" id="82e91" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%202402%20896&#39;%3E%3C/svg%3E" width="2402"/><small placeholder="Add Photo Caption...">The Radboud University team’s assessment gives very poor marks to ChatGPT’s and Llama’s open-source status. (The <a href="https://opening-up-chatgpt.github.io/" target="_blank">full table</a> had 20 entries at press time, we show only the top and bottom entries here.) </small></p><p>In fact, OpenAI’s <a href="https://spectrum.ieee.org/tag/chatgpt">ChatGPT</a> model has scored the worst out of all models currently assessed on the team’s openness table. Of the available statuses—open, partial, and closed—ChatGPT is marked “closed” in all assessments other than “<a href="https://arxiv.org/abs/1810.03993" rel="noopener noreferrer" target="_blank"><u>model card</u></a>”—a standard format for describing the model and its limitations—and “preprint”—whether or not there is an in-depth research paper about the model. For these two, ChatGPT only gets a “partial” grade. Llama 2 is ranked second worst overall with an overall openness ranking only marginally better than that of ChatGPT.</p><h2>AI’s Reproducibility Problems</h2><p>Liesenfeld’s concerns about the reproducibility of ChatGPT-based research have borne some evidentiary fruit. A separate <a href="https://arxiv.org/abs/2307.09009" rel="noopener noreferrer" target="_blank"><u>preprint</u></a> from scientists at Stanford University and the University of California, Berkeley, recently demonstrated that both GPT-4 and GPT-3.5’s performance on reasoning tasks has changed between March and June of this year, mostly for the worse. These changes have occurred without any accompanying announcement from <a href="https://spectrum.ieee.org/tag/openai">OpenAI</a>. Such changes may prevent the reproduction of any research results produced from the use of these models during that time period.</p><p>While Liesenfeld and their colleagues determined that several smaller, research-focused models were considerably more open than Llama 2 or ChatGPT, they found that all the models they assessed were closed in two key ways. First, very few of the models gave sufficient detail of the important refinement process required of modern LLM function, also known as <a href="https://arxiv.org/pdf/1706.03741.pdf" rel="noopener noreferrer" target="_blank"><u>reinforcement learning with human feedback (RLHF)</u></a>. This key step, which tunes language models to give useful outputs from the statistical patterns trained into them during model pretraining, appears to be the secret sauce behind contemporary LLM performance. The process is <a href="https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots" rel="noopener noreferrer" target="_blank"><u>labor-intensive</u></a>, requiring human-in-the-loop assessment of model outputs during training.</p><p>The second major issue the researchers point to is the ways commercial LLM releases have avoided the peer review process. While publishing model architecture, training methods, and performance through reviewed conferences or journals is a well-established practice in academic research, ChatGPT and Llama 2 were both released with only a company-hosted preprint document, most likely to protect trade secret details around model structure and training.</p><p>While the light this project shines on the variable openness of LLMs may in fact push the field toward truly open-source model development, Liesenfeld and colleagues remain wary of commercial model use in academic research. <a href="https://www.ru.nl/en/people/dingemanse-m" target="_blank">Mark Dingemanse</a>, a coauthor of this report, had a particularly strong assessment of the Llama 2 model: “Meta using the term ‘open source’ for this is positively misleading: There is no source to be seen, the training data is entirely undocumented, and beyond the glossy charts the technical documentation is really rather poor. We do not know why Meta is so intent on getting everyone into this model, but the history of this company’s choices does not inspire confidence. Users beware.”</p></div></div></div>
  </body>
</html>
