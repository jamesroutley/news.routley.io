<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/gaming/2023/03/epics-new-motion-capture-animation-tech-has-to-be-seen-to-be-believed/">Original</a>
    <h1>Epic’s new motion-capture animation tech has to be seen to be believed</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/Screen-Shot-2023-03-22-at-5.35.08-PM-800x421.png" alt="Would you believe that creating this performance took only minutes of video processing and no human tweaking?"/>
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/Screen-Shot-2023-03-22-at-5.35.08-PM.png" data-height="1503" data-width="2858">Enlarge</a> <span>/</span> Would you believe that creating this performance took only minutes of video processing and no human tweaking?</p></figcaption>  </figure>

  




<!-- cache hit 13:single/related:04eb92d35fe59c276af23a7b10a783aa --><!-- empty -->
<p>SAN FRANCISCO—Every year at the Game Developers Conference, a handful of competing companies show off their latest motion-capture technology, which transforms human performances into 3D animations that can be used on in-game models. Usually, these technical demonstrations involve a lot of specialized hardware for the performance capture and a good deal of computer processing and manual artist tweaking to get the resulting data into a game-ready state.</p>
<p>Epic&#39;s upcoming MetaHuman facial animation tool looks set to revolutionize that kind of labor- and time-intensive workflow. In <a href="https://www.youtube.com/watch?v=pnaKyc3mQVk">an impressive demonstration</a> at <a href="https://www.youtube.com/watch?v=teTroOAGZjM">Wednesday&#39;s State of Unreal stage presentation</a>, Epic showed off the new machine-learning-powered system, which needed just a few minutes to generate impressively real, uncanny-valley-leaping facial animation from a simple head-on video taken on an iPhone.</p>
<p>The potential to get quick, high-end results from that kind of basic input &#34;has literally changed how [testers] work or the kind of work they can take on,&#34; Epic VP of Digital Humans Technology Vladimir Mastilovic said in a panel discussion Wednesday afternoon.</p>
<h2>A stunning demo</h2>
<p>The new automatic animation technology builds on <a href="https://www.unrealengine.com/en-US/metahuman">Epic&#39;s MetaHuman modeling tool</a>, which launched in 2021 as a way to manually create highly detailed human models in Unreal Engine 5. Since that launch, over 1 million users have created millions of MetaHumans, Epic said, some from just a few minutes of processing on three photos of a human face.</p>
<p>The main problem with these MetaHumans, as Mastilovic put it on stage Wednesday morning, is that &#34;animating them still wasn&#39;t easy.&#34; Even skilled studios would often need to use a detailed <a href="https://www.vpglossary.com/vpglossary/four-dimensional-4d-capture/">&#34;4D capture&#34;</a> from specialized hardware and &#34;weeks or months of processing time&#34; and human tweaking to get game-usable animation, he said.</p>                                            
                                                        
<figure><p><iframe type="text/html" width="640" height="360" src="https://www.youtube.com/embed/pnaKyc3mQVk?start=0&amp;wmode=transparent" frameborder="0" allowfullscreen=""></iframe></p><figcaption><p>Watch Melina Juergens&#39; performance transformed into a stunningly accurate 3D animation in just minutes.</p></figcaption></figure>
<p>MetaHuman Animator is designed to vastly streamline that process. To demonstrate that, Epic relied on Ninja Theory Performance Artist Melina Juergens, well known for her role as Senua in <a href="https://arstechnica.com/gaming/2015/08/hellblade-dev-wants-the-games-industry-to-grow-up-and-tackle-topics-like-mental-health/">2017&#39;s <em>Hellblade: Senua&#39;s Sacrifice</em></a>.</p>
<p>Juergens&#39; 15-second on-stage performance was captured on a stock iPhone mounted on a tripod in front of her. The resulting video of that performance was then processed on a high-end AMD machine in less than a minute, creating a 3D animation that was practically indistinguishable from the original video.</p>
<p>The speed and fidelity of the result drew a huge round of applause from the developers gathered at the Yerba Buena Center for the Arts and <a href="https://www.youtube.com/watch?v=pnaKyc3mQVk">really needs to be seen to be believed</a>. Tiny touches in Juergens&#39; performance—from bared teeth to minuscule mouth quivers to sideways glances—are all incorporated into the animation in a way that makes it almost indistinguishable from the original video. Even realistic tongue movements are extrapolated from the captured audio, using an &#34;audio to tongue&#34; algorithm that &#34;is what it sounds like,&#34; Mastilovic said.</p>
<p>What&#39;s more, Epic also showed how all those facial tics could be applied not just to Juergens&#39; own MetaHuman model, but to any model built on the same MetaHuman standard. Seeing Juergens&#39; motions and words coming from the mouth of a highly stylized cartoon character, just minutes after she performed them, was striking, to say the least.</p>
<figure><p><iframe type="text/html" width="640" height="360" src="https://www.youtube.com/embed/K1qG8pREfkA?start=0&amp;wmode=transparent" frameborder="0" allowfullscreen=""></iframe></p><figcaption><p>The human performance in this trailer &#34;hasn&#39;t been polished or edited in any way and took a MetaHuman animator just minutes to process, start to finish.&#34;</p></figcaption></figure>
<p>The presentation finished off with the debut of <a href="https://www.youtube.com/watch?v=teTroOAGZjM">a performance-focused trailer for the upcoming <em>Senua&#39;s Saga: Hellblade II</em></a>. That trailer is made all the more impressive by Mastilovic saying that Juergens&#39; full-body motion-captured performance in it &#34;hasn&#39;t been polished or edited in any way and took a MetaHuman animator just minutes to process, start to finish.&#34;</p>

                                                </div></div>
  </body>
</html>
