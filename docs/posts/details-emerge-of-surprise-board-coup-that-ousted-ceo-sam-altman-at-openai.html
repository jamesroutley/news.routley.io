<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/">Original</a>
    <h1>Details emerge of surprise board coup that ousted CEO Sam Altman at OpenAI</h1>
    
    <div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Things fall apart    —
</h4>
            
            <h2 itemprop="description">Microsoft CEO &#34;furious&#34;; OpenAI President and 3 researchers resign. COO says &#34;No malfeasance.&#34;</h2>
            <section>

  


  
</section>        </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/sutskever_header_2-800x450.jpg" alt="Ilya Sutskever, OpenAI Chief Scientist, speaks at Tel Aviv University on June 5, 2023."/>
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/sutskever_header_2.jpg" data-height="675" data-width="1200">Enlarge</a> <span>/</span> Ilya Sutskever, OpenAI Chief Scientist, speaks at Tel Aviv University on June 5, 2023.</p></figcaption>  </figure>

  




<!-- cache hit 193:single/related:94cf44775f0ab56ff87fde04dd3d1807 --><!-- empty -->
<p>On Friday, OpenAI <a href="https://arstechnica.com/ai/2023/11/openai-fires-ceo-sam-altman-citing-less-than-candid-communications/">fired CEO Sam Altman</a> in a surprise move that led to the <a href="https://arstechnica.com/information-technology/2023/11/openai-president-greg-brockman-quits-as-nervous-employees-hold-all-hands-meeting/">resignation</a> of President Greg Brockman and <a href="https://x.com/hellokillian/status/1725797467315486902?s=20">three senior scientists</a>. The move also blindsided key investor and minority owner Microsoft, <a href="https://www.bloomberg.com/news/articles/2023-11-18/openai-altman-ouster-followed-debates-between-altman-board#xj4y7vzkg">reportedly</a> making CEO Satya Nadella furious. As Friday night wore on, <a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety">reports emerged</a> that the ousting was likely orchestrated by Chief Scientist Ilya Sutskever over concerns about the safety and speed of OpenAI&#39;s tech deployment.</p>

<p>&#34;This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity,&#34; Sutskever told employees at an emergency all-hands meeting on Friday afternoon, as reported by <a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety">The Information</a>.</p>
<p>Since its founding, OpenAI has pursued the development of artificial general intelligence (or AGI), which is a hypothetical technology that would be able to perform any intellectual task a human can do, potentially replacing a large number of humans at their jobs.</p>
<p>Internally at OpenAI, insiders say that disagreements had emerged over the speed at which Altman was pushing for commercialization and company growth, with Sutskever arguing to slow things down. Sources <a href="https://x.com/karaswisher/status/1725702612379378120?s=20">told</a> reporter Kara Swisher that OpenAI&#39;s <a href="https://arstechnica.com/information-technology/2023/11/openai-introduces-gpt-4-turbo-larger-memory-lower-cost-new-knowledge/">Dev Day event</a> on November 6, with Altman front and center in a keynote pushing consumer-like products, was an &#34;inflection moment of Altman pushing too far, too fast.&#34;</p>
<p>In a <a href="https://x.com/gdb/status/1725736242137182594?s=20">joint statement</a> released Friday night, Altman and Brockman said they were &#34;shocked and saddened&#34; by the board&#39;s actions. And they weren&#39;t the only ones shocked by the news, as tech insiders took to social media on Friday to share their reactions. Angel investor Ron Conway <a href="https://x.com/RonConway/status/1725759359748309381?s=20">wrote</a>, &#34;What happened at OpenAI today is a Board coup that we have not seen the likes of since 1985 when the then-Apple board pushed out Steve Jobs. It is shocking; it is irresponsible; and it does not do right by Sam &amp; Greg or all the builders in OpenAI.&#34;</p>
<p>OpenAI has an <a href="https://openai.com/our-structure">unusual structure</a> where its for-profit arm is owned and controlled by a non-profit 501(c)(3) public charity. Prior to yesterday, that non-profit was controlled by a board of directors that <a href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/">included</a> Altman, Brockman, Ilya Sutskever and three others who were not OpenAI employees: Adam D’Angelo, the CEO of Quora; Tasha McCauley, an adjunct senior management scientist at RAND corporation; and Helen Toner, director of strategy and foundational research grants at Georgetown’s Center for Security and Emerging Technology. Now, only Sutskever, D&#39;Angelo, McCauley, and Toner remain.</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg" data-height="652" data-width="873" alt="A block diagram of OpenAI&#39;s unusual structure, provided by OpenAI."><img alt="A block diagram of OpenAI&#39;s unusual structure, provided by OpenAI." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure-640x478.jpg" width="640" height="478" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg 2x"/></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg" data-height="652" data-width="873">Enlarge</a> <span>/</span> A block diagram of OpenAI&#39;s unusual structure, provided by OpenAI.</p></figcaption></figure>
<h2>Surprise moves and turmoil</h2>
<p>According to the joint statement from Brockman and Altman, Altman&#39;s firing came as a complete surprise to the pair, and they laid out a rough timeline of what happened. On Thursday night, Altman was asked to attend a remote board meeting on Friday at noon. The next day, Brockman, who was Chairman of the OpenAI board, was not invited to this board meeting, where Altman was fired.</p>

<p>Around 30 minutes later, Brockman was informed by Sutskever that he was being removed from his board role but could remain at the company, and that Altman had been fired (Brockman declined, and <a href="https://arstechnica.com/information-technology/2023/11/openai-president-greg-brockman-quits-as-nervous-employees-hold-all-hands-meeting/">resigned</a> his role later on Friday). According to Brockman, the OpenAI management team was only made aware of these moves shortly after the fact, but former CTO (now interim CEO) Mira Murati had been informed on Thursday night.</p>
<p>Key questions remain about accusations made against Altman in the <a href="https://openai.com/blog/openai-announces-leadership-transition">OpenAI blog post</a> that announced his departure, where the board said that Altman &#34;was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities.&#34; That has yet to be clarified by the company, but insiders say the move was mostly a power play that resulted from a cultural schism between Altman and Sutskever over Altman&#39;s <a href="https://x.com/karaswisher/status/1725733594310512775?s=20">management style</a> and drive for high-profile publicity. On September 29, Sutskever <a href="https://x.com/ilyasut/status/1707752576077176907?s=20">tweeted</a>, &#34;Ego is the enemy of growth.&#34;</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-scaled.jpg" data-height="1707" data-width="2560" alt="Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023."><img alt="Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-640x427.jpg" width="640" height="427" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-1280x853.jpg 2x"/></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-scaled.jpg" data-height="1707" data-width="2560">Enlarge</a> <span>/</span> Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023.</p></figcaption></figure>
<p>The schism is causing further turmoil on the inside. Three AI researchers loyal to Altman departed the company as well on Friday, resigning in reaction to the news: Jakub Pachocki, GPT-4 lead and OpenAI&#39;s director of research; Aleksander Madry, head of a team evaluating AI risk, and Szymon Sidor, an open source baselines researcher.</p>
<h2>Pushing back the &#34;veil of ignorance&#34;</h2>
<p>Rumors have already begun swirling about potential internal breakthroughs at OpenAI that may have intensified the slow/fast rift within the company, owing to Sutskever&#39;s role as co-lead of a &#34;<a href="https://openai.com/blog/introducing-superalignment">Superalignment</a>&#34; team that is tasked with figuring out how to control hypothetical superintelligent AI. At the APEC CEO Summit on Thursday, Altman <a href="https://x.com/thecaptain_nemo/status/1725743009629983215?s=20">said</a>, &#34;Four times now in the history of OpenAI—the most recent time was just in the last couple of weeks—I’ve gotten to be in the room when we push the veil of ignorance back and the frontier of discovery forward. And getting to do that is like the professional honor of a lifetime.&#34;</p>                                            
                                                        

<p>The concern here not necessarily being that OpenAI has developed superintelligence, which experts say is unlikely, but that the new breakthrough Altman mentioned may have added pressure to a company that is fighting within itself to proceed safely (from its non-profit branch) but also make money (from its for-profit subsidiary). Altman also <a href="https://arstechnica.com/ai/2023/11/openai-ceo-sam-altman-wants-to-build-ai-superintelligence/">recently said</a> that GPT-5, presumed to be a powerful successor to the <a href="https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/">alarm-causing GPT-4</a>, is now in development.</p>
<p>As news spread, some predictably shared quips on social media. X user shaurya <a href="https://x.com/shauseth/status/1725757968619278587?s=20">wrote</a>, &#34;this is like the roman empire for people who do matrix multiplication.&#34; And AI futurist Daniel Jeffries <a href="https://x.com/Dan_Jeffries1/status/1725807257772872062?s=20">said</a>, &#34;<span>The entire AI industry would like to thank the OpenAI board for giving us all a chance to catch up.</span>&#34;</p>
<p>But not all reactions were doom and gloom. As Friday night wore on, some at OpenAI made forward-looking statements. Evan Morikawa, Engineering Manager at OpenAI <a href="https://x.com/E0M/status/1725721507161395415?s=20">wrote on X</a>, &#34;For those wondering what’ll happen next, the answer is we’ll keep shipping. @sama &amp; @gdb weren’t micro-managers. The ✨ comes from the many geniuses here in research product eng &amp; design. There’s clear internal uniformity among these leaders that we’re here for the bigger mission.&#34;</p>
<p>Expect to hear more on the OpenAI board&#39;s side of the story as further details emerge.</p>
<p><strong>Update: 11/18/2023 - 2:30 PM Eastern</strong></p>
<h2>&#34;Decision not made in response to malfeasance&#34;</h2>
<p>An internal memo written by OpenAI chief operating officer Brad Lightcap <a href="https://www.axios.com/2023/11/18/openai-memo-altman-firing-malfeasance-communications-breakdown">obtained by Axios</a> says that the board&#39;s decision to fire Altman &#34;was not made in response to malfeasance or anything related to our financial, business, safety, or security/privacy practices. This was a breakdown in communication between Sam and the board.&#34;</p>
<p>The memo states that the announcement to fire Altman &#34;took all of us by surprise,&#34; and that Lightcap has made efforts to better understand &#34;the reasons and process behind their decision.&#34;</p>
<p>&#34;I&#39;m sure you all are feeling confusion, sadness, and perhaps some fear,&#34; Lightcap writes. &#34;We are fully focused on handling this, pushing toward resolution and clarity, and getting back to work. Our collective responsibility right now is to our teammates, partners, users, customers, and the broader world who shares our vision of broadly beneficial AGI. Hang in there, we are behind you all 1000%.&#34;</p>
<p>After reassuring staff that the company&#39;s position remains strong and expressing support for Mira Murati as interim CEO, he states, &#34;We still share your concerns about how the process has been handled, are working to resolve the situation, and will provide updates as we&#39;re able.&#34;</p>

                                                </div>

            
            
        </section>
    </div></div>
  </body>
</html>
