<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://juno-labs.com/blogs/every-company-building-your-ai-assistant-is-an-ad-company">Original</a>
    <h1>Every company building your AI assistant is now an ad company</h1>
    
    <div id="readability-page-1" class="page">
    <!-- Pre-order banner -->
    <a href="https://store.juno-labs.com">
      Pre-orders for the Juno Pioneer Edition now open, reserve your Juno today!
    </a>

    <!-- Font family toggle -->
    

    <!-- Table of Contents Sidebar -->
    

    

    <p>
      Friday, 20 February 2026 Â·
      <a href="https://juno-labs.com/cdn-cgi/l/email-protection#dfbebbbeb29fb5aab1b0f2b3bebdacf1bcb0b2">Adam Juhasz</a>
    </p>

    <p>
      On January 16, OpenAI quietly announced that ChatGPT would begin showing
      advertisements. By February 9th, ads were live. Eight months earlier,
      OpenAI spent $6.5 billion to acquire Jony Ive&#39;s hardware startup io.
      They&#39;re building a pocket-sized, screenless device with built-in cameras
      and microphones -- &#34;contextually aware,&#34; designed to replace your phone.
    </p>

    <p>
      But this isn&#39;t a post about OpenAI. They&#39;re just the latest. The problem
      is structural.
    </p>

    <p>
      <strong>Every single company<sidenote><a href="https://9to5mac.com/2025/04/14/apple-rebrands-search-ads-business-as-apple-ads/">We can quibble about Apple.</a></sidenote>
        building AI assistants is now funded by advertising.</strong>
      And every one of them is building hardware designed to see and hear
      everything around you, all day, every day. These two facts are on a
      collision course, and local on-device inference is the only way off the
      track.
    </p>

    <h2>The always-on future is inevitable</h2>

    <p>
      Before we talk about who&#39;s building it, let&#39;s be clear about
      <em>what&#39;s</em> being built.
    </p>

    <p>
      Every mainstream voice assistant today works behind a gate. You say a
      magic word -- &#34;Hey Siri,&#34; &#34;OK Google,&#34; &#34;Alexa&#34; -- and only then does the
      system listen. Everything before the wake word is theoretically discarded.
    </p>

    <p>
      This was a reasonable design in 2014. It is a dead end for where AI
      assistance needs to go.
    </p>

    <p>
      Here&#39;s what happens in a real kitchen at 6:30am:<sidenote>Anonymized from one of our test homes. The real version was messier and
        included a toddler screaming about Cheerios.</sidenote>
    </p>
    <blockquote>
      &#34;Are we out of eggs again? I&#39;m thinking frittata tonight but we also need
      to -- oh wait, did the school email about Thursday? I think there&#39;s a
      early release. Anyway, if we don&#39;t have eggs, I&#39;ll get them from Target
      and also that dish soap, the blue one.&#34;
    </blockquote>

    <p>
      Nobody is going to preface that with a wake word. The information is woven
      into natural speech between two flustered parents getting the family ready
      to leave the house. The moment you require a trigger, you lose the most
      valuable interactions -- the ones that happen while people are living
      their lives, not thinking of how to give context to an AI assistant.
    </p>

    <p>
      You cannot build proactive assistance behind a wake word. The AI has to be
      present in the room, continuously, accumulating context over days and
      weeks and months, to build the understanding that makes proactive help
      possible.
    </p>

    <p>
      This is where every major AI company is heading. Not just audio -- vision,
      presence detection, wearables, multi-room awareness. The next generation
      of AI assistants will hear and see everything. Some will be on your face
      or in your ears all day. They will be always on, always sensing, always
      building a model of your life.
    </p>

    <p>
      <strong>
        The question is not <em>whether</em> always-on AI will happen. It&#39;s who
        controls the data it collects. And right now, the answer to that
        question is: advertising companies.</strong>
    </p>

    <h2>Policy is a promise. Architecture is a guarantee.</h2>

    <p>
      Here&#39;s where the industry&#39;s response gets predictable. &#34;We encrypt the
      data in transit.&#34; &#34;We delete it after processing.&#34; &#34;We anonymize
      everything.&#34; &#34;Ads don&#39;t influence the AI&#39;s answers.&#34; &#34;Read our privacy
      policy.&#34;<sidenote>With cloud processing, every user is trusting:</sidenote>
    </p>

    <p>
      OpenAI&#39;s own ad announcement includes this language: &#34;OpenAI keeps
      conversations with ChatGPT private from advertisers, and never sells data
      to advertisers.&#34; It sounds reassuring. But Google
      <a href="https://en.wikipedia.org/wiki/Privacy_concerns_with_Google#Gmail">scanned every Gmail for ad targeting for thirteen years</a>
      before quietly stopping in 2017. Policies change. Architectures don&#39;t.
    </p>

    <p>Policy is a promise. Architecture is a guarantee.</p>

    <p>
      When a device processes data locally, the data
      <em>physically cannot leave the network</em>. There is no API endpoint to
      call. There is no telemetry pipeline. There is no &#34;anonymized usage data&#34;
      that somehow still contains enough signal to be useful for ad targeting.
      The inference hardware sits inside the device or in the user&#39;s home, on
      their network.
    </p>

    <p>
      Your email is sensitive. A continuous audio and visual feed of your home
      is something else entirely. It captures arguments, breakdowns, medical
      conversations, financial discussions, intimate moments, parenting at its
      worst, the completely unguarded version of people that exists only when
      they believe nobody is watching.<sidenote>We wrote a deep dive on our memory system in
        <a href="https://juno-labs.com/blogs/building-memory-for-an-always-on-ai-that-listens-to-your-kitchen.html">Building Memory for an Always-On AI That Listens to Your Kitchen</a>.</sidenote>
    </p>

    <p>
      Amazon already showed us what happens.
      <a href="https://www.entrepreneur.com/business-news/amazon-echo-ends-do-not-send-voice-recordings-option/488677">They eliminated local voice processing.</a>
      <a href="https://alexaechos.com">They planned to feed Alexa conversations to advertisers.</a>
      <a href="https://www.eff.org/deeplinks/2025/07/amazon-ring-cashes-techno-authoritarianism-and-mass-surveillance">
        They partnered Ring with a surveillance network that had federal law
        enforcement access.</a>
      What happens when those same economic incentives are applied to devices
      that capture everything?
    </p>

    <h2>The edge inference stack is ready</h2>

    <p>
      The counterargument is always the same: &#34;Local models aren&#39;t good enough.&#34;
      Three years ago, that was true. It is no longer true.
    </p>

    <p>
      You can run a complete ambient AI pipeline today -- real-time
      speech-to-text, semantic memory, conversational reasoning, text-to-speech,
      etc -- on a device that fits next to a cable box (remember those?). No fan
      noise. A one-time hardware purchase with no per-query fee and no data
      leaving the building. New model architectures, better compression, and
      open-source inference engines have converged to make this possible, and
      the silicon roadmap points in one direction: more capability per watt,
      every year.<sidenote>We&#39;ve been running always-on prototypes in five homes. The complaints
        we get are about the AI misunderstanding context, not about raw model
        capability. That&#39;s a memory architecture problem, not a model size
        problem.</sidenote>
    </p>

    <p>
      Are local models as capable as the best cloud models? No. But we&#39;re
      usually not asking our smart speaker to re-derive the Planck constant.
    </p>

    <p>
      Hardware that runs inference on-device. Models that process audio and
      video locally and never transmit it.
      <strong>There needs to be a business model based on selling the hardware and
        software, not the data the hardware collects. An architecture where the
        company that makes the device <em>literally cannot access</em> the data
        it processes, because there is no connection to access it
        through.</strong>
    </p>

    <p>
      The most helpful AI will also be the most intimate technology ever built.
      It will hear everything. See everything. Know everything about the family.
      The only architecture that keeps that technology safe is one where it is
      structurally incapable of betraying that knowledge. Not policy. Not
      promises. Not a privacy setting that can be quietly removed in a March
      software update.
    </p>

    <p>
      Choose local. Choose edge. Build the AI that knows everything but phones
      home nothing.
    </p>

    <hr/>

    
  


</div>
  </body>
</html>
