<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.collabora.com/news-and-blog/blog/2022/03/23/how-to-write-vulkan-driver-in-2022/">Original</a>
    <h1>How to write a Vulkan driver in 2022</h1>
    
    <div id="readability-page-1" class="page"><p>An incredible amount has changed in Mesa and in the Vulkan ecosystems since we wrote the first Vulkan driver in Mesa for Intel hardware back in 2015. Not only has Vulkan grown, but Mesa has as well, and we&#39;ve built up quite a suite of utilities and helpers for making writing Vulkan drivers easier. This blog post will be a tutorial of sorts (we won&#39;t have a functioning Vulkan driver in the end, sorry), showing off a bunch of those helpers and demonstrating the latest Mesa best practices for Vulkan drivers.</p><p>Vulkan in Mesa started with this git commit from Kristian Kristansen who was at Intel at the time:</p><p>Kristian, Chad Versace, and I had just pivoted from a different prototype project to working on Vulkan. Kristian started us off with a very skeletal start to a driver with lots of hard-coded values, just barely capable of drawing a triangle. We continued developing the driver internally (Vulkan was still under an NDA at the time) until we were <a href="https://lists.freedesktop.org/archives/mesa-announce/2016-February/000201.html" target="_blank" rel="nofollow noreferrer noopener">finally able to go public</a> on February 16 of 2016, when the Vulkan spec was released, and the NDA lifted.</p><p>At the time we were developing ANV (the Intel Vulkan driver), the Vulkan spec itself was still under development and everything was constantly in flux. There were no best practices; there were barely even tools. Everyone working on Vulkan was making it up as they went because it was a totally new API. Most of the code we wrote was purpose-built for the Intel driver because there were no other Mesa drivers to share code. (Except for the short-lived LunarG Intel driver based in ilo, which we were replacing.) If we had tried to build abstractions, they could have gotten shot to pieces at any moment by a spec change. (We rewrote the descriptor set layout code from scratch at least five or six times before the driver ever shipped.) It was frustrating, exhausting, and a whole lot of fun.</p><p>These days, however, the Vulkan spec has been stable and shipping for six years, the tooling and testing situation is pretty solid, and there are six Vulkan drivers in the Mesa tree with more on the way. We&#39;ve also built up a lot of common infrastructure. This is important both because it makes writing a Vulkan driver easier and because it lets us fix certain classes of annoying bugs in a common place instead of everyone copying and pasting those bugs. So, without further ado, let&#39;s get down to it!</p><p>First off, every driver needs a name. We&#39;re not actually writing one here but it&#39;ll make the examples easier if we pretend we are. Just for the sake of example, I&#39;m going to pick on NVIDIA because... Why not? Such a driver is clearly missing and really should happen soon. (Hint! Hint!) We&#39;re going to call this hypothetical new Vulkan driver NVK. It&#39;s short and obvious. If you don&#39;t like me picking on NVIDIA, just pretend it stands for &#34;New VulKan&#34; or nouvulkan, if you prefer.</p><p>The first thing we need for this driver is a folder to put it in. Most Vulkan drivers live in <code>src/&lt;vendor&gt;/vulkan</code>. A typical directory structure looks something like this:</p><p>If there is already a driver for OpenGL or OpenGL ES, it probably lives in <code>src/gallium/drivers/&lt;driver&gt;/</code>. If you want to re-use the compiler (you probably do) then it will have to be moved. You may also want to pull other common components into <code>src/&lt;vendor&gt;</code> such as an image memory layout calculation library, device info structures, or anything else which you want to share. You don&#39;t necessarily need to do all the code motion before starting on Vulkan, but you&#39;ll want to do it early in the project before it becomes a headache.</p><p>Put the following in <code>src/&lt;vendor&gt;/vulkan/meson.build</code> and adjust as needed for your driver:</p><div>
<pre>nvidia_icd = custom_target(
  &#39;nvidia_icd&#39;,
  input : [vk_icd_gen, vk_api_xml],
  output : &#39;nvidia_icd.@0@.json&#39;.format(host_machine.cpu()),
  command : [
    prog_python, &#39;@INPUT0@&#39;,
    &#39;--api-version&#39;, &#39;1.3&#39;, &#39;--xml&#39;, &#39;@INPUT1@&#39;,
    &#39;--lib-path&#39;, join_paths(get_option(&#39;prefix&#39;), get_option(&#39;libdir&#39;),
                             &#39;libvulkan_nvidia.so&#39;),
    &#39;--out&#39;, &#39;@OUTPUT@&#39;,
  ],
  build_by_default : true,
  install_dir : with_vulkan_icd_dir,
  install : true,
)

nvk_files = files( )

nvk_deps = [ ]

libvulkan_nvidia = shared_library(
  &#39;vulkan_nvidia&#39;,
  [ nvk_files ],
  include_directories : [ inc_include, inc_src, ],
  dependencies : nvk_deps,
  gnu_symbol_visibility : &#39;hidden&#39;,
  install : true,
)
</pre>
<p>This will build a new shared library, <code>libvulkan_nvidia.so</code>, as well as an ICD file named <code>nvidia_icd.&lt;arch&gt;.json</code> which points to it, when installed. There are many details in here around how Vulkan drivers get loaded on multi-arch systems, which I will ignore because they&#39;re very boring.</p>
<h3>Dispatch</h3>
<p>Before we can start implementing Vulkan entrypoints, we need to set up the dispatch infrastructure. Put the following (and modify as needed) into <code>src/&lt;vendor&gt;/vulkan/meson.build</code>:</p>
<pre>nvk_entrypoints = custom_target(
  &#39;nvk_entrypoints&#39;,
  input : [vk_entrypoints_gen, vk_api_xml],
  output : [&#39;nvk_entrypoints.h&#39;, &#39;nvk_entrypoints.c&#39;],
  command : [
    prog_python, &#39;@INPUT0@&#39;, &#39;--xml&#39;, &#39;@INPUT1@&#39;, &#39;--proto&#39;, &#39;--weak&#39;,
    &#39;--out-h&#39;, &#39;@OUTPUT0@&#39;, &#39;--out-c&#39;, &#39;@OUTPUT1@&#39;, &#39;--prefix&#39;, &#39;nvk&#39;,
  ],
  depend_files : vk_entrypoints_gen_depend_files,
)
</pre>
<p>This will generate two files: <code>nvk_entrypoints.h</code> and <code>nvk_entrypoints.c</code>. The first contains function prototypes for every Vulkan entrypoint with the <code>vk</code> prefix replaced with <code>&lt;prefix&gt;_</code>. For example, since we passed <code>--prefix nvk</code> to the generation script, <code>vkCreateDevice()</code> will be named <code>nvk_CreateDevice()</code>. The second file, <code>nvk_entrypoints.c</code> contains generated entrypoint tables containing your entrypoints. You don&#39;t have to do anything special to declare what entrypoints you actually define. Thanks to a bit of compiler magic, any entrypoints you don&#39;t define will show up as <code>NULL</code> in the table.</p>
<p dir="auto" data-sourcepos="162:1-165:14">To ensure these get added into your driver library, you&#39;ll need to add <code>nvk_entrypoints</code> to the input list in your <code>shared_library()</code> call and <code>idep_vulkan_util</code> and <code>idep_vulkan_runtime</code> to <code>nvk_deps in your </code>meson.build`:</p>
<pre>nvk_files = files( )

nvk_deps = [
  idep_vulkan_runtime,
  idep_vulkan_util,
]

libvulkan_nvidia = shared_library(
  &#39;vulkan_nvidia&#39;,
  [ nvk_entrypoints, nvk_files ],
  include_directories : [ inc_include, inc_src, ],
  dependencies : nvk_deps,
  gnu_symbol_visibility : &#39;hidden&#39;,
  install : true,
)
</pre>
<p>(<strong>Note:</strong> The weak function pointers used to implement entrypoint tables occasionally break in strange ways depending on link order. The solution is to ensure that anything which pulls in intermediate libraries which contain Vulkan entrypoints is linked with <code>link_whole</code>, unless you&#39;re using the Visual Studio compiler. See <code>src/vulkan/runtime/meson.build</code> for more details.)</p>
<h3>Setting up the instance</h3>
<p>We&#39;re about to start defining structs that are part of your new Vulkan driver so we&#39;ll need somewhere to put them. Most Vulkan drivers in Mesa today lump everything into <code>&lt;prefix&gt;_private.h</code> because we did that with ANV, and everyone copied+pasted that structure. If you want to be a bit better organized, go for it! We&#39;ll use <code>nvk_private.h</code> because I&#39;m boring and don&#39;t want to strain my brain just for a blog post.</p>
<p>In <code>nvk_private.h</code>, we&#39;ll need to define a <code>nvk_instance</code> struct to hold our instance and any related data, so we&#39;ll put the following in <code>nvk_private.h</code>:</p>
<pre><span><strong>#include &#34;nvk_entrypoints.h&#34;
#include &#34;vulkan/runtime/vk_instance.h&#34;
#include &#34;vulkan/runtime/vk_log.h&#34;
#include &#34;vulkan/util/vk_alloc.h&#34;</strong></span>

<strong>struct <span>nvk_instance</span></strong> {
   <strong>struct <span>vk_instance</span></strong> vk;

  <span> <em>/* Any other stuff you want goes here */</em></span>
};

VK_DEFINE_HANDLE_CASTS(nvk_instance, vk.base, VkInstance,
                       VK_OBJECT_TYPE_INSTANCE)
</pre>
<p>As you can see, the first element of our <code>nvk_instance</code> struct is a <code>vk_instance</code> called <code>vk</code>. This acts as the base class for all Vulkan instances in Mesa and stores a bunch of useful stuff for debug logging, dispatch, etc. If you look at the definition of <code>vk_instance</code>, you&#39;ll see that its first member is <code>vk_object_base</code>. Every Vulkan object in your driver <em>must</em> be derived from <code>vk_object_base</code> and the base struct must always be the first member. This is because there are a few things which use void pointer casts because of C&#39;s lack of support for proper subclassing. However, it&#39;s not as bad as you may think because we do have mechanisms for attempting to verify a <code>vk_object_base</code> pointer at runtime, so it&#39;s not quite as unsafe as it sounds.</p>
<p>The <code>VK_DEFINE_HANDLE_CASTS</code> macro defines a pair of functions: <code>nvk_instance_to_handle()</code> and <code>nvk_instance_from_handle()</code> which do about what you&#39;d expect: convert a <code>VkInstance</code> to and from a <code>struct nvk_instance *</code>. These also enable the use of the <code>VK_FROM_HANDLE()</code> macro, which we&#39;ll see shortly. When converting from a <code>VkInstance</code> to a <code>nvk_instance</code> pointer, we assert at runtime that the object type is <code>VK_OBJECT_TYPE_INSTANCE</code> to provide a bit of added type safety because some handle types just map to <code>uint64_t</code> and so have no real compile-time type information.</p>
<p>Now that we have the header file in shape, it&#39;s time for some code. We&#39;ll create a new file called <code>nvk_device.c</code> for all our instance and device-level stuff. (Again, yes, we could stand to be better organized.) We&#39;ll start with our table of supported instance extensions:</p>
<pre><strong>#include &#34;nvk_private.h&#34;</strong>

<strong>static const struct <span>vk_instance_extension_table</span></strong> instance_extensions = {
   .KHR_get_physical_device_properties2   = <span>true</span>,
   .EXT_debug_report                      = <span>true</span>,
   .EXT_debug_utils                       = <span>true</span>,
};
</pre>
<p>You may want more than this eventually, but these three you&#39;ll want to implement right away. Both VK_EXT_debug_report and VK_EXT_debug_utils will be implemented for you if you use the right base structs. All you have to do is advertise them. KHR_get_physical_device_properties2 is one you&#39;ll have to implement, but it&#39;s basically required for Vulkan these days, so there&#39;s no sense in waiting.</p>
<p>Next, we implement <code>nvk_CreateInstance()</code>:</p>
<pre>VKAPI_ATTR VkResult VKAPI_CALL
<span><strong>nvk_CreateInstance</strong></span>(<strong>const</strong> VkInstanceCreateInfo *pCreateInfo,
                   <strong>const</strong> VkAllocationCallbacks *pAllocator,
                   VkInstance *pInstance)
{
   <strong>struct <span>nvk_instance</span></strong> *instance;
   VkResult result;

   <strong>if</strong> (pAllocator == <span>NULL</span>)
      pAllocator = vk_default_allocator();

   instance = vk_alloc(pAllocator, <strong>sizeof</strong>(*instance), <span>8</span>,
                       VK_SYSTEM_ALLOCATION_SCOPE_INSTANCE);
   <strong>if</strong> (!instance)
      <strong>return</strong> vk_error(<span>NULL</span>, VK_ERROR_OUT_OF_HOST_MEMORY);

   <strong>struct <span>vk_instance_dispatch</span></strong>_table dispatch_table;
   vk_instance_dispatch_table_from_entrypoints(
      &amp;dispatch_table, &amp;nvk_instance_entrypoints, <span>true</span>);

   result = vk_instance_init(&amp;instance-&gt;vk, &amp;instance_extensions,
                             &amp;dispatch_table, pCreateInfo, pAllocator);
   <strong>if</strong> (result != VK_SUCCESS) {
      vk_free(pAllocator, instance);
      <strong>return</strong> result;
   }

   <span><em>/* Initialize driver-specific stuff */</em></span>

   <strong>return</strong> VK_SUCCESS;
}
</pre>
<p>Let&#39;s start with allocation. Most vulkan entrypoints which create or destroy an object take a <code>VkAllocationCallbacks</code> pointer, which you&#39;re supposed to use to allocate memory for the object. Working with these manually is tedious at best so we provide helpful <code>vk_alloc/free</code> which allocate with respect to the requested allocator. The <code>vk_alloc2/free2</code> versions take two allocators and implement the required fall-back. We also provide <code>vk_default_allocator()</code> which is an allocator that maps everything to the C standard library <code>malloc/free()</code>. These and a few other nifty allocation helpers can be found in <code>src/vulkan/util/vk_alloc.h</code>.</p>
<p>Before we can actually initialize the base <code>vk_instance</code>, we need to convert our entrypoint table to a dispatch table. The entrypoint table generator we invoked earlier generates a <code>vk_entrypoint_table</code> but <code>vk_instance_init</code> wants a <code>vk_dispatch_table</code>. What&#39;s the difference, and why are there two of them? That&#39;s a topic for another day. The short version is that the conversion deals with de-duplicating entrypoints from when an extension gets promoted.</p>
<p>Finally, we can actually initialize our <code>vk_instance</code> by calling <code>vk_instance_init()</code>. This function does a bit more than just initialize a data structure. It sets up all the logging infrastructure for instance create logging through VK_EXT_debug_utils. It also does a few Vulkan API version number checks and checks to ensure that every extension specified by <code>VkInstanceCreateInfo::ppEnabledExtensionNames</code> is actually supported by your implementation and returns <code>VK_ERROR_EXTENSION_NOT_PRESENT</code> if an unsupported extension is requested.</p>
<p>And there you go! You&#39;ve created your first <code>VkInstance</code> object. For completeness, we should also implement <code>vkDestroyInstance()</code>:</p>
<pre>VKAPI_ATTR <span><strong>void</strong></span> VKAPI_CALL
<span><strong>nvk_DestroyInstance</strong></span>(VkInstance _instance,
                    <strong>const</strong> VkAllocationCallbacks *pAllocator)
{
   VK_FROM_HANDLE(nvk_instance, instance, _instance);

   <strong>if</strong> (!instance)
      <strong>return</strong>;

   vk_instance_finish(&amp;instance-&gt;vk);
   vk_free(&amp;instance-&gt;vk.alloc, instance);
}
</pre>
<p>Before we brush past it, there is one interesting thing here: the call to <code>VK_FROM_HANDLE()</code>. This macro declares a pointer to a <code>struct nvk_instance</code> and initializes it with <code>nvk_instance_to_handle(_instance)</code>. Because these sorts of casts are so prevalent in a Vulkan driver, especially at the tops of entrypoints, having a macro for it helps the ergonomics a good bit.</p>
<p>Now that we have an instance, we can implement <code>vkGetInstanceProcAddr()</code> trivially as it&#39;s just a wrapper around a helper provided in <code>vk_instance.h</code>:</p>
<pre>VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL
<span><strong>nvk_GetInstanceProcAddr</strong></span>(VkInstance _instance,
                        <strong>const <span>char</span></strong> *pName)
{
   VK_FROM_HANDLE(nvk_instance, instance, _instance);
   <strong>return</strong> vk_instance_get_proc_addr(&amp;instance-&gt;vk,
                                    &amp;nvk_instance_entrypoints,
                                    pName);
}

PUBLIC VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL
<span><strong>vk_icdGetInstanceProcAddr</strong></span>(VkInstance instance,
                          <strong>const <span>char</span></strong> *pName);


PUBLIC VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL
<span><strong>vk_icdGetInstanceProcAddr</strong></span>(VkInstance instance,
                          <strong>const <span>char</span></strong> *pName)
{
   <strong>return</strong> nvk_GetInstanceProcAddr(instance, pName);
}
</pre>
<p>The last bit adds a wrapper, so we also expose the more loader-friendly <code>vk_icdGetInstanceProcAddr()</code>. For more details about the loader interface, see the <a href="https://github.com/KhronosGroup/Vulkan-Loader/blob/master/docs/LoaderDriverInterface.md" target="_blank" rel="nofollow noreferrer noopener">loader driver interface doc</a>.</p>
<h3>Logging</h3>
<p>Before we get into creating other objects, we should explain that <code>vk_error()</code> call in <code>nvk_CreateInstance()</code>. This is part of the broader common logging framework found in <code>src/vulkan/runtime/vk_log.h</code>. Any messages logged through this framework automatically get broadcast to <code>stderr</code> in debug builds, the Android logging framework if you&#39;ve built for Android, and passed to the client via VK_EXT_debug_report and VK_EXT_debug_utils.</p>
<p>For most log messages, use the <code>vk_log*</code> family of macros. These are printf-like macros and support anything that your C standard library&#39;s <code>printf()</code> call does. For instance, to log a debug-level message on a device, do:</p>
<pre>vk_logd(VK_LOG_OBJS(device), <span>&#34;vkDeviceWaitIdle() took %u us&#34;</span>, wait_time);
</pre>
<p>The <code>VK_LOG_OBJS()</code> macro can take up to 8 objects which will be passed along with the message to any <code>VkDebugUtilsMessangerEXT</code>s. If you want to log something on the instance only, with no objects, you can use <code>VK_LOG_NO_OBJS(instance)</code> instead. If <code>VK_LOG_NO_OBJS(NULL)</code> is used, then the message will only go to <code>stderr</code> and the Android logging framework because we can&#39;t get the list of messengers.</p>
<p>For errors, there is a special <code>vk_error()</code> macro which takes a <code>VkResult</code> and generates a log message containing the error. If you want to provide additional information in the log message, the <code>vk_errorf()</code> macro is a printf-like macro which generates the same message as <code>vk_error()</code> but with your log message appended. The typical pattern is to wrap each error in a <code>vk_error()</code> or <code>vk_errorf()</code> wherever the error was originally generated. If you&#39;re propagating errors from some other function, there&#39;s no need to wrap because it&#39;s already been logged. We already saw one example when creating our instance above:</p>
<pre>instance = vk_alloc(pAllocator, <strong>sizeof</strong>(*instance), 8,
                    VK_SYSTEM_ALLOCATION_SCOPE_INSTANCE);
<strong>if</strong> (!instance)
   <strong>return <span>vk_error</span></strong>(<span>NULL</span>, VK_ERROR_OUT_OF_HOST_MEMORY);
</pre>
<p>Here&#39;s another example from ANV&#39;s <code>vkMapMemory()</code> implementation:</p>
<pre><strong>if</strong> (mem-&gt;map != <span>NULL</span>) {
   <strong>return</strong> vk_errorf(device, VK_ERROR_MEMORY_MAP_FAILED,
                    <span>&#34;Memory object already mapped.&#34;</span>);
}</pre>
<p>Both macros take an object as their first parameter, the object generating the error. For object creation errors (like out of memory), this should be the parent object, typically a device or instance. If you don&#39;t have a parent object (such as in <code>vkCreateInstance()</code>), you can pass in <code>NULL</code>. As with other logging, this means that it won&#39;t show up in any client call-backs.</p>
<h3>Physical devices</h3>
<p>Physical devices look much the same as instances:</p>
<pre><strong>struct <span>nvk_physical_device</span></strong> {
   <strong>struct <span>vk_physical_device</span></strong> vk;

   <span><em>/* Driver-specific stuff */</em></span>
};

VK_DEFINE_HANDLE_CASTS(nvk_physical_device, vk.base, VkPhysicalDevice,
                       VK_OBJECT_TYPE_PHYSICAL_DEVICE)
</pre>
<p>We won&#39;t spend too much time on the struct, initialization, etc. If you&#39;ve written much C code at all, you know the pattern. One difference between physical devices an instances is when they are created. The instance has an explicit <code>vkCreateInstance()</code> entrypoint whereas physical devices get created implicitly at some unknown time between <code>vkCreateInstance()</code> and the first call to <code>vkEnumeratePhysicalDevice()</code>. Most Mesa Vulkan drivers do the actual walking of <code>/dev/dri</code> and creation of corresponding physical devices as part of the first <code>vkEnumeratePhysicalDevice()</code> to make instance creation faster. I don&#39;t know that this has any tangible benefits but it&#39;s the common pattern in Mesa today.</p>
<p>One other difference from instance initialization which may be useful is that, while <code>vk_physical_device_init()</code> takes a <code>vk_device_extensions</code> struct of supported device extensions, you can also pass NULL and it will simply <code>memset()</code> the table to all false so you can fill it out yourself later. This is because determining feature support often requires that a bunch of the physical device initialization work has already been done. Allowing drivers to re-order initialization such that determining feature support happens late in the process makes things a bit easier. I don&#39;t personally like this and, one day, I&#39;d like to have a better-defined point at which the <code>vk_physical_device</code> is fully initialized, but it&#39;s convenient for now.</p>
<p>If a client is going to use your physical device, they&#39;re going to need to know about supported features, so the next step is to implement <code>vkGetPhysicalDeviceFeatures2()</code> and <code>vkGetPhysicalDeviceProperties2()</code>. Note the 2. Don&#39;t bother implementing the original Vulkan 1.0 calls unless you really want to. If it&#39;s missing from your dispatch table, we&#39;ll implement it for you in terms of <code>vkGetPhysicalDeviceFeatures2()</code> or <code>vkGetPhysicalDeviceProperties2()</code>. Here&#39;s what a <code>vkGetPhysicalDeviceFeatures2()</code> implementation might look like:</p>
<pre>VKAPI_ATTR <span><strong>void</strong></span> VKAPI_CALL
<span><strong>nvk_GetPhysicalDeviceFeatures2</strong></span>(VkPhysicalDevice physicalDevice,
                                 VkPhysicalDeviceFeatures2 *pFeatures)
{
   VK_FROM_HANDLE(nvk_physical_device, pdevice, physicalDevice);

   pFeatures-&gt;features = (VkPhysicalDeviceFeatures) {
      .robustBufferAccess = <span>true</span>,
      <span><em>/* More features */</em></span>
   };

   VkPhysicalDeviceVulkan11Features core_1_1 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_1_FEATURES,
      <span><em>/* Vulkan 1.1 features */</em></span>
   };

   VkPhysicalDeviceVulkan12Features core_1_2 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_2_FEATURES,
      <span><em>/* Vulkan 1.2 features */</em></span>
   };

   VkPhysicalDeviceVulkan13Features core_1_3 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_3_FEATURES,
      <span><em>/* Vulkan 1.3 features */</em></span>
   };

   vk_foreach_struct(ext, pFeatures-&gt;pNext) {
      <strong>if</strong> (vk_get_physical_device_core_1_1_feature_ext(ext, &amp;core_1_1))
         <strong>continue</strong>;
      <strong>if</strong> (vk_get_physical_device_core_1_2_feature_ext(ext, &amp;core_1_2))
         <strong>continue</strong>;
      <strong>if</strong> (vk_get_physical_device_core_1_3_feature_ext(ext, &amp;core_1_3))
         <strong>continue</strong>;

      <strong>switch</strong> (ext-&gt;sType) {
      <strong>case</strong> VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_4444_FORMATS_FEATURES_EXT: {
         VkPhysicalDevice4444FormatsFeaturesEXT *features = (void *)ext;
         features-&gt;formatA4R4G4B4 = <span>true</span>;
         features-&gt;formatA4B4G4R4 = <span>true</span>;
         <strong>break</strong>;
      }
      <span><em>/* More feature structs */</em></span>
      default:
         <strong>break</strong>;
      }
   }
}
</pre>
<p>Most of this is pretty self-explanatory, but there&#39;s some bits around core features and properties that we should discuss. The <code>vk_get_physical_device_core_1_1_feature_ext()</code> call at the top of our loop checks to see if the provided extension struct is <code>VkPhysicalDeviceVulkan11Features</code> or is from an extension promoted to core in Vulkan 1.1 and, if it is, fills it out from the <code>VkPhysicalDeviceVulkan11Features</code> struct we passed in, and returns true to let us know it&#39;s been handled. There are helpers like this for every major Vulkan version. This allows us to avoid any possible mismatches between features advertised through extensions and those advertised through the core structs.</p>
<p>One thing you don&#39;t need to worry about implementing is <code>vkEnumerateDeviceExtensionProperties()</code>. Because the table of supported extensions lives in the <code>vk_physical_device</code>, we can implement that one for you in common code. This saves you the headache of dealing with extension name strings and lets us handle certain annoying Android corner cases for you.</p>
<p>To satisfy the <a href="https://github.com/KhronosGroup/Vulkan-Loader/blob/master/docs/LoaderDriverInterface.md" target="_blank" rel="nofollow noreferrer noopener">loader driver interface requirements</a>, you&#39;ll also need to implement <code>vk_icdGetPhysicalDeviceProcAddr()</code>:</p>
<pre>PUBLIC VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL
<span><strong>vk_icdGetPhysicalDeviceProcAddr</strong></span>(VkInstance  _instance,
                                <strong>const <span>char</span></strong>* pName);

PUBLIC VKAPI_ATTR PFN_vkVoidFunction VKAPI_CALL
<span><strong>vk_icdGetPhysicalDeviceProcAddr</strong></span>(VkInstance  _instance,
                                <strong>const <span>char</span></strong>* pName)
{
   VK_FROM_HANDLE(nvk_instance, instance, _instance);
   <strong>return</strong> vk_instance_get_physical_device_proc_addr(&amp;instance-&gt;vk, pName);
}
</pre>
<h3>Common implementation of entrypoints</h3>
<p>I mentioned above, without much explanation, that if you don&#39;t implement <code>vkGetPhysicalDeviceFeatures()</code> that it will get implemented in terms of <code>vkGetPhysicalDeviceFeatures2()</code>. How does this work? I&#39;m so very glad you asked! Let&#39;s take a moment to properly explore this.</p>
<p>Inside the Vulkan runtime code in Mesa located in <code>src/vulkan/runtime</code>, we have a set of entrypoint tables using the <code>vk_common_</code> prefix. These are used to implement a variety of functionality ranging from trivial wrappers to full complex implementations of whole object types. As part of <code>vk_instance_init()</code> or <code>vk_device_init()</code>, we look for <code>NULL</code> function pointers in your dispatch table and fill them with common implementations if a common implementation exists. We do this regardless of whether or not you actually support the feature and trust the <code>vkGet*ProcAddr()</code> implementation to return <code>NULL</code> for unsupported entrypoints. If you&#39;re looking to see if the runtime code has an implementation of <code>vkFoo()</code>, search for <code>vk_common_Foo()</code> and that should find it.</p>
<p>One of the most common uses of this is to implement <code>vkFoo()</code> in terms of <code>vkFoo2()</code>. If you&#39;re implementing something where the latest Vulkan spec has both a <code>vkFoo()</code> and a <code>vkFoo2()</code>, you should always skip <code>vkFoo()</code> and go straight to <code>vkFoo2()</code> unless you really want to implement both. This will work even if you don&#39;t expose the Vulkan core version or extension that provides <code>vkFoo2()</code>. If a wrapper does not yet exist for the entrypoint you&#39;re implementing, make a merge request to add one.</p>
<h3>Devices and Queues</h3>
<p>Device creation looks much the same as instance creation as far as the common Vulkan runtime code goes. There is an explicit <code>vkCreateDevice()</code> entrypoint in which you need to create your device and <code>vk_device_init</code> takes a dispatch table and <code>pCreateInfo</code> just like <code>vk_instance_init()</code>. As with instances, <code>vk_device_init()</code> checks to ensure that every extension specified by <code>VkDeviceCreateInfo::ppEnabledExtensionNames</code> is actually supported according to the table of supported extensions in the <code>vk_physical_device</code> and returns <code>VK_ERROR_EXTENSION_NOT_PRESENT</code> if an unsupported extension is requested.</p>
<p>With your device, you&#39;ll also need to create queues. These also have a base struct called <code>vk_queue</code>. As with physical devices, queues are weird in that the spec doesn&#39;t say when they get created. It must be between <code>vkCreateDevice()</code> and the first call to <code>vkGetDeviceQueue()</code> which requests it. All Mesa drivers create them as part of <code>vkCreateDevice()</code>. This allows us to maintain a list of queues inside the <code>vk_device</code> and implement <code>vkGetDeviceQueue()</code> and <code>vkGetDeviceQueue2()</code> for you.</p>
<p>Of course, your devices and queues will need to be more than a bare <code>vk_device</code> or <code>vk_queue</code>. You&#39;ll likely also need data structures for memory allocation, handles to various kernel driver resources, etc. Then, you&#39;ll need to implement the various APIs around allocating and binding memory, creating images, buffers, and other Vulkan objects, etc. We won&#39;t cover any of that in detail here because there&#39;s not much we can do to help in common code just yet; it&#39;s mostly vendor-specific.</p>
<h3>Synchronization</h3>
<p>Before you get too excited and start to implement <code>VkFence</code>, <code>VkSemaphore</code>, and <code>vkQueueSubmit()</code>, stop. Unless you are a very special driver such as venus, which is implementing Vulkan pass-through for VMs, you should not be implementing synchronization yourself. You will get it wrong.</p>
<p>Instead, we have a common synchronization framework built around <code>vk_sync</code> objects. In <code>vk_physical_device</code>, there is a <code>supported_sync_types</code> array which describes each <code>vk_sync_type</code> supported by your implementation. If your driver uses DRM sync objects (it should!), a <code>vk_sync</code> implementation is provided for you in <code>vk_drm_syncobj.h</code>. For any other synchronization type such as BO-based synchronization for talking with X11 or amdgpu&#39;s internal sync handles, you can implement your own <code>vk_sync_type</code>, which describes the capabilities of the synchronization primitive and provides hooks for various operations such as waiting on it or signaling it from the CPU. Once you&#39;ve provided some <code>vk_sync_types</code>, <code>VkFence</code> and <code>VkSemaphore</code> are taken care of for you by common code.</p>
<p>Your driver will also need to fill out <code>vk_queue::driver_submit</code> with a function that handles submission to the kernel driver. We provide implementations of <code>vkQueueSubmit()</code> and <code>vkQueueBindSparse()</code> in terms of this hook. This allows us to implement both userspace emulated and kernel assisted timeline semaphores for you. The cross-process negotiation that makes timeline semaphores on Linux possible is extremely tricky and subtle; you will get it wrong if you try to do it yourself.</p>
<p>If you want timeline semaphores, there are currently two options on Linux. The first and better option is to implement DRM sync object timeline support in your kernel driver. If you do, <code>vk_drm_syncobj_get_type()</code> will return a type with syncobj support, <code>VkSemaphore</code> will advertise cross-process sharing support for timelines, and we&#39;ll take care of the negotiation stuff for you. If your kernel doesn&#39;t support timeline DRM sync objects, you can use <code>vk_sync_timeline</code>, which emulates timelines using another binary <code>vk_sync_type</code>. The former is preferred because it supports sharing, but the emulation may be necessary for supporting Vulkan 1.2 on older kernel drivers.</p>
<p>Everything I&#39;ve outlined so far is about Linux, but it should work fine on Windows too. Things are actually quite a bit simpler there because the built-in synchronization primitive already does timelines. When working on the synchronization framework, I typed up <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/15122" target="_blank" rel="nofollow noreferrer noopener">support for WDDM2 fences</a> to prove that it works. It&#39;s sitting in a WIP state and isn&#39;t exactly well-tested because we don&#39;t have any Windows drivers to use it yet, but it should work.</p>
<h3>Command buffers and pools</h3>
<p>We provide base <code>vk_command_pool</code> and <code>vk_command_buffer</code> structs which you should use. These are required for our generic implementation of VK_EXT_debug_utils and its command buffer tagging. You also get a few little things for free such as <code>vkResetCommandPool()</code>.</p>
<p>The other big thing that using <code>vk_command_buffer</code> will get you soon is a common capture/replay solution for secondary command buffers. Boris Brezillon at Collabora has <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/14406" target="_blank" rel="nofollow noreferrer noopener">a merge request</a> posted, which implements this and enables it for panvk. Implementing secondary command buffers directly is recommended since it&#39;s likely better for performance on most hardware. However, some hardware really can&#39;t do better than capture/replay, in which case this will let us handle all those capture/replay details in common code.</p>
<h3>Images and views</h3>
<p>There are also <code>vk_image</code> and <code>vk_image_view</code> base structs which you can optionally use in your driver. Unlike most of the base objects we&#39;ve discussed so far, these don&#39;t really do anything. They just hold copies of all the image and view creation parameters for you. However, given the number of places in the API where a size, format, or number of layers is pulled implicitly from the image view, you&#39;ll need at least some of this information on hand. We also deal with the image usage vs. view usage distinction added in VK_KHR_maintenance1 for you in case that matters for your driver.</p>
<p>Even though these structs are currently optional, and the immediate value isn&#39;t huge, I expect we&#39;ll be building more common code which uses them in the future. You&#39;ll probably want to get onboard eventually.</p>
<h3>Render passes</h3>
<p>Whether or not you need real render passes is a decision only you can make. Some hardware gets real benefit from re-ordering and combining subpasses within a render pass. However, for most desktop hardware, there&#39;s no real point and we just want to blast commands into a buffer. If you don&#39;t care about subpass re-ordering or combining, then you don&#39;t need to bother implementing render passes at all.</p>
<p>Landed just this week is <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/14961" target="_blank" rel="nofollow noreferrer noopener">a merge request</a> which implements all of render passes in terms of VK_KHR_dynamic_rendering. All you have to do is implement <code>vkCmdBeginRendering()</code> and <code>vkCmdEndRendering()</code>. For the couple of places where render passes are passed into the API, there are helpers which return you a <code>VK_KHR_dynamic_rendering</code> version of the relevant data. For driers which don&#39;t care about subpass combining, this is a fantastic simplification. The ANV (Intel) patch is +926/-2633 lines of code and the new code is not only shorter but way easier to read and understand.</p>
<p>If you choose to use the common render pass implementation, your driver will need to use <code>vk_image</code> and <code>vk_image_view</code> as we need to be able to introspect images and views.</p>
<h3>Final comments</h3>
<p>Before we wrap up, there&#39;s a few odds and ends that should be addressed but don&#39;t really deserve their own section:</p>
<ul>
<li>We haven&#39;t discussed compilers at all. There&#39;s a huge common infrastructure for that in Mesa called NIR which you&#39;ll be using. You can read about it in <a href="https://www.jlekstrand.net/jason/blog/2022/01/in-defense-of-nir/" target="_blank" rel="nofollow noreferrer noopener">my recent blog post about NIR</a>. Before anyone asks, no, you cannot bring your own SPIR-V parser and just use LLVM.</li>
<li>We implement VK_EXT_private_data for you. This is a big part of why we made <code>vk_object_base</code> in the first place. Assuming you used base objects everywhere, everything needed for the extension is already in place. Just turn it on.</li>
<li>I&#39;m working on <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/13184" target="_blank" rel="nofollow noreferrer noopener">a common <code>VkPipelineCache</code> implementation</a> which has been making progress but isn&#39;t quite ready yet.</li>
<li>There are common <code>vk_shader_module</code> and <code>vk_framebuffer</code> objects that simply capture the input parameters. These are optional and there for you to use if you want. Not much relies on these yet. There is a SPIR-V to NIR helper which uses <code>vk_shader_module</code> if you choose to use it, but there is also a version that takes the SPIR-V directly so using <code>vk_shader_module</code> isn&#39;t strictly required.</li>
</ul>
<p>And that&#39;s about it for now. Mesa will continue to evolve and the core Vulkan runtime code and best practices will evolve with it. New stuff is getting added constantly. By 2024 or so, we may have enough fresh material to justify another post like this. Until then, if you&#39;re developing a Vulkan driver in Mesa, best keep your eyes on merge requests tagged &#34;vulkan&#34; to make sure you don&#39;t miss any cool new updates that gets added. Happy hacking!</p>
</div></div>
  </body>
</html>
