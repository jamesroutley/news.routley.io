<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://christianjmills.com/posts/arc-a770-testing/part-2/">Original</a>
    <h1>Testing Intel‚Äôs Arc A770 GPU for Deep Learning</h1>
    
    <div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">



<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#initial-headaches">Initial Headaches</a></li>
<li><a href="#training-performance-on-native-ubuntu">Training Performance on Native Ubuntu</a></li>
<li><a href="#training-performance-on-wsl">Training Performance on WSL</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<section id="series-links">
<h2 data-anchor-id="series-links">Series Links</h2>
<ul>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-1/">Part 1</a>: I tested inference performance with OpenVINO and DirectML on the A770 and attempted to train models using PyTorch-DirectML.</li>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-2/">Part 2</a>: I trained image classification models with Intel‚Äôs PyTorch extension on the Arc A770 GPU.</li>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-3/">Part 3</a>: I trained style transfer models and ran Stable Diffusion 2.1 using ü§ó Diffusers with Intel‚Äôs PyTorch extension on the Arc A770.</li>
<li><a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">Getting Started with Intel‚Äôs PyTorch Extension for Arc GPUs on Ubuntu</a>: This tutorial provides a step-by-step guide to setting up Intel‚Äôs PyTorch extension on Ubuntu to train models with Arc GPUs</li>
</ul>
</section>
<section id="introduction">
<h2 data-anchor-id="introduction">Introduction</h2>
<p><a href="https://christianjmills.com/posts/arc-a770-testing/part-1/">Last October</a>, I wrote about my findings from testing the inference performance of Intel‚Äôs <a href="https://www.intel.com/content/www/us/en/products/sku/229151/intel-arc-a770-graphics-16gb/specifications.html">Arc A770</a> GPU using <a href="https://docs.openvino.ai/2022.3/home.html">OpenVINO</a> and <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml">DirectML</a>. I also attempted to train various models with the <a href="https://pypi.org/project/pytorch-directml/">PyTorch-DirectML</a> package. The card did well on inference, especially with Intel‚Äôs OpenVINO library. However, the PyTorch-DirectML package was incomplete, and I could not adequately test the card‚Äôs training performance.</p>
<p>Shortly after that post, Intel released an <a href="https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.10.200%2Bgpu">extension for PyTorch</a>, which added support for Intel GPUs. Based on my initial testing, I decided the extension was not in a state that warranted a follow-up post. In hindsight, I don‚Äôt believe the initial release officially supported Arc GPUs. The <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.10.200+gpu/tutorials/installation.html#hardware-requirement">installation guide</a> for that version only mentions data center GPUs.</p>
<p>Since then, Intel has released a couple of updates for the extension, the most <a href="https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.13.120%2Bxpu">recent</a> being about a month ago at the time of writing. Unlike the initial release, this version lists Arc GPUs as having <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.13.120+xpu/tutorials/installation.html#hardware-requirement">experimental support</a>. Given that and the driver improvements for Windows and Linux, I decided to pop the A770 back into my desktop and give it another shot. In short, it works now.</p>
<p>In this post, I discuss my experience getting Intel‚Äôs PyTorch extension running on Ubuntu and Windows Subsystem for Linux (WSL). I also cover my initial findings from training models. I‚Äôll provide a tutorial for setting up and using the extension in a dedicated post.</p>
<ul>
<li><a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">Getting Started with Intel‚Äôs PyTorch Extension for Arc GPUs on Ubuntu</a></li>
</ul>
</section>
<section id="initial-headaches">
<h2 data-anchor-id="initial-headaches">Initial Headaches</h2>
<p>To be blunt, my initial attempts to get this working were a bit of a nightmare. The instructions required to enable support for Arc GPUs on Ubuntu and set up Intel‚Äôs PyTorch extension span across multiple sites and are sometimes contradictory. The instructions on some sites are outdated to the point of being impossible to follow.</p>
<p>For example, Intel‚Äôs Arc Graphics Driver for Ubuntu <a href="https://www.intel.com/content/www/us/en/download/747008/intel-arc-graphics-driver-ubuntu.html">page</a> provided a link to a separate documentation site with driver installation instructions.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-arc-graphics-driver-ubuntu-page.png"/></p>
</figure>
</div>
<p>The instructions on the documentation site say to <a href="https://dgpu-docs.intel.com/installation-guides/ubuntu/ubuntu-jammy-arc.html#step-2-install-linux-kernel">install a specific Linux kernel</a>, <code>5.19.0-35</code>, which is <a href="https://www.ubuntuupdates.org/package/core/jammy/main/updates/linux-image-5.19.0-35-generic">no longer available</a>.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-dgpu-docs-ubuntu-driver-installation-instructions-install-kernel.png"/></p>
</figure>
</div>
<p>Still, I attempted to follow the instructions on a new Ubuntu 22.04 install and a more recent <code>5.19</code> kernel. Trying to boot into Ubuntu on the Arc card with the <code>5.19</code> kernel results in the following error:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span>snd_hda_intel</span> 0000:04:00.0 hsw/bdw hd-audio hdmi/dp requires binding with gfx driver</span></code></pre></div>
<p>The error is a known issue, and Intel even has a <a href="https://www.intel.com/content/www/us/en/support/articles/000092607/graphics.html">troubleshooting page</a> with a proposed workaround. Unfortunately, disabling the ‚ÄúIntegrated graphics Multi-Monitor‚Äù BIOS option, as the page recommends, did not resolve the issue.</p>
<p>I decided to continue following the instructions on integrated graphics and see if I could use the Arc card once I installed all the driver packages. That attempt went so poorly that I had to pop out the motherboard‚Äôs CMOS battery to reset the BIOS.</p>
<p>I made several more attempts, which failed at various stages. Fortunately, I eventually got everything working, and my current setup process is pretty straightforward.</p>
<p>I ended up needing Linux kernel <code>6.2</code> or newer. That kernel version <a href="https://www.phoronix.com/news/Linux-6.2-Released">supports the Arc card</a> out of the box. You can install that kernel on Ubuntu 22.04, but I recommend just going with Ubuntu 23.04 (or newer) if starting from a fresh install. Ubuntu 23.04 already has a kernel version <code>‚â•6.2</code>, and I verified it works with Intel‚Äôs PyTorch extension.</p>
<p>As mentioned earlier, I‚Äôll provide detailed instructions for the setup process in a dedicated post.</p>
</section>
<section id="training-performance-on-native-ubuntu">
<h2 data-anchor-id="training-performance-on-native-ubuntu">Training Performance on Native Ubuntu</h2>
<p>I used the training notebook from my recent <a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/">beginner PyTorch tutorial</a> for testing. That tutorial covers fine-tuning image classification models with PyTorch and the timm library by creating a hand gesture recognizer. Using the training notebook simplifies directly comparing the Arc A770 and my Titan RTX, which I used to create the tutorial. Nearly everything is identical for the testing environment down to the dataset location.</p>
<p>The one additional variable is that the tutorial uses PyTorch 2.0, while Intel‚Äôs PyTorch extension currently requires a <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/latest/tutorials/installation.html#pytorch-intel-extension-for-pytorch-version-mapping">patched version</a> of PyTorch 1.13. However, I don‚Äôt use model compilation in the tutorial, so this should not be a significant factor.</p>
<p>The training notebook only required a few tweaks to use Intel‚Äôs PyTorch extension, with most of the code remaining unchanged. The extension even supports PyTorch‚Äôs <code>autocast()</code> context manager for mixed-precision training.</p>
<p>The first training session was alarmingly slow, with the first pass through the training set taking around 42 minutes and 30 seconds. However, the loss and accuracy values were comparable to those with the Titan RTX, so I let it run for a while. After the first epoch, passes through the training set fell to approximately 16 minutes and 50 seconds. The total training time was only a few minutes less than the free GPU tier on Google Colab. Strangely, the inference speed on the validation set was nearly identical to the Titan RTX.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-ubuntu-bad-memory-layout.png"/></p>
</figure>
</div>
<p>We can get more insight into using the <code>intel-gpu-top</code> command-line tool. Below are the readouts from the first and third passes through the training set:</p>

<p>Note that the memory throughput for the first training pass is particularly low. Although, the third pass is not great, either.</p>
<p>After some investigation on the <a href="https://github.com/intel/intel-extension-for-pytorch/issues/296#issuecomment-1426537682">extension‚Äôs GitHub repository</a>, it appears the slow training time is due to the backward pass for some operations. Fortunately, the fix involved setting a <a href="https://github.com/intel/intel-extension-for-pytorch/issues/296#issuecomment-1461118993">single environment variable</a>.</p>
<p>After setting <code>IPEX_XPU_ONEDNN_LAYOUT=1</code>, the total training time is within 10% of my Titan RTX on the same system. The gap would be slightly wider if I compiled the model on the Titan with PyTorch 2.0.</p>
<p>We can see the difference with <code>intel-gpu-top</code>, which shows much higher memory throughput.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-gpu-top-arc-a770-usage-training.png"/></p>
</figure>
</div>
<p>The final loss and accuracy values fluctuate slightly, even when using fixed seed values for PyTorch, NumPy, and Python. However, they stay pretty close to the results on my Nvidia GPU.</p>
<p>Here is a screenshot of the training session with the Arc A770:</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-ubuntu.png"/></p>
</figure>
</div>
<p>Here is a link to the training session with the Titan RTX:</p>
<ul>
<li><a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/#train-the-model">Titan RTX training session</a></li>
</ul>
<pre><code>Epochs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [11:15&lt;00:00, 224.96s/it]
Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4324/4324 [03:29&lt;00:00, 21.75it/s, accuracy=0.894, avg_loss=0.374, loss=0.0984, lr=0.000994]
Eval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 481/481 [00:17&lt;00:00, 50.42it/s, accuracy=0.975, avg_loss=0.081, loss=0.214, lr=]
Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4324/4324 [03:28&lt;00:00, 22.39it/s, accuracy=0.968, avg_loss=0.105, loss=0.0717, lr=0.000462]
Eval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 481/481 [00:16&lt;00:00, 55.14it/s, accuracy=0.988, avg_loss=0.0354, loss=0.02, lr=]
Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4324/4324 [03:28&lt;00:00, 21.94it/s, accuracy=0.99, avg_loss=0.0315, loss=0.00148, lr=4.03e-9]
Eval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 481/481 [00:16&lt;00:00, 53.87it/s, accuracy=0.995, avg_loss=0.0173, loss=0.000331, lr=]</code></pre>
<p>The training sessions for the A770 and the Titan both used mixed precision.</p>
<p>I also tested training on the Arc card with the newer 6.3 Linux kernel but did not see a notable performance difference versus the 6.2 Linux kernel.</p>
<p>Since Intel‚Äôs extension only recently added support for Arc cards, more performance may get unlocked in future updates. However, getting so close to the Titan RTX was already more than I had hoped.</p>
<p>I decided to move on and see how the extension performed in WSL.</p>
</section>
<section id="training-performance-on-wsl">
<h2 data-anchor-id="training-performance-on-wsl">Training Performance on WSL</h2>
<p>Now that I had a streamlined process for setting everything up on Ubuntu, getting WSL up and running was easy. It only required a subset of the steps compared to a bare-metal Ubuntu installation. I used the default <a href="https://apps.microsoft.com/store/detail/ubuntu/9PDXGNCFSCZV">Ubuntu terminal environment</a> and stuck with the included kernel.</p>
<p>Total training time in WSL is <code>‚âà34%</code> slower than in native Ubuntu with the dataset in the same virtual hard disk (VHD) that stores the WSL-Ubuntu install.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-wsl.png"/></p>
</figure>
</div>
<p>I remember getting a similar performance hit the last time I used WSL with the Titan RTX. It‚Äôs one of the reasons I prefer to dual-boot Windows and Ubuntu.</p>
<p>Here is a screenshot of the GPU usage when running the training notebook on the A770 in WSL:</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/task-manager-pytorch-arc-a770-wsl-gpu-usage.png"/></p>
</figure>
</div>
<p>There is an additional <code>‚âà20%</code> increase in training time when storing the dataset outside the VHD with the WSL-Ubuntu install.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-wsl-external-dataset.png"/></p>
</figure>
</div>
<p>One workaround is to <a href="https://woshub.com/move-wsl-another-drive-windows/">move the WSL installation</a> to a larger drive if your <code>C</code> drive has limited space.</p>
<p>The performance hit makes it hard to recommend WSL for deep learning tasks. On top of that, the <a href="https://christianjmills.com/posts/pytorch-cuda-wsl2/#the-headaches">issues</a> I encountered when I first tested using PyTorch on WSL2 in 2020 are still present, at least on Windows 10.</p>
<p>Therefore, I recommend using a bare-metal installation to get the most out of your hardware. The Ubuntu website provides <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">a step-by-step guide</a> to installing Ubuntu on your PC, and you can install it alongside an existing operating system.</p>
</section>
<section id="closing-thoughts">
<h2 data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>My experience with the PyTorch-DirectML package and the first version of Intel‚Äôs extension left me thinking it would be a while before the Arc GPUs became viable options for deep learning.</p>
<p>Several months later, my initial attempts to get everything working last week had me thinking it would be even longer still. Fortunately, once you know the proper steps, setting everything up is relatively straightforward.</p>
<p>While there is much more testing to do, I believe the Arc GPUs are now credible options for deep learning.</p>
<p>There are likely still edge cases or certain operations that cause problems, and I‚Äôll make updates to this post if I encounter any. I‚Äôll also try to keep the <a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">setup tutorial</a> updated as new versions of Intel‚Äôs PyTorch extension come out.</p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><!-- End Cloudflare Web Analytics -->


</div></div>
  </body>
</html>
