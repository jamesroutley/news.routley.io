<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/start-building-with-gemini-25-flash/">Original</a>
    <h1>Gemini 2.5 Flash</h1>
    
    <div id="readability-page-1" class="page"><div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Tulsee+Doshi">Tulsee Doshi</a>
            
              <span>Director of Product Management</span>
            
            
              <span>Gemini</span>
            
          </p>
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <p data-block-key="w22bj">Today we are rolling out an early version of <b>Gemini 2.5 Flash</b> in <b>preview</b> through the Gemini API via <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-04-17">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a>. Building upon the popular foundation of 2.0 Flash, this new version delivers a major upgrade in reasoning capabilities, while still prioritizing speed and cost. Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off. The model also allows developers to set thinking budgets to find the right tradeoff between quality, cost, and latency. Even with <b>thinking off,</b> developers can maintain the fast speeds of 2.0 Flash, and improve performance.</p><p data-block-key="b171q">Our Gemini 2.5 models are thinking models, capable of reasoning through their thoughts before responding. Instead of immediately generating an output, the model can perform a &#34;thinking&#34; process to better understand the prompt, break down complex tasks, and plan a response. On complex tasks that require multiple steps of reasoning (like solving math problems or analyzing research questions), the thinking process allows the model to arrive at more accurate and comprehensive answers. In fact, Gemini 2.5 Flash performs strongly on <a href="https://lmarena.ai/?leaderboard">Hard Prompts in LMArena</a>, second only to 2.5 Pro.</p>
</div>   

<div>
    <div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/comparison-table-LLM.original.png" alt="Comparison table showing price and performance metrics for LLMs"/></p><p>
                    2.5 Flash has comparable metrics to other leading models for a fraction of the cost and size.
                </p>
            
        
    </div>
</div>
  <div>
    <h2 data-block-key="w22bj">Our most cost-efficient thinking model</h2><p data-block-key="15dd0">2.5 Flash continues to lead as the model with the best price-to-performance ratio.</p>
</div>   

<div>
    <div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2.5-Flash-price-to-performance-compariso.original.png" alt="Gemini 2.5 Flash price-to-performance comparison"/></p><p>
                    Gemini 2.5 Flash adds another model to Google’s pareto frontier of cost to quality.*
                </p>
            
        
    </div>
</div>
  <div>
    <h2 data-block-key="hippi">Fine-grained controls to manage thinking</h2><p data-block-key="4g2lu">We know that different use cases have different tradeoffs in quality, cost, and latency. To give developers flexibility, we’ve enabled setting a <b>thinking budget</b> that offers fine-grained control over the maximum number of tokens a model can generate while thinking. A higher budget allows the model to reason further to improve quality. Importantly, though, the budget sets a cap on how much 2.5 Flash can think, but the model does not use the full budget if the prompt does not require it.</p>
</div>   

<div>
    <div>
        
            <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_s_b_s_scaling_graphs.original.png" alt="Plot graphs show improvements in reasoning quality as thinking budget increases"/></p><p>
                    Improvements in reasoning quality as thinking budget increases.
                </p>
            
        
    </div>
</div>
  <div>
    <p data-block-key="hippi">The model is trained to know how long to think for a given prompt, and therefore automatically decides how much to think based on the perceived task complexity.</p><p data-block-key="c6ud">If you want to keep the lowest cost and latency while still improving performance over 2.0 Flash, <b>set the thinking budget to 0.</b> You can also choose to <b>set a specific token budget</b> for the thinking phase using a parameter in the API or the slider in Google AI Studio and in Vertex AI. The budget can range from 0 to 24576 tokens for 2.5 Flash.</p><p data-block-key="bm9va">The following prompts demonstrate how much reasoning may be used in the 2.5 Flash’s default mode.</p><h3 data-block-key="4qsi3"><b></b></h3><p data-block-key="ee1fc"><b>Example 1:</b> “Thank you” in Spanish</p><p data-block-key="dfdib"><b>Example 2:</b> How many provinces does Canada have?</p><h3 data-block-key="5r2iv"><b></b></h3><p data-block-key="2hnrv"><b>Example 1:</b> You roll two dice. What’s the probability they add up to 7?</p><p data-block-key="t908"><b>Example 2:</b> My gym has pickup hours for basketball between 9-3pm on MWF and between 2-8pm on Tuesday and Saturday. If I work 9-6pm 5 days a week and want to play 5 hours of basketball on weekdays, create a schedule for me to make it all work.</p><h3 data-block-key="6ooqr"><b></b></h3><p data-block-key="99tu"><b>Example 1:</b> A cantilever beam of length L=3m has a rectangular cross-section (width b=0.1m, height h=0.2m) and is made of steel (E=200 GPa). It is subjected to a uniformly distributed load w=5 kN/m along its entire length and a point load P=10 kN at its free end. Calculate the maximum bending stress (σ_max).</p><p data-block-key="c8ugt"><b>Example 2:</b> Write a function <code>evaluate_cells(cells: Dict[str, str]) -&gt; Dict[str, float]</code> that computes the values of spreadsheet cells.</p><p data-block-key="4reqs">Each cell contains:</p><ul><li data-block-key="52odg">A number (e.g., <code>&#34;3&#34;</code>)</li></ul><ul><li data-block-key="7pvlf">Or a formula like <code>&#34;=A1 + B1 * 2&#34;</code> using <code>+</code>, <code>-</code>, <code>*</code>,<code>/</code> and other cells.</li></ul><p data-block-key="2b2uc">Requirements:</p><ul><li data-block-key="p7co">Resolve dependencies between cells.</li></ul><ul><li data-block-key="b35hd">Handle operator precedence (<code>*/</code> before <code>+-</code>).</li></ul><ul><li data-block-key="b432o">Detect cycles and raise <code>ValueError(&#34;Cycle detected at &lt;cell&gt;&#34;)</code>.</li></ul><ul><li data-block-key="2884i">No <code>eval()</code>. Use only built-in libraries.</li></ul><h2 data-block-key="nq6j"></h2><p data-block-key="erb39">Gemini 2.5 Flash with thinking capabilities is now available in preview via the <a href="https://ai.google.dev/gemini-api/docs/thinking">Gemini API</a> in <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-04-17">Google AI Studio</a> and in <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a>, and in a dedicated dropdown in the <a href="http://gemini.google.com/">Gemini app</a>. We encourage you to experiment with the <code>thinking_budget</code> parameter and explore how controllable reasoning can help you solve more complex problems.</p>
</div>   

<div>
    <div><pre><span></span><span>from</span> <span>google</span> <span>import</span> <span>genai</span>

<span>client</span> <span>=</span> <span>genai</span><span>.</span><span>Client</span><span>(</span><span>api_key</span><span>=</span><span>&#34;GEMINI_API_KEY&#34;</span><span>)</span>

<span>response</span> <span>=</span> <span>client</span><span>.</span><span>models</span><span>.</span><span>generate_content</span><span>(</span>
  <span>model</span><span>=</span><span>&#34;gemini-2.5-flash-preview-04-17&#34;</span><span>,</span>
  <span>contents</span><span>=</span><span>&#34;You roll two dice. What’s the probability they add up to 7?&#34;</span><span>,</span>
  <span>config</span><span>=</span><span>genai</span><span>.</span><span>types</span><span>.</span><span>GenerateContentConfig</span><span>(</span>
    <span>thinking_config</span><span>=</span><span>genai</span><span>.</span><span>types</span><span>.</span><span>ThinkingConfig</span><span>(</span>
      <span>thinking_budget</span><span>=</span><span>1024</span>
    <span>)</span>
  <span>)</span>
<span>)</span>

<span>print</span><span>(</span><span>response</span><span>.</span><span>text</span><span>)</span>
</pre></div>
</div>  <div>
    <p data-block-key="hippi">Find detailed API references and thinking guides in our <a href="https://ai.google.dev/gemini-api/docs/thinking#set-budget">developer docs</a> or get started with <a href="https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_thinking.ipynb">code examples</a> from the <a href="https://github.com/google-gemini/cookbook/">Gemini Cookbook</a>.</p><p data-block-key="637cu">We will continue to improve Gemini 2.5 Flash, with more coming soon, before we make it generally available for full production use.</p>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div></div>
  </body>
</html>
