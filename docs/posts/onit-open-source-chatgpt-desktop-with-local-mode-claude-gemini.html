<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/synth-inc/onit">Original</a>
    <h1>Show HN: Onit ‚Äì open-source ChatGPT Desktop with local mode, Claude, Gemini</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a href="https://www.getonit.ai" rel="nofollow">
    <img src="https://github.com/synth-inc/onit/raw/main/macos/Onit/Assets.xcassets/AppIcon.appiconset/app_icon_1x.png" alt="Onit Logo" width="128" height="128"/>
  </a>
</p>

<p dir="auto">Onit is an open-source AI chat assistant that lives in your desktop!</p>
<p dir="auto">It&#39;s like ChatGPT Desktop, but with <strong>local mode</strong> and support for <em>other</em> model providers (Anthropic, GoogleAI, xAI, etc). It&#39;s also like Cursor Chat, but everywhere on your computer - not just in your IDE!</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/423a469373a4df2fcb6c9ec21b71c28e92f94463b6b2885724deb6f3e35782c0/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f6f6e69745f6d61696e5f64656d6f2e676966"><img src="https://camo.githubusercontent.com/423a469373a4df2fcb6c9ec21b71c28e92f94463b6b2885724deb6f3e35782c0/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f6f6e69745f6d61696e5f64656d6f2e676966" alt="Onit Main Demo" width="800" height="auto" data-animated-image="" data-canonical-src="https://syntheticco.blob.core.windows.net/onit-media/onit_main_demo.gif"/></a>
</p>

<ul dir="auto">
<li><strong>Download:</strong> Get the pre-built version from <a href="https://www.getonit.ai" rel="nofollow">www.getonit.ai</a></li>
<li><strong>Build from source:</strong> Clone this repository and run in Xcode</li>
</ul>

<p dir="auto">We are building Onit based on these core beliefs:</p>
<ol dir="auto">
<li><strong>Universal Access:</strong> AI assistants should be accessible from anywhere on your computer, not just in browsers or specific apps.</li>
<li><strong>Provider Freedom:</strong> Users should have the choice between models and model providers (Anthropic, OpenAI, xAI, etc.) and not be locked into a single provider.</li>
<li><strong>Local First:</strong> AI is <em>much</em> more useful with access to your data. But that doesn&#39;t count for much if you have to upload personal files to an untrusted server first. Onit will always provide options for local processing. No personal data will leave your computer without explicit approval.</li>
<li><strong>Customizability:</strong> Onit is your assistant. You should be able to configure it to your liking.</li>
<li><strong>Extensibility:</strong> Onit should allow the community to build and share extensions, making it more useful for everyone.</li>
</ol>

<ul dir="auto">
<li><strong>ü§ñ Local Mode:</strong> Chat with any model running locally on Ollama - no internet required</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4117dd45bc55e3cfd916e55a01a62665422a2efe18c44d149e85dd0d3e5cdee4/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f6c6f63616c5f6d6f64655f64656d6f2e676966"><img src="https://camo.githubusercontent.com/4117dd45bc55e3cfd916e55a01a62665422a2efe18c44d149e85dd0d3e5cdee4/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f6c6f63616c5f6d6f64655f64656d6f2e676966" alt="Local Mode Demo" width="800" height="auto" data-animated-image="" data-canonical-src="https://syntheticco.blob.core.windows.net/onit-media/local_mode_demo.gif"/></a>
</p>
<ul dir="auto">
<li><strong>üîÑ Multi-Provider Support:</strong> Toggle between top models from OpenAI, Anthropic, and xAI</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b76b8fcb96c940b3d3766b7f3680b693190fbbc5723e22ebdabd53aa8a394ca1/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f3430735f6d756c74695f70726f76696465725f64656d6f2e676966"><img src="https://camo.githubusercontent.com/b76b8fcb96c940b3d3766b7f3680b693190fbbc5723e22ebdabd53aa8a394ca1/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f3430735f6d756c74695f70726f76696465725f64656d6f2e676966" alt="Multi-Provider Demo" width="800" height="auto" data-animated-image="" data-canonical-src="https://syntheticco.blob.core.windows.net/onit-media/40s_multi_provider_demo.gif"/></a>
</p>
<ul dir="auto">
<li><strong>üìé File Upload:</strong> Add context through images or files (with drag &amp; drop support)</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2c7e97fa6b3c68b8103b033727a3e0a4ae5782bb52ea98a8110210deb9c94ffa/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f647261675f616e645f64726f705f64656d6f2e676966"><img src="https://camo.githubusercontent.com/2c7e97fa6b3c68b8103b033727a3e0a4ae5782bb52ea98a8110210deb9c94ffa/68747470733a2f2f73796e746865746963636f2e626c6f622e636f72652e77696e646f77732e6e65742f6f6e69742d6d656469612f647261675f616e645f64726f705f64656d6f2e676966" alt="File Upload Demo" width="800" height="auto" data-animated-image="" data-canonical-src="https://syntheticco.blob.core.windows.net/onit-media/drag_and_drop_demo.gif"/></a>
</p>
<ul dir="auto">
<li><strong>üìú History:</strong> Access previous chats through history view or up/down arrow shortcuts</li>
<li><strong>‚å®Ô∏è Customizable Shortcuts:</strong> Choose your hotkey to launch the chat window
<ul dir="auto">
<li>Default: <code>Command+0</code></li>
<li>Local: <code>Command+Shift+0</code></li>
</ul>
</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">üõ†Ô∏è Technical Details</h2><a id="user-content-Ô∏è-technical-details" aria-label="Permalink: üõ†Ô∏è Technical Details" href="#Ô∏è-technical-details"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<ol dir="auto">
<li>Download and install <a href="https://ollama.com/" rel="nofollow">Ollama</a></li>
<li>Onit will automatically detect your local models through Ollama&#39;s API</li>
</ol>

<ul dir="auto">
<li><strong>Remote:</strong>
<ul dir="auto">
<li>Anthropic (Claude)</li>
<li>OpenAI (GPT-4, GPT-3.5)</li>
<li>xAI (Grok)</li>
</ul>
</li>
<li><strong>Local:</strong> Any model supported by Ollama</li>
</ul>

<ul dir="auto">
<li>No server component in V1</li>
<li>Local requests are handled locally</li>
<li>Remote requests go directly to model providers&#39; APIs</li>
<li>Only crash reports are collected (via Firebase) and non-personal analytics (via PostHog)</li>
</ul>

<ul>
<li> Autocontext: Automatically pull context from your computer</li>
<li> Local-RAG: Index and create context from files without uploading</li>
<li> Local-typeahead: Like Cursor Tab, but everywhere</li>
<li> Computer Use &amp; Agents</li>
<li> Additional platform support (Linux/Windows)</li>
<li> More model providers (Mistral, Deepseek, etc.)</li>
<li> Bundled Ollama integration</li>
<li> And much more!</li>
</ul>

<p dir="auto">Onit V1 is released under a Creative Commons Non-Commercial license. We believe in:</p>
<ul dir="auto">
<li>Open-source transparency</li>
<li>User customization freedom</li>
<li>Protection against commercial exploitation</li>
</ul>

<p dir="auto">V1 is completely free. Future versions may include paid premium features, but:</p>
<ul dir="auto">
<li>Local chat will always remain free</li>
<li>Source code will remain open for customization</li>
</ul>

<p dir="auto">We are Synth, Inc., a small team of developers in San Francisco building at the edge of AI progress. Other projects include:</p>
<ul dir="auto">
<li><a href="https://www.checkbin.dev" rel="nofollow">Checkbin</a></li>
<li>Alias (deprecated - <a href="http://www.alias.inc" rel="nofollow">www.alias.inc</a>)</li>
</ul>

<p dir="auto">We&#39;d love to hear from you! Reach out at <a href="mailto:contact@getonit.ai">contact@getonit.ai</a></p>

<p dir="auto"><strong>Q: Why not Linux or Windows?</strong></p>
<p dir="auto"><strong>Q: How can I contribute?</strong></p>
</article></div></div>
  </body>
</html>
