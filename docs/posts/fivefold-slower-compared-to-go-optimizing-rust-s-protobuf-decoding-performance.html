<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.greptime.com/blogs/2024-04-09-rust-protobuf-performance">Original</a>
    <h1>Fivefold Slower Compared to Go? Optimizing Rust&#39;s Protobuf Decoding Performance</h1>
    
    <div id="readability-page-1" class="page"><div data-v-fe5c02a4=""><div data-v-fe5c02a4=""><div><h2 id="background" tabindex="-1">Background <a href="#background" aria-label="Permalink to &#34;Background&#34;">​</a></h2><p>When optimizing the write performance of GreptimeDB v0.7, we discovered through flame graphs that the CPU time spent parsing Prometheus write requests accounted for about 12% of the total. In comparison, the CPU time spent on protocol parsing by VictoriaMetrics, which is implemented in Go, is only around 5%. This forced us to start considering optimizing the overhead of the protocol conversion layer.</p><p>To simplify the discussion, all the test code is stored in the GitHub repository <a href="https://github.com/v0y4g3r/prom-write-request-bench" target="_blank" rel="noreferrer">https://github.com/v0y4g3r/prom-write-request-bench</a>.</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>clone</span><span> </span><span>https://github.com/v0y4g3r/prom-write-request-bench</span><span> </span></span>
<span><span>cd</span><span> </span><span>prom-write-request-bench</span></span>
<span><span>export</span><span> PROJECT_ROOT</span><span>=</span><span>$(</span><span>pwd</span><span>)</span></span></code></pre></div><h2 id="optimization-steps" tabindex="-1">Optimization Steps <a href="#optimization-steps" aria-label="Permalink to &#34;Optimization Steps&#34;">​</a></h2><h3 id="step-1-reproduce" tabindex="-1">Step 1: Reproduce <a href="#step-1-reproduce" aria-label="Permalink to &#34;Step 1: Reproduce&#34;">​</a></h3><p>First, let&#39;s set up the baseline using a minimal reproducible benchmark. Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step1/reproduce</span></span></code></pre></div><p>Rust-related benchmark code（<code>benches/prom_decode.rs</code>）：</p><div><p><span>rust</span></p><pre><code><span><span>fn</span><span> </span><span>bench_decode_prom_request</span><span>(</span><span>c</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>Criterion</span><span>)</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> </span><span>mut</span><span> d </span><span>=</span><span> </span><span>std</span><span>::</span><span>path</span><span>::</span><span>PathBuf</span><span>::</span><span>from</span><span>(</span><span>env!</span><span>(</span><span>&#34;</span><span>CARGO_MANIFEST_DIR</span><span>&#34;</span><span>));</span></span>
<span><span>    d</span><span>.</span><span>push</span><span>(</span><span>&#34;</span><span>assets</span><span>&#34;</span><span>);</span></span>
<span><span>    d</span><span>.</span><span>push</span><span>(</span><span>&#34;</span><span>1709380533560664458.data</span><span>&#34;</span><span>);</span></span>
<span><span>    </span><span>let</span><span> data </span><span>=</span><span> </span><span>Bytes</span><span>::</span><span>from</span><span>(</span><span>std</span><span>::</span><span>fs</span><span>::</span><span>read</span><span>(</span><span>d</span><span>).</span><span>unwrap</span><span>());</span></span>
<span><span>    </span><span>let</span><span> </span><span>mut</span><span> request_pooled </span><span>=</span><span> </span><span>WriteRequest</span><span>::</span><span>default</span><span>();</span></span>
<span><span>    c</span><span>.</span><span>benchmark_group</span><span>(</span><span>&#34;</span><span>decode</span><span>&#34;</span><span>)</span></span>
<span><span>        </span><span>.</span><span>bench_function</span><span>(</span><span>&#34;</span><span>write_request</span><span>&#34;</span><span>,</span><span> </span><span>|</span><span>b</span><span>|</span><span> </span><span>{</span></span>
<span><span>            b</span><span>.</span><span>iter</span><span>(||</span><span> </span><span>{</span></span>
<span><span>                </span><span>let</span><span> </span><span>mut</span><span> request </span><span>=</span><span> </span><span>WriteRequest</span><span>::</span><span>default</span><span>();</span></span>
<span><span>                </span><span>let</span><span> data </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>                request</span><span>.</span><span>merge</span><span>(</span><span>data</span><span>).</span><span>unwrap</span><span>();</span></span>
<span><span>            </span><span>});</span></span>
<span><span>        </span><span>});</span></span>
<span><span>}</span></span></code></pre></div><p>Run the benchmark command multiple times:</p><div><p><span>bash</span></p><pre><code><span><span>cargo</span><span> </span><span>bench</span><span> </span><span>--</span><span> </span><span>decode/write_request</span></span></code></pre></div><p>To receive the baseline result:</p><div><p><span>text</span></p><pre><code><span><span>decode/write_request</span></span>
<span><span>time:   [7.3174 ms 7.3274 ms 7.3380 ms]</span></span>
<span><span>change: [+128.55% +129.11% +129.65%] (p = 0.00 &lt; 0.05)</span></span></code></pre></div><p>Pull the VictoriaMetrics code in the current directory to set up a Go performance testing environment:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>clone</span><span>  </span><span>https://github.com/VictoriaMetrics/VictoriaMetrics</span></span>
<span><span>cd</span><span> </span><span>VictoriaMetrics</span></span>
<span><span>cat</span><span> </span><span>&lt;&lt;</span><span>EOF</span><span> </span><span>&gt;</span><span> ./lib/prompb/prom_decode_bench_test.go</span></span>
<span><span>package prompb</span></span>
<span></span>
<span><span>import (</span></span>
<span><span>        &#34;io/ioutil&#34;</span></span>
<span><span>        &#34;testing&#34;</span></span>
<span><span>)</span></span>
<span></span>
<span><span>func BenchmarkDecodeWriteRequest(b *testing.B) {</span></span>
<span><span>        data, _ := ioutil.ReadFile(&#34;</span><span>${</span><span>PROJECT_ROOT</span><span>}</span><span>/assets/1709380533560664458.data&#34;)</span></span>
<span><span>        wr := &amp;WriteRequest{}</span></span>
<span><span>        for n := 0; n &lt; b.N; n++ {</span></span>
<span><span>                b.StartTimer()</span></span>
<span><span>                wr.Reset()</span></span>
<span><span>                err := wr.UnmarshalProtobuf(data)</span></span>
<span><span>                if err != nil {</span></span>
<span><span>                        panic(&#34;failed to unmarshall&#34;)</span></span>
<span><span>                }</span></span>
<span><span>                b.StopTimer()</span></span>
<span><span>        }</span></span>
<span><span>}</span></span>
<span><span>EOF</span></span>
<span></span>
<span><span>go</span><span> </span><span>test</span><span> </span><span>github.com/VictoriaMetrics/VictoriaMetrics/lib/prompb</span><span> </span><span>--bench</span><span> </span><span>BenchmarkDecodeWriteRequest</span></span></code></pre></div><blockquote><p>The data file path points to the <code>1709380533560664458.data</code> file located in the <code>assets</code> directory of the <code>prom-write-request-bench</code> repository.</p></blockquote><p>The outputs are as follows:</p><div><p><span>bash</span></p><pre><code><span><span>goos:</span><span> </span><span>linux</span></span>
<span><span>goarch:</span><span> </span><span>amd64</span></span>
<span><span>pkg:</span><span> </span><span>github.com/VictoriaMetrics/VictoriaMetrics/lib/prompb</span></span>
<span><span>cpu:</span><span> </span><span>AMD</span><span> </span><span>Ryzen</span><span> </span><span>7</span><span> </span><span>7735</span><span>HS</span><span> </span><span>with</span><span> </span><span>Radeon</span><span> </span><span>Graphics</span></span>
<span><span>BenchmarkDecodeWriteRequest-16</span><span>               </span><span>961</span><span>           </span><span>1196101</span><span> </span><span>ns/op</span></span>
<span><span>PASS</span></span>
<span><span>ok</span><span>      </span><span>github.com/VictoriaMetrics/VictoriaMetrics/lib/prompb</span><span>   </span><span>1.328</span><span>s</span></span></code></pre></div><p>You can see that Rust takes about 7.3ms to parse a Prometheus write request with 10,000 timelines, while the Go version by VictoriaMetrics only takes 1.2ms, which is only 1/6 of the Rust version&#39;s time.</p><div><p>Note</p><p>Though you may notice that despite all the efforts below, the Go version still outperforms Rust version. That&#39;s the tradeoff between code maintainability and performance. If we replace all <code>Bytes</code> with <code>&amp;[u8]</code>, then the Rust version can reach the same performance. It is also worth noting that VictoriaMetrics team made great effort in optimizing Protobuf performance using techniques like object pooling and they even created <a href="https://github.com/VictoriaMetrics/easyproto" target="_blank" rel="noreferrer">easyproto</a> to replace the official Protobuf implementation.</p></div><p>Here, you might have quickly spotted the issue: <strong>In the Go version, each deserialization uses the same WriteRequest structure, merely performing a reset before deserialization to avoid data contamination. In contrast, Rust uses a new structure for each deserialization.</strong></p><p>This is one of the optimizations VictoriaMetrics has made for write performance VictoriaMetrics heavily leverages the pooling technique (as in <code>sync.Pool</code>) in its write path to reduce the cost of garbage collection. If the Go version builds a new structure for each deserialization like Rust, then the time consumed would increase to about 10ms, worse than the Rust result mentioned above.</p><p>So, can a similar pooling technique be used in the Rust version? We can conduct a simple experiment: <code>pooled_write_request</code>.</p><p>The logic of the test is similar to the Go version:</p><div><p><span>rust</span></p><pre><code><span><span>let</span><span> </span><span>mut</span><span> request_pooled </span><span>=</span><span> </span><span>WriteRequest</span><span>::</span><span>default</span><span>();</span></span>
<span><span>c</span><span>.</span><span>bench_function</span><span>(</span><span>&#34;</span><span>pooled_write_request</span><span>&#34;</span><span>,</span><span> </span><span>|</span><span>b</span><span>|</span><span> </span><span>{</span></span>
<span><span>    b</span><span>.</span><span>iter</span><span>(||</span><span> </span><span>{</span></span>
<span><span>        </span><span>let</span><span> data </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>        request_pooled</span><span>.</span><span>clear</span><span>();</span></span>
<span><span>        request_pooled</span><span>.</span><span>merge</span><span>(</span><span>data</span><span>).</span><span>unwrap</span><span>();</span></span>
<span><span>    </span><span>});</span></span>
<span><span>});</span></span></code></pre></div><p>Execute:</p><div><p><span>bash</span></p><pre><code><span><span>cargo</span><span> </span><span>bench</span><span> </span><span>--</span><span> </span><span>decode/pooled_write_request</span></span></code></pre></div><p>The result is as follows:</p><div><p><span>text</span></p><pre><code><span><span>decode/pooled_write_request</span></span>
<span><span>time:   [7.1445 ms 7.1645 ms 7.1883 ms]</span></span></code></pre></div><p>It appears that there isn&#39;t a significant performance improvement. So, why is that?</p><div><p>Performance Review So Far:</p><ul><li>Rust baseline time: 7.3ms</li><li>Go parsing time: 1.2ms</li><li>Rust current time: 7.1ms</li></ul></div><h3 id="step-2-repeatedfield" tabindex="-1">Step 2: RepeatedField <a href="#step-2-repeatedfield" aria-label="Permalink to &#34;Step 2: RepeatedField&#34;">​</a></h3><p>Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step2/repeated_field</span></span></code></pre></div><p>To answer the question above, let&#39;s take a look at the data structure of Prometheus&#39;s <a href="https://github.com/prometheus/prometheus/blob/main/prompb/remote.proto#L22-L28" target="_blank" rel="noreferrer">WriteRequest</a>:</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image1.png" alt="image1"/></p><p>The <code>WriteRequest</code> contains a vector of <code>TimeSeries</code>, and each <code>TimeSeries</code> in turn holds vectors of <code>Label</code>, <code>Sample</code>, and <code>Exemplar</code>. If we only reuse the outermost WriteRequest, every time we clear it, the vectors for Labels, Samples, and Exemplars will also be cleared, and thus we fail to reuse the inner struct.</p><p>What about Go? Let&#39;s take a look at the <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/c005245741fc3d7d744f258959be2a5ae388f8ec/lib/prompb/prompb.go#L19-L37" target="_blank" rel="noreferrer">Reset method of WriteRequest</a>:</p><div><p><span>go</span></p><pre><code><span><span>wr</span><span>.</span><span>Timeseries </span><span>=</span><span> tss</span><span>[:</span><span>0</span><span>]</span></span></code></pre></div><p>Rather than setting the TimeSeries field to nil, the Go version sets it to an empty slice. This means the original elements within the slice are still retained and not garbage collected (only the len field is set to 0), hence Go&#39;s object reuse mechanism can effectively avoid repeated memory allocations.</p><p>Could Rust adopt a similar mechanism?</p><p>Here we come to a mechanism called <a href="https://docs.rs/protobuf/2.28.0/protobuf/struct.RepeatedField.html" target="_blank" rel="noreferrer">RepeatedField</a> from another popular Protobuf library in the Rust ecosystem, rust-protobuf v2.x.</p><p>It&#39;s designed to avoid the drop overhead from <code>Vec::clear</code> by manually maintaining the <code>vec</code> and <code>len</code> fields. When clearing, it only sets <code>len</code> to 0 without calling clear from <code>vec</code>, thereby ensuring the elements inside the <code>vec</code> and the <code>vec</code>s within those elements are not dropped.</p><p>Then, the question arises: How can we integrate the RepeatedField mechanism into PROST? Obviously, PROST does not have a similar configuration option, so we need to manually expand the code generated by PROST&#39;s procedural macros.</p><p>During this process, we found that some fields are currently not needed in the writing process so that we can skip them.</p><div><p><span>bash</span></p><pre><code><span><span>cargo</span><span> </span><span>bench</span><span> </span><span>--</span><span> </span><span>decode/pooled_write_request</span></span></code></pre></div><div><p><span>text</span></p><pre><code><span><span>decode/pooled_write_request</span></span>
<span><span>time:   [2.6941 ms 2.7004 ms 2.7068 ms]</span></span>
<span><span>change: [-66.969% -66.417% -65.965%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>Performance has improved.</span></span></code></pre></div><p>Wow! By using the <code>RepeatedField</code> mechanism, we successfully reduced the processing time to about 36% of the original.</p><p>But can this time be further reduced, and what other things can we learn from Go&#39;s code?</p><blockquote><p>It&#39;s worth mentioning that, since <code>RepeatedField</code> is not as convenient to use as <code>Vec</code>, <a href="https://github.com/stepancheg/rust-protobuf/issues/518#issuecomment-751870333" target="_blank" rel="noreferrer">version 3.x of rust-protobuf has removed it</a>. However, <a href="https://github.com/stepancheg/rust-protobuf/issues/503#issuecomment-1030822294" target="_blank" rel="noreferrer">the author also mentioned</a> that there might be an option to add <code>RepeatedField</code> back in the future.</p></blockquote><div><p>Performance Review So Far:</p><ul><li>Rust baseline time: 7.3ms</li><li>Go parsing time: 1.2ms</li><li>Rust current time: 2.7ms</li></ul></div><h3 id="step-3-string-or-bytes" tabindex="-1">Step 3: String or Bytes? <a href="#step-3-string-or-bytes" aria-label="Permalink to &#34;Step 3: String or Bytes?&#34;">​</a></h3><p>Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step3/bytes</span></span></code></pre></div><p>In Go, a string is just a simple wrapper around <code>[]byte</code>, and deserializing a string field can be done by simply assigning the original buffer&#39;s pointer and length to the string field. However, Rust&#39;s PROST, when deserializing <code>String</code> type fields, needs to copy the data from the original buffer into the <code>String</code>, ensuring that the lifecycle of the deserialized structure is independent of the original buffer. However, this introduces an additional overhead of data copying.</p><p>So could we change the Label fields to <code>Bytes</code> instead of <code>String</code>? I recall that <a href="https://docs.rs/prost-build/latest/prost_build/struct.Config.html#method.bytes" target="_blank" rel="noreferrer">there&#39;s a <code>Config::bytes</code> option in <code>PROST_build</code></a>. In this PR for PROST, support was added to generate fields of <code>bytes</code> type as <code>Bytes</code> instead of the default <code>Vec&lt;u8&gt;</code>, thus enabling zero-copy parsing.</p><p>We could similarly change the types of <code>Label</code>&#39;s <code>name</code> and <code>value</code> fields to <code>Bytes</code>. The advantage of this is that it eliminates the need for copying, but the problem is also clear: where <code>Label</code> is needed to use, <code>Bytes</code> must still be converted to <code>String</code>. In this conversion step, we could choose to use <code>String::from_utf8_unchecked</code> to skip the string valid check to further improving performance.</p><p>Of course, if a GreptimeDB instance is exposed to the public internet, such an operation is clearly unsafe. Therefore, in <a href="https://github.com/GreptimeTeam/greptimedb/issues/3435" target="_blank" rel="noreferrer">#3435</a>, we mentioned the need to add a strict mode to verify the legality of the strings.</p><p>After modifying the types of <code>Label::name</code> and <code>Label::value</code>, we run the test again:</p><div><p><span>bash</span></p><pre><code><span><span>cargo</span><span> </span><span>bench</span><span> </span><span>--</span><span> </span><span>decode/pooled_write_request</span></span></code></pre></div><p>Here comes the result:</p><div><p><span>text</span></p><pre><code><span><span>decode/pooled_write_request</span></span>
<span><span>time:   [3.4295 ms 3.4315 ms 3.4336 ms]</span></span>
<span><span>change: [+26.763% +27.076% +27.383%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>Performance has regressed.</span></span></code></pre></div><p>Wait. Why did the performance get even worse? Let&#39;s generate a flame graph to better understand the underlying issues.</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image2.png" alt="image2"/></p><p>It&#39;s apparent that the majority of CPU time is being spent on <code>copy_to_bytes</code>. From the <a href="https://github.com/tokio-rs/prost/blob/v0.12.4/src/encoding.rs#L989" target="_blank" rel="noreferrer">code in PROST for parsing Bytes fields</a>, we can see the following:</p><div><p><span>rust</span></p><pre><code><span><span>pub</span><span> </span><span>fn</span><span> </span><span>merge</span><span>&lt;</span><span>A</span><span>,</span><span> </span><span>B</span><span>&gt;(</span></span>
<span><span>    wire_type</span><span>:</span><span> </span><span>WireType</span><span>,</span></span>
<span><span>    value</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>A</span><span>,</span></span>
<span><span>    buf</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>B</span><span>,</span></span>
<span><span>    _ctx</span><span>:</span><span> </span><span>DecodeContext</span><span>,</span></span>
<span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;(),</span><span> </span><span>DecodeError</span><span>&gt;</span></span>
<span><span>where</span></span>
<span><span>    </span><span>A</span><span>:</span><span> </span><span>BytesAdapter</span><span>,</span></span>
<span><span>    </span><span>B</span><span>:</span><span> </span><span>Buf</span><span>,</span></span>
<span><span>{</span></span>
<span><span>    </span><span>check_wire_type</span><span>(</span><span>WireType</span><span>::</span><span>LengthDelimited</span><span>,</span><span> wire_type</span><span>)?;</span></span>
<span><span>    </span><span>let</span><span> len </span><span>=</span><span> </span><span>decode_varint</span><span>(</span><span>buf</span><span>)?;</span></span>
<span><span>    </span><span>if</span><span> len </span><span>&gt;</span><span> buf</span><span>.</span><span>remaining</span><span>()</span><span> </span><span>as</span><span> </span><span>u64</span><span> </span><span>{</span></span>
<span><span>        </span><span>return</span><span> </span><span>Err</span><span>(</span><span>DecodeError</span><span>::</span><span>new</span><span>(</span><span>&#34;</span><span>buffer underflow</span><span>&#34;</span><span>));</span></span>
<span><span>    </span><span>}</span></span>
<span><span>    </span><span>let</span><span> len </span><span>=</span><span> len </span><span>as</span><span> </span><span>usize</span><span>;</span></span>
<span><span>    //...</span></span>
<span><span>    value</span><span>.</span><span>replace_with</span><span>(</span><span>buf</span><span>.</span><span>copy_to_bytes</span><span>(</span><span>len</span><span>));</span></span>
<span><span>    </span><span>Ok</span><span>(())</span></span>
<span><span>}</span></span></code></pre></div><p><a href="https://github.com/tokio-rs/prost/blob/v0.12.4/src/encoding.rs#L912" target="_blank" rel="noreferrer">When the type of the <code>value</code> variable is <code>Bytes</code>, the <code>value.replace_with</code> call will invoke <code>copy_to_bytes</code> again.</a></p><div><p><span>rust</span></p><pre><code><span><span>impl</span><span> </span><span>sealed</span><span>::</span><span>BytesAdapter</span><span> </span><span>for</span><span> </span><span>Bytes</span><span> </span><span>{</span></span>
<span><span>    </span><span>fn</span><span> </span><span>replace_with</span><span>&lt;</span><span>B</span><span>&gt;(&amp;</span><span>mut</span><span> self</span><span>,</span><span> </span><span>mut</span><span> buf</span><span>:</span><span> </span><span>B</span><span>)</span></span>
<span><span>    </span><span>where</span></span>
<span><span>        </span><span>B</span><span>:</span><span> </span><span>Buf</span><span>,</span></span>
<span><span>    </span><span>{</span></span>
<span><span>        </span><span>*</span><span>self </span><span>=</span><span> buf</span><span>.</span><span>copy_to_bytes</span><span>(</span><span>buf</span><span>.</span><span>remaining</span><span>());</span></span>
<span><span>    </span><span>}</span></span>
<span><span>}</span></span></code></pre></div><p>Could we eliminate one copy operation? Although <code>Bytes::copy_to_bytes</code> doesn&#39;t involve actual data copying but rather pointer operations, its overhead is still considerable.</p><div><p>Performance Review So Far:</p><ul><li>Rust baseline time: 7.3ms</li><li>Go parsing time: 1.2ms</li><li>Rust current time: 3.4ms</li></ul></div><h3 id="step-4-eliminate-one-copy" tabindex="-1">Step 4: Eliminate One Copy <a href="#step-4-eliminate-one-copy" aria-label="Permalink to &#34;Step 4: Eliminate One Copy&#34;">​</a></h3><p>Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step4/bytes-eliminate-one-copy</span></span></code></pre></div><p>Since we parse Prometheus&#39;s <code>WriteRequest</code> from <code>Bytes</code>, we can directly specialize the generic parameter <code>B: Buf</code> to Bytes. This way, <code>PROST::encoding::bytes::merge</code> becomes the following <code>merge_bytes</code> method:</p><div><p><span>rust</span></p><pre><code><span><span>#[</span><span>inline</span><span>(</span><span>always</span><span>)]</span></span>
<span><span>fn</span><span> </span><span>copy_to_bytes</span><span>(</span><span>data</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>Bytes</span><span>,</span><span> len</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Bytes</span><span> </span><span>{</span></span>
<span><span>    </span><span>if</span><span> len </span><span>==</span><span> data</span><span>.</span><span>remaining</span><span>()</span><span> </span><span>{</span></span>
<span><span>        </span><span>std</span><span>::</span><span>mem</span><span>::</span><span>replace</span><span>(</span><span>data</span><span>,</span><span> </span><span>Bytes</span><span>::</span><span>new</span><span>())</span></span>
<span><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span></span>
<span><span>        </span><span>let</span><span> ret </span><span>=</span><span> data</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>..</span><span>len</span><span>);</span></span>
<span><span>        data</span><span>.</span><span>advance</span><span>(</span><span>len</span><span>);</span></span>
<span><span>        ret</span></span>
<span><span>    </span><span>}</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> </span><span>fn</span><span> </span><span>merge_bytes</span><span>(</span><span>value</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>Bytes</span><span>,</span><span> buf</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>Bytes</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;(),</span><span> </span><span>DecodeError</span><span>&gt;</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> len </span><span>=</span><span> </span><span>decode_varint</span><span>(</span><span>buf</span><span>)?;</span></span>
<span><span>    </span><span>if</span><span> len </span><span>&gt;</span><span> buf</span><span>.</span><span>remaining</span><span>()</span><span> </span><span>as</span><span> </span><span>u64</span><span> </span><span>{</span></span>
<span><span>        </span><span>return</span><span> </span><span>Err</span><span>(</span><span>DecodeError</span><span>::</span><span>new</span><span>(</span><span>format!</span><span>(</span></span>
<span><span>            </span><span>&#34;</span><span>buffer underflow, len: </span><span>{}</span><span>, remaining: </span><span>{}&#34;</span><span>,</span></span>
<span><span>            len</span><span>,</span></span>
<span><span>            buf</span><span>.</span><span>remaining</span><span>()</span></span>
<span><span>        </span><span>)));</span></span>
<span><span>    </span><span>}</span></span>
<span><span>    </span><span>*</span><span>value </span><span>=</span><span> </span><span>copy_to_bytes</span><span>(</span><span>buf</span><span>,</span><span> len </span><span>as</span><span> </span><span>usize</span><span>);</span></span>
<span><span>    </span><span>Ok</span><span>(())</span></span>
<span><span>}</span></span></code></pre></div><p>After making the replacement, run the benchmark again:</p><div><p><span>bash</span></p><pre><code><span><span>cargo</span><span> </span><span>bench</span><span> </span><span>--</span><span> </span><span>decode/pooled_write_request</span></span></code></pre></div><p>The results are as follows:</p><div><p><span>text</span></p><pre><code><span><span>decode/pooled_write_request</span></span>
<span><span>time:   [2.7597 ms 2.7630 ms 2.7670 ms]</span></span>
<span><span>change: [-19.582% -19.483% -19.360%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>Performance has improved.</span></span></code></pre></div><p>We can see that there&#39;s improvement, but not much. It seems we&#39;ve only returned to the performance level we had just achieved. So, can we go even further?</p><div><p>Performance Review So Far:</p><ul><li>Rust baseline time: 7.3ms</li><li>Go parsing time: 1.2ms</li><li>Rust current time: 2.76ms</li></ul></div><h3 id="step-5-why-is-bytes-slice-so-slow" tabindex="-1">Step 5: Why is <code>Bytes::slice</code> So Slow? <a href="#step-5-why-is-bytes-slice-so-slow" aria-label="Permalink to &#34;Step 5: Why is `Bytes::slice` So Slow?&#34;">​</a></h3><p>Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step5/bench-bytes-slice</span></span></code></pre></div><p>The primary reason is that PROST&#39;s field trait bound is <code>BytesAdapter</code>, while the trait bound for the deserialized <code>Bytes</code> is <code>Buf</code>. Although <code>Bytes</code> implements both traits, if you want to assign one type to another, you need to go through the copy_to_bytes process twice to convert it. In the <code>merge</code> method, because the actual type of <code>Buf</code> is unknown, it first needs to convert <code>Buf</code> into Bytes using <code>Buf::copy_to_bytes</code>. Then, it passes <code>Bytes</code> to <code>BytesAdapter::replace_with</code>, where it again uses <code>&lt;&lt;Bytes as Buf&gt;&gt;::copy_to_bytes</code> to convert <code>Buf</code> into <code>Bytes</code>. Finally, we get the specific type that implements <code>BytesAdapter</code>: <code>Bytes</code>.</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image3.png" alt="image3"/></p><p>From the perspective of PROST, <code>Bytes::copy_to_bytes</code> does not involve copying data, so it can be considered a zero-copy operation. However, the overhead of this zero-copy operation is not that low.</p><p>Let&#39;s do a simple test to verify:</p><div><p><span>rust</span></p><pre><code><span><span>c</span><span>.</span><span>benchmark_group</span><span>(</span><span>&#34;</span><span>slice</span><span>&#34;</span><span>).</span><span>bench_function</span><span>(</span><span>&#34;</span><span>bytes</span><span>&#34;</span><span>,</span><span> </span><span>|</span><span>b</span><span>|</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> </span><span>mut</span><span> data </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>    b</span><span>.</span><span>iter</span><span>(||</span><span> </span><span>{</span></span>
<span><span>        </span><span>let</span><span> </span><span>mut</span><span> bytes </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>        </span><span>for</span><span> _ </span><span>in</span><span> </span><span>0</span><span>..</span><span>10000</span><span> </span><span>{</span></span>
<span><span>            bytes </span><span>=</span><span> </span><span>black_box</span><span>(</span><span>bytes</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>..</span><span>1</span><span>));</span></span>
<span><span>        </span><span>}</span></span>
<span><span>    </span><span>});</span></span>
<span><span>});</span></span></code></pre></div><div><p><span>go</span></p><pre><code><span><span>func</span><span> </span><span>BenchmarkBytesSlice</span><span>(</span><span>b </span><span>*</span><span>testing</span><span>.</span><span>B</span><span>)</span><span> </span><span>{</span></span>
<span><span>    data</span><span>,</span><span> _ </span><span>:=</span><span> ioutil</span><span>.</span><span>ReadFile</span><span>(</span><span>&#34;</span><span>&lt;any binary file&gt;</span><span>&#34;</span><span>)</span></span>
<span><span>     </span><span>for</span><span> n </span><span>:=</span><span> </span><span>0</span><span>;</span><span> n </span><span>&lt;</span><span> b</span><span>.</span><span>N</span><span>;</span><span> n</span><span>++</span><span> </span><span>{</span></span>
<span><span>        b</span><span>.</span><span>StartTimer</span><span>()</span></span>
<span><span>        bytes </span><span>:=</span><span> data</span></span>
<span><span>        </span><span>for</span><span> i </span><span>:=</span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> </span><span>10000</span><span>;</span><span> i</span><span>++</span><span> </span><span>{</span></span>
<span><span>            bytes </span><span>=</span><span> bytes</span><span>[:</span><span>1</span><span>]</span></span>
<span><span>        </span><span>}</span></span>
<span><span>        b</span><span>.</span><span>StopTimer</span><span>()</span></span>
<span><span>     </span><span>}</span></span>
<span><span>}</span></span></code></pre></div><p>The execution time in Go is 2.93 microseconds, whereas in Rust, it is 103.31 microseconds:</p><div><p><span>text</span></p><pre><code><span><span>goos: linux</span></span>
<span><span>goarch: amd64</span></span>
<span><span>pkg: github.com/VictoriaMetrics/VictoriaMetrics/lib/prompb</span></span>
<span><span>cpu: AMD Ryzen 7 7735HS with Radeon Graphics</span></span>
<span><span>BenchmarkBytesSlice-16            497607              2930 ns/op</span></span>
<span><span>PASS</span></span>
<span><span>ok      github.com/VictoriaMetrics/VictoriaMetrics/lib/prompb   6.771s</span></span></code></pre></div><div><p><span>text</span></p><pre><code><span><span>slice/bytes</span></span>
<span><span>time:   [103.23 µs 103.31 µs 103.40 µs]</span></span>
<span><span>change: [+7.6697% +7.8029% +7.9374%] (p = 0.00 &lt; 0.05)</span></span></code></pre></div><p>It can be observed that the slice operation in Rust is two orders of magnitude slower than in Go.</p><p>Go&#39;s slice only includes three fields: <code>ptr</code>, <code>cap</code>, and <code>len</code>. Its slice operation involves only modifications to these three variables.</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image4.png" alt="image4"/></p><p>In Rust, to ensure memory safety, the output of deserialization (<code>WriteRequest</code>) must be independent with the lifecycle of the input data (<code>Bytes</code>). To avoid data copying, <code>Bytes</code> employs a reference counting mechanism.</p><p>As illustrated below, two Bytes instances, A and B, fundamentally point to the same underlying memory area. However, each also has a data pointer pointing to a structure that holds the reference count information. The original memory array is only dropped when the reference count reaches zero. While this approach avoids copying, it also incurs some overhead.</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image5.png" alt="image5"/></p><ul><li><p>The slice operation for <code>Bytes</code> instances created via <code>From&lt;Vec&lt;u8&gt;&gt;</code> is based on reference counting. Each slicing requires copying the original buffer&#39;s pointer, length, reference count, and the pointer and length of the slice&#39;s return value, etc. Compared to Go&#39;s garbage collection, which is based on reachability analysis, the efficiency is undoubtedly much lower.</p></li><li><p>Since Bytes supports multiple implementations, <a href="https://docs.rs/bytes/1.5.0/src/bytes/bytes.rs.html#529-534" target="_blank" rel="noreferrer">certain methods (such as clone) rely on vtable for dynamic dispatch.</a></p></li><li><p>To ensure the safety of slice operations, <a href="https://docs.rs/bytes/1.5.0/src/bytes/bytes.rs.html#255-266" target="_blank" rel="noreferrer">Bytes manually inserts bounds checks in many places.</a></p></li></ul><h3 id="step6-a-little-bit-unsafe" tabindex="-1">Step6: A little bit unsafe <a href="#step6-a-little-bit-unsafe" aria-label="Permalink to &#34;Step6: A little bit unsafe&#34;">​</a></h3><p>Corresponding branch:</p><div><p><span>bash</span></p><pre><code><span><span>git</span><span> </span><span>checkout</span><span> </span><span>step6/optimize-slice</span></span></code></pre></div><p>Is there a way to optimize the overhead further?</p><p>A distinctive feature of the write interface in GreptimeDB is that once a <code>WriteRequest</code> is parsed, it will be immediately transformed into GreptimeDB&#39;s own data structures instead of directly using the <code>WriteRequest</code>. <strong>This means the lifespan of the deserialized input Bytes is always longer than that of the parsed structure.</strong></p><p>Therefore, we can make some hacky modifications to the slice operation, directly assembling the returned <code>Bytes</code> using the original array&#39;s pointer and length. In this way, as long as the original <code>A</code> instance remains alive, all <code>Bytes</code> instances sliced from it will point to valid memory.</p><p><img src="https://words.filippo.io/blogs/2024-04-09-rust-protobuf-performance/image6.png" alt="image6"/></p><p>We replace the <code>data.slice(..len)</code> operation with the following <code>split_to</code> method:</p><div><p><span>rust</span></p><pre><code><span><span>pub</span><span> </span><span>fn</span><span> </span><span>split_to</span><span>(</span><span>buf</span><span>:</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>Bytes</span><span>,</span><span> end</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Bytes</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> len </span><span>=</span><span> buf</span><span>.</span><span>len</span><span>();</span></span>
<span><span>    </span><span>assert!</span><span>(</span></span>
<span><span>        end </span><span>&lt;=</span><span> len</span><span>,</span></span>
<span><span>        </span><span>&#34;</span><span>range end out of bounds: </span><span>{</span><span>:?</span><span>}</span><span> &lt;= </span><span>{</span><span>:?</span><span>}&#34;</span><span>,</span></span>
<span><span>        end</span><span>,</span></span>
<span><span>        len</span><span>,</span></span>
<span><span>    </span><span>);</span></span>
<span></span>
<span><span>    </span><span>if</span><span> end </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span></span>
<span><span>        </span><span>return</span><span> </span><span>Bytes</span><span>::</span><span>new</span><span>();</span></span>
<span><span>    </span><span>}</span></span>
<span></span>
<span><span>    </span><span>let</span><span> ptr </span><span>=</span><span> buf</span><span>.</span><span>as_ptr</span><span>();</span></span>
<span><span>    </span><span>let</span><span> x </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ptr</span><span>,</span><span> end</span><span>)</span><span> </span><span>};</span></span>
<span><span>    // `Bytes::drop` does nothing when it&#39;s built via `from_static`.</span></span>
<span><span>    </span><span>Bytes</span><span>::</span><span>from_static</span><span>(</span><span>x</span><span>)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// benchmark</span></span>
<span><span>c</span><span>.</span><span>bench_function</span><span>(</span><span>&#34;</span><span>split_to</span><span>&#34;</span><span>,</span><span> </span><span>|</span><span>b</span><span>|</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> data </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>    b</span><span>.</span><span>iter</span><span>(||</span><span> </span><span>{</span></span>
<span><span>        </span><span>let</span><span> </span><span>mut</span><span> bytes </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>        </span><span>for</span><span> _ </span><span>in</span><span> </span><span>0</span><span>..</span><span>10000</span><span> </span><span>{</span></span>
<span><span>            bytes </span><span>=</span><span> </span><span>black_box</span><span>(</span><span>unsafe</span><span> </span><span>{</span><span> </span><span>split_to</span><span>(&amp;</span><span>bytes</span><span>,</span><span> </span><span>1</span><span>)</span><span> </span><span>});</span></span>
<span><span>        </span><span>}</span></span>
<span><span>    </span><span>});</span></span>
<span><span>})</span></span></code></pre></div><p>Let&#39;s benchmark it again to see the result:</p><div><p><span>text</span></p><pre><code><span><span>slice/bytes</span></span>
<span><span>time:   [103.23 µs 103.31 µs 103.40 µs]</span></span>
<span><span>change: [+7.6697% +7.8029% +7.9374%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>slice/split_to</span></span>
<span><span>time:   [24.061 µs 24.089 µs 24.114 µs]</span></span>
<span><span>change: [+0.2058% +0.4198% +0.6371%] (p = 0.00 &lt; 0.05)</span></span></code></pre></div><p>Time consumption dropped considerably from 103us to 24us. Now, what about the overall overhead of deserialization?</p><div><p><span>text</span></p><pre><code><span><span>decode/pooled_write_request</span></span>
<span><span>time:   [1.6169 ms 1.6181 ms 1.6193 ms]</span></span>
<span><span>change: [-37.960% -37.887% -37.815%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>Performance has improved.</span></span></code></pre></div><p><strong>Finally, we have managed to reduce the time it takes to parse a single WriteRequest to about 1.6ms, which is only 33.3% slower than Go&#39;s 1.2ms!</strong></p><p>Of course, there is still room for optimization. If we completely abandon <code>Bytes</code> and use Rust&#39;s slices (<code>&amp;[u8]</code>), we can achieve performance close to Go&#39;s (considering only the overhead of slicing):</p><div><p><span>rust</span></p><pre><code><span><span>c</span><span>.</span><span>bench_function</span><span>(</span><span>&#34;</span><span>slice</span><span>&#34;</span><span>,</span><span> </span><span>|</span><span>b</span><span>|</span><span> </span><span>{</span></span>
<span><span>    </span><span>let</span><span> data </span><span>=</span><span> data</span><span>.</span><span>clone</span><span>();</span></span>
<span><span>    </span><span>let</span><span> </span><span>mut</span><span> slice </span><span>=</span><span> data</span><span>.</span><span>as_ref</span><span>();</span></span>
<span><span>    b</span><span>.</span><span>iter</span><span>(</span><span>move</span><span> </span><span>||</span><span> </span><span>{</span></span>
<span><span>        </span><span>for</span><span> _ </span><span>in</span><span> </span><span>0</span><span>..</span><span>10000</span><span> </span><span>{</span></span>
<span><span>            slice </span><span>=</span><span> </span><span>black_box</span><span>(&amp;</span><span>slice</span><span>[..</span><span>1</span><span>]);</span></span>
<span><span>        </span><span>}</span></span>
<span><span>    </span><span>});</span></span>
<span><span>});</span></span></code></pre></div><p>The corresponding result is as follows:</p><div><p><span>text</span></p><pre><code><span><span>slice/slice</span></span>
<span><span>time:   [4.6192 µs 4.7333 µs 4.8739 µs]</span></span>
<span><span>change: [+6.1294% +9.8655% +13.739%] (p = 0.00 &lt; 0.05)</span></span>
<span><span>Performance has regressed.</span></span></code></pre></div><p>However, since this part of the overhead already constitutes a very low proportion of the entire write pathway, further optimization would not significantly affect the overall throughput.</p><p>If you are interested, you can also try to refactor the deserialization code using slices, and we&#39;d be happy if you shared your experience with us.</p><div><p>Performance Review So Far:</p><ul><li>Rust baseline duration: 7.3ms</li><li>Go parsing duration: 1.2ms</li><li>Rust current duration: 1.62ms</li></ul></div><h2 id="summary" tabindex="-1">Summary <a href="#summary" aria-label="Permalink to &#34;Summary&#34;">​</a></h2><p>In this article, we tried various means to optimize the overhead of deserializing Protobuf-encoded <code>WriteRequest</code> data.</p><p>First, we utilized pooling techniques to avoid repeated memory allocation and deallocation, directly reducing the time consumption to about 36% of the baseline. Then, to leverage zero-copy features, we replaced the <code>Label</code>&#39;s <code>String</code> fields with <code>Bytes</code> type, but found that performance actually decreased. Flame graphs revealed that PROST introduced some extra overhead to allow <code>Bytes</code> to convert between the <code>BytesAdapter</code> and <code>Buf</code> traits. By specializing the type, we managed to eliminate these overheads. Additionally, we noticed in the flame graphs that some extra overheads are introduced by <code>Bytes::slice</code> itself to ensure memory safety. Considering our use case, we hacked the slice implementation, eventually reducing the time consumption to about 20% of the baseline.</p><p>Overall, Rust imposes quite a few restrictions when directly manipulating byte arrays to ensure memory safety. Using <code>Bytes</code> can circumvent lifetime issues via reference counting, but at the cost of low efficiency. On the other hand, using <code>&amp;[u8]</code> forces one to deal with the contagion of lifetimes.</p><p>In this article, a compromise approach was adopted, bypassing the reference counting mechanism of <code>Bytes</code> through <code>unsafe</code> methods, manually ensuring the input buffer remains valid for the entire lifecycle of the output. <strong>It&#39;s worth noting that this isn&#39;t a universally applicable optimization method, but it&#39;s worth trying when the cost is part of a hot code path.</strong></p><p>Furthermore, &#34;zero-cost abstraction&#34; is one of the key design philosophies of the Rust language. However, not all abstractions are zero-cost. In this article, we saw the overhead of conversion between PROST&#39;s <code>BytesAdapter</code> and <code>Buf</code> traits, and the dynamic dispatch cost introduced by <code>Bytes</code> to accommodate different underlying data sources, etc. This reminds us to pay more attention to the underlying implementation of critical code paths and guarantee high performance through continuous profiling.</p><p>Besides optimizing deserialization, we also made other efforts in the write path for GreptimeDB v0.7. Initially, the <code>WriteRequest</code> had to be fully parsed before converting to GreptimeDB&#39;s <code>RowInsertRequest</code>. Now, we eliminate the intermediate structure, directly converting the <code>TimeSeries</code> structure into table-dimension write data during the deserialization of <code>WriteRequest</code>. In this way, it can reduce the traversal of all timelines (<a href="https://github.com/GreptimeTeam/greptimedb/pull/3425" target="_blank" rel="noreferrer">#3425</a>, <a href="https://github.com/GreptimeTeam/greptimedb/pull/3478" target="_blank" rel="noreferrer">#3478</a>), while also lowering the memory overhead of the intermediate structure. Moreover, the default HashMap in Rust based on SipHash did not perform ideally for constructing table-dimension write data. By switching to a HashMap based on aHash, we achieved nearly a 40% performance improvement in table lookup.</p><p>Performance optimization is inherently systematic, marked by the meticulous accumulation of improvements in even the smallest details that cumulatively yield substantial gains. The GreptimeDB team is steadfastly committed to this ongoing journey, striving to push the boundaries of efficiency and excellence.</p><hr/><h4 id="about-greptime" tabindex="-1">About Greptime <a href="#about-greptime" aria-label="Permalink to &#34;About Greptime&#34;">​</a></h4><p>We help industries that generate large amounts of time-series data, such as Connected Vehicles (CV), IoT, and Observability, to efficiently uncover the hidden value of data in real-time.</p><p>Visit the <a href="https://www.greptime.com/resources" target="_blank" rel="noreferrer">latest v0.7</a> from any device to get started and get the most out of your data.</p><ul><li><a href="https://github.com/GreptimeTeam/greptimedb" target="_blank" rel="noreferrer">GreptimeDB</a>, written in Rust, is a distributed, open-source, time-series database designed for scalability, efficiency, and powerful analytics.</li><li><a href="https://www.greptime.com/product/cloud" target="_blank" rel="noreferrer">GreptimeCloud</a> offers a fully managed DBaaS that integrates well with observability and IoT sectors.</li><li><a href="https://www.greptime.com/product/ai" target="_blank" rel="noreferrer">GreptimeAI</a> is a tailored observability solution for LLM applications.</li></ul><p>If anything above draws your attention, don&#39;t hesitate to star us on <a href="https://github.com/GreptimeTeam/greptimedb" target="_blank" rel="noreferrer">GitHub</a> or join GreptimeDB Community on <a href="https://www.greptime.com/slack" target="_blank" rel="noreferrer">Slack</a>. Also, you can go to our <a href="https://github.com/GreptimeTeam/greptimedb/contribute" target="_blank" rel="noreferrer">contribution page</a> to find some interesting issues to start with.</p></div></div></div></div>
  </body>
</html>
