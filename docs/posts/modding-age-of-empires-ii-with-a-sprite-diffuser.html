<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.engine.study/blog/modding-age-of-empires-ii-with-a-sprite-diffuser/">Original</a>
    <h1>Modding Age of Empires II with a Sprite-Diffuser</h1>
    
    <div id="readability-page-1" class="page"><article id="post-468">
	<!-- .entry-header -->

	<div>
		
<figure><img loading="lazy" width="1024" height="666" src="https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser-1024x666.png" alt="" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser-1024x666.png 1024w, https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser-300x195.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser-768x499.png 768w, https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser.png 1100w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Last month I set out to create a way for my friends to make custom civilization sprites for our Age of Empires II lobbies.</p>



<p>Below are some thoughts and process on how to create a versatile prompt-based image generator. For beginners I would recommend <a rel="noreferrer noopener" href="https://www.getalpaca.io/" target="_blank">Alpaca</a>, and for those comfortable with coding – <a rel="noreferrer noopener" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" target="_blank" data-type="URL" data-id="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Stable Diffusion Web UI</a> and Python. </p>



<p>Special thanks to the AoEII modding communities <a rel="noreferrer noopener" href="https://openage.sft.mx/" target="_blank">OpenAge</a>, <a rel="noreferrer noopener" href="https://aok.heavengames.com/cgi-bin/forums/display.cgi?action=ct&amp;f=9,44685,,60" target="_blank">SLX Studio</a>, and <a rel="noreferrer noopener" href="https://aok.heavengames.com/" target="_blank">Age of Kings Heaven</a>. </p>



<h2>Visual Explorations</h2>



<h3>Screenshot Transfers</h3>



<p>This idea came about while playing with<strong> image transfer </strong>(img2img) on Age of Empires II screenshots. All the techniques described below use the Stable Diffusion generative “AI” (which I also refer to as the <strong>model</strong> or <strong>network</strong>). </p>



<p>I started in Photoshop with Alpaca and worked on full game screenshots. Mostly what I was looking for was how the model behaved, what shapes and textures it chose to preserve and what it discarded in its stylistic wanderings. Overall it managed to stay in perspective and theme quite well. </p>



<figure><img loading="lazy" width="1019" height="765" src="https://www.engine.study/blog/wp-content/uploads/2023/05/AoE2.gif" alt=""/><figcaption>Age of Empires II in anime, Martian, painterly, and other styles. </figcaption></figure>



<p>What was immediately interesting was how elements of the image started working together. Tiled terrain gave way to roads and paths – there is communication between the buildings and environment. For now we will only be working with building sprites – but it demonstrates that machine learning could be a good tool for <strong>blending procedural elements</strong> of a game.</p>



<h3>The Caspar David Friedrich Benchmark</h3>



<p>Following this I prompted the network to output images into a strongly isometric perspective, looking to get consistent results across lighting, color, shape, and texture. </p>



<figure><ul><li><figure><img loading="lazy" width="1280" height="1024" src="https://www.engine.study/blog/wp-content/uploads/2023/05/AoE0085-1.png" alt="" data-id="558" data-link="https://www.engine.study/blog/?attachment_id=558" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/AoE0085-1.png 1280w, https://www.engine.study/blog/wp-content/uploads/2023/05/AoE0085-1-300x240.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/AoE0085-1-1024x819.png 1024w, https://www.engine.study/blog/wp-content/uploads/2023/05/AoE0085-1-768x614.png 768w" sizes="(max-width: 1280px) 100vw, 1280px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/00129-2015192264.png" alt="" data-id="516" data-link="https://www.engine.study/blog/?attachment_id=516" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/00129-2015192264.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/00129-2015192264-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/00129-2015192264-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/00031-2015192265.png" alt="" data-id="480" data-link="https://www.engine.study/blog/?attachment_id=480" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/00031-2015192265.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/00031-2015192265-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/00031-2015192265-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/00030-2015192264-1.png" alt="" data-id="613" data-full-url="https://www.engine.study/blog/wp-content/uploads/2023/05/00030-2015192264-1.png" data-link="https://www.engine.study/blog/modding-age-of-empires-ii-with-a-sprite-diffuser/00030-2015192264-1/" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/00030-2015192264-1.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/00030-2015192264-1-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/00030-2015192264-1-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li></ul><figcaption>Another screenshot but experimenting with different seeds and weights.</figcaption></figure>



<p>Some really awesome results, as the strength of the image transfer increases, parts of the minimap and UI would become other buildings or terrain.</p>



<h2>Sprite-Diffuser</h2>



<h3>Anime Loyalists vs. Moon Colonists vs. Zombie Romans</h3>



<p>Now it was time to make some civilizations. </p>



<p>When generating the model requires 512×512 images, luckily all the Age of Empires II sprites are about half that so we don’t have to worry about resizing. These were the first results.</p>



<figure><img loading="lazy" width="2048" height="745" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Civilization.gif" alt=""/></figure>



<p>These buildings were cherrypicked and cleaned in Photoshop and weren’t batched. In order to get diverse results the strength of the image transfer was set very high, but as a result the lighting, proportion, and level of detail varied greatly. The castle asset (left) would continue to be a pain point as it is 2x larger most buildings, but the network would insist it was an oversized house.</p>



<h3>Refining Outputs with Control Net and Loopbacks</h3>



<p>To get consistent results while having a high transfer strength I needed to use Control Net, a system that guides generation using input like lineart, depth, or segmentation. </p>







<p>At this point everything worked, sprites stayed in perspective and listened to the prompt, but they failed to be imaginative or unexpected. This can’t be solved by making the prompt strength extremely high, the lighting or color will start to vary too much, control net cannot help there.</p>



<figure><ul><li><figure><img loading="lazy" width="351" height="351" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Space0.png" alt="" data-id="571" data-link="https://www.engine.study/blog/?attachment_id=571" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Space0.png 351w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space0-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space0-150x150.png 150w" sizes="(max-width: 351px) 100vw, 351px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Space4.png" alt="" data-id="572" data-link="https://www.engine.study/blog/?attachment_id=572" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Space4.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space4-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space4-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Space.png" alt="" data-id="573" data-link="https://www.engine.study/blog/?attachment_id=573" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Space.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Space2-1.png" alt="" data-id="575" data-full-url="https://www.engine.study/blog/wp-content/uploads/2023/05/Space2-1.png" data-link="https://www.engine.study/blog/?attachment_id=575" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Space2-1.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space2-1-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Space2-1-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li></ul></figure>



<p>Instead, there is a technique called loopback – this runs the generated image back over itself with the same prompt. Without it, the network isn’t able to imagine novel changes to shapes, textures, and color.</p>



<figure><ul><li><figure><img loading="lazy" width="379" height="442" src="https://www.engine.study/blog/wp-content/uploads/2023/05/302_01.png" alt="" data-id="643" data-full-url="https://www.engine.study/blog/wp-content/uploads/2023/05/302_01.png" data-link="https://www.engine.study/blog/modding-age-of-empires-ii-with-a-sprite-diffuser/302_01/" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/302_01.png 379w, https://www.engine.study/blog/wp-content/uploads/2023/05/302_01-257x300.png 257w" sizes="(max-width: 379px) 100vw, 379px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle1.png" alt="" data-id="580" data-link="https://www.engine.study/blog/?attachment_id=580" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle1.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle1-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle1-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle3.png" alt="" data-id="582" data-link="https://www.engine.study/blog/?attachment_id=582" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle3.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle3-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle3-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle4.png" alt="" data-id="583" data-link="https://www.engine.study/blog/?attachment_id=583" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Castle4.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle4-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Castle4-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li></ul><figcaption>Novel shapes emerging in the interior of the shape thanks to looping.</figcaption></figure>



<p>The final technique I settled on was Control Net with Zoe Depth Estimation, two loopbacks, both with about 85% strength (only 15% of the original image is preserved).</p>



<h2>Prompting</h2>



<p>This is arguably the most important part of the process, but I have left it for last. That is because copying what worked for me will probably hold you back, I didn’t spend that much time on prompting! But this is a good place to start. </p>



<p>I used simple formula for each image with the following prompts. The only field that changed for each building was the Subject (i.e. Archery Range, Market, House).</p>



<div>
<div>
<ol><li>Shape</li><li>Descriptor</li><li>Subject</li><li>Style</li><li>Emphasis</li><li>Modifiers</li></ol>




</div>



<div>
<ol><li>Isometric exterior of a</li><li>ancient Roman</li><li>Barracks</li><li>in the style of Giovanni Paolo Panini</li><li>3D roman architecture, greco-roman stone and pillars with intricate stonework and roofs</li><li>desaturated, 8k, bright sunny natural lighting, trending on artstation</li></ol>
</div>
</div>



<figure><img loading="lazy" width="1024" height="666" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Thumbnail-1-1024x666.png" alt="" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Thumbnail-1-1024x666.png 1024w, https://www.engine.study/blog/wp-content/uploads/2023/05/Thumbnail-1-300x195.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Thumbnail-1-768x499.png 768w, https://www.engine.study/blog/wp-content/uploads/2023/05/Thumbnail-1.png 1100w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Lastly, Stable Diffusion does not create transparencies. I thought object detection would work but surprisingly they struggled to find a solid mask. Instead I forced a solid background color in the prompt and created a few transparent flood fills with ImageMagick </p>



<h2>Final Result</h2>



<figure><img loading="lazy" width="1751" height="1019" src="https://www.engine.study/blog/wp-content/uploads/2023/05/sprite-diffuser-gif-full.gif" alt=""/></figure>



<h2>Other Experiments and Thoughts</h2>



<h3>Custom Buildings &amp; Fine Tuning</h3>



<p>It also possible to reverse the process. Instead of creating different styles of existing sprites, new sprites in the original style could be made using a fine-tuned Age of Empires II model. Either 3D blockouts or photo images of real buildings could work as inputs. </p>



<figure><ul><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Custom_1_GIF-2.gif" alt="" data-id="552" data-full-url="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Custom_1_GIF-2.gif" data-link="https://www.engine.study/blog/?attachment_id=552"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Custom_2_GIF.gif" alt="Image gallery image" data-id="551"/></figure></li></ul></figure>



<h3>Greyboxing to Image</h3>



<p>With one of my existing Unity projects, I took a greyboxed level and applied segmentation to the buildings, ground, and trees according to the ADE20k dataset. </p>



<figure><ul><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Color-1.png" alt="Image gallery image" data-id="505" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Color-1.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Color-1-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Color-1-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Seg.png" alt="" data-id="577" data-link="https://www.engine.study/blog/?attachment_id=577" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Seg.png 512w, https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Seg-300x300.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Seg-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"/></figure></li><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/Engine_Render_GIF.gif" alt="Image gallery image" data-id="504"/></figure></li></ul><figcaption>Original image, object segmentation map, and outputs.</figcaption></figure>



<p>With Control Net and object segmentation we can run it through the same Caspar David Friedrich prompt. This could be used in concept art or level design workflows to quickly block-out environment art. </p>







<h3>Image Rich Mindset, Seeding, Spawning</h3>



<p>With so much semantic and syntactic information of an image now available, each image in the project can be a starting point for synthesizing new outputs. </p>



<figure><ul><li><figure><img loading="lazy" width="512" height="512" src="https://www.engine.study/blog/wp-content/uploads/2023/05/makingvillage.gif" alt="" data-id="671"/></figure></li><li><figure><img loading="lazy" width="2507" height="2200" src="https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1.png" alt="" data-id="672" data-full-url="https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1.png" data-link="https://www.engine.study/blog/modding-age-of-empires-ii-with-a-sprite-diffuser/xyz_grid-0004-3252908729_segmentation-1/" srcset="https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1.png 2507w, https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1-300x263.png 300w, https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1-1024x899.png 1024w, https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1-768x674.png 768w, https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1-1536x1348.png 1536w, https://www.engine.study/blog/wp-content/uploads/2023/05/xyz_grid-0004-3252908729_segmentation-1-2048x1797.png 2048w" sizes="(max-width: 2507px) 100vw, 2507px"/></figure></li></ul><figcaption> Recreate Age of Empires II inside the model with only a depth map and no screenshot for reference.  </figcaption></figure>



<p>By defining 10-20 hero assets using a traditional art workflows, be it characters, buildings, or environments, a development team could then kit bash new assets together. Studios with a large internal catalogue of concept art and assets might be interested in bringing this to fans to extend their lore and worlds.</p>



<h2>Conclusion</h2>



<p>These models are surprisingly versatile and are a lot of fun to work with. Future games, should they choose to, could create a set of <strong>base assets<em> </em></strong>that then <strong>seed</strong><em><strong> </strong></em><strong>user-generated lore </strong>or internal development. The game world is itself an image model, video games are both a place to be and a desirable frame for future images. </p>



<p>The project is online at <a rel="noreferrer noopener" href="https://twitter.com/neilsonks" target="_blank">@neilsonks</a> and <a rel="noreferrer noopener" href="https://engine.study/sprite-diffuser/" target="_blank">engine.study/sprite-diffuser/</a>. </p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>
  </body>
</html>
