<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/satmihir/fair">Original</a>
    <h1>Fair: A Go library for serving resources fairly</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1cf6cdf19d364dcb0779d4dcb478417dc102b652ffd358686a8179c3cb8a24b8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f7665726167652d39312e372532352d627269676874677265656e"><img src="https://camo.githubusercontent.com/1cf6cdf19d364dcb0779d4dcb478417dc102b652ffd358686a8179c3cb8a24b8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f7665726167652d39312e372532352d627269676874677265656e" alt="Coverage" data-canonical-src="https://img.shields.io/badge/Coverage-91.7%25-brightgreen"/></a></p>
<p dir="auto">FAIR is a Go library designed to ensure fairness in the resource-constrained environments. It helps distribute the limited resources (e.g., database/blob storage throughput, job execution resources etc.) evenly across multiple clients during the time of shortage, preventing over-allocation and starvation based on client behavior.</p>

<p dir="auto">The core algorithm of FAIR is based on the <a href="https://rtcl.eecs.umich.edu/rtclweb/assets/publications/2001/feng2001fair.pdf" rel="nofollow">Stochastic Fair BLUE</a> often used for network congestion control with a few modifications. The philosophy of FAIR is to only throttle when there&#39;s a genuine shortage of resources as opposed to the approaches like token bucket or leaky bucket which may reject requests even when the resource is still available (a creative configuration of FAIR can enable that type of behavior but we don&#39;t encourage it). Since the state is stored in a multi-level <a href="https://medium.com/p/e25942ab6093" rel="nofollow">Bloom Filter</a> style data structure, the memory needed is constant and does not scale with the number of clients. When properly configured, FAIR can scale to a very large number of clients with a low probability of false positives and a near zero probability of persistent false positives thanks to the hash rotation mechanism that regularly rehashes clients to avoid any correlated behavior longer than a few minutes.</p>

<ul dir="auto">
<li>Framework and protocol agnostic and easy to integrate into any HTTP/GRPC service.</li>
<li>Automatic tuning with minimal configuration out of the box with flexibility to fully tune if needed.</li>
<li>Scalable to large numbers of clients with constant memory requirements.</li>
<li>A simple resource and error tracking model that can be easily morphed into many types of throttling scenarios.</li>
</ul>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://pjg1.site/satmihir/fair/blob/main/eval.png"><img src="https://pjg1.site/satmihir/fair/raw/main/eval.png" alt="Evaluation"/></a></p>
<p dir="auto">In this example, 20 clients are competing for a resource that regenerates at the rate of 20/s (every data point in the graph is 5s apart). 18 out of 20 clients are &#34;well behaved&#34; because they request a resource every second while the remaining two clients try to get a resource every 100ms which is an &#34;unfair&#34; rate. On the left, we see that when left unthrottled, the two unfair clients grab a disproportionately large amount of resource while the regular workloads starve and get a lot less than 1/s rate. On the right, when throttled with fair, the regular workloads stay virtually unaffected while the unfair ones get throttled. On average, even the unfair workloads get their fair share when seen over larger time periods.</p>

<p dir="auto">To install the FAIR library, use <code>go get</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="go get github.com/satmihir/fair"><pre>go get github.com/satmihir/fair</pre></div>
<p dir="auto">Then, import it into your Go code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import &#34;github.com/satmihir/fair&#34;"><pre><span>import</span> <span>&#34;github.com/satmihir/fair&#34;</span></pre></div>

<p dir="auto">To use the default config which should work well is most cases:</p>
<div dir="auto" data-snippet-clipboard-copy-content="trkB := NewFairnessTrackerBuilder()

trk, err := trkB.BuildWithDefaultConfig()
defer trk.Close()"><pre><span>trkB</span> <span>:=</span> <span>NewFairnessTrackerBuilder</span>()

<span>trk</span>, <span>err</span> <span>:=</span> <span>trkB</span>.<span>BuildWithDefaultConfig</span>()
<span>defer</span> <span>trk</span>.<span>Close</span>()</pre></div>
<p dir="auto">If you want to make some changes to the config, you can use the setters on the builder:</p>
<div dir="auto" data-snippet-clipboard-copy-content="trkB := NewFairnessTrackerBuilder()
// Rotate the underlying hashes every one minute to avoid correlated false positives
trkB.SetRotationFrequency(1 * time.Minute)

trk, err := trkB.Build()
defer trk.Close()"><pre><span>trkB</span> <span>:=</span> <span>NewFairnessTrackerBuilder</span>()
<span>// Rotate the underlying hashes every one minute to avoid correlated false positives</span>
<span>trkB</span>.<span>SetRotationFrequency</span>(<span>1</span> <span>*</span> <span>time</span>.<span>Minute</span>)

<span>trk</span>, <span>err</span> <span>:=</span> <span>trkB</span>.<span>Build</span>()
<span>defer</span> <span>trk</span>.<span>Close</span>()</pre></div>
<p dir="auto">For every incoming request, you have to pass the flow identifier (the id over which you want to maintain fairness) into the tracket to see if it needs to be throttled. A client ID for example could be such ID to maintain resource fairness among all your clients.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ctx := context.Background()
id := []byte(&#34;client_id&#34;)

resp, _ := trk.RegisterRequest(ctx, id)
if resp.ShouldThrottle {
    throttleRequest()
}"><pre><span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()
<span>id</span> <span>:=</span> []<span>byte</span>(<span>&#34;client_id&#34;</span>)

<span>resp</span>, <span>_</span> <span>:=</span> <span>trk</span>.<span>RegisterRequest</span>(<span>ctx</span>, <span>id</span>)
<span>if</span> <span>resp</span>.<span>ShouldThrottle</span> {
    <span>throttleRequest</span>()
}</pre></div>
<p dir="auto">For any failure that indicates a shortage of resource (which is our trigger to start throttling), you report outcome as a failure. For any other outcomes that are considered failures in your business logic that don&#39;t indicate resource shortage, do not report any outcome.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ctx := context.Background()
id := []byte(&#34;client_id&#34;)

trk.ReportOutcome(ctx, id, request.OutcomeFailure)"><pre><span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()
<span>id</span> <span>:=</span> []<span>byte</span>(<span>&#34;client_id&#34;</span>)

<span>trk</span>.<span>ReportOutcome</span>(<span>ctx</span>, <span>id</span>, <span>request</span>.<span>OutcomeFailure</span>)</pre></div>
<p dir="auto">On the other hand, when you are able to get the resource, you report success.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ctx := context.Background()
id := []byte(&#34;client_id&#34;)

trk.ReportOutcome(ctx, id, request.OutcomeSuccess)"><pre><span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()
<span>id</span> <span>:=</span> []<span>byte</span>(<span>&#34;client_id&#34;</span>)

<span>trk</span>.<span>ReportOutcome</span>(<span>ctx</span>, <span>id</span>, <span>request</span>.<span>OutcomeSuccess</span>)</pre></div>

<p dir="auto">You can use the <code>GenerateTunedStructureConfig</code> to tune the tracker without directly touching the algorithm parameters. It exposes a simple interface where you have to pass the following things based on your application logic and scaling requirements.</p>
<ul dir="auto">
<li><code>expectedClientFlows</code> - Number of concurrent clients you expect to your app</li>
<li><code>bucketsPerLevel</code> - Number of buckets per level in the core structure</li>
<li><code>tolerableBadRequestsPerBadFlow</code> - Number of requests we can tolerate before we fully shut down a flow</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="conf := config.GenerateTunedStructureConfig(1000, 1000, 25)
trkB := NewFairnessTrackerBuilder()

trk, err := trkB.BuildWithConfig(config)
defer trk.Close()"><pre><span>conf</span> <span>:=</span> <span>config</span>.<span>GenerateTunedStructureConfig</span>(<span>1000</span>, <span>1000</span>, <span>25</span>)
<span>trkB</span> <span>:=</span> <span>NewFairnessTrackerBuilder</span>()

<span>trk</span>, <span>err</span> <span>:=</span> <span>trkB</span>.<span>BuildWithConfig</span>(<span>config</span>)
<span>defer</span> <span>trk</span>.<span>Close</span>()</pre></div>
</article></div></div>
  </body>
</html>
