<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://writings.stephenwolfram.com/2023/06/prompts-for-work-play-launching-the-wolfram-prompt-repository/">Original</a>
    <h1>The Wolfram Prompt Repository (2023)</h1>
    
    <div id="readability-page-1" class="page"><div>
            

<p><a href="https://resources.wolframcloud.com/PromptRepository/"><img title="Prompts for Work &amp; Play: Launching the Wolfram Prompt Repository" src="https://content.wolfram.com/sites/43/2023/06/prompt-repo-hero-v3.png" alt="Prompts for Work &amp; Play: Launching the Wolfram Prompt Repository" width="620" height="315"/></a></p>
<h2 id="building-blocks-of-llm-programming">Building Blocks of “LLM Programming”</h2>
<p>Prompts are how one channels an LLM to do something. LLMs in a sense always have lots of “latent capability” (e.g. from their training on billions of webpages). But prompts—in a way that’s <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">still scientifically mysterious</a>—are what let one “engineer” what part of that capability to bring out.<span id="more-50735"></span></p>
<div id="gpt-stripe">
<p>The functionality described here will be built into the upcoming version of <a href="https://www.wolfram.com/language/">Wolfram Language</a> (Version 13.3). To install it in the now-current version (Version 13.2), use </p>
<p data-c2c-file="https://content.wolfram.com/sites/43/2023/05/sw053123pacletinstall.txt" data-c2c-type="text/html" id="writtings-c2c_above"><tt>PacletInstall[&#34;Wolfram/Chatbook&#34;]</tt></p>
<p>and</p>
<div data-c2c-file="https://content.wolfram.com/sites/43/2023/05/sw052223pacletinstallimg1_copy.txt" data-c2c-type="text/html" id="writtings-c2cB_above"><tt>PacletInstall[&#34;Wolfram/LLMFunctions&#34;]</tt><p>.</p></div>
<p>You will also need an API key for the <a href="https://openai.com/">OpenAI</a> LLM or another LLM.</p>
</div>
<p>There are many different ways to use prompts. One can use them, for example, to tell an LLM to “adopt a particular persona”. One can use them to effectively get the LLM to “apply a certain function” to its input. And one can use them to get the LLM to frame its output in a particular way, or to call out to tools in a certain way.</p>
<p>And much as functions are the building blocks for computational programming—say in the <a href="https://www.wolfram.com/language/">Wolfram Language</a>—so prompts are the building blocks for “LLM programming”. And—much like functions—there are prompts that correspond to “lumps of functionality” that one can expect will be repeatedly used.</p>
<p>Today we’re launching the <a href="https://resources.wolframcloud.com/PromptRepository/">Wolfram Prompt Repository</a> to provide a curated collection of useful community-contributed prompts—set up to be seamlessly accessible both interactively in <a href="https://writings.stephenwolfram.com/2023/06/introducing-chat-notebooks-integrating-llms-into-the-notebook-paradigm">Chat Notebooks</a> and programmatically in <a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">things like <tt>LLMFunction</tt></a>: </p>
<p><a href="https://resources.wolframcloud.com/PromptRepository"><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg1a.png" alt="Wolfram Prompt Repository home page" title="Wolfram Prompt Repository home page" width="528" height="499"/></a></p>
<p>As a first example, let’s talk about the <a href="https://resources.wolframcloud.com/PromptRepository/resources/Yoda/"><span>&#34;Yoda&#34;</span></a> prompt, that’s listed as a “<a href="https://resources.wolframcloud.com/PromptRepository/category/personas">persona prompt</a>”. Here’s its page:</p>
<p><a href="https://resources.wolframcloud.com/PromptRepository/resources/Yoda/"><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg2.png" alt="Wolfram Prompt Repository Yoda persona" title="Wolfram Prompt Repository Yoda persona" width="528" height="384"/></a></p>
<p>So how do we use this prompt? If we’re using a Chat Notebook (say obtained from <tt>File</tt> &gt; <tt>New</tt> &gt; <tt>Chat-Driven Notebook</tt>) then just typing <tt><a href="https://resources.wolframcloud.com/PromptRepository/resources/Yoda/">@Yoda</a></tt> will “invoke” the Yoda persona:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg3.png" alt="Should I eat a piece of chocolate now?" title="Should I eat a piece of chocolate now?" width="605" height="112"/></p>
<p>At a programmatic level, one can “invoke the persona” through <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMPrompt</a></tt> (the result is different because there’s by default randomness involved):</p>

<div colspan="1" rowspan="1">
<div>
					<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg4.png" alt="" title="" width="624" height="73"/></p></div>

</div>
<p>There are several initial categories of prompts in the Prompt Repository:</p>
<p id="prompt-table"><a href="https://resources.wolframcloud.com/PromptRepository/category/personas"><img src="https://content.wolfram.com/sites/43/2023/06/prompt-repo-list-01a.png" width="620" height="auto"/></a><a href="https://resources.wolframcloud.com/PromptRepository/category/function-prompts"><img src="https://content.wolfram.com/sites/43/2023/06/prompt-repo-list-02.png" width="620" height="auto"/></a><a href="https://resources.wolframcloud.com/PromptRepository/category/modifier-prompts"><img src="https://content.wolfram.com/sites/43/2023/06/prompt-repo-list-03.png" width="620" height="auto"/></a></p>
<p>There’s a certain amount of crossover between these categories (and there’ll be more categories in the future—particularly related to generating computable results, and <a href="https://writings.stephenwolfram.com/2023/04/instant-plugins-for-chatgpt-introducing-the-wolfram-chatgpt-plugin-kit/">calling computational tools</a>). But there are different ways to use prompts in different categories.</p>
<p>Function prompts are all about taking existing text, and transforming it in some way. We can do this programmatically using <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMResourceFunction</a></tt>:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg6.png" alt="" title="" width="624" height="47"/>
				</p>

</div>

<p>We can also do it in a Chat Notebook using <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/ActiveVoiceRephrase/">!ActiveVoiceRephrase</a></span>, with the shorthand <span>^</span> to refer to text in the cell above, and <span>&gt;</span> to refer to text in the current chat cell:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg7.png" alt="The AI was switched off by him." title="The AI was switched off by him." width="605" height="105"/></p>
<p>Modifier prompts have to do with specifying how to modify output coming from the LLM. In this case, the LLM typically produces a whole mini-essay:</p>

<div colspan="1" rowspan="1">
<div>
					<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg8.png" alt="" title="" width="563" height="96"/></p></div>

</div>
<p>But with the <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/YesNo/">YesNo</a></span> modifier prompt, it simply says “Yes”:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg9.png" alt="" title="" width="601" height="73"/>
				</p>

</div>

<p>In a Chat Notebook, you can introduce a modifier prompt using <span>#</span>:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg10.png" alt="Is a watermelon bigger than a human head?" title="Is a watermelon bigger than a human head?" width="605" height="113"/></p>
<p>Quite often you’ll want several modifier prompts:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg11.png" alt="Is a watermelon bigger than a human head?" title="Is a watermelon bigger than a human head?" width="605" height="109"/></p>
<h2 id="what-does-having-a-prompt-repository-do-for-one">What Does Having a Prompt Repository Do for One?</h2>
<p>LLMs are powerful things. And one might wonder why, if one has a description for a prompt, one can’t just use that description directly, rather than having to store a prewritten prompt. Well, sometimes just using the description will indeed work fine. But often it won’t. Sometimes that’s because one needs to clarify further what one wants. Sometimes it’s because there are <a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/#how-it-works-and-wrangling-the-ai">not-immediately-obvious corner cases to cover</a>. And sometimes there’s just a certain amount of “LLM wrangling” to be done. And this all adds up to the need to do at least some “prompt engineering” on almost any prompt.</p>
<p>The <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/YesNo/">YesNo</a></span> modifier prompt from above is currently fairly simple:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg12.png" alt="" title="" width="550" height="94"/>
				</p>

</div>

<p>But it’s still already complicated enough one that doesn’t want to have to repeat it every time one’s trying to force a yes/no answer. And no doubt there’ll be subsequent versions of this prompt (that, yes, will have <a href="https://reference.wolfram.com/language/guide/WolframResourceSystem.html">versioning handled seamlessly</a> by the Prompt Repository) that will get increasingly elaborate, as more cases show up, and more prompt engineering gets done to address them. </p>
<p>Many of the prompts in the Prompt Repository even now are considerably more complicated. Some contain typical “general prompt engineering”, but others contain for example special information that the LLM doesn’t intrinsically know, or <a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/#functions-from-examples">detailed examples</a> that home in on what one wants to have happen.</p>
<p>In the simplest cases, prompts (like the <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/YesNo/">YesNo</a></span> one above) are just plain pieces of text. But often they contain parameters, or have additional computational or other content. And a key feature of the Wolfram Prompt Repository is that it can handle this ancillary material, ultimately by representing everything using <a href="https://www.wolfram.com/language/fast-introduction-for-programmers/en/symbolic-expressions/">Wolfram Language symbolic expressions</a>.</p>
<p>As we discussed in connection with <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMFunction</a></tt>, etc. <a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">in another post</a>, the core “textual” part of a prompt is represented by a symbolic <tt><a href="http://reference.wolfram.com/language/ref/StringTemplate.html">StringTemplate</a></tt> that immediately allows positional or named parameters. Then there can be an interpreter that applies a Wolfram Language <tt><a href="http://reference.wolfram.com/language/ref/Interpreter.html">Interpreter</a></tt> function to the raw textual output of the LLM—transforming it from plain text to a computable symbolic expression. More sophisticatedly, there can also be specifications of tools that the LLM can call (represented symbolically as <a href="https://reference.wolfram.com/language/ref/LLMTool.html"><tt>LLMTool</tt></a> constructs), as well as other information about the required LLM configuration (represented by an <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMConfiguration</a></tt> object). But the key point is that all of this is automatically “packaged up” in the Prompt Repository. </p>
<p>But what actually is the Wolfram Prompt Repository? Well, ultimately it’s just part of the general <a href="https://resources.wolframcloud.com/">Wolfram Resource System</a>—the same one that’s used for the <a href="https://resources.wolframcloud.com/FunctionRepository/">Wolfram Function Repository</a>, <a href="https://datarepository.wolframcloud.com/" target="_blank" rel="noopener">Wolfram Data Repository</a>, <a href="https://resources.wolframcloud.com/NeuralNetRepository/">Wolfram Neural Net Repository</a>, <a href="https://notebookarchive.org/">Wolfram Notebook Archive</a>, and many other things. </p>
<p>And so, for example, the <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/Yoda/">&#34;Yoda&#34;</a></span> prompt is in the end represented by a symbolic <tt><a href="http://reference.wolfram.com/language/ref/ResourceObject.html">ResourceObject</a></tt> that’s part of the Resource System:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg13.png" alt="" title="" width="550" height="101"/>
				</p>

</div>

<p>Open up the display of this resource object, and we’ll immediately see various pieces of metadata (and a link to documentation), as well as the ultimate canonical UUID of the object:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg14b.png" alt="" title="" width="603" height="176"/>
				</p>

</div>

<p>Everything that needs to use the prompt—Chat Notebooks, <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMPrompt</a></tt>, <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMResourceFunction</a></tt>, etc.—just works by accessing appropriate parts of the <tt><a href="http://reference.wolfram.com/language/ref/ResourceObject.html">ResourceObject</a></tt>, so that for example the “hero image” (used for the persona icon) is retrieved like this:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg15.png" alt="" title="" width="622" height="137"/>
				</p>

</div>

<p>There’s a lot of important infrastructure that “comes for free” from the general Wolfram Resource System—like efficient caching, automatic updating, documentation access, etc. And things like <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMPrompt</a></tt> follow the exact same approach as things like <tt><a href="http://reference.wolfram.com/language/ref/NetModel.html">NetModel</a></tt> in being able to immediately reference entries in a repository.</p>
<h2 id="whats-in-the-prompt-repository-so-far">What’s in the Prompt Repository So Far</h2>
<p>We haven’t been working on the Wolfram Prompt Repository for very long, and we’re just opening it up for outside contributions now. But already the Repository contains (as of today) about two hundred prompts. So what are they so far? Well, it’s a range. From “just for fun”, to very practical, useful and sometimes quite technical.</p>
<p>In the “just for fun” category, there are all sorts of <a href="https://resources.wolframcloud.com/PromptRepository/category/personas">personas</a>, including:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg16.png" alt="In a sentence or two, what are you good for?" title="In a sentence or two, what are you good for?" width="605" height="110"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg17a.png" alt="In a sentence or two, what are you good for?" title="In a sentence or two, what are you good for?" width="605" height="124"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg18.png" alt="In a sentence or two, what are you good for?" title="In a sentence or two, what are you good for?" width="605" height="118"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg19.png" alt="In a sentence or two, what are you good for?" title="In a sentence or two, what are you good for?" width="605" height="167"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg20.png" alt="In a sentence or two, what are you good for?" title="In a sentence or two, what are you good for?" width="605" height="112"/></p>
<p>There are also slightly more “practical” personas—like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/SupportiveFriend/">SupportiveFriend</a></span> and <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/SportsCoach/">SportsCoach</a></span> too—which can be more helpful sometimes than others:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg21a.png" alt="I&#39;m a bit tired of writing all these posts." title="I&#39;m a bit tired of writing all these posts." width="605" height="167"/></p>
<p>Then there are “functional” ones like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/NutritionistBot/">NutritionistBot</a></span>, etc.—though most of these are still very much under development, and will advance considerably when they are hooked up to tools, so they’re able to access <a href="https://www.wolfram.com/knowledgebase/">accurate computable knowledge</a>, external data, etc.</p>
<p>But the largest category of prompts so far in the Prompt Repository are <a href="https://resources.wolframcloud.com/PromptRepository/category/function-prompts">function prompts</a>: prompts which take text you supply, and do operations on it. Some are based on straightforward (at least for an LLM) text transformations:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg22.png" alt="There are many prompts available." title="There are many prompts available." width="605" height="112"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg23.png" alt="AIs are cool." title="AIs are cool." width="605" height="298"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg24.png" alt="!ShorterRephrase" title="!ShorterRephrase" width="605" height="146"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg25.png" alt="I hope you can come to my party." title="I hope you can come to my party." width="605" height="111"/></p>
<p>There are all sorts of text transformations that can be useful:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg26.png" alt="Stephen Wolfram lives in Concord, MA" title="Stephen Wolfram lives in Concord, MA" width="605" height="112"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg27.png" alt="A curated collection of prompts, personas, functions, &amp; more for LLMs" title="A curated collection of prompts, personas, functions, &amp; more for LLMs" width="605" height="122"/></p>
<p>Some function prompts—like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/Summarize/">Summarize</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/TLDR/">TLDR</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/NarrativeToResume/">NarrativeToResume</a></span>, etc.—can be very useful in making text easier to assimilate. And the same is true of things like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/LegalDejargonize/">LegalDejargonize</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/MedicalDejargonize/">MedicalDejargonize</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/ScientificDejargonize/">ScientificDejargonize</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/BizDejargonize/">BizDejargonize</a></span>—or, depending on your background, the <span>*Jargonize</span> versions of these:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg28.png" alt="The rat ignored the maze and decided to eat the cheese" title="The rat ignored the maze and decided to eat the cheese" width="605" height="144"/></p>
<p>Some text transformation prompts seem to perhaps make use of a little more “cultural awareness” on the part of the LLM:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg29.png" alt="WOLFRAM PROMPT REPOSITORY (UNDER CONSTRUCTION)" title="WOLFRAM PROMPT REPOSITORY (UNDER CONSTRUCTION)" width="605" height="188"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg30.png" alt="WOLFRAM PROMPT REPOSITORY (UNDER CONSTRUCTION)" title="WOLFRAM PROMPT REPOSITORY (UNDER CONSTRUCTION)" width="605" height="322"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg31.png" alt="AIs provide excellent programming advice." title="AIs provide excellent programming advice." width="605" height="212"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg32.png" alt="An app to let cats interact with chatbots" title="An app to let cats interact with chatbots" width="605" height="111"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg33.png" alt="A dinosaur that can roll itself up in a ball" title="A dinosaur that can roll itself up in a ball" width="605" height="111"/></p>
<p>Some function prompts are for analyzing text (or, for example, for doing <a href="https://reference.wolfram.com/language/guide/QuestionsAndAssessment.html">educational assessments</a>):</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg34.png" alt="I woz going to them place when I want stop" title="I woz going to them place when I want stop" width="605" height="167"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg35.png" alt="I believe plants should be the only organisms on the planet" title="I believe plants should be the only organisms on the planet" width="605" height="210"/></p>
<p>Sometimes prompts are most useful when they’re applied programmatically. Here are two synthesized sentences:</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg36.png" alt="" title="" width="586" height="119"/>
				</p>

</div>

<p>Now we can use the <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/DocumentCompare/">DocumentCompare</a></span> prompt to compare them (something that might, for example, be useful in regression testing):</p>

<div colspan="1" rowspan="1">
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg37.png" alt="" title="" width="590" height="96"/>
									</p>

</div>

<p>There are other kinds of “text analysis” prompts, like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/GlossaryGenerate/">GlossaryGenerate</a></span>, <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/CharacterList/">CharacterList</a></span> (characters mentioned in a piece of fiction) and <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/LOCTopicSuggest/">LOCTopicSuggest</a></span> (Library of Congress book topics):</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg38.png" alt="What is ChatGPT Doing and Why Does It Work?" title="What is ChatGPT Doing and Why Does It Work?" width="605" height="146"/></p>
<p>There are lots of other function prompts already in the Prompt Repository. Some—like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/FilenameSuggest/">FilenameSuggest</a></span> and <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/CodeImport/">CodeImport</a></span>—are aimed at doing computational tasks. Others make use of common-sense knowledge. And some are just fun. But, yes, writing good prompts is hard—and what’s in the Prompt Repository will gradually improve. And when there are bugs, they can be pretty weird. Like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/PunAbout/">PunAbout</a></span> is supposed to generate a pun about some topic, but here it decides to protest and say it must generate three:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg39.png" alt="Parrot" title="Parrot" width="605" height="234"/></p>
<p>The final category of prompts currently in the Prompt Repository are <a href="https://resources.wolframcloud.com/PromptRepository/category/modifier-prompts">modifier prompts</a>, intended as a way to modify the output generated by the LLM. Sometimes modifier prompts can be essentially textual:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg40.png" alt="How many legs does a spider have?" title="How many legs does a spider have?" width="605" height="115"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg41.png" alt="How many legs does a spider have?" title="How many legs does a spider have?" width="605" height="144"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg42.png" alt="How many legs does a spider have?" title="How many legs does a spider have?" width="605" height="145"/></p>
<p>But often modifier prompts are intended to create output in a particular form, suitable, for example, for interpretation by an interpreter in <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMFunction</a></tt>, etc.:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg43.png" alt="How many legs does a spider have?" title="How many legs does a spider have?" width="605" height="112"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg44.png" alt="Number of legs for the 5 common invertebrates" title="Number of legs for the 5 common invertebrates" width="605" height="252"/></p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg45.png" alt="Are AIs good?" title="Are AIs good?" width="605" height="112"/></p>
<p>So far the modifier prompts in the Prompt Repository are fairly simple. But once there are prompts that make use of tools (i.e. call back into Wolfram Language during the generation process) we can expect modifier prompts that are much more sophisticated, useful and robust.</p>
<h2 id="adding-your-own-prompts">Adding Your Own Prompts</h2>
<p>The Wolfram Prompt Repository is set up to be a curated public collection of prompts where it’s easy for anyone to submit a new prompt. But—as we’ll explain—you can also use the framework of the Prompt Repository to store “private” prompts, or share them with specific groups.</p>
<p>So how do you define a new prompt in the Prompt Repository framework? The easiest way is to fill out a Prompt Resource Definition Notebook:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg46.png" alt="Prompt Resource Definition Notebook" title="Prompt Resource Definition Notebook" width="528" height="auto"/></p>
<p>You can get this notebook <a href="https://resources.wolframcloud.com/PromptRepository/Unnamed-Prompt.nb">here</a>, or from the <tt>Submit a Prompt</tt> button at the top of the Prompt Repository website, or by evaluating <a href="https://reference.wolfram.com/language/ref/CreateNotebook.html"><tt>CreateNotebook</tt></a><tt>[&#34;PromptResource&#34;]</tt>.</p>
<p>The setup is directly analogous to the ones for the <a href="https://resources.wolframcloud.com/FunctionRepository">Wolfram Function Repository</a>, <a href="https://datarepository.wolframcloud.com/">Wolfram Data Repository</a>, <a href="https://resources.wolframcloud.com/NeuralNetRepository">Wolfram Neural Net Repository</a>, etc. And once you’ve filled out the Definition Notebook, you’ve got various choices:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg47.png" alt="Definition Notebook deployment options" title="Definition Notebook deployment options" width="272" height="143"/></p>
<p><tt>Submit to Repository</tt> sends the prompt to our curation team for our official Wolfram Prompt Repository; <a href="https://reference.wolfram.com/language/ref/Deploy.html"><tt>Deploy</tt></a> deploys it for your own use, and for people (or AIs) you choose to share it with. If you’re using the prompt “privately”, you can refer to it using its URI or other identifier (if you use <tt><a href="http://reference.wolfram.com/language/ref/ResourceRegister.html">ResourceRegister</a></tt> you can also just refer to it by the name you give it). </p>
<p>OK, so what do you need to specify in the Definition Notebook? The most important part is the actual prompt itself. And quite often the prompt may just be a (carefully crafted) piece of plain text. But ultimately—<a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/#how-it-all-works">as discussed elsewhere</a>—a prompt is a symbolic template, that can include parameters. And you can insert parameters into a prompt using “template slots”:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/05/sw053123promptrepoimg48.png" alt="Template slots" title="Template slots" width="272" height="313"/></p>
<p>(<tt>Template Expression</tt> lets you insert Wolfram Language code that will be evaluated when the prompt is applied—so you can for example include the current time with <tt><a href="http://reference.wolfram.com/language/ref/Now.html">Now</a></tt>.)</p>
<p>In simple cases, all you’ll need to specify is the “pure prompt”. But in more sophisticated cases you’ll also want to specify some “outside the prompt” information—and there are some sections for this in the Definition Notebook: </p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg49a.png" alt="Definition Notebook sections" title="Definition Notebook sections" width="480" height="108"/></p>
<p>Chat-Related Features is most relevant for personas:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg50a.png" alt="Chat features" title="Chat features" width="480" height="253"/></p>
<p>You can give an icon that will appear in Chat Notebooks for that persona. And then you can give Wolfram Language functions which are to be applied to the contents of each chat cell before it is fed to the LLM (“Cell Processing Function”), and to the output generated by the LLM (“Cell Post Evaluation Function”). These functions are useful in transforming material to and from the plain text consumed by the LLM, and supporting richer display and computational structures.</p>
<p>Programmatic Features is particularly relevant for function prompts, and for the way prompts are used in <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMResourceFunction</a></tt> etc.:</p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg51c.png" alt="Programmatic Features" title="Programmatic Features" width="480" height="266"/></p>
<p>There’s “function-oriented documentation” (analogous to what’s used for built-in Wolfram Language functions, or for functions in the Wolfram Function Repository). And then there’s the Output Interpreter: a function to be applied to the textual output of the LLM, to generate the actual expression that will be returned by <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMResourceFunction</a></tt>, or for formatting in a Chat Notebook.</p>
<p>What about the LLM Configuration section? </p>
<p><img src="https://content.wolfram.com/sites/43/2023/06/sw053123promptrepoimg52a.png" alt="LLM configuration options" title="LLM configuration options" width="480" height="141"/></p>
<p>The first thing it does is to define tools that can be requested by the LLM when this prompt is used. We’ll discuss tools in another post. But as we’ve mentioned several times, they’re a way of having the LLM call Wolfram Language to get particular computational results that are then returned to the LLM. The other part of the LLM Configuration section is a more general <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMConfiguration</a></tt> specification, which can include “temperature” settings, the requirement of using a particular underlying model (e.g. GPT-4), etc.</p>
<p>What else is in the Definition Notebook? There are two main documentation sections: one for Chat Examples, and one for Programmatic Examples. Then there are various kinds of metadata. </p>
<p>Of course, at the very top of the Definition Notebook there’s another very important thing: the name you specify for the prompt. And here—with the initial prompts we’ve put into the Prompt Repository—we’ve started to develop some conventions. Following typical Wolfram Language usage we’re “camel-casing” names (so it’s <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/TitleSuggest/">&#34;TitleSuggest&#34;</a></span> not <span>&#34;title suggest&#34;</span>). Then we try to use different grammatical forms for different kinds of prompts. For personas we try to use noun phrases (like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/Cheerleader/">&#34;Cheerleader&#34;</a></span> or <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/SommelierBot/">&#34;SommelierBot&#34;</a></span>). For functions we usually try to use verb phrases (like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/Summarize/">&#34;Summarize&#34;</a></span> or <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/HypeUp/">&#34;HypeUp&#34;</a></span>). And for modifiers we try to use past-tense verb forms (like <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/Translated/">&#34;Translated&#34;</a></span> or <span><a href="https://resources.wolframcloud.com/PromptRepository/resources/HaikuStyled/">&#34;HaikuStyled&#34;</a></span>). </p>
<p>The overall goal with prompt names—like with ordinary Wolfram Language function names—is to provide a summary of what the prompt does, in a form that’s short enough that it appears a bit like a word in computational language input, chats, etc.</p>
<p>OK, so let’s say you’ve filled out a Definition Notebook, and you <a href="https://reference.wolfram.com/language/ref/Deploy.html"><tt>Deploy</tt></a> it. You’ll get a webpage that includes the documentation you’ve given—and looks pretty much like any of the pages in the Wolfram Prompt Repository. And now if you want to use the prompt, you can just click the appropriate place on the webpage, and you’ll get a copyable version that you can immediately paste into an input cell, a chat cell, etc. (Within a Chat Notebook there’s an even more direct mechanism: in the chat icon menu, go to <tt>Add &amp; Manage Personas</tt>, and when you browse the Prompt Repository, there’ll be an <span><kbd>Install</kbd></span> button that will automatically install a persona.)</p>
<h2 id="a-language-of-prompts">A Language of Prompts</h2>
<p>LLMs fundamentally deal with natural language of the kind we humans normally use. But when we set up a named prompt we’re in a sense defining a “<a href="https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#the-concept-of-concepts">higher-level word</a>” that can be used to “communicate” with the LLM—at the least with the kind of “harness” that <tt><a href="https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/">LLMFunction</a></tt>, Chat Notebooks, etc. provide. And we can then imagine in effect “talking in prompts” and for example building up more and more levels of prompts.</p>
<p>Of course, we already have a major example of something that at least in outline is similar: the way in which over the past few decades we’ve been able to progressively <a href="https://writings.stephenwolfram.com/2019/05/what-weve-built-is-a-computational-language-and-thats-very-important/">construct a whole tower of functionality</a> from the <a href="https://reference.wolfram.com/language/">built-in functions in the Wolfram Language</a>. There’s an important difference, however: in defining built-in functions we’re always working on “solid ground”, with precise (carefully designed) computational specifications for what we’re doing. In setting up prompts for an LLM, try as we might to “write the prompts well” we’re in a sense ultimately “at the mercy of the LLM” and how it chooses to handle things.</p>
<p>It feels in some ways like the difference between dealing with engineering systems and with human organizations. In both cases one can set up plans and procedures for what should happen. In the engineering case, however, one can expect that (at least at the level of individual operations) the system will do exactly as one says. In the human case—well, all kinds of things can happen. That is not to say that amazing results can’t be achieved by human organizations; history clearly shows they can.</p>
<p>But—as someone who’s managed <a href="https://www.wolfram.com/">(human) organizations</a> now for more than four decades—I think I can say the “rhythm” and practices of dealing with human organizations differ in significant ways from those for technological ones. There’s still a definite pattern of what to do, but it’s different, with a different way of going back and forth to get results, different approaches to “debugging”, etc. </p>
<p>How will it work with prompts? It’s something we still need to get used to. But for me there’s immediately another useful “comparable”. Back in the early 2000s we’d had a decade or two of experience in developing what’s now Wolfram Language, with its precise formal specifications, carefully designed with consistency in mind. But then we started working on <a href="https://www.wolframalpha.com/">Wolfram|Alpha</a>—where now we wanted a system that would just deal with whatever input someone might provide. At first it was jarring. How could we develop any kind of manageable system based on boatloads of potentially incompatible heuristics? It took a little while, but eventually we realized that when everything is a heuristic there’s a certain pattern and structure to that. And over time the development we do has become progressively more systematic.</p>
<p>And so, I expect, it will be with prompts. In the Wolfram Prompt Repository today, we have a collection of prompts that cover a variety of areas, but are almost all “first level”, in the sense that they depend only on the base LLM, and not on other prompts. But over time I expect there’ll be whole hierarchies of prompts that develop (including metaprompts for building prompts, etc. ) And indeed I won’t be surprised if in this way all sorts of “repeatable lumps of functionality” are found, that actually can be implemented in a direct computational way, without depending on LLMs. (And, yes, this may well go through the kind of <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#semantic-grammar-and-the-power-of-computational-language">“semantic grammar” structure that I’ve discussed elsewhere</a>.)</p>
<p>But as of now, we’re still just at the point of first launching the Wolfram Prompt Repository, and beginning the process of understanding the range of things—both useful and fun—that can be achieved with prompts. But it’s already clear that there’s going to be a very interesting world of prompts—and a progressive development of “prompt language” that in some ways will probably parallel (though at a considerably faster rate) the historical development of ordinary human languages. </p>
<p>It’s going to be a community effort—just as it is with ordinary human languages—to explore and build out “prompt language”. And now that it’s launched, I’m excited to see how people will use our Prompt Repository, and just what remarkable things end up being possible through it.</p>
        </div></div>
  </body>
</html>
