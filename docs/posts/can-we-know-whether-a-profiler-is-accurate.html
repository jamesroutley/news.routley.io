<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stefan-marr.de/2025/10/can-we-know-whether-a-profiler-is-accurate/">Original</a>
    <h1>Can we know whether a profiler is accurate?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>If you have been following the adventures of our <a href="https://github.com/HumphreyHCB">hero</a> over the last couple of years,
you might remember that we <a href="https://stefan-marr.de/2023/09/dont-blindly-trust-your-profiler/">can’t really trust sampling profilers for Java</a>,
and <a href="https://stefan-marr.de/2024/09/instrumenation-based-profiling-on-jvms-is-broken/">it’s even worse for Java’s instrumentation-based profilers</a>.</p>

<p>For sampling profilers, the so-called <em>observer effect</em> gets in the way: when we profile a program, the profiling itself can change the program’s performance behavior. This means we can’t simply increase the sampling frequency to get a more accurate profile, because the sampling causes inaccuracies.
So, how could we possibly know whether a profile correctly reflects an execution?</p>

<p>We could try to look at the code and estimate how long each bit takes, and then painstakingly compute what an accurate profile would be. Unfortunately, with the complexity of today’s processors and language runtimes, this would require a cycle-accurate simulator that needs to model everything, from the processor’s pipeline, over the cache hierarchy, to memory and storage.
While there are simulators that do this kind of thing, they are generally too slow to simulate a full JVM with JIT compilation for any interesting program within a practical amount of time.
This means that simulation is currently impractical, and it is impractical to determine what a <em>ground truth</em> would be.</p>

<p>So, what other approaches might there be to determine whether a profile is accurate?</p>

<p>In 2010, <a href="https://dl.acm.org/doi/10.1145/1806596.1806618">Mytkowicz et al.</a> already checked whether Java profilers were <em>actionable</em>
by inserting computations at the Java bytecode level.
On today’s VMs, that’s unfortunately an approach that changes performance in fairly unpredictable ways, because it interacts with the compiler optimizations.
However, the idea to check whether a profiler accurately reflects the slowdown of a program is sound.
For example, an inaccurate profiler is less likely to correctly identify a change in the distribution of where a program spends its time.
Similarly, if we change the overall amount of time a program takes, without changing the distribution of where time is spent,
it may attribute run time to the wrong parts of a program.</p>

<p>We can detect both of these issues by accurately slowing down a program.
And, as you might know from the <a href="https://stefan-marr.de/2025/08/how-to-slow-down-a-program/">previous post</a>,
we are able to slow down programs fairly accurately.
<a href="#fig1">Figure 1</a> illustrates the idea with a stacked bar chart for a hypothetical distribution of run-time over three methods. This distribution should remain identical, independent of a slowdown observed by the program.
So, there’s a linear relation between the absolute time measured and a constant relation between the percentage of time per method, depending on the slowdown.</p>

<figure id="fig1">
<img src="https://stefan-marr.de/assets/2025/10/sketch-of-ideal-slowdown.svg"/>
<figcaption><strong>Figure 1:</strong> A stacked bar chart for a hypothetical program execution, showing the absolute time per method. A profiler should see the linear increase in run time taken by each method, but still report the same percentage of run time taken. If a profiler reports something else, we have found an inaccuracy.</figcaption>
</figure>

<p>With this slowdown approach, we can detect whether the profiler is accurate with respect to the predicted time increase.
I’ll leave all the technical details to the <a href="#paper">paper</a>.
We can also slow down individual basic blocks accurately to make a particular method take more time.
As it turns out, this is a good litmus test for the accuracy of profilers,
and we find a number of examples where they fail to attribute the run time correctly.
<a href="#fig2">Figure 2</a> shows an example for the <a href="https://github.com/smarr/are-we-fast-yet/tree/master/benchmarks/Java/src/havlak">Havlak benchmark</a>.
The bar charts show how much change the four profilers detect after we slowed down
<code>Vector.hasSome</code> to the level indicated by the red dashed line.
In this particular example, async-profiler detects the change accurately.
JFR is probably within the margin of error.
However, JProfiler and YourKit are completely off. JProfiler likely can’t deal with inlining and attributes the change to the <code>forEach</code> method that calls <code>hasSome</code>.
YourKit does not seem to see the change at all.</p>

<figure id="fig2">
<img src="https://stefan-marr.de/assets/2025/10/havlak-slowdown-of-hassome.svg"/>
<figcaption><strong>Figure 2:</strong> Bar chart with the change in run time between the baseline and slowed-down version, for the top 5 methods of the Havlak benchmark. 
The red dashed line indicates the expected change for the <code>Vector.hasSome</code> method. Only async-profiler and JFR come close to the expectation.</figcaption>
</figure>

<p>With this slowdown-based approach, we finally have a way to see how accurate sampling profilers are by approximating the <em>ground truth</em> profile. Since we can’t measure the ground truth directly, we found a way to sidestep a fundamental problem and found a reasonably practical solution.</p>

<p>The <a href="#paper">paper</a> details how we implement our <em>divining</em> approach, i.e., how we slow down programs accurately.
It also has all the methodological details, research questions, benchmarking setup, and lots more numbers, especially in the appendix. So, please give it a read, and let us know what you think.</p>

<p>If you happen to attend the SPLASH conference,
Humphrey is presenting our work <a href="https://conf.researchr.org/details/icfp-splash-2025/vmil-2025/3/Evaluating-Candidate-Instructions-for-Reliable-Program-Slowdown-at-the-Compiler-Level">today</a> and on <a href="https://2025.splashcon.org/details/OOPSLA/207/Divining-Profiler-Accuracy-An-Approach-to-Approximate-Profiler-Accuracy-Through-Mach">Saturday</a>.</p>

<p>Questions, pointers, and suggestions are always welcome, for instance, on 
<a href="https://mastodon.acm.org/@smarr/115375396310482176">Mastodon</a>,
<a href="https://bsky.app/profile/stefan-marr.de/post/3m36z2u34tk2l">BlueSky</a>, or
<a href="https://x.com/smarr/status/1978259584432091530">Twitter</a>.</p>

<p>Thanks to <a href="https://octavelarose.github.io/">Octave</a> for feedback on this post.</p>



<p><strong>Abstract</strong></p>

<blockquote>
  <p>Optimizing performance on top of modern runtime systems with just-in-time (JIT) compilation is a challenge for a wide range of applications from browser-based applications on mobile devices to large-scale server applications. Developers often rely on sampling-based profilers to understand where their code spends its time. Unfortunately, sampling of JIT-compiled programs can give inaccurate and sometimes unreliable results.</p>

<p>To assess accuracy of such profilers, we would ideally want to compare their results to a known ground truth. With the complexity of today’s software and hardware stacks, such ground truth is unfortunately not available. Instead, we propose a novel technique to approximate a ground truth by accurately slowing down a Java program at the machine-code level, preserving its optimization and compilation decisions as well as its execution behavior on modern CPUs.</p>

<p>Our experiments demonstrate that we can slow down benchmarks by a specific amount, which is a challenge because of the optimizations in modern CPUs, and we verified with hardware profiling that on a basic-block level, the slowdown is accurate for blocks that dominate the execution. With the benchmarks slowed down to specific speeds, we confirmed that async-profiler, JFR, JProfiler, and YourKit maintain original performance behavior and assign the same percentage of run time to methods. Additionally, we identify cases of inaccuracy caused by missing debug information, which prevents the correct identification of the relevant source code. Finally, we tested the accuracy of sampling profilers by approximating the ground truth by the slowing down of specific basic blocks and found large differences in accuracy between the profilers.</p>

<p>We believe, our slowdown-based approach is the first practical methodology to assess the accuracy of sampling profilers for JIT-compiling systems and will enable further work to improve the accuracy of profilers.</p>

</blockquote>

<ul>
  <li>Divining Profiler Accuracy: An Approach to Approximate Profiler Accuracy Through Machine Code-Level Slowdown</li>

    <li>
      Paper:
        <a href="https://stefan-marr.de/downloads/oopsla25-burchell-marr-divining-profiler-accuracy.pdf">
          PDF</a>
    </li>

    <li>
        DOI: <a href="https://doi.org/10.1145/3763180">10.1145/3763180</a>
    </li>

    
    <li>
      Appendix: <a href="https://doi.org/10.5281/zenodo.16911348">online appendix</a>
    </li>
    


    <li>
      BibTex:
      <span tabindex="0"><span>bibtex</span>
      <pre>@article{Burchell:2025:Divining,
  abstract = {Optimizing performance on top of modern runtime systems with just-in-time (JIT) compilation is a challenge for a wide range of applications from browser-based applications on mobile devices to large-scale server applications. Developers often rely on sampling-based profilers to understand where their code spends its time. Unfortunately, sampling of JIT-compiled programs can give inaccurate and sometimes unreliable results.
  
  To assess accuracy of such profilers, we would ideally want to compare their results to a known ground truth. With the complexity of today&#39;s software and hardware stacks, such ground truth is unfortunately not available. Instead, we propose a novel technique to approximate a ground truth by accurately slowing down a Java program at the machine-code level, preserving its optimization and compilation decisions as well as its execution behavior on modern CPUs.
  
  Our experiments demonstrate that we can slow down benchmarks by a specific amount, which is a challenge because of the optimizations in modern CPUs, and we verified with hardware profiling that on a basic-block level, the slowdown is accurate for blocks that dominate the execution. With the benchmarks slowed down to specific speeds, we confirmed that async-profiler, JFR, JProfiler, and YourKit maintain original performance behavior and assign the same percentage of run time to methods. Additionally, we identify cases of inaccuracy caused by missing debug information, which prevents the correct identification of the relevant source code. Finally, we tested the accuracy of sampling profilers by approximating the ground truth by the slowing down of specific basic blocks and found large differences in accuracy between the profilers.
  
  We believe, our slowdown-based approach is the first practical methodology to assess the accuracy of sampling profilers for JIT-compiling systems and will enable further work to improve the accuracy of profilers.},
  acceptancerate = {0.356},
  appendix = {https://doi.org/10.5281/zenodo.16911348},
  articleno = {402},
  author = {Burchell, Humphrey and Marr, Stefan},
  blog = {https://stefan-marr.de/2025/10/can-we-know-whether-a-profiler-is-accurate/},
  doi = {10.1145/3763180},
  issn = {2475-1421},
  journal = {Proceedings of the ACM on Programming Languages},
  keywords = {Accuracy GroundTruth Java MeMyPublication Profiling Sampling myown},
  month = oct,
  number = {OOPSLAB25},
  numpages = {32},
  pdf = {https://stefan-marr.de/downloads/oopsla25-burchell-marr-divining-profiler-accuracy.pdf},
  publisher = {{ACM}},
  series = {OOPSLA&#39;25},
  title = {{Divining Profiler Accuracy: An Approach to Approximate Profiler Accuracy Through Machine Code-Level Slowdown}},
  year = {2025},
  month_numeric = {10}
}
</pre>
      </span>
    </li>
</ul>


</div></div>
  </body>
</html>
