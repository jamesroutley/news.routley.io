<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2024/Oct/25/pelicans-on-a-bicycle/">Original</a>
    <h1>Pelicans on a bicycle</h1>
    
    <div id="readability-page-1" class="page"><div>



<p><strong><a href="https://github.com/simonw/pelican-bicycle/blob/main/README.md">Pelicans on a bicycle</a></strong>. I decided to roll out my own LLM benchmark: how well can different models render an SVG of a pelican riding a bicycle?</p>
<p>I chose that because a) I like pelicans and b) I&#39;m pretty sure there aren&#39;t any pelican on a bicycle SVG files floating around (yet) that might have already been sucked into the training data.</p>
<p>My prompt:</p>
<blockquote>
<p><code>Generate an SVG of a pelican riding a bicycle</code></p>
</blockquote>
<p>I&#39;ve run it through 16 models so far - from OpenAI, Anthropic, Google Gemini and  Meta (Llama running on Cerebras), all using my <a href="https://llm.datasette.io/">LLM</a> CLI utility. Here&#39;s my (<a href="https://gist.github.com/simonw/32273a445da3318df690749701805863">Claude assisted</a>) Bash script: <a href="https://github.com/simonw/pelican-bicycle/blob/b25faf3e29dcf73c97278dfdd7b7b973462eb0cb/generate-svgs.sh">generate-svgs.sh</a></p>
<p>Here&#39;s Claude 3.5 Sonnet (2024-06-20) and Claude 3.5 Sonnet (2024-10-22):</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/claude-3-5-sonnet-20240620.svg"/> <img src="https://static.simonwillison.net/static/2024/pelican-bicycles/claude-3-5-sonnet-20241022.svg"/></p>
<p>Gemini 1.5 Flash 001 and Gemini 1.5 Flash 002:</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/gemini-1.5-flash-001.svg"/> <img src="https://static.simonwillison.net/static/2024/pelican-bicycles/gemini-1.5-flash-002.svg"/></p>
<p>GPT-4o mini and GPT-4o:</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/gpt-4o-mini.svg"/> <img src="https://static.simonwillison.net/static/2024/pelican-bicycles/gpt-4o.svg"/></p>
<p>o1-mini and o1-preview:</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/o1-mini.svg"/> <img src="https://static.simonwillison.net/static/2024/pelican-bicycles/o1-preview.svg"/></p>
<p>Cerebras Llama 3.1 70B and Llama 3.1 8B:</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/cerebras-llama3.1-70b.svg"/> <img src="https://static.simonwillison.net/static/2024/pelican-bicycles/cerebras-llama3.1-8b.svg"/></p>
<p>And a special mention for Gemini 1.5 Flash 8B:</p>
<p><img src="https://static.simonwillison.net/static/2024/pelican-bicycles/gemini-1.5-flash-8b-001.svg"/></p>
<p>The rest of them are <a href="https://github.com/simonw/pelican-bicycle/blob/main/README.md">linked from the README</a>.</p>



</div></div>
  </body>
</html>
