<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theregister.com/2025/10/02/microsoft_maia_dc/">Original</a>
    <h1>Microsoft CTO says he wants to swap most AMD and Nvidia GPUs for homemade chips</h1>
    
    <div id="readability-page-1" class="page"><div id="body">
<p>Microsoft buys a lot of GPUs from both Nvidia and AMD. But moving forward, Redmond&#39;s leaders want to shift the majority of its AI workloads from GPUs to its own homegrown accelerators.</p>
<p>The software titan is rather late to the custom silicon party. While Amazon and Google have been building custom CPUs and AI accelerators for years, Microsoft only <a target="_blank" rel="nofollow" href="https://www.nextplatform.com/2023/11/15/microsoft-holds-chip-makers-feet-to-the-fire-with-homegrown-cpu-and-ai-chips/">revealed</a> its Maia AI accelerators in late 2023.</p>
<p>Driving the transition is a focus on performance per dollar, which for a hyperscale cloud provider is arguably the only metric that really matters. Speaking during a <a target="_blank" rel="nofollow" href="https://www.cnbc.com/2025/10/01/microsoft-wants-to-mainly-use-its-own-ai-chips-in-the-future.html">fireside</a> chat moderated by CNBC on Wednesday, Microsoft CTO Kevin Scott said that up to this point, Nvidia has offered the best price-performance, but he&#39;s willing to entertain anything in order to meet demand.</p>

    

<p>Going forward, Scott suggested Microsoft hopes to use its homegrown chips for the majority of its datacenter workloads.</p>

        


        

<p>When asked, &#34;Is the longer term idea to have mainly Microsoft silicon in the data center?&#34; Scott responded, &#34;Yeah, absolutely.&#34;</p>
<p>Later, he told CNBC, &#34;It&#39;s about the entire system design. It&#39;s the networks and cooling, and you want to be able to have the freedom to make decisions that you need to make in order to really optimize your compute for the workload.&#34;</p>

        

<p>With its first in-house AI accelerator, the Maia 100, Microsoft was able to free up GPU capacity by shifting OpenAI&#39;s GPT-3.5 to its own silicon back in 2023. However, with just 800 teraFLOPS of BF16 performance, 64GB of HBM2e, and 1.8TB/s of memory bandwidth, the chip fell well short of competing GPUs from Nvidia and AMD.</p>
<ul>

<li><a href="https://www.theregister.com/2025/09/27/alibaba_ai_drive/">Alibaba unveils $53B global AI plan – but it will need GPUs to back it up</a></li>

<li><a href="https://www.theregister.com/2025/09/11/nvidias_graceblackwell_drives_arms_cpu/">Arm wrestles away 25% share of server market thanks to Nvidia&#39;s home-grown CPUs</a></li>

<li><a href="https://www.theregister.com/2025/06/11/sipearl_rhea1_reference_design/">SiPearl ships reference node design for Rhea1 high-spec Arm chip</a></li>

<li><a href="https://www.theregister.com/2025/04/01/arm_datacenter_cpu_market/">Arm reckons it&#39;ll own 50% of the datacenter by year&#39;s end</a></li>
</ul>
<p>Microsoft is <a target="_blank" rel="nofollow" href="https://www.theinformation.com/articles/microsoft-scales-back-ambitions-ai-chips-overcome-delays">reportedly</a> in the process of bringing a second-generation Maia accelerator to market next year that will no doubt offer more competitive compute, memory, and interconnect performance.</p>
<p>But while we may see a change in the mix of GPUs to AI ASICs in Microsoft data centers moving forward, they&#39;re unlikely to replace Nvidia and AMD&#39;s chips entirely.</p>
<p>Over the past few years, Google and Amazon have deployed tens of thousands of their TPUs and Trainium accelerators. While these chips have helped them secure some high-profile customer wins, Anthropic for <a target="_blank" href="https://www.theregister.com/2025/07/04/project_rainier_deep_dive/">example</a>, these chips are more often used to accelerate the company&#39;s own in-house workloads.</p>
<p>As such, we continue to see large-scale Nvidia and AMD GPU deployments on these cloud platforms, in part because customers still want them.</p>

        

<p>It should be noted that AI accelerators aren&#39;t the only custom chips Microsoft has been working on. Redmond also has its own CPU called <a target="_blank" rel="nofollow" href="https://www.cnbc.com/2025/10/01/microsoft-wants-to-mainly-use-its-own-ai-chips-in-the-future.html">Cobalt</a> and a whole host of platform security silicon <a target="_blank" href="https://www.theregister.com/2025/08/26/microsoft_silicon_security/">designed</a> to accelerate cryptography and safeguard key exchanges across its vast datacenter domains. ®</p>                                
                    </div></div>
  </body>
</html>
