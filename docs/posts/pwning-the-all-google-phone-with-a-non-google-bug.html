<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.blog/2023-01-23-pwning-the-all-google-phone-with-a-non-google-bug/">Original</a>
    <h1>Pwning the all Google phone with a non-Google bug</h1>
    
    <div id="readability-page-1" class="page"><div>
  <div>
    


<main role="main" id="post-69576">
  
<h2 id="the-not-google-bug-in-the-all-google-phone">The “not-Google” bug in the “all-Google” phone<a href="#the-not-google-bug-in-the-all-google-phone" aria-label="The “not-Google” bug in the “all-Google” phone"></a></h2>
<p>The year is 2021 A.D. The first “all Google” phone, the Pixel 6 series, made entirely by Google, is launched.</p>
<p>Well not entirely…</p>
<p>One small GPU chip still holds out. And life is not easy for security researchers who audit the fortified camps of <a href="https://developer.arm.com/Architectures/Midgard">Midgard</a>, <a href="https://developer.arm.com/Architectures/Bifrost">Bifrost</a>, and <a href="https://developer.arm.com/Architectures/Valhall">Valhall</a>.<sup id="fnref-69576-1"><a href="#fn-69576-1" title="Read footnote.">1</a></sup></p>

<p>An unfortunate security researcher was about to learn this the hard way as he wandered into the Arm Mali regime:<br/>
</p>
<h2 id="cve-2022-38181">CVE-2022-38181<a href="#cve-2022-38181" aria-label="CVE-2022-38181"></a></h2>
<p>In this post I’ll cover the details of <a href="https://developer.arm.com/Arm%20Security%20Center/Mali%20GPU%20Driver%20Vulnerabilities">CVE-2022-38181</a>, a vulnerability in the Arm Mali GPU that I reported to the Android security team on 2022-07-12 along with a proof-of-concept exploit that used this vulnerability to gain arbitrary kernel code execution and root privileges on a Pixel 6 from an Android app. The bug was assigned bug ID 238770628. After initially rating it as a High-severity vulnerability, the Android security team later decided to reclassify it as a “Won’t fix” and they passed my report to Arm’s security team. I was eventually able to get in touch with Arm’s security team to independently follow up on the issue. The Arm security team were very helpful throughout and released a public patch in version <a href="https://developer.arm.com/downloads/-/mali-drivers/valhall-kernel">r40p0 of the driver on 2022-10-07</a> to address the issue, which was considerably quicker than similar disclosures that I had in the past on Android. A coordinated disclosure date of around mid-November was also agreed to allow time for users to apply the patch.   However, I was unable to connect with the Android security team and the bug was quietly fixed in the January update on the Pixel devices as bug <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13-qpr1%5E%21/#F0">259695958</a>. Neither the CVE ID, nor the bug ID (the original 238770628 and the new 259695958) were mentioned in the security bulletin. Our advisory, including the disclosure timeline, can be found <a href="https://securitylab.github.com/advisories/GHSL-2022-054_Arm_Mali/">here</a>.</p>
<h2 id="the-arm-mali-gpu">The Arm Mali GPU<a href="#the-arm-mali-gpu" aria-label="The Arm Mali GPU"></a></h2>
<p>The Arm Mali GPU is a “device-specific” hardware component which can be integrated into various devices, ranging from Android phones to smart TV boxes. For example, all of the international versions of the Samsung S series phones, up to S21 use the Mali GPU, as well as the Pixel 6 series. For additional examples, see “implementations” in <a href="https://en.wikipedia.org/wiki/Mali_(GPU)">Mali(GPU) Wikipedia entry</a> for some specific devices that use the Mali GPU.</p>
<p>As explained in my <a href="https://github.blog/2022-06-16-the-android-kernel-mitigations-obstacle-race/">other post</a>, GPU drivers on Android are a very attractive target for an attacker, as they can be reached directly from the untrusted app domain and most Android devices use either Qualcomm’s Adreno GPU, or the Arm Mali GPU, meaning that relatively few bugs can cover a large number of devices.</p>
<p>In fact, of the seven Android 0-days that were detected as exploited in the wild in 2021– five targeted GPU drivers. Another more recent bug that was exploited in the wild – <a href="https://source.android.com/security/bulletin/pixel/2022-03-01">CVE-2021-39793</a>, disclosed in March 2022 – also targeted a GPU driver. Together, of these six bugs that were exploited in the wild that targeted Android GPU drivers, three bugs targeted the Qualcomm GPU, while the other three targeted the Arm Mali GPU.</p>
<p>Due to the complexity involved in managing memory sharing between user space applications and the GPU, many of the vulnerabilities in the Arm Mali GPU involve the memory management code. The current vulnerability is another example of this, and involves a special type of GPU memory: the JIT memory.</p>
<p>Contrary to the name, JIT memory does not seem to be related to JIT compiled code, as it is created as non-executable memory. Instead, it seems to be used for memory caches, managed by the GPU kernel driver, that can readily be shared with user applications and returned to the kernel when memory pressure arises.</p>
<p>Many other types of GPU memory are created directly using ioctl calls like <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_mem_linux.c#292&gt;KBASE_IOCTL_MEM_ALLOC&lt;/a&gt;&lt;/code&gt;%20or%20&lt;code&gt;&lt;a%20href=" https:="">KBASE_IOCTL_MEM_IMPORT</a></code>. (See, for example, the section <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#memory-management-in-the-mali-kernel-driver">“Memory management in the Mali kernel driver”</a> in my previous post.) This, however, is not the case for JIT memory regions, which are created by submitting a special GPU instruction using the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_core_linux.c#822">KBASE_IOCTL_JOB_SUBMIT</a></code> <code>ioctl</code> call.</p>
<p>The <code>KBASE_IOCTL_JOB_SUBMIT</code> <code>ioctl</code> can be used to submit a “job chain” to the GPU for processing. Each job chain is basically a list of jobs, which are opaque data structures that contain job headers, followed by payloads that contain the specific instructions. For an example, see the <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#writing-to-gpu-memory">Writing to GPU memory</a> section in my previous post. While the <code>KBASE_IOCTL_JOB_SUBMIT</code> is normally used for sending instructions to the GPU itself, there are also some jobs that are implemented in the kernel and run on the host (CPU) instead. These are the software jobs (“softjobs”) and among them are jobs that instruct the kernel to allocate and free JIT memory (<code>BASE_JD_REQ_SOFT_JIT_ALLOC</code> and <code>BASE_JD_REQ_SOFT_JIT_FREE</code>).</p>
<h3 id="the-life-cycle-of-jit-memory">The life cycle of JIT memory<a href="#the-life-cycle-of-jit-memory" aria-label="The life cycle of JIT memory"></a></h3>
<p>While <code>KBASE_IOCTL_JOB_SUBMIT</code> is a general purpose <code>ioctl</code> call and contains code paths that are responsible for handling different types of GPU jobs, the <code>BASE_JD_REQ_SOFT_JIT_ALLOC</code> job essentially calls <code>kbase_jit_allocate_process</code>, which then calls <code>kbase_jit_allocate</code> to create a JIT memory region. To understand the lifetime and usage of JIT memory, let me first introduce a few different concepts.</p>
<p>When using the Mali GPU driver, a user app first needs to create and initialize a <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_defs.h#1747">kbase_context</a></code> kernel object. This involves the user app opening the driver file and using the resulting file descriptor to make a series of <code>ioctl</code> calls.  A <code>kbase_context</code> object is responsible for managing resources for each driver file that is opened and is unique for each file handle. In particular, it has three <code>list_head</code> fields that are responsible for managing JIT memory: the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_defs.h#1915">jit_active_head</a></code>, the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_defs.h#1916)">jit_pool_head</a></code>, and the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_defs.h#1917">jit_destroy_head</a></code>. As their names suggest, <code>jit_active_head</code> contains memory that is still in use by the user application, <code>jit_pool_head</code> contains memory regions that are not in use, and <code>jit_destroy_head</code> contains memory regions that are pending to be freed and returned to the kernel. Although both <code>jit_pool_head</code> and <code>jit_destroy_head</code> are used to manage JIT regions that are free, <code>jit_pool_head</code> acts like a memory pool and contains JIT regions that are intended to be reused when new JIT regions are allocated, while <code>jit_destroy_head</code> contains regions that are going to be returned to the kernel.</p>
<p>When <code>kbase_jit_allocate</code> is called, it’ll first try to find a suitable region in the <code>jit_pool_head</code>:</p>
<pre><code>    if (info-&gt;usage_id != 0)
        /* First scan for an allocation with the same usage ID */
        reg = find_reasonable_region(info, &amp;kctx-&gt;jit_pool_head, false);
        ...
    if (reg) {
        ...
        list_move(&amp;reg-&gt;jit_node, &amp;kctx-&gt;jit_active_head);
</code></pre>
<p>If a suitable region is found, then it’ll be moved to <code>jit_active_head</code>, indicating that it is now in use in userland. Otherwise, a memory region will be created and added to the <code>jit_active_head</code> instead. The region allocated by <code>kbase_jit_allocate</code>, whether it is newly created or reused from <code>jit_pool_head</code>, is then stored in the <code>jit_alloc</code> array of the <code>kbase_context</code> by <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_softjobs.c#1201">kbase_jit_allocate_process</a></code>.</p>
<p>When the user no longer needs the JIT memory, it can send a <code>BASE_JD_REQ_SOFT_JIT_FREE</code> job to the GPU. This then uses <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.c#4525">kbase_jit_free</a></code> to free the memory. However, rather than returning the backing pages of the memory region back to the kernel immediately, <code>kbase_jit_free</code> first reduces the backing region to a minimal size and removes any CPU side mapping, so the pages in the region are no longer reachable from the address space of the user process:</p>
<pre><code>void kbase_jit_free(struct kbase_context *kctx, struct kbase_va_region *reg)
{
    ...
    //First reduce the size of the backing region and unmap the freed pages
    old_pages = kbase_reg_current_backed_size(reg);
    if (reg-&gt;initial_commit &lt; old_pages) {
        u64 new_size = MAX(reg-&gt;initial_commit,
            div_u64(old_pages * (100 - kctx-&gt;trim_level), 100));
        u64 delta = old_pages - new_size;
        //Free delta pages in the region and reduces its size to old_pages - delta
        if (delta) {
            mutex_lock(&amp;kctx-&gt;reg_lock);
            kbase_mem_shrink(kctx, reg, old_pages - delta);
            mutex_unlock(&amp;kctx-&gt;reg_lock);
        }
    }
    ...
    //Remove the pages from address space of user process
    kbase_mem_shrink_cpu_mapping(kctx, reg, 0, reg-&gt;gpu_alloc-&gt;nents);    
</code></pre>
<p>Note that the backing pages of the region (<code>reg</code>) are not completely removed at this stage, and <code>reg</code> is also not going to be freed here. Instead, <code>reg</code> is moved back into <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.c#4579">jit_pool_head</a></code>. However, perhaps more interestingly, <code>reg</code> is also moved to the <code>evict_list</code> of the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.c#4579">kbase_context</a></code>:</p>
<pre><code>    kbase_mem_shrink_cpu_mapping(kctx, reg, 0, reg-&gt;gpu_alloc-&gt;nents);
    ...
    mutex_lock(&amp;kctx-&gt;jit_evict_lock);
    /* This allocation can&#39;t already be on a list. */
    WARN_ON(!list_empty(&amp;reg-&gt;gpu_alloc-&gt;evict_node));
    //Add reg to evict_list
    list_add(&amp;reg-&gt;gpu_alloc-&gt;evict_node, &amp;kctx-&gt;evict_list);
    atomic_add(reg-&gt;gpu_alloc-&gt;nents, &amp;kctx-&gt;evict_nents);
    //Move reg to jit_pool_head
    list_move(&amp;reg-&gt;jit_node, &amp;kctx-&gt;jit_pool_head);
</code></pre>
<p>After <code>kbase_jit_free</code> completed, its caller, <code>kbase_jit_free_finish</code>, will also clean up the reference stored in <code>jit_alloc</code> when the region was allocated, even though <code>reg</code> is still valid at this stage:</p>
<pre><code>static void kbase_jit_free_finish(struct kbase_jd_atom *katom)
{
    ...
    for (j = 0; j != katom-&gt;nr_extres; ++j) {
        if ((ids[j] != 0) &amp;&amp; (kctx-&gt;jit_alloc[ids[j]] != NULL)) {
            ...
            if (kctx-&gt;jit_alloc[ids[j]] !=
                    KBASE_RESERVED_REG_JIT_ALLOC) {
                ...
                kbase_jit_free(kctx, kctx-&gt;jit_alloc[ids[j]]);
            }
            kctx-&gt;jit_alloc[ids[j]] = NULL;    //&lt;--------- clean up reference
        }
    }
    ...
}
</code></pre>
<p>As we’ve seen before, the memory region in the <code>jit_pool_head</code> list may now be reused when the user allocates another JIT region. So this explains <code>jit_pool_head</code> and <code>jit_active_head</code>. What about <code>jit_destroy_head</code>? When JIT memory is freed by calling <code>kbase_jit_free</code>, it is also put on the <code>evict_list</code>. Memory regions in the <code>evict_list</code> are regions that can be freed when memory pressure arises. By putting a JIT region that is no longer in use in the <code>evict_list</code>, the Mali driver can hold onto unused JIT memory for quick reallocation, while returning them to the kernel when the resources are needed.</p>
<p>The Linux kernel provides a mechanism to reclaim unused cached memory, called <a href="https://lwn.net/Articles/550463/">shrinkers</a>. Kernel components, such as drivers, can define a <code><a href="https://elixir.bootlin.com/linux/v5.19.9/source/include/linux/shrinker.h#L60">shrinker</a></code> object, which, amongst other things, involves defining the <code>count_objects</code> and <code>scan_objects</code> methods:</p>
<pre><code>struct shrinker {
    unsigned long (*count_objects)(struct shrinker *,
                       struct shrink_control *sc);
    unsigned long (*scan_objects)(struct shrinker *,
                      struct shrink_control *sc);
    ...
};
</code></pre>
<p>The custom <code>shrinker</code> can then be registered via the <code><a href="https://elixir.bootlin.com/linux/v5.19.9/source/mm/vmscan.c#L656">register_shrinker</a></code> method. When the kernel is under memory pressure, it’ll go through the list of registered <code>shrinkers</code> and use their <code>count_objects</code> method to determine potential amount of memory that can be freed, and then use <code>scan_objects</code> to free the memory. In the case of the Mali GPU driver, the <code>shrinker</code> is defined and registered in the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#757">kbase_mem_evictable_init</a></code> method:</p>
<pre><code>int kbase_mem_evictable_init(struct kbase_context *kctx)
{
    ...
    //kctx-&gt;reclaim is a shrinker
    kctx-&gt;reclaim.count_objects = kbase_mem_evictable_reclaim_count_objects;
    kctx-&gt;reclaim.scan_objects = kbase_mem_evictable_reclaim_scan_objects;
    ...
    register_shrinker(&amp;kctx-&gt;reclaim);
    return 0;
}
</code></pre>
<p>The more interesting part of these methods is the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#702">kbase_mem_evictable_reclaim_scan_objects</a></code>, which is responsible for freeing the memory needed by the kernel.</p>
<pre><code>static
unsigned long kbase_mem_evictable_reclaim_scan_objects(struct shrinker *s,
        struct shrink_control *sc)
{
    ...
    list_for_each_entry_safe(alloc, tmp, &amp;kctx-&gt;evict_list, evict_node) {
        int err;

        err = kbase_mem_shrink_gpu_mapping(kctx, alloc-&gt;reg,
                0, alloc-&gt;nents);
        ...
        kbase_free_phy_pages_helper(alloc, alloc-&gt;evicted);
        ...
        list_del_init(&amp;alloc-&gt;evict_node);
        ...
        kbase_jit_backing_lost(alloc-&gt;reg);   //&lt;------- moves `reg` to `jit_destroy_pool`
    }
    ...
}
</code></pre>
<p>This is called to remove cached memory in <code>jit_pool_head</code> and return it to the kernel. The function <code>kbase_mem_evictable_reclaim_scan_objects</code> goes through the <code>evict_list</code>, unmaps the backing pages from the GPU (recall that the CPU mapping is already removed in <code>kbase_jit_free</code>) and then frees the backing pages. It then calls <code>kbase_jit_backing_lost</code> to move <code>reg</code> from <code>jit_pool_head</code> to <code>jit_destroy_head</code>:</p>
<pre><code>void kbase_jit_backing_lost(struct kbase_va_region *reg)
{
    ...
    list_move(&amp;reg-&gt;jit_node, &amp;kctx-&gt;jit_destroy_head);

    schedule_work(&amp;kctx-&gt;jit_work);
}
</code></pre>
<p>The memory region in <code>jit_destroy_head</code> is then picked up by the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.c#3750">kbase_jit_destroy_worker</a></code>, which then frees the <code>kbase_va_region</code> in <code>jit_destroy_head</code> and removes references to the <code>kbase_va_region</code> entirely.</p>
<p>Well not entirely…one small pointer still holds out against the clean up logic. And lifetime management is not easy for the pointers in the fortified camps of the Arm Mali regime.</p>
<p>The clean up logic in <code>kbase_mem_evictable_reclaim_scan_objects</code> is not responsible for removing the reference in <code>jit_alloc</code> from when the JIT memory is allocated, but this is not a problem, because as we’ve seen before, this reference was cleared when <code>kbase_jit_free_finish</code> was called to put the region in the <code>evict_list</code> and, normally, a JIT region is only moved to the <code>evict_list</code> when the user frees it via a <code>BASE_JD_REQ_SOFT_JIT_FREE</code> job, which removes the reference stored in <code>jit_alloc</code>.</p>
<p>But we don’t do normal things here, nor do the people who seek to compromise devices.</p>
<h3 id="the-vulnerability">The vulnerability<a href="#the-vulnerability" aria-label="The vulnerability"></a></h3>
<p>While the semantics of memory eviction is closely tied to JIT memory with most eviction functionality referencing “JIT” (for example, the use of <code>kbase_jit_backing_lost</code> in <code>kbase_mem_evictable_reclaim_objects</code>), evictable memory is more general and other types of GPU memory can also be added to the <code>evict_list</code> and be made evictable. This can be achieved by calling <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#829">kbase_mem_evictable_make</a></code> to add memory regions to the <code>evict_list</code> and <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#855">kbase_mem_evictable_unmake</a></code> to remove memory regions from it. From userspace, these can be called via the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#909">KBASE_IOCTL_MEM_FLAGS_CHANGE</a></code> <code>ioctl</code>. Depending on whether the <code>KBASE_REG_DONT_NEED</code> flag is passed, a memory region can be added or removed from the <code>evict_list</code>:</p>
<pre><code>int kbase_mem_flags_change(struct kbase_context *kctx, u64 gpu_addr, unsigned int flags, unsigned int mask)
{
    ...
    prev_needed = (KBASE_REG_DONT_NEED &amp; reg-&gt;flags) == KBASE_REG_DONT_NEED;
    new_needed = (BASE_MEM_DONT_NEED &amp; flags) == BASE_MEM_DONT_NEED;
    if (prev_needed != new_needed) {
        ...
        if (new_needed) {
            ...
            ret = kbase_mem_evictable_make(reg-&gt;gpu_alloc);  //&lt;------ Add to `evict_list`
            if (ret)
                goto out_unlock;
        } else {
            kbase_mem_evictable_unmake(reg-&gt;gpu_alloc);     //&lt;------- Remove from `evict_list`
        }
    }
</code></pre>
<p>By putting a JIT memory region directly in the <code>evict_list</code> and then creating memory pressure to trigger <code>kbase_mem_evictable_reclaim_scan_objects</code>, the JIT region will be freed with a pointer to it still stored in <code>jit_alloc</code>. After that, a <code>BASE_JD_REQ_SOFT_JIT_FREE</code> job can be submitted to trigger <code>kbase_jit_free_finish</code> to use the freed object pointed to in <code>jit_alloc</code>:</p>
<pre><code>static void kbase_jit_free_finish(struct kbase_jd_atom *katom)
{
    ...
    for (j = 0; j != katom-&gt;nr_extres; ++j) {
        if ((ids[j] != 0) &amp;&amp; (kctx-&gt;jit_alloc[ids[j]] != NULL)) {
            ...
            if (kctx-&gt;jit_alloc[ids[j]] !=
                    KBASE_RESERVED_REG_JIT_ALLOC) {
                ...
                kbase_jit_free(kctx, kctx-&gt;jit_alloc[ids[j]]);  //&lt;----- Use of the now freed jit_alloc[ids[j]]
            }
            kctx-&gt;jit_alloc[ids[j]] = NULL;
        }
    }
</code></pre>
<p>Amongst other things, <code>kbase_jit_free</code> will first free some of the backing pages in the now freed <code>kctx-&gt;jit_alloc[ids[j]]</code>:</p>
<pre><code>void kbase_jit_free(struct kbase_context *kctx, struct kbase_va_region *reg)
{
    ...
    old_pages = kbase_reg_current_backed_size(reg);
    if (reg-&gt;initial_commit &lt; old_pages) {
        ...
        u64 delta = old_pages - new_size;
        if (delta) {
            mutex_lock(&amp;kctx-&gt;reg_lock);
            kbase_mem_shrink(kctx, reg, old_pages - delta);  //&lt;----- Free some pages in the region
            mutex_unlock(&amp;kctx-&gt;reg_lock);
        }
    }
</code></pre>
<p>So by replacing the freed JIT region with a fake object, I can potentially free arbitrary pages, which is a very powerful primitive.</p>
<h2 id="exploiting-the-bug">Exploiting the bug<a href="#exploiting-the-bug" aria-label="Exploiting the bug"></a></h2>
<p>As explained before, this bug is triggered when the kernel is under memory pressure and calls <code>kbase_mem_evictable_reclaim_scan_objects</code> via the shrinker mechanism. From a user process, the required memory pressure can be created as simply as mapping a large amount of memory using the <code>mmap</code> system call. However, the exact amount of memory required to trigger the shrinker scanning is uncertain, meaning that there is no guarantee that a shrinker scan will be triggered after such an allocation. While I can try to allocate an excessive amount of memory to ensure that the shrinker scanning is triggered, doing so risks causing an out-of-memory crash and may also cause the object replacement to be unreliable. This causes problems in triggering and exploiting the bug reliably.</p>
<p>It would be good if I could allocate memory incrementally and check whether the JIT region is freed by <code>kbase_mem_evictable_reclaim_scan_objects</code> after each allocation step and only proceed with the exploit when I’m sure that the bug has been triggered.</p>
<p>The Mali driver provides an <code>ioctl</code>, <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#541">KBASE_IOCTL_MEM_QUERY</a></code> for querying properties of memory regions at a specific GPU address. If the address is invalid, the <code>ioctl</code> will fail and return an error. This allows me to check whether the JIT region is freed, because when <code>kbase_mem_evictable_reclaim_scan_objects</code> is called to free the JIT region, it’ll first remove its GPU mappings, making its GPU address invalid. By using the <code>KBASE_IOCTL_MEM_QUERY</code> <code>ioctl</code> to query the GPU address of the JIT region after each allocation, I can therefore check whether the region has been freed by <code>kbase_mem_evictable_reclaim_scan_objects</code> or not, and only start spraying the heap to replace the JIT region when it is actually freed. Moreover, the <code>KBASE_IOCTL_MEM_QUERY</code> <code>ioctl</code> doesn’t involve memory allocation, so it won’t interfere with the object replacement. This makes it perfect for testing whether the bug has been triggered.</p>
<p>Although shrinker is a kernel mechanism for freeing up evictable memory, the scanning and removal of evictable objects via shrinkers is actually performed by the process that is requesting the memory. So for example, if my process is mapping some memory to its address space (via <code>mmap</code> and then faulting the pages), and the amount of memory that I am mapping creates sufficient memory pressure that a shrinker scan is triggered, then the shrinker scan and the removal of the evictable objects will be done in the context of my process. This, in particular, means that if I pin my process to a CPU while the shrinker scan is triggered, the JIT region that is removed during the scan will be freed on the same CPU. (Strictly speaking, this is not a hundred percent correct, because the JIT region is actually scheduled to be freed on a <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.c#4607">worker</a>, but most of the time, the worker is indeed executed immediately on the same CPU.) This helps me to replace the freed JIT region reliably, because when objects are freed in the kernel, they are placed within a per CPU cache, and subsequent object allocations on the same CPU will first be allocated from the CPU cache. This means that, by allocating another object of similar size on the same CPU, I’m likely to be able to replace the freed JIT region. Moreover, the JIT region, which is a <code>kbase_va_region</code>, is actually a rather large object that is allocated in the <code>kmalloc-256</code> cache, (which is used to allocate objects of size between <code>256-512</code> bytes when <code>kmalloc</code> is called) instead of the <code>kmalloc-128</code> cache, (which allocates objects of size less than <code>128</code> bytes), and the <code>kmalloc-256</code> cache is a less used cache. This, together with the relative certainty of the CPU that frees the JIT region, allows me to reliably replace the JIT region after it is freed.</p>
<h3 id="replacing-the-freed-object">Replacing the freed object<a href="#replacing-the-freed-object" aria-label="Replacing the freed object"></a></h3>
<p>Now that I can reliably replace the freed JIT region, I can look at how to exploit the bug. As explained before, the freed JIT memory can be used as the <code>reg</code> argument in the <code>kbase_jit_free</code> function to potentially be used for freeing arbitrary pages:</p>
<pre><code>void kbase_jit_free(struct kbase_context *kctx, struct kbase_va_region *reg)
{
    ...
    old_pages = kbase_reg_current_backed_size(reg);
    if (reg-&gt;initial_commit &lt; old_pages) {
        ...
        u64 delta = old_pages - new_size;
        if (delta) {
            mutex_lock(&amp;kctx-&gt;reg_lock);
            kbase_mem_shrink(kctx, reg, old_pages - delta);  //&lt;----- Free some pages in the region
            mutex_unlock(&amp;kctx-&gt;reg_lock);
        }
    }
</code></pre>
<p>One possibility is to use the well-known <a href="https://blog.lexfo.fr/cve-2017-11176-linux-kernel-exploitation-part3.html">heap spraying technique</a> to replace the freed JIT region with arbitrary data using <code>sendmsg</code>. This would enable me to create a fake <code>kbase_va_region</code> with a fake <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.h#529">gpu_alloc</a></code> and fake <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem.h#138">pages</a></code> that could be used to free arbitrary pages in <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#2334">kbase_mem_shrink</a></code>:</p>
<pre><code>int kbase_mem_shrink(struct kbase_context *const kctx,
        struct kbase_va_region *const reg, u64 new_pages)
{
    ...
    err = kbase_mem_shrink_gpu_mapping(kctx, reg,
            new_pages, old_pages);
    if (err &gt;= 0) {
        /* Update all CPU mapping(s) */
        kbase_mem_shrink_cpu_mapping(kctx, reg,
                new_pages, old_pages);
        kbase_free_phy_pages_helper(reg-&gt;cpu_alloc, delta);   //&lt;------- free pages in cpu_alloc
        if (reg-&gt;cpu_alloc != reg-&gt;gpu_alloc)
            kbase_free_phy_pages_helper(reg-&gt;gpu_alloc, delta);   //&lt;--- free pages in gpu_alloc
</code></pre>
<p>In order to do so, I’d need to know the addresses of some data that I can control, so I could create a fake <code>gpu_alloc</code> and its <code>pages</code> field at those addresses. This could be done either by finding a way to leak addresses of kernel objects, or use techniques like the one I wrote about in the Section “<a href="https://github.blog/2022-06-16-the-android-kernel-mitigations-obstacle-race/#the-ultimate-fake-object-store">The Ultimate fake object store</a>” in my other post.</p>
<p>But why use a fake object when you can use a real one?</p>
<p>The JIT region that is involved in the use-after-free bug here is a <code>kbase_va_region</code>, which is a complex object that has multiple states. Many operations can only be performed on memory objects with a correct state. In particular, <code>kbase_mem_shrink</code> can  only be used on a <code>kbase_va_region</code> that has not been mapped multiple times.</p>
<p>The Mali driver provides the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#1765">KBASE_IOCTL_MEM_ALIAS</a></code> <code>ioctl</code> that allows multiple memory regions to share the same backing pages. I’ve written about how <code>KBASE_IOCTL_MEM_ALIAS</code> works in more details in <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#memory-alias">my previous post</a>, but for the purpose of this exploit, the crucial point is that <code>KBASE_IOCTL_MEM_ALIAS</code> can be used to create memory regions in the GPU and user address spaces that are aliased to a <code>kbase_va_region</code>, meaning that they are backed by the same physical pages. If a <code>kbase_va_region</code> <code>reg</code> is mapped multiple times by using <code>KBASE_IOCTL_MEM_ALIAS</code> and then has its backing pages freed by <code>kbase_mem_shrink</code>, then only the memory mappings in <code>reg</code> are removed, so the alias regions created by <code>KBASE_IOCTL_MEM_ALIAS</code> can still be used to access the freed backing pages.</p>
<p>To prevent <code>kbase_mem_shrink</code> from being called on aliased JIT memory, <code>kbase_mem_alias</code> checks for the <code>KBASE_REG_NO_USER_FREE</code>, so that JIT memory cannot be aliased:</p>
<pre><code>u64 kbase_mem_alias(struct kbase_context *kctx, u64 *flags, u64 stride,
            u64 nents, struct base_mem_aliasing_info *ai,
            u64 *num_pages)
{
    ...
    for (i = 0; i &lt; nents; i++) {
        if (ai[i].handle.basep.handle &lt; BASE_MEM_FIRST_FREE_ADDRESS) {
            if (ai[i].handle.basep.handle !=
                BASEP_MEM_WRITE_ALLOC_PAGES_HANDLE)
            ...
        } else {
            ...
            if (aliasing_reg-&gt;flags &amp; KBASE_REG_NO_USER_FREE)  //&lt;-- 2.
                goto bad_handle; /* JIT regions can&#39;t be
                          * aliased. NO_USER_FREE flag
                          * covers the entire lifetime
                          * of JIT regions. The other
                          * types of regions covered
                          * by this flag also shall
                          * not be aliased.            
            ...
        }
</code></pre>
<p>Now suppose I trigger the bug and replace the freed JIT region with a normal memory region allocated via the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-raviole-5.10-android13/mali_kbase/mali_kbase_mem_linux.c#292">KBASE_IOCTL_MEM_ALLOC</a></code> <code>ioctl</code>, which is an object of the exact same type, but without the <code>KBASE_REG_NO_USER_FREE</code> flag that is associated with a JIT region. I then use <code>KBASE_IOCTL_MEM_ALIAS</code> to create an extra mapping for the backing store of this new region. All these are valid as I’m just aliasing a normal memory region that does not have the <code>KBASE_REG_NO_USER_FREE</code> flag. However, because of the bug, a dangling pointer in <code>jit_alloc</code> also points to this new region, which has now been aliased.</p>
<p>If I now submit a <code>BASE_JD_REQ_SOFT_JIT_FREE</code> job to call <code>kbase_jit_free</code> on this memory, then <code>kbase_mem_shrink</code> will be called, and part of the backing store in this new region will be freed, but the extra mappings created in the aliased region will not be removed, meaning that I can still access the freed backing pages from the alias region. By using a real object of the same type, not only do I save the effort needed to craft a fake object, but it also reduces the risk of having side effects that could result in a crash.</p>
<p>The situation is now very similar to what I had in <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/">my previous post</a> and the exploit flow from this point on is also very similar. For completeness, I’ll give an overview of how the exploit works here, but readers who are interested can take a look at more details from the Section “<a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">Breaking out of the context</a>” onwards in that post.</p>
<p>To recap, I now have access to the backing pages in a <code>kbase_va_region</code> object that is already freed and I’d like to reuse these freed backing pages so I can gain read and write access to arbitrary memory. To understand how this can be done, we need to know how backing pages to a <code>kbase_va_region</code> are allocated.</p>
<p>When allocating pages for the backing store of a <code>kbase_va_region</code>, the <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_mem_pool.c#529">kbase_mem_pool_alloc_pages</a></code> function is used:</p>
<pre><code>int kbase_mem_pool_alloc_pages(struct kbase_mem_pool *pool, size_t nr_4k_pages,
        struct tagged_addr *pages, bool partial_allowed)
{
    ...
    /* Get pages from this pool */
    while (nr_from_pool--) {
        p = kbase_mem_pool_remove_locked(pool);     //&lt;------- 1.
        ...
    }
    ...
    if (i != nr_4k_pages &amp;&amp; pool-&gt;next_pool) {
        /* Allocate via next pool */
        err = kbase_mem_pool_alloc_pages(pool-&gt;next_pool,      //&lt;----- 2.
                nr_4k_pages - i, pages + i, partial_allowed);
        ...
    } else {
        /* Get any remaining pages from kernel */
        while (i != nr_4k_pages) {
            p = kbase_mem_alloc_page(pool);     //&lt;------- 3.
            ...
        }
        ...
    }
    ...
}
</code></pre>
<p>The input argument <code>kbase_mem_pool</code> is a memory pool managed by the <code>kbase_context</code> object associated with the driver file that is used to allocate the GPU memory. As the comments suggest, the allocation is actually done in tiers. First the pages are allocated from the current <code>kbase_mem_pool</code> using <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_mem_pool.c#96">kbase_mem_pool_remove_locked</a></code> (1 in the above). If there is not enough capacity in the current <code>kbase_mem_pool</code> to meet the request, then <code>pool-&gt;next_pool</code>, is used to allocate the pages (2 in the above). If even <code>pool-&gt;next_pool</code> does not have the capacity, then <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_mem_pool.c#153">kbase_mem_alloc_page</a></code> is used to allocate pages directly from the kernel via the buddy allocator (the page allocator in the kernel).</p>
<p>When freeing a page, the opposite happens: <code><a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/tags/android-12.0.0_r0.42/mali_kbase/mali_kbase_mem_pool.c#738">kbase_mem_pool_free_pages</a></code> first tries to return the pages to the <code>kbase_mem_pool</code> of the current <code>kbase_context</code>, if the memory pool is full, it’ll try to return the remaining pages to <code>pool-&gt;next_pool</code>. If the next pool is also full, then the remaining pages are returned to the kernel by freeing them via the buddy allocator.</p>
<p>As noted in <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">my previous post</a>, <code>pool-&gt;next_pool</code> is a memory pool managed by the Mali driver and shared by all the <code>kbase_context</code>. It is also used for allocating <a href="https://www.kernel.org/doc/gorman/html/understand/understand006.html">page table global directories (PGD)</a> used by GPU contexts. In particular, this means that by carefully arranging the memory pools, it is possible to cause a freed backing page in a <code>kbase_va_region</code> to be reused as a PGD of a GPU context. (The details of how to achieve this can be found in <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">my previous post</a>.) As the bottom level PGD stores the physical addresses of the backing pages to GPU virtual memory addresses, being able to write to PGD will allow me to map arbitrary physical pages to the GPU memory, which I can then read from and write to by issuing GPU commands. This gives me access to arbitrary physical memory. As physical addresses for kernel code and static data are not randomized and depend only on the kernel image, I can use this primitive to overwrite arbitrary kernel code and gain arbitrary kernel code execution.</p>
<p>In the following figure, the green block indicates the same page being reused as the PGD.</p>

<p>To summarize, the exploit involves the following steps:</p>
<ol>
<li>Create JIT memory.</li>
<li>Mark the JIT memory as evictable.</li>
<li>Increase memory pressure by mapping memory to the user space via normal <code>mmap</code> system calls.</li>
<li>Use the <code>KBASE_IOCTL_MEM_QUERY</code> <code>ioctl</code> to check if the JIT memory is freed. Carry on applying memory pressure until the JIT region is freed.</li>
<li>Allocate new GPU memory regions using the <code>KBASE_IOCTL_MEM_ALLOC</code> <code>ioctl</code> to replace the freed JIT memory.</li>
<li>Create an alias region to the new GPU memory region that replaced the JIT memory so that the backing pages of the new GPU memory are shared with the alias region.</li>
<li>Submit a <code>BASE_JD_REQ_SOFT_JIT_FREE</code> job to free the JIT region. As the JIT region is now replaced by the new memory region, this will cause <code>kbase_jit_free</code> to remove the backing pages of the new memory region, but the GPU mappings created in the alias region in step 6. will not be removed. The alias region can now be used to access the freed backing pages.</li>
<li>Reuse the freed backing pages as PGD of the <code>kbase_context</code>. The alias region can now be used to rewrite the PGD. I can then map arbitrary physical pages to the GPU address space.</li>
<li>Map kernel code to the GPU address space to gain arbitrary kernel code execution, which can then be used to rewrite the credentials of our process to gain root, and to disable SELinux.</li>
</ol>
<p>The exploit for Pixel 6 can be found <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/Android/Mali/CVE_2022_38181">here</a> with some setup notes.</p>
<h2 id="disclosure-and-patch-gapping">Disclosure and patch gapping<a href="#disclosure-and-patch-gapping" aria-label="Disclosure and patch gapping"></a></h2>
<p>At the start of the post, I mentioned that I initially reported this bug to the Android Security team, but it was later dismissed as a “Won’t fix” bug. While it is unclear to me why such a decision was made, it is perhaps worth taking a look at the wider picture instead of treating this as an isolated incident.</p>
<p>There has been a long history of N-day vulnerabilities being exploited in the Android kernel, many of which were fixed in the upstream kernel but didn’t get ported to Android. Perhaps the most infamous of these was <a href="https://googleprojectzero.blogspot.com/2019/11/bad-binder-android-in-wild-exploit.html">CVE-2019-2215 (Bad Binder)</a>, which was initially discovered by the <a href="https://groups.google.com/forum/#!msg/syzkaller-bugs/QyXdgUhAF50/g-FXVo1OAwAJ">syzkaller fuzzer</a> in November 2017 and patched in February 2018. However, this fix was never included in an Android monthly security bulletin until it was rediscovered as an exploited in-the-wild bug in September 2019. Another exploited in-the-wild bug, <a href="https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2021/CVE-2021-1048.html">CVE-2021-1048</a>, was introduced in the upstream kernel in December 2020, and was fixed upstream a few weeks later. The patch, however, was not included in the Android Security Bulletin until November 2021, when it was discovered to be exploited in-the-wild. Yet another exploited in-the-wild vulnerability, <a href="https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2021/CVE-2021-0920.html">CVE-2021-0920</a>, was found in 2016 with details visible in a Linux kernel email <a href="https://patchwork.ozlabs.org/project/netdev/patch/CAOssrKcfncAYsQWkfLGFgoOxAQJVT2hYVWdBA6Cw7hhO8RJ_wQ@mail.gmail.com/">thread</a>. The report, however, was dismissed by kernel developers at the time, until it was rediscovered to be exploited in-the-wild and patched in November 2021.</p>
<p>To be fair, these cases were patched or ignored upstream without being identified as security issues (for example, CVE-2021-0920 was ignored), making it difficult for any vendor to identify such issues before it’s too late.</p>
<p>This again shows the importance of properly addressing security issues and recording them by assigning a CVE-ID, so that downstream users can apply the relevant security patches. Unfortunately, vendors sometimes see having security vulnerabilities in their products as a damage to their reputation and try to silently patch or downplay security issues instead. The above examples show just how serious the consequences of such a mentality can be.</p>
<p>While Android has made improvements to keep the kernel branches more unified and up-to-date to avoid problems such as CVE-2019-2215, where the vulnerability was patched in some branches but not others, some recent disclosures highlight a rather worrying trend.</p>
<p>On March 7th, 2022, <a href="https://dirtypipe.cm4all.com/">CVE-2022-0847 (Dirty pipe)</a> was disclosed publicly, with full details and a proof-of-concept exploit to overwrite read-only files. While the bug was patched upstream on February 23rd, 2022, with the patch merged into the Android kernel on <a href="https://android-review.googlesource.com/c/kernel/common/+/1998671">February, 24th, 2022</a>, the patch was not included in the Android Security Bulletin until May 2022 and the public proof-of-concept exploit still ran successfully on a Pixel 6 with the April patch. While this may look like another incident where a security bug was patched silently upstream, this case was very different. According to the disclosure timeline, the bug report was shared with the Android Security Team on February 21st, 2022, a day after it was reported to the Linux kernel.</p>
<p>Another vulnerability, <a href="https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2021/CVE-2021-39793.html">CVE-2021-39793</a> in the Mali driver, was patched by Arm in version r36p0 of the driver (as <a href="https://developer.arm.com/Arm%20Security%20Center/Mali%20GPU%20Driver%20Vulnerabilities">CVE-2022-22706</a>), which was released on <a href="https://developer.arm.com/downloads/-/mali-drivers/valhall-kernel">February 11th, 2022</a>. The patch was only included in the Android Security Bulletin in March as an exploited in-the-wild bug.</p>
<p>Yet another vulnerability, <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/">CVE-2022-20186</a> that I reported to the Android Security Team on January 15th, 2022, was patched by Arm in version r37p0 of the Mali driver, which was released on April 21st, 2022. The patch was only included in the Android Security Bulletin in June and a Pixel 6 running the May patch was still affected.</p>
<p>Taking a look at security issues reported by Google’s Project Zero team, between June and July 2022, Jann Horn of Project Zero reported five security issues (<a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2325">2325</a>, <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2327">2327</a>, <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2331">2331</a>, <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2333">2333</a>, <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2334">2334</a>) in the Arm Mali GPU that affected the Pixel phones. These issues were promptly fixed as <a href="https://developer.arm.com/Arm%20Security%20Center/Mali%20GPU%20Driver%20Vulnerabilities">CVE-2022-33917</a> and <a href="https://developer.arm.com/Arm%20Security%20Center/Mali%20GPU%20Driver%20Vulnerabilities">CVE-2022-36449</a> by the Arm security team on July 25th, 2022 (CVE-2022-33917 in<a href="https://developer.arm.com/downloads/-/mali-drivers/valhall-kernel"> r39p0</a>) and on August 18th, 2022 (CVE-2022-36449 in <a href="https://developer.arm.com/downloads/-/mali-drivers/valhall-kernel">r38p1</a>). The details of these bugs, including proof of concepts, were disclosed on September 18th, 2022. However, at least some of the issues remained unfixed in December 2022, (for example, issue <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2327">2327</a> was only fixed silently in the January 2023 patch, without mentioning the CVE ID) after Project zero published a <a href="https://googleprojectzero.blogspot.com/2022/11/mind-the-gap.html">blog post</a> highlighting the patching problem with these particular issues on November 22nd, 2022.</p>
<p>In all of these instances, the bugs were only patched in Android a couple months after a patch was publicly released upstream. In light of this, the response to this current bug is perhaps not too surprising.</p>
<p>The year is 2023 A.D., and it’s still easy to pwn Android with N-days entirely. Well, yes, entirely.</p>

<h3 id="notes">Notes<a href="#notes" aria-label="Notes"></a></h3>


      
  </main>


  </div>
</div></div>
  </body>
</html>
