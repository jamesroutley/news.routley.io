<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.tweag.io/blog/2023-04-20-medical-computing-at-scale/">Original</a>
    <h1>Processing medical images at scale on the cloud</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Artificial Intelligence (AI). Machine Learning (ML). Deep Learning. Neural Networks (NNs). Large Language Models (LLMs)…
The list of hyped buzzwords goes on and on, even more so since ChatGPT made a wider audience realize what is now achievable.
As scary or awe-inspiring as it is, one can’t deny the great impact AI can have when applied to fields with positive social value, such as healthcare.</p>
<p>The MedTech industry is buzzing thanks to a continuous stream of innovation, promising to be more precise, efficient and accessible than ever.
In particular oncology, a branch of medicine that focuses on cancer, could benefit immensely from these new technologies, which may enable clinicians to detect cancer earlier and increase chances of survival.
Detecting cancerous cells in microscopic photography of cells (Whole Slide Images, aka WSIs) is usually done with segmentation algorithms, which NNs are very good at.
While using ML and NNs for image segmentation is a fairly standard task with established solutions, doing it on WSIs is a different kettle of fish.
Most training pipelines and systems are designed to handle fairly small, sub-megapixel images.
In the case of WSIs, the image is so huge that a single file is at least a few hundred megabytes and can be dozens of gigabytes.
To allow innovation in medical imaging with AI, we need efficient and affordable ways to store and process these WSIs at scale.</p>
<p>In this blog post, I will explain the underlying technical challenges and share the solution that we helped implement at <a href="https://kaiko.ai">kaiko.ai</a>, a MedTech startup in Amsterdam that is building a Data Platform to support AI research in hospitals.</p>

<p>Whole Slide Images (WSIs) are ubiquitous in digital pathology.
These files store microscopic photography images of a slide, a piece of glass with cells on it.</p>
<p><span>
      <a href="https://www.tweag.io/static/8869191a464ec7cb0048196f1f2a5d5b/5a190/wsi.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="WSI" title="WSI" src="https://www.tweag.io/static/8869191a464ec7cb0048196f1f2a5d5b/fcda8/wsi.png" srcset="/static/8869191a464ec7cb0048196f1f2a5d5b/12f09/wsi.png 148w,
/static/8869191a464ec7cb0048196f1f2a5d5b/e4a3f/wsi.png 295w,
/static/8869191a464ec7cb0048196f1f2a5d5b/fcda8/wsi.png 590w,
/static/8869191a464ec7cb0048196f1f2a5d5b/5a190/wsi.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p><em>OpenSlide <a href="https://openslide.cs.cmu.edu/download/openslide-testdata/Generic-TIFF/">test data: <code>CMU-1.tiff</code></a></em></p>
<p>Since the capture is done through a microscope, an image of a few centimeters becomes millions of pixel long.
The ratio from pixels to real distance is called <em>micrometer per pixel</em> (aka MPP).
The lower the MPP, the more the image is zoomed in.</p>
<p>An image of a slide with a low MPP is very large thus slow to read, which is not fit for every use case.
For example, someone might just need to visually confirm the quality of the overall image at a higher MPP.
To allow using an MPP that fits any usage, multiple images at higher MPP are stored as well, like a pyramid.</p>
<p><span>
      <a href="https://www.tweag.io/static/1ba543729f2c1975659845e2ee7ad2b7/6e9ba/wsi-pyramid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="WSI pyramid" title="WSI pyramid" src="https://www.tweag.io/static/1ba543729f2c1975659845e2ee7ad2b7/fcda8/wsi-pyramid.png" srcset="/static/1ba543729f2c1975659845e2ee7ad2b7/12f09/wsi-pyramid.png 148w,
/static/1ba543729f2c1975659845e2ee7ad2b7/e4a3f/wsi-pyramid.png 295w,
/static/1ba543729f2c1975659845e2ee7ad2b7/fcda8/wsi-pyramid.png 590w,
/static/1ba543729f2c1975659845e2ee7ad2b7/6e9ba/wsi-pyramid.png 731w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p><em>A pyramid of images, from <a href="https://www.researchgate.net/publication/353769558_Multi_Scale_Tools_A_Python_Library_to_Exploit_Multi-Scale_Whole_Slide_Images">“Multi_Scale_Tools: A Python Library to Exploit Multi-Scale Whole Slide Images”, N. Marini et al</a></em></p>
<p>This results in a very large amount of data for a single slide, often a few gigabytes per slide, which is all stored in one big file.
A single hospital makes many captures a day, producing terabytes of such data to store and process.</p>
<p>To store this data, hospitals are often equipped with on-premises infrastructure, more or less provided by the same manufacturer of the capture devices.
These decades-old systems were tailored to support doctors in their traditional tasks, like displaying a WSI for manual analysis.
But the rise of Machine Learning in research has driven a need for new systems that are more performant and more flexible.</p>
<p>Thankfully, cloud-based infrastructure is now an established solution which can help do this in a cost-effective way.
As a simple solution, files can be stored on cloud storage services, such as Azure Blob Storage or AWS S3, which can scale more easily than on-premises infrastructure.
However, it is a big shift in architecture that leads to numerous technical challenges.</p>

<p>The first basic challenge is to actually read the image.
Whether displaying it on a screen or feeding it to a neural network, it is fundamental to have a tool to turn the stored bytes into a meaningful representation.
Fortunately, there is <a href="https://openslide.org/">OpenSlide</a>, the most widely used open-source library to read WSI files… or so we’d like.
But as it turns out, we can’t use it.</p>
<p>Although it has Python bindings, OpenSlide is implemented in C and reads files using standard OS file handlers, however our data sits on cloud storage that is accessible via HTTP.
This means that, to open a WSI file, one needs to first download the entire file to disk, and only then can they load it with OpenSlide.
But then, what if we need to read tens of thousands of WSIs, a few gigabytes each?
This can total more than what a single disk can contain.
Besides, even if we mounted multiple disks, the cost and time it would take to transfer all this data on every new machine would be too much.
In addition to that, most of the time only a fraction of the entire WSI is of interest, so downloading the entire data is inefficient.</p>
<p>A solution is to read the bytes that we need when we need them directly from Blob Storage.
<a href="https://github.com/fsspec/filesystem_spec"><code>fsspec</code></a> is a Python package that allows us to define “abstract” filesystems, with a custom implementation to list, read and write files.
One such implementation, <a href="https://github.com/fsspec/adlfs"><code>adlfs</code></a>, works for Azure Blob Storage.</p>
<p>Thanks to these libraries, we can keep the data on cloud storage and still read it partially.</p>
<div data-language="python"><pre><code><span>from</span> adlfs <span>import</span> AzureBlobFileSystem


fs <span>=</span> AzureBlobFileSystem<span>(</span>anon<span>=</span><span>False</span><span>,</span> account_name<span>=</span><span>&#34;my_account&#34;</span><span>)</span>

<span>with</span> fs<span>.</span><span>open</span><span>(</span><span>&#34;container/file.svs&#34;</span><span>)</span> <span>as</span> f<span>:</span>
  
  <span>print</span><span>(</span>f<span>.</span>read<span>(</span><span>256</span><span>)</span><span>)</span></code></pre></div>
<p>Written on top of <code>fsspec</code>, <a href="https://github.com/bayer-science-for-a-better-life/tiffslide"><code>tiffslide</code></a> is another Python package that is supposed to be a drop-in replacement of <code>openslide-python</code>, the Python bindings of OpenSlide.
Since it uses <code>fsspec</code> behind the scenes, it can be used to directly read the WSIs that are stored on Azure Blob Storage without copying them first to disk.
From our experience, the performance is somewhat acceptable for our machine learning use cases, thanks to the fast connection in cloud computing data centers.</p>
<p>Another option would be to use <a href="https://github.com/Azure/azure-storage-fuse">blobfuse</a>, which uses FUSE to make it seem like the Azure Blob Storage container is mounted just like any disk.
Unfortunately, we have found this solution to be quite limited, as it needs to download the entire file locally which gives a huge overhead.
There is a <a href="https://github.com/Azure/azure-storage-fuse/blob/main/STREAMING.md">“streaming” mode</a> which is supposed to directly read byte ranges from Blob Storage, but we did not investigate further because <code>blobfuse</code> only works on Linux, while our users needed it to run on MacOS.<sup id="fnref-1"><a href="#fn-1">1</a></sup></p>

<p>The most common way to train NNs is using Stochastic Gradient Descent (or similar).
This means we randomly loop over samples and use backpropagation to “train” the model.
In this loop, one would usually want to iterate on batches of samples.
So at every step, instead of computing the gradient on a single sample, it is computed on multiple samples.<sup id="fnref-2"><a href="#fn-2">2</a></sup>
This supposedly makes the gradient descent more stable and epochs faster.
Usually, the batch size ranges from tens to hundreds of samples.</p>
<p>As stated earlier, WSIs are quite large, which means that it would be hard to stack so many of them in RAM, let alone on the GPU.
We are not interested in the entire image either.
In oncology, WSIs are cut down to smaller images call <em>patches</em>, which are of a more reasonable size.
To generate a patch, one needs to read a region of the image, for instance using <a href="https://openslide.org/api/python/#openslide.OpenSlide.read_region"><code>openslide.OpenSlide.read_region</code></a> or <code>tiffslide</code>’s equivalent.</p>
<p>We can either generate all patch images and store them, or we can patch <em>“on-the-fly”</em>.
From our discussions with researchers, precomputing patches usually takes a lot of time and is quite inflexible.
In fact, one could look at parameters such as the patch size as a hyper-parameter to the model which should be tuned.
Since it takes a lot of time to generate all the patches of all WSIs, this creates a very long feedback loop.
This also multiplies the storage cost, as the weight of all patch images is roughly the same as the WSIs.
For these reasons, we tried to implement patching “on-the-fly”, or <em>online patching</em>.</p>
<p>The minimalistic script below shows how we can do online patching to train a PyTorch model.</p>
<div data-language="python"><pre><code><span>import</span> pytorch_lightning <span>as</span> pl

<span>from</span> pydantic<span>.</span>dataclasses <span>import</span> dataclass
<span>from</span> tiffslide <span>import</span> TiffSlide
<span>from</span> torch<span>.</span>utils<span>.</span>data <span>import</span> DataLoader


<span>@dataclass</span><span>(</span>frozen<span>=</span><span>True</span><span>)</span>
<span>class</span> <span>PatchSpec</span><span>:</span>
    level<span>:</span> <span>int</span>
    x<span>:</span> <span>int</span>
    y<span>:</span> <span>int</span>
    width<span>:</span> <span>int</span>
    height<span>:</span> <span>int</span>


<span>class</span> <span>PatchDataset</span><span>(</span>data<span>.</span>IterableDataset<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> slides_specs<span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>list</span><span>[</span>PatchSpec<span>]</span><span>]</span><span>)</span><span>:</span>
          self<span>.</span>_slides_specs <span>=</span> slides_specs

    <span>def</span> <span>__iter__</span><span>(</span>self<span>)</span><span>:</span>
        <span>for</span> file_uri<span>,</span> specs <span>in</span> self<span>.</span>_slides_specs<span>.</span>items<span>(</span><span>)</span><span>:</span>
            <span>with</span> fsspec<span>.</span><span>open</span><span>(</span>file_uri<span>)</span> <span>as</span> f<span>:</span>
              slide <span>=</span> TiffSlide<span>(</span>f<span>)</span>
            <span>for</span> spec <span>in</span> specs<span>:</span>
                <span>yield</span> slide<span>.</span>read_region<span>(</span>
                    location<span>=</span><span>(</span>spec<span>.</span>x<span>,</span> spec<span>.</span>y<span>)</span><span>,</span>
                    level<span>=</span>spec<span>.</span>level<span>,</span>
                    size<span>=</span><span>(</span>spec<span>.</span>width<span>,</span> spec<span>.</span>height<span>)</span><span>,</span>
                <span>)</span>


<span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span><span>:</span>
  model<span>:</span> pl<span>.</span>LightningModule <span>=</span> <span>.</span><span>.</span><span>.</span>  
  slides_specs<span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>list</span><span>[</span>PatchSpec<span>]</span><span>]</span> <span>=</span> <span>.</span><span>.</span><span>.</span>  
  dataset <span>=</span> PatchDataset<span>(</span>slides_specs<span>=</span>slides_specs<span>)</span>
  train_loader <span>=</span> DataLoader<span>(</span>dataset<span>)</span>
  trainer <span>=</span> pl<span>.</span>Trainer<span>(</span>limit_train_batches<span>=</span><span>100</span><span>,</span> max_epochs<span>=</span><span>1</span><span>)</span>
  trainer<span>.</span>fit<span>(</span>model<span>=</span>model<span>,</span> train_dataloaders<span>=</span>train_loader<span>)</span>
  <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Unfortunately, we found that loading each patch individually into batches like this is slower than the time it takes to run a training iteration step.</p>
<p>What happens is:</p>
<ul>
<li>a batch of patches is generated and fed to the training loop;</li>
<li>while it does a training step (inference + backprop + weight update), it generates the next batch of patches;</li>
<li>unfortunately, the training step is finished before it has generated the next batch of patches, so the GPU is idle for a while.</li>
</ul>
<p>This leads to low usage of the GPU and slower training, which is not ideal.</p>
<p>Ideally, we would meet the following constraint:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow></msub><mo>&gt;</mo><msub><mi>n</mi><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mi>t</mi><mrow><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{train\_step} &gt; n_{batch\_size} \times t_{load\_patch}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>t</span><span>r</span><span>ain</span><span>_</span><span>s</span><span>t</span><span>e</span><span>p</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>&gt;</span><span></span></span><span><span></span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>ba</span><span>t</span><span>c</span><span>h</span><span>_</span><span>s</span><span>i</span><span>ze</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>×</span><span></span></span><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>l</span><span>o</span><span>a</span><span>d</span><span>_</span><span>p</span><span>a</span><span>t</span><span>c</span><span>h</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></p>
<p>Where:</p>
<ul>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{train\_step}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>t</span><span>r</span><span>ain</span><span>_</span><span>s</span><span>t</span><span>e</span><span>p</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> is the average time the GPU takes to run a training step;</li>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{batch\_size}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>ba</span><span>t</span><span>c</span><span>h</span><span>_</span><span>s</span><span>i</span><span>ze</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> is the batch size;</li>
<li><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{load\_patch}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>l</span><span>o</span><span>a</span><span>d</span><span>_</span><span>p</span><span>a</span><span>t</span><span>c</span><span>h</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> is the average time it takes to load a single patch.</li>
</ul>
<p>We don’t really want to change the batch size, and we can hardly improve <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{train\_step}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>t</span><span>r</span><span>ain</span><span>_</span><span>s</span><span>t</span><span>e</span><span>p</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span>.
So in order to speed up the training and reach 100% GPU utilization, we need to generate patches faster.</p>
<p>… or we can change the equation!</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow></msub><mo>&gt;</mo><mfrac><mrow><msub><mi>n</mi><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mi>t</mi><mrow><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow><msub><mi>n</mi><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>l</mi></mrow></msub></mfrac></mrow><annotation encoding="application/x-tex">t_{train\_step} &gt; \frac{n_{batch\_size} \times t_{load\_patch}}{n_{parallel}}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>t</span><span>r</span><span>ain</span><span>_</span><span>s</span><span>t</span><span>e</span><span>p</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>&gt;</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>p</span><span>a</span><span>r</span><span>a</span><span>ll</span><span>e</span><span>l</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>ba</span><span>t</span><span>c</span><span>h</span><span>_</span><span>s</span><span>i</span><span>ze</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>×</span><span><span>t</span><span><span><span><span><span><span></span><span><span><span>l</span><span>o</span><span>a</span><span>d</span><span>_</span><span>p</span><span>a</span><span>t</span><span>c</span><span>h</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span><sup id="fnref-3"><a href="#fn-3">3</a></sup></p>
<p>Where <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{parallel}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>p</span><span>a</span><span>r</span><span>a</span><span>ll</span><span>e</span><span>l</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> is the number of parallel steps in the data loading.</p>
<p>We can easily increase parallelism thanks to <code>torch.utils.data.DataLoader</code>’s <code>num_workers</code> parameter: setting it to a value above 1 makes it load batch items in parallel.
This requires some changes to the above implementation of <code>PatchDataset</code>, but nothing too fancy.</p>
<p>Unfortunately, we witnessed that the amount of parallelism required to meet the constraint was way above the number of CPU cores on the machines.
Threads would quickly clutter and the throughput was limited.</p>
<p>But you know what they say: if one machine is not enough, use more machines!</p>

<p>Fortunately, we can scale horizontally by distributing over multiple machines.
This is where <a href="https://www.ray.io/">Ray</a> comes into play.</p>
<p>Ray is “an open-source unified compute framework that makes it easy to scale AI and Python workloads”.<sup id="fnref-4"><a href="#fn-4">4</a></sup>
One of Ray’s selling points is how simple it is to go from a local environment, to develop and debug, to a production environment at scale.
Much like Spark, its module <code>ray.data</code> is focused on loading and processing data as scale.</p>
<p>With Ray, we could use the following architecture.</p>
<p><span>
      <a href="https://www.tweag.io/static/6b5ec6294b214ecead018a908f79359b/37e0d/distributed-processing.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Distributed patching of WSI in the cloud" title="Distributed patching of WSI in the cloud" src="https://www.tweag.io/static/6b5ec6294b214ecead018a908f79359b/37e0d/distributed-processing.png" srcset="/static/6b5ec6294b214ecead018a908f79359b/12f09/distributed-processing.png 148w,
/static/6b5ec6294b214ecead018a908f79359b/e4a3f/distributed-processing.png 295w,
/static/6b5ec6294b214ecead018a908f79359b/37e0d/distributed-processing.png 482w" sizes="(max-width: 482px) 100vw, 482px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>A researcher is working on their laptop, which connects to a VM in a cloud cluster.
This VM is the one on which the training loop happens, so it has a beefy GPU,
and it can connect to other VMs in the cluster to distribute the workload on patching.</p>
<p>This allows us to increase <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{parallel}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>n</span><span><span><span><span><span><span></span><span><span><span>p</span><span>a</span><span>r</span><span>a</span><span>ll</span><span>e</span><span>l</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> as much as we want, if we want to optimize for utilization, until it meets the constraints.</p>
<p>Below, we demonstrate a simplified way of using Ray to distribute the WSI processing to feed the training loop.</p>
<div data-language="python"><pre><code><span>import</span> pandas <span>as</span> pd
<span>import</span> PIL<span>.</span>Image
<span>import</span> ray<span>.</span>data
<span>import</span> torch<span>.</span>utils<span>.</span>data

<span>.</span><span>.</span><span>.</span>


<span>def</span> <span>read_patch</span><span>(</span>record<span>)</span> <span>-</span><span>&gt;</span> PIL<span>.</span>Image<span>.</span>Image<span>:</span>
    file_uri<span>:</span> <span>str</span> <span>=</span> record<span>[</span><span>&#34;file_uri&#34;</span><span>]</span>
    spec<span>:</span> PatchSpec <span>=</span> record<span>[</span><span>&#34;spec&#34;</span><span>]</span>
    <span>with</span> fsspec<span>.</span><span>open</span><span>(</span>file_uri<span>)</span> <span>as</span> f<span>:</span>
        slide <span>=</span> TiffSlide<span>(</span>f<span>)</span>
        <span>return</span> <span>{</span>
            <span>&#34;patch&#34;</span><span>:</span> slide<span>.</span>read_region<span>(</span>
              location<span>=</span><span>(</span>spec<span>.</span>x<span>,</span> spec<span>.</span>y<span>)</span><span>,</span>
              level<span>=</span>spec<span>.</span>level<span>,</span>
              size<span>=</span><span>(</span>spec<span>.</span>width<span>,</span> spec<span>.</span>height<span>)</span><span>,</span>
            <span>)</span><span>,</span>
        <span>}</span>


<span>def</span> <span>get_data_loader</span><span>(</span>
    slides_specs<span>:</span> <span>dict</span><span>[</span><span>str</span><span>,</span> <span>list</span><span>[</span>PatchSpec<span>]</span><span>]</span><span>,</span>
    batch_size<span>:</span> <span>int</span><span>,</span>
    prefetch_blocks<span>:</span> <span>int</span><span>,</span>
<span>)</span> <span>-</span><span>&gt;</span> torch<span>.</span>utils<span>.</span>data<span>.</span>IterableDataset<span>:</span>
    df <span>=</span> pd<span>.</span>DataFrame<span>(</span><span>{</span><span>&#34;file_uri&#34;</span><span>:</span> k<span>,</span> <span>&#34;spec&#34;</span><span>:</span> v<span>}</span> <span>for</span> k<span>,</span> v <span>in</span> slides_specs<span>.</span>items<span>(</span><span>)</span><span>)</span>
    ds <span>=</span> <span>(</span>
        ray<span>.</span>data<span>.</span>from_pandas<span>(</span>df<span>)</span>
        
        <span>.</span>repartition<span>(</span>num_blocks<span>=</span><span>len</span><span>(</span>df<span>)</span><span>/</span>batch_size<span>)</span>
        
        <span>.</span>window<span>(</span>blocks_per_window<span>=</span><span>1</span><span>)</span>
        
        <span>.</span><span>map</span><span>(</span>read_patch<span>)</span>
    <span>)</span>
    <span>return</span> ds<span>.</span>to_torch<span>(</span>
      feature_columns<span>=</span><span>&#34;patch&#34;</span><span>,</span>
      batch_size<span>=</span>batch_size<span>,</span>
      prefetch_blocks<span>=</span>prefetch_blocks<span>,</span>
    <span>)</span></code></pre></div>
<p>This snippet can benefit from numerous optimizations and improvements.
However the rough idea is as follows:</p>
<ol>
<li>We flatten and turn the previous <code>slides_specs</code> into a <code>ray.data.Dataset</code> to work with Ray.</li>
<li><code>.repartition</code> distributes it into many blocks,<sup id="fnref-5"><a href="#fn-5">5</a></sup> otherwise <code>.map</code> would compute everything on the same worker.</li>
<li><code>.window</code> turns the dataset into a <code>ray.data.DatasetPipeline</code>, otherwise <code>.map</code> would compute all blocks.</li>
<li>Finally, <code>.map</code> makes a pipeline that will effectively read the WSI patches when iterated.</li>
</ol>
<p>Then this dataset can be plugged to our PyTorch script using <code>.to_torch</code>.</p>
<p>However this code can’t be run locally, as a single computer will not have enough cores to parallelize it enough.</p>

<p>In order to scale this distributed processing pipeline, we ought to use the cloud!</p>
<p>In our case, we decided to use <a href="https://learn.microsoft.com/en-us/azure/aks/">AKS</a>, Azure’s managed Kubernetes, to set up the compute cluster,
and <a href="https://github.com/ray-project/kuberay"><code>kuberay</code></a>, an open source toolkit to run Ray applications on Kubernetes, to set up the ray clusters on top of it.
More specifically, <code>kuberay</code> will deploy the Custom Resource Definitions, Operator and Service that make it easy to manage clusters with YAML files and a CLI.</p>
<p>Since we use OpenSlide and other specific packages, we need pods to run on our own Docker images that will have our tools and libraries installed.
Thus we connect AKS to an <a href="https://learn.microsoft.com/en-us/azure/container-registry/">Azure Container Registry</a> in our Virtual Private Cloud (VPC).</p>
<p>Now, let’s imagine we have the following Ray cluster in our Kubernetes’ default namespace:</p>
<ul>
<li>1 head pod, GPU, named <code>ray-head</code></li>
<li>8 worker pods, no GPU, named <code>ray-worker-{number}</code>, <code>{number}</code> ranging from <code>1</code> to <code>8</code></li>
</ul>
<p>Once <code>kubectl</code> is configured on the user’s laptop, they can SSH into the head worker with the following command.</p>
<div data-language="console"><pre><code>$ kubectl attach ray-head</code></pre></div>
<p>This allows the user to work directly in the pod from their terminal.</p>
<p>However, it is usually preferable to use Ray’s job system instead.
We can send a job to the ray cluster thanks to Ray’s CLI,
but that requires communicating with the <a href="https://docs.ray.io/en/latest/ray-core/ray-dashboard.html">Ray cluster’s dashboard server</a>.
It possible to do this with <code>kubectl port-forward</code>.</p>
<div data-language="text"><pre><code>$ kubectl port-forward ray-head 8265:8265 &amp;
$ ray job submit --runtime-env-json &#39;{&#34;py_modules&#34;:[&#34;mymodule&#34;]}&#39; -- python -m mymodule</code></pre></div>
<p>The runtime environment allows us to easily specify a local Python module that we are working on, here <code>mymodule</code>, that should be pushed from the user’s laptop to the cluster, among <a href="https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#api-reference">many other settings</a>.</p>
<p>With this setup, a user can easily write a Python module, run it locally to debug it, then run it at scale on a powerful cluster.</p>

<p>All in all, it is about building a platform for researchers to focus on what they really want to do: research.
Machine Learning researchers should write their ML model and data processing, push that to a service, and it should <em>just work</em>.
We achieved that to a certain degree thanks to Ray and Kubernetes.</p>
<p>In our case, processing the data “online” at each training iteration was the bottleneck, and doing it all “offline” was not a good solution.
Fortunately this workload could be parallelized.
But one computer wasn’t enough, so we used distribution.</p>
<p>This is why Ray was such a good fit: it provided an easy way to write distributed code in Python, the ability to schedule and run jobs on Kubernetes, and also a convenient CLI to submit these jobs.</p>
<p>Many challenges still remain.
Ray doesn’t have <a href="https://github.com/ray-project/ray/issues/21161">a proper job queue</a> that can schedule jobs when resources are available, so teams have to check the availability of compute on the cluster themselves before they can submit a job.
Related to that, it is not possible to control and assign resources to teams;
unlike <a href="https://slurm.schedmd.com/">Slurm</a>, which is widely used in the academic world, but is less flexible.</p>
<p>Our work built the core of a Data Platform which achieves flexibility with reasonable usability,
suited for our client’s use case and all its various ad-hoc requirements that come from working on diverse and unstructured data.</p>
</div></div></div>
  </body>
</html>
