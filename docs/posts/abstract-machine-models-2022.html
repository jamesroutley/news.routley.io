<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dr-knz.net/abstract-machine-models.html">Original</a>
    <h1>Abstract Machine Models (2022)</h1>
    
    <div id="readability-page-1" class="page"><div>
            
            <p>Ever since 2010, I have studied the “meta” of software, by studying
(and thinking about) the continued dialogue between programming
language designers, computer designers, and programmers.</p>
<p>The following constitutes a snapshot of my current thinking.</p>
<div id="epistemological-context">
<h2><a href="#toc-entry-1">Epistemological context</a></h2>
<p>During the period 2008-2012, I was requested to help design&amp;build programming
tools for a proposed new microprocessor architecture. The details of
said architecture do not matter here; what is interesting is that
folk in that research group had the following idea:</p>
<ul>
<li>their architecture had many design knobs, and they didn’t know what
position to choose in the design spectrum.</li>
<li>so instead they decided they would <em>abstract</em> over all the possible
design points, and spell out a <em>model</em> that describes them all.</li>
<li>then they asked me to make programming tools that work over all
the possible-but-not-yet-existing platforms described by that model.</li>
</ul>
<p>Of note, I did not know this is what was asked of me at the beginning. I only
figured it out towards the end.</p>
<p>The more remarkable aspect is <em>that these researchers did not
understand that this is what they were doing either</em>.</p>
<p>Instead, what they were <em>saying</em> they were doing was:</p>
<ul>
<li>“we’re trying to invent a microprocessor.”</li>
<li>“we specified a virtual machine for it and we implemented an emulator.”</li>
<li>“it’s not finished.”  (what they meant, but did not understand, is
that too many design points were remaining open; plus the emulator
was always changing and incomplete.)</li>
<li>“please make a C compiler happen.”</li>
</ul>
<p>What wasn’t clear to me at the time, nor to them, is that <strong>the
particular design choices that go into a hardware microprocessor have
heavy implications on the design and implementation of programming
tools</strong>.</p>
<p>In particular, we found that when we change the hardware too much, it
becomes hard to design efficient algorithms using existing languages,
even if a compiler/toolchain exists.</p>
<p>So the particular project above wasn’t exactly successful (there was
no hardware, and too many knobs were left unspecified), I explained so
much in the <a href="https://pure.uva.nl/ws/files/1813100/109494_12.pdf">preface</a> to my <a href="https://dare.uva.nl/search?identifier=8c8d2d3d-270e-4653-b8c8-11c5f21104b6">doctoral thesis</a>, also later <a href="https://dr-knz.net/dark-resistance.html">ranted
about the arrogance of such a scientific premise in the context of
software history</a>, then that project stopped.</p>
<p>But the insight about this “software meta” was still open: <em>why are
programming languages so intimately linked to hardware architectures?</em></p>
<p>I continued studying this question throughout the period 2012-2018,
and it remains a hobby to this day.</p>
<p>❦❦❦</p>
<p>As I started my own “research program” on this topic, I spent time to
scrutinize the vocabulary in use in the field and in the academic community.</p>
<p>It turns out, computer architecture practitioners really like working
with <em>models</em>, because models are cheaper to work with than real
hardware. After all, there’s never enough money in academia. But then,
they also ask computer scientists and programmers to work with them,
and everyone is then working in model-land, with emulators and simulators.</p>
<p>To simplify and satirize the situation, it is as if millions of euros
were spent finding solutions to important social and mechanical
problems by analyzing and programming the <a href="https://www.lexaloffle.com/pico-8.php"><span>PICO</span>-8</a> fantasy console.</p>
<p>Everyone says “my architecture, and my software for it, do things” and
nods politely to each other, without ever acknowledging that there’s
no way for anyone to hold an artifact in their hands that works like
what their model predicts.</p>
<p>By far, the most insiduous intellectual fallacy I found in that
environment is that enough scientists confuse <em>specification</em> and
<em>description</em>. They design a model to describe something and make
predictions about it (that’s fine), then they <em>change their model</em> and
say “we can build a physical system that follows this new model”. The
latter is scientific nonsense.</p>
<p>Changing a <em>descriptive model</em> is not an act of design. It does not
“create” anything in the real world. If one is lucky, the new model
can <em>describe something else</em> that happens to exist already. If one is
unlucky, the new model describes nothing that exists; that new model
is useless and pointless.</p>
<p>That was my first self-guided foray in computing epistemology:
<strong>modeling and specification (&amp; system design) are two fundamentally
different intellectual activities.</strong></p>
<p>I held my first <a href="https://science.raphael.poss.name/files/20130130-epistemology.pdf">public talk</a> about this in 2013.</p>
<p><a href="https://science.raphael.poss.name/files/20130130-epistemology.pdf"><img alt="Epistemology screenshot" src="https://dr-knz.net/abstract-machine-models/epistemology.png"/></a></p>
</div>
<div id="boundary-of-functional-semantics-syntactic-variance">
<h2><a href="#toc-entry-2">Boundary of functional semantics: syntactic variance</a></h2>
<p>One of the major obstacles I encountered on my way to the above insight
was the existence of Haskell (the programming language), and a community
of peers who were very strong Haskell advocates and practitioners.</p>
<p>Haskell presented an obstacle because Haskell has <em>denotational
semantics</em>: a machine-independent model of what Haskell programs “do”
when they run. It is machine-independent because it does not require
the decomposition of a computation into hardware steps to predict the result.</p>
<p>At face value, back then, I was thinking that Haskell
can be used to specify programs and their behavior in the abstract, but
also simultaneously <em>their behavior in the real world</em>. It felt, to me, as if
Haskell’s descriptive abstract model somehow had “specification power” over the
physical world.</p>
<p>As long as was stuck there, I was not able to see the difference
between description and specification.</p>
<p>My breakthrough happened when I saw these three specifications of an
integer sort function:</p>
<div><pre><span></span><span>f</span><span> </span><span>::</span><span> </span><span>[</span><span>Int</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>Int</span><span>]</span>

<span>f</span><span> </span><span>=</span><span> </span><span>map</span><span> </span><span>sum</span><span> </span><span>.</span><span> </span><span>transpose</span><span> </span><span>.</span><span> </span><span>transpose</span><span> </span><span>.</span>
<span>    </span><span>map</span><span> </span><span>(</span><span>flip</span><span> </span><span>replicate</span><span> </span><span>1</span><span>)</span>

<span>f</span><span> </span><span>(</span><span>p</span><span>:</span><span>xs</span><span>)</span><span> </span><span>=</span><span> </span><span>f</span><span> </span><span>[</span><span> </span><span>y</span><span> </span><span>|</span><span> </span><span>y</span><span> </span><span>&lt;-</span><span> </span><span>xs</span><span>,</span><span> </span><span>y</span><span> </span><span>&lt;</span><span> </span><span>p</span><span> </span><span>]</span>
<span>           </span><span>++</span><span> </span><span>[</span><span>p</span><span>]</span><span> </span><span>++</span>
<span>           </span><span>f</span><span> </span><span>[</span><span> </span><span>y</span><span> </span><span>|</span><span> </span><span>y</span><span> </span><span>&lt;-</span><span> </span><span>xs</span><span>,</span><span> </span><span>y</span><span> </span><span>&gt;=</span><span> </span><span>p</span><span> </span><span>]</span>

<span>f</span><span> </span><span>(</span><span>h</span><span>:</span><span>tl</span><span>)</span><span> </span><span>=</span><span> </span><span>snd</span><span> </span><span>$</span><span> </span><span>foldl</span><span> </span><span>g</span><span> </span><span>(</span><span>h</span><span>,</span><span> </span><span>[]</span><span>)</span><span> </span><span>tl</span>
<span>           </span><span>where</span>
<span>           </span><span>g</span><span> </span><span>(</span><span>s</span><span>,</span><span> </span><span>r</span><span>)</span><span> </span><span>x</span><span> </span><span>|</span><span> </span><span>x</span><span> </span><span>&lt;</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>(</span><span>x</span><span>,</span><span> </span><span>s</span><span>:</span><span>r</span><span>)</span>
<span>                      </span><span>|</span><span> </span><span>otherwise</span><span> </span><span>=</span><span> </span><span>(</span><span>s</span><span>,</span><span> </span><span>x</span><span>:</span><span>r</span><span>)</span>
</pre></div>
<p>(The first one is an implementation of <a href="https://en.wikipedia.org/wiki/Bead_sort">bead sort</a>, the second one is a
<a href="https://en.wikipedia.org/wiki/Quicksort">quicksort</a>, and the third one is an <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a>.)</p>
<p>In Haskell’s denotational semantics, these three implementations are
<em>functionally equivalent</em>: we could swap one for another in any program
without change in semantics.</p>
<p>And then, because Haskell’s denotational semantics <em>only</em> provides
knowledge about functional semantics, this means that <em>there is no
difference, under that model, between these three implementations</em>.</p>
<p>And yet, these three implementations exist, and they differ from
each other. Why would a programmer ever want to choose one over another?</p>
<p>There was clearly <em>something that mattered</em> in the expression of each
of these three functions, but that the denotational semantics model
was not able to represent.</p>
<p>❦❦❦</p>
<p>That “special something”, of course, had something to do with run-time performance.</p>
<p>In casual conversations, and some less-than-stellar writeups by fellow
practitioners, I often heard the following theory: since the model
predicts these functions are equivalent, “it should be possible” to
make an optimizing compiler which, given one of them, automatically
derives the others, to choose the best one given a target hardware platform.</p>
<p>The suggestion that was made to me was that to build software <em>in
general</em>, it should be good enough to invent <em>one</em> program that works
in an abstract model, and then build “sufficiently clever”
compilers that take care of translating that program optimally to any
target hardware without additional programmer input.</p>
<p>And so I investigated this. Could it be true? Maybe these differences
above were just inconsequential noise?</p>
<p>Alas for my fellow practictioners, I was vindicated by the discovery
of the following article, which cemented my distrust of descriptive
semantic models forever: <a href="https://dl.acm.org/doi/10.1145/502175.502181">Jeroen Voeten, On the fundamental
limitations of transformational design, <span>ACM</span> Transactions on Design
Automation of Electronic Systems, Volume 6, Issue 4, October 2001, pp
533–552, <span>DOI</span> 10.1145/502175.502181</a>.</p>
<p><a href="https://dl.acm.org/doi/10.1145/502175.502181"><img alt="Voeten, TDAES" src="https://dr-knz.net/abstract-machine-models/voeten01.png"/></a></p>
<p>In short, Jeroen V. demonstrated mathematically that <em>if a specification
system is sufficiently general (like Haskell’s semantics), the
automatic derivation of all functionally equivalent specifications
from a given starting point is undecidable.</em></p>
<p>So much for universally general optimizing compilers.</p>
<p>In other words, the choice made by programmers for one implementation
over another, when they are functionally equivalent, matters somehow
in a way that cannot be described in the model of their functional semantics.</p>
<p>In hindsight, I recognize that sounds obvious, almost tautological. Yet,
virtually all of my peers at the time did not believe me at first, and were annoyed
that my statements could risk their sources of funding.</p>
</div>
<div id="abstract-machine-models-1">
<h2><a href="#toc-entry-3">Abstract Machine Models</a></h2>
<div id="introduction">
<h3><a href="#toc-entry-4">Introduction</a></h3>
<p>From there, I focused on the following: “what’s in the mind of
programmers, when they choose one way of doing things over another
that’s functionally equivalent?”</p>
<p>The one thing that was clear from the start, is that most programmers
“simulate” the behavior of their program in their mind, to predict
how the program will behave at run-time.</p>
<p>As we’ve determined above, that simulation does not happen in the
<em>functional</em> model of the programming language.</p>
<p>Meanwhile, I knew from my teaching practice that nobody really
understands hardware computers, and so this mental simulation was also
not happening with a model of a <em>hardware</em> platform. In fact, I’ve
found that folk would rather not think about hardware at all, and
thankfully so: this made it possible, over and over, to <em>port
software</em> from one hardware platform to another, without rewriting the software.</p>
<p>This meant that all programmers are able to construct a somewhat
<em>abstract</em> model of their computer in their mind, but not so abstract
that it becomes <em>purely functional</em>.</p>
<p>That is when I coined the phrase <strong>abstract machine model</strong> (<span>AMM</span>), and
it became the anchor of my subsequent study.</p>
<p>I then made a prediction of what AMMs would and would not include:</p>
<ul>
<li><p>AMMs extend functional models with models/intuition of
<em>extra-functional behavior</em>, including:</p>
<ul>
<li>Time to result.</li>
<li>Memory usage.</li>
<li>Available I/O primitives.</li>
<li>Interfaces with debuggers and tracing facilities.</li>
<li>Throughput/latency of operations.</li>
<li>Jitter of operations.</li>
<li>Energy expenditure.</li>
</ul>
</li>
<li><p>AMMs have <em>compositional semantics</em> for programs: programmers want
to predict what’s the behavior of combining two sub-programs, when
they have prior intuition about each sub-program.</p>
<p>So AMMs must contain “program combining operators” (e.g. sequencing,
parallel execution, process duplication) and allow extra-functional
predictions about the results of these operators.</p>
</li>
<li><p>AMMs do <em>not</em> commonly include low-level details such as wiring
topology, specific processor counts, specific memory sizes,
instruction set architecture (<span>ISA</span>), etc.</p>
</li>
</ul>
<p>I announced this project to my peers early in 2014, at the Netherlands
Functional Programming Day workshop (<a href="https://science.raphael.poss.name/files/20140111-compositional-hw-virt.pdf">slides</a>).</p>
<p><a href="https://science.raphael.poss.name/files/20140111-compositional-hw-virt.pdf"><img alt="AMMs 2014" src="https://dr-knz.net/abstract-machine-models/amms2014.png"/></a></p>
<p>❦❦❦</p>
<p>As I soon discovered, I was not the first with an interest to create
an inventory of abstract machine models.</p>
<p>The following article, too, shaped my thinking durably: Peter van Emde
Boas, Handbook of theoretical computer science (vol. A), chapter
<a href="https://scholar.google.com/scholar?cluster=11558607896992369247&amp;hl=en&amp;as_sdt=0,5">Machine models and simulations</a>, p. 1-66, <span>MIT</span> Press, 1990, <span>ISBN</span>
0-444-88071-2. (Usually available in university libraries, contact me otherwise.)</p>
<p><a href="https://scholar.google.com/scholar?cluster=11558607896992369247&amp;hl=en&amp;as_sdt=0,5"><img alt="Van Emde Boas 1990" src="https://dr-knz.net/abstract-machine-models/emdeboas1990.png"/></a></p>
<p>In there, Peter v. E.-B. identified that the study of algorithmic complexity,
which is about predicting execution time of programs, depends on
particular properties of the target computer. He then went on to
<em>classify various machine models</em> that associate <em>different
algorithmic complexities</em> to the same algorithms.</p>
<p>This was, incidentally, the analysis that formalized the difference
between <a href="https://en.wikipedia.org/wiki/Random-access_machine">RAMs</a>, used to predict the behavior of simple sequential
programs and <a href="https://en.wikipedia.org/wiki/Parallel_RAM">P-RAMs</a>, used to predict the behavior of programs run
on multiprocessors with shared memory. These two have since become two
staples of computer science curricula around the world.</p>
<p>The author also identified <span>MIMD</span>-<span>RAM</span>, a model of networked machines with a
dynamically adjustable number of processors, which he demonstrated to
be yet a separate class.</p>
<p>Yet, Peter v. E.-B. was strictly interested in execution runtime,
estimated as a count of basic operations known to take fixed amount of
time in the physical world, and memory usage.</p>
<p>There was nothing there to be found about the other dimensions of
extra-functional behavior that I found interesting: intuition about
address spaces, task scheduling, operational jitter, I/O interfaces
and performance, and perhaps what would make one programming language
better than another.  That’s how I found it worth to think about AMMs further.</p>
</div>
<div id="not-languages-nor-computers">
<h3><a href="#toc-entry-5">Not languages, nor computers</a></h3>
<p>One thing that bothered me much early on was whether AMMs were truly distinct
from programming languages or the computers that we use.</p>
<p>The question was really: <em>when a programmer thinks about the run-time
behavior of their program, are they only able to formulate their
thoughts within the confines of the language they’re using to write
the program or the computer they’re working with?</em></p>
<p>I developed my answer to this (negative) from three different sources
of truth.</p>
<p>One argument came from linguistics. The question above is really a
rephrasing, within computer science, of the question of <a href="https://en.wikipedia.org/wiki/Linguistic_relativity">linguistic
relativity</a> (also known as the “Sapir-Whorf hypothesis”): whether
language shapes human thoughts. Today, linguistic consensus is that
yes, language <em>influences</em> thought, but no, it does not <em>constrain</em>
it. People are able to think thoughts outside of their language.</p>
<p>The second argument came from the history of computer science. By and
large, algorithmic complexity was well-understood before we defined
programming languages and the computing machines to run them. We knew
the execution costs of many classes of programs using <a href="https://en.wikipedia.org/wiki/Turing_machine">Turing</a> and
<a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">Von Neumann</a> machines and the <a href="https://en.wikipedia.org/wiki/Lambda_calculus">Lambda Calculus</a>, all three being
purely mathematical constructs, in the 1950s before any computer was
ever built and before the first programming language was invented. In
the “chicken or egg” metaphysics of computer science, the AMMs came
before the languages and the machines.</p>
<p>The third argument stemmed from empirical observation.</p>
<p>I could clearly see that a programmer trained to write simple C code
on an embedded microcontroller had transferrable skills when they
learned Python to write programs on a <a href="https://en.wikipedia.org/wiki/Supercomputer">supercomputer</a>. Over and over,
I was able to confirm that programmers could transpose their skills
over one class of languages and platform to another, without much
effort compared to a new learner. They knew <em>one or more
AMMs that they could reuse effectively across languages and platforms.</em></p>
<p>Yet, I could also clearly observe there are multiple distinct AMMs in
use side-by-side <em>within a single programming language</em>, and also
<em>within a single hardware platform</em>.</p>
<p>In the first category, I found myself studying Haskell again, and
determined that Haskell programmers, by and large, use a common <span>AMM</span>
which is an abstraction of the <a href="https://medusa.teodesian.net/docs/computing/hask035-voellmy.pdf"><span>MIO</span> runtime system</a>. Under <span>MIO</span>, it
is possible to reliably predict the performance of Haskell programs,
and develop a strong intuition of how a Haskell program does I/O, what
influences its execution externally, etc, even without precise
knowledge of the hardware platform.</p>
<p>Yet, <span>MIO</span> is not the only way to design and think about Haskell programs.
A group of coworkers developed <a href="https://clash-lang.org/">Clash</a>, a technology which transforms
Haskell programs to hardware circuits. When writing Haskell for Clash,
the operational semantics are all different, and the rules needed
to predict behavior are different too.</p>
<p>Clash defines a separate <span>AMM</span> for Haskell, independent from the one
that emerges from <span>MIO</span>, and the intuitions for one are not portable to
the other. <em>They are separate AMMs for the same language.</em></p>
<p>In summary, I incrementally developed an understanding that:</p>
<ul>
<li>Programmers use AMMs to write software.</li>
<li>AMMs exist separately from programming languages, and separately from hardware platforms.</li>
<li>There is more than one <span>AMM</span>, and AMMs differ in prediction rules and expressivity.</li>
<li>An <span>AMM</span> can sometimes be used to program effectively across multiple
languages, but not all.</li>
<li>An <span>AMM</span> can sometimes be used to program effectively across multiple
hardware computers, but not all.</li>
</ul>
</div>
<div id="programming-skills-abstract-over-amms-not-languages">
<h3><a href="#toc-entry-6">Programming skills abstract over AMMs, not languages</a></h3>
<p>After I gained more confidence in my understanding of AMMs, I started
to think about programming <em>skills</em>: could we use AMMs to more
formally and <em>generally</em> identify what separates programmers in skill levels?</p>
<p>To test this, I collected from my peers in academia and in the software
industry an inventory of sentences that they use to describe programming skills in
specific programming languages, and on specific hardware computers. I
then removed the parts of the sentences that referred to specific
languages/computers, and replaced them with phrases that refer to the most
common properties of the AMMs I knew of (at the time).</p>
<p>The result was a generic description of programming skills independent
from programming languages and independent from specific computers.</p>
<p>I <a href="https://dr-knz.net/programming-levels.html">published this description online</a> in 2014; to this day, this is <em>by
far</em> my most viewed web page, with tens of thousands of views every
year. It is cited, reused <span>&amp;</span> translated right, left and center. It appears
that folk find this phrasing valuable, across a multitude of
programming languages, computers and programming cultures.</p>
<p><a href="https://dr-knz.net/programming-levels.html"><img alt="Programming levels" src="https://dr-knz.net/programming-levels/prog-skill-matrix.png"/></a></p>
<p>I took this as a confirmation that an <span>AMM</span>-centered meta-understanding
of programming skills is valuable somehow.</p>
</div>
<div id="an-amm-inventory">
<h3><a href="#toc-entry-7">An <span>AMM</span> inventory</a></h3>
<p>Which AMMs are there anyways?</p>
<p>As I was gaining confidence AMMs were really a thing, the question of
<em>identifying</em> them became more pressing, at least to illustrate my
points during discussions with peers.</p>
<p>To start, I had found the Van Emde Boas classification (see above)
between <span>RAM</span>/<span>PRAM</span>, etc., insufficient. For example, I wanted to explain
the following empirical observations:</p>
<ul>
<li><p>the operational semantics of C++ programs using <span>POSIX</span> threads, Java
programs using <span>JVM</span> threads, and that of Go programs using goroutines
could all be reliably described by the P-<span>RAM</span>
machine model.</p>
</li>
<li><p>yet, it was very visible that the intuitions about run-time behavior
developed for each of these three environments were not easily
portable to the others:</p>
<ul>
<li>cooperative (e.g. Go prior to v1.14) vs preemptive scheduling.</li>
<li>memory cost of threads: <span>POSIX</span> is <span>OK</span> with 100s of threads, but not
10000s, Go and Java doesn’t care.</li>
<li>start latency of threads: Go less than 30µs, Java 50-100µs, <span>POSIX</span>
larger than 100µs.</li>
</ul>
<p>All these aspects heavily influence the design of concurrent algorithms.</p>
</li>
</ul>
<p>At the time (2014), I was able to separate the following AMMs from each other:</p>
<table>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr><th>Aspect (rows) / <span>AMM</span>
(columns)</th>
<th>C (e.g. C, C++,
Python, Rust)</th>
<th>Unix</th>
<th><span>JVM</span> (e.g.  Java,
Scala, Clojure)</th>
<th><span>JS</span>/<span>DOM</span>
(e.g. Javascript,
Typescript)</th>
<th><span>BEAM</span>
(e.g. Erlang,
Elixir)</th>
<th>GPUs (e.g. <span>CUDA</span>,
OpenGL, Vulkan)</th>
<th><span>GHC</span>/<span>MIO</span>
(e.g. Haskell)</th>
<th>Go</th>
<th><span>SQL</span> (e.g.
pgSQL)</th>
</tr>
</thead>
<tbody>
<tr><td>Units of
specification
(effective)</td>
<td>Statements /
Functions /
compilation
units or modules</td>
<td>Executable programs</td>
<td>Class methods /
Classes / Packages</td>
<td>Statements /
Functions</td>
<td>Functions /
Modules /
Processes</td>
<td>Thread function (on
<span>GPU</span>) and
coordination code
(on <span>CPU</span>)</td>
<td>Expressions /
Functions /
Packages</td>
<td>Statements /
Functions / Packages</td>
<td>Clauses /
Statements</td>
</tr>
<tr><td>Program composition,
visible at run-time</td>
<td>Sequence points,
function calls,
accesses to
<code>volatile</code> objects</td>
<td><code>fork</code> / <code>exec</code> /
sockets / file
descriptors</td>
<td>Method invocation,
use of
synchronization
primitives</td>
<td>Function calls,
callback
registration on
<span>DOM</span> objects</td>
<td>Function calls /
mailbox
operations /
process spawn</td>
<td><span>GPU</span> calls on <span>CPU</span>,
sometimes thread
function calls</td>
<td>Conditionals,
pattern maching
(destructuring),
uses of MVars</td>
<td>Function calls,
goroutine creation,
channel access, uses of
<code>atomic</code></td>
<td>CTEs,
windowing,
sub-queries
with an <span>ORDER</span>
<span>BY</span> / <span>LIMIT</span>
clause</td>
</tr>
<tr><td>Run-time system
embeds compiler:
enables REPLs and
user-defined
extensions at
run-time</td>
<td>No (yes with Python
and other interpreted
languages with
mandatory <code>eval</code>
function)</td>
<td>Yes (via <code>cc</code> and
<code>sh</code>)</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Depends on <span>DB</span>
engine, usually
no</td>
</tr>
<tr><td>Dynamic program
loading at run-time</td>
<td>Limited, via
non-standard APIs
(yes for Python and
other interpreted
languages with
mandatory <code>eval</code>)</td>
<td>Yes (via mounts)</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes for code
running on <span>CPU</span>, no
for code running on
<span>GPU</span></td>
<td>Limited, via
non-standard APIs</td>
<td>Limited, via
non-standard APIs</td>
<td>Depends on <span>DB</span>
engine</td>
</tr>
<tr><td>Base machine
abstraction for
hardware parallelism</td>
<td><span>POSIX</span> threads</td>
<td>Processes and threads</td>
<td>Java threads</td>
<td>Web workers</td>
<td>(Hidden)</td>
<td>Hardware thread</td>
<td>Evaluation
dispatchers, <span>IO</span>
threads</td>
<td>runtime.P objects</td>
<td>(Hidden)</td>
</tr>
<tr><td>Controlled program
placement on separate
hardware processors</td>
<td>Limited, via
non-standard APIs</td>
<td>Limited, via
non-standard APIs</td>
<td>Limited, via
non-standard APIs</td>
<td>Limited, via
non-standard APIs</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr><td>Managed N:M
concurrency
scheduling</td>
<td>Explicit, via
libraries (C) or async
calls and workers
(C++, Python, Rust)</td>
<td>Explicit, via
non-standard tools</td>
<td>Explicit: futures
and workers</td>
<td>Explicit: async
calls and workers</td>
<td>Implicit, for
all processes</td>
<td>Experimental</td>
<td>Implicit, for all
reductions</td>
<td>Implicit, for all
goroutines</td>
<td>Implicit, for
independent
sub-plans</td>
</tr>
<tr><td>Program can manage
disorderly
cancellation of async
work, e.g. upon
errors</td>
<td>Yes, via non-standard
APIs</td>
<td>Yes</td>
<td>Yes (partially)</td>
<td>Yes (partially)</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr><td>Ability to define
custom memory
management in program</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Limited</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr><td>Controlled program
placement on separate
memory domains</td>
<td>Limited, via
non-standard APIs</td>
<td>Limited, via
non-standard APIs</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr><td>Memory reachability:
all memory use at
run-time stems from
live objects in
program</td>
<td>Yes</td>
<td>No</td>
<td>No (async <span>GC</span>)</td>
<td>No (async <span>GC</span>)</td>
<td>Optional</td>
<td>Yes</td>
<td>No (async <span>GC</span>)</td>
<td>No (async <span>GC</span>)</td>
<td>Depends on <span>DB</span>
engine</td>
</tr>
<tr><td>Guaranteed minimum
I/O facilities with
human user</td>
<td>Yes
(stdin/stdout/stderr,
and PTYs on unix)</td>
<td>Yes (terminals)</td>
<td>Yes
(stdin/stdout/stderr)</td>
<td>Yes (<span>DOM</span> + alert +
console)</td>
<td>Yes (<code>io</code>,
<code>sys:log</code>,
<code>sys:trace</code>)</td>
<td>No</td>
<td>Yes
(stdin/stdout/stderr)</td>
<td>Yes
(stdin/stdout/stderr)</td>
<td>No</td>
</tr>
<tr><td>Guaranteed minimum
<span>IP</span> networking</td>
<td>No, but <span>BSD</span> sockets
are prevalent</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No, but expecting
underlying <span>BSD</span>
sockets to be
available as <span>API</span></td>
<td>Yes</td>
<td>No</td>
</tr>
<tr><td>Embedded under the
Unix <span>AMM</span>; ability to
launch and
control
sub-processes at the
<span>OS</span> level, synchronize
with pipes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr><td>I/O synchronization</td>
<td>Controlled by
program, inline <span>&amp;</span>
blocking by default,
async I/O available
via non-standard APIs</td>
<td>Controlled by
program, inline <span>&amp;</span>
blocking by default,
async I/O available
via non-standard APIs</td>
<td>I/O threads,
non-blocking</td>
<td>Inline <span>&amp;</span> blocking
(but can be
deferred / batched
via judicious
chaining of async
calls)</td>
<td>I/O threads,
non-blocking</td>
<td>I/O threads,
non-blocking</td>
<td>I/O threads,
non-blocking</td>
<td>I/O threads,
non-blocking</td>
<td>Inline,
blocking</td>
</tr>
<tr><td>External intervention
while program is
running, without
stopping program</td>
<td>Breakpoints (blocking)
ptrace (non-blocking)</td>
<td>ptrace
(non-blocking),
signals</td>
<td>Breakpoints
(blocking)</td>
<td>Breakpoints
(blocking)</td>
<td>Breakpoints
(non-blocking)</td>
<td>Breakpoints
(blocking)</td>
<td>Breakpoints
(blocking)</td>
<td>Breakpoints
(blocking)</td>
<td>No</td>
</tr>
<tr><td>External observation
while program is
running</td>
<td>Watchpoints,
profiling, ptrace</td>
<td>ptrace, profiling</td>
<td>Watchpoints,
profiling</td>
<td>Watchpoints,
profiling</td>
<td>Watchpoints,
profiling</td>
<td>Watchpoints,
profiling</td>
<td>Tracepoints,
stack dumps,
profiling</td>
<td>Profiling, stack dumps</td>
<td>Tracepoints,
profiling</td>
</tr>
</tbody>
</table>
<p>Note: I consider .<span>NET</span> to provide yet another <span>AMM</span>, close but not
equivalent to, that of the <span>JVM</span>. But I did not (and still do not) know
much about it, so I couldn’t include it in this table.</p>
</div>
</div>
<div id="amm-communities">
<h2><a href="#toc-entry-8"><span>AMM</span> communities</a></h2>
<p>AMMs define software ecosystems.</p>
<p>They define “cultural boundaries”: it’s easy for a programmer who
knows an <span>AMM</span> to transition to a different language whose semantics
project well into the same <span>AMM</span>, and it’s harder to cross <span>AMM</span> boundaries.</p>
<p>And so it was interesting to me to wonder: <em>“when do AMMs appear? When
does a programming language designer push for a new <span>AMM</span>, and when
can they slip into the shoes of an existing community?”</em></p>
<p>While building the table above and studying <span>PL</span> history, I
discovered that language designers come in three groups:</p>
<ol>
<li><strong>machine-first designers</strong>, who start with one or more hardware
platform that’s sufficiently different from everything that was done
before that it needs a new <span>AMM</span>, and often a new programming language
to program it.</li>
<li><strong>second-language designers</strong>, who assume the existence of some
machine/language ecosystem, adopts it and simply adds new
abstractions / expressivity on top.</li>
<li><strong><span>AMM</span>-first designers</strong>, who are interested to control the way
programmers think first (usually, due to some idea
about how this will result in better software quality), and
who merely think about hardware diversity as an inconvenience
that needs to be hidden from programmers.</li>
</ol>
<div id="most-common-second-language-ecosystems">
<h3><a href="#toc-entry-9">Most common: second-language ecosystems</a></h3>
<p>Second-language ecosystems are the most prevalent nowadays.
Language designers in this category
actively reuse the same platform abstractions as a well-known,
understood <span>AMM</span>, and explain (more or less explicitly) that
programmers in their language can work with the same <span>AMM</span> in mind.</p>
<p>For example, the <a href="https://www.rust-lang.org/">Rust</a> documentation does not define its own <span>AMM</span> and
the community largely understands that Rust uses the same <span>AMM</span> as C/C++.</p>
<p>Likewise, the <a href="https://www.typescriptlang.org/">TypeScript</a> docs do not define a custom <span>AMM</span> and the
community understands it maps to the <span>JS</span>/<span>DOM</span> <span>AMM</span>.</p>
<p><a href="https://elixir-lang.org/">Elixir</a> docs are more explicit and spell out clearly that Elixir
programs use the same <span>AMM</span> as Erlang/<span>OTP</span>.</p>
</div>
<div id="machine-first-ecosystems-innovation-by-tinkering">
<h3><a href="#toc-entry-10">Machine-first ecosystems: innovation by tinkering</a></h3>
<p>Machine-first designers used to be extremely common in the period
1960-1990.  They are, in fact, responsible for the explosion of AMMs
and programming languages until the late 1990s. Many of these AMMs
have since disappeared into obscurity, and only a few remain in active use.</p>
<p>The most visible artifact of that period, of course, is the unix <span>AMM</span>
and the various C/C++ AMMs.</p>
<p>Despite what the table above suggests, there’s not just one C/C++ <span>AMM</span>;
instead, there are “dialectal” differences in AMMs used by C/C++
programmers. For example, certain ways to think about the machine and
to algorithmic choices are different depending on whether a programmer
targets an embedded system without virtual memory and threads, or a
multi-computer network.</p>
<p>However, by and large, the majority of programmers who write C/C++ and
other related languages (incl. Python, Rust) use a “common dialect”
<span>AMM</span> with threads, shared memory, per-thread private storage, a
heap/stack split, unified code/data addressing, raw access to pointers
and bytes in memory, a private address space, a single filesystem and
file descriptors / sockets for I/O.</p>
<p>Post-1990s, the only widely-successful machine-first design stemmed
from the hard industry push towards accelerator-based architectures,
especially programmable GPUs. This resulted in unique AMMs fully
separated from what was prevalent at the time. We’ll discuss this more below.</p>
</div>
<div id="constrained-programming-amm-first-designs">
<h3><a href="#toc-entry-11">Constrained programming: <span>AMM</span>-first designs</a></h3>
<p>Some language designers are very intent on controlling the way
programmers think about platform semantics, and so work actively to
define and document their own <span>AMM</span>, carefully to hide whichever
semantics are available in the underlying hardware platform where
programs run.</p>
<p>They do this, generally, out of three types of concern:</p>
<ul>
<li><p>they have a strong desire to ensure that <em>all</em> programs can be
portable across a wide diversity of hardware platforms. For this,
it was paramount that <em>no</em> programmer could ever make specific
assumptions about the hardware platform.</p>
<p>For example, this happened with the <span>JVM</span> and <span>JS</span>/<span>DOM</span>.</p>
</li>
<li><p>they have a theory that a constrained <span>AMM</span> will make it possible to
prove (or guarantee) software correctness / stability / quality /
compositionality for a large class of programs.</p>
<p>For example, this was the reason for the definition of <span>SQL</span>. Later,
the Erlang designers did this too with <span>BEAM</span>.</p>
</li>
<li><p>they have some theory that a different <span>AMM</span> will guide programmers
towards simpler solutions for common programming tasks, or that the
<span>AMM</span> will make it easier to maintain / extend programs somehow.</p>
<p>The Go designers did this, regarding everything related to
concurrency, by restricting concurrent programming patterns to those
allowed by Tony Hoare’s calculus of <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes">Communicating Sequential
Processes</a>.</p>
<p>The Haskell situation is a bit different. The original innovation of
Haskell was to project programs into a graph reduction machine
using term substitution, and that clearly defines an <span>AMM</span> that is
quite different from everything else at the time it was invented.</p>
<p>However, over time, pragmatic Haskell programmers also needed I/O,
networking and other features! So the Haskell ecosystem gradually
developed an <span>AMM</span> with these features by abstracting from the most
commonly used implementation, <span>GHC</span>/<span>MIO</span>, which is constructively
embedded inside the C/C++ and Unix AMMs and so inherits some of
their features.</p>
</li>
</ul>
</div>
</div>
<div id="amm-adequacy-and-success">
<h2><a href="#toc-entry-12"><span>AMM</span> adequacy and success</a></h2>
<div id="programmers-target-amms-not-languages-or-machines">
<h3><a href="#toc-entry-13">Programmers target AMMs, not languages or machines</a></h3>
<p>It sounds almost trite to spell out that most programmers expect that
their programs can run… on a real computer.</p>
<p>In fact, the majority of software is written with that expectation, and
a great deal of software is <em>optimized</em> by programmers to run <em>well</em> on a
particular class of computers.</p>
<p>And as we’ve seen above, they do not (nor would like to) think about
specific hardware parameters, and so they wish to abstract over
hardware, but they also usually want to ensure their programming
skills transpose across multiple programming languages.</p>
<p>In other words, <strong>the ability of a programmer to do their job well is
largely dependent on their ability to utilize hardware capabilities in
their programs, and predict program behavior, using an <span>AMM</span> as thinking tool.</strong></p>
</div>
<div id="parallel-programming-is-hard">
<h3><a href="#toc-entry-14">Parallel programming is hard</a></h3>
<p>By far, the most significant event in the evolution of AMMs in our
computing history was the loss of <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> on single
processors, and the mandatory gradual move to multi-core platforms.</p>
<p>Where prior to year 2000, parallel programming was an activity
restricted to a few practioners with unusual computing needs, after
~2005 it became everyone’s problem. And through the period 2000-2010,
the software industry as a whole had to scramble around the
realization that they did not possess good AMMs to program parallel
hardware effectively.</p>
<p>This resulted in a flurry of research projects and more-or-less
successful technical developments. Besides <span>ATI</span>’s and NVidia’s efforts,
which <em>eventually</em> culminated in the emergence of the accelerator
architecture and its “Compute <span>GPU</span>” abstraction as the dominant <span>AMM</span>,
there was a myriad of smaller-scope projects with various degrees of
funding and programmer interest.</p>
<p>For example, I am personally fond of <a href="https://chapel-lang.org/">Chapel</a>, which provides a simple
<span>AMM</span> over distributed compute nodes (a strictly more powerful <span>AMM</span> than P-RAMs).</p>
<p>In 2015, I organized my thoughts around the diversity of AMMs for
heterogeneous parallel platforms and captured them in <a href="https://science.raphael.poss.name/files/20151119-shonan-models.pdf">this
presentation</a> to a research seminar.</p>
<p><a href="https://science.raphael.poss.name/files/20151119-shonan-models.pdf"><img alt="HPC AMMs" src="https://dr-knz.net/abstract-machine-models/ppamm1.png"/></a></p>
<p>This was also the time I was toying with my own concrete proposal for
a more intelligent Unix model to run on many-core computers. This was
also well-received, and this article was accepted at a relatively
prestigious journal: <a href="http://doi.org/10.1109/TPDS.2015.2492542">Poss, R.; and Koning, K. <span>AM3</span>: Towards a hardware
Unix accelerator for many-cores. <span>IEEE</span> Trans. Parallel
Distrib. Syst., 26. October 2015. <span>DOI</span> 10.1109/<span>TPDS</span>.2015.2492542</a> (<a href="https://science.raphael.poss.name/pub/poss.15.tpds.pdf">preview</a>).</p>
<p><a href="http://doi.org/10.1109/TPDS.2015.2492542"><img alt="AM3" src="https://dr-knz.net/abstract-machine-models/am3.png"/></a></p>
</div>
<div id="natural-tension-control-vs-guarantees">
<h3><a href="#toc-entry-15">Natural tension: control vs guarantees</a></h3>
<p>Hardware is messy. More specifically, hardware behavior outside of the
<span>CPU</span>/memory/disk trifecta is extremely hard to model accurately. This
includes things like external I/O (e.g. networking, <span>USB</span>, touchpads),
internal I/O (e.g. cache coherence, memory interconnect), energy
usage, etc.</p>
<p>So any programmer who cares about these things needs to hold an <span>AMM</span> in
their mind with a great(er) deal of complexity. They either need to
find an ecosystem with an existing <span>AMM</span> with all the facilities they
need, or develop their own <span>AMM</span> with more specific assumptions about
their target computer, i.e. tie their personal <span>AMM</span> to one physical machine.</p>
<p>When they do this, they often reduce their ability to predict program
behavior accurately when the program increases in complexity.  They
also lose the ability to obtain predictable behavior when the program
runs on a different computer (if it runs at all).</p>
<p>Conversely, a programmer who cares about engineering costs over time,
including reuse and portability, will likely constrain themselves to
thinking their software in the terms of an <span>AMM</span> that has powerful
prediction abilities and strong compositional semantics over a variety
of hardware platforms.</p>
<p>This is commonly achieved by restricting the number of ways that
programs can be written, to a fixed subset of software patterns with
predictable behavior.</p>
</div>
<div id="fallacy-control-and-guarantees-are-not-either-or">
<h3><a href="#toc-entry-16">Fallacy: control and guarantees are not either/or</a></h3>
<p>A common fallacy in software engineering is to think about AMMs as
existing on a <em>linear spectrum</em> with “more control, less guarantees”
at one end, and “less control, more guarantees” at the other end.</p>
<p>Something like this:</p>
<p><img alt="" src="https://dr-knz.net/abstract-machine-models/spectrum.png"/></p><p>However, the reality is that this spectrum is not linear.  Even though
there is a <em>general</em> inverse correlation between these two dimensions,
certain AMMs provide more control at equal level of guarantees.</p>
<p>For example, it is possible to model, then exploit in programs,
support for thread-local storage (<span>TLS</span>) in those hardware platforms that
provide it, without losing the ability to reason about deadlock
freedom, object lifetimes and freedom from race conditions. This is
possible as long as this model has restrictions on the lifetime
and sharing of references to <span>TLS</span>, such as is achieved with Rust’s lifetime
and reference sharing semantics.</p>
<p>So extending an <span>AMM</span> with modeling power over hardware facilities does
not necessarily result in loss of guarantees. Conversely, at a given
level of guarantees on software correctness / cost / stability /
maintainability, certain AMMs have more modeling power than
others. Arguably, they are “better.”</p>
<p>It is thus more useful to think about AMMs as points on a
two-dimensional space, with a <a href="https://en.wikipedia.org/wiki/Pareto_front">Pareto front</a> of maximally useful
AMMs on this control/guarantees space. Something like this:</p>
<p><img alt="" src="https://dr-knz.net/abstract-machine-models/spectrum2.png"/>
</p></div>
</div>
<div id="rust-pushed-the-pareto-envelope">
<h2><a href="#toc-entry-17">Rust pushed the Pareto envelope</a></h2>
<p>Rust’s designers chose an interesting position in the design space of
programming languages: for most simple programs, it enables
programmers to reuse the C/C++ <span>AMM</span> and thereby exposes access to the
largest diversity of I/O interactions; and yet, it also moderates
access to memory and concurrency (using its lifetime and mutable
reference checks) in a way that makes it easier, cheaper and more
reliable to write correct and more stable programs.</p>
<p>As a “cherry on top of the cake”, Rust was designed with <em>functional
ergonomics</em>: it presents to programmer the expressivity of a modern
functional language, with a modern type system.</p>
<p>This combination of advanced ergonomics while offering an <span>AMM</span> that
provides intuition about hardware behavior that’s at least as good as
C’s <span>AMM</span> with more guarantees on program correctness, was <strong>absolutely
revolutionary</strong>.</p>
<p>You can find a few more of my thoughts on Rust’s unique position in the <span>AMM</span>
bestiary in <a href="https://science.raphael.poss.name/files/20170112-rust-amms.pdf">this introduction to Rust</a> I gave to a research group
in 2017.</p>
<p><a href="https://science.raphael.poss.name/files/20170112-rust-amms.pdf"><img alt="Intro Rust" src="https://dr-knz.net/abstract-machine-models/rusttable.png"/></a></p>
</div>
<div id="benefits-what-comes-next">
<h2><a href="#toc-entry-18">Benefits <span>&amp;</span> what comes next</a></h2>
<p>I have already integrated this understanding in my mentoring and my
teaching practice. I am now able to explain that what makes certain
programming problems “hard” or “interesting” is not related to
oddities in hardware or programming languages, but rather to the way
programmers think about machines, i.e. the properties of their AMMs.</p>
<p>This makes me able to connect related software
challenges across programming language boundaries, or to recognize
when similar-looking programs in different languages have, in fact,
extremely different semantics.</p>
<p>It also makes me able to estimate how much time or effort it will take
me to learn a new technology stack or programming language: if I can
track its ancestry and design principles, I can estimate its
conceptual distance to AMMs I already know.</p>
<p>It also makes me able to estimate whether an already-written program
will work well on a new computer, with or without translation to a
different language or machine instruction set (<span>ISA</span>), depending on what
I know of the <span>AMM</span> that its programmer likely had in mind when the
program was written.</p>
<p>That said, I also think that our “good” AMMs today (in 2022) are also
too complex. In particular, I think the problem of finding good AMMs
for parallel programming, AMMs that are both easy to teach, easy to reason
about and powerful enough to predict performance accurately, is still
an open topic of research. So I’ll continue thinking about that.</p>
<p><img alt="" src="https://dr-knz.net/abstract-machine-models/ppamm2.png"/>
</p></div>
<div id="references-further-reading">
<h2><a href="#toc-entry-19">References <span>&amp;</span> further reading</a></h2>
<ul>
<li>Jeroen Voeten, <a href="https://dl.acm.org/doi/10.1145/502175.502181">On the fundamental limitations of transformational
design</a>, <span>ACM</span> Transactions on Design Automation of Electronic Systems,
Volume 6, Issue 4, October 2001, pp 533–552, <span>DOI</span> 10.1145/502175.502181.</li>
<li>Peter van Emde
Boas, Handbook of theoretical computer science (vol. A), chapter
<a href="https://scholar.google.com/scholar?cluster=11558607896992369247&amp;hl=en&amp;as_sdt=0,5">Machine models and simulations</a>, p. 1-66, <span>MIT</span> Press, 1990, <span>ISBN</span> 0-444-88071-2.</li>
<li>Poss, R.; and Koning, K. <a href="http://doi.org/10.1109/TPDS.2015.2492542"><span>AM3</span>: Towards a hardware
Unix accelerator for many-cores</a>. <span>IEEE</span> Trans. Parallel
Distrib. Syst., 26. October 2015. <span>DOI</span> 10.1109/<span>TPDS</span>.2015.2492542.</li>
<li><a href="https://dr-knz.net/rust-for-functional-programmers.html">Rust for functional programmers</a> on this site.</li>
</ul>
</div>



             




 
                <section>
    
    

    
</section>

            <hr/>
<section>
    <h2>Keep Reading</h2>

<hr/>
</section>
            
        </div></div>
  </body>
</html>
