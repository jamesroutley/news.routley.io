<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp">Original</a>
    <h1>DeepSeek-v3.2-Exp</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">



<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true"><img src="https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3"/></a>
</p>
<hr/>
<p><a href="https://www.deepseek.com/" rel="nofollow">
    <img alt="Homepage" src="https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/badge.svg?raw=true"/>
  </a>
  <a href="https://chat.deepseek.com/" rel="nofollow">
    <img alt="Chat" src="https://camo.githubusercontent.com/00ba04aacbe45f97b5ebcc3d1b9c0f546e0ce3981265e97a110994184ef67fc8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa496253230436861742d446565705365656b25323056332d3533366166353f636f6c6f723d353336616635266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/ðŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&amp;logoColor=white"/>
  </a>
  <a href="https://huggingface.co/deepseek-ai" rel="nofollow">
    <img alt="Hugging Face" src="https://camo.githubusercontent.com/5e3115539d4583e22d65cb89eb1759e767cb9e1d70772923292fcfc80a654be4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e67253230466163652d446565705365656b25323041492d6666633130373f636f6c6f723d666663313037266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&amp;logoColor=white"/>
  </a>
</p>
<p><a href="https://discord.gg/Tc7c45Zzu5" rel="nofollow">
    <img alt="Discord" src="https://camo.githubusercontent.com/e227481a149714ed5187e4fd0b60b9f736099c2dd2083e6c091e29f1446cbb1a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d446565705365656b25323041492d3732383964613f6c6f676f3d646973636f7264266c6f676f436f6c6f723d776869746526636f6c6f723d373238396461" data-canonical-src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&amp;logoColor=white&amp;color=7289da"/>
  </a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true">
    <img alt="Wechat" src="https://camo.githubusercontent.com/562efc618da65f0a69bc804395005b8124f5c2ed2eb73441c4e359185cc01467/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5765436861742d446565705365656b25323041492d627269676874677265656e3f6c6f676f3d776563686174266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&amp;logoColor=white"/>
  </a>
  <a href="https://twitter.com/deepseek_ai" rel="nofollow">
    <img alt="Twitter Follow" src="https://camo.githubusercontent.com/8272710ecd020c821b4f62c1c455efb89e0db4eb179c5f5f971c3c1f69452c54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547769747465722d646565707365656b5f61692d77686974653f6c6f676f3d78266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&amp;logoColor=white"/>
  </a>
</p>
<p><a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/LICENSE">
    <img alt="License" src="https://camo.githubusercontent.com/1af067540f64107f8fe7715d12150fb910e21f0d2c6aa0c319087c7510c8b934/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d6635646535333f26636f6c6f723d663564653533" data-canonical-src="https://img.shields.io/badge/License-MIT-f5de53?&amp;color=f5de53"/>
  </a>
</p>

<p dir="auto">We are excited to announce the official release of DeepSeek-V3.2-Exp, an experimental version of our model. As an intermediate step toward our next-generation architecture, V3.2-Exp builds upon V3.1-Terminus by introducing DeepSeek Sparse Attentionâ€”a sparse attention mechanism designed to explore and validate optimizations for training and inference efficiency in long-context scenarios.</p>
<p dir="auto">This experimental release represents our ongoing research into more efficient transformer architectures, particularly focusing on improving computational efficiency when processing extended text sequences.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/cost.jpg"><img src="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/raw/main/cost.jpg"/></a>
</p>
<ul dir="auto">
<li>
<p dir="auto">DeepSeek Sparse Attention (DSA) achieves fine-grained sparse attention for the first time, delivering substantial improvements in long-context training and inference efficiency while maintaining virtually identical model output quality.</p>
</li>
<li>
<p dir="auto">To rigorously evaluate the impact of introducing sparse attention, we deliberately aligned the training configurations of DeepSeek-V3.2-Exp with V3.1-Terminus. Across public benchmarks in various domains, DeepSeek-V3.2-Exp demonstrates performance on par with V3.1-Terminus.</p>
</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Benchmark</th>
<th>DeepSeek-V3.1-Terminus</th>
<th>DeepSeek-V3.2-Exp</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reasoning Mode w/o Tool Use</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td>85.0</td>
<td>85.0</td>
</tr>
<tr>
<td>GPQA-Diamond</td>
<td>80.7</td>
<td>79.9</td>
</tr>
<tr>
<td>Humanity&#39;s Last Exam</td>
<td>21.7</td>
<td>19.8</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>74.9</td>
<td>74.1</td>
</tr>
<tr>
<td>AIME 2025</td>
<td>88.4</td>
<td>89.3</td>
</tr>
<tr>
<td>HMMT 2025</td>
<td>86.1</td>
<td>83.6</td>
</tr>
<tr>
<td>Codeforces</td>
<td>2046</td>
<td>2121</td>
</tr>
<tr>
<td>Aider-Polyglot</td>
<td>76.1</td>
<td>74.5</td>
</tr>
<tr>
<td><strong>Agentic Tool Use</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BrowseComp</td>
<td>38.5</td>
<td>40.1</td>
</tr>
<tr>
<td>BrowseComp-zh</td>
<td>45.0</td>
<td>47.9</td>
</tr>
<tr>
<td>SimpleQA</td>
<td>96.8</td>
<td>97.1</td>
</tr>
<tr>
<td>SWE Verified</td>
<td>68.4</td>
<td>67.8</td>
</tr>
<tr>
<td>SWE-bench Multilingual</td>
<td>57.8</td>
<td>57.9</td>
</tr>
<tr>
<td>Terminal-bench</td>
<td>36.7</td>
<td>37.7</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">For TileLang kernels with <strong>better readability and research-purpose design</strong>, please refer to <a href="https://github.com/tile-ai/tilelang/tree/main/examples/deepseek_v32">TileLang</a>.</p>
<p dir="auto">For <strong>high-performance CUDA kernels</strong>, indexer logit kernels (including paged versions) are available in <a href="https://github.com/deepseek-ai/DeepGEMM/pull/200" data-hovercard-type="pull_request" data-hovercard-url="/deepseek-ai/DeepGEMM/pull/200/hovercard">DeepGEMM</a>. Sparse attention kernels are released in <a href="https://github.com/deepseek-ai/FlashMLA/pull/98" data-hovercard-type="pull_request" data-hovercard-url="/deepseek-ai/FlashMLA/pull/98/hovercard">FlashMLA</a>.</p>


<p dir="auto">We provide an updated inference demo code in the <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp/tree/main/inference" rel="nofollow">inference</a> folder to help the community quickly get started with our model and understand its architectural details.</p>
<p dir="auto">First convert huggingface model weights to the the format required by our inference demo. Set <code>MP</code> to match your available GPU count:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd inference
export EXPERTS=256
python convert.py --hf-ckpt-path ${HF_CKPT_PATH} --save-path ${SAVE_PATH} --n-experts ${EXPERTS} --model-parallel ${MP}"><pre><span>cd</span> inference
<span>export</span> EXPERTS=256
python convert.py --hf-ckpt-path <span>${HF_CKPT_PATH}</span> --save-path <span>${SAVE_PATH}</span> --n-experts <span>${EXPERTS}</span> --model-parallel <span>${MP}</span></pre></div>
<p dir="auto">Launch the interactive chat interface and start exploring DeepSeek&#39;s capabilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export CONFIG=config_671B_v3.2.json
torchrun --nproc-per-node ${MP} generate.py --ckpt-path ${SAVE_PATH} --config ${CONFIG} --interactive"><pre><span>export</span> CONFIG=config_671B_v3.2.json
torchrun --nproc-per-node <span>${MP}</span> generate.py --ckpt-path <span>${SAVE_PATH}</span> --config <span>${CONFIG}</span> --interactive</pre></div>


<div data-snippet-clipboard-copy-content="# H200
docker pull lmsysorg/sglang:dsv32

# MI350
docker pull lmsysorg/sglang:dsv32-rocm

# NPUs
docker pull lmsysorg/sglang:dsv32-a2
docker pull lmsysorg/sglang:dsv32-a3"><pre><code># H200
docker pull lmsysorg/sglang:dsv32

# MI350
docker pull lmsysorg/sglang:dsv32-rocm

# NPUs
docker pull lmsysorg/sglang:dsv32-a2
docker pull lmsysorg/sglang:dsv32-a3
</code></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="python -m sglang.launch_server --model deepseek-ai/DeepSeek-V3.2-Exp --tp 8 --dp 8 --page-size 64"><pre>python -m sglang.launch_server --model deepseek-ai/DeepSeek-V3.2-Exp --tp 8 --dp 8 --page-size 64</pre></div>

<p dir="auto">vLLM provides day-0 support of DeepSeek-V3.2-Exp. See the <a href="https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-V3_2-Exp.html" rel="nofollow">recipes</a> for up-to-date details.</p>

<p dir="auto">This repository and the model weights are licensed under the <a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/LICENSE">MIT License</a>.</p>

<div data-snippet-clipboard-copy-content="@misc{deepseekai2024deepseekv32,
      title={DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention}, 
      author={DeepSeek-AI},
      year={2025},
}"><pre><code>@misc{deepseekai2024deepseekv32,
      title={DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention}, 
      author={DeepSeek-AI},
      year={2025},
}
</code></pre></div>

<p dir="auto">If you have any questions, please raise an issue or contact us at <a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/service@deepseek.com">service@deepseek.com</a>.</p>
</article></div></div>
  </body>
</html>
