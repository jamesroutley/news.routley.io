<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.dolthub.com/blog/2022-09-02-a-trillion-prices/">Original</a>
    <h1>Health insurers just published close to a trillion hospital prices</h1>
    
    <div id="readability-page-1" class="page"><div data-cy="blog-post-text"><h2 id="health-insurers-just-published-close-to-a-trillion-hospital-prices"><a href="#health-insurers-just-published-close-to-a-trillion-hospital-prices" aria-label="health insurers just published close to a trillion hospital prices permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Health insurers just published close to a trillion hospital prices</h2>
<p>On July 1, insurance companies started dumping an absurd amount of data onto the internet. No one appreciates the scale of it.</p>
<p>I scraped the headers for hundreds of thousands of files from Humana, UnitedHealthcare, Aetna, and others. Compressed, the the sum total of the data they&#39;re offering up weighs in at around 100TB. That data, uncompressed, the data runs into the petabyte range, dwarfing the Library of Congress, the LibGen catalog, the full uncompressed English Wikipedia, and the entire HD Netflix Catalog — combined.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/912fc/sl-insurance.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="insurance" title="insurance" src="https://www.dolthub.com/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/ad12c/sl-insurance.png" srcset="/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/a48b3/sl-insurance.png 214w,
/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/47730/sl-insurance.png 428w,
/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/ad12c/sl-insurance.png 856w,
/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/7a18f/sl-insurance.png 1284w,
/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/56caf/sl-insurance.png 1712w,
/blog/static/d61faaf13a3499676a6ce8a3dd01e5ea/912fc/sl-insurance.png 1934w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<blockquote>
<p>Note: if you&#39;re inclined to reproduce this chart, you can do it yourself by running the <a href="https://github.com/alecstein/transparency-in-coverage-filesizes">scrapers I provided in this GitHub repo</a>. You can use it to get the file sizes you see above, as well as get URLs of all the files if you want to try to download some of them.</p>
</blockquote>
<h2 id="everything-has-a-price"><a href="#everything-has-a-price" aria-label="everything has a price permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Everything has a price</h2>
<p>In the newly-released data, each &#34;negotiated rate&#34; (or simply &#34;price&#34;) is associated with a lot of metadata, but it boils down to: who&#39;s paying, who&#39;s getting paid, what they&#39;re getting paid for, plus some extra fluff to keep track of versioning. The hundreds of billions of prices in the dataset (probably over a trillion) result from all the possible combinations of these things. Codes can have different types, or versions. Prices can have service codes. And so on.</p>
<p>And because prices change, the insurers release new versions of these 100TB files monthly.</p>
<!-- <details><summary>Click to see an example schema</summary>
```
REPORTING_ENTITY_NAME
REPORTING_ENTITY_TYPE
LAST_UPDATED_ON
VERSION
NPI
TIN
TYPE
NEGOTIATION_ARRANGEMENT
NAME
BILLING_CODE_TYPE
BILLING_CODE_TYPE_VERSION
BILLING_CODE
DESCRIPTION
NEGOTIATED_TYPE
NEGOTIATED_RATE
EXPIRATION_DATE
SERVICE_CODE
BILLING_CLASS
BILLING_CODE_MODIFIER
ADDITIONAL_INFO
BUNDLED_BILLING_CODE_TYPE
BUNDLED_BILLING_CODE_VERSION
BUNDLED_BILLING_CODE
BUNDLED_DESCRIPTION
```
</details> -->
<h2 id="fermi-math"><a href="#fermi-math" aria-label="fermi math permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fermi math</h2>
<p>I naively thought that insurers would be publishing the prices they negotiated with the 6,000 hospitals in the US. I was wrong.</p>
<p>A back-of-the-envelope calculation gets me a rough estimate of over 500B different prices, simply from counting how many prices are in each file, multiplying by the number of files. But this is just from the handful of insurers I scraped (and who were in compliance.) All told, the total number of prices could reach over a trillion.</p>
<p>That&#39;s because the data dumps include the negotiated rates with every entity that the insurance companies have contracts with. It&#39;s impossible to say how many there are without going through the &#34;in network&#34; files directly, but a cursory look suggests that there are millions.</p>
<p>Humana dumped <a href="https://developers.humana.com/Resource/PCTFilesList?fileType=innetwork">nearly half a million compressed CSV files</a> totaling 50TB compressed (~600TB uncompressed.) At around 70k prices per 9MB file, this translates into about 400 billion individual prices negotiated with different providers.</p>
<p>Other payers are similar in their largesse. On <a href="https://transparency-in-coverage.uhc.com/">UnitedHealthcare&#39;s page</a> they list over 55,000 individual files for download. Together these make up 9TB of compressed JSON, or around 250TB uncompressed. By estimating how many prices there are per GB of compressed JSON, I estimate they&#39;ve alone published around a 100 billion prices.</p>
<h2 id="too-much-of-a-good-thing"><a href="#too-much-of-a-good-thing" aria-label="too much of a good thing permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Too much of a good thing</h2>
<p>The industry <a href="https://www.healthcaredive.com/news/payers-employers-argue-price-transparency-push-wont-help-consumers/571393/">opposed releasing the data</a> under the new price-transparency law. In the past, <a href="https://hbr.org/2022/05/negotiating-lower-hospital-prices-as-a-self-insured-employer">it was nigh impossible for employers</a> to know how much their insurance companies agreed to pay. So in theory, employers can use the new data to get a better deal. But in order to use it, they&#39;ll need to get it. And that&#39;s the problem.</p>
<p>There&#39;s just <em>so much data.</em> To scrape the data you&#39;ll need to be sure to have a business-level fiber-optic connection that can handle 400Mbps, tens of thousands of dollars of disk space, and compute time to wrangle 90GB JSON blobs.</p>
<p>But maybe we can solve a simpler problem first.</p>
<h2 id="a-path-forward"><a href="#a-path-forward" aria-label="a path forward permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>A path forward</h2>
<p>Maybe we won&#39;t be able to get all this data into one database. (As an aside, it&#39;s not clear why the CMS, who helped write the law, didn&#39;t build this database themselves directly from the insurance company data.)</p>
<p>But we have options:</p>
<ul>
<li>For this database to be useful, we <strong>don&#39;t necessarily have to look at every procedure, nor every provider.</strong> Foregoing the extra information of them can cut down the space constraints by more than 100x.</li>
<li>Similarly, as we did in our past <a href="https://www.dolthub.com/bounties">data bounties</a>, like gathering prices from <a href="https://www.dolthub.com/blog/2022-07-01-hospitals-compliance/">nearly 2,000 hospitals</a>, we can <strong>spread out the effort and resources by running this as a distributed challenge.</strong></li>
<li><strong>We can make custom tools</strong> like <a href="https://github.com/dolthub/jsplit">this one for splitting huge JSON blobs into JSONL files</a>.</li>
<li><strong>We can filter down the NPIs (&#34;national provider identifier&#34;)</strong> to those major hospitals that we&#39;re interested in by using <a href="https://data.cms.gov/provider-data/">the CMS&#39;s own data.</a></li>
<li>We can <strong>limit ourselves to just those</strong> <a href="https://www.cms.gov/files/document/2019-12-03-hospital-presentation.pdf"><strong>70 codes required by the CMS</strong></a>.</li>
</ul>
<p>We think that this data deserves to be in the public hands and we&#39;re working on making it a possibility.</p>
<p>If you have comments, questions, or ideas — or just want to say hello — write me at <a href="mailto:alec@dolthub.com">alec@dolthub.com</a>.</p></div></div>
  </body>
</html>
