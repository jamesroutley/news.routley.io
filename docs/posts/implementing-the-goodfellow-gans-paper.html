<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ym2132.github.io/GenerativeAdversarialNetworks_Goodfellow">Original</a>
    <h1>Implementing the Goodfellow GANs paper</h1>
    
    <div id="readability-page-1" class="page"><div id="quarto-content">

<main id="quarto-document-content">




<hr/>
<p>Generative Adversarial Networks (GANs), discovered by Ian Goodfellow in 2014, were an early method in the area of generative AI. I will focus on image generation as set out in the paper Generative Adversarial Nets<a href="#1"><sup>1</sup></a>. This paper is the focal point of this blog post, and I will guide you through the implementation of the paper. After reading this I hope you understand GANs better and how to build them.</p>
<p>A small note, this blog post will attempt to show you my full process for understanding and implementing the paper. I try to include my entire thought process which leads up to the final code for the model, I hope you find this helpful. I will assume some prior background knowledge of deep learning techniques, e.g. what is an MLP<a href="#2"><sup>2</sup></a>, the basics of PyTorch<a href="#3"><sup>3</sup></a>.</p>
<p>The name Generative Adversarial Network tells us some of the story of this framework. In a GAN we have two models, which we pit against each other, the Generator (G) model and the Discriminator (D) model. The goal of G is to capture the distribution of the training data and then use this to generate samples (images in our case) from that distribution. Now what does it mean for a dataset of images to have a distribution, simply the images themselves have stastical properties. In an image typically neighbouring pixels have high correlation and distant have low correlation, in MNIST specifically there is a lot of straight lines and curves (as you’d expect in images). The G model is learning these statistical properties, hence learning the distribution and samples from this to generate new images.</p>
<p>On the other hand, the goal of D is to determine whether an image is from the training set distribution or the G distribution i.e. to detect if an image is real (a real image is one from the training set), or fake (an image from the generated set).</p>
<p>The training regime is as follows: the D model is trained to maximise the probability of assigning the correct label to both generated and training examples, the G model is trained to maximise the probabilty of D making a mistake (more on this later). Let’s now explore the journey I took to arrive at my final implementation!</p>
<section id="the-path-to-implementation">
<h2 data-anchor-id="the-path-to-implementation">The Path to Implementation</h2>
<p>A major point of initial confusion for me was the idea of training two neural networks simultaneously and the mechanics of this. So, first I trained just one neural network, namely the Discriminator model. I figured that if I can get a D model which could classify between generated random noise images and real images, it would build my underlying understanding of the GAN and how to create the training loop. To get started with this lets first define the D and G models. We will only train D we will not update the parameters of G.</p>
<p>This idea came from examining Algorithm 1 provided in the paper:</p>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/767ddf10-1-image.png"/></p>
<figcaption>Algorithm 1</figcaption>
</figure>
</div>
<p>We see in Algorithm 1 we have two gradient updates, initially to get our heads around the problem lets simply update the generator only.</p>
<hr/>
<p><b>Heads up</b> The following is an insight into my process of understanding the paper. My hope is to provide some insight into my process, feel free to skip ahead to the <a href="#skip">actual implemenation</a>.</p>
<hr/>
<section id="simple-generator">
<h3 data-anchor-id="simple-generator">Simple Generator</h3>
<p>First, let’s get all the admin stuff out the way ;)</p>
<div id="8bf5f2b1" data-execution_count="41">
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span># All the imports required for this implementation</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span>import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span>import</span> torchvision</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span>import</span> torch.nn <span>as</span> nn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span>import</span> torchvision.transforms <span>as</span> transforms</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span>from</span> torch.utils.data <span>import</span> TensorDataset, ConcatDataset, random_split, DataLoader, Dataset</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span>import</span> numpy <span>as</span> np</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span># We can make use of a GPU if you have one on your computer. This works for Nvidia and M series GPU&#39;s</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span>if</span> torch.backends.mps.is_available():</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    device <span>=</span> torch.device(<span>&#34;mps&#34;</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span># These 2 lines assign some data on the memory of the device and output it. The output confirms</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span># if we have set the intended device</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    x <span>=</span> torch.ones(<span>1</span>, device<span>=</span>device)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span>print</span> (x)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span>elif</span> torch.backends.cuda.is_built():</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    device <span>=</span> torch.device(<span>&#34;cuda&#34;</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    x <span>=</span> torch.ones(<span>1</span>, device<span>=</span>device)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span>print</span> (x)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span>else</span>:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    device <span>=</span> (<span>&#34;cpu&#34;</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    x <span>=</span> torch.ones(<span>1</span>, device<span>=</span>device)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span>print</span> (x)</span></code></pre></div>
<div>
<pre><code>tensor([1.], device=&#39;mps:0&#39;)</code></pre>
</div>
</div>
<p>I define a simple G which takes an input of size 1 and returns an image which is just random noise. In the paper it is stated that the input to G is random noise, here I choose a number from a Normal distribution as my noise and for this instance of G I set the input size to 1. Also, the ReLU layer’s in this model come from the paper, despite the actual model architecture not being specified, they state it was a a Multi-Layer Perceptron (MLP) for both D and G. For G I use a simple two layer MLP with ReLU between the layers, I also employ a tanh for the output layer. The tanh ensures the output values are between [-1, 1] this keeps our pixel values in the same range as the actual mnist data. Note, in the paper the G uses ReLU and Signmoid but I opt for Tanh as it works better.</p>
<hr/>
<p>This is a common theme when implementing papers, you have to use your intuition when deciding the architecture and piece together the puzzle the best you can from the hints given in the paper. The papers are often incomplete in their description of the techniques used, the best way to build your intuition is doing it repeatedly and not being afraid to try different things.</p>
<hr/>
<p>To finish off, the actual output of the model must be converted to a matrix. I chose to do this inside the forward function and I include my own implementation as well as the PyTorch way. Uncomment my code to play around with it, it currently only works when the input has dimensions [1] (I leave it up to you to try and implement this to work with inputs which have more than 1 image). The reason being is that I do not handle the batch dimension, to do so you’d need another for loop.</p>
<div id="262ddde1" data-execution_count="54">
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span># The following code block is a simple way to define neural networks in PyTorch.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span># We init the layers and then pass x through these layers in the forward pass.</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span>class</span> Generator(nn.Module): </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__init__</span>(<span>self</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span>super</span>().<span>__init__</span>()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear1 <span>=</span> nn.Linear(<span>1</span>, <span>256</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu1 <span>=</span> nn.ReLU()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear2 <span>=</span> nn.Linear(<span>256</span>, <span>784</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.tanh <span>=</span> nn.Tanh()</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span>def</span> forward(<span>self</span>, x):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear1(x)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu1(x)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear2(x)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.tanh(x)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span># Need to convert the output vector x to a matrix</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span># Note this is my way of doing the conversion, there are much better ways to do this</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span># but, implementing it by hand may give you some insights into what is happening on line 40</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span>&#39;&#39;&#39;</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span>        g_out_mat = torch.zeros(1, 28, 28)</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span>        m = 0</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span>        n = 0</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span>        for i in range(len(x)):</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span>            if i % 28 == 0 and i != 0:</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span>                m += 1</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span>                n = 0</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span>            g_out_mat[0, m, n] = x[i]</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span>            n += 1</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span>        &#39;&#39;&#39;</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        <span># A simpler way to reshape the output to a 28x28 matrix</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span># We use -1 as the first dim as it tells PyTorch to automatically calculate the correct size for x</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span># i.e. the batch size. Try out a different value and see what happens. Functionally it is equivalent to</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span># putting x.size(0)</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> x.view(<span>-</span><span>1</span>, <span>28</span>, <span>28</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        <span>return</span> x</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>generator <span>=</span> Generator()</span></code></pre></div>
</div>
<p>Now lets generate a random noise sample and show what this model outputs!</p>
<div id="d9f73b8c" data-execution_count="55">
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span># Set mu and sigma for our Normal distrubiton and sample one value from the distribution</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>mu, sigma <span>=</span> <span>0</span>, <span>1</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>noise_value <span>=</span> np.random.normal(mu, sigma, <span>1</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span># The input to our network has to be a tensor datatype, in this case it just has one value</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>g_in <span>=</span> torch.tensor(noise_value, dtype<span>=</span>torch.float32)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span># We do the forward pass on the input</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>g_out <span>=</span> generator(g_in)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span># This is a small function to display the output</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span>def</span> imshow(img):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    img <span>=</span> img <span>/</span> <span>2</span> <span>+</span> <span>0.5</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    npimg <span>=</span> img.numpy()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    plt.imshow(np.transpose(npimg, (<span>1</span>, <span>2</span>, <span>0</span>)))</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>imshow(g_out.detach().cpu()), torch.Tensor([<span>0</span>])</span></code></pre></div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-4-output-1.png"/></p>
</figure>
</div>
</div>
</div>
<p>We see that the image is completely random and has no patterns, which is exactly what we wanted. Now, when training the D model, we must train on both generated and real images. I was unsure on how to do this in practice, but we can use a hack in this case. Lets supplement the MNIST dataset with 60k generated images, i.e. create a 50/50 split on generated/real images.</p>
<p>This method is not what we use to train the actual network, as in the actual training loop we must provide newly generated samples at each epoch (the generator is improving so we want the new samples to be better at fooling the discriminator). But, for now lets stick with it!</p>
<div id="d9355075" data-scrolled="false" data-execution_count="56">
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span># Lets first generate 70k noise numbers from the normal dist</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>noise_tensor <span>=</span> torch.randn(<span>70000</span>, <span>1</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span># Will pass each of these to the model to give us 70k noisy images</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span>with</span> torch.no_grad():</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    gen_images <span>=</span> generator(noise_tensor)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    gen_images <span>=</span> gen_images.unsqueeze(<span>1</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>gen_labels <span>=</span> torch.zeros((<span>70000</span>, <span>1</span>))  <span># We init a list of 70k labels which are all 0. 0 means generated image</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>gen_labels <span>=</span> [<span>0</span>] <span>*</span> <span>70000</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span># Lets show an example of what we just generated</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>imshow(gen_images[<span>0</span>].detach()), gen_labels[<span>0</span>]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span>print</span>(<span>f&#34;Dimension of generated images Tensor: </span><span>{</span>gen_images<span>.</span>shape<span>}</span><span>&#34;</span>)</span></code></pre></div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-5-output-1.png"/></p>
</figure>
</div>
</div>
<div>
<pre><code>Dimension of generated images Tensor: torch.Size([70000, 1, 28, 28])</code></pre>
</div>
</div>
<p>As we wanted we get a random image just as before, only now we have 70000 of them. The next step is to add these to the original MNIST dataset. We do this as follows: create a PyTorch dataset of the generated images and their labels, create a train/test split (matching MNIST train/test split size) of the generated dataset and then finally combine the MNIST and Generated dataset together. Take a look at how this is done!</p>
<div id="7d390f23" data-execution_count="57">
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span># First we need to load in the MNIST dataset. The following code is a standard way to download PyTorch</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span># datasets</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>batch_size <span>=</span> <span>32</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span># We normalise the images and convert them to tensors.</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>transform <span>=</span> transforms.Compose([</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span>0.5</span>,), (<span>0.5</span>,)),</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span># Load both MNIST test and train sets</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>mnist_train <span>=</span> torchvision.datasets.MNIST(</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    root<span>=</span><span>&#39;./Data&#39;</span>,</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    train<span>=</span><span>True</span>,</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    download<span>=</span><span>True</span>,</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    transform<span>=</span>transform,</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>mnist_test <span>=</span> torchvision.datasets.MNIST(</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    root<span>=</span><span>&#39;./Data&#39;</span>,</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    train<span>=</span><span>False</span>,</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    download<span>=</span><span>True</span>,</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    transform<span>=</span>transform</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span># For our example we are classifying if an image is from MNIST or the generated set, so we assign all examples</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span># from MNIST with the label 1</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>mnist_train.targets <span>=</span> torch.ones_like(mnist_train.targets, dtype<span>=</span>torch.float32)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>mnist_test.targets <span>=</span> torch.ones_like(mnist_train.targets, dtype<span>=</span>torch.float32)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span># In PyTorch we can use DataLoader class to instantiate an iterator which will efficiently pass data to the </span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span># network</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>train_loader <span>=</span> torch.utils.data.DataLoader(</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    mnist_train, </span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    shuffle<span>=</span><span>True</span>,</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    batch_size<span>=</span>batch_size,</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>test_loader <span>=</span> torch.utils.data.DataLoader(</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    mnist_test,</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    shuffle<span>=</span><span>True</span>,</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    batch_size<span>=</span>batch_size,</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span># </span><span>TODO</span><span>: We never use the train/test split why not just train with all data?</span></span></code></pre></div>
</div>
<p>Above we load the actual MNIST dataset and now we combine the real MNIST images and the generated images.</p>
<div id="08e88924" data-execution_count="58">
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span># Create a custom dataset class which allows us to keep the labels as integers to match the MNIST data</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span># The datatype for MNIST labels is integers, if we do not define a custom dataset class the label types</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span># will not match up so this is necessary for the code to work</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span>class</span> CustomTensorDataset(Dataset):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;&#34;&#34;Dataset wrapping tensors and integer labels.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span>    Arguments:</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span>        tensors (Tensor): contains sample data.</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span>        labels (list of int): contains sample labels.</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span>    &#34;&#34;&#34;</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__init__</span>(<span>self</span>, tensors, labels):</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span>assert</span> tensors.size(<span>0</span>) <span>==</span> <span>len</span>(labels)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.tensors <span>=</span> tensors</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.labels <span>=</span> labels</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__getitem__</span>(<span>self</span>, index):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span>return</span> <span>self</span>.tensors[index], <span>self</span>.labels[index]</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__len__</span>(<span>self</span>):</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span>return</span> <span>self</span>.tensors.size(<span>0</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>gen_dataset <span>=</span> CustomTensorDataset(gen_images, gen_labels)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span># Create the train/test split of the generated dataset</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>train_size <span>=</span> <span>60000</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>test_size <span>=</span> <span>10000</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>gen_train_dataset, gen_test_dataset <span>=</span> random_split(gen_dataset, [train_size, test_size])</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span># Combine MNIST and the generated dataset</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>comb_train_dataset <span>=</span> ConcatDataset([mnist_train, gen_train_dataset])</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>comb_test_dataset <span>=</span> ConcatDataset([mnist_test, gen_test_dataset])</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span># Create DataLoaders for the combined datasets</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>comb_train_loader <span>=</span> DataLoader(comb_train_dataset, batch_size<span>=</span><span>64</span>, shuffle<span>=</span><span>True</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>comb_test_loader <span>=</span> DataLoader(comb_test_dataset, batch_size<span>=</span><span>64</span>, shuffle<span>=</span><span>False</span>)</span></code></pre></div>
</div>
</section>
<section id="simple-discriminator">
<h3 data-anchor-id="simple-discriminator">Simple Discriminator</h3>
<p>Now the dataset is ready to go so let’s build the classifier, AKA the Discrimanator model.</p>
<p>The D model is another MLP network. The input is one or more image/s and the output is a binary classification, 1 for a real image and 0 for a generated image. Again I define a somewhat arbitrary network structure, as in the case of the G model, and I once again advise you that this is a skill you will develop by trying different things when implementing these papers. In the paper it is stated that maxout activations are used, but I use ReLU and Sigmoid there isn’t a big reason why other than that it works! I understand this answer may not be satisfactory, but when implementing papers we have to test multiple avenues and find what works. I’ve found this to be the best approach for me. As I said before one of the goals is to build your intuition and it is only done through trial and error. A tip, if something doesn’t make sense like maxout activations or seems unfamiliar use something which is familiar and see if it works, sometimes you may even get better results!</p>
<p>To wrap up, our D model is a simple 2 layer MLP and acts as a binary classifier.</p>
<div id="d9cd5ea1" data-execution_count="59">
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span>class</span> Discriminator(nn.Module): </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__init__</span>(<span>self</span>):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span>super</span>().<span>__init__</span>()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear1 <span>=</span> nn.Linear(<span>784</span>, <span>256</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu1 <span>=</span> nn.ReLU()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.dropout1 <span>=</span> nn.Dropout(<span>0.5</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear2 <span>=</span> nn.Linear(<span>256</span>, <span>1</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.dropout2 <span>=</span> nn.Dropout(<span>0.5</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span># Use sigmoid to ensure output is a probability for the loss function</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.sigmoid <span>=</span> nn.Sigmoid()</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span>def</span> forward(<span>self</span>, x):</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear1(x)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu1(x)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.dropout1(x)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear2(x)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.sigmoid(x)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span>return</span> x</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>discriminator <span>=</span> Discriminator()</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span># We also send our device to the &#34;device&#34;, i.e. the GPU if available</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>discriminator.to(device)</span></code></pre></div>
<div data-execution_count="59">
<pre><code>Discriminator(
  (linear1): Linear(in_features=784, out_features=256, bias=True)
  (relu1): ReLU()
  (dropout1): Dropout(p=0.5, inplace=False)
  (linear2): Linear(in_features=256, out_features=1, bias=True)
  (dropout2): Dropout(p=0.5, inplace=False)
  (sigmoid): Sigmoid()
)</code></pre>
</div>
</div>
</section>
<section id="training-the-noise-classifier">
<h3 data-anchor-id="training-the-noise-classifier">Training the Noise Classifier</h3>
<p>Now we can get to the fun stuff and train our noise classifier (the D model), I call it this as we will be classifying between real images and the generated images which are noise.</p>
<p>First, we must choose our loss function. I use the Binary Cross Entropy Loss here, it the binary equivalent of Cross Entropy Loss. Cross Entropy Loss is a good metric for classification problems and when you implement different papers in the deep learning space you’ll come across it alot. For our purposes we just need to know it is our loss function, i.e. how good or bad our model is performing. Next we initialise our optimizer, I’ll skip over the details of this here<a href="#4"><sup>4</sup></a> (I may or may not make a post explaining all the moving parts of the training loop).</p>
<div id="d8ed7c97" data-execution_count="60">
<div id="cb11"><pre><code><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>criterion <span>=</span> nn.BCELoss()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>optimizer <span>=</span> torch.optim.SGD(discriminator.parameters(), lr<span>=</span><span>0.05</span>, momentum<span>=</span><span>0.9</span>)</span></code></pre></div>
</div>
<p>Next we setup the training loop, I have added comments to describe the role of each piece of the loop.</p>
<div id="0d0ce36d" data-scrolled="true" data-execution_count="25">
<div id="cb12"><pre><code><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span># An epoch just means 1 iteration, here we train for only 3 iterations. You&#39;ll see the model converges quickly</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span># This is becuase the task is so simple</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span>for</span> epoch <span>in</span> <span>range</span>(<span>3</span>):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span># Running loss keeps track of the loss at each forward/backward pass of the network, we use it to calculate</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span># average loss of the network on each epoch</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    running_loss <span>=</span> <span>0.0</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span># .train() sets the model to train mode, this is PyTorch behavior. You see later we have .eval() both these </span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span># methods change properties of some layers in the network.</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    discriminator.train()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span># We iterate over each batch in the train_loader</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span>for</span> i, data <span>in</span> <span>enumerate</span>(comb_train_loader, <span>0</span>):</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span># data is a tuple of inputs, labels so we split them up</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        inputs, labels <span>=</span> data        </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        <span># Flatten the input, it is current a tensor of dimension (batch_size, 28, 28) </span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        <span># the first layer of the network expects a 784 length vector so after flattening </span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span># dimension is (batch_size, 784)</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        inputs <span>=</span> torch.flatten(inputs, start_dim<span>=</span><span>1</span>)        </span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span># Push the inputs and labels to the GPU if available</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        inputs, labels <span>=</span> inputs.to(device), labels.to(device)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span># Zero the gradients of the optimizer, this is standard in training loops</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        <span># it ensures our gradient steps are not too large</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>        <span># Perform the forward pass on our data</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>        outputs <span>=</span> discriminator(inputs)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>        <span># Ensure outputs and labels have the same shape</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>        labels <span>=</span> labels.unsqueeze(<span>1</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>        labels <span>=</span> labels.<span>float</span>()</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>        <span># Calculate the loss of our network, i.e. how good/bad were it&#39;s prediction</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>        loss <span>=</span> criterion(outputs, labels)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>        <span># Using the loss perform backpropagation</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        <span># Using the calculated gradients bump the parameters of the model</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        running_loss <span>+=</span> loss.item() </span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>    <span># Print the average loss for the epoch</span></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>    <span>print</span>(<span>f&#39;Epoch [</span><span>{</span>epoch <span>+</span> <span>1</span><span>}</span><span>] loss: </span><span>{</span>running_loss <span>/</span> <span>len</span>(train_loader)<span>:.3f}</span><span>&#39;</span>)</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    running_loss <span>=</span> <span>0.0</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    <span># As before we set the model to eval mode</span></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    discriminator.<span>eval</span>()</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    correct <span>=</span> <span>0</span></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    total <span>=</span> <span>0</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>    <span># Since we&#39;re not training, we don&#39;t need to calculate the gradients for our outputs</span></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>    <span>with</span> torch.no_grad():</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>        <span># Perform a forward pass on the network and calculate the loss</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>        <span># When evaluating we do not need to calculate gradients or perform a step</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>        <span>for</span> data <span>in</span> comb_test_loader:</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>            images, labels <span>=</span> data</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>            images <span>=</span> torch.flatten(images, start_dim<span>=</span><span>1</span>)</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>            labels <span>=</span> labels.unsqueeze(<span>1</span>)</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>            labels <span>=</span> labels.<span>float</span>()</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>            <span># Push images and labels to gpu</span></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>            images, labels <span>=</span> images.to(device), labels.to(device)</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>            <span># calculate outputs by running images through the network</span></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>            outputs <span>=</span> discriminator(images)</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>            <span># As we have 2 classes we interpret any prediction above 0.5 as a 1 and below a 0</span></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>            predicted <span>=</span> (outputs <span>&gt;</span> <span>0.5</span>).<span>float</span>()  <span># Convert probabilities to binary predictions</span></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>            correct <span>+=</span> (predicted <span>==</span> labels).<span>sum</span>().item()</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>    test_accuracy <span>=</span> <span>100</span> <span>*</span> correct <span>/</span> <span>len</span>(comb_test_dataset)</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>    <span>print</span>(<span>f&#39;Accuracy: </span><span>{</span>test_accuracy<span>:.2f}</span><span>%&#39;</span>)</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a><span>print</span>(<span>&#39;Finished Training&#39;</span>)</span></code></pre></div>
<div>
<pre><code>Epoch [1] loss: 0.001
Accuracy: 100.00%
Epoch [2] loss: 0.000
Accuracy: 100.00%
Epoch [3] loss: 0.000
Accuracy: 100.00%
Finished Training</code></pre>
</div>
</div>
<p>Observing the accuracy of the network we see 100% accuracy, this may be alarming at first but given the nature of the task it makes sense. It’s a very simple task and the network is doing well, we can verify if it works by generating a new random sample and checking the output of the network.</p>
<div id="9e0f8ed7" data-execution_count="26">
<div id="cb14"><pre><code><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>noise_value <span>=</span> np.random.normal(<span>0</span>, <span>1</span>, <span>1</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>g_in <span>=</span> torch.tensor(noise_value, dtype<span>=</span>torch.float32)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>g_out <span>=</span> generator(g_in)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>g_out <span>=</span> g_out.to(device)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>discriminator(torch.flatten(g_out, start_dim<span>=</span><span>1</span>))</span></code></pre></div>
<div data-execution_count="26">
<pre><code>tensor([[3.6444e-09]], device=&#39;mps:0&#39;, grad_fn=&lt;SigmoidBackward0&gt;)</code></pre>
</div>
</div>
<p>The output is very small, which means the model correctly classified the input as a generated image.</p>
<p>Success! We now have a generator which generates random images and a discriminator which can determine between generated and real images. But wait, what does this have to do with GANs? Well, the goal of a GAN is to train a D model to detect generated images and a G model to generate good generated images (or to fool the D model). What we have done above is the first step in the back and forth process, we have created a D model which can detect the poorly generated images.</p>
<hr/>

</section>
</section>
<section id="the-generative-adversarial-network">
<h2 data-anchor-id="the-generative-adversarial-network">The Generative Adversarial Network</h2>
<p>Now lets extend this to implement the GAN proper!</p>
<p>From section 3 in the paper, the goal in training our two networks is to:</p>
<p><span>\[ \min \log(D(x)) \tag{1}\]</span> <span>\[ \max \log(D(G(z))) \tag{2}\]</span></p>
<p>What the <span>\(D()\)</span> and <span>\(D(G())\)</span> actually refer to are the outputs of the model, however we do not mean the raw outputs but rather the output after being passed through the loss function.</p>
<p>So in (1) we are dealing with the D model and we are minimising the loss function of the D model. The input x consists of both real and generated images. This means we want the D model to get its classifications between generated and real images correct, we want the D model to become a better classifier.</p>
<p>Then in (2), we are maximising the loss of the discriminator when the inputs are generated images. The input to D is G(z), where z is random noise and G(z) being generated images. So, the loss of D(G(z)) will be high when the discriminator incorrectly classifies the generated images as real images and this is exactly what we want. Now, in practice we flip the labels of the generated images (so they have label 1 instead of 0), this allows us to turn this into a minimisation problem where we want D to classify our generated images as real. The flipping of labels and transformation to a minimisation problem also presents better gradient properties, meaning we get a better model<a href="#5"><sup>5</sup></a>.</p>
<hr/>
<section id="the-new-d-and-g-models">
<h3 data-anchor-id="the-new-d-and-g-models">The new D and G models</h3>
<p>Now we understand the training regime of our GAN, how do we go about implementing it? Given the nature of our task it lends us well to increase the complexity of our D and G models (they are still MLPs), I will redefine them below. My models here worked well, but feel free to add/remove layers and make your own changes and see how the output changes. Despite the changes to the models, the key differences come in the form of the new training loop.</p>
<p>The D model now has 4 linear layers with dropout and ReLU being applied to layers 1-3 and the output of layer 4 is passed through a Sigmoid function. This scheme arises from the paper where it is stated in section 5:</p>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/5306fe85-1-image.png"/></p>
<figcaption>Architectural hints</figcaption>
</figure>
</div>
<p>Here instead of maxout activations we use ReLU within layers and Sigmoid for the output to ensure comptability with our BCE loss.</p>
<div id="c455b1db" data-execution_count="61">
<div id="cb16"><pre><code><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span># Note the layer size choice is arbitrary in that I have no good reason for choosing it other than</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span># that it works. This is why I advise you to play around with, e.g. see what happens if the first layer</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span># is nn.Linear(784, 256) etc.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span>class</span> Discriminator(nn.Module): </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__init__</span>(<span>self</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span>super</span>().<span>__init__</span>()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear1 <span>=</span> nn.Linear(<span>784</span>, <span>1024</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu1 <span>=</span> nn.ReLU()</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.dropout1 <span>=</span> nn.Dropout(<span>0.3</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear2 <span>=</span> nn.Linear(<span>1024</span>, <span>512</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu2 <span>=</span> nn.ReLU()</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.dropout2 <span>=</span> nn.Dropout(<span>0.3</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear3 <span>=</span> nn.Linear(<span>512</span>, <span>256</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu3 <span>=</span> nn.ReLU()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.dropout3 <span>=</span> nn.Dropout(<span>0.3</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear4 <span>=</span> nn.Linear(<span>256</span>, <span>1</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        <span># Use sigmoid to ensure output is a probability</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.sigmoid <span>=</span> nn.Sigmoid()</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    <span>def</span> forward(<span>self</span>, x):</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span># We transform the input of (batch_size, 28, 28) to (batch_size, 784)</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> x.view(x.size(<span>0</span>), <span>784</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear1(x)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu1(x)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.dropout1(x)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear2(x)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu2(x)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.dropout2(x)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear3(x)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu3(x)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.dropout3(x)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear4(x)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.sigmoid(x)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>        <span>return</span> x</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>discriminator <span>=</span> Discriminator().to(device)</span></code></pre></div>
</div>
<p>Similarily, the G model has 4 linear layers and it takes as input a vector of length 100. The change from input size 1 to 100 is another choice driven by empirical evidence, I’m not entirely sure why it works but my intuition is that as the task is more complex the higher dimensionality aids learning. Mess around with the size and see what happens if you make it smaller or bigger, be aware that it’s usually the case that the input size is smaller than what we are trying to generate (784 in this case).</p>
<div id="34f90d57" data-execution_count="62">
<div id="cb17"><pre><code><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span>class</span> Generator(nn.Module): </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span>def</span> <span>__init__</span>(<span>self</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>        <span>super</span>().<span>__init__</span>()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear1 <span>=</span> nn.Linear(<span>100</span>, <span>256</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu1 <span>=</span> nn.ReLU()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear2 <span>=</span> nn.Linear(<span>256</span>, <span>512</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu2 <span>=</span> nn.ReLU()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear3 <span>=</span> nn.Linear(<span>512</span>, <span>1024</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.relu3 <span>=</span> nn.ReLU()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.linear4 <span>=</span> nn.Linear(<span>1024</span>, <span>784</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span>self</span>.tanh <span>=</span> nn.Tanh()</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span>def</span> forward(<span>self</span>, x):</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear1(x)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu1(x)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear2(x)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu2(x)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear3(x)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.relu3(x)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.linear4(x)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> <span>self</span>.tanh(x)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>        <span># Reshape the output from (batch_size, 784) to a (batch_size, 28, 28) matrix</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>        x <span>=</span> x.view(x.size(<span>0</span>), <span>1</span>, <span>28</span>, <span>28</span>)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        <span>return</span> x</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>generator <span>=</span> Generator().to(device)</span></code></pre></div>
</div>
<p>Here we go we’re at the crux of the implementation the training loop, let’s dive right in!</p>
<div id="b5f062d1" data-execution_count="63">
<div id="cb18"><pre><code><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span># As before we use the Binary Cross Entropy Loss</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>criterion <span>=</span> nn.BCELoss()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span># Intialise two optimisers, we use the Adam optimiser as it performs better than Stochastic Gradient Descent,</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span># however this will work if you use Stochastic Gradient Descent as in the paper (just replace .Adam with .SGD)</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>optimizer_D <span>=</span> torch.optim.Adam(discriminator.parameters(), lr<span>=</span><span>0.0001</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>optimizer_G <span>=</span> torch.optim.Adam(generator.parameters(), lr<span>=</span><span>0.0001</span>)</span></code></pre></div>
</div>
<p>Let’s look at algorithm 1 again. In algo 1 there are two loops, one lines up with ours the outer loop represents the number of epochs however we do not include the inner loop from algo 1. Our inner loop is simply iterating over our dataset and updating the model in batches. In algo 1 the inner loop has k=1 so in practice we can ignore it. The rest of algo 1 lines up with our code pretty nicely. Let’s break down each step in the algorithm and it’s representation in python:</p>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/47c02a4d-1-image-5.png"/></p>
<figcaption>Algorithm 1</figcaption>
</figure>
</div>
<p>I have numbered the key parts of Algorithm 1 and will refer to these numbers here for brevity.</p>
<p><strong>1</strong> - Corresponds to the number of training iterations or the number of epochs, so line 4 in the next code block. We run our training loop for 50 epochs, feel free to run for more/less and observe the changes in the generated images.</p>
<p><strong>2</strong> - Is the loop we ignore as k=1.</p>
<p><strong>3</strong> - Here we are simply generating our $ z $ inputs (the noise) for the G model. In line 11 of the code, we generate the tensor of noise inputs and then in line 13 we pass these to the G model to create the generated images.</p>
<p><strong>4</strong> - This step is implemented across a few lines. The algortihm does not use batches, but we do this leads to a small change in our code. Lines 5 and 6 handle the selection of the batch of data. We then need to combine these images with the generated images, the combined images will be our input to the D model. The combining of images is handled in lines 16, 17, 20, 21, 24, 25 and 26.</p>
<p><strong>5</strong> - Lines 29 - 33 handle the updating of the model. We calculate the output of the D model and update it’s parameter appropriately.</p>
<p><strong>6</strong> - We sample a new tensor of noise input in line 36 and generate the images in line 40.</p>
<p><strong>7</strong> - Lines 43 - 46 handle this, we pass the newly generated images to the updated discriminator model and then bump the gradient based on the loss of the discriminator</p>
<p>Thats it! We have implemented the training algorithm from the paper, all that’s left is to run the code and look at out results :)</p>
<div id="bbf59c97" data-scrolled="true" data-execution_count="53">
<div id="cb19"><pre><code><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span># Whenever you see a .to(device) it means we are sending that data to the GPU memory</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span># We now run the training for 50 epochs</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span>for</span> epoch <span>in</span> <span>range</span>(<span>50</span>):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span>for</span> i, data <span>in</span> <span>enumerate</span>(train_loader):</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        real_images, _ <span>=</span> data  <span># We dont care about the MNIST labels we generate a vector of all 1s to</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>                               <span># simulate them</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        real_images <span>=</span> real_images.to(device)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span># Sample from noise and generate the fake images</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        noise_tensor <span>=</span> torch.randn((batch_size, <span>100</span>)).to(device)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span>with</span> torch.no_grad():</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            gen_images <span>=</span> generator(noise_tensor)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span># Create the real and fake labels</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        gen_labels <span>=</span> torch.zeros((batch_size, <span>1</span>)).to(device)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        real_labels <span>=</span> torch.ones((batch_size, <span>1</span>)).to(device)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span># Concat fake and real images</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        combined_images <span>=</span> torch.cat((real_images, gen_images))</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        combined_labels <span>=</span> torch.cat((real_labels, gen_labels))</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span># shuffle the combined batch to prevent the model from learning order</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        indices <span>=</span> torch.randperm(combined_images.size(<span>0</span>))</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        combined_images <span>=</span> combined_images[indices]</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        combined_labels <span>=</span> combined_labels[indices]</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>                        </span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        <span># First update the D model</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        discriminator.zero_grad()</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        d_outputs_combined <span>=</span> discriminator(combined_images)  </span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>        loss_d <span>=</span> criterion(d_outputs_combined, combined_labels)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        loss_d.backward()</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        optimizer_D.step()</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        <span># Generate new images for updating G</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        noise_tensor <span>=</span> torch.randn((batch_size, <span>100</span>)).to(device)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        <span># Next update the G model, </span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        generator.zero_grad()</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        gen_images <span>=</span> generator(noise_tensor)  <span># Gen new images for training G</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        <span># For generator updating we need the labels for generated images to be 1&#39;s to fool the discriminator</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>        <span># We do this by just passing the real_labels to the loss function</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        <span># Note we use the D model, the equation in the paper is max log(D(G(z))) and we already have G(z)</span></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        d_outputs_generated <span>=</span> discriminator(gen_images)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        loss_g <span>=</span> criterion(d_outputs_generated, real_labels)</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        loss_g.backward()</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        optimizer_G.step()</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>        <span>if</span> i <span>==</span> batch_size<span>-</span><span>1</span>:  </span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>            <span>print</span>(<span>f&#39;Epoch </span><span>{</span>epoch<span>}</span><span>: Loss_D: </span><span>{</span>loss_d<span>.</span>item()<span>}</span><span>, Loss_G: </span><span>{</span>loss_g<span>.</span>item()<span>}</span><span>&#39;</span>)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>            imshow(torchvision.utils.make_grid(gen_images.cpu()))</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span>print</span>(<span>&#34;Training complete&#34;</span>)</span></code></pre></div>
<div>
<pre><code>Epoch 0: Loss_D: 0.5401761531829834, Loss_G: 0.5183898210525513
Epoch 1: Loss_D: 0.1499895453453064, Loss_G: 5.324292182922363
Epoch 2: Loss_D: 0.025092430412769318, Loss_G: 3.794947385787964
Epoch 3: Loss_D: 0.021893952041864395, Loss_G: 6.434882164001465
Epoch 4: Loss_D: 0.07149051129817963, Loss_G: 8.799638748168945
Epoch 5: Loss_D: 0.1581605076789856, Loss_G: 4.5844831466674805
Epoch 6: Loss_D: 0.23052126169204712, Loss_G: 3.3655669689178467
Epoch 7: Loss_D: 0.26046210527420044, Loss_G: 2.545144557952881
Epoch 8: Loss_D: 0.2686162292957306, Loss_G: 2.548086643218994
Epoch 9: Loss_D: 0.2686983346939087, Loss_G: 1.6180634498596191
Epoch 10: Loss_D: 0.3472312390804291, Loss_G: 1.6022381782531738
Epoch 11: Loss_D: 0.30659836530685425, Loss_G: 1.4573436975479126
Epoch 12: Loss_D: 0.38582366704940796, Loss_G: 1.4528765678405762
Epoch 13: Loss_D: 0.5046684741973877, Loss_G: 1.5923973321914673
Epoch 14: Loss_D: 0.45513787865638733, Loss_G: 1.1574714183807373
Epoch 15: Loss_D: 0.39396199584007263, Loss_G: 1.257398009300232
Epoch 16: Loss_D: 0.4915952682495117, Loss_G: 1.2052321434020996
Epoch 17: Loss_D: 0.5572727918624878, Loss_G: 1.6261529922485352
Epoch 18: Loss_D: 0.47256916761398315, Loss_G: 1.25663161277771
Epoch 19: Loss_D: 0.47100916504859924, Loss_G: 1.1608779430389404
Epoch 20: Loss_D: 0.5367802381515503, Loss_G: 1.1478102207183838
Epoch 21: Loss_D: 0.5882614850997925, Loss_G: 1.1012860536575317
Epoch 22: Loss_D: 0.6434062719345093, Loss_G: 0.8529677987098694
Epoch 23: Loss_D: 0.5590254664421082, Loss_G: 1.146052598953247
Epoch 24: Loss_D: 0.5280067920684814, Loss_G: 1.077160358428955
Epoch 25: Loss_D: 0.5576744079589844, Loss_G: 1.108898639678955
Epoch 26: Loss_D: 0.5741003155708313, Loss_G: 1.0328296422958374
Epoch 27: Loss_D: 0.5455783605575562, Loss_G: 1.0831691026687622
Epoch 28: Loss_D: 0.5194895267486572, Loss_G: 1.1595090627670288
Epoch 29: Loss_D: 0.6039822101593018, Loss_G: 0.9630967974662781
Epoch 30: Loss_D: 0.5976564884185791, Loss_G: 0.9659303426742554
Epoch 31: Loss_D: 0.5610702633857727, Loss_G: 0.9479303956031799
Epoch 32: Loss_D: 0.48189422488212585, Loss_G: 0.9485967755317688
Epoch 33: Loss_D: 0.5847359299659729, Loss_G: 0.9069305658340454
Epoch 34: Loss_D: 0.5342729091644287, Loss_G: 0.9326433539390564
Epoch 35: Loss_D: 0.5249197483062744, Loss_G: 1.2315685749053955
Epoch 36: Loss_D: 0.6528917551040649, Loss_G: 1.1090407371520996
Epoch 37: Loss_D: 0.5926652550697327, Loss_G: 0.9224941730499268
Epoch 38: Loss_D: 0.5641552209854126, Loss_G: 1.0132805109024048
Epoch 39: Loss_D: 0.5224989652633667, Loss_G: 1.0145323276519775
Epoch 40: Loss_D: 0.6086934208869934, Loss_G: 1.0904998779296875
Epoch 41: Loss_D: 0.6544982194900513, Loss_G: 1.076159119606018
Epoch 42: Loss_D: 0.567204475402832, Loss_G: 0.9043337106704712
Epoch 43: Loss_D: 0.5489742755889893, Loss_G: 0.9356962442398071
Epoch 44: Loss_D: 0.5661631226539612, Loss_G: 0.928362250328064
Epoch 45: Loss_D: 0.5908459424972534, Loss_G: 0.8346718549728394
Epoch 46: Loss_D: 0.600044310092926, Loss_G: 0.8804260492324829
Epoch 47: Loss_D: 0.62596595287323, Loss_G: 1.0049660205841064
Epoch 48: Loss_D: 0.5493007898330688, Loss_G: 0.994965672492981
Epoch 49: Loss_D: 0.612429141998291, Loss_G: 0.9046852588653564
Training complete</code></pre>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-2.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-3.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-4.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-5.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-6.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-7.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-8.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-9.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-10.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-11.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-12.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-13.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-14.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-15.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-16.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-17.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-18.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-19.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-20.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-21.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-22.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-23.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-24.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-25.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-26.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-27.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-28.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-29.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-30.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-31.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-32.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-33.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-34.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-35.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-36.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-37.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-38.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-39.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-40.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-41.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-42.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-43.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-44.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-45.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-46.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-47.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-48.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-49.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-50.png"/></p>
</figure>
</div>
</div>
<div>
<div>
<figure>
<p><img src="https://amontalenti.com/2024/06/01/GenerativeAdversarialNetworks_Goodfellow_files/figure-html/cell-15-output-51.png"/></p>
</figure>
</div>
</div>
</div>
<p>When running this code locally, there are some issues you should be aware of. Firstly, due to the stochastic nature of neural networks it is likely your generated images won’t match mine exactly. A more pressing issue can occur where the generated images all look bad and do not seem to improve, when this happens the best solution is to reinitialise the networks and run the training loop again.</p>
<hr/>
</section>
</section>
<section id="congrats-youve-implemented-and-trained-a-gan">
<h2 data-anchor-id="congrats-youve-implemented-and-trained-a-gan">Congrats, you’ve implemented and trained a GAN</h2>
<p>You can now see the outputs of your model and they look pretty good, perhaps you can get them to look better with more epochs or a different model architecture. Also, here’s a cool project you could try after this: traing your GAN and generate a bunch of samples of the generated digits, then build an MNIST classifier and pass these through the trained classifier and see if it gets them correct.</p>
<p>I’ll leave you with an issue with this setup of GANs. The updating of the G model is dependent upon the performance of the D model, in essence the better the feedback the D model gives the better our G model will become. However, when the G model gets good enough such that the accuracy of the D model becomes 0.5 (its guessing randomly) it’s feedback is essentially meaningless and our G model stops improving. This can be seen in our model too.</p>
<p>The cool idea that we should make clear is that the GAN truly does generate new images, it does not learn the training data but it generates new images. Exactly how may not be fully understood (by me anyways) but this is what is happening, isn’t that amazing!</p>
<hr/>
<p><a id="1" href=""><sup>1</sup></a> <a href="https://arxiv.org/pdf/1406.2661">https://arxiv.org/pdf/1406.2661</a></p>
<p><a id="2" href=""><sup>2</sup></a> If you don’t know here’s a good resource to learn: <a href="https://www.deeplearningbook.org/contents/mlp.html">https://www.deeplearningbook.org/contents/mlp.html</a></p>
<p><a id="3" href=""><sup>3</sup></a> Here’s a great book to get familiar with PyTorch <a href="https://www.manning.com/books/deep-learning-with-pytorch">https://www.manning.com/books/deep-learning-with-pytorch</a></p>
<p><a id="4" href=""><sup>4</sup></a> I know this can be a bit frustrating to hear, but if you have any questions on this or anything discussed here feel free to reach out to me @ <a href="mailto:y%75sufmohamma%64@l%69ve.com">yusufmohammad@live.com</a></p>
<p><a id="5" href=""><sup>5</sup></a> https://github.com/soumith/ganhacks check hack 2</p>
</section>

</main>
<!-- /main column -->

</div></div>
  </body>
</html>
