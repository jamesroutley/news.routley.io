<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stevenharman.net/so-we-have-a-memory-leak">Original</a>
    <h1>So We&#39;ve Got a Memory Leak</h1>
    
    <div id="readability-page-1" class="page"><article role="article" itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div>
    <p>Memory leaks happen.
And if you‚Äôre here, reading this, I‚Äôd bet you‚Äôre dealing with one.
First things first - are you <a href="https://medium.com/klaxit-techblog/tracking-a-ruby-memory-leak-in-2021-9eb56575f731#5051" title="Tracking a Ruby memory leak in 2021">sure it‚Äôs a leak, and not bloat</a>?</p>

<p>Okay, so it‚Äôs a leak.
Much has been written about various tools for <a href="https://blog.appsignal.com/2022/08/10/a-deep-dive-into-memory-leaks-in-ruby.html" title="A Deep Dive into Memory Leaks in Ruby">profiling a leak</a>, <a href="https://www.cloudbees.com/blog/the-definitive-guide-to-ruby-heap-dumps-part-i" title="The Definitive Guide to Ruby Heap Dumps, Part I">understanding heap dumps</a>, <a href="https://blog.devops.dev/understanding-memory-leaks-in-ruby-on-rails-applications-43a84222f49c" title="Understanding Memory Leaks in Ruby on Rails Applications">common causes of leaks</a>, <a href="https://shopify.engineering/ruby-variable-width-allocation" title="Optimizing Ruby&#39;s Memory Layout: Variable Width Allocation">work being done to improve Ruby‚Äôs memory layout</a>, and so much more.
Ben Sheldon‚Äôs recent ‚Äú<a href="https://island94.org/2024/01/the-answer-is-in-your-heap-debugging-big-rails-memory" title="The answer is in your heap: debugging a big memory increase in Ruby on Rails">The answer is in your heap: debugging a big memory increase in Ruby on Rails</a>‚Äù is a great example.
Ben mentions and shows how he and some teammates used several different tools to generate heap dumps, analyze and interrogate them, and ultimately find and fix the source of a leak in Rails itself.</p>

<p>These are all great resources, and can be crucial knowledge in our hunt for a leak.
But they all suppose we already have an idea of where to start looking, or use stripped down examples to showcase the tools.
The <a href="https://github.com/SamSaffron/memory_profiler" title="MemoryProfiler - A memory profiler for Ruby"><code>memory_profiler</code> Gem</a> can profile memory allocations around some suspect code, if we already know that code is suspect.
<a href="https://github.com/zombocom/derailed_benchmarks/blob/main/README.md#i-want-more-heap-dumps" title="Derailed Benchmarks - A series of things you can use to benchmark a Rails or Ruby app.">Derailed Benchmarks</a> can get us
started on tracking down a leak in the overall stack, or a known problematic resource, and generate heap dumps for us.
Comparing those dumps with <a href="https://github.com/zombocom/heapy" title="Heapy (Ruby Heap Dump Inspector) - A CLI for analyzing Ruby Heap dumps.">heapy</a> can point us in the right direction by revealing memory being unexpectedly retained over time.
We can use <a href="https://github.com/jhawthorn/sheap" title="sheap - A library for interactively exploring Ruby Heap dumps. Sheap contains contains a command-line tool and a library for use in IRB.">sheap</a> to track down exactly where problematic objects allocations are happening, once we‚Äôve identified those problematic objects.</p>

<p>But what if we‚Äôve reviewed all recent code changes, and nothing stands out?
Or if the leaks don‚Äôt happen consistently, across all instances of the running app?
Or memory starts leaking different times?
Where do we even start?</p>

<!-- more -->

<p>That‚Äôs what I was asking myself recently with a decade old Rails app I work on.
This is a real production app, driving substantial revenue.
It serves a sustained load of 400-500 requests/second, with peaks into several thousands/second.</p>

<p>Then one, nondescript day, amongst the usual flow of deploys, memory started spiking. üìà
The pager started yelling. üìü
And we had what looked like a memory leak. üíß</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/initial-memory-spikes.png" alt="Graph of memory starting to spike over and over mid-way across the view" title="We have a memory leak! So. Many. Spikeys!"/>
  <figcaption>We have a memory leak! So. Many. Spikeys!</figcaption>
</figure>

<h2 id="put-out-the-fire">üî• First put out the fire</h2>

<p>It certainly looked like a leak, rather than bloat, meaning we had one sure-fire way to temporarily fix the problem.
Restart things!
We run on <a href="https://heroku.com" title="Heroku is a container-based cloud Platform as a Service (PaaS).">Heroku</a>, and what we‚Äôre seeing above are per-<a href="https://www.heroku.com/dynos" title="Dynos: the heart of the Heroku platform">Dyno</a> memory numbers.
In the short term, we‚Äôd either let our normal cadence of many-deploys-a-day restart our <code>web</code> instances, or we‚Äôd manually restart individual Dynos approaching their memory limit.</p>

<h2 id="look-for-suspect-changes">üîé Look for suspect changes</h2>

<p>With the fire under control we turned our attention to changes that happened in the hours before the first big spike.
The graph above doesn‚Äôt show our deploy markers (they were too distracting at this granularity) but starting with the deploy just inside of the first spike and working backward, we audited all code changes going back three days.</p>

<p>We found a few changes that seemed like they <em>could</em> be related.
One of them introduced a memory leak in <code>development</code> mode due to Rails‚Äô code reloading.
Another caused us to hit Redis more than we intended during certain request filtering.
The third looked like we were making more database calls, loading more <code>ActiveRecord</code> instances than we wanted (a classic N+1).
We fixed the first two and rolled back the third, deploying them one at a time.
The memory leak continued. üìà</p>

<p>No other code changes <em>looked</em> like they could cause a leak.
But, we had made a few tooling changes to start collecting Ruby language and Puma pool usage metrics, so we backed those out and deployed.
The memory leak continued. üìà</p>

<h2 id="look-for-patterns">üß© Look for patterns</h2>

<p>Next we went looking for patterns to the memory growth.
Of note, it was only our <code>web</code> Dynos that were leaking.
All of our <a href="https://sidekiq.org/products/enterprise.html" title="Simple, efficient background jobs for Ruby.">Sidekiq</a> and <a href="https://github.com/collectiveidea/delayed_job" title="Delayed::Job (or DJ) encapsulates the common pattern of asynchronously executing longer tasks in the background.">Delayed::Job</a> (yes, both, for‚Ä¶ reasons lost to history) Dynos looked just fine.
Also, not all <code>web</code> Dynos were always leaking memory.
Sometimes they‚Äôd go hours with relatively flat-ish memory usage consistent with a long-running web process.
Then one, or a few, or all of them would start to leak memory.
This made us suspicious that perhaps the leak was specific to a certain <em>kind</em> of traffic, rather than a problem in the stack, or with volume of traffic.</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/memory-spikes-delayed.png" alt="Graph of memory flat for 4 hours, and then starting to rise" title="Low-traffic period, just post deploy. Hours pass before 2 of 4 Dynos start to leak memory."/>
  <figcaption>Low-traffic period, just post deploy. Hours pass before 2 of 4 Dynos start to leak memory.</figcaption>
</figure>

<p>When we looked at our Puma workers, we also saw that not all workers on a single Dyno were leaking.
We run Puma in clustered mode, with 12 worker processes for the 8 <abbr title="Virtual CPU">vCPU</abbr> on each Dyno.
It wasn‚Äôt unusual to see just a couple of the 12 processes were using up nearly all of the memory on the Dyno.
i.e., a couple workers were leaking, while the rest were fine.</p>

<p>Due to aggressive sampling we were unable to use our <a href="https://opentelemetry.io/docs/concepts/signals/traces/" title="OpenTelemetry Traces">OpenTelmetry Traces</a> to match specific kinds of traffic to specific Dynos at times that correlated to the start of the leaks.
But we still had a strong suspicion the leaks had <em>something</em> to do with particular traffic.
One of the smart folks I work with had the idea to try correlating via our logs - which are not sampled.
But the tooling there didn‚Äôt make that particularly easy.
So we put that idea in our back pocket and moved on to another.</p>

<h2 id="go-to-the-dumps">üöõ Go to the dumps!</h2>

<p>If memory is being leaked, looking at dumps of Ruby‚Äôs memory heap is probably a good idea.
After all, all of those very smart Internet Folks wrote lots of words about it.</p>

<h3 id="step-0-tooling">Step 0: Get the tooling in place</h3>

<p>We use <a href="https://github.com/tmm1/rbtrace" title="rbtrace: like strace, but for ruby code"><code>rbtrace</code></a> to attach to a running Ruby process, meaning it needs to be loaded into the running process.
Basically, make sure it‚Äôs in the <code>Gemfile</code>.
It‚Äôs generally fine to have this loaded in production.
But we‚Äôve made it somewhat toggle-able; we can opt in/out of loading <code>rbtrace</code> via an Environment Variable:</p>

<div><div><pre><code><span>gem</span> <span>&#34;rbtrace&#34;</span><span>,</span> <span>require: </span><span>String</span><span>(</span><span>ENV</span><span>.</span><span>fetch</span><span>(</span><span>&#34;FEATURE_ENABLE_MEMORY_DUMPS&#34;</span><span>,</span> <span>false</span><span>))</span> <span>==</span> <span>&#34;true&#34;</span>
</code></pre></div></div>

<h3 id="step-1-find-leaking-process">Step 1: Find a leaking process</h3>

<p>Running on Heroku meant we needed to dump the heap of a live, running <code>web</code> process, from within a Dyno itself.
Luckily, Herkou and the Ruby community have already built all of the tooling necessary.</p>

<p>Using <a href="https://devcenter.heroku.com/articles/exec" title="Heroku Exec (SSH Tunneling)"><code>heroku ps:exec</code></a> to open an SSH tunnel into a leaking Dyno, we needed to find a particular Puma worker process to dump.
We went to our old *nix friend <code>ps</code>.</p>

<div><div><pre><code>ps <span>-eo</span> pid,ppid,comm,rss,vsz <span>--sort</span> <span>-rss</span> | <span>grep </span>ruby
</code></pre></div></div>

<p>This gave us a list of all of the Ruby processes running on the Dyno, sorted by their <a href="https://stackoverflow.com/questions/7880784/what-is-rss-and-vsz-in-linux-memory-management" title="What is RSS and VSZ in Linux memory management">RSS</a> (amount of memory being used by the process).
In the case of a <code>web</code> Dyno, most of them have the same <abbr title="Parent Process IDentifier"><code>PPID</code></abbr>.
These are the Puma workers.
The process with a matching <abbr title="Process IDentifier"><code>PID</code></abbr> is the Puma primary (master) process.
It will look something similar for Sidekiq.
Other Ruby tools that run only a single process would look a little different.
Picking the process with the most memory (i.e., the leakiest of them) we use its <code>PID</code> to and <code>rbtrace</code> to start tracing memory allocations.</p>

<h3 id="step-2-enable-tracing">Step 2: Enable memory allocation tracing</h3>

<p>We set that worker process ID as <code>$DUMP_PID</code> to be used as a variable in later steps.
This helps prevent silly typos and much face-into-keyboard-ing later on. ü§¶</p>

<div><div><pre><code><span>DUMP_PID</span><span>=</span>&lt;pid&gt;
<span># Turn on allocation tracking in the Ruby process.</span>
<span># This will impact performance; it can use a lot of memory and CPU</span>
rbtrace <span>--pid</span><span>=</span><span>&#34;</span><span>${</span><span>DUMP_PID</span><span>}</span><span>&#34;</span> <span>--eval</span><span>=</span><span>&#34;Thread.new{require &#39;objspace&#39;;ObjectSpace.trace_object_allocations_start}.join&#34;</span>
</code></pre></div></div>

<h3 id="step-3-dump-the-heap">Step 3: Dump the heap</h3>

<div><div><pre><code><span># Generate the first heap dump</span>
rbtrace <span>--pid</span><span>=</span><span>&#34;</span><span>${</span><span>DUMP_PID</span><span>}</span><span>&#34;</span> <span>--eval</span><span>=</span><span>&#34;Thread.new{require &#39;objspace&#39;; GC.start(); io=File.open(&#39;/tmp/heap-</span><span>${</span><span>DUMP_PID</span><span>}</span><span>.json&#39;, &#39;w&#39;); ObjectSpace.dump_all(output: io); io.close}.join&#34;</span> <span>--timeout</span><span>=</span>600
</code></pre></div></div>

<p>The <code>.json</code> file can be quite large.
On a leaking process that had been running for a few hours, it was 5-6<abbr title="Gibibyte">GiB</abbr> in size.
I‚Äôd recommend <code>gzip</code>-ing it.</p>

<div><div><pre><code><span>gzip</span> <span>&#34;/tmp/heap-</span><span>${</span><span>DUMP_PID</span><span>}</span><span>.json&#34;</span>
</code></pre></div></div>

<p>That will replace the <code>.json</code> dump file with a <code>.json.gz</code> file which could be up to an order of magnitude smaller.</p>

<h3 id="step-4-fetch-the-dump">Step 4: Fetch the dump</h3>

<p>This will differ depending on where the application is deployed, but on Heroku we run the following (adjusting for exact file and Dyno names) from a shell on our local machine.</p>

<div><div><pre><code>heroku ps:copy /tmp/heap-&lt;pid&gt;.json.gz <span>--dyno</span><span>=</span>&lt;web.1&gt; <span>--app</span><span>=</span>&lt;app name&gt;
</code></pre></div></div>

<p>Decompress and move the file somewhere organized.
I‚Äôd recommend renaming it based on which dump this is; we‚Äôll grab at least three if we‚Äôre going to use <code>heapy</code> to try to find retained memory, for example.</p>

<div><div><pre><code><span>mv </span>heap-&lt;pid&gt;.json.gz ~/dumps/.
<span>gzip</span> <span>--keep</span> <span>--decompress</span> ~/dumps/heap-&lt;pid&gt;.json.gz
</code></pre></div></div>

<p>Repeat steps 3 and 4 to grab as many dumps as needed.</p>

<h3 id="step-5-clean-up">Step 5: Clean up after ourselves</h3>

<p>Be sure to turn off the allocation tracking, and probably remove those dumps from the Dyno.
Or just restart the Dyno.</p>

<div><div><pre><code>rbtrace <span>--pid</span><span>=</span><span>&#34;</span><span>${</span><span>DUMP_PID</span><span>}</span><span>&#34;</span> <span>--eval</span><span>=</span><span>&#34;Thread.new{GC.start;require &#39;objspace&#39;;ObjectSpace.trace_object_allocations_stop;ObjectSpace.trace_object_allocations_clear}.join&#34;</span>
</code></pre></div></div>

<h2 id="analyze-the-heap-dumps">üßê Analyze the heap dumps</h2>

<p>We tried looking at the retained memory reports via <code>heapy</code>, and meandering the diffs via <code>sheap</code>, but with no particular spot to start looking, it felt like looking for a specific needle in a stack of needles.
(Thanks for that line, Tom Hanks.)</p>

<p>In hopes of <em>seeing</em> something that looked off, <a href="https://ruby.social/@stevenharman/111791414166558864" title="Me, asking questions on ruby.social">I went in search</a> of a way to visualize the heap dumps.
And The Internet‚Ñ¢ did not disappoint!
<a href="https://github.com/oxidize-rb/reap" title="A tool for parsing Ruby heap dumps by analyzing the reference graph."><code>reap</code> is a tool for analyzing a Ruby heap dump‚Äôs reference graph</a>, and generating visualizations.
Including flame graphs!
Here‚Äôs a graphs of the third dump we took off of a leaking process, per the steps above.</p>

<div><div><pre><code>reap path/to/heap-&lt;pid&gt;-2.json <span>--count</span><span>=</span>15 <span>--flamegraph</span><span>=</span>dump-2.svg
</code></pre></div></div>
<p>The way to read this is starting at the top and moving downward are references from a ‚Äúroot‚Äù (in the view of the Ruby Garbage Collector) to other objects.
That is, objects further down are references by objects above them.
And the more memory an object (or an object it references) is holding onto, the wider the cell in the graph.</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/flamegraph-2.png" alt="Flame graph showing a Thread holding 1.9GiB of memory." title="Flame graph showing a Thread holding 1.9GiB of memory."/>
  <figcaption>Flame graph showing a Thread holding 1.9GiB of memory.</figcaption>
</figure>

<p>Notice anything odd?
What‚Äôs up with that <code>Thread</code> holding 1.9GiB of memory?
Or really, it‚Äôs the <code>Array</code> at the bottom, holding onto references to <code>32,067</code> other objects, in turn holding 1.9GiB of memory.
So what the heck is that array?
Where did it come from?
Why is it referencing so much memory?</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/flamegraph-2-annotated.png" alt="Flame graph calling out an Array of 32k things, referencing 1.9GiB of memory." title="Flame graph calling out an Array of 32k things, referencing 1.9GiB of memory."/>
  <figcaption>Flame graph calling out an Array of 32k things, referencing 1.9GiB of memory.</figcaption>
</figure>

<h2 id="go-spelunking-with-sheap">üßó Go spelunking with <code>sheap</code></h2>

<p>Using the latest <code>main</code> branch from <a href="https://github.com/jhawthorn/sheap" title="sheap - A library for interactively exploring Ruby Heap dumps. Sheap contains contains a command-line tool and a library for use in IRB."><code>sheap</code></a> (because some of the features like <code>find_path</code> weren‚Äôt yet released to RubyGems), we compared the second and third dumps.
It will take a while to parse these dumps, which were pushing 6GiB in our case. ‚òïÔ∏è</p>

<div><div><pre><code>~/code/jhawthorn/sheap/bin/sheap heap-&lt;pid&gt;-1.json heap-&lt;pid&gt;-2.json
</code></pre></div></div>

<p>That opens an <abbr title="Interactive Ruby">IRB</abbr> console where we can explore the dumps and the diff between them.
See the <a href="https://github.com/jhawthorn/sheap/blob/main/README.md" title="Sheap is a library for interactively exploring Ruby Heap dumps"><code>README</code></a> (and the source code) for all that it can do.</p>

<div><div><pre><code><span>irb: </span><span>t</span> <span>=</span> <span>$after</span><span>.</span><span>at</span><span>(</span><span>&#34;0x55adecb68498&#34;</span><span>)</span>
<span>===&gt;</span> <span>&lt;</span><span>DATA</span> <span>0x55adecb68498</span> <span>VM</span><span>/</span><span>thread</span> <span>(</span><span>137</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>$after</span><span>.</span><span>find_path</span><span>(</span><span>t</span><span>)</span>
<span>===&gt;</span> <span>[</span><span>&lt;</span><span>ROOT</span> <span>vm</span> <span>(</span><span>4014</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span> <span>&lt;</span><span>DATA</span> <span>0x55addb8deff8</span> <span>ractor</span> <span>(</span><span>31</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span> <span>&lt;</span><span>DATA</span> <span>0x55adecb68498</span> <span>VM</span><span>/</span><span>thread</span> <span>(</span><span>137</span> <span>refs</span><span>)</span><span>&gt;</span><span>]</span>
</code></pre></div></div>

<p>We first investigated that <code>Thread</code> to understand where it was coming from.
Our suspicion was that it was a background thread from one of our telemetry or metrics tools - maybe the <abbr title="OpenTelemetry">OTel</abbr> tracer, or error reporter, or something like that?
But, <code>sheap</code> told us it was a Puma thread - the one actually working requests, meaning it‚Äôs ‚Äúthe Rails thread.‚Äù
So that question is answered.</p>

<p>Next we wanted to know more about that <code>ActiveSupport::SubscriberQueueRegistry</code> object.
We went looking at the stable branch for the version of Rails we‚Äôre currently on (6.1) and found that <a href="https://github.com/rails/rails/blob/517ff4b7c6c6aeaa588993475277d816b0ba038e/activesupport/lib/active_support/subscriber.rb#L155">it‚Äôs basically a per-<code>Thread</code> <code>Hash</code> used to store lists of <code>ActiveSupport::Subscriber</code> instances</a>, based on the event name.
And <code>ActiveSupport::Notifications::Event</code> objects are pushed onto and popped off that per-thread, per-event-name list (<code>Array</code>) as <code>ActiveSupport::Notifications.instrument</code> blocks are run.
Going back to <code>sheap</code> we can see that in action - the <code>SubscriberQueueRegistry</code> instance holds a reference to a <code>Hash</code>, which has references to some <code>String</code> and <code>Array</code> objects.</p>

<div><div><pre><code><span>irb: </span><span>asr</span> <span>=</span> <span>$after</span><span>.</span><span>at</span><span>(</span><span>&#34;0x55adeeb31798&#34;</span><span>)</span>
<span>===&gt;</span> <span>&lt;</span><span>OBJECT</span> <span>0x55adeeb31798</span> <span>ActiveSupport</span><span>::</span><span>SubscriberQueueRegistry</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>asr</span><span>.</span><span>references</span>
<span>===&gt;</span> <span>[</span><span>&lt;</span><span>HASH</span> <span>0x55adeeb31748</span> <span>(</span><span>6</span> <span>refs</span><span>)</span><span>&gt;</span><span>]</span>
<span>irb: </span><span>asr</span><span>.</span><span>references</span><span>.</span><span>first</span><span>.</span><span>references</span>
<span>===&gt;</span>
<span>[</span><span>&lt;</span><span>STRING</span> <span>0x55adeb01afb0</span> <span>&#34;ActiveRecord::LogSubscriber-9300&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>ARRAY</span> <span>0x55adeeb314f0</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf09ffaf8</span> <span>&#34;Lograge::LogSubscribers::ActionController-276520&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>ARRAY</span> <span>0x55adf09ffb20</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4a029e8</span> <span>&#34;Lograge::LogSubscribers::GRPCWeb-276540&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>ARRAY</span> <span>0x55adf4a02a10</span><span>&gt;</span><span>]</span>
</code></pre></div></div>

<p>The only <code>Array</code> with anything in it was in the middle of the flame graph with addresses ending <code>ffb20</code>.
It held a reference to a single <code>ActiveSupport::Notifications::Event</code> instance.
And that instance then held a reference to the <code>Array</code> of 32k+ other objects.
If we look at the code for that <code>Event</code> class, we <a href="https://github.com/rails/rails/blob/517ff4b7c6c6aeaa588993475277d816b0ba038e/activesupport/lib/active_support/notifications/instrumenter.rb#L64">see it contains a single <code>@children</code> ivar <code>Array</code></a>.
So, it‚Äôs an <code>Array</code> of what then?
<em>Child</em> <code>Event</code> instances, presumably.
We grabbed a couple to confirm.</p>

<div><div><pre><code><span>irb: </span><span>event</span> <span>=</span> <span>asr</span><span>.</span><span>references</span><span>.</span><span>first</span><span>.</span><span>references</span><span>[</span><span>3</span><span>].</span><span>references</span><span>.</span><span>first</span>
<span>===&gt;</span> <span>&lt;</span><span>OBJECT</span> <span>0x55adf4fdda70</span> <span>ActiveSupport</span><span>::</span><span>Notifications</span><span>::</span><span>Event</span> <span>(</span><span>4</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>children_ary</span> <span>=</span> <span>event</span><span>.</span><span>references</span><span>.</span><span>last</span>
<span>===&gt;</span> <span>&lt;</span><span>ARRAY</span> <span>0x55adf4fdda20</span> <span>(</span><span>32067</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>children_ary</span><span>.</span><span>references</span><span>.</span><span>first</span>
<span>===&gt;</span> <span>&lt;</span><span>OBJECT</span> <span>0x55adf523e9e0</span> <span>ActiveSupport</span><span>::</span><span>Notifications</span><span>::</span><span>Event</span> <span>(</span><span>4</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>children_ary</span><span>.</span><span>references</span><span>.</span><span>first</span><span>.</span><span>references</span>
<span>===&gt;</span> <span>[</span><span>&lt;</span><span>STRING</span> <span>0x55addbe19ae0</span> <span>&#34;redirect_to.action_controller&#34;</span><span>&gt;</span><span>,</span> <span>&lt;</span><span>HASH</span> <span>0x55adf523e9b8</span> <span>(</span><span>10</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span> <span>&lt;</span><span>STRING</span> <span>0x55adedec2188</span> <span>&#34;19b24a9862f0e692859e&#34;</span><span>&gt;</span><span>,</span> <span>&lt;</span><span>ARRAY</span> <span>0x55adf523e990</span><span>&gt;</span><span>]</span>
</code></pre></div></div>

<p>Sure enough, the huge <code>Array</code> is a list of ‚Äúchildren‚Äù <code>Event</code> objects.
This first child <code>Event</code> was for a <code>redirect_to.action_controller</code> event name.
And it would have been pushed onto this <code>Event#children</code> list because some <a href="https://github.com/rails/rails/blob/517ff4b7c6c6aeaa588993475277d816b0ba038e/activesupport/lib/active_support/subscriber.rb#L138-L139">other <code>Event</code> was already on the <code>event_stack</code></a>.</p>

<p>At this point our intuition was telling us something was wrong here - these <code>Event</code>s were incorrectly being put on this <code>#children</code> <code>Array</code>.
We wanted to know what else that child <code>Event</code> had to tell us, like what is in that <code>Hash</code> it‚Äôs holding a reference to?</p>

<div><div><pre><code><span>irb: </span><span>first_child</span> <span>=</span> <span>children_ary</span><span>.</span><span>references</span><span>.</span><span>first</span>
<span>===&gt;</span> <span>&lt;</span><span>OBJECT</span> <span>0x55adf523e9e0</span> <span>ActiveSupport</span><span>::</span><span>Notifications</span><span>::</span><span>Event</span> <span>(</span><span>4</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>first_child</span><span>.</span><span>references</span><span>[</span><span>1</span><span>].</span><span>references</span>
<span>===&gt;</span>
<span>[</span><span>&lt;</span><span>OBJECT</span> <span>0x55adf4e54e38</span> <span>ActionDispatch</span><span>::</span><span>Request</span> <span>(</span><span>10</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55ade7965bf0</span> <span>&#34;PresentationController&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4250150</span> <span>&#34;view&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>HASH</span> <span>0x55adf4f6d4f0</span> <span>(</span><span>507</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>OBJECT</span> <span>0x55adf4f5c998</span> <span>ActionDispatch</span><span>::</span><span>Http</span><span>::</span><span>Headers</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4cccca0</span> <span>&#34;GET&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4f6e8a0</span> <span>nil</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>HASH</span> <span>0x55adf5378c70</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>ARRAY</span> <span>0x55adf5378ae0</span> <span>(</span><span>2</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>OBJECT</span> <span>0x55adf5382310</span> <span>(</span><span>0x55adf5400058</span><span>)</span> <span>(</span><span>4</span> <span>refs</span><span>)</span><span>&gt;</span><span>]</span>
</code></pre></div></div>

<p>Whoa, an entire <code>ActionDispatch::Request</code> object. üò±
The request that was being redirected.
What did that look like?
Maybe we could reproduce this locally?</p>

<div><div><pre><code><span>irb: </span><span>first_child</span><span>.</span><span>references</span><span>[</span><span>1</span><span>].</span><span>references</span><span>.</span><span>first</span>
<span>===&gt;</span> <span>&lt;</span><span>OBJECT</span> <span>0x55adf4e54e38</span> <span>ActionDispatch</span><span>::</span><span>Request</span> <span>(</span><span>10</span> <span>refs</span><span>)</span><span>&gt;</span>
<span>irb: </span><span>first_child</span><span>.</span><span>references</span><span>[</span><span>1</span><span>].</span><span>references</span><span>.</span><span>first</span><span>.</span><span>references</span>
<span>===&gt;</span>
<span>[</span><span>&lt;</span><span>HASH</span> <span>0x55adf4ccced0</span> <span>(</span><span>222</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>HASH</span> <span>0x55adf4f6d4f0</span> <span>(</span><span>507</span> <span>refs</span><span>)</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4f6e8f0</span> <span>&#34;/view/abc123def456?parked=junk&amp;parking=junk&amp;parseSchema=junk&amp;‚Ä¶ eliding more param tampering ‚Ä¶ &amp;password=[FILTERED]&amp; ‚Ä¶ &amp;portbl=junk&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55addc723e60</span> <span>&#34;https://&#34;</span><span>&gt;</span><span>,</span>
 <span>&lt;</span><span>STRING</span> <span>0x55adf4cccca0</span> <span>&#34;GET&#34;</span><span>&gt;</span><span>,</span>
 <span>‚Ä¶</span> <span># eliding more stuff</span>
 <span>&lt;</span><span>OBJECT</span> <span>0x55adf4f5c998</span> <span>ActionDispatch</span><span>::</span><span>Http</span><span>::</span><span>Headers</span> <span>(</span><span>1</span> <span>refs</span><span>)</span><span>&gt;</span><span>]</span>
</code></pre></div></div>

<p>Well look at that.
It‚Äòs a mostly valid request, to an actual <code>Route</code> in the app, with a valid public ID of a resource (changed to protect the innocent, of course).
What‚Äôs not legit is the parameter tampering - the work of a scanner very likely.
What especially stood out was the <code>password=[FILTERED]</code> , which means something was catching the request and cleaning sensitive info we‚Äôd not want in logs and such.</p>

<h2 id="reproduce-it">üîÑ Reproduce it</h2>

<p>With the questionable looking query path and params, we opened the production app in an incognito browser window and made a request.
We were met with a <abbr title="Internal Server Error">500</abbr> server error.</p>

<p>üéâ Success! ‚ú®</p>

<p>Logs confirmed that it was an error.
Specifically a <code>URI::InvalidURIError</code>.
The logs also recorded which Dyno the request had hit.
We popped open our memory graphs and by sheer luck, that Dyno was currently showing normal memory usage.
We put a temporary deploy freeze in place so we could monitor memory usage for a few minutes and before long the trend line was clear.
We had a leak.</p>

<p>With some confidence we were leaking <code>Event</code> objects as part of the <code>ActiveSupport::Notifications</code> tooling, we still wanted to reproduce it locally so we could step through the code and see what was going on.
Leaning on a little bit of <code>binding.pry</code> and even more <code>puts</code> debugging in the <code>activesupport</code> Gem (if you don‚Äôt know, <code>bundle open &lt;gem name&gt;</code>, <a href="https://bundler.io/v2.5/man/bundle-open.1.html">check it out</a>), we eventually reproduced the situation locally.
And with a backtrace!</p>

<p>The error‚Äôs backtrace pointed to the <code>uri</code> Gem (part of Ruby‚Äôs standard library), which was being <a href="https://github.com/bugsnag/bugsnag-ruby/blob/v6.26.1/lib/bugsnag/integrations/railtie.rb#L45">used by Bugsnag‚Äôs <code>Bugsnag.cleaner.clean_url</code> method</a>, as part of a <code>ActiveSupport::Notifications.subscribe</code> block.
Which sounded awfully familiar.
A little more debugging and stepping through the Bugsnag and <code>ActiveSupport</code> code and We‚Äôd narrowed in on the problem(s).</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/puts-debugging-before.png" alt="Logs showing a Event object left on the stack after the error is raised." title="Logs showing a Event object left on the stack after the error is raised."/>
  <figcaption>Logs showing a Event object left on the stack after the error is raised.</figcaption>
</figure>

<h2 id="understand-the-cause">üí°Understand the cause</h2>

<p>There were two related problems, right next to each other.
The first was to do with <code>ActiveSupport::Subscriber</code>‚Äôs notion of <code>#children</code> and how it was tracking them.
<a href="https://jhawthorn.com/">John Hawthorn</a> explains it, and had <a href="https://github.com/rails/rails/pull/43390">already fixed it in Rails 7.1</a> (we were on 6.1 at the time).</p>

<p>This alone wasn‚Äôt the cause our memory leak.
But in combination with a change to the Bugsnag Gem to <a href="https://github.com/bugsnag/bugsnag-ruby/pull/806">start cleaning URLs Rails breadcrumbs</a>, it manifested in a leak.
The Bugsnag change relied on <code>URI</code> to parse and then redact certain sensitive query strings.
The <code>URI</code> is rightfully pretty strict about what it considers a valid <abbr title="Uniform Resource Identifier">URI</abbr>, raising an error when given an invalid URI.
Meaning the <code>ActiveSupport::Notifications.subscribe</code> block in the Bugsnag Gem could now <code>raise</code> an error while processing an <code>ActiveSupport::Notifications::Event</code>.
And raising that error meant that the <code>parent</code> <code>Event</code> <a href="https://github.com/rails/rails/blob/517ff4b7c6c6aeaa588993475277d816b0ba038e/activesupport/lib/active_support/subscriber.rb#L145">wasn‚Äôt getting popped off the <code>Subscriber#event_stack</code></a>.
So the <code>parent</code> <code>Event</code> was sticking around (leaking memory), and it was still holding a reference to the child <code>Event</code> via its <code>#children</code> <code>Array</code> (leaking more memory).</p>

<p>John‚Äôs change not only removed the <code>Event#children</code> concept, but completely removed the shared-<code>Array</code> used to track <code>Events</code>.
The source of both leaks, gone in a single PR. üëè</p>

<h2 id="fix-the-problem">üõ†Ô∏è Fix the problem</h2>

<p>John‚Äôs fix for newer Rails means this is no longer a problem‚Ä¶ on newer Rails versions.
But we weren‚Äôt there yet.
As luck would have it, just days prior <a href="https://github.com/bugsnag/bugsnag-ruby/pull/811">Bugsnag had fixed</a> the <code>Bugsnag.cleaner.clean_url</code> method to not <code>raise</code> an error on invalid URIs.</p>

<p>Our fix, in the short term, was to upgrade the Bugsnag Gem to a version that included the ‚Äúdon‚Äôt raise an error while trying to clean an invalid URI‚Äù change.
Longer term we‚Äôre upgrading Rails versions.</p>

<figure>
  <img src="https://bytes.zone/assets/images/posts/memory_leak/puts-debugging-after.png" alt="Upgraded dependency no longer raises, and now the stack is empty." title="Upgraded dependency no longer raises, and now the stack is empty."/>
  <figcaption>Upgraded dependency no longer raises, and now the stack is empty.</figcaption>
</figure>

<h2 id="its-me-hi-im-the-problem-its-me">ü§° It‚Äôs me, hi, I‚Äôm the problem, it‚Äôs me.</h2>

<p><cite>(with apologies to Taylor Swift) üôè</cite></p>

<p>Funny story.
It turns out that Bugsnag change was introduced to our code base right around when the first memory spikes occurred.
We‚Äôd upgraded from <code>v6.26.0</code> to <code>v6.26.1</code> to fix a deprecation warning for a different dependency.
We (by which I mean me, I, myself) audited this change too.
And dismissed it as not being related because‚Ä¶ why the heck would redacting part of a URI, something the Bugsnag Gem already did in other places, cause such a bad and sudden memory leak!?!?
Well‚Ä¶ <em>something-something-something</em> assumptions. ü§¶</p>

  </div>

  
</article></div>
  </body>
</html>
