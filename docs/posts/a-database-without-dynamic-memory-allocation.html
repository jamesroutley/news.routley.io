<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tigerbeetle.com/blog/a-database-without-dynamic-memory/">Original</a>
    <h1>A database without dynamic memory allocation</h1>
    
    <div id="readability-page-1" class="page"><div>
  <p>Some folks who read
<a href="https://github.com/tigerbeetledb/tigerbeetle/blob/main/docs/TIGER_STYLE.md">TIGER_STYLE.md</a>
(the <a href="https://github.com/tigerbeetledb/tigerbeetle">TigerBeetle</a> coding guide) are surprised to learn that TigerBeetle
allocates no memory after startup.</p>
<blockquote><p lang="en" dir="ltr">&#34;All memory must be statically allocated at startup. No memory may be dynamically allocated[..] This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free.&#34;<a href="https://t.co/YycKqWNWed">https://t.co/YycKqWNWed</a></p>— Alon Zakai (@kripken) <a href="https://twitter.com/kripken/status/1568428308131622913?ref_src=twsrc%5Etfw">September 10, 2022</a></blockquote> 
<h2>Static and dynamically allocated memory</h2>
<p>Let’s recap memory allocation in general. In most languages, you can
choose to have fixed size objects and arrays at program start. Or,
you can modify the object and array sizes during the run of the
program, maybe to add new keys to the object or maybe to grow the
array to fit more elements.</p>
<p>For example if, in JavaScript, you create an empty array and push
items into it, the array may allocate and reallocate behind the scenes
to fit new entries. This is dynamic memory allocation.</p>
<p>Or, in JavaScript, you could initialize an array with a fixed size and
never change that size. Only placing elements at indices within the
capacity of the array. This is static memory allocation.</p>
<p>TigerBeetle is written in <a href="https://ziglang.org/">Zig</a>. And like
JavaScript, you can choose to use data structures that dynamically
allocate memory (along the lines of JavaScript’s arrays) or you can
choose to only statically allocate memory. TigerBeetle does the
latter.</p>
<p>But one nice part of Zig’s standard library is that its data
structures are designed to be static allocation friendly. For example,
TigerBeetle use’s Zig’s
<a href="https://ziglang.org/documentation/0.9.1/std/#root;ArrayList">ArrayList</a>
and
<a href="https://ziglang.org/documentation/0.9.1/std/#root;HashMap">HashMap</a>
but with fixed sizes. Methods like
<a href="https://github.com/ziglang/zig/blob/0b47e69b7c0aedbc142400305cda86ef58b41656/lib/std/array_list.zig#L171-L177">ArrayList.addOneAssumeCapacity</a>
and
<a href="https://github.com/ziglang/zig/blob/master/lib/std/hash_map.zig#L556-L561">HashMap.putAssumeCapacityNoClobber</a>
help catch bugs where we would accidentally allocate more memory.</p>
<h2>What we gain from this</h2>
<p>You might guess we do this to avoid both garbage collection and most
use-after-free bugs. Those are good reasons, but there are a few more!</p>
<p>Static memory allocation allows us to easily <a href="https://sre.google/sre-book/handling-overload/">handle overload</a>. With
fixed sizes of objects and arrays, there is no ever-growing buffer
when an incorrectly-configured client tries to make too many
connections or send too many messages at once.</p>
<p>This makes TigerBeetle more predictable for operators. Like cgroups in
your database.</p>
<p>And there are a few more angles that are worth exploring but deserve
their own blog posts to fully flesh out:</p>
<ul>
<li>Calculating exactly how much of a resource you will need means less
chance of resource deadlocks and liveness issues in production.</li>
<li>Reducing the amount of memory used means fewer cache lines fetched
from main memory in general, reducing thrashing of the CPU’s cache
hierarchy and improving cache hits for optimal performance.</li>
</ul>
<h2>But how is this possible?</h2>
<p>Basically, TigerBeetle works with fixed amounts of everything:</p>
<ul>
<li>Number of connections</li>
<li>Concurrent messages per connection</li>
<li>Maximum number of replicas in the cluster</li>
<li>Size of messages</li>
<li>Queries per message (queries are always batched)</li>
<li>And so on</li>
</ul>
<p>The total memory needed is simply calculated with a bit of addition
and multiplication at startup. (Currently it’s determined even before
startup, at compile-time, but startup is the important point since
that is the first time that memory can be allocated.)</p>
<p>For example, <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/b8b0562db0b890fb6e6ce123c33f3bdfb659a9fd/src/message_pool.zig#L20-L57">here</a> is how we calculate the amount of memory needed to
store messages for TigerBeetle’s consensus protocol (even across all
combinations of concurrent interactions and protocol permutations):</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>/// The number of full-sized messages allocated at initialization by the replica message pool.
</span></span></span><span><span><span>/// There must be enough messages to ensure that the replica can always progress, to avoid deadlock.
</span></span></span><span><span><span></span><span>pub</span> <span>const</span> messages_max_replica <span>=</span> messages_max<span>:</span> {
</span></span><span><span>    <span>var</span> sum<span>:</span> <span>usize</span> <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    sum <span>+=</span> config.io_depth_read <span>+</span> config.io_depth_write; <span>// Journal I/O
</span></span></span><span><span><span></span>    sum <span>+=</span> config.clients_max; <span>// Replica.client_table
</span></span></span><span><span><span></span>    sum <span>+=</span> <span>1</span>; <span>// Replica.loopback_queue
</span></span></span><span><span><span></span>    sum <span>+=</span> config.pipeline_max; <span>// Replica.pipeline
</span></span></span><span><span><span></span>    sum <span>+=</span> <span>1</span>; <span>// Replica.commit_prepare
</span></span></span><span><span><span></span>    <span>// Replica.do_view_change_from_all_replicas quorum:
</span></span></span><span><span><span></span>    <span>// Replica.recovery_response_quorum is only used for recovery and does not increase the limit.
</span></span></span><span><span><span></span>    <span>// All other quorums are bitsets.
</span></span></span><span><span><span></span>    sum <span>+=</span> config.replicas_max;
</span></span><span><span>    sum <span>+=</span> config.connections_max; <span>// Connection.recv_message
</span></span></span><span><span><span></span>    sum <span>+=</span> config.connections_max <span>*</span> config.connection_send_queue_max_replica; <span>// Connection.send_queue
</span></span></span><span><span><span></span>    sum <span>+=</span> <span>1</span>; <span>// Handle bursts (e.g. Connection.parse_message)
</span></span></span><span><span><span></span>    <span>// Handle Replica.commit_op&#39;s reply:
</span></span></span><span><span><span></span>    <span>// (This is separate from the burst +1 because they may occur concurrently).
</span></span></span><span><span><span></span>    sum <span>+=</span> <span>1</span>;
</span></span><span><span>    sum <span>+=</span> <span>20</span>; <span>// TODO Our network simulator allows up to 20 messages for path_capacity_max.
</span></span></span><span><span><span></span>
</span></span><span><span>    <span>break</span> <span>:</span>messages_max sum;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>/// The number of full-sized messages allocated at initialization by the client message pool.
</span></span></span><span><span><span></span><span>pub</span> <span>const</span> messages_max_client <span>=</span> messages_max<span>:</span> {
</span></span><span><span>    <span>var</span> sum<span>:</span> <span>usize</span> <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    sum <span>+=</span> config.replicas_max; <span>// Connection.recv_message
</span></span></span><span><span><span></span>    sum <span>+=</span> config.replicas_max <span>*</span> config.connection_send_queue_max_client; <span>// Connection.send_queue
</span></span></span><span><span><span></span>    sum <span>+=</span> config.client_request_queue_max; <span>// Client.request_queue
</span></span></span><span><span><span></span>    <span>// Handle bursts (e.g. Connection.parse_message, or sending a ping when the send queue is full).
</span></span></span><span><span><span></span>    sum <span>+=</span> <span>1</span>;
</span></span><span><span>    sum <span>+=</span> <span>20</span>; <span>// TODO Our network simulator allows up to 20 messages for path_capacity_max.
</span></span></span><span><span><span></span>
</span></span><span><span>    <span>break</span> <span>:</span>messages_max sum;
</span></span><span><span>};
</span></span></code></pre></div><p>
  And if we get the calculation wrong? Well, since we enforce static
  allocation, we can check these calculations with assertions (i.e. that
  a free message is always available). If we then get the static
  allocation calculation wrong, this can be surfaced sooner through
  fuzzing, rather than having no limits and eventual resource exhaustion
  (and cascading failure!) in production. When combined with assertions,
  static allocation is a force multiplier for fuzzing!
</p>
<p>This is just one example where memory is allocated in TigerBeetle. But
like this example, all allocations occur only once at startup. With a
simple calculation.</p>
<p>Doing this was possible because we sketched out all resource usage
(network, disk, memory, CPU) in the design phase with
back-of-the-envelope calculations.</p>
<h2>More concretely</h2>
<p>But “fixed amounts of everything” might still sound unclear. So let’s
look at a couple points in a bit more detail.</p>
<p>TigerBeetle only allows a maximum of N client connections at
once. This might sound restrictive, but it is no different than <a href="https://dev.mysql.com/doc/refman/8.0/en/too-many-connections.html">MySQL</a>
or <a href="https://postgresqlco.nf/doc/en/param/max_connections/">PostgreSQL</a>. When more than N connections are made at once,
TigerBeetle drops connections.</p>
<p>Also, TigerBeetle has exactly two data types: accounts
and transfers. Accounts and transfers are fixed-size and cache line
aligned. <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/27f70fcaa5cf9fc52f80cb17665e6432bb274ca2/src/tigerbeetle.zig#L24">Both</a>
types are <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/27f70fcaa5cf9fc52f80cb17665e6432bb274ca2/src/tigerbeetle.zig#L79">128
bytes</a>
(<a href="https://news.ycombinator.com/item?id=25659615">we’re looking at you M1!</a>).</p>
<p><a href="https://capnproto.org/news/2014-06-17-capnproto-flatbuffers-sbe.html">Inspired by Cap’n
Proto</a>,
there is no serialization or deserialization in TigerBeetle. Clients
write the bytes of the account or transfer struct over the
wire. TigerBeetle casts the bytes back into the account or transfer
struct when it reads the message from the client. Zero-copy. Messages
contain a checksum to detect random bit flips. And further validation
is done by the business logic.</p>
<p>Clients can only have one message in flight at a time. Each message
has a maximum number of queries (the default maximum is 8191 queries
per message, leaving space for the 128 byte header). The client must
wait for a response to the last message before sending another. This
batching of queries to the database, aside from static memory
allocation, means high throughput and bounded latency.</p>
<h3>Storage</h3>
<p>Now you get the gist: that static allocation of memory is easy with a
fixed maximum number of connections and fixed-size messages and so on.</p>
<p>There’s still the problem of storage. As you add transfers and
accounts to TigerBeetle, the memory used increases, right?</p>
<p>Well, static allocation is about what is in memory. TigerBeetle is a
database, so long-term storage is not in memory. The dynamic part of
the database is what’s stored on disk.</p>
<p>TigerBeetle implements its own <a href="https://blog.acolyer.org/2014/11/26/the-log-structured-merge-tree-lsm-tree/">LSM
tree</a>
system for storage (in fact, around 30 trees all integrated into an
<a href="https://www.youtube.com/watch?v=yBBpUMR8dHw">LSM forest</a> for some
interesting optimizations). And like all LSM trees there’s a portion
in memory and a portion on disk. The in-memory portion is, you guessed
it, allocated on startup. And small, incremental flushes to disk keep
the in-memory portion perfectly bounded.</p>
<p>The details get more complex, but the rule about static memory
allocation does not change.</p>
<h2>Where to now?</h2>
<p>Building a system that allocates memory once up-front requires
up-front thinking. For many developers (like myself) it is a big
adjustment. But as we’ve found: you spend just a few weeks thinking
through the memory you need, and it pays off massively over time.</p>
<p>If you like to build toy databases, try statically allocating memory
in your next project! And if you want to see it in action in
TigerBeetle, <a href="https://docs.tigerbeetle.com/">download the
database</a> (note: it’s still pre-production!)  and give it a go!</p>

<blockquote><p lang="en" dir="ltr">A number of folks have read TIGER_STYLE.md and asked: how can a database allocate no dynamic memory?</p>— TigerBeetle (@TigerBeetleDB) <a href="https://twitter.com/TigerBeetleDB/status/1580576830238531584?ref_src=twsrc%5Etfw">October 13, 2022</a></blockquote> 

</div></div>
  </body>
</html>
