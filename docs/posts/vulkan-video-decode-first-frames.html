<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://poniesandlight.co.uk/reflect/island_video_decoder/">Original</a>
    <h1>Vulkan Video Decode: First Frames</h1>
    
    <div id="readability-page-1" class="page"><div>
    
  	<div><p>I recently <a href="https://github.com/tgfrerer/island/releases/tag/v0.12.0-vk-video-decode">wrote a video decoder &amp; player module that uses the Vulkan
Video decode API</a>, and integrated it into my R&amp;D engine,
Island.</p>
<p>It can decode and play 14 1080p@50 videos comfortably and draw all
that at 60fps, while only using the decode units of my GPU.</p>
<p>Unfortunately I can’t show a recording of this because the marine wildlife
documentary video that I used for testing is non-free. But I can share
a recording which shows locally sourced fauna instead. Behold Milo,
the house cat, whose antics metaphorically mirror my development
process:</p>
</div>
<p><iframe src="https://player.vimeo.com/video/889463078?h=9c2d5381e0?autoplay=0&amp;loop=0&amp;muted=0" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>
<p>It took a lot of tail-chasing to get there.</p>
<div>
	
<p>The <a href="https://docs.vulkan.org/spec/latest/chapters/video_extensions.html">Vulkan Video API</a> is a pretty unwieldy concern, and if you ever
felt that Vulkan was a “depth-first” (vs breadth-first) API, this
sentiment will be even more fully realized when using Vulkan Video.</p>
<p>I’m using this post and probably some future ones to retrace my steps,
in the hope that it will help me to better remember what I did, and
that it might allow others to not repeat my mistakes.</p>

<p>I had wanted to write a Vulkan Video player almost ever since Vulkan
Video was announced a couple of years ago. For Island it means that
I could finally have a hardware-accelerated video player module that
was self-contained. Vulkan Video Decode allows you to keep everything
running on the GPU throughout, which I find elegant: it means probably
<strong>best achievable performance</strong>, potentially <strong>lower memory
pressure</strong>, maybe <strong>better latency</strong> – and definitely <strong>total
control over resource synchronisation</strong>. But the low-level nature of
the API made it difficult for me to understand and formulate
a step-by-step plan.</p>
<p>On the surface of it, writing a video decoder and player (and
integrating it into an existing engine) looks like a strange
all-or-nothing proposition: After a couple of months of work digging
through the thicket of the Vulkan Video API, video codec specs, and
previous sins manifested in my own Vulkan framework code, there might
be some images animating — or not.</p>
<p>Is the pain worth it? Maybe. But then, undeniably, Vulkan Video <a href="https://www.thisdayinquotes.com/2010/03/george-mallory-coins-because-its-there.html?m=1">is
there</a>.</p>
<p>So, where to start this journey? Perhaps with a look at the lay of the
land.</p>

<p>As of today (November 2023), I could only find a small handful of open
source implementations and blog posts discussing Vulkan Video
implementations in any detail.</p>
<p>There are some presentations (<a href="https://www.youtube.com/watch?v=R5x6_nBRrv4">A Deep Dive into Vulkan
Video</a>, and <a href="https://www.google.com/search?tbm=vid&amp;q=vulkan%20video#fpstate=ive&amp;vld=cid:792abc2f,vid:uvz1GJ8A6ZM,st:0">Video
decoding in
Vulkan</a>)
recorded at Conferences - which are pretty thorough, but were pretty
tough for me to parse - from the implied knowledge it seems that the
intended audience for these talks are video decoding specialists
first, and graphics programmers second.</p>
<p>I poked at the <a href="https://github.com/nvpro-samples/vk_video_samples">NVIDIA vulkan video example</a> (which appears to
moonlight as the official Khronos example, but doesn’t seem to have
too many fans, and I coudn’t warm to it either; it seems to do too
many things at once to be clearly instructive for a relative novice to
video coding like me).</p>
<p>To find out more about Video coding in general, and h.264 video
decoding in particular, there is of course no more accurate resource
than the <a href="https://www.itu.int/rec/T-REC-H.264">official h.264 spec</a>, which is useful, and super
detailed and verbose, and will tell you nothing about Vulkan Video.</p>
<p>This aspect is better covered by a few blog posts - Lynne’s <a href="https://lynne.ee/vulkan-video-decoding.html">blog post
</a>discusses how Vulkan Video compares to other hardware
accelerated decoder APIs; while <a href="https://twitter.com/turanszkij">János
Turánszki</a> probably wrote <a href="https://wickedengine.net/2023/05/07/vulkan-video-decoding/">the most
comprehensive post</a> so far (and the only accessible open-source
implementation and integration into a game engine that I could get my
hands upon). It describes how he brought Vulkan Video to <a href="https://wickedengine.net/">Wicked
Engine</a>, touches upon demuxing, creating video sessions,
managing the DPB, etc.</p>
<p>In case you wonder what a DPB is and if you should care, I believe
Daniel Rakos of <a href="https://rastergrid.com">rastergrid.com</a> wrote <a href="https://www.rastergrid.com/blog/multimedia/2021/05/video-compression-basics/">one of
the best intros to video coding</a> that I could find, where
all these things are explained.</p>

<p>While János’ blog gave me courage, Rastergrid’s blog showed me
a promising crack in what looked like an intimidating all-or nothing
API surface: The first frame of a video will usually be an I-frame,
and an I-frame can be decoded all by itself. This bears repeating:</p>
</div>
<div>
	
<blockquote>
	<p><span>&#34;The first frame of a video will usually be an I-frame, and an I-frame can be decoded all by itself.&#34;</span>
	</p>
</blockquote>
<p>Why is that important? Usually, in video decoding, frames are decoded
based on previous frames and previous decoder state, and implementing
this all in one go would mean a massive <a href="https://www.youtube.com/watch?v=q-JIfjNnnMA">leap of faith</a>.</p>
<p>Had I started by writing a full video player straight away, so many
things could have been subtly wrong at the same time that the
situation would have been un-debuggable, simply because I wouldn’t
have known what correct dynamic <span>states to expect</span><span>; after all, debugging a moving state machine is many times harder than debugging the non-moving thing</span>.</p>
</div>
<div>
	
<p>Since the first I-frame depends on no previous state, we have a way to
simplify radically: instead of allowing the decoder to progress, we
<span>reset it </span><span>at the beginning of every update cycle </span>and decode only
the first frame over and over again, until we know that everything
worked as expected. This gives us a first test and experiment, and one
that is easy, and reliable to reproduce, because it is essantially
stateless.</p>
<p>Instead of starting with a video player, I’m starting with a hardware
accelerated frame decoder.</p>
<h2 id="the-lure-of-the-mythical-first-black-triangle">The Lure of The Mythical First Black Triangle <a href="#the-lure-of-the-mythical-first-black-triangle"></a></h2>
<p>Now that we have identified the <a href="http://rampantgames.com/blog/?p=7745">mythical first black
triangle</a> of video decoding, we
know our first goal: it is to see that first I-frame decoded.</p>
<p>On screen, we will only see a single frame, the first frame of the
video. It won’t move. But if this frame displays - or becomes visible
in a frame debugger, we know:</p>
<ol>
<li>Loading the video file works</li>
<li>Demuxing the video file works</li>
<li>Uploading slice data to GPU buffers works</li>
<li>Setting up a video decode queue works</li>
<li>Setting up a decode session works</li>
<li>Decoding the frame works</li>
</ol>
<p>Once we can see this first I-frame, we are at about half-way to having
a working video player. But to get to this point, we have to implement
all the things listed above, in about the order listed.</p>
<p>So, let’s start writing some code.</p>
<h2 id="1-load-the-video-file">1. Load the Video File <a href="#1-load-the-video-file"></a></h2>
<p>Nothing fancy to see here. I got lazy and slurped the whole <code>.mp4</code>
file (all 500kb of it) into a <code>std::vector&lt;char&gt;</code>.</p>
<h2 id="2-demux-the-video-file">2. Demux the Video File <a href="#2-demux-the-video-file"></a></h2>
<p>This byte-array can’t be directly mapped to GPU memory, however, as
the Vulkan Video decoder expects only raw video frame data, and the
mp4 file (our byte-array) contains this data muxed (interleaved) with
stream data (such as audio, subtitles, etc).</p>
<p>To extract video slice data, I then followed the steps outlined by
János in his <a href="https://wickedengine.net/2023/05/07/vulkan-video-decoding/">blog post</a> on bringing Vulkan Video to Wicked
Engine. I’m using <a href="https://github.com/lieff/minimp4">minimp4</a>, just like him. Minimp4 is
a minimalistic header-only, C-library to demux mp4 files, released
into the Public Domain, and a perfect fit for a c-ish engine.</p>
<h3 id="foreman">Foreman <a href="#foreman"></a></h3>
</div>
<div>
	
<p>As a bonus, minimp4 comes with <a href="https://github.com/lieff/minimp4/blob/master/vectors/out_ref.mp4">a test video of an enthusiastic
foreman</a>
gesticulating at a building site, which I enthusiastically used for
the initial bringup. It is a useful file to keep around.</p>
<figure>
<img loading="lazy" src="https://news.wosu.org/img/reflect/island_video_decoder/foreman.jpg" alt="an enthusiastic foreman" title="an enthusiastic foreman"/>
<figcaption>
    Fig. 1: <a href="https://github.com/lieff/minimp4/blob/master/vectors/out_ref.mp4">out_ref.mp4</a>(screenshot) It looks like this video snippet has been used in countless scientific papers (<a href="https://www.researchgate.net/publication/228961623_A_New_Unequal_Error_Protection_Technique_Based_on_the_Mutual_Information_of_the_MPEG-4_Video_Frames_over_Wireless_Networks">example</a>), but nobody seems to specifically credit the file, which is a bit sad, because I’m sure there’s an interesting story to this clip.
</figcaption>
</figure>
<h3 id="media-analyzer">Media Analyzer <a href="#media-analyzer"></a></h3>
<p>To test whether demuxing and parsing worked, I compared the output
from the debugger with what I could find out about the test file by
dropping it onto Media Analyzer. This little wonder is a local web app
(it doesn’t upload any video data as far as I can tell) which allows
you to inspect the structure of an mp4 file:
<a href="https://media-analyzer.pro/app">https://media-analyzer.pro/app</a></p>
<figure>
<img loading="lazy" src="https://news.wosu.org/img/reflect/island_video_decoder/media_analyzer.png" alt="media analyzer screenshot" title="media analyzer screenshot"/>
<figcaption>
    <a href="https://media-analyzer.pro/app">media analyzer</a> is great: here we can see that at address <code>0000002c</code> in the file, the I-Frame begins. </figcaption>
</figure>
<h2 id="3-upload-slice-data-to-gpu-buffers">3. Upload slice data to GPU buffers <a href="#3-upload-slice-data-to-gpu-buffers"></a></h2>
<p>For uploading video slice data to the GPU, I initially took
a shortcut: I uploaded <em>all the slices</em> (that is all the raw video
data) onto one big host-mapped GPU buffer. I made sure that the
individual slices were properly aligned at boundaries, according to
what the driver reported for <code>VkVideoCapabilitiesKHR</code> as
<code>minBitstreamBufferSizeAlignment</code>, and
<code>minBitstreamBufferOffsetAlignment</code>. Respecting these offsets is
important, but fortunately the Vulkan Validation layers will pipe up
if you mess up here.</p>
</div>
<div>
	
<p>Speaking of validation layers: these are some of the best things about
Vulkan. They are effectively a very comprehensive suite of unit tests
that comes at a very fair performance cost, and you should switch them
on whenever you’re running in debug.</p>
<h2 id="4-set-up-a-vulkan-video-decode-queue">4. Set Up a Vulkan Video Decode Queue <a href="#4-set-up-a-vulkan-video-decode-queue"></a></h2>
<p>The next bit of work, setting up a video decode queue, was already
taken care of by Island, where I can require a pass to be a video
decode pass, and the engine will set things up accordingly. Because
Video Decode is an extension to Vulkan, we must make sure that it (and
other extensions that it depends on) are loaded when we initialize the
Vulkan backend.</p>
<p>To this effect, I added a global <code>init()</code> method to my video player
API, which users of the video player must call before instantiating
an Island app that wants to use the video player module. <code>init()</code>
then adds to the shopping list of extensions and capabilities (and
queue capabilities!) required from the Vulkan backend, so that when it
is initialized, it can ensure to match all there requirements, or bail
out.</p>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>void</span> <span>le_video_decoder_init</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>// adding this during initialisation means there is no way for the application
</span></span></span><span><span><span></span>  <span>// to start if it does not support the correct extension
</span></span></span><span><span><span></span>  <span>bool</span> <span>result</span> <span>=</span> <span>true</span><span>;</span>
</span></span><span><span>  <span>result</span> <span>&amp;=</span> <span>le_backend_vk</span><span>::</span><span>settings_i</span><span>.</span><span>add_required_device_extension</span><span>(</span> <span>VK_KHR_VIDEO_QUEUE_EXTENSION_NAME</span> <span>);</span>
</span></span><span><span>  <span>result</span> <span>&amp;=</span> <span>le_backend_vk</span><span>::</span><span>settings_i</span><span>.</span><span>add_required_device_extension</span><span>(</span> <span>VK_KHR_VIDEO_DECODE_QUEUE_EXTENSION_NAME</span> <span>);</span>
</span></span><span><span>  <span>result</span> <span>&amp;=</span> <span>le_backend_vk</span><span>::</span><span>settings_i</span><span>.</span><span>add_required_device_extension</span><span>(</span> <span>VK_KHR_VIDEO_DECODE_H264_EXTENSION_NAME</span> <span>);</span>
</span></span><span><span>  <span>assert</span><span>(</span> <span>result</span> <span>&amp;&amp;</span> <span>&#34;We must successfully require vk extensions for video&#34;</span> <span>);</span>
</span></span><span><span>  
</span></span><span><span>  <span>VkQueueFlags</span> <span>queue_capablitities</span><span>[]</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>VK_QUEUE_VIDEO_DECODE_BIT_KHR</span> <span>|</span> <span>VK_QUEUE_TRANSFER_BIT</span><span>,</span> <span>// video queues must also support transfer, and we want a video decode queue
</span></span></span><span><span><span></span>  <span>};</span>
</span></span><span><span>
</span></span><span><span>  <span>result</span> <span>=</span> <span>le_backend_vk</span><span>::</span><span>settings_i</span><span>.</span><span>add_requested_queue_capabilities</span><span>(</span> <span>queue_capablitities</span><span>,</span> <span>ARRAY_SIZE</span><span>(</span> <span>queue_capablitities</span> <span>)</span> <span>)</span> 
</span></span><span><span>
</span></span><span><span>  <span>if</span> <span>(</span> <span>false</span> <span>==</span> <span>result</span> <span>)</span> <span>{</span>
</span></span><span><span>    <span>logger</span><span>.</span><span>error</span><span>(</span> <span>&#34;Could not request queue capabilities required for video decode.&#34;</span> <span>);</span> <span>}</span> 
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><h3 id="video-player-api-surface">Video Player API Surface <a href="#video-player-api-surface"></a></h3>
<p>Maybe this is the point where I should talk a little about the API
surface of the video player. Here is the minimum viable video player
API that I came up with.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>struct</span> <span>le_video_decoder_api</span> <span>{</span>
</span></span><span><span>  <span>struct</span> <span>le_video_decoder_interface_t</span> <span>{</span>
</span></span><span><span>    <span>void</span>                   <span>(</span><span>*</span> <span>init</span>    <span>)(</span> <span>);</span>
</span></span><span><span>    <span>le_video_decoder_o</span> <span>*</span>   <span>(</span><span>*</span> <span>create</span>  <span>)(</span> <span>le_renderer_o</span><span>*</span> <span>renderer</span><span>,</span> <span>char</span> <span>const</span> <span>*</span> <span>file_path</span> <span>);</span>
</span></span><span><span>    <span>void</span>                   <span>(</span><span>*</span> <span>destroy</span> <span>)(</span> <span>le_video_decoder_o</span><span>*</span> <span>self</span> <span>);</span>
</span></span><span><span>    <span>void</span>                   <span>(</span><span>*</span> <span>update</span>  <span>)(</span> <span>le_video_decoder_o</span><span>*</span> <span>self</span><span>,</span> <span>le_rendergraph_o</span><span>*</span> <span>rg</span><span>,</span> <span>uint64_t</span> <span>ticks</span> <span>);</span>
</span></span><span><span>    <span>void</span>                   <span>(</span><span>*</span> <span>play</span>    <span>)(</span> <span>le_video_decoder_o</span><span>*</span> <span>self</span> <span>);</span>
</span></span><span><span>  
</span></span><span><span>    <span>le_img_resource_handle</span> <span>(</span><span>*</span> <span>get_latest_available_frame</span> <span>)(</span><span>le_video_decoder_o</span><span>*</span> <span>self</span><span>);</span>
</span></span><span><span>  
</span></span><span><span>    <span>// not shown: seek, on_playback_complete_callback, pause, get_pause_state... 
</span></span></span><span><span><span></span>  <span>}</span>
</span></span><span><span><span>}</span> 
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>A few things are maybe worth pointing out:</p>
<ul>
<li><code>create()</code> will attempt to load the file given by the path and will
return a <code>nullptr</code> if it was not successful. This means that if the
file could not be found or opened, you don’t get a video player.</li>
<li><code>update()</code> does most of the heavy lifting. You are only supposed to
call this method once per video player per frame, and ideally before
you refer to the latest available frame for anything.</li>
<li><code>get_latest_available_frame()</code> gives you an image handle holding the
currentmost image (after calling <code>update()</code>). The image handle is
yours- but only for the duration of the current render frame.</li>
<li><code>play()</code> doesn’t do very much, it just changes the playback state of
the video player. There are also methods to set the state to
<code>pause()</code> and to query the playback state, but I have left these out
here for brevity’s sake.</li>
</ul>

<p>After this little aspirational interlude, let’s focus back on the
arguably most important function call of this exercise. It looks
deceptively simple:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span> <span>vkCmdDecodeVideoKHR</span><span>(</span> <span>cmd</span><span>,</span> <span>&amp;</span><span>video_decode_info</span> <span>);</span> 
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>The devil is of course in the <code>&amp;info</code>. And he is of a rather bureaucratic disposition: Even in <span>its simplest form</span><span>, not using any reference slots since we’re only decoding the first I-Frame and then throwing it away</span>, we must fill in quite a lot of structs. That can get complicated pretty quickly.</p>
<p>To wit, here is a screenshot which shows how the Nvidia Video Decoding example
sets up its <code>VkVideoDecodeInfoKHR</code>. The pink highlights show where the struct
is accessed, and it becomes clear that you will have to keep a lot of things in
your head at the same time if you want to follow this code.</p>
<figure>
<img loading="lazy" src="https://news.wosu.org/img/reflect/island_video_decoder/nvidia_example_video_decode_info.png" alt="screenshot nvidia example" title="screenshot nvidia example"/>
<figcaption>
    A screenshot showing part of the <a href="https://github.com/nvpro-samples/vk_video_samples/blob/b1358338631dfaf0deb7759c84e0fbd95c9464a7/vk_video_decoder/libs/VkVideoParser/VulkanVideoParser.cpp#L1700"><code>DecodePicture</code> function</a> of the NVIDIA Video Decoding example implementation. This code does a lot of things at once.</figcaption>
</figure>
<p>Fortunately there is a way to make this a bit more legible. With
C++20, you can almost achieve the legibility of C99 — by using the
brand spanking new <a href="https://en.cppreference.com/w/cpp/language/aggregate_initialization#Designated_initializers">designated initializers</a>.
Here is how we could initialize this struct:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>VkVideoDecodeInfoKHR</span> <span>video_decode_info</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span>               <span>=</span> <span>VK_STRUCTURE_TYPE_VIDEO_DECODE_INFO_KHR</span><span>,</span><span>// VkStructureType
</span></span></span><span><span><span></span>  <span>.</span><span>pNext</span>               <span>=</span> <span>&amp;</span><span>h264_picture_info</span><span>,</span>                     <span>// must contain a VkVideoDecodeH264PictureInfoKHR *
</span></span></span><span><span><span></span>  <span>.</span><span>flags</span>               <span>=</span> <span>0</span><span>,</span>                                      <span>// VkVideoDecodeFlagsKHR, optional
</span></span></span><span><span><span></span>  <span>.</span><span>srcBuffer</span>           <span>=</span> <span>decoder</span><span>-&gt;</span><span>gpu_bitstream_buffer</span><span>.</span><span>buffer</span><span>,</span>   <span>// VkBuffer
</span></span></span><span><span><span></span>  <span>.</span><span>srcBufferOffset</span>     <span>=</span> <span>0</span><span>,</span>                                      <span>// VkDeviceSize
</span></span></span><span><span><span></span>  <span>.</span><span>srcBufferRange</span>      <span>=</span> <span>first_i_frame_size_in_bytes</span><span>,</span>            <span>// VkDeviceSize, aligned to minBitstreamBufferSizeAlignment
</span></span></span><span><span><span></span>  <span>.</span><span>dstPictureResource</span>  <span>=</span> <span>dst_picture_resource</span><span>,</span>                   <span>// VkVideoPictureResourceInfoKHR
</span></span></span><span><span><span></span>  <span>.</span><span>pSetupReferenceSlot</span> <span>=</span> <span>nullptr</span><span>,</span>                                <span>// VkVideoReferenceSlotInfoKHR const * 
</span></span></span><span><span><span></span>  <span>.</span><span>referenceSlotCount</span>  <span>=</span> <span>0</span><span>,</span>                                      <span>// uint32_t
</span></span></span><span><span><span></span>  <span>.</span><span>pReferenceSlots</span>     <span>=</span> <span>0</span><span>,</span>                                      <span>// VkVideoReferenceSlotInfoKHR const * 
</span></span></span><span><span><span></span><span>};</span>
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>This looks prettier, but can get rather tedious to type out and
transcribe, and since C++20 (in contrast to good old C99) requires the
order of initializers to match field declaration order, you cannot
omit any fields without risking to make things really fragile in the
future.</p>
</div>
<div>
	
<p>To help with this, <a href="https://github.com/tgfrerer/island/blob/:xaff19be5e8fe91942eeaa6713ebde5e9cfdf4e0ff/scripts/codegen/gen_vk_structs.py">I wrote a little python script</a>
which taps into the Vulkan SDK codegen infrastructure to generate
little struct scaffolds on-demand, and from inside an interactive
window. This script comes with Island, inside <code>scripts/codegen/</code>, but
can be used <span>perfectly well without it</span><span>, it only depends on the Vulkan SDK and Python being installed</span>.</p>
<p>Anyway, back to our <code>VkVideoDecodeInfoKHR</code>. Note how I set anything
concerning Reference Slots to <code>0</code> or <code>nullptr</code> — this is because we
don’t care about any Reference Pictures for our initial attempt at
decoding the first I-Frame.</p>
<p>But we do, however, need to tell the decode operation where to store
the decoded Image, and for this we use an image view that we created
earlier for precisely this purpose. If we know its handle, we can set
up the <code>dstPictureResource</code> as follows:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>VkVideoPictureResourceInfoKHR</span> <span>dst_picture_resource</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span>            <span>=</span> <span>VK_STRUCTURE_TYPE_VIDEO_PICTURE_RESOURCE_INFO_KHR</span><span>,</span>           <span>// VkStructureType
</span></span></span><span><span><span></span>  <span>.</span><span>pNext</span>            <span>=</span> <span>nullptr</span><span>,</span>                                                     <span>// void *, optional
</span></span></span><span><span><span></span>  <span>.</span><span>codedOffset</span>      <span>=</span> <span>{</span> <span>0</span><span>,</span> <span>0</span> <span>},</span>                                                    <span>// VkOffset2D
</span></span></span><span><span><span></span>  <span>.</span><span>codedExtent</span>      <span>=</span> <span>{</span> <span>decoder</span><span>-&gt;</span><span>video_data</span><span>-&gt;</span><span>width</span><span>,</span> <span>decoder</span><span>-&gt;</span><span>video_data</span><span>-&gt;</span><span>height</span> <span>},</span> <span>// VkExtent2D
</span></span></span><span><span><span></span>  <span>.</span><span>baseArrayLayer</span>   <span>=</span> <span>0</span><span>,</span>                                                           <span>// uint32_t
</span></span></span><span><span><span></span>  <span>.</span><span>imageViewBinding</span> <span>=</span> <span>decoder_memory_frame</span><span>-&gt;</span><span>maybe_dst_image_info</span><span>-&gt;</span><span>dst_image_view</span><span>,</span>  <span>// VkImageView
</span></span></span><span><span><span></span><span>};</span>
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><h2 id="5-setting-up-a-video-decode-session">5. Setting up a Video Decode Session <a href="#5-setting-up-a-video-decode-session"></a></h2>
<p>The <code>vkCmdDecodeVideoKHR</code> command above must happen <span>inside an active Video Decode Session</span><span> (this is similar to how draw commands must be placed inside Renderpass Begin|End commands)</span>.</p>
<p>Creating the Video Decode Session object is fairly straightforward, but to use
it, the Session requires its own <code>vkVideoSessionParametersKHR</code> object, which is
positively humungous. It (and its dependent structures) is arguably the most
work to set up.</p>
</div>
<div>
	
<p>Fortunately, this is mostly typing work filling in the forms, pardon, structs
for the SPS (Sequence Parameter Set) and the PPS (Picture Parameter Set).
Minimp4 will have extracted these values for us — all we have to do is to
transcribe these values into the appropriate Vulkan struct fields, which are
generally easy to find.</p>
<p>The reason the parameter object is not directly compiled into the Session is
that these parameters may change per-frame. Fortunately, this seems to happen
only very rarely (at least in the few videos that I used for testing) so for
decoding just the first frame we should be fine setting up the video decode
session with just one parameter object.</p>
<h3 id="two-things-that-tripped-me-up-here">Two things that tripped me up here: <a href="#two-things-that-tripped-me-up-here"></a></h3>
<ol>
<li>The very first time we use the video decode session (and only then!), we
must explicitly reset it. This happens by recording a video coding control
command into the decoding command buffer:</li>
</ol>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>VkVideoCodingControlInfoKHR</span> <span>video_coding_control_info</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span> <span>=</span> <span>VK_STRUCTURE_TYPE_VIDEO_CODING_CONTROL_INFO_KHR</span><span>,</span> <span>// VkStructureType
</span></span></span><span><span><span></span>  <span>.</span><span>pNext</span> <span>=</span> <span>nullptr</span><span>,</span>                                         <span>// void *, optional
</span></span></span><span><span><span></span>  <span>.</span><span>flags</span> <span>=</span> <span>VK_VIDEO_CODING_CONTROL_RESET_BIT_KHR</span><span>,</span>           <span>// VkVideoCodingControlFlagsKHR
</span></span></span><span><span><span></span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>vkCmdControlVideoCodingKHR</span><span>(</span> <span>cmd</span><span>,</span> <span>&amp;</span><span>video_coding_control_info</span> <span>);</span> 
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><ol start="2">
<li>If a video stream does not explitly set its chroma format (I’m
looking at you, Foreman), then the chroma format can be inferred from
the video’s <em>video profile</em>. Any profile smaller than <code>IDC_HIGH</code>
implies <code>STD_VIDEO_H264_CHROMA_</code> <code>FORMAT_IDC_420</code> by default. Not checking for
this will most likely set a default chroma format value of <code>0</code> which
is incorrect, as <code>0</code> mapps to
<code>STD_VIDEO_H264_CHROMA_FORMAT</code> <code>_IDC_MONOCHROME</code>. This is pretty
important, because while most other parameters are a bit forgiving,
messing the chroma format up will cause the decoder to (silently) fail
and you won’t see anything, not even strange artifacts.</li>
</ol>

<p>Once we have everything set up, we need to somehow be able to tell if
everything worked okay. We could assume everything worked and go ahead
and implement the infrastructure to display the image on screen, but
that would need some extra steps (synchronisation, mostly, and queue
ownership transfers). These extra steps are extra opportunities for
things to go wrong, and so for now we’d just be happy to know that
somewhere in GPU memory there sits a correctly decoded image.</p>
<p>Now, without seeing the image, how can we tell whether decoding went
well? Query and you shall be returned an answer: we just have to ask
nicely. There is a special <code>VkQuery</code> that can be used to interrogate
the result of a <code>vkCmdDecodeVideoKHR</code> command. If the query reports
anything other than success or times out, we know something went
wrong. If it reports success, then we know all’s well, and we should
have a correctly decoded image somewhere.</p>
<p>To issue queries, you must first create a query pool, from which
queries can be allocated. We only need one query per <em>in-flight</em>
frame: Once the frame decode command and its query have finished
executing on the GPU, you can read the result of the query and re-use
it.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>VkQueryPoolCreateInfo</span> <span>pool_create_info</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span>              <span>=</span> <span>VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO</span><span>,</span> <span>// VkStructureType
</span></span></span><span><span><span></span>  <span>.</span><span>pNext</span>              <span>=</span> <span>&amp;</span><span>self</span><span>-&gt;</span><span>video_profile_info</span><span>,</span>                <span>// VkVideoProfileInfoKHR* info chain
</span></span></span><span><span><span></span>  <span>.</span><span>flags</span>              <span>=</span> <span>0</span><span>,</span>                                        <span>// VkQueryPoolCreateFlags, optional
</span></span></span><span><span><span></span>  <span>.</span><span>queryType</span>          <span>=</span> <span>VK_QUERY_TYPE_RESULT_STATUS_ONLY_KHR</span><span>,</span>     <span>// VkQueryType
</span></span></span><span><span><span></span>  <span>.</span><span>queryCount</span>         <span>=</span> <span>10</span><span>,</span>                                       <span>// uint32_t
</span></span></span><span><span><span></span>  <span>.</span><span>pipelineStatistics</span> <span>=</span> <span>0</span><span>,</span>                                        <span>// VkQueryPipelineStatisticFlags, optional
</span></span></span><span><span><span></span><span>};</span>
</span></span><span><span><span>vkCreateQueryPool</span><span>(</span> <span>self</span><span>-&gt;</span><span>device</span><span>,</span> <span>&amp;</span><span>pool_create_info</span><span>,</span> <span>nullptr</span><span>,</span> <span>&amp;</span><span>self</span><span>-&gt;</span><span>vk_query_pool</span> <span>);</span>
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>Note that the query pool must be initialized with a pointer to your
video profile info - a lot of the Vulkan objects allocated and
associated with video decoding need to know about this info, and it’s
best to keep these around. I store these setting objects with the
decoder, so that they are available for the full lifetime of the
decoder.</p>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="c"><span><span><span>self</span><span>-&gt;</span><span>settings</span><span>.</span><span>decode_h264_profile_info</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span>         <span>=</span> <span>VK_STRUCTURE_TYPE_VIDEO_DECODE_H264_PROFILE_INFO_KHR</span><span>,</span>
</span></span><span><span>  <span>.</span><span>pNext</span>         <span>=</span> <span>nullptr</span><span>,</span>
</span></span><span><span>  <span>.</span><span>stdProfileIdc</span> <span>=</span> <span>STD_VIDEO_H264_PROFILE_IDC_BASELINE</span><span>,</span>
</span></span><span><span>  <span>.</span><span>pictureLayout</span> <span>=</span> <span>VK_VIDEO_DECODE_H264_PICTURE_LAYOUT_INTERLACED_INTERLEAVED_LINES_BIT_KHR</span><span>,</span>
</span></span><span><span><span>};</span>
</span></span><span><span><span>self</span><span>-&gt;</span><span>settings</span><span>.</span><span>profile_info</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>.</span><span>sType</span>               <span>=</span> <span>VK_STRUCTURE_TYPE_VIDEO_PROFILE_INFO_KHR</span><span>,</span>
</span></span><span><span>  <span>.</span><span>pNext</span>               <span>=</span> <span>&amp;</span><span>self</span><span>-&gt;</span><span>settings</span><span>.</span><span>decode_h264_profile_info</span><span>,</span>
</span></span><span><span>  <span>.</span><span>videoCodecOperation</span> <span>=</span> <span>VK_VIDEO_CODEC_OPERATION_DECODE_H264_BIT_KHR</span><span>,</span>
</span></span><span><span>  <span>.</span><span>chromaSubsampling</span>   <span>=</span> <span>VK_VIDEO_CHROMA_SUBSAMPLING_420_BIT_KHR</span><span>,</span>
</span></span><span><span>  <span>.</span><span>lumaBitDepth</span>        <span>=</span> <span>VK_VIDEO_COMPONENT_BIT_DEPTH_8_BIT_KHR</span><span>,</span>
</span></span><span><span>  <span>.</span><span>chromaBitDepth</span>      <span>=</span> <span>VK_VIDEO_COMPONENT_BIT_DEPTH_8_BIT_KHR</span><span>,</span>
</span></span><span><span><span>};</span>
</span></span></code></pre></td></tr></tbody></table>
</div>
</div></div>
<div>
	
<p>Once we have a query pool, we can associate a query to each frame that
we will decode. Just before the call to <code>vkCmdDecodeVideoKHR()</code> we
record a command to reset the current query, then begin the query, and
end it after the decode command. Once a frame has reached its
<code>VkFence</code> (meaning all its GPU operations have completed) we can read
the result of the query via <code>vkGetQueryPoolResults</code>.</p>

<p>It took a little while to get this far, and eventually, I managed to
get the Query to report <code>VK_QUERY_RESULT_STATUS_</code> <code>COMPLETE_KHR</code> — in
other words: success!</p>
<p>Time to take a frame debugger (<a href="https://developer.nvidia.com/nsight-graphics">Nvidia NSight</a> in my case) and
look at the image. But, alas, I could not get it to display the
decoded image. I could, however, look at the raw data, and what I saw
didn’t look like random leftover bytes — promising.</p>
<p>I saved the raw image data to a <code>.bin</code> file and imported it into GIMP.
A little bit of fiddling with the import settings, and … voila:</p>
<figure>
<img loading="lazy" src="https://news.wosu.org/img/reflect/island_video_decoder/first_foreman_raw_luma.png" alt="a look at some raw data saved via NVidia NSight" title="a look at some raw data saved via NVidia NSight"/>
<figcaption>
    A celebratory screenshot I took when I saw that the binary blob that I had stored via NSight turned out to be a decoded image plane.
</figcaption>
</figure>
<p>Why did I not see anything in NSight? It seems that NSight only allows
you to view image previews for images that have been created with the
usage flag <code>VK_IMAGE_USAGE_SAMPLED_BIT</code> set. That’s what I forgot to
do. Once I created my images with this usage flag, I could even see
them in NSight.</p>

<p><a href="https://duckduckgo.com/?t=ffab&amp;q=draw+the+rest+of+the+owl&amp;iax=images&amp;ia=images">Drawing the Rest of the Owl</a> means integrating the Video Decoder
into the existing engine, and implementing playback logic — another
long and winding road. There will be a few nice things worth visiting
upon: Frame-based sync! Inter-queue sync! Integration with the
rendergraph! Seamless loop and transport! Hardware-accelerated YUV
sampling!</p>
<p>But this post has already grown very long indeed, and this will have
to wait until another time…</p>
<figure>
<img loading="lazy" src="https://news.wosu.org/img/island_preview.png" alt="Island preview image" title="Island preview image"/>
<figcaption>
    If you want to take a look how the video player module turned out in the end, look no further than the <a href="https://github.com/tgfrerer/island/releases/tag/v0.12.0-vk-video-decode">Island github repository</a>, and the new <a href="https://github.com/tgfrerer/island/tree/wip/apps/examples/video_player_example">Island Video Player Example</a>.
</figcaption>
</figure>

<p>For now, to me, even though slightly less mystified, video coding
still appears a strange beast. The practice seems often done deep
inside corporations, or at some dark murky depths, and on the surface,
all that hints at the hardship and toil going on below is the
occasional <a href="https://github.com/mpv-player/mpv/blob/b9d351f02a3266b76256a90fc9c51f9d3cbf185d/demux/demux.h#L61">wail of desperation</a>
that tries to reach up to the light above.</p>
<p>But what joy it is to see the first frame decoded, and arriving at
that first stepping stone. What joy!</p>


	</div>
	
	
	
		<div>
			<h3>RSS:</h3>
			<p>Find out first about new posts by subscribing to the <a href="https://poniesandlight.co.uk/reflect/feed.xml">RSS Feed</a> <a href="https://poniesandlight.co.uk/reflect/feed.xml" type="application/rss+xml"><svg style="width: 1em; position:relative; bottom:-0.25em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm64 120c0 17.7-14.3 32-32 32s-32-14.3-32-32s14.3-32 32-32s32 14.3 32 32z"></path></svg></a></p>
		</div>
	
		<p>
			<h3>Further Posts:</h3>
		</p>
		
        </div></div>
  </body>
</html>
