<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://questdb.io/blog/billion-row-challenge-step-by-step/">Original</a>
    <h1>The Billion Row Challenge (1BRC) – Step-by-Step from 71s to 1.7s</h1>
    
    <div id="readability-page-1" class="page"><div><article><p>
  QuestDB is a high performance time series database with SQL 
  analytics that can power through data ingestion and analysis. 
  It&#39;s <a href="https://github.com/questdb/questdb">open source</a> 
  and integrates with many tools and languages. Give us a try!</p><hr/><p>As I was browsing my timeline on the boring afternoon of the New Year&#39;s Day
2024,
<a href="https://twitter.com/gunnarmorling/status/1741839724933751238" target="_blank" rel="noopener noreferrer">this tweet by Gunnar Morling</a>
jumped out:</p><blockquote><p>How fast can YOU aggregate 1B rows using modern #Java? Grab your threads, flex
your SIMD, and kick off 2024 true coder style by joining this friendly little
competition. Submissions accepted until Jan 31.</p></blockquote><p>The challenge was this:</p><blockquote><p>Write a Java program for retrieving temperature measurement values from a text
file and calculating the min, mean, and max temperature per weather station.
There’s just one caveat: the file has 1,000,000,000 rows!</p></blockquote><p>My first thought was, &#34;Pfft, min, mean and max, that&#39;s so simple!&#34; And the
dataset was simple as well: just 413 unique keys, of quite uniform, short
lengths. Super-simple data format. A whole <em>month</em> to do it. Where&#39;s the
challenge?? As is often the case, the devil was in the details.</p><p>It soon dawned on the contestants that calculating only min, mean and max made
the competition harder, not easier. But why? There wasn&#39;t one obvious place
consuming CPU cycles. Opportunities to make it even faster lay everywhere, even
in the darkest corners of the CPU architecture.</p><p>As a saving grace, the challenge was held out in the open on GitHub. Copying
others&#39; ideas wasn&#39;t just allowed, it was encouraged. This was to be a learning
experience, not a war of secrets.</p><p>It was also going to be a month-long frenzy of research, ingenuity, and just
plain <em>fun</em>. It grabbed the attention and devotion of hundreds of enthusiasts,
including at least a dozen or two top Java performance experts.</p><p>The winning solution is the one submitted by none other than Thomas Wuerthinger
(<a href="https://github.com/thomaswue" target="_blank" rel="noopener noreferrer">@thomaswue</a>), the lead of the GraalVM project —
that&#39;s the kind of heavyweights I&#39;m talking about! Along with several other key
contestants, he introduced many of the great ideas that everyone else grabbed
and incorporated into their own submissions.</p><p>My submission did quite well, ending up at spot #9. My QuestDB colleague,
Jaromir Hamala (<a href="https://github.com/jerrinot" target="_blank" rel="noopener noreferrer">@jerrinot</a>), fared even better,
placing 3rd — just 73 milliseconds behind the winner!</p><figure><div><p><img alt="Screenshot of 1BRC Scoreboard" src="https://questdb.io/img/blog/2024-02-20/1brc-scoreboard.webp" loading="lazy"/></p><figcaption>The Official 1BRC Scoreboard</figcaption></div></figure><h2><a aria-hidden="true" tabindex="-1" id="what-came-out-on-top"></a>What came out on top<a href="#what-came-out-on-top" title="Direct link to heading">#</a></h2><p>Now that you read the rules, can you guess what&#39;s the actual challenge? Can you
visualize what the winning code would look like? Here,
<a href="https://github.com/gunnarmorling/1brc/blob/main/src/main/java/dev/morling/onebrc/CalculateAverage_thomaswue.java" target="_blank" rel="noopener noreferrer">have a look!</a></p><p>For that matter, look at <em>any</em> of the top 10 solutions, including
<a href="https://github.com/gunnarmorling/1brc/blob/main/src/main/java/dev/morling/onebrc/CalculateAverage_mtopolnik.java" target="_blank" rel="noopener noreferrer">mine</a>,
and especially at the hot loop in each of them — the part of the code where the
program spends almost all of its time.</p><p>If you ever had the experience of writing a small program in C++ or Rust, and
then looking at the optimized machine code the compiler produced, you&#39;ll get
similar vibes here. Abstractions are spilled open, concerns are criss-crossing
and interleaving each other. A ton of utterly alien-looking, bit-twiddling
logic.</p><p>How could a human programmer possibly get to this point? Like in so many other
cases, it was people working together and improving step by step. Dozens of Java
experts iterated through many tricks and hacks, and as January rolled on, the
processing time kept dropping lower and lower.</p><p>The main thing I&#39;d like to show you in this post is that a good part of that
amazing speed comes from easy-to-grasp, reusable tricks that you could apply in
your code as well. Towards the end, I&#39;ll also show you some of the magical parts
that take it beyond that level.</p><h2><a aria-hidden="true" tabindex="-1" id="the-normal-implementation"></a>The &#34;normal&#34; implementation<a href="#the-normal-implementation" title="Direct link to heading">#</a></h2><p>OK: 1,000,000,000 rows - here we go!</p><p>For context, this is a sample of the temperature input file. Each line contains
a station name and a temperature reading:</p><p>And this is the expected output:</p><p>As a first take, let&#39;s apply some
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog1.java" target="_blank" rel="noopener noreferrer">idiomatic Java code</a>
that would pass muster with any seasoned Java developer:</p><p>This code:</p><ul><li>uses parallel Java streams, which put all the CPU cores to work</li><li>doesn&#39;t fall into any known performance traps like Java regex</li><li>leans heavily into all the great building blocks provided by the JDK</li></ul><p>On a Hetzner CCX33 instance with OpenJDK 21.0.2, it takes 71 seconds to
complete. But the best solution takes 1.5 seconds — that&#39;s a jaw-dropping 47
times faster! As we said, the way to get there is step by step, so let&#39;s start
with the first one.</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-0-choose-a-good-vm"></a>Optimization 0: Choose a good VM<a href="#optimization-0-choose-a-good-vm" title="Direct link to heading">#</a></h2><p>Before we touch the code, there&#39;s a low effort way to speed up your program: use
a modernized JVM. Many production deployments still run on Java 8 or 11, but the
pace of progress since those days has been significant.</p><p>During the 1BRC challenge, we found that <a href="https://www.graalvm.org/" target="_blank" rel="noopener noreferrer">GraalVM</a> is
one damn fast JVM. It also supports compiling into a native binary, which
eliminates the JVM startup cost.</p><p>By simply downloading GraalVM and making it the default, my solution improved
from 71 seconds to 66 — a solid 7.5% improvement for very little effort.</p><p>When we get deeper into optimizing and bring down the runtime to 2-3 seconds,
eliminating the JVM startup provides another 150-200ms in relief. That becomes a
big deal.</p><h2><a aria-hidden="true" tabindex="-1" id="first-profile-then-optimize"></a>First profile, then optimize<a href="#first-profile-then-optimize" title="Direct link to heading">#</a></h2><p>Every successful 1BRC contestant used profiling of one kind or another to guide
their optimization efforts. I used a combination of three tools:</p><ol><li>Good old
<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/visualvm/" target="_blank" rel="noopener noreferrer">VisualVM</a></li><li><a href="https://github.com/async-profiler/async-profiler" target="_blank" rel="noopener noreferrer">Async Profiler</a></li><li><a href="https://perf.wiki.kernel.org/index.php/Tutorial" target="_blank" rel="noopener noreferrer"><code>perf</code></a> command-line tool</li></ol><p>Many people consider VisualVM outdated, but it harbors a hidden gem: The
VisualGC plugin. You have to install it from the Tools→Plugins menu. Once you
attach it to a running Java program, VisualGC shows up as the rightmost tab in
the window.</p><p>Be sure to select the shortest refresh period (100 ms), and then enjoy the show.
A realtime animation of all the memory regions the garbage collector maintains,
along with a graph of JIT compilations and GC runs will appear. I used to spend
hours staring at this oddly satisfying, complex dance of GC&#39;s cogwheels. For the
1BRC program, I added a <code>while (true)</code> statement to keep processing the input
file forever; otherwise things just flash by.</p><p>The Async Profiler came from following Gunnar&#39;s advice on the
<a href="https://github.com/gunnarmorling/1brc?tab=readme-ov-file#flamegraphprofiling" target="_blank" rel="noopener noreferrer">1BRC GitHub page</a>.
The <code>jbang</code> tool provides very convenient access to it. You run the program
once, and get an HTML file with a flamegraph. The flamegraph then tells you
which functions/methods your program is spending the most time in.</p><p>The third tool, <code>perf</code>, has many features, but for Java the most popular choice
is <code>perf stat</code>. It doesn&#39;t analyze any specific method, but gives you insight
into low-level CPU counters. It shows:</p><ul><li>How many instructions it executed</li><li>How many branches and memory accesses</li><li>How many of those were branch/L1 cache misses.</li></ul><p>To receive these insights, I used the following command:</p><p>VisualGC was the most useful in the initial optimization phase. Then, once I
sorted out allocation, the flamegraph proved highly useful to pinpoint the
bottlenecks in the code. However, once the runtime went below ~3 seconds, its
usefulness declined. At this level we&#39;re squeezing out performance not from
methods, but from individual CPU instructions. This is where <code>perf stat</code> became
the best tool.</p><p>For reference, here&#39;s the <code>perf stat</code> report for our basic implementation:</p><p>It&#39;s most helpful to interpret the numbers on a per-row basis (dividing
everything by 1 billion). We can see that the program spends more than 2,000
instructions on each row. No need to get into more details; initially we&#39;ll be
driving down just this metric.</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-1-parallelize-io"></a>Optimization 1: Parallelize I/O<a href="#optimization-1-parallelize-io" title="Direct link to heading">#</a></h2><p>A quick profiling run with VisualVM and
<a href="https://questdb.io/html/blog/profile-blog1.html" target="_blank" rel="noopener noreferrer">flamegraph</a> reveals no clear
bottleneck for our initial Streams API code.</p><blockquote><p><strong>Note:</strong> Scroll down the flamegraph page to see the graph!</p></blockquote><p>The time divides roughly equally among three main tasks:</p><ol><li><code>BufferedReader</code> work that outputs a string for each line</li><li>Processing these lines</li><li>Garbage collection (GC)</li></ol><p>VisualVM shows GC cycles running like crazy, 10 times per second or more. What&#39;s
worse, there&#39;s some spilling to the Old generation, triggering background GC
runs as well. We have to decide what to attack first.</p><p>The first thing most of us at the challenge realized was that we have to
parallelize the I/O. In the above code, a single thread does all the file
reading and emits a stream of lines. This includes finding the newline and
allocating a string for each line. On the other hand, the entire input file fits
into the disk cache. It&#39;s a great target for parallelization.</p><p>One tried-and-true approach is to split the file into as many chunks as there
are threads, and process each chunk independently. Unfortunately, in order to
take that step, we have to say goodbye to the concise Streams API and do
everything by hand.</p><p>We could read the chunks using the API of <code>RandomAccessFile</code>, but since it
doesn&#39;t natively support buffered reading, it would be a quirky implementation
that would involve copying from the native memory to the Java buffer.</p><p>Instead, everyone went for the <code>mmap</code> approach. This meant that you would work
with the file as if it was a large in-memory array. Java has supported <code>mmap</code>
for a long time, relying on the <code>ByteBuffer</code> API to read the native memory. It
uses <code>int</code> for indexing, limiting the mapped region size to 2 GB.</p><p>The JDK team is currently introducing a newer API based on <code>long</code> indexing,
<code>MemorySegment</code>. In the spirit of 1BRC, which encourages using the latest and
greatest Java features, let&#39;s go with that:</p><p>There are some finicky details involved in finding the exact place to split the
files, launch threads, wait on them, and so on. Tending to these details sees
our code explode from the initial 17 lines to 120. You can review it
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog2.java" target="_blank" rel="noopener noreferrer">here</a>
(for now we&#39;re using the commented-out &#34;Variant 1&#34; at
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog2.java#L84C20-L84C29" target="_blank" rel="noopener noreferrer">line 84</a>).</p><p>Let&#39;s focus on a few key snippets.</p><p>First, the hot loop now looks like this:</p><p>With the Streams API and <code>BufferedReader</code> gone, we run a hand-coded function,
<code>findByte()</code>, to find the separator characters. This avoids creating a string
for the whole line, but still creates strings for the name and the temperature,
using the method named <code>stringAt()</code>. Here are these two methods:</p><p>We also added code to collect the partial results from all the threads and merge
them. All put together, this brings the processing time down by a whopping 4x,
from 66 to 17 seconds!</p><p>On any other day, you may congratulate your expert self on this achievement. But
in the 1BRC, we were just getting started.</p><p>Let&#39;s see the <code>perf stat</code> report on this code:</p><p>We halved the number of instructions per row to 945.</p><p>Another <a href="https://questdb.io/html/blog/profile-blog2-variant1.html" target="_blank" rel="noopener noreferrer">flamegraph</a> reveals
that GC time has almost disappeared. But in VisualVM, we can see there&#39;s still a
lot of minor GC runs, although they use much less CPU because there&#39;s no more
promotion to the Old generation.</p><p>The CPU is now spending most of its time in <code>stringAt</code>, primarily in string
creation and in copying the data from native memory into a heap-allocated
<code>byte[]</code>. Significant time is also spent in <code>Map.computeIfAbsent()</code>,
<code>Double.parseDouble()</code>, and <code>findByte()</code>.</p><p>Let&#39;s attack temperature parsing first.</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-2-directly-parse-temperature-as-int"></a>Optimization 2: Directly parse temperature as int<a href="#optimization-2-directly-parse-temperature-as-int" title="Direct link to heading">#</a></h2><p>We can improve temperature parsing a lot. As it is, first we allocate a
<code>String</code>, then call <code>parseDouble()</code> on it, and then convert to <code>int</code> for
efficient storage and calculation. Instead, we should
directly create the integer:</p><p>This code is in the
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog2.java" target="_blank" rel="noopener noreferrer">same file as above</a>,
only using &#34;Variant 2&#34; at
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog2.java#L88" target="_blank" rel="noopener noreferrer">line 88</a>.</p><p>With this change alone, our time drops by 1.6x, to 11 seconds. Not only do we
spend much less CPU cycles on parsing, we also eliminate the allocation of a
temporary <code>String</code>.</p><p>And now, the <code>perf stat</code> report:</p><p>Instruction count dropped by another 1.6x, down to 607 per row.</p><p>The new <a href="https://questdb.io/html/blog/profile-blog2-variant2.html" target="_blank" rel="noopener noreferrer">flamegraph</a> shows
that temperature parsing shrunk from 21% of total time to just 6%. The time
spent in <code>stringAt()</code> has also dropped, since we now call it only once. However,
it still looms large, at 35% of total time.</p><p>What can we do?</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-3-custom-hashtable"></a>Optimization 3: Custom hashtable<a href="#optimization-3-custom-hashtable" title="Direct link to heading">#</a></h2><p>We&#39;d like to avoid calling <code>stringAt()</code> for the station name, because it
involves copying the data and initializing a new string instance. In almost all
cases, the only purpose of that instance is to find the existing entry in the
<code>HashMap</code>.</p><p>However, avoiding calls to <code>stringAt()</code> will be pretty hard to accomplish if we
stick to using <code>HashMap</code>. It expects that we pass in an instance of the key
class that is equal to an existing instance. We&#39;d rather avoid that. So… maybe
we should build a custom hashtable?</p><p>This may sound crazy at first. Isn&#39;t Java supposed to already have a
super-optimized HashMap implementation? Were they all lying to us when they said
&#34;don&#39;t be a smartass, use the standard library&#34;?</p><p>Well, no. In general, they&#39;re totally right.</p><p>But here we have a highly specific, highly constrained problem, and we can do a
lot better with a custom implementation. Beyond our main motivation to get rid
of <code>stringAt()</code>, <code>HashMap</code> has to gracefully serve each and every use case, and
even defend from denial-of-service attacks.</p><p>We&#39;re fighting for every CPU cycle and want our implementation to do the bare
minimum that serves the purpose.</p><p>On top of all that, you&#39;ll see that implementing an open-addressed hashtable
with a predetermined size isn&#39;t all that much trouble. Here&#39;s most of the code
you need (full code
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog3.java" target="_blank" rel="noopener noreferrer">here</a>):</p><p>And here&#39;s the main loop that uses it:</p><p>Instead of creating a string every time, now we just store the location of the
name within the file. With this, we have completely eliminated allocation within
the hot loop. The GC thread is now idle.</p><p>That&#39;s great on its own, but the main benefit is something else: zero allocation
stops the churning of the CPU cache contents. Now the cache fills up with the
hashtable data, which is very important because that&#39;s the part of our in-memory
state where we can&#39;t avoid random access.</p><p>Now our runtime is down to 6.6 seconds, a 1.7x speedup — our approach was worth
it.</p><p>Let&#39;s check in with <code>perf stat</code>:</p><p>We improved instructions-per row again by 1.6x. As predicted, cache misses
improved even more, by 2.2x.</p><p>And our <a href="https://questdb.io/html/blog/profile-blog3.html" target="_blank" rel="noopener noreferrer">flamegraph</a>? It now reveals
that 47% of total time is spent in <code>findAcc</code> — we&#39;ll see if we can improve that.
Also it points out that, as we optimized other things, 20% of our CPU time is
now spent parsing the temperature. Hmmmm. More to do!</p><p>But before we go on, let&#39;s check into how GraalVM is working for us. So far,
we&#39;ve been running all our optimization steps on GraalVM. But how would this
code run on OpenJDK?</p><p>It would take 9.6 seconds, or 3.3 seconds slower than GraalVM. That&#39;s a 45%
improvement!</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-4-sunmiscunsafe-swar"></a>Optimization 4: sun.misc.Unsafe, SWAR<a href="#optimization-4-sunmiscunsafe-swar" title="Direct link to heading">#</a></h2><p>So far, we have improved on our initial solution by a clean order of magnitude:
from 66 seconds down to 6.6 seconds. Not bad. The techniques we applied are
relatively simple to digest and use standard, safe Java.</p><p>Even if you stop reading here, you&#39;ll walk away with a set of tricks that can
make you a performance hero in your own projects. <strong>But we want to push far
beyond this level of performance!</strong></p><p>For that, 1BRC contestants looked to more esoteric optimizations.</p><p>Some of them are obviously dangerous and can result in hard JVM crashes with a
low-level Segmentation Fault. Others are highly specific to this challenge.</p><p>Readability and maintainability also take a big hit, while providing diminishing
returns in performance. But, a challenge is a challenge, and the contestants
pressed on without looking back!</p><p>For this next iteration, we&#39;ll apply a few techniques that all the top solutions
shared:</p><ul><li><p>Use <code>sun.misc.Unsafe</code> instead of <code>MemorySegment</code> to avoid bounds checks</p></li><li><p>Avoid re-reading the same input bytes: reuse the same loaded value for hashing
and semicolon search</p></li><li><p>Process the data 8 bytes at a time, using a SWAR technique to find the
semicolon</p></li><li><p>Use <a href="https://github.com/MeryKitty" target="_blank" rel="noopener noreferrer">@merykitty</a>&#39;s magic SWAR (SIMD Within A
Register) code to parse the temperature</p></li></ul><p>Now check out the new hot loop. It&#39;s
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog4.java" target="_blank" rel="noopener noreferrer">looking pretty alien</a>:</p><p>And wait till you see the methods this calls into:</p><p>That&#39;s a lot of bit-twiddling magic, but note one general thing: there are
almost no <code>if</code> statements, and that&#39;s the point. We replaced branch instructions
with straight-through bitwise calculation.</p><p>The CPU now tries to predict whether it will go into the &#34;then&#34; or the &#34;else&#34;
branch for each <code>if</code> statement, based on previous iterations. As a result, it
starts to decode the appropriate instructions before having all the data ready
to evaluate the condition.</p><p>So, whenever it gets it wrong, it has to discard all that work and start to
decode the other instructions. As a rule of thumb, a single branch misprediction
costs as much as 10-15 instructions.</p><p>We also applied the SWAR idea: SIMD Within A Register, which means treating a
<code>long</code> number as a vector of 8 byte values, and performing the same operation on
each.</p><p>In our case, <code>semicolonMatchBits()</code> locates the ASCII semicolon byte and returns
a <code>long</code> with bits set to one where it was found. Then the method <code>nameLen()</code>
turns that bit pattern into the number telling us where it is. This comes from a
standard technique, used for example in C to efficiently determine the length of
a zero-terminated string.</p><blockquote><p>Read a detailed explanation of a very similar approach in this insightful post
<a href="https://richardstartin.github.io/posts/finding-bytes#finding-null-terminators-without-branches" target="_blank" rel="noopener noreferrer">Finding Null Terminators without Branches</a>
by Richard Startin.</p></blockquote><p>The method <code>maskWord()</code> takes a <code>long</code> containing 8 bytes of input data and
zeroes out all the bytes beyond the semicolon. We need this to perform a fast
name equality check.</p><p>The algorithm in <code>parseTemperature()</code> and <code>dotPos()</code> is a genius creation by
<a href="https://github.com/MeryKitty" target="_blank" rel="noopener noreferrer">@merykitty</a> (Quan Anh Mai), who made it
specifically for this challenge. It leverages the properties of the bit patterns
of ASCII <code>-</code> and <code>.</code>, as well as several other tricks, and produces the integer
value of the two or three temperature digits, accounting for all four possible
patterns (<code>X.X</code>, <code>-X.X</code>, <code>XX.X</code> and <code>-XX.X</code>) in one go.</p><p>If you want to study it in more detail, keep in mind that the number string is
stored in the long in little-endian order. For example, this line:
<code>long signed = (invNumberBytes &lt;&lt; 59) &gt;&gt; 63;</code> isolates bit number 4 of the first
byte – the one where the minus sign may appear – and sign-extends it across the
<code>long</code>.</p><p>This bit is 0 in the <code>-</code> sign, and 1 in all the digits. The operation is done
after flipping all the bits (<code>~numberBytes</code>), so this becomes either all 1&#39;s if
the byte is <code>-</code>, or all 0&#39;s otherwise.</p><p>This parsing code deserves a blog post of its own, and it would distract us too
much to explain it in detail here. Instead I&#39;ve thrown in
<a href="https://github.com/MeryKitty" target="_blank" rel="noopener noreferrer">@merykitty</a>&#39;s original code, and expanded his
comments a bit more:</p><p>All these techniques put together result in a 2.8x speedup. From 6.6 seconds,
we&#39;re now down to 2.4 seconds. Our overall improvement is now 28x.</p><p>As <code>perf stat</code> reports:</p><p>There is a huge drop in instruction count, by 3x. Since that&#39;s just 120
instructions per row now, we should look into making the same number of
instructions execute faster. One thing stands out: there are 0.66
<code>branch-misses</code> per row.</p><p>Can we do something about that?</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-5-win-with-statistics"></a>Optimization 5: Win with statistics<a href="#optimization-5-win-with-statistics" title="Direct link to heading">#</a></h2><p>The <a href="https://questdb.io/html/blog/profile-blog4.html" target="_blank" rel="noopener noreferrer">flamegraph</a> for our current
solution indicates that the relative impact of methods hasn&#39;t changed much. The
CPU spends 45% of its time total inside <code>findAcc()</code>, and just <code>nameEquals()</code>
alone takes 19%:</p><p>On the surface, that looks pretty efficient. It compares the station names eight
bytes at a time, and even uses the trick of reusing the mask operation on the
last block, passing it in as <code>lastNameWord</code>. But, it has a loop, which results
in unpredictable branching, and it re-reads the input name from memory.</p><p>How do we know the branch instruction in the loop will be unpredictable? The
answer lies in the statistics of the station names.</p><p>If most of the names are less than 8 bytes long, the condition that decides
whether to go into another iteration will always be false, and that will result
in a predictable branch instruction.</p><p>So, what&#39;s the actual distribution of the name lengths? While doing the
challenge, I wrote some code on the side, in a file called
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Statistics.java" target="_blank" rel="noopener noreferrer">Statistics.java</a>,
to find out things like that.</p><p>The <code>distribution()</code> method prints out the statistical distribution of name
lengths. If you run it on a dataset generated using one of the scaffolding
scripts (<code>create_meauserements.sh</code>) from the 1BRC repo, you&#39;ll see that there&#39;s
an almost even split between the names up to and longer than 8 bytes.</p><p>I also wrote a method that simulates the CPU&#39;s branch prediction
(<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Statistics.java#L46" target="_blank" rel="noopener noreferrer"><code>branchPrediction()</code></a>
in the same file). The CPU has a Branch History Table (BHT) that tracks the
behavior of each branch instruction in the hot loop.</p><p>An entry in the table is a 2-bit saturating counter which increments/decrements
depending on the outcome of the branch condition. Instead of overflowing, it
gets stuck at the min/max value (in other words, it saturates). When the counter
is 0 or 1, it predicts that the branch will be taken; if it&#39;s 2 or 3, in
predicts it won&#39;t be taken.</p><p>Running <code>Statistics.branchPrediction()</code> with the condition
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Statistics.java#L63" target="_blank" rel="noopener noreferrer"><code>nameLen &gt; 8</code></a>
results in 50% branch mispredictions. But if we change the condition in that
line of code to <code>nameLen &gt; 16</code>, mispredictions drop to just 2.5%.</p><p>Informed by this finding, it&#39;s clear that we have to write some code to avoid
any branch instructions on the condition <code>nameLen &gt; 8</code>, and instead go directly
for <code>nameLen &gt; 16</code>.</p><p>To do that, we have to unroll the semicolon-searching loop along these lines:</p><ol><li>Perform the first two steps in one go, without checking any conditions</li><li>Use bit-twiddling logic to combine the results of finding the semicolon in
each of the two <code>long</code> words</li><li>Use the combined result in an <code>if</code> check, which now accounts for all the
initial 16 bytes</li></ol><p>We also need specialized variants of <code>findAcc()</code> and <code>nameEquals()</code> for the
cases where the name is up to 16 bytes or more.</p><p>In
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog5.java" target="_blank" rel="noopener noreferrer">my solution</a>,
this reduces the time to 1.8 seconds — another 33% improvement, for the new
total improvement of ~40x.</p><p>And <code>perf stat</code> confirms our reasoning:</p><p>There&#39;s only a modest improvement in instructions per row, from 120 to 98. But
look at &#34;branch-misses&#34;! It dropped almost 8 times, from 0.657 to 0.084 per row.</p><p>This explains most of the speed improvement. Cache misses dropped as well, from
0.092 to 0.069 per row. This probably comes from the improved memory layout of
our stats accumulator, which now stores the first 16 name bytes inside the class
instance, and not in the separately-allocated array.</p><p>Another metric that people like to track is instructions-per-cycle (IPC). We can
see that it improved in this last step from 1.89 to 2.19. Reducing branch
mispredictions means that the CPU has to do a lot less rework, discarding the
speculatively executed instructions. This combines with the drop in
instructions-per-row to explain the overall 33% improvement.</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-6-eliminate-startupcleanup-costs"></a>Optimization 6: Eliminate startup/cleanup costs<a href="#optimization-6-eliminate-startupcleanup-costs" title="Direct link to heading">#</a></h2><p>If we want to compare our current result of 1.8 seconds to the winner, 1.5
seconds, we have to take into account the measurement methodology.</p><p>All along this post, we&#39;ve been reporting inner timings, that the code reports
for itself. The outer timing, as measured in the contest, includes both the JVM
startup and cleanup at the end. This adds 200 milliseconds - so we&#39;re actually
at 2.0 seconds compared to 1.5 seconds.</p><p>@thomaswue realized that around half of this time, 100 ms, is spent on unmapping
the memory-mapped file after the output is already produced. He found a way to
avoid paying for this with a hack, which was immediately copied by all the other
top contenders. He started a subprocess that would actually do the work, so that
the parent process could end as soon as it forwarded all the output. It would
then leave the subprocess to clean up in the background.</p><p>For this trick to work, contestants had to eliminate the JVM startup time as
well, otherwise they&#39;d pay for it twice. This would cancel out all the
improvement! As a result, this forced everyone to also use ahead-of-time
compilation into a native binary.</p><p>With these two tricks added, our outer timing becomes almost identical to the
inner timing we&#39;ve been reporting, which means we are truly getting close!</p><h2><a aria-hidden="true" tabindex="-1" id="optimization-7-use-smaller-chunks-and-work-stealing"></a>Optimization 7: Use smaller chunks and work stealing<a href="#optimization-7-use-smaller-chunks-and-work-stealing" title="Direct link to heading">#</a></h2><p>At this point, we&#39;re deep into low-level optimization territory. The tricks that
further improve the timing are coupled to the detailed specifics of
<strong>everything</strong>, such as:</p><ul><li>CPU make and model</li><li>Architecture of the connection to the RAM subsystem</li><li>Minute details of the compiler</li></ul><p>Explaining all these tricks would get us deep into the weeds, and wouldn&#39;t be
reusable knowledge. Instead let me show you one last trick that&#39;s kind of cute,
and might come in handy in real-life scenarios.</p><p>The way we divide the work into a single chunk per thread, we can end up with
some threads getting &#34;luckier&#34; than others and completing sooner. When that
happens, the CPU is underutilized for the remaining computation.</p><p>To address this, we can introduce a small update that changes this to a larger
number of small, fixed-size chunks. Up-front we&#39;ll only calculate the number of
chunks, and then let the threads grab them and calculate their bounds when
they&#39;re ready.</p><p>The key element is in ensuring that every chunk gets processed <strong>exactly once</strong>.</p><p>And the beauty of it is that it&#39;s almost a one-liner:</p><p>And that&#39;s it! All the magic happens in the
<a href="https://github.com/mtopolnik/billion-row-challenge/blob/main/src/Blog6.java" target="_blank" rel="noopener noreferrer">atomic counter we increment</a>.
This trick ekes out one last tenth of a second, down to 1.7 seconds.</p><h2><a aria-hidden="true" tabindex="-1" id="conclusion"></a>Conclusion<a href="#conclusion" title="Direct link to heading">#</a></h2><p>At the end of our 1BRC speedrun, we managed a 42x improvement over the Parallel
Streams implementation on OpenJDK, from 71 seconds down to 1.7. You may notice
that my official 1BRC result was quite a bit worse, at 2.3 seconds. The code in
this post is different from what I submitted; some of it I wrote just for the
post. It turned out that I had to choose between one last round of optimization
at 1BRC, or giving full attention to the challenge I got while getting hired for
QuestDB. I&#39;m very glad I chose the latter!</p><p>Performance optimizations we went through are certainly impressive, but do keep
in mind that a lot of the gains come from dispensing with all the best practices
that apply to production code: validations, bounds checks, hashtable resizing,
and so on.</p><p>The sole purpose of this code was to be fast at one very particularly specified,
error-free input file. It has absolutely no tolerance for any kind of deviation,
for example a single temperature reading that exceeds the three-digit maximum
would cause it to completely lose track, and probably crash.</p><p>But, coding challenges are meant to be fun — and everybody knows input
validation is the opposite of fun!</p><div><div><div><p><a href="https://questdb.io/download/">Download QuestDB</a><span> Open source under Apache 2.0. Blazing fast ingest. SQL analytics. </span></p></div></div></div></article></div></div>
  </body>
</html>
