<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://donnywinston.com/posts/what-functions-do-ideas-about-selves-serve/">Original</a>
    <h1>What Functions Do Ideas About Selves Serve?</h1>
    
    <div id="readability-page-1" class="page"><div id="content">

<p><time>April 13, 2022</time></p><div>
<p>One must not mistake defining things for knowing what they are. You can know what a tiger is without defining it. You may define a tiger, yet know scarcely anything about it.</p>
<p>“Self” is a term used to talk about a sense of identity. Instead of asking, <em>“What are selves?&#34;</em> we can ask, instead, <em>“What are our ideas about Selves?&#34;</em> – and then we can ask, <em>“What psychological functions do those ideas serve?&#34;</em></p>
<p>Our ideas about our Selves include beliefs about what we <em>are</em> – both what we are capable of doing and what we may be disposed to do. We may refer to such beliefs as <em>self-images</em>, as opposed to <em>self-ideals</em>, that is, ideas about what we’d <em>like</em> to be or about what we <em>ought</em> to be.</p>
<p>When dealing with digital resources – datasets, models, workflows, schema – there are subtle semiotics at play in representing and communicating these selves and their identities:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p><img src="https://files.polyneme.xyz/dropshare/semiotic-information-triad-ZiIhqWAvNf.png" alt="semiotic-information-triad"/></p>
<p>There are real things that occupy a given domain and scope of inquiry that are, unfortunately, neither understandable nor transmittable as fully correct messages (in the Shannon information sense).</p>
<p>Consider a dynamic digital object that represents the total information theoretic potential of – that is, all that one might say about – a real object. In representing our dynamic objects, we can only convey them as somewhat incomplete immediate objects – there is information loss.</p>
<p>So too is there loss in how these immediate objects are pointed to or signified – as something iconic like an image, described in words, etc. Our signification, our message, is imperfect.</p>
<p>And there is information loss at the response level by the interpreter that must decode the message that had to be encoded.</p>
<p>Finally, this may be the case not just for real things, but for ideal things - not just what is, but what ought to be.</p>
<p><small>
This post was adapted from a note sent to my email list on Machine-Centric Science.
</small>
</p>
<section role="doc-endnotes">
<hr/>
<ol>
<li id="fn:1" role="doc-endnote">
<p>M. K. Bergman, <em>A Knowledge Representation Practionary: Guidelines Based on Charles Sanders Peirce.</em> Springer International Publishing, 2018. <a href="https://doi.org/10.1007/978-3-319-98092-8">doi:10.1007/978-3-319-98092-8</a>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

</div>




</div></div>
  </body>
</html>
