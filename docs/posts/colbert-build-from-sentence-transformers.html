<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/raphaelsty/neural-cherche">Original</a>
    <h1>Show HN: ColBERT Build from Sentence Transformers</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto">
  
  <p dir="auto">Neural Search</p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://tinylogger.com/raphaelsty/neural-cherche/blob/main/docs/img/logo.png"><img width="500" src="http://tinylogger.com/raphaelsty/neural-cherche/raw/main/docs/img/logo.png"/></a></p>
<p><a href="https://raphaelsty.github.io/neural-cherche/" rel="nofollow"><img src="https://camo.githubusercontent.com/55ea6fa73d2ec8f07475d456a6d339e1bb2712bcc21b3e695ca900eec0012401/68747470733a2f2f696d672e736869656c64732e696f2f776562736974653f6c6162656c3d446f63756d656e746174696f6e267374796c653d666c61742d7371756172652675726c3d68747470732533412532462532467261706861656c7374792e6769746875622e696f2f6e657572616c2d636865726368652f253246" alt="documentation" data-canonical-src="https://img.shields.io/website?label=Documentation&amp;style=flat-square&amp;url=https%3A%2F%2Fraphaelsty.github.io/neural-cherche/%2F"/></a>
  
  <a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/ad3ef6f300e4672d89c879c54ee490a4bae95c62b0930b74eecdf702205af3c4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e7376673f7374796c653d666c61742d737175617265" alt="license" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square"/></a>
</p>
<p dir="auto">Neural-Cherche is a library designed to fine-tune neural search models such as Splade, ColBERT, and SparseEmbed on a specific dataset. Neural-Cherche also provide classes to run efficient inference on a fine-tuned retriever or ranker. Neural-Cherche aims to offer a straightforward and effective method for fine-tuning and utilizing neural search models in both offline and online settings. It also enables users to save all computed embeddings to prevent redundant computations.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-installation" aria-hidden="true" tabindex="-1" href="#installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">We can install neural-cherche using:</p>
<div data-snippet-clipboard-copy-content="pip install neural-cherche"><pre><code>pip install neural-cherche
</code></pre></div>
<p dir="auto">If we plan to evaluate our model while training install:</p>
<div data-snippet-clipboard-copy-content="pip install &#34;neural-cherche[eval]&#34;"><pre><code>pip install &#34;neural-cherche[eval]&#34;
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-documentation" aria-hidden="true" tabindex="-1" href="#documentation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<p dir="auto">The complete documentation is available <a href="https://raphaelsty.github.io/neural-cherche/" rel="nofollow">here</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-quick-start" aria-hidden="true" tabindex="-1" href="#quick-start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<p dir="auto">Your training dataset must be made out of triples <code>(anchor, positive, negative)</code> where anchor is a query, positive is a document that is directly linked to the anchor and negative is a document that is not relevant for the anchor.</p>
<div dir="auto" data-snippet-clipboard-copy-content="X = [
    (&#34;anchor 1&#34;, &#34;positive 1&#34;, &#34;negative 1&#34;),
    (&#34;anchor 2&#34;, &#34;positive 2&#34;, &#34;negative 2&#34;),
    (&#34;anchor 3&#34;, &#34;positive 3&#34;, &#34;negative 3&#34;),
]"><pre><span>X</span> <span>=</span> [
    (<span>&#34;anchor 1&#34;</span>, <span>&#34;positive 1&#34;</span>, <span>&#34;negative 1&#34;</span>),
    (<span>&#34;anchor 2&#34;</span>, <span>&#34;positive 2&#34;</span>, <span>&#34;negative 2&#34;</span>),
    (<span>&#34;anchor 3&#34;</span>, <span>&#34;positive 3&#34;</span>, <span>&#34;negative 3&#34;</span>),
]</pre></div>
<p dir="auto">And here is how to fine-tune ColBERT from a Sentence Transformer pre-trained checkpoint using neural-cherche:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import torch

from neural_cherche import models, utils, train

model = models.ColBERT(
    model_name_or_path=&#34;sentence-transformers/all-mpnet-base-v2&#34;,
    device=&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;
)

optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)

X = [
    (&#34;query&#34;, &#34;positive document&#34;, &#34;negative document&#34;),
    (&#34;query&#34;, &#34;positive document&#34;, &#34;negative document&#34;),
    (&#34;query&#34;, &#34;positive document&#34;, &#34;negative document&#34;),
]

for anchor, positive, negative in utils.iter(
        X,
        epochs=1,
        batch_size=32,
        shuffle=True
    ):

    loss = train.train_colbert(
        model=model,
        optimizer=optimizer,
        anchor=anchor,
        positive=positive,
        negative=negative,
    )

model.save_pretrained(&#34;checkpoint&#34;)"><pre><span>import</span> <span>torch</span>

<span>from</span> <span>neural_cherche</span> <span>import</span> <span>models</span>, <span>utils</span>, <span>train</span>

<span>model</span> <span>=</span> <span>models</span>.<span>ColBERT</span>(
    <span>model_name_or_path</span><span>=</span><span>&#34;sentence-transformers/all-mpnet-base-v2&#34;</span>,
    <span>device</span><span>=</span><span>&#34;cuda&#34;</span> <span>if</span> <span>torch</span>.<span>cuda</span>.<span>is_available</span>() <span>else</span> <span>&#34;cpu&#34;</span>
)

<span>optimizer</span> <span>=</span> <span>torch</span>.<span>optim</span>.<span>AdamW</span>(<span>model</span>.<span>parameters</span>(), <span>lr</span><span>=</span><span>3e-5</span>)

<span>X</span> <span>=</span> [
    (<span>&#34;query&#34;</span>, <span>&#34;positive document&#34;</span>, <span>&#34;negative document&#34;</span>),
    (<span>&#34;query&#34;</span>, <span>&#34;positive document&#34;</span>, <span>&#34;negative document&#34;</span>),
    (<span>&#34;query&#34;</span>, <span>&#34;positive document&#34;</span>, <span>&#34;negative document&#34;</span>),
]

<span>for</span> <span>anchor</span>, <span>positive</span>, <span>negative</span> <span>in</span> <span>utils</span>.<span>iter</span>(
        <span>X</span>,
        <span>epochs</span><span>=</span><span>1</span>,
        <span>batch_size</span><span>=</span><span>32</span>,
        <span>shuffle</span><span>=</span><span>True</span>
    ):

    <span>loss</span> <span>=</span> <span>train</span>.<span>train_colbert</span>(
        <span>model</span><span>=</span><span>model</span>,
        <span>optimizer</span><span>=</span><span>optimizer</span>,
        <span>anchor</span><span>=</span><span>anchor</span>,
        <span>positive</span><span>=</span><span>positive</span>,
        <span>negative</span><span>=</span><span>negative</span>,
    )

<span>model</span>.<span>save_pretrained</span>(<span>&#34;checkpoint&#34;</span>)</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-references" aria-hidden="true" tabindex="-1" href="#references"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>
<p dir="auto"><em><a href="https://arxiv.org/abs/2107.05720" rel="nofollow">SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking</a></em> authored by Thibault Formal, Benjamin Piwowarski, Stéphane Clinchant, SIGIR 2021.</p>
</li>
<li>
<p dir="auto"><em><a href="https://arxiv.org/abs/2109.10086" rel="nofollow">SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval</a></em> authored by Thibault Formal, Carlos Lassance, Benjamin Piwowarski, Stéphane Clinchant, SIGIR 2022.</p>
</li>
<li>
<p dir="auto"><em><a href="https://research.google/pubs/pub52289/" rel="nofollow">SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval</a></em> authored by Weize Kong, Jeffrey M. Dudek, Cheng Li, Mingyang Zhang, and Mike Bendersky, SIGIR 2023.</p>
</li>
<li>
<p dir="auto"><em><a href="https://arxiv.org/abs/2004.12832" rel="nofollow">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</a></em> authored by Omar Khattab, Matei Zaharia, SIGIR 2020.</p>
</li>
</ul>
</article>
          </div></div>
  </body>
</html>
