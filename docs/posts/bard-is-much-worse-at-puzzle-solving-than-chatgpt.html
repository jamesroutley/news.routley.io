<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://twofergoofer.com/blog/bard">Original</a>
    <h1>Bard is much worse at puzzle solving than ChatGPT</h1>
    
    <div id="readability-page-1" class="page"><article><p>Google released Bard <a href="https://blog.google/technology/ai/try-bard/">today</a>, the company&#39;s competitor to ChatGPT. Earlier this week, we <a>wrote about</a> ChatGPT&#39;s (impressive) ability to solve Twofer Goofers.</p>
<p><strong>TLDR</strong></p>
<ul>
<li>GPT-4 solves Twofer Goofers at a 96% rate</li>
<li>Humans solve at an 82% rate</li>
<li>Bard solves at, essentially, a 0% rate</li>
</ul>
<h3>Wait, what&#39;s a Twofer Goofer?</h3>
<p>Twofer Goofers are daily pairs of rhyming words described by a roundabout prompt. Players use the prompt and a series of clues to solve the puzzle and are rewarded with a piece of custom art. At this point, more than 12,000 human users have cumulatively solved the 240 distinct puzzles more than 100,000 cumulative times.</p>
<p>Here&#39;s an example of a solved Twofer Goofer:
<img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/Example?t=2023-03-21T18%3A40%3A52.885Z" alt="example"/></p>
<h3>Back to the chatbots</h3>
<p><strong>In fancy terms</strong>: we have a proprietary dataset of human puzzle-solving data against which we can test these AI tools.</p>
<p><strong>In normal terms</strong>: it&#39;s fun to see if the robots can figure out the creative non-linear thinking required to solve rhyme-based riddles. It&#39;s particularly fun because the robots don&#39;t actually understand what rhyming is.</p>
<p>The results from last week&#39;s test (full blog post <a href="https://twofergoofer.com/blog/gpt-4">here</a>):</p>
<ul>
<li>Human users solve about 82% of Twofer Goofers, using an average of 1.6 clues</li>
<li>GPT-4 is much better than humans, solving 96% of the puzzles and needing only 0.9 clues</li>
<li>GPT-3.5 is impressive, but worse than humans at a 72% solve rate with 2.0 clues per puzzle</li>
</ul>
<p><img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/Results%20chart" alt="Results chart"/></p>
<p>I was thrilled to toss Bard into the fray after gaining access to the open beta today. However, the results were shockingly disappointing.</p>
<p><strong>Bard was not able to solve a single Twofer Goofer when given the prompt.</strong> It was close in a couple instances, but ultimately unsuccessful.</p>
<p>Here&#39;s Bard&#39;s attempt at the first 20 Twofer Goofers:
<img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/bard1" alt="bard1"/></p>
<p>Even without seeing the prompts, you can tell these are incorrect guesses because they aren&#39;t pairs of rhyming words. Ultimately, Bard&#39;s first attempt at all 100 puzzles was a failure.</p>
<p>On a handful of Twofers, I ran through the full gauntlet of clues, but Bard still failed. Here&#39;s one of the easiest puzzles (as evidenced by a user solve rate of 97%):
<img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/Easy%20Twofer" alt="Easy Twofer"/></p>
<p>GPT-4 and GPT-3.5 solved this puzzle immediately. Here&#39;s Bard&#39;s attempt(s):
<img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/bardcactus2?t=2023-03-21T18%3A22%3A36.558Z" alt="bardcactus"/></p>
<p><em>Note</em>: Our <a href="https://twofergoofer.com/blog/gpt-4">GPT-4 blog post</a> has <em>much</em> more detail about exactly how we ran this test, including the documentation of the exact prompting used.</p>
<h3>But these are hard puzzles to solve, even for humans!</h3>
<p>Indeed, but the concept of rhyming isn&#39;t <em>too</em> difficult for humans. (Though Twofer Goofer HQ&#39;s adherence to strict <a href="https://www.masterclass.com/articles/perfect-vs-imperfect-rhymes">&#34;perfect&#34; rhyme</a> can be tricky for those slant rhyme-inclined.) Regardless, Bard&#39;s understanding of rhyming is meaningfully behind ChatGPT, as evidenced by this hastily-conceived test.</p>
<p><img src="https://rfwouezcbvpmywbsuans.supabase.co/storage/v1/object/public/brand-assets/Rhyme?t=2023-03-21T18%3A33%3A58.195Z" alt="rhyme"/></p>
<h3>What does this all mean?</h3>
<p>Not much! But we&#39;ve seen many &#34;empirical&#34; tests quoted to demonstrate the quality of a given AI model (LSAT scores, etc). However, we all know that humans thrive at creativity, non-linear thinking, and conceptual understanding (like what rhymes are!). Tests on data like Twofer Goofer solve rates are a valuable way to assess the true progress of these tools.</p>
<p>More to come! Send any feedback or complaints or musings to <a href="https://twofergoofer.com/cdn-cgi/l/email-protection" data-cfemail="ddbeb2b1b1b4b39da9aab2bbb8afbab2b2bbb8aff3beb2b0">[emailÂ protected]</a></p>
</article></div>
  </body>
</html>
