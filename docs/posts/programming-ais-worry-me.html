<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/">Original</a>
    <h1>Programming AIs worry me</h1>
    
    <div id="readability-page-1" class="page"><div>

                

                
                    
                        <p>For some inane reason, Github classifies me as a “major open source maintainer”, which means I get a free <a href="https://github.com/features/copilot" target="_blank">copilot subscription</a>.<sup id="fnref:github"><a href="#fn:github">1</a></sup> I’ve been using it for a couple months now and I got to say, it’s a <em>goddamn delight</em>. It can write boilerplate like nobody’s business. I find the tool works best when I’m using it as a keystroke saving device, where it writes 1-2 lines at a time. I write <code>x =</code> and it completes with <code>really[long][dict][lookup]</code>. It’s all very easy.</p>
<p>And this easiness worries me. I got a lot more worried when I read <a href="https://cacm.acm.org/blogs/blog-cacm/268103-what-do-chatgpt-and-ai-based-automatic-program-generation-mean-for-the-future-of-software/fulltext" target="_blank">What Do ChatGPT and AI-based Automatic Program Generation Mean for the Future of Software</a>, by Bertrand Meyer. He starts by testing ChatGPT with a tricky spec:</p>
<blockquote>
<p>I like to use the example of a function that starts with explicit values: 0 for 0, 1 for 1, 4 for 2, 9 for 3, 16 for 4, 25 for 5. […] This time I fed the above values to ChatGPT and for good measure added that the result for 6 is 35. Yes, 35, not a typo. Now, lo and behold, ChatGPT still infers the square root [sic] function!</p>
</blockquote>
<p>About what I expect. After he told ChatGPT that it was for 6, ChatGPT gave back a giant if-else chain. This technically is compliant with his spec but doesn’t capture the spirit of what he wants. A good example of the limits of the tool.</p>
<p>But then things take a turn for the worse.</p>
<blockquote>
<p>but things becomes amazing again, in fact more amazing than before, when I point out my dissatisfaction with the above style:</p>
<p><img alt="Bertrand gets the function `n(n+1)(2n+1)/6`" src="https://buttondown-attachments.s3.us-west-2.amazonaws.com/images/11a24d7e-af67-4f4b-b446-c46c53f81014.png"/> </p>
<p>The inferred function is rather impressive. What human would come up with that function in less time than it takes to say “Turing test”?</p>
</blockquote>
<p>Except the inferred function is completely wrong. Not even subtly wrong. The first incorrect input is <strong>2</strong>. Bertrand didn’t notice.</p>
<p>Now, here’s some important context: Bertrand Meyer’s entire <em>deal</em> is software correctness. He invented <a href="https://www.eiffel.org/" target="_blank">Eiffel</a>. He trademarked Design By Contract (tee em). He <a href="https://cacm.acm.org/blogs/blog-cacm/248022-what-everyone-knows-and-what-no-one-knows/fulltext" target="_blank">regularly rants</a> about how SEs don’t know about logic. He didn’t notice the error. Oh, and this article had <a href="https://news.ycombinator.com/item?id=34473783" target="_blank">114 comments on Hacker News</a> and exactly <a href="https://news.ycombinator.com/item?id=34473783#34474532" target="_blank"><em>one</em></a> commenter (of 48)  noticed.</p>
<p>Using AI-assisted code changes our work from <em>writing</em> code to <em>proofreading</em> code. And that’s a problem.</p>
<h3>Proofreading is hard</h3>
<p>So a quick story: back in 2020 I experimented with voice-to-text. I bought <a href="https://www.nuance.com/dragon.html" target="_blank">a Dragon license</a> and everything. I can speak a <em>lot</em> faster than I can type, after all! I’d say it was about 95% accurate. The problem was finding that 5% of errors. Most of the typos I make when writing <em>feel</em> wrong. I can feel my fingers slip up and type the wrong thing, and I can immediately go back and correct it. But most speakos feel normal. I say “Code matches the spec” and it transcribes “code smashes the spec”. After I wrote something, I’d have to go through very carefully and correct all the speakos. It was goddamn <em>exhausting</em>, and many errors still fell through. Proofreading is hard!<sup id="fnref:code-review"><a href="#fn:code-review">2</a></sup> </p>
<p>Over time I bent my workflow around proofreading, like putting each spoken sentence on a newline to break my reading flow. This helped find more errors but made the whole process even more miserable, and eventually I just gave up and went back to typing.</p>
<p>It takes longer to write a code “sentence” than a prose one, so a sentence-level generate-proofread loop is still more convenient than writing everything manually. That’s why I like Copilot. But as we start using AIs to generate larger blocks of code, we’re going to be faced with more and more proofreading work. And I’m worried more bugs will then slip through. If Bertrand Meyer can’t proofread closely enough to catch errors, what hope do us mere mortals have?</p>
<h3>Critiques</h3>
<p>Two reasons I could be less worried:</p>
<ol>
<li>People need to be proofread too, so as long as AIs eventually make fewer mistakes than the average programmer, they’re a net win.</li>
<li>We can make proofreading easier with better tooling. Unit tests are a means of “proofreading”: we can catch AI errors automatically with tests.</li>
</ol>
<p>I don’t know how true either these are. I can certainly see a future where both of these are true, and we happily use AIs without a second thought. I <em>also</em> see a future where we don’t adapt our skillsets and tooling around using AIs “properly”, and they become a net negative for a lot of people. I don’t know! That’s why I’m excited but also worried.</p>
<p>We’ll also have to see what happens when Copilot (and ChatGPT, sorta) aren’t the only games in town. Are there going to be AIs that specialize in certain domains? AIs that specialize in writing tests? AIs that are designed for language newcomers? I feel like I’d be a bit less worried if there was a more diverse ecosystem, for some reason.</p>
<h2>Programming AIs I want</h2>
<p>Might as well share a wishlist.</p>
<ul>
<li>A ChatGPT-style AI that can <em>only</em> reply with links to reference docs, libraries, or wikipedia articles</li>
<li>An AI that only highlights possible issues in the code, like “this looks kinda like an N+1 query” or </li>
<li>An AI that takes code and generates comments, mostly so I could quickly understand new configuration formats</li>
<li>AI-guided property-based testing. We already have AI-guided fuzzing, why not apply that at a more granular level</li>
</ul>
<p>While I have your attention, I’ll close with my favorite use of ChatGPT:</p>
<p><img alt="ChatGPT hilariously bungling a riddle" src="https://buttondown-attachments.s3.us-west-2.amazonaws.com/images/9d5ef006-a65c-4e04-8e53-3e73dfa287c6.png"/> </p>
<hr/>
<h3>Update for the Internets</h3>
<p>This was sent as part of an email newsletter; you can subscribe <a href="https://buttondown.email/hillelwayne/" target="_blank">here</a>. Common topics are <a href="https://buttondown.email/hillelwayne/archive/why-uml-really-died/" target="_blank">software history</a>, <a href="https://buttondown.email/hillelwayne/archive/10-misconceptions-about-formal-methods/" target="_blank">formal methods</a>, the <a href="https://buttondown.email/hillelwayne/archive/reject-simplicity-embrace-complexity/" target="_blank">theory of software engineering</a>, and <a href="https://buttondown.email/hillelwayne/archive/whats-the-most-expensive-software-per-byte/" target="_blank">silly research dives</a>. Updates are 6x a month. I also have a <a href="https://www.hillelwayne.com/" target="_blank">website</a> where I put my polished writing (the newsletter is more for off-the-cuff stuff). <em>That</em> usually updates monthly, though I want to try getting it to bimonthly at some point.</p>
<p>Also you can check out the flip side, where I talk about ways of using ChatGPT to program better <a href="https://buttondown.email/hillelwayne/archive/making-chatgpt-useful/" target="_blank">here</a></p>
<p>Also also <a href="https://www.aprilcools.club/" target="_blank">April Cools</a> is coming up woooo write something for that if you have a blog, it’s hella fun</p>

                    
                
            </div></div>
  </body>
</html>
