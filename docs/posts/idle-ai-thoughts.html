<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://george.mand.is/2025/06/idle-ai-thoughts/">Original</a>
    <h1>Idle AI Thoughts</h1>
    
    <div id="readability-page-1" class="page"><div><article><section><header><p><time datetime="2025-06-07">June 7th, 2025</time> • ~600 words • 3 minute read</p></header><p>Ideas have always been cheap; it&#39;s the <a href="https://sive.rs/multiply">execution that&#39;s the multiplier</a>. In the AI world we&#39;re hurtling toward is driving down the cost of execution, I guess that means ideas are more devalued than ever?</p><p>Cheaper still than an idea is an <em>observation</em>. It&#39;s the xerox of an idea run through a filter, artifacts and fidelity sometimes lost... but perhaps a bit of unique character introduced.</p><p>Everyone seems to have their own AI thoughts these days. Fresh off of 4.5 years leading engineering efforts around a SaaS product through the birth of this LLM era we&#39;re all living in now, I thought I&#39;d a collection of my own:</p><h2>AGI</h2><p>The psychology of AGI, SGI and trusting our robot overlords fascinates me. Science-fiction has always been aspirational, but you have to remember that it&#39;s ultimately <em>fiction</em>. Real-life always lands differently</p><p>You achieve AGI when you’re willing to trust the machine blindly. I think that’s a product of comfort over time more than capability. At the end of the day, it&#39;s a marketing term for a highly capable version of this tool that hasn&#39;t quite landed yet, but I can squint and see it. We&#39;re talking about tools, not machines with will. We always have been.</p><p>It says more about us when we decide to feel comfortable making that leap than the capabilities of the thing. I have a while personal theory that AGI is also only perceivable to the extent you’ve given the brain in a jar tools to act on its scattered thoughts. I can&#39;t really conceive or understand an intelligence in the abstract independent of tools that help me recognize that level of cognizance—writing, speaking, actions.</p><p>I guess you could simulate tools and actions and wait until it’s ready. But that reminds me of code interviews and how shitty those are.</p><p>It’s like anthropomorphizing Excel or a bash script, to some extent. Or maybe asking Deep Blue or Watson to operate a forklift.</p><p>Anyway, debating AGI strikes me as a distraction. A fun distraction, but not a particularly useful one beyond feeding the marketing hype. Discussing the inevitable capabilities of these tools and agency we might might feel comfortable granting them however is not.</p><p>AGI happens when you&#39;re ready.</p><h2>Abstractions on Abstractions</h2><p>Computing is the history of abstractions. We&#39;ve gone from punching holes in cards to performa calculations to talking to pocket devices in our mother tongue asking what the weather will be in less than a century.</p><p>The advent of computer languages to create instructions led to software as we know it. From peeking and poking at individual memory addresses to writing scripts.</p><p>What happens when the the next hello world program is just &#34;ask the computer to write a hello world program.&#34; Sure, behind the scenes it may literally write an entire operating system from scratch in some virutalized container all in service of simply spitting out the words &#34;Hello World&#34; but it doesn&#39;t matter.</p><h2>Probabilistic Elevators</h2><p>At some point the interface to everything becomes a machine you talk to. In the same way microcontrollesr have found their way into all manner of things. They&#39;re fast, cheap and out of control. Wait until we have highly capable LLMs on chips. In that world why create a unique electronic component for a button when you can simply have a magical component that you nicely <em>ask</em> to behave like a button.</p><p>Imagine a grid of elevator buttons, floor 1-10. Each programmed with a simple prompt &#34;Send the elevator to floor X.&#34;</p><p>Now if you&#39;re thinking about the probabilistic nature of elevators you might be thinking &#34;That is insane. I would like a deterministic elevator please.&#34;</p><p>But the truth is, if it&#39;s cheaper and easier, it will win.</p><p>And the other truth is, we&#39;re already living in a probabilistic world. This future is simply embracing it.</p>--<p><em>Published on Saturday, June 7th 2025. Read this post in <a href="https://george.mand.is/2025/06/idle-ai-thoughts/">Markdown</a> or <a href="https://george.mand.is/2025/06/idle-ai-thoughts/">plain-text</a>.</em></p></section></article></div></div>
  </body>
</html>
