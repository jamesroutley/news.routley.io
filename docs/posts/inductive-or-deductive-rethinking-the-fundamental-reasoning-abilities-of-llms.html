<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2408.00114">Original</a>
    <h1>Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+K">Kewei Cheng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J">Jingfeng Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+H">Haoming Jiang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z">Zhengyang Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+B">Binxuan Huang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+R">Ruirui Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S">Shiyang Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z">Zheng Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+Y">Yifan Gao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+X">Xian Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+B">Bing Yin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+Y">Yizhou Sun</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2408.00114">View PDF</a>
    <a href="https://arxiv.org/html/2408.00114v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-context examples. By focusing on inductive reasoning and separating it from LLM-based deductive reasoning, we can isolate and investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our observations reveal that LLMs demonstrate remarkable inductive reasoning capabilities through SolverLearner, achieving near-perfect performance with ACC of 1 in most cases. Surprisingly, despite their strong inductive reasoning abilities, LLMs tend to relatively lack deductive reasoning capabilities, particularly in tasks involving ``counterfactual&#39;&#39; reasoning.
    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Kewei Cheng [<a href="https://arxiv.org/show-email/1103d223/2408.00114">view email</a>]      </p></div></div>
  </body>
</html>
