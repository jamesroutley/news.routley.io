<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://fractalfir.github.io/generated_html/cg_gcc_bootstrap.html">Original</a>
    <h1>Building the Rust Compiler with GCC</h1>
    
    <div id="readability-page-1" class="page"><div><div>

<p>If you know one thing about me, it is that I love working on the Rust compiler. Some people kayak, travel or play guitar - and I stare at assembly, trying to figure out what I broke.</p>

<p>This summer, I am taking on quite a large task: bootstrapping the Rust compiler using <a href="https://github.com/rust-lang/rustc_codegen_gcc">`cg_gcc`</a></p>

<p>What does that mean? <a href="https://rustc-dev-guide.rust-lang.org/building/bootstrapping/what-bootstrapping-does.html">&#34;bootstrapping&#34;</a> is simply a name given to the Rust compiler build process.</p>

<p>So, what I am really trying to do is build a Rust compiler, without using LLVM - and using GCC instead.</p>

<p><img src="https://maryrosecook.com/blog/images/gcc_bootstrap_process.png" alt="Diagram explaining the bootstrap process"/></p>

<p>The bootstrap process is quite complex, and split into 3 stages.</p>

<h2 id="stage_1">Stage 1</h2>

<p>First, we use a pre-existing, LLVM-based Rust compiler to build <code>rustc</code>, and the GCC-based codegen.</p>

<h2 id="stage_2">Stage 2</h2>

<p>Then, we take that GCC-based codegen, and rebuild the Rust compiler using GCC.</p>

<h2 id="stage_3">Stage 3</h2>

<p>As a sanity check, we built the compiler <strong>*again</strong>*, this time using <code>stage2</code>.</p>

<p>The idea here is quite simple: if <code>stage1</code> and <code>stage2</code> produce identical executables, then they behave identically, which means the rust compiler build with GCC is (more or less) equivalent to the one built with LLVM.</p>

<p>Of course, a lot of this is a gross oversimplification, but you should get the gist. Getting to the stage3 is a big milestone - and the goal of my GSoC project.</p>



<p>You may be asking: what is preventing us from building a working stage 3 build right now?</p>

<p>Usually, I would answer this question with something akin to <em>&#34;If knew what bugs we had, I would have fixed them already&#34;</em>. However, this is a rare case, where I knew exactly what bugs I needed to fix.</p>

<p>How could I know that?</p>

<p>Via the advanced debugging technique I dubbed <em>&#34;Giving the compiler a lobotomy&#34;</em>.</p>

<h2 id="lobotomizing_ferris">Lobotomizing ferris</h2>

<p>Some of the bugs I presented had some pretty clear symptoms:</p>

<p><code>libgcccjit</code>(the library we use to interface with GCC) would show errors, complaining about some sort of IR issue.</p>

<p>It would then abort the build, and give me the name of the problematic crate.</p>

<pre><code>   Compiling rustix v0.38.44
libgccjit.so: error: : gcc_jit_block_add_assignment: mismatching types: assignment to input_register (type: __int8_t *) from param1 (type: restrict __int32_t  __attribute__((aligned(4))) *)</code></pre>

<p>So, I went into the source code of that crate, found the function responsible, and just patched the problem out.</p>

<p>The compiler does not support 128 bit matches? Cool, a bunch of <code>if</code>’s it is.</p>

<pre><code>if val == 0 {
    // Do sth
} else if val == 1{
    // Do sth else
} else if val == 2{
    // Do other thing
}/*...*/
else{
    // Do yet another thing
}</code></pre>

<p>Inline causes trouble? Well, out it goes.</p>

<pre><code>/*#[inline(always)]*/ // Who needs inlining, anyways?</code></pre>

<p>The compiler segfaults? It works with optimizations disabled? Well, who cares about speed, let’s build the compiler with none of that &#34;optimization&#34; business.</p>

<p>After axing enough things, I got a pretty good idea about the source of my issues.</p>

<p>I got a stage 2 build working, and was pretty close to stage 3. So, I knew loosely what needed fixing.</p>

<p>Still, I have got to implement those fixes… somehow. Hopefully, they are not too hard.</p>



<p>The first bug I fought is kind of obvious in hindsight.</p>

<p>It is caused by using the <code>#[inline(always)]</code> attribute on a recursive function.</p>

<pre><code>#[inline(always)]
fn fib(n:u32) -&gt; u32{
  if n &lt;= 1{return 1}
  else{ fib(n - 1) + fib(n - 2) }
}</code></pre>

<p>Now, a big chunk of you might be confused as to why this works when using LLVM.</p>

<p>If we read the attribute literally, we are asking <code>rustc</code> to &#34;always inline this function&#34;. Since fib is recursive, that would mean we have to inline it into itself.</p>

<p>Let us try that!</p>

<pre><code>#[inline(always)]
fn fib(n: u32) -&gt;u32{
    if n &lt;= 1 {
        return 1;
    } else {
        (if n - 1 &lt;= 1 {
            1
        } else {
            fib(n - 1 - 1) + fib(n - 1 - 2)
        }) + (if n - 2 &lt;= 1 {
            1
        } else {
            fib(n - 2 - 1) + fib(n - 2 - 2)
        })
    }
}</code></pre>

<p>Uh, you might already see the problem. No matter how many times we inline fib, it will always still contain a non-inlined call to itself.</p>

<p>We are asking the compiler to do something impossible. So, it is no wonder the GCC based backend fails to do this, and errors out.</p>

<p>How on earth does LLVM manage to fully inline fib?</p>

<p>The answer is… it does not.</p>

<h2 id="it_was_just_a_hint,_bro">It was just a hint, bro</h2>

<p>Yeap, you hear me right - <code>#[inline(always)]</code> does not guarantee our function will always get inlined. Maybe, the more appropriate name would be <code>#[inline(inline_this_if_u_can_pretty_please)]</code>.</p>

<p>That might be a bit harder to remember, though ;).</p>

<p>So, <code>#[inline(always)]</code> does not always inline. Is this not a compiler bug?</p>

<p>Nope! It is actually intended behaviour, and something <a href="https://doc.rust-lang.org/nightly/reference/attributes/codegen.html?highlight=inline#the-inline-attribute">the docs</a> clearly state:</p>

<blockquote>
<p><code>#[inline(always)]</code> <em>suggests</em> that an inline expansion should always be performed</p>
</blockquote>

<p>Seems a bit silly, but... ¯\<em>(ツ)</em>/¯.</p>

<p>Yeah, so if we tell LLVM to &#34;always inline&#34; something, and it can’t do that, it will just not inline it, and happily chug on.</p>

<p><em>Sidenote: There exists a way to make LLVM error out in this case, but it is not used by <code>rustc</code> here.</em> <em>If you want this behaviour, you&#39;d have to use the internal <code>#[rustc_force_inline]</code> attribute instead.</em></p>

<p>So, the GCC error is not <em>really</em> a fault of GCC - we are telling it to always inline this function, and it simply tells us it is not possible.</p>

<p>How can we work around this?</p>



<p>Really, the problem stems from us asking GCC to do something impossible, and being shocked when it does not work as expected.</p>

<p>What we need to do is somehow prevent this kind of cyclic, unconditional inline.</p>

<h2 id="demoting_inlines">Demoting inlines</h2>

<p>The simplest solution to this problem is to treat all uses of <code>#[inline(always)]</code> the same way <code>#[inline]</code> is treated.</p>

<p>This does work, and is a one-line change.</p>

<pre><code>// Change this
InlineAttr::Hint =&gt; Some(FnAttribute::Inline),
InlineAttr::Always | InlineAttr::Force { .. } =&gt; Some(FnAttribute::AlwaysInline),
// into this:
InlineAttr::Always | InlineAttr::Hint =&gt; Some(FnAttribute::Inline),
InlineAttr::Force { .. } =&gt; Some(FnAttribute::AlwaysInline),</code></pre>

<p>Since <code>#[inline(always)]</code> is <em>just a hint</em>, ignoring it is fully correct.</p>

<p>However, it is also not without its own downsides.</p>

<p>People are using <code>#[inline(always)]</code> for a reason: they have determined that <code>#[inline]</code> will not suffice.</p>

<p>So, we can expect performance regressions from this &#34;fix&#34;.</p>

<h2 id="checking_if_a_function_is_recursive">Checking if a function is recursive</h2>

<p>You might think you have came up with a clever solution that allows us to have our cake and eat it too.</p>

<p>This problem is caused by functions marked with <code>#[inline(always)]</code> calling themselves.</p>

<p>Can&#39;t we just check for that?</p>

<p>Given a function <code>fib</code>, decorated with the attribute #[inline(always)], could we check if it ever calls <code>fib</code>?</p>

<pre><code>#[inline(always)]
fn fib(n:u32) -&gt; u32{
  if n &lt;= 1{return 1}
  else{ fib(n - 1) + fib(n - 2) }
}</code></pre>

<p>We could replace <code>#[inline(always)]</code> with plain ol&#39; inline in just that case.</p>

<p>Well, this works... <em>in simple scenarios</em>. It even fixed the problem that originally caused me to look into this:</p>

<p>The <strong>one</strong> use of recursive always-inline in the Rust compiler!</p>

<p>Remember: This is the <strong>main</strong> reason I am looking into this particular set of issues:</p>

<p><em>they are preventing us from using cg_gcc to build the Rust compiler.</em></p>

<p>So... this is the fix, right? Not really...</p>

<p>Despite fixing the original symptom of the issue, this fix is flawed.</p>

<p>It ignores indirectly-recursive functions.</p>

<h3 id="indirectly-recursive_functions">Indirectly-recursive functions</h3>

<p>What do I mean by that?</p>

<p>Suppose we are felling funny: we create <em>two</em> copies of our <code>fib</code> function:</p>

<ol type="1">
<li><code>fib_a</code> calling <code>fib_b</code>...</li>

<li>and <code>fib_b</code> calling fib_a.</li>
</ol>

<p>Kind of like this:</p>

<pre><code>#[inline(always)]
fn fib_a(n:u32) -&gt; u32{
  if n &lt;= 1{return 1}
  else{ fib_b(n - 1) + fib_b(n - 2) }
}
#[inline(always)]
fn fib_a(n:u32) -&gt; u32{
  if n &lt;= 1{return 1}
  else{ fib_b(n - 1) + fib_b(n - 2) }
}</code></pre>

<p>Now, none of those functions <em>directly</em> call themselves. So, our check will not trigger, but the original bug <em>will</em>.</p>

<p>After we inline <code>fib_b</code> into <code>fib_a</code>, it now will directly call itself, recreating the original bug.</p>

<pre><code>#[inline(always)]
fn fib_a(n: u32) -&gt;u32{
    if n &lt;= 1 {
        return 1;
    } else {
        (if n - 1 &lt;= 1 {
            1
        } else {
            fib_a(n - 1 - 1) + fib_a(n - 1 - 2)
        }) + (if n - 2 &lt;= 1 {
            1
        } else {
            fib_a(n - 2 - 1) + fib_a(n - 2 - 2)
        })
    }
}</code></pre>

<p>However, by that point, the function is squarely in the <code>GCC</code>s hand, and we will get a <code>libgccjit</code> error.</p>

<p>You may think: can we make the check <em>recursive</em>?</p>

<p>As in, we descend trough all the functions called by <code>fib_a</code>, and then functions called by <code>fib_b</code>, and so on, checking if <code>fib_a</code> is recursive?</p>

<p><em>Well</em>, this would get very complex, very quickly.</p>

<p>uppose we have some function f0, which calls f1, which calls f2, which calls f3, and so on, till f2^20.</p>

<p>Such a recursion check would be sluggish, and easily overflow the compiler stack.</p>

<p>That is... not exactly what we want to happen. We could place some limits, but that would be a bit <em>awkward</em>.</p>

<p>We want a solution that is both <em>performant</em>, and <em>correct</em>.</p>

<h2 id="attribute_based_check.">Attribute based check.</h2>

<p>We can rephrase the problem a bit.</p>

<p>Instead of checking for recursion, we check if a function marked with <code>#[inline(always)]</code> calls another function marked with the same attribute.</p>

<p>This will prevent any issues recursive, unconditional inling could cause.</p>

<p>Can we detect a scenario like this? Yup, and with ease.</p>

<p>All we need to do is:</p>

<ol type="1">
<li>Grab the function MIR(the function representation used by the compiler)</li>

<li>Iterate trough all the blocks of this function</li>

<li>Check if they end with a function call(function calls can only be present at the end of a block)</li>

<li>Check if that function is marked inline(always)</li>
</ol>

<p>This is surpsinly cheap, and straightforward.</p>

<p>First and foremost, we only need to perform this check for functions marked with <code>#[inline(always)]</code></p>

<pre><code>InlineAttr::Always =&gt; if resursively_inline(compiler_context, function) {
    Some(FnAttribute::Inline) // Use weaker attribute to break potential cycles
} else {
    Some(FnAttribute::AlwaysInline) // Cycle impossible, use stronger attribute.
}</code></pre>

<p>So, most of the time, this does not trigger, and is thus &#34;free&#34;.</p>

<p>Second, we already need the function MIR to be able to compile it to GIMPLE(the IR GCC uses).</p>

<p>So, checking the function MIR incurs no additional cost: the data we need is computed anyway.</p>

<pre><code>let body = cx.tcx.optimized_mir(instance.def_id());</code></pre>

<p>Additionally, most functions contain a relatively small number of <em>blocks</em>.</p>

<p>MIR blocks are ended by terminators, which affect the control flow.</p>

<p>So, to check for <em>calls</em>, we only need to check all the <em>terminators</em>.</p>

<pre><code>for block in body.basic_blocks.iter() {
    let Some(ref terminator) = block.terminator else { continue };
    // I assume that the recursive-inline issue applies only to functions, and not to drops.
    // In principle, a recursive, `#[inline(always)]` drop could(?) exist, but I don&#39;t think it does.
    let TerminatorKind::Call { ref func, .. } = terminator.kind else { continue };
    let Some((def, _args)) = func.const_fn_def() else { continue };</code></pre>

<p>Checking what <em>attributes</em> a function has is also a dirt-cheap process.</p>

<pre><code>if matches!(
    cx.tcx.codegen_fn_attrs(def).inline,
    InlineAttr::Always | InlineAttr::Force { .. }
) {
    return true;
}</code></pre>

<p>This is the solution <a href="https://github.com/rust-lang/rustc_codegen_gcc/commit/f111416e43a36a1ee062a2194eae37c39d0f0be1">I went with</a>: it is simple to understand &amp; implement.</p>

<p>It also allows us to keep the benefits of <code>#[inline(always)]</code> in <em>most</em> cases.</p>



<p>There is another bug preventing GCC from bootstrapping rustc: an incorrect implementation of 128 bit <code>SwitchInt</code> terminator.</p>

<p>This issue has a pretty clear symptom: <code>libgccjit</code> yells at us, and the compiler stops.</p>

<p>But, what is <code>SwitchInt</code>, and why do we have a problem with 128 bit intigers?</p>

<p><code>SwitchInt</code> is the primitive used to implement all conditional control flow in MIR(Rust compiler’s IR).</p>

<p>It more or less works like the C switch statement. Given some value to switch on, and a list of cases, we jump to the case with the matching value.</p>

<pre><code>switchInt(_11) -&gt; [0: bb10, 1: bb9, otherwise: bb8];</code></pre>

<p>Simple stuff, really.</p>

<p>Mapping this to GCC IR is very, very easy. We just... turn it into a switch. Duh.</p>

<pre><code>switch (local_11){
    case 0: 
        goto bb10;
    case 1:
        goto bb9;
    default:
        goto bb8;
}</code></pre>

<p>The problem arises when we try to create a switch, which operates on 128 bit integers. This works just fine in C, but not in Rust. Why?</p>

<p>Well, all switch cases must be constants. Creating those is not too hard: we just need to call this libgccjit function and…</p>

<pre><code>extern gcc_jit_rvalue *
gcc_jit_context_new_rvalue_from_long (gcc_jit_context *ctxt,
				      gcc_jit_type *numeric_type,
				      long value);</code></pre>

<p>Yeah, you can already see the problem… This function accepts 64 bit arguments(longs), but we need to create 128 bit constants. That is not going to work.</p>

<p>The GCC compiler is using the GCC-internal APIs, which do expose a way to create such a value. <code>cg_gcc</code> is using GCC as a library(<code>libgccjit</code>), and uses the API exposed by this library. That API does not have the function we need.</p>

<p>In all other places, we can kind of cheat to get a 128 bit value the long way round. We simply assemble it from its high and low qwords, like this:</p>

<pre><code>uint128_t res = (((uint128_t) high)&lt;&lt;64) | ((uint128_t) low);</code></pre>

<p>This approach, however, means that instead of a simple literal, our value is an expression. So, it can’t be used as a switch case.</p>

<p>Now, the long term fix for this problem is kind of obvious: we need to add a new function to <code>libgccjit</code>, allowing us to get 128 bit constants directly.</p>

<p>This is difficult for 2 reasons:</p>

<ol type="1">
<li>Modifying <code>libgccjit</code> is not all that easy, in general</li>

<li>
<p>GCC does not support 128 bit intigers on 32 bit targets... which would break <code>libgccjit</code> code there.</p>

<pre><code>extern gcc_jit_rvalue *
gcc_jit_context_new_rvalue_from_very_long (gcc_jit_context *ctxt,
				      gcc_jit_type *numeric_type,
                  // Fails to compile on 32 bit targets :(
				      int128_t value);</code></pre>
</li>
</ol>

<p>However, just to get things going, is there a simpler workaround?</p>

<h2 id="switching_on_quadwords">Switching on quadwords</h2>

<p>At first, your thought might be to split the switch statement up, first matching on its lower qword(<code>u64</code>) and then matching on the high qword.</p>

<pre><code>uint64_t high = (uint64_t)(big&gt;&gt;64);
uint64_t low = (uint64_t)big;
switch(high){
    case 0:
        switch(low){
            case 0:
                do_sth();
                break;
            case 120453:
                do_sth_else();
                break;
            default:
                do_nothing();
        }
        break;
    case 3453:
    switch(low){
            case 0:
                do_sth();
            /* ... and so on ..*/
    }
}</code></pre>

<p>This <em>would</em> work as expected, but would also introduce many, many unnecessary blocks and switches. Additionally, it would be a bit ugly to implement.</p>

<p>I don’t want that: the fewer branches we need to have, the better.</p>

<p>Additionally, we must ask ourselves one more question: would GCC be able to &#34;see&#34; what we are doing?</p>

<p>In the good old days, writing clever, complex algorithms was quite often needed to squeeze every bit of performance out of your computer. The compilers were as dumb as a sack of bricks, and you needed to wrangle them into generating decent assembly.</p>

<p>This is where things like the <a href="https://en.wikipedia.org/wiki/Duff%27s_device">duff’s device</a>, or the <a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root">fast inverse square root</a> and other such oddities come from.</p>

<p>Nowadays, compilers are quite a bit smarter. They are able to detect naive implementations of certain operations, and replace them with optimized intrinsics.</p>

<p>A manual copy loop will get replaced with a <code>memcpy</code> call, manual <code>stren</code> will also get replaced by an efficient builtin, and so on.</p>

<p>Now, the compiler is not omnipotent: it can’t read your mind, and discover what your complex, hard to read function is doing. Sometimes, simplicity is the key: it allows a compiler to understand your code a bit better.</p>

<p>In this case, it is unlikely GCC will turn our nested switch into something simpler. Some other patterns, however, might be a bit easier to understand. Maybe if we dumb our code down, it will work better?</p>

<h2 id="if_ladder">if ladder</h2>

<p>What is the most common, most stupid replacement for a switch? Something loads of people will write, and then be laughed at?</p>

<p><em>A whole lot of ifs.</em></p>

<p>Really, think about it. How often do you see somebody inexperienced use ifs instead of a switch? This pattern is common enough for most compilers to recognize, and more importantly, optimize it.</p>

<p>Those 2 functions</p>

<pre><code>char* test(int num){
    switch(num){
        case 0:
            return &#34;zero&#34;;
        case 1:
            return &#34;one&#34;;
        case 2:
            return &#34;two&#34;;
        default:
            return &#34;IDK, go bother somebody else&#34;;
    }
}
char* test2(int num){
    if(num == 0)return &#34;zero&#34;;
    else if(num == 1)return &#34;one&#34;;
    else if(num == 2)return &#34;two&#34;;
    else return &#34;IDK, go bother somebody else&#34;;
}</code></pre>

<p>result in the same assembly in GCC:</p>

<pre><code>&#34;test&#34;:
        mov     eax, OFFSET FLAT:.LC1
        cmp     edi, 1
        je      .L1
        mov     eax, OFFSET FLAT:.LC2
        cmp     edi, 2
        je      .L1
        test    edi, edi
        mov     eax, OFFSET FLAT:.LC0
        mov     edx, OFFSET FLAT:.LC3
        cmovne  rax, rdx
.L1:
        ret
&#34;test2&#34;:
        mov     eax, OFFSET FLAT:.LC0
        test    edi, edi
        je      .L6
        mov     eax, OFFSET FLAT:.LC1
        cmp     edi, 1
        je      .L6
        cmp     edi, 2
        mov     eax, OFFSET FLAT:.LC3
        mov     edx, OFFSET FLAT:.LC2
        cmove   rax, rdx
.L6:
        ret</code></pre>

<p>Moreover, if we turn the optimizations above level 2, GCC will merge those 2 functions. Man, compilers are smart.</p>

<p>So, by doing something seemingly stupid, we can indirectly create a 128 bit switch.</p>

<p>Of course, we should not rely on compiler optimizations here, but, for now, this is good enough.</p>

<p>Working inefficiently is better than not working at all.</p>

<p>So, I applied <a href="https://github.com/rust-lang/rustc_codegen_gcc/commit/33966ccbb6570c83b9fc1dd0942f83ae2d56f47c">those patches</a>, and… we have a liftoff! The compiler can now successfully crawl till stage 2!</p>

<p>Sadly, we experience some <a href="https://en.wiktionary.org/wiki/rapid_unplanned_disassembly">rapid unscheduled disassembly</a> - the stage 2 segfaults.</p>

<p>Looks like we are not out of the woods quite yet.</p>



<p>The sentence &#34;the compiler segfaulted&#34;  does not tell us all that much. Such a thing can happen for a whole bunch of reasons: invalid memory accesses, corrupt data, stack overflows, incorrect alignment.</p>

<p>However, there are a few hints that can help us diagnose the issue.</p>

<p>The first hint is very interesting: this issue only happens when the optimization level is larger than 1.</p>

<p>That means the <code>GIMPlE</code>(GCC IR) we generate is not fully incorrect, but is broken after optimization. That suggest we are dealing with undefined behaviour. <strong>Ouch.</strong></p>

<p>We can use a few tricks to deuce exactly what is going on here.</p>

<h2 id="toggling_optimizations_on_and_off.">Toggling optimizations on and off.</h2>

<p>We know that compiling with <code>-Copt-level=1</code> works, but compiling with <code>-Copt-level=2</code> does not. From the GCC docs, we can get a list of passes that <code>-O2</code> enables.</p>

<p>One of those is involved in this issue.</p>

<p>Which one? Well, I managed to cut the list down to this much smaller set.</p>

<p>I know, for a fact, that the issue is caused by one of the vectorisation passes.</p>

<p>Sadly, at this point, things became much more… wobbly. I could not pinpoint a single pass that was required for the issue to occur. I know some combo of them was required, but I did not know which exactly.</p>

<p>Running unoptimized compiler builds is… not exactly pleasant.</p>

<p>Due to some issues(which will I mention later) I was only able to use one thread at most during the build. That slowed it down to a nice, leasuirly 50 minutes per build.</p>

<p>That is not too terrible, but it makes the investigation process much, much harder. Can we do something else to diagnose the issue?</p>

<h2 id="debugging_the_compiler">Debugging the compiler</h2>

<p>Normally, debuing the compiler is fairly straightforward: it is more or less a run of the mill executable.</p>

<p>In the bootstrap process, the entire thing becomes way more complex. You see, <code>rustc</code> is not invoked directly. The bootstrap script calls a wrapper around the compiler.</p>

<p>Running that wrapped <code>rustc</code> is not easy to run either: it requires a whole lot of complex, environment flags to be set.</p>

<p>All that is to say: I don’t know how to debug the Rust compiler. I am 99.9 % sure there is an easy way to do this, documented somewhere I did not think to look. After I post this, somebody will tell me &#34;oh, you just need to do X&#34;.</p>

<p>Still, at the time of writing, I did not know how to do this.</p>

<p>So, can we attach gdb to the running process? Nope, it crashes way to quickly for that.</p>

<p>Funny - I never thought I&#39;d be complaining my computer is <em>too fast</em>.</p>

<p>This may seem like a hopeless situation, but it is not.</p>

<h3 id="core_dumps">Core dumps</h3>

<p>Even tough the process in question no longer exists, we can still debug it. How?</p>

<p>We can use a core dump:</p>

<pre><code>coredumpctl gdb</code></pre>

<p>What is a core dump? It is an image of the crashed process, at the point of failure. This snapshot contains all the data we need to diagnose this issue.</p>

<p>Let&#39;s look a the stack trace:</p>

<pre><code>#18 0x00007fe64d16ebcd in &lt;hashbrown::raw::RawTable&lt;(rustc_middle::ty::context::InternedInSet&lt;rustc_middle::ty::consts::valtree::ValTreeKind&gt;, ())&gt;&gt;::find_or_find_insert_slot::&lt;rustc_data_structures::sharded::table_entry&lt;rustc_middle::ty::context::InternedInSet&lt;rustc_middle::ty::consts::valtree::ValTreeKind&gt;, (), rustc_middle::ty::consts::valtree::ValTreeKind&gt;::{closure#0}, rustc_data_structures::sharded::table_entry&lt;rustc_middle::ty::context::InternedInSet&lt;rustc_middle::ty::consts::valtree::ValTreeKind&gt;, (), rustc_middle::ty::consts::valtree::ValTreeKind&gt;::{closure#1}&gt;::{closure#0} ()
   from librustc_driver.so
#19 0x00007fe64d171e65 in &lt;hashbrown::raw::RawTableInner&gt;::find_or_find_insert_slot_inner () from librustc_driver.so
#20 0x00007fe64d1b2cf2 in &lt;rustc_middle::ty::context::TyCtxt&gt;::intern_valtree () from librustc_driver.so</code></pre>

<p>Huh, we are crashing when building a hash table, inside of the Rust compiler interner(<code>intern_valtree</code>). What is an interner? Glad you asked.</p>

<p>The interner is a data structure, used by the Rust compiler to store most of it’s types. It is quite complex, but you can kind of think of it as a mix between an arena allocator, and a hash map. Each item in an interner is guaranteed to be <em>unique</em>.</p>

<p>Now, this is the first place I&#39;d expect Rust to break in.</p>

<p>The interner contains a bit of unsafe code, and uses a <strong>lot</strong> of advanced features to squeze every bit of performance it can.</p>

<p>This could explain our issue: maybe we don’t translate all of that into GCC IR correctly? Most code does not really on those finer detali, so it might have slipped trough the tests.</p>

<p>Let us take a look at the assembly of the offending function:</p>

<pre><code>   0x00007fe64d16ebc9 &lt;+41&gt;:    test   %cl,%cl
   0x00007fe64d16ebcb &lt;+43&gt;:    jne    0x7fe64d16ebe8
=&gt; 0x00007fe64d16ebcd &lt;+45&gt;:    vmovdqa 0x2(%rax),%xmm0
   0x00007fe64d16ebd2 &lt;+50&gt;:    vpxor  0x2(%rdx),%xmm0,%xmm0
   0x00007fe64d16ebd7 &lt;+55&gt;:    vptest %xmm0,%xmm0</code></pre>

<p>Would you look at that -  it is a 256 bit vector move instruction. I wonder what the address it operates on is…</p>

<pre><code>(gdb) p/x *(int8_t[16]*)$rax
$10 = {0x0, 0x8, 0x1, 0x0 &lt;repeats 13 times&gt;}
p/x $rax
$6 = 0x7fe646423b90</code></pre>

<p>Huh, it points to accessible memory, but it does not look correctly aligned to me… we need an alignment of 32 bytes, but this pointer is only aligned to 16.</p>

<p>So, case closed! We have a misaligned pointer dereference! Eh, not so fast… we still don’t know <em>why</em> the pointer is misaligned.</p>

<p>There are multiple reasons <em>why</em> we might dereference an unaligned pointer.</p>

<ol type="1">
<li>This pointer was <em>supposed</em> to be <strong>aligned</strong>, but we screwed up with pointer arthimetnics, and it is not.</li>

<li>This pointer was <em>supposed</em> to be <strong>unaligned</strong>, and we used an aligned load(eg. a vector load) instead of an unaligned one.</li>
</ol>

<p>Both of those options are equally likely, and figuring out the real cause will require some more investigative work.</p>

<p>We segfault in the code <em>interning</em> some data. It might be worth looking at that code, or at least at the types in play.</p>

<p>Who knows - maybe we&#39;ll notice something intresting.</p>

<h2 id="valtree_and_scalarint">ValTree and ScalarInt</h2>

<p>We crash when creating a <code>ValTree</code>. Let us take a look at that type:</p>

<pre><code>pub struct ValTree&lt;&#39;tcx&gt;(pub(crate) Interned&lt;&#39;tcx, ValTreeKind&lt;&#39;tcx&gt;&gt;);</code></pre>

<p>So, <code>ValTree</code> is a pointer to an interned(stored in the compilers arena allocator) <code>ValTreeKind</code>.</p>

<h3 id="valtreekind"><code>ValTreeKind</code></h3>

<p>How does a <code>ValTreeKind</code> look like?</p>

<pre><code>pub enum ValTreeKind&lt;&#39;tcx&gt; {
    Leaf(ScalarInt),
    Branch(Box&lt;[ValTree&lt;&#39;tcx&gt;]&gt;),
}</code></pre>

<p>Ok, so it is a classic tree. It contains either <em>itself</em>, or a <code>ScalarInt</code>. That makes sense - <code>ValTreeKind</code> is used to represent constants.</p>

<p>So far, I don&#39;t see anything suspicious. Let us take a look at  <code>ScalarInt</code>.</p>

<h3 id="scalarint">ScalarInt</h3>

<pre><code>#[derive(Clone, Copy, PartialEq)]
#[repr(packed(1))]
pub struct ScalarInt {
    data: u128,
    size: u8,
}</code></pre>

<p>Ah! I can imedietly sense something suspicious about this code!</p>

<p>We have an <em>alignment</em> issue, and <code>#[repr(packed(1))]</code> is supposed to relax the alignment requirements.</p>

<p>Perhaps we are simply translating it incorrectly?</p>

<p>Let us see if we can minimize the issue:</p>

<pre><code>#[derive(Clone, Copy, PartialEq)]
#[repr(packed(1))]
pub struct ScalarInt {
    data: u128,
    size: u8,
}
#[inline(never)]
fn eq(a: &amp;ScalarInt, b: &amp;ScalarInt) -&gt; bool {
    a == b
}
fn main() {
    // We create an array of 2 elements to get an unaligned `ScalarInt`
    // (which is normally fine with `#[repr(packed(1))]`).
    let data = [std::hint::black_box(ScalarInt { data: 0, size: 1 }); 2];
    data.iter().all(|v| eq(v, &amp;ScalarInt { data: 0, size: 1 }));
}</code></pre>

<p>Yeap - that is enough to make the program <em>crash</em>.</p>

<p>So, we now know for sure that:</p>

<ol type="1">
<li>The pointer is <em>supposed</em> to be unaligned, and</li>

<li>We are supposed to codegen an unaligned load instruction here</li>

<li>But we codegen an aligned one instead.</li>
</ol>

<p>Surprisingly, this issue occurs <strong>only</strong> if we use <code>i128</code> or <code>u128</code>.</p>

<p>Any other type - everything works out just fine... why? Why does packed work with <code>u64</code>(and use unalgined loads there), but breaks with <code>u128</code>?</p>

<p>Let us take a look and the code handling unaligned loads.</p>

<h2 id="unaligned_loads">unaligned loads</h2>

<pre><code>fn load(&amp;mut self, pointee_ty: Type&lt;&#39;gcc&gt;, ptr: RValue&lt;&#39;gcc&gt;, align: Align) -&gt; RValue&lt;&#39;gcc&gt; {
    let block = self.llbb();
    let function = block.get_function();</code></pre>

<p>Ok, so we get a pointer, a type, and an alignment. Seems fine so far</p>

<pre><code>// FIXME(antoyo): this check that we don&#39;t call get_aligned() a second time on a type.
// Ideally, we shouldn&#39;t need to do this check.
let aligned_type = if pointee_ty == self.cx.u128_type || pointee_ty == self.cx.i128_type {
    pointee_ty
} else {
    pointee_ty.get_aligned(align.bytes())
}</code></pre>

<p>Huh? Normally, we set the alignment of the pointer, but here... we just skip that for 128 bit intigers.</p>

<p>That... that explains the bug.</p>

<p>Now, you may wonder why we need to skip the alignment here in the first place.</p>

<p>You see, <code>libgccjit</code> is sometimes a bit... special.</p>

<p>It behaves in a consistent, kind of logical way, that is also utterly infuriating.</p>

<p>If you call <code>get_aligned(4)</code> on a <code>uint8_t</code>, it will turn it into:</p>

<pre><code>__attribute__((aligned(4))) uint8_t</code></pre>

<p>logical.</p>

<p>If we call <code>get_aligned(4)</code> on that type, we&#39;ll get:</p>

<pre><code>__attribute__((aligned(4))) __attribute__((aligned(4))) uint8_t</code></pre>

<p>obviously.</p>

<p>Also, <code>__attribute__((aligned(4))) uint8_t</code> and <code>__attribute__((aligned(4))) __attribute__((aligned(4))) uint8_t</code> are different, incompatible types, and you can&#39;t mix them together.</p>

<p>So, we have to avoid calling <code>get_aligned</code> twice on a type at all costs.</p>

<p>The fix ended up being simple: we just skip calling <code>get_aligned</code> only when the alignment is already correct.</p>

<pre><code>let aligned_type = if (pointee_ty == self.cx.u128_type || pointee_ty == self.cx.i128_type) &amp;&amp; align == self.int128_align</code></pre>

<p>And, <a href="https://github.com/rust-lang/rustc_codegen_gcc/commit/1afdb550193caea993648e2dc34427335eaca4b2">with this fix</a>, we can limp on to stage3!</p>

<p>...with the emphasis on <em>limp</em>. At some points, we are using over 100 GB of RAM... not ideal.</p>

<p>We also often overflow our stack(in a GCC analysis pass)... but that is a story for another day.</p>



<p>Yeah. We achieved some neat things. But, as always in life, there is so much more to do...</p>

<p>To spoil my future articles, both of the issues I mentioned... have been fixed for over a month.</p>

<p>I have <em>so much</em> to write about. Fuzzing with <code>rustlantis</code>, bootstrapping on ARM, ABI bugs, GCC(?) bugs...</p>

<p>But my writing has been lagging behind my work by a lot.</p>

<p>I suppose that is a good thing.</p>

<p>If you want some unedited, more up-to-date information about my progress, you can check out the GSoC proposal&#39;s <a href="https://rust-lang.zulipchat.com/#narrow/channel/421156-gsoc/topic/Project.3A.20Bootstrap.20of.20rustc.20with.20rustc_codegen_gcc/with/527276268">zulip channel</a>.</p>

<p>That is the place where I discuss the progress with other Rust compiler devs. Overall, I&#39;d recommend you read over all the<a href="https://rust-lang.zulipchat.com/#narrow/channel/421156-gsoc"> GSoC zulip channels</a> - there are some great projects in the works :).</p>

<p>If you want to check out <a href="https://github.com/rust-lang/rustc_codegen_gcc">`rustc_codegen_gcc`, here is the repo link</a>.</p>

<p>As always: if you have any questions(or feedback), feel free to let me know :)!</p>
</div></div></div>
  </body>
</html>
