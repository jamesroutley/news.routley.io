<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gizmodo.com/californias-ag-tells-ai-companies-practically-everything-theyre-doing-might-be-illegal-2000555896">Original</a>
    <h1>Cali&#39;s AG Tells AI Companies Almost Everything They&#39;re Doing Might Be Illegal</h1>
    
    <div id="readability-page-1" class="page"><div>
              
              
              <p>The legality of the AI industry’s business practices has long been <a href="https://gizmodo.com/a-new-class-action-lawsuit-adds-to-openais-growing-lega-1850593431">a hanging question</a>. As a “disruptive” new technology, artificial intelligence has <a href="https://eng.vt.edu/magazine/stories/fall-2023/ai.html">caused a wealth of problems</a> at the very same time that it has offered society new benefits. Notably, AI has been used to <a href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes">mislead consumers</a>, to create new forms of <a href="https://hai.stanford.edu/news/disinformation-machine-how-susceptible-are-we-ai-propaganda">disinformation and propaganda</a>, and to <a href="https://www.aclu.org/news/privacy-technology/how-artificial-intelligence-can-deepen-racial-and-economic-inequities">discriminate against certain groups of people</a>. Now, the California Attorney General’s office has issued a legal memo emphasizing the fact that all of that stuff is probably illegal.</p> <p>On January 13th, California AG Rob Bonta issued <a href="https://oag.ca.gov/system/files/attachments/press-docs/Legal%20Advisory%20-%20Application%20of%20Existing%20CA%20Laws%20to%20Artificial%20Intelligence.pdf">two legal advisories</a> that illustrate all of the myriad areas where the AI industry could be getting itself into trouble. “The AGO encourages the responsible use of AI in ways that are safe, ethical, and consistent with human dignity,” the advisory says. “For AI systems to achieve their positive potential without doing harm, they must be developed and used ethically and legally,” it continues, before dovetailing into the many ways in which AI companies could, potentially, be breaking the law.</p> <p>Some of those ways include:</p>

 <ul> <li><strong>Using AI to “foster or advance deception.”</strong> If you hadn’t noticed, the internet is currently awash in a veritable tsunami of fake content. Concerns about a new generation of deepfakes and disinformation have exploded ever since AI content generators became popular—and with good reason. California’s memo makes clear that companies that use AI to create “deepfakes, chatbots, and voice clones that appear to represent people, events, and utterances that never existed” could fall under the category of “deceptive” and, thus, be considered a breach of state law.</li> <li><strong>Falsely advertising “the accuracy, quality, or utility of AI systems.”</strong> There has been quite <a href="https://www.businessinsider.com/generative-ai-exaggeration-openai-nvidia-microsoft-chatgpt-jobs-investors-markets-2024-3">a lot of, shall we say, <em>hyperbole</em></a>, when it comes to the AI industry and what it claims it can accomplish versus what it can actually accomplish. Bonta’s office says that, to steer clear of California’s false advertising law, companies should refrain from “claiming that an AI system has a capability that it does not; representing that a system is completely powered by AI when humans are responsible for performing some of its functions; representing that humans are responsible for performing some of a system’s functions when AI is responsible instead; or claiming without basis that a system is accurate, performs tasks better than a human would, has specified characteristics, meets industry or other standards, or is free from bias.”</li> <li><strong>Create or sell an AI system or product that has “an adverse or disproportionate impact on members of a protected class, or create, reinforce, or perpetuate discrimination or segregation of members of a protected class</strong>.<strong>“</strong> AI systems have been shown to integrate human bias into their algorithms, which is particularly disturbing when you consider that AI is now being used to vet people for housing and employment opportunities. Bonta’s office notes that automated systems that have disparate impacts on different groups of people could run afoul of the state’s anti-discrimination laws.</li> </ul> <p>Bonta’s advisory also includes a list of recently passed regulations related to the AI industry. The fact that the advisory says that all of these activities “may” break the law seems to signal that companies should effectively sell-regulate, lest they stray into criminal territory and tempt the state to take action against them.</p> <p>Bonta’s memo clearly illustrates what a legal clusterfuck the AI industry represents, though it doesn’t even get around to mentioning U.S. copyright law, which is another <a href="https://crsreports.congress.gov/product/pdf/LSB/LSB10922">legal gray area</a> where AI companies are perpetually running into trouble. Currently, OpenAI is <a href="https://gizmodo.com/openai-accuses-the-new-york-times-of-hacking-chatgpt-1851290653">being sued by the New York Times</a>, which has accused the company of breaking U.S. copyright law by using its articles to train its algorithms. AI companies have <a href="https://www.wired.com/story/ai-copyright-case-tracker/">repeatedly been sued over this issue</a> but, because AI’s foray into content generation represents largely unsettled legal territory, none of those lawsuits have yet been successful.</p>
                          </div></div>
  </body>
</html>
