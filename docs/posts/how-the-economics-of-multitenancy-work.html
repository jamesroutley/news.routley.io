<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.blacksmith.sh/blog/the-economics-of-operating-a-ci-cloud">Original</a>
    <h1>How the economics of multitenancy work</h1>
    
    <div id="readability-page-1" class="page"><div><p>In the early days of Blacksmith, back when we were just a scrappy<a href="https://www.blacksmith.sh/blog/going-through-yc-winter-24" target="_blank"> YC startup</a> building a serverless cloud platform for CI workloads, we ran simulations to model our margins. We figured that with enough customers, the math would work out, and we crossed our fingers — but we didn’t have any real-world data to back up our predictions.</p><p>About six months after we launched, I came across<a href="https://brooker.co.za/blog/2023/03/23/economics.html" target="_blank"> a blog post</a> by Marc Brooker on the economics of multitenant systems. It captured what we were trying to do much more elegantly than the half-formed ideas in our heads. This post was heavily inspired by Marc’s, and reading it was a real moment of, <em>&#34;Oh! someone else has thought about this, and it makes sense.&#34;<br/></em></p><h2>CI Isn’t Like Production (And That Matters).</h2><p>Unlike production workloads, CI workloads tend to be very spiky. Below, we’ve plotted CPU utilization for one of our customers over a 24-hour window. It spikes when someone pushes code, then chills out in between.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/68223888bd42f0e49049f825_AD_4nXeSffqllExgAscJ5z_HPS-3cikKIYBSQ7gFOVXlNh1bUll0ULzze95PXiy-F6eN35iYWqHIEVcrYltdvZio8Cxj0UFhz6SAkvNbM0UuLFXYU_LtM4vlwYCwer_95FoaToTrBPy6Jg.png" loading="lazy" alt=""/></p></figure><p>This customer runs 35 jobs on 16 vCPU machines for every git push, meaning they need over 500 vCPUs every time they run CI. See where the chart flatlines like a patient on the George Clooney classic “ER”? Since their team is split across the US and EU, there’s an 8-hour stretch in the middle with zero usage. And when a few engineers push at once — say, five people — they suddenly need 2,500+ vCPUs instantly. And all these CI jobs are short-lived. Most CI jobs finish fast (relatively speaking), somewhere between 5 and 40 minutes. All of these chaotic characteristics of CI workloads might sound like a nightmare, but it’s actually a perfect fit for the serverless model we’ve built our platform around, and most importantly, for our customers.<br/></p><h2>Why Our Serverless CI Model Works.</h2><p>Think about it from the customer&#39;s side: If you need 2,500 vCPUs at peak, it would be crazy to buy and manage all that hardware yourself — especially when it would sit idle most of the time. But with Blacksmith’s serverless CI cloud, you get to borrow from our pool and only pay for what you use. Spiky, bursty, chaotic? No problem. </p><p>What’s more, CI traffic is highly predictable. Developers are pushing code during work hours, not at 2AM or during holiday weekends. Unlike some production workloads, our fleet is not bracing for Black Friday-style traffic surges — and that shapes a lot of how we built it.</p><h2>Our Fleet: What It Looks Like and What Matters Most.</h2><p>We have a fleet of hundreds of bare-metal gaming CPUs that we’re virtualizing over — when a customer needs to run a CI job, we spin up a microVM using<a href="https://firecracker-microvm.github.io/" target="_blank"> Firecracker</a>, and once the job’s complete — poof! It’s gone. </p><p>Each of our machines has 32 vCPUs, and across the whole kit and kaboodle, we manage tens of thousands of vCPUs across our region us-west and eu-central. We pin customers to one region for consistency and workflow support.</p><p>Currently, we lease these machines for a fixed period. Soon, we’ll be racking them up in a datacenter. Regardless, these machines are a fixed cost — whether we have customers or not, we’re still paying for them. So, the name of the CI cost optimization game is utilization. If they’re barely used, our margins are low; if they’re used enough, we make that cash money. The metric we track the most is average fleet utilization — and that’s where customer chaos becomes our secret weapon.</p><h2>A Bit of Chaos is Bad. A Lot of Chaos? Chef&#39;s Kiss.</h2><p>Let’s say we only had one customer — the one from earlier who needs 2,500 vCPUs at peak. We’d need around 80 machines to handle that load, but for most of the day, those machines would just sit there, twiddling their thumbs. We’d be bleeding money.</p><p>Now, add a second customer in the same time zone. Their CI jobs don’t peak at the exact same time, so instead of needing 160 machines (80 + 80), we might only need 110 to cover both. As we add more customers, the effect compounds. We add even more customers, and all the random bursts of activity start to blend together.</p><p>Over time, CI jobs start behaving like a Poisson process — random, short bursts spread out across time. From a distance, what once looked like sharp spikes from individual customers smooths into a predictable pattern. The more customers we serve, the less intense each individual spike appears. In short: the more chaotic it gets, the better it is for our business. And when it’s better for business, it’s better for customers, too — because as our fleet gets busier, the cost to serve each job goes down. That lets us keep prices low while still running a sustainable business.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682238886ac6ab91059416e4_AD_4nXfIih5C-WAkfSy3pSAJ76i2gj1bGIsxKW5QDg3a8L43g1DQpyNEw6ntx6uHvNeXoV5e3PjOBe60GENpCB4vXXcNQJXpwRRsjIj7AtQIkKPs6OsRf9vPJnB75HT4ACv0ZNelQRgr.png" loading="lazy" alt=""/></p></figure><p>The beauty of this setup is that every new customer actually makes the system better for everyone. Like when you have a dinner party and say, “<em>the more the merrier</em>” and actually mean it. More customers = more randomness = smoother overall operation. Multitenant systems work better with more users: utilization goes up, and our costs to serve go down. That means that growing chaos on our fleet only improves cost savings and efficiencies. You win. We win. In fact, even our fleet running hot is a good thing.</p><h2><em>A Fleet Running Hot Means More Money.</em></h2><p>Since we have to pay for a fixed fleet of machines no matter what, our gross margins depend almost entirely on how busy our machines are.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682247cde86bb073c71e164e_image%20(4).png" loading="lazy" alt=""/></p></figure><p>Basically, our revenue scales with the average utilization of the fleet. There’s a direct link between utilization and gross margins, and it’s not linear.</p><ul role="list"><li>At 10% utilization, we’re already hitting around 35% gross margins.</li><li>At 20% utilization, margins jump to about 70%.</li><li>At 35% utilization, we’re flirting with 85%+ gross margins.</li></ul><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682246036dd76c966b3d0821_Screenshot%202025-05-12%20at%2011.56.25%E2%80%AFAM.png" loading="lazy" alt=""/></p></figure><p>Modest improvements in utilization result in massive improvements in profitability. Once utilization is high, the next major lever to keep improving margins is driving down the cost of acquiring machines — and for that time of day plays a surprisingly big role.</p><h2>Who’s Pushing Code When?</h2><p>During the weekends, our fleet only sees about 1/5<sup>th</sup> our typical usage. But weekdays? That’s when the party really starts.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682246d5bddb0bc7c9cf73dd_hourly%20utilization.png" loading="lazy" alt=""/></p></figure><p>Most of our customers are based in the US, with a decent chunk in Europe, and a slowly growing portion in Asia. As seen in the chart below, utilization stays low during the first 8 hours of the day. Here’s the breakdown (in UTC time):</p><ul role="list"><li>Early hours = crickets (our Asian customer base is still small).</li><li>Midday = a bump from Europe.</li><li>Late Afternoon = the US wakes up, and our fleet is flying.</li></ul><p>The biggest spikes we see come when Europe’s finishing the day, and when the East Coast and West Coast are both working at the same time. Customers outside the US use our fleet during low-traffic hours — essentially free utilization. That boosts margins without us needing more machines. That’s CI cost optimization at its finest. Add it to the board, another win. We only really need to expand our fleet to keep up with growth in the US. And just like time zones shape customers’ daily usage and how we think about our fleet, geography shapes where we build and scale our fleet.</p><h2>Region Economics.</h2><p>We originally started with a single region in eu-central, but over time, we realized that we needed a second region in the US. This was driven by customer requests since Docker pushes to a container registry in the US is even faster when your runner is in the US. Plus, a few customers preferred keeping their code inside the US for compliance reasons. At first, the US region had just one big customer, so margins and utilization were meh. But as more folks have joined, our numbers are looking better and better as utilization improves. </p><p>We’re still working on optimally load balancing our regions, but this post is already too long so that’s a story for another day. If you made it this far, thanks for reading. Still burning a few VC dollars, but hey — margins are looking good thanks to the power of multitenancy. If you’d like to help improve them even more, <a href="https://app.blacksmith.sh/" target="_blank">try out Blacksmith</a>.</p></div></div>
  </body>
</html>
