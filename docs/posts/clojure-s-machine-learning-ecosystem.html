<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://codewithkira.com/2024-04-04-state-of-clojure-ml.html">Original</a>
    <h1>Clojure&#39;s machine learning ecosystem</h1>
    
    <div id="readability-page-1" class="page"><div>

      
<p>I had a really enlightening talk with <a href="https://www.linkedin.com/in/daniel-slutsky-42122b4/">Daniel Slutsky</a> this week (who is an exceptional data scientist, software engineer, and community organizer I highly recommended meeting if you haven&#39;t already) about the current state of the machine learning landscape in Clojure. This post is my attempt to distill it into a summary for the community&#39;s benefit, so more people can understand where things are at and what the active developers in this space are working on.</p><p>It&#39;s no secret I love Clojure and especially working with data in Clojure, but it&#39;s fair to say that the Clojure for data science ecosystem is not anywhere near as easy to use or understand as reasonable potential users might expect. This is the main problem I&#39;m focusing on this year, and there is significant effort being put into refining our tools to make them more accessible to a wider audience.</p><p>There are already people doing &#34;real&#34; machine learning work in Clojure, though, and below is an overview of what the current state of our libraries and tools are in that area, as of April 2024.</p><h2 id="summary">Summary</h2><p>There are a lot of links in this post. This table is an attempt to aggregate and summarize them. There are more details worth reading below, but in case you don&#39;t have time, this is the gist of it. To make a very long story short, current efforts are heavily focused on consolidating all of these amazing libraries into one (or at least a small number of clearly delineated ones) that is/are easy-to-use, providing a comphrehensive toolkit for doing machine learning in Clojure.</p><table><thead><tr><th>Category</th><th>Library</th><th>Description</th><th>License</th></tr></thead><tbody><tr><td><strong>Java ML Libraries</strong></td><td><a href="https://tribuo.org/">Tribuo</a></td><td>A comprehensive Java ML framework, preferred library for ML workflows</td><td>Apache 2.0</td></tr><tr><td></td><td><a href="https://github.com/haifengl/smile">Smile 2.x</a></td><td>Currently being phased out of main Clojure ML libraries</td><td>LGPL</td></tr><tr><td></td><td><a href="https://github.com/haifengl/smile">Smile 3.x</a></td><td>Avoided due to licensing</td><td>GPL</td></tr><tr><td></td><td><a href="https://xgboost.readthedocs.io/en/stable/jvm/index.html">XGBoost for JVM</a></td><td>Implements gradient boosting algorithms, can be used through Tribuo</td><td>Apache 2.0</td></tr><tr><td><strong>Clojure Wrappers</strong></td><td><a href="https://github.com/generateme/fastmath">fastmath 2.4.0+</a></td><td>Clojure ML/stats library, dependency on Smile 2.x</td><td>MIT</td></tr><tr><td></td><td><a href="https://github.com/generateme/fastmath">fastmath 3.x</a></td><td>Fastmath with no Smile dependency</td><td>MIT</td></tr><tr><td></td><td><a href="https://github.com/generateme/fastmath-clustering">fastmath-clustering</a></td><td>Fastmath wrapper around Smile clustering, dependency on Smile 2.x</td><td>EPL-2.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/scicloj.ml.tribuo">scicloj.ml.tribuo</a></td><td>Clojure wrapper for Tribuo, likely to become the main source for ML algorithms</td><td>EPL-1.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/scicloj.ml.smile">scicloj.ml.smile</a></td><td>Clojure wrapper for more of Smile (than fastmath), likely to be deprecated due to licensing</td><td>EPL-2.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/scicloj.ml.xgboost">scicloj.ml.xgboost</a></td><td>Clojure wrapper for XGBoost directly</td><td>EPL-1.0</td></tr><tr><td></td><td><a href="https://github.com/techascent/tech.ml.dataset">tech.ml.dataset</a></td><td>Core dataframe/dataset library in Clojure, incorporates some Tribuo functionality</td><td>EPL-1.0</td></tr><tr><td></td><td><a href="https://github.com/techascent/tech.ml">tech.ml</a></td><td>Early Clojure ML library, superceded by various scicloj.ml libraries</td><td>EPL-1.0</td></tr><tr><td><strong>Clojure ML Pipelines</strong></td><td><a href="https://github.com/scicloj/metamorph">metamorph</a></td><td>Clojure function composition library</td><td>EPL-2.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/metamorph.ml">metamorph.ml</a></td><td>Clojure library for composing ML pipelines based on metamorph</td><td>EPL-2.0</td></tr><tr><td><strong>Collections/Frameworks</strong></td><td><a href="https://github.com/scicloj/scicloj.ml">scicloj.ml</a></td><td>Collection of Clojure ML libraries and documentation, being deprecated in favour of noj</td><td>EPL-2.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/noj">noj</a></td><td><strong>Consolidated Clojure data science toolkit, likely to become the main, unified entry-point for Clojure&#39;s data science stack</strong></td><td>EPL-1.0</td></tr><tr><td><strong>Interop</strong></td><td><a href="https://github.com/cnuernber/libpython-clj">libpython-clj</a></td><td>Python bindings for Clojure, enabling use of Python code and libraries directly from Clojure</td><td>EPL-2.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/sklearn-clj">sklearn-clj</a></td><td>Utilizes libpython-clj for access to scikit-learn estimators and models from Clojure</td><td>EPL-1.0</td></tr><tr><td></td><td><a href="https://github.com/scicloj/clojisr">clojisr</a></td><td>Bridge from Clojure to R, less relevance for ML compared to Python interop</td><td>EPL-2.0</td></tr></tbody></table><p>In addition to all of these libraries, the post mentions the <a href="https://clojurians.zulipchat.com/">Clojurians Zulip</a>, the main Clojure-for-data-science community discussion forum, where main contributors to the ecosystem are active daily.</p><h2 id="java_ml_libraries">Java ML Libraries</h2><p>There are two (sort of four) popular Java libraries that implement many of the main algorithms and tools used in machine learning today (e.g. classification, regression, clustering, model development, etc.): <a href="https://tribuo.org/">Tribuo</a> (including XGBoost, more on that in a second) and <a href="https://haifengl.github.io/">Smile</a>. We count Smile as two libraries because Smile 2.x is LGPL-licensed, and Smile 3.x is GPL-licensed, which poses some potential conflicts for some end users. The community consensus is converging around moving away from Smile due to the GPL-relicensing issue, focusing instead on Tribuo and hand-rolled solutions.</p><p>There is also <a href="https://xgboost.readthedocs.io/en/stable/jvm/index.html">XGBoost</a> for the JVM, mentioned above, which is an implementation of gradient boosting. XGBoost is a collection of algorithms whereas Tribuo is a more comprehensive framework (including things like data management, model evaluation, and experiment tracking). XGBoost can be used from Tribuo, so I don&#39;t exactly count it as a standalone library, although it can also be used in that way.</p><h2 id="clojure_wrappers">Clojure wrappers</h2><p>There are two main &#34;families&#34; of libraries that wrap these Java ML libraries in Clojure.</p><p><a href="https://github.com/generateme/fastmath">Fastmath</a> includes statistical as well as machine learning tools for Clojure. Fastmath 2.4.0+ depends on Smile 2, and the forthcoming fastmath 3.x will have no Smile dependency at all. The clustering functionality in fastmath 2.x that depended on smile has been moved to the <a href="https://github.com/generateme/fastmath-clustering">fastmath-clustering</a> library, which will have a Smile 2.x dependency going forward. There is a strong preference in the community to avoid introducing GPL-licensed libraries into the ecosystem.</p><p>Clustering functionality will mostly be provided by <a href="https://github.com/scicloj/scicloj.ml.tribuo">scicloj.ml.tribuo</a> going forward which, as you might expect, wraps the Tribuo Java library, and is likely to become the main source of ML algorithms for the ecosystem. This is one of a few libraries in the second family of libraries that wrap the Java libraries mentioned above. Other (self-explanatory) ones include <a href="https://github.com/scicloj/scicloj.ml.smile">scicloj.ml.smile</a>, which wraps more of Smile than fastmath did (does), and <a href="https://github.com/scicloj/scicloj.ml.xgboost">scicloj.ml.xgboost</a>.</p><p>It&#39;s also worth mentioning <a href="https://github.com/techascent/tech.ml.dataset">tech.ml.dataset</a> (the core dataframe/dataset library underlying tablecloth), which <a href="https://github.com/techascent/tech.ml.dataset/blob/master/src/tech/v3/libs/tribuo.clj">incorporates some of the functionality of tribuo</a>, with the API centred around individual datasets. There also used to be a library called <a href="https://github.com/techascent/tech.ml">tech.ml</a>, which implements some machine learning tools, but has been deprecated in favour of the various libraries discussed above.</p><p>The concept of orienting an API around individual datasets vs something else leads me to the next group of libraries. </p><h2 id="clojure_ml_pipelines">Clojure ML Pipelines</h2><p><a href="https://github.com/scicloj/metamorph">Metamorph</a> is a library that implements a function composition mechanism for composing ML pipelines. It arises from the common ML practice of repeatedly running the same set of functions with varied parameters. You might, for example, try many different test/train splits to see how that affects your results, or fit the same data using many different algorithms, or try training your model using different sets of features. This leads to an explosion of pipeline permutations, so it&#39;s useful to have machinery to encapsulate the variable components of your ML pipeline into a single function. This is where metamorph.ml comes in. </p><p><a href="https://github.com/scicloj/metamorph.ml">Metamorph.ml</a> is based on this concept of meta-functions and pipelines. It is currently the central library for orchestrating ML pipelines in Clojure. The API is stable, but there are currently <a href="https://clojurians.zulipchat.com/#narrow/stream/321125-noj-dev/topic/ols.20interaction.20tutorial/near/422408507">many ways (10+)</a> to achieve the same outcomes. This is great for power users who have complex needs and a clear understanding of the metamorph mental model, but it can be a bit daunting for newcomers, making it more challenging to pick a clear place to start. The community is actively discussing the best approach for consolidating and/or documenting these different approaches in the interest of making Clojure&#39;s ML stack more accessible.</p><h2 id="collections/frameworks">Collections/Frameworks</h2><p>The community is well aware that it is difficult to know where to get started and several efforts have been made in an attempt to make the path more clear for people who want tools that Just Work. <a href="https://github.com/scicloj/scicloj.ml">scicloj.ml</a> is one such project. It&#39;s a collection of libraries (mostly the ones mentioned above) with some lightweight wrappers and efforts in creating documentation.</p><p>The community is heading toward deprecating this library, though, in favour of <a href="https://github.com/scicloj/noj">noj</a>, which we are hoping to stabilize in the near future. The goal is to have a single entry-point into the Clojure data science stack, gathering all the tools one would need to work with data consolidated in one place, with seamless interoperability akin to R&#39;s tidyverse of libraries.</p><h2 id="interop">Interop</h2><p>It wouldn&#39;t be a complete roundup of the state of ML in Clojure without a mention of <a href="https://github.com/clj-python/libpython-clj">libpython-clj</a>. This is a library that provides Python bindings for Clojure, so you can call Python code directly from Clojure if necessary. <a href="https://github.com/scicloj/sklearn-clj">sklearn-clj</a> makes use of this bridge to provide direct access to all of the estimators and models from Python <a href="https://scikit-learn.org/">scikit-learn</a> in Clojure, so for cases where something is truly only available in Python, we can still access it.</p><p>It&#39;s worth also briefly mentioning <a href="https://github.com/scicloj/clojisr">clojisr</a> here, which is a similar kind of bridge from Clojure to R (and there exist libraries for Julia and Wolframite, too), but these are all less relevant for the specific area of ML, where Python is the overwhelmingly most popular current tool of choice.</p><h2 id="more_updates">More updates</h2><p>These discussions all happen in the open, on the <a href="https://clojurians.zulipchat.com">Clojurian&#39;s Zulip instance</a>, which has become the main gathering place of the Clojure-for-data-science community. The <code>#data-science</code> and <code>#noj-dev</code> streams are the most active on these topics at the time of this writing. You can follow along with developments in the trenches over there, or follow the key libraries on github for updates (<a href="https://github.com/scicloj/scicloj.ml.tribuo">scicloj.ml.tribuo</a>, <a href="https://github.com/scicloj/metamorph.ml">metamorph.ml</a>, <a href="https://github.com/scicloj/noj">noj</a>). I will also post periodic updates here and all the other corners of the internet where I lurk. Thank you for reading!</p>

<p><i>Published: 2024-04-04</i></p>

<p>
  <i>
  Tagged:
  
  <span>
    <a href="https://codewithkira.com/tags/clojure.html">clojure</a>
  </span>
  
  <span>
    <a href="https://codewithkira.com/tags/scicloj.html">scicloj</a>
  </span>
  
  <span>
    <a href="https://codewithkira.com/tags/machine-learning.html">machine learning</a>
  </span>
  
  </i>
</p>



      
      
      
    </div></div>
  </body>
</html>
