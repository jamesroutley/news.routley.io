<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41586-022-05172-4">Original</a>
    <h1>Discovering faster matrix multiplication algorithms with reinforcement learning</h1>
    
    <div id="readability-page-1" class="page"><div>
                <section data-title="Main"><div id="Sec1-section"><h2 id="Sec1">Main</h2><div id="Sec1-content"><p>We focus on the fundamental task of matrix multiplication, and use deep reinforcement learning (DRL) to search for provably correct and efficient matrix multiplication algorithms. This algorithm discovery process is particularly amenable to automation because a rich space of matrix multiplication algorithms can be formalized as low-rank decompositions of a specific three-dimensional (3D) tensor<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e494">2</a></sup>, called the matrix multiplication tensor<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bürgisser, P., Clausen, M. &amp; Shokrollahi, A. Algebraic Complexity Theory Vol. 315 (Springer Science &amp; Business Media, 2013)." href="#ref-CR3" id="ref-link-section-d97101721e498">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bläser, M. Fast matrix multiplication. Theory Comput. 5, 1–60 (2013)." href="#ref-CR4" id="ref-link-section-d97101721e498_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="#ref-CR5" id="ref-link-section-d97101721e498_2">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pan, V. Y. Fast feasible and unfeasible matrix multiplication. Preprint at 
                  https://arxiv.org/abs/1804.04102
                  
                 (2018)." href="#ref-CR6" id="ref-link-section-d97101721e498_3">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Lim, L.-H. Tensors in computations. Acta Numer. 30, 555–764 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR7" id="ref-link-section-d97101721e501">7</a></sup>. This space of algorithms contains the standard matrix multiplication algorithm and recursive algorithms such as Strassen’s<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e505">2</a></sup>, as well as the (unknown) asymptotically optimal algorithm. Although an important body of work aims at characterizing the complexity of the asymptotically optimal algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schönhage, A. Partial and total matrix multiplication. SIAM J. Comput. 10, 434–455 (1981)." href="#ref-CR8" id="ref-link-section-d97101721e509">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Coppersmith, D. &amp; Winograd, S. Matrix multiplication via arithmetic progressions. In ACM Symposium on Theory of Computing 1–6 (ACM, 1987)." href="#ref-CR9" id="ref-link-section-d97101721e509_1">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Strassen, V. The asymptotic spectrum of tensors and the exponent of matrix multiplication. In 27th Annual Symposium on Foundations of Computer Science 49–54 (IEEE, 1986)." href="#ref-CR10" id="ref-link-section-d97101721e509_2">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Le Gall, F. Powers of tensors and fast matrix multiplication. In International Symposium on Symbolic and Algebraic Computation 296–303 (ACM, 2014)." href="#ref-CR11" id="ref-link-section-d97101721e509_3">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Alman, J. &amp; Williams, V. V. A refined laser method and faster matrix multiplication. In ACM-SIAM Symposium on Discrete Algorithms 522–539 (SIAM, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR12" id="ref-link-section-d97101721e512">12</a></sup>, this does not yield practical algorithms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e516">5</a></sup>. We focus here on practical matrix multiplication algorithms, which correspond to explicit low-rank decompositions of the matrix multiplication tensor. In contrast to two-dimensional matrices, for which efficient polynomial-time algorithms computing the rank have existed for over two centuries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Gauss, C. F. Theoria Motus Corporum Coelestium in Sectionibus Conicis Solum Ambientium (Perthes and Besser, 1809)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR13" id="ref-link-section-d97101721e521">13</a></sup>, finding low-rank decompositions of 3D tensors (and beyond) is NP-hard<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Hillar, C. J. &amp; Lim, L.-H. Most tensor problems are NP-hard. J. ACM 60, 1–39 (2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR14" id="ref-link-section-d97101721e525">14</a></sup> and is also hard in practice. In fact, the search space is so large that even the optimal algorithm for multiplying two 3 × 3 matrices is still unknown. Nevertheless, in a longstanding research effort, matrix multiplication algorithms have been discovered by attacking this tensor decomposition problem using human search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e529">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. Bull. Am. Math. Soc. 82, 126–128 (1976)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR15" id="ref-link-section-d97101721e532">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hopcroft, J. E. &amp; Kerr, L. R. On minimizing the number of multiplications necessary for matrix multiplication. SIAM J. Appl. Math. 20, 30–36 (1971)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR16" id="ref-link-section-d97101721e535">16</a></sup>, continuous optimization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vervliet, N., Debals, O., Sorber, L., Van Barel, M. &amp; De Lathauwer, L. Tensorlab 3.0 (2016); 
                  https://www.tensorlab.net/
                  
                " href="#ref-CR17" id="ref-link-section-d97101721e539">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Smirnov, A. V. The bilinear complexity and practical algorithms for matrix multiplication. Comput. Math. Math. Phys. 53, 1781–1795 (2013)." href="#ref-CR18" id="ref-link-section-d97101721e539_1">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Sedoglavic, A. &amp; Smirnov, A. V. The tensor rank of 5x5 matrices multiplication is bounded by 98 and its border rank by 89. In Proc. 2021 on International Symposium on Symbolic and Algebraic Computation 345–351 (ACM, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR19" id="ref-link-section-d97101721e542">19</a></sup> and combinatorial search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Heule, M. J., Kauers, M. &amp; Seidl, M. New ways to multiply 3 × 3-matrices. J. Symb. Comput. 104, 899–916 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR20" id="ref-link-section-d97101721e546">20</a></sup>. These approaches often rely on human-designed heuristics, which are probably suboptimal. We instead use DRL to learn to recognize and generalize over patterns in tensors, and use the learned agent to predict efficient decompositions.</p><p>We formulate the matrix multiplication algorithm discovery procedure (that is, the tensor decomposition problem) as a single-player game, called TensorGame. At each step of TensorGame, the player selects how to combine different entries of the matrices to multiply. A score is assigned based on the number of selected operations required to reach the correct multiplication result. This is a challenging game with an enormous action space (more than 10<sup>12</sup> actions for most interesting cases) that is much larger than that of traditional board games such as chess and Go (hundreds of actions). To solve TensorGame and find efficient matrix multiplication algorithms, we develop a DRL agent, AlphaTensor. AlphaTensor is built on AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR1" id="ref-link-section-d97101721e555">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hubert, T. et al. Learning and planning in complex action spaces. In International Conference on Machine Learning 4476–4486 (PMLR, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR21" id="ref-link-section-d97101721e558">21</a></sup>, where a neural network is trained to guide a planning procedure searching for efficient matrix multiplication algorithms. Our framework uses a single agent to decompose matrix multiplication tensors of various sizes, yielding transfer of learned decomposition techniques across various tensors. To address the challenging nature of the game, AlphaTensor uses a specialized neural network architecture, exploits symmetries of the problem and makes use of synthetic training games.</p><p>AlphaTensor scales to a substantially larger algorithm space than what is within reach for either human or combinatorial search. In fact, AlphaTensor discovers from scratch many provably correct matrix multiplication algorithms that improve over existing algorithms in terms of number of scalar multiplications. We also adapt the algorithm discovery procedure to finite fields, and improve over Strassen’s two-level algorithm for multiplying 4 × 4 matrices for the first time, to our knowledge, since its inception in 1969. AlphaTensor also discovers a diverse set of algorithms—up to thousands for each size—showing that the space of matrix multiplication algorithms is richer than previously thought. We also exploit the diversity of discovered factorizations to improve state-of-the-art results for large matrix multiplication sizes. Through different use-cases, we highlight AlphaTensor’s flexibility and wide applicability: AlphaTensor discovers efficient algorithms for structured matrix multiplication improving over known results, and finds efficient matrix multiplication algorithms tailored to specific hardware, by optimizing for actual runtime. These algorithms multiply large matrices faster than human-designed algorithms on the same hardware.</p></div></div></section><section data-title="Algorithms as tensor decomposition"><div id="Sec2-section"><h2 id="Sec2">Algorithms as tensor decomposition</h2><div id="Sec2-content"><p>As matrix multiplication (<b>A</b>, <b>B</b>) <span>↦</span> <b>A</b><b>B</b> is bilinear (that is, linear in both arguments), it can be fully represented by a 3D tensor: see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig1">1a</a> for how to represent the 2 × 2 matrix multiplication operation as a 3D tensor of size 4 × 4 × 4, and refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Bürgisser, P., Clausen, M. &amp; Shokrollahi, A. Algebraic Complexity Theory Vol. 315 (Springer Science &amp; Business Media, 2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR3" id="ref-link-section-d97101721e587">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e590">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Lim, L.-H. Tensors in computations. Acta Numer. 30, 555–764 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR7" id="ref-link-section-d97101721e593">7</a></sup> for more details. We write <span>\({{\mathscr{T}}}_{n}\)</span> for the tensor describing <i>n</i> × <i>n</i> matrix multiplication. The tensor <span>\({{\mathscr{T}}}_{n}\)</span> is fixed (that is, it is independent of the matrices to be multiplied), has entries in {0, 1}, and is of size <i>n</i><sup>2</sup> × <i>n</i><sup>2</sup> × <i>n</i><sup>2</sup>. More generally, we use <span>\({{\mathscr{T}}}_{n,m,p}\)</span> to describe the rectangular matrix multiplication operation of size <i>n</i> × <i>m</i> with <i>m</i> × <i>p</i> (note that <span>\({{\mathscr{T}}}_{n}={{\mathscr{T}}}_{n,n,n}\)</span>). By a decomposition of <span>\({{\mathscr{T}}}_{n}\)</span> into <i>R</i> rank-one terms, we mean</p><div id="Equ1"><p><span>$${{\mathscr{T}}}_{n}=\mathop{\sum }\limits_{r=1}^{R}{{\bf{u}}}^{(r)}\otimes {{\bf{v}}}^{(r)}\otimes {{\bf{w}}}^{(r)},$$</span></p><p>
                    (1)
                </p></div><p>where <span>⊗</span> denotes the outer (tensor) product, and <b>u</b><sup>(<i>r</i>)</sup>, <b>v</b><sup>(<i>r</i>)</sup> and <b>w</b><sup>(<i>r</i>)</sup> are all vectors. If a tensor <span>\({\mathscr{T}}\)</span> can be decomposed into <i>R</i> rank-one terms, we say the rank of <span>\({\mathscr{T}}\)</span> is at most <i>R</i>, or <span>\(\,\text{Rank}\,({\mathscr{T}}\,)\le R\)</span>. This is a natural extension from the matrix rank, where a matrix is decomposed into <span>\({\sum }_{r=1}^{R}{{\bf{u}}}^{(r)}\otimes {{\bf{v}}}^{(r)}\)</span>.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Matrix multiplication tensor and algorithms."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Matrix multiplication tensor and algorithms.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-022-05172-4/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="271"/></picture></a></div><p><b>a</b>, Tensor <span>\({{\mathscr{T}}}_{2}\)</span> representing the multiplication of two 2 × 2 matrices. Tensor entries equal to 1 are depicted in purple, and 0 entries are semi-transparent. The tensor specifies which entries from the input matrices to read, and where to write the result. For example, as <i>c</i><sub>1</sub> = <i>a</i><sub>1</sub><i>b</i><sub>1</sub> + <i>a</i><sub>2</sub><i>b</i><sub>3</sub>, tensor entries located at (<i>a</i><sub>1</sub>, <i>b</i><sub>1</sub>, <i>c</i><sub>1</sub>) and (<i>a</i><sub>2</sub>, <i>b</i><sub>3</sub>, <i>c</i><sub>1</sub>) are set to 1. <b>b</b>, Strassen&#39;s algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e1243">2</a></sup> for multiplying 2 × 2 matrices using 7 multiplications. <b>c</b>, Strassen&#39;s algorithm in tensor factor representation. The stacked factors <b>U</b>, <b>V</b> and <b>W</b> (green, purple and yellow, respectively) provide a rank-7 decomposition of <span>\({{\mathscr{T}}}_{2}\)</span> (equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Equ1">1</a>)). The correspondence between arithmetic operations (<b>b</b>) and factors (<b>c</b>) is shown by using the aforementioned colours.</p></div></figure></div><p>A decomposition of <span>\({{\mathscr{T}}}_{n}\)</span> into <i>R</i> rank-one terms provides an algorithm for multiplying arbitrary <i>n</i> × <i>n</i> matrices using <i>R</i> scalar multiplications (see Algorithm <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec3">1</a>). We refer to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig1">1b,c</a> for an example algorithm multiplying 2 × 2 matrices with <i>R</i> = 7 (Strassen’s algorithm).</p><p>Crucially, Algorithm <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec3">1</a> can be used to multiply block matrices. By using this algorithm recursively, one can multiply matrices of arbitrary size, with the rank <i>R</i> controlling the asymptotic complexity of the algorithm. In particular, <i>N</i> × <i>N</i> matrices can be multiplied with asymptotic complexity <span>\({\mathcal{O}}({N}^{{\log }_{n}(R)})\)</span>; see ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e1443">5</a></sup> for more details.</p><div data-expandable-box-container="true"><div data-expandable-box="true" aria-hidden="true" id="box-Sec3"><h3 id="Sec3">Algorithm 1</h3><div><p>A meta-algorithm parameterized by <span>\({\{{{\bf{u}}}^{(r)},{{\bf{v}}}^{(r)},{{\bf{w}}}^{(r)}\}}_{r=1}^{R}\)</span> for computing the matrix product <b>C</b> = <b>A</b><b>B</b>. It is noted that <i>R</i> controls the number of multiplications between input matrix entries.</p><p>Parameters: <span>\({\{{{\bf{u}}}^{(r)},{{\bf{v}}}^{(r)},{{\bf{w}}}^{(r)}\}}_{r=1}^{R}\)</span>: length-<i>n</i><sup>2</sup> vectors such that <span>\({{\mathscr{T}}}_{n}={\sum }_{r=1}^{R}{{\bf{u}}}^{(r)}\otimes {{\bf{v}}}^{(r)}\otimes {{\bf{w}}}^{(r)}\)</span></p><p>Input: <b>A</b>, <b>B</b>: matrices of size <i>n</i> × <i>n</i></p><p>Output: <b>C</b> = <b>A</b><b>B</b></p><p>(1) <b>for</b> <i>r</i> = 1, …, <i>R</i> <b>do</b></p><p>(2)     <span>\({m}_{r}\leftarrow \left({u}_{1}^{(r)}{a}_{1}+\cdots +{u}_{{n}^{2}}^{(r)}{a}_{{n}^{2}}\right)\left({v}_{1}^{(r)}{b}_{1}+\cdots +{v}_{{n}^{2}}^{(r)}{b}_{{n}^{2}}\right)\)</span></p><p>(3) <b>for</b> <i>i</i> = 1, …, <i>n</i><sup>2</sup> <b>do</b></p><p>(4)     <span>\({c}_{i}\leftarrow {w}_{i}^{(1)}{m}_{1}+\cdots +{w}_{i}^{(R)}{m}_{R}\)</span></p><p>return <b>C</b></p></div></div></div></div></div></section><section data-title="DRL for algorithm discovery"><div id="Sec4-section"><h2 id="Sec4">DRL for algorithm discovery</h2><div id="Sec4-content"><p>We cast the problem of finding efficient matrix multiplication algorithms as a reinforcement learning problem, modelling the environment as a single-player game, TensorGame. The game state after step <i>t</i> is described by a tensor <span>\({{\mathscr{S}}}_{t}\)</span>, which is initially set to the target tensor we wish to decompose: <span>\({{\mathscr{S}}}_{0}={{\mathscr{T}}}_{n}\)</span>. In each step <i>t</i> of the game, the player selects a triplet (<b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup>, <b>w</b><sup>(<i>t</i>)</sup>), and the tensor <span>\({{\mathscr{S}}}_{t}\)</span> is updated by subtracting the resulting rank-one tensor: <span>\({{\mathscr{S}}}_{t}\leftarrow {{\mathscr{S}}}_{t-1}-{{\bf{u}}}^{(t)}\otimes {{\bf{v}}}^{(t)}\otimes {{\bf{w}}}^{(t)}\)</span>. The goal of the player is to reach the zero tensor <span>\({{\mathscr{S}}}_{t}={\bf{0}}\)</span> by applying the smallest number of moves. When the player reaches the zero tensor, the sequence of selected factors satisfies <span>\({{\mathscr{T}}}_{n}={\sum }_{t=1}^{R}{{\bf{u}}}^{(t)}\otimes {{\bf{v}}}^{(t)}\otimes {{\bf{w}}}^{(t)}\)</span> (where <i>R</i> denotes the number of moves), which guarantees the correctness of the resulting matrix multiplication algorithm. To avoid playing unnecessarily long games, we limit the number of steps to a maximum value, <i>R</i><sub>limit</sub>.</p><p>For every step taken, we provide a reward of −1 to encourage finding the shortest path to the zero tensor. If the game terminates with a non-zero tensor (after <i>R</i><sub>limit</sub> steps), the agent receives an additional terminal reward equal to <span>\(-\gamma ({{\mathscr{S}}}_{{R}_{\text{limit}}})\)</span>, where <span>\(\gamma ({{\mathscr{S}}}_{{R}_{\text{limit}}})\)</span> is an upper bound on the rank of the terminal tensor. Although this reward optimizes for rank (and hence for the complexity of the resulting algorithm), other reward schemes can be used to optimize other properties, such as practical runtime (see ‘Algorithm discovery results’). Besides, as our aim is to find exact matrix multiplication algorithms, we constrain {<b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup>, <b>w</b><sup>(<i>t</i>)</sup>} to have entries in a user-specified discrete set of coefficients <i>F</i> (for example, <i>F</i> = {−2, −1, 0, 1, 2}). Such discretization is common practice to avoid issues with the finite precision of floating points<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. Bull. Am. Math. Soc. 82, 126–128 (1976)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR15" id="ref-link-section-d97101721e2903">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Smirnov, A. V. The bilinear complexity and practical algorithms for matrix multiplication. Comput. Math. Math. Phys. 53, 1781–1795 (2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR18" id="ref-link-section-d97101721e2906">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Heule, M. J., Kauers, M. &amp; Seidl, M. New ways to multiply 3 × 3-matrices. J. Symb. Comput. 104, 899–916 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR20" id="ref-link-section-d97101721e2909">20</a></sup>.</p><p>To play TensorGame, we propose AlphaTensor (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig2">2</a>), an agent based on AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR1" id="ref-link-section-d97101721e2919">1</a></sup>, which achieved <i>tabula rasa</i> superhuman performance in the classical board games of Go, chess and shogi, and on its extension to handle large action spaces Sampled AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hubert, T. et al. Learning and planning in complex action spaces. In International Conference on Machine Learning 4476–4486 (PMLR, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR21" id="ref-link-section-d97101721e2926">21</a></sup>. Similarly to AlphaZero, AlphaTensor uses a deep neural network to guide a Monte Carlo tree search (MCTS) planning procedure. The network takes as input a state (that is, a tensor <span>\({{\mathscr{S}}}_{t}\)</span> to decompose), and outputs a policy and a value. The policy provides a distribution over potential actions. As the set of potential actions (<b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup>, <b>w</b><sup>(<i>t</i>)</sup>) in each step is enormous, we rely on sampling actions rather than enumerating them<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hubert, T. et al. Learning and planning in complex action spaces. In International Conference on Machine Learning 4476–4486 (PMLR, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR21" id="ref-link-section-d97101721e2984">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling. In International Joint Conferences on Artificial Intelligence Vol. 95, 1114–1120 (Morgan Kaufmann Publishers, 1995)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR22" id="ref-link-section-d97101721e2987">22</a></sup>. The value provides an estimate of the distribution <i>z</i> of returns (cumulative reward) starting from the current state <span>\({{\mathscr{S}}}_{t}\)</span>. With the above reward scheme, the distribution <i>z</i> models the agent’s belief about the rank of the tensor <span>\({{\mathscr{S}}}_{t}\)</span>. To play a game, AlphaTensor starts from the target tensor (<span>\({{\mathscr{T}}}_{n}\)</span>) and uses the MCTS planner at each step to choose the next action. Finished games are used as feedback to the network to improve the network parameters.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Overview of AlphaTensor."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Overview of AlphaTensor.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-022-05172-4/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="494"/></picture></a></div><p>The neural network (bottom box) takes as input a tensor <span>\({{\mathscr{S}}}_{t}\)</span>, and outputs samples (<b>u</b>, <b>v</b>, <b>w</b>) from a distribution over potential next actions to play, and an estimate of the future returns (for example, of <span>\(-{\rm{Rank}}\,({{\mathscr{S}}}_{t})\)</span>). The network is trained on two data sources: previously played games and synthetic demonstrations. The updated network is sent to the actors (top box), where it is used by the MCTS planner to generate new games.</p></div></figure></div><p>Overcoming the challenges posed by TensorGame—namely, an enormous action space, and game states described by large 3D tensors representing an abstract mathematical operation—requires multiple advances. All these components, described briefly below,  substantially improve the overall performance over a plain AlphaZero agent (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec15">Methods</a> and Supplementary Information for details).</p><h3 id="Sec5">Neural network architecture</h3><p>We propose a transformer-based<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Vaswani, A. Attention is all you need. In International Conference on Neural Information Processing Systems Vol 30, 5998–6008 (Curran Associates, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR23" id="ref-link-section-d97101721e3206">23</a></sup> architecture that incorporates inductive biases for tensor inputs. We first project the <i>S</i> × <i>S</i> × <i>S</i> input tensor into three <i>S</i> × <i>S</i> grids of feature vectors by using linear layers applied to the three cyclic transpositions of the tensor. The main part of the model comprises a sequence of attention operations, each applied to a set of features belonging to a pair of grids (Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig8">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig9">4</a>). This generalizes axial attention<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Ho, J., Kalchbrenner, N., Weissenborn, D. &amp; Salimans, T. Axial attention in multidimensional transformers. Preprint at 
                  https://arxiv.org/abs/1912.12180
                  
                 (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR24" id="ref-link-section-d97101721e3232">24</a></sup> to multiple grids, and is both more efficient and yields better results than naive self-attention. The proposed architecture, which disregards the order of rows and columns in the grids, is inspired by the invariance of the tensor rank to slice reordering. The final feature representation of the three matrices is passed both to the policy head (an autoregressive model) and the value head (a multilayer perceptron).</p><h3 id="Sec6">Synthetic demonstrations</h3><p>Although tensor decomposition is NP-hard, the inverse task of constructing the tensor from its rank-one factors is elementary. Hence, we generate a large dataset of tensor-factorization pairs (synthetic demonstrations) by first sampling factors <span>\({\{({{\bf{u}}}^{(r)},{{\bf{v}}}^{(r)},{{\bf{w}}}^{(r)})\}}_{r=1}^{R}\)</span> at random, and then constructing the tensor <span>\({\mathscr{D}}={\sum }_{r=1}^{R}{{\bf{u}}}^{(r)}\otimes {{\bf{v}}}^{(r)}\otimes {{\bf{w}}}^{(r)}\)</span>. We train the network on a mixture of supervised loss (that is, to imitate synthetic demonstrations) and standard reinforcement learning loss (that is, learning to decompose a target tensor <span>\({{\mathscr{T}}}_{n}\)</span>) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig2">2</a>). This mixed training strategy—training on the target tensor and random tensors— substantially outperforms each training strategy separately. This is despite randomly generated tensors having different properties from the target tensors.</p><h3 id="Sec7">Change of basis</h3><p> <span>\({{\mathscr{T}}}_{n}\)</span> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig1">1a</a>) is the tensor representing the matrix multiplication bilinear operation in the canonical basis. The same bilinear operation can be expressed in other bases, resulting in other tensors. These different tensors are equivalent: they have the same rank, and decompositions obtained in a custom basis can be mapped to the canonical basis, hence obtaining a practical algorithm of the form in Algorithm <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec3">1</a>. We leverage this observation by sampling a random change of basis at the beginning of every game, applying it to <span>\({{\mathscr{T}}}_{n}\)</span>, and letting AlphaTensor play the game in that basis (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig2">2</a>). This crucial step injects diversity into the games played by the agent.</p><h3 id="Sec8">Data augmentation</h3><p>From every played game, we can extract additional tensor-factorization pairs for training the network. Specifically, as factorizations are order invariant (owing to summation), we build an additional tensor-factorization training pair by swapping a random action with the last action from each finished game.</p></div></div></section><section data-title="Algorithm discovery results"><div id="Sec9-section"><h2 id="Sec9">Algorithm discovery results</h2><div id="Sec9-content"><h3 id="Sec10">Discovery of matrix multiplication algorithms</h3><p>We train a single AlphaTensor agent to find matrix multiplication algorithms for matrix sizes <i>n</i> × <i>m</i> with <i>m</i> × <i>p</i>, where <i>n</i>, <i>m</i>, <i>p</i> ≤ 5. At the beginning of each game, we sample uniformly a triplet (<i>n</i>, <i>m</i>, <i>p</i>) and train AlphaTensor to decompose the  tensor <span>\({{\mathscr{T}}}_{n,m,p}\)</span>. Although we consider tensors of fixed size (<span>\({{\mathscr{T}}}_{n,m,p}\)</span> has size <i>n</i><i>m</i> × <i>m</i><i>p</i> × <i>p</i><i>n</i>), the discovered algorithms can be applied recursively to multiply matrices of arbitrary size. We use AlphaTensor to find matrix multiplication algorithms over different arithmetics—namely, modular arithmetic (that is, multiplying matrices in the quotient ring <span>\({{\mathbb{Z}}}_{2}\)</span>), and standard arithmetic (that is, multiplying matrices in <span>\({\mathbb{R}}\)</span>).</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig3">3</a> (left) shows the complexity (that is, rank) of the algorithms discovered by AlphaTensor. AlphaTensor re-discovers the best algorithms known for multiplying matrices (for example, Strassen’s<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e3800">2</a></sup> and Laderman’s<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. Bull. Am. Math. Soc. 82, 126–128 (1976)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR15" id="ref-link-section-d97101721e3804">15</a></sup> algorithms). More importantly, AlphaTensor improves over the best algorithms known for several matrix sizes. In particular, AlphaTensor finds an algorithm for multiplying 4 × 4 matrices using 47 multiplications in <span>\({{\mathbb{Z}}}_{2}\)</span>, thereby outperforming Strassen’s two-level algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e3837">2</a></sup>, which involves 7<sup>2</sup> = 49 multiplications. By applying this algorithm recursively, one obtains a practical matrix multiplication algorithm in <span>\({{\mathbb{Z}}}_{2}\)</span> with complexity <span>\({\mathcal{O}}({N}^{2.778})\)</span>. Moreover, AlphaTensor discovers efficient algorithms for multiplying matrices in standard arithmetic; for example, AlphaTensor finds a rank-76 decomposition of <span>\({{\mathscr{T}}}_{4,5,5}\)</span>, improving over the previous state-of-the-art complexity of 80 multiplications. See Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig6">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig7">2</a> for examples.</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Comparison between the complexity of previously known matrix multiplication algorithms and the ones discovered by AlphaTensor."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Comparison between the complexity of previously known matrix multiplication algorithms and the ones discovered by AlphaTensor.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-022-05172-4/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="484"/></picture></a></div><p>Left: column (<i>n</i>, <i>m</i>, <i>p</i>) refers to the problem of multiplying <i>n</i> × <i>m</i> with <i>m</i> × <i>p</i> matrices. The complexity is measured by the number of scalar multiplications (or equivalently, the number of terms in the decomposition of the tensor). ‘Best rank known’ refers to the best known upper bound on the tensor rank (before this paper), whereas ‘AlphaTensor rank’ reports the rank upper bounds obtained with our method, in modular arithmetic (<span>\({{\mathbb{Z}}}_{2}\)</span>) and standard arithmetic. In all cases, AlphaTensor discovers algorithms that match or improve over known state of the art (improvements are shown in red). See Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig6">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig7">2</a> for examples of algorithms found with AlphaTensor. Right: results (for arithmetic in <span>\({\mathbb{R}}\)</span>) of applying AlphaTensor-discovered algorithms on larger tensors. Each red dot represents a tensor size, with a subset of them labelled. See Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Tab1">1</a> for the results in table form. State-of-the-art results are obtained from the list in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Fast matrix multiplication algorithms catalogue. Université de Lille 
                  https://fmm.univ-lille.fr/
                  
                 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR64" id="ref-link-section-d97101721e4052">64</a></sup>.</p></div></figure></div><p>AlphaTensor generates a large database of matrix multiplication algorithms—up to thousands of algorithms for each size. We exploit this rich space of algorithms by combining them recursively, with the aim of decomposing larger matrix multiplication tensors. We refer to refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Drevet, C.-É., Islam, M. N. &amp; Schost, É. Optimization techniques for small matrix multiplication. Theor. Comput. Sci. 412, 2219–2236 (2011)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR25" id="ref-link-section-d97101721e4067">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Sedoglavic, A. A non-commutative algorithm for multiplying (7 × 7) matrices using 250 multiplications. Preprint at 
                  https://arxiv.org/abs/1712.07935
                  
                 (2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR26" id="ref-link-section-d97101721e4070">26</a></sup> and Appendix H in Supplementary Information for more details. Using this approach, we improve over the state-of-the-art results for more than 70 matrix multiplication tensors (with <i>n</i>, <i>m</i>, <i>p</i> ≤ 12). See Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig3">3</a> (right) and Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Tab1">1</a> for the results.</p><p>A crucial aspect of AlphaTensor is its ability to learn to transfer knowledge between targets (despite providing no prior knowledge on their relationship). By training one agent to decompose various tensors, AlphaTensor shares learned strategies among these, thereby improving the overall performance (see Supplementary Information for analysis). Finally, it is noted that AlphaTensor scales beyond current computational approaches for decomposing tensors. For example, to our knowledge, no previous approach was able to handle <span>\({{\mathscr{T}}}_{4}\)</span>, which has an action space 10<sup>10</sup> times larger than <span>\({{\mathscr{T}}}_{3}\)</span>. Our agent goes beyond this limit, discovering decompositions matching or surpassing state-of-the-art for large tensors such as <span>\({{\mathscr{T}}}_{5}\)</span>.</p><h3 id="Sec11">Analysing the symmetries of matrix multiplication algorithms</h3><p>From a mathematical standpoint, the diverse algorithms discovered by AlphaTensor show that the space is richer than previously known. For example, while the only known rank-49 factorization decomposing <span>\({{\mathscr{T}}}_{4}={{\mathscr{T}}}_{2}\otimes {{\mathscr{T}}}_{2}\)</span> before this paper conforms to the product structure (that is, it uses the factorization of <span>\({{\mathscr{T}}}_{2}\)</span> twice, which we refer to as Strassen-square<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e4283">2</a></sup>), AlphaTensor finds more than 14,000 non-equivalent factorizations (with standard arithmetic) that depart from this scheme, and have different properties (such as matrix ranks and sparsity—see Supplementary Information). By non-equivalent, we mean that it is not possible to obtain one from another by applying a symmetry transformation (such as permuting the factors). Such properties of matrix multiplication tensors are of great interest, as these tensors represent fundamental objects in algebraic complexity theory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Bürgisser, P., Clausen, M. &amp; Shokrollahi, A. Algebraic Complexity Theory Vol. 315 (Springer Science &amp; Business Media, 2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR3" id="ref-link-section-d97101721e4287">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e4290">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Lim, L.-H. Tensors in computations. Acta Numer. 30, 555–764 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR7" id="ref-link-section-d97101721e4293">7</a></sup>. The study of matrix multiplication symmetries can also provide insight into the asymptotic complexity of matrix multiplication<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e4297">5</a></sup>. By exploring this rich space of algorithms, we believe that AlphaTensor will be useful for generating results and guiding mathematical research. See Supplementary Information for proofs and details on the symmetries of factorizations.</p><h3 id="Sec12">Beyond standard matrix multiplication</h3><p>Tensors can represent any bilinear operation, such as structured matrix multiplication, polynomial multiplication or more custom bilinear operations used in machine learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Battaglia, P. W. et al. Relational inductive biases, deep learning, and graph networks. Preprint at 
                  https://arxiv.org/abs/1806.01261
                  
                 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR27" id="ref-link-section-d97101721e4309">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Balog, M., van Merriënboer, B., Moitra, S., Li, Y. &amp; Tarlow, D. Fast training of sparse graph neural networks on dense hardware. Preprint at 
                  https://arxiv.org/abs/1906.11786
                  
                 (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR28" id="ref-link-section-d97101721e4312">28</a></sup>. We demonstrate here a use-case where AlphaTensor finds a state-of-the-art algorithm for multiplying an <i>n</i> x <i>n</i> skew-symmetric matrix  with a vector of length <i>n</i>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig4">4a</a> shows the obtained decompositions for small instance sizes <i>n</i>. We observe a pattern that we generalize to arbitrary <i>n</i>, and prove that this yields a general algorithm for the skew-symmetric matrix-vector product (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig4">4b</a>). This algorithm, which uses <span>\((n-1)(n+2)/2 \sim \frac{1}{2}{n}^{2}\)</span> multiplications (where <span>∼</span> indicates asymptotic similarity), outperforms the previously known algorithms using asymptotically <i>n</i><sup>2</sup> multiplications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Ye, K. &amp; Lim, L.-H. Fast structured matrix computations: tensor rank and Cohn–Umans method. Found. Comput. Math. 18, 45–95 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR29" id="ref-link-section-d97101721e4426">29</a></sup>, and is asymptotically optimal. See Supplementary Information for a proof, and for another use-case showing AlphaTensor’s ability to re-discover the Fourier basis (see also Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Tab2">2</a>). This shows that AlphaTensor can be applied to custom bilinear operations, and yield efficient algorithms leveraging the problem structure.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Algorithm discovery beyond standard matrix multiplication."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Algorithm discovery beyond standard matrix multiplication.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-022-05172-4/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="518"/></picture></a></div><p><b>a</b>, Decompositions found by AlphaTensor for the tensors of size <span>\(\frac{n(n-1)}{2}\times n\times n\)</span> (with <i>n</i> = 3, 4, 5, 6) representing the skew-symmetric matrix-vector multiplication. The red pixels denote 1, the blue pixels denote −1 and the white pixels denote 0. Extrapolation to <i>n</i> = 10 is shown in the rightmost figure. <b>b</b>, Skew-symmetric matrix-by-vector multiplication algorithm, obtained from the examples solved by AlphaTensor. The <i>w</i><sub><i>i</i><i>j</i></sub> and <i>q</i><sub><i>i</i></sub> terms in steps 3 and 5 correspond to the <i>m</i><sub><i>r</i></sub> terms in Algorithm 1. It is noted that steps 6–9 do not involve any multiplications.</p></div></figure></div><h3 id="Sec13">Rapid tailored algorithm discovery</h3><p>We show a use-case where AlphaTensor finds practically efficient matrix multiplication algorithms, tailored to specific hardware, with zero prior hardware knowledge. To do so, we modify the reward of AlphaTensor: we provide an additional reward at the terminal state (after the agent found a correct algorithm) equal to the negative of the runtime of the algorithm when benchmarked on the target hardware. That is, we set <span>\({r}_{t}^{{\prime} }={r}_{t}+\lambda {b}_{t}\)</span>, where <i>r</i><sub><i>t</i></sub> is the reward scheme described in ‘DRL for algorithm discovery’, <i>b</i><sub><i>t</i></sub> is the benchmarking reward (non-zero only at the terminal state) and <i>λ</i> is a user-specified coefficient. Aside from the different reward, the exact same formulation of TensorGame is used.</p><p>We train AlphaTensor to search for efficient algorithms to multiply 4 × 4 block matrices, and focus on square matrix multiplication of size 8,192 (each block is hence of size 2,048) to define the benchmarking reward. AlphaTensor searches for the optimal way of combining the 16 square blocks of the input matrices on the considered hardware. We do not apply the 4 × 4 algorithm recursively, to leverage the efficient implementation of matrix multiplication on moderate-size matrices (2,048 × 2,048 in this case). We study two hardware devices commonly used in machine learning and scientific computing: an Nvidia V100 graphics processing unit (GPU) and a Google tensor processing unit (TPU) v2. The factorization obtained by AlphaTensor is transformed into JAX<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Bradbury, J. et al. JAX: composable transformations of Python+NumPy programs. GitHub 
                  http://github.com/google/jax
                  
                 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR30" id="ref-link-section-d97101721e4635">30</a></sup> code, which is compiled (just in time) before benchmarking.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig5">5a,b</a> shows the efficiency of the AlphaTensor-discovered algorithms on the GPU and the TPU, respectively. AlphaTensor discovers algorithms that outperform the Strassen-square algorithm, which is a fast algorithm for large square matrices<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Benson, A. R. &amp; Ballard, G. A framework for practical parallel fast matrix multiplication. ACM SIGPLAN Not. 50, 42–53 (2015)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR31" id="ref-link-section-d97101721e4645">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Huang, J., Smith, T. M., Henry, G. M. &amp; Van De Geijn, R. A. Strassen’s algorithm reloaded. In International Conference for High Performance Computing, Networking, Storage and Analysis 690–701 (IEEE, 2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR32" id="ref-link-section-d97101721e4648">32</a></sup>. Although the discovered algorithm has the same theoretical complexity as Strassen-square, it outperforms it in practice, as it is optimized for the considered hardware. Interestingly, AlphaTensor finds algorithms with a larger number of additions compared with Strassen-square (or equivalently, denser decompositions), but the discovered algorithms generate individual operations that can be efficiently fused by the specific XLA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Abadi, M. et al. Tensorflow: a system for large-scale machine learning. In USENIX Symposium On Operating Systems Design And Implementation 265–283 (USENIX, 2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR33" id="ref-link-section-d97101721e4652">33</a></sup> grouping procedure and thus are more tailored towards the compiler stack we use. The algorithms found by AlphaTensor also provide gains on matrix sizes larger than what they were optimized for. Finally, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig5">5c</a> shows the importance of tailoring to particular hardware, as algorithms optimized for one hardware do not perform as well on other hardware.</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Speed-ups of the AlphaTensor-discovered algorithm."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Speed-ups of the AlphaTensor-discovered algorithm.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-022-05172-4/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig5_HTML.png?as=webp"/><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-022-05172-4/MediaObjects/41586_2022_5172_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="263"/></picture></a></div><p><b>a</b>,<b>b</b>, Speed-ups (%) of the AlphaTensor-discovered algorithms tailored for a GPU (<b>a</b>) and a TPU (<b>b</b>), optimized for a matrix multiplication of size 8,192 × 8,192. Speed-ups are measured relative to standard (for example, cuBLAS for the GPU) matrix multiplication on the same hardware. Speed-ups are reported for various matrix sizes (despite optimizing the algorithm only on one matrix size). We also report the speed-up of the Strassen-square  algorithm. The median speed-up is reported over 200 runs. The standard deviation over runs is &lt;0.4 percentage points (see Supplementary Information for more details). <b>c</b>, Speed-up of both algorithms (tailored to a GPU and a TPU) benchmarked on both devices.</p></div></figure></div></div></div></section><section data-title="Discussion"><div id="Sec14-section"><h2 id="Sec14">Discussion</h2><div id="Sec14-content"><p>Trained from scratch, AlphaTensor discovers matrix multiplication algorithms that are more efficient than existing human and computer-designed algorithms. Despite improving over known algorithms, we note that a limitation of AlphaTensor is the need to pre-define a set of potential factor entries <i>F</i>, which discretizes the search space but can possibly lead to missing out on efficient algorithms. An interesting direction for future research is to adapt AlphaTensor to search for <i>F</i>. One important strength of AlphaTensor is its flexibility to support complex stochastic and non-differentiable rewards (from the tensor rank to practical efficiency on specific hardware), in addition to finding algorithms for custom operations in a wide variety of spaces (such as finite fields). We believe this will spur applications of AlphaTensor towards designing algorithms that optimize metrics that we did not consider here, such as numerical stability or energy usage.</p><p>The discovery of matrix multiplication algorithms has far-reaching implications, as matrix multiplication sits at the core of many computational tasks, such as matrix inversion, computing the determinant and solving linear systems, to name a few<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Lim, L.-H. Tensors in computations. Acta Numer. 30, 555–764 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR7" id="ref-link-section-d97101721e4711">7</a></sup>. We also note that our methodology can be extended to tackle related primitive mathematical problems, such as computing other notions of rank (for example, border rank—see Supplementary Information), and NP-hard matrix factorization problems (for example, non-negative factorization). By tackling a core NP-hard computational problem in mathematics using DRL—the computation of tensor ranks—AlphaTensor demonstrates the viability of DRL in addressing difficult mathematical problems, and potentially assisting mathematicians in discoveries.</p></div></div></section><section data-title="Methods"><div id="Sec15-section"><h2 id="Sec15">Methods</h2><div id="Sec15-content"><h3 id="Sec16">TensorGame</h3><p>TensorGame is played as follows. The start position <span>\({{\mathscr{S}}}_{0}\)</span> of the game corresponds to the tensor <span>\({\mathscr{T}}\)</span> representing the bilinear operation of interest, expressed in some basis. In each step <i>t</i> of the game, the player writes down three vectors (<b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup>, <b>w</b><sup>(<i>t</i>)</sup>), which specify the rank-1 tensor <b>u</b><sup>(<i>t</i>)</sup> <span>⊗</span> <b>v</b><sup>(<i>t</i>)</sup> <span>⊗</span> <b>w</b><sup>(<i>t</i>)</sup>, and the state of the game is updated by subtracting the newly written down factor:</p><div id="Equ2"><p><span>$${{\mathscr{S}}}_{t}\leftarrow {{\mathscr{S}}}_{t-1}-{{\bf{u}}}^{(t)}\otimes {{\bf{v}}}^{(t)}\otimes {{\bf{w}}}^{(t)}.$$</span></p><p>
                    (2)
                </p></div><p>The game ends when the state reaches the zero tensor, <span>\({{\mathscr{S}}}_{R}={\bf{0}}\)</span>. This means that the factors written down throughout the game form a factorization of the start tensor <span>\({{\mathscr{S}}}_{0}\)</span>, that is, <span>\({{\mathscr{S}}}_{0}={\sum }_{t=1}^{R}{{\bf{u}}}^{(t)}\otimes {{\bf{v}}}^{(t)}\otimes {{\bf{w}}}^{(t)}\)</span>. This factorization is then scored. For example, when optimizing for asymptotic time complexity the score is −<i>R</i>, and when optimizing for practical runtime the algorithm corresponding to the factorization <span>\({\{({{\bf{u}}}^{(t)},{{\bf{v}}}^{(t)},{{\bf{w}}}^{(t)})\}}_{t=1}^{R}\)</span> is constructed (see Algorithm <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec3">1</a>) and then benchmarked on the fly (see Supplementary Information).</p><p>In practice, we also impose a limit <i>R</i><sub>limit</sub> on the maximum number of moves in the game, so that a weak player is not stuck in unnecessarily (or even infinitely) long games. When a game ends  because it has run out of moves, a penalty score is given so that it is never advantageous to deliberately exhaust the move limit. For example, when optimizing for asymptotic time complexity, this penalty is derived from an upper bound on the tensor rank of the final residual tensor <span>\({{\mathscr{S}}}_{{R}_{\text{limit}}}\)</span>. This upper bound on the tensor rank is obtained by summing the matrix ranks of the slices of the tensor.</p><h4 id="Sec17">TensorGame over rings</h4><p>We say that the decomposition of <span>\({{\mathscr{T}}}_{n}\)</span> in equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Equ1">1</a>) is in a ring <span>\({\mathcal{E}}\)</span> (defining the arithmetic operations) if each of the factors <b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup> and <b>w</b><sup>(<i>t</i>)</sup> has entries belonging to the set <span>\({\mathcal{E}}\)</span>, and additions and multiplications are interpreted according to <span>\({\mathcal{E}}\)</span>. The tensor rank depends, in general, on the ring. At each step of TensorGame, the additions and multiplications in equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Equ2">2</a>) are interpreted in <span>\({\mathcal{E}}\)</span>. For example, when working in <span>\({{\mathbb{Z}}}_{2}\)</span>, (in this case, the factors <b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup> and <b>w</b><sup>(<i>t</i>)</sup> live in <i>F</i> = {0, 1}), a modulo 2 operation is applied after each state update (equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Equ2">2</a>)).</p><p>We note that integer-valued decompositions <b>u</b><sup>(<i>t</i>)</sup>, <b>v</b><sup>(<i>t</i>)</sup> and <b>w</b><sup>(<i>t</i>)</sup> lead to decompositions in arbitrary rings <span>\({\mathcal{E}}\)</span>. Hence, provided <i>F</i> only contains integers, algorithms we find in standard arithmetic apply more generally to any ring.</p><h3 id="Sec18">AlphaTensor</h3><p>AlphaTensor builds on AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR1" id="ref-link-section-d97101721e5607">1</a></sup> and its extension Sampled AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hubert, T. et al. Learning and planning in complex action spaces. In International Conference on Machine Learning 4476–4486 (PMLR, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR21" id="ref-link-section-d97101721e5611">21</a></sup>, combining a deep neural network with a sample-based MCTS search algorithm.</p><p>The deep neural network, <i>f</i><sub><i>θ</i></sub>(<i>s</i>) = (<i>π</i>, <i>z</i>) parameterized by <i>θ</i>, takes as input the current state <i>s</i> of the game and outputs a probability distribution <i>π</i>(<span>⋅</span><span>∣</span><i>s</i>) over actions and <i>z</i>(<span>⋅</span><span>∣</span><i>s</i>) over returns (sum of future rewards) <i>G</i>. The parameters <i>θ</i> of the deep neural network are trained by reinforcement learning from self-play games and synthetic demonstrations. Self-play games are played by actors, running a sample-based MCTS search at every state <i>s</i><sub><i>t</i></sub> encountered in the game. The MCTS search returns an improved probability distribution over moves from which an action <i>a</i><sub><i>t</i></sub> is selected and applied to the environment. The sub-tree under <i>a</i><sub><i>t</i></sub> is reused for the subsequent search at <i>s</i><sub><i>t</i>+1</sub>. At the end of the game, a return <i>G</i> is obtained and the trajectory is sent to the learner to update the neural network parameters <i>θ</i>. The distribution over returns <i>z</i>(<span>⋅</span><span>∣</span><i>s</i><sub><i>t</i></sub>) is learned through distributional reinforcement learning using the quantile regression distributional loss<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Dabney, W., Rowland, M., Bellemare, M. &amp; Munos, R. Distributional reinforcement learning with quantile regression. In AAAI Conference on Artificial Intelligence Vol. 32, 2892–2901 (AAAI Press, 2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR34" id="ref-link-section-d97101721e5701">34</a></sup>, and the network policy <i>π</i>(<span>⋅</span><span>∣</span><i>s</i><sub><i>t</i></sub>) is updated using a Kullback–Leibler divergence loss, to maximize its similarity to the search policy for self-play games or to the next action for synthetic demonstrations. We use the Adam optimizer<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Kingma, D. P., &amp; Ba, J. Adam: a method for stochastic optimization. In International Conference on Learning Representations (ICLR) (2015)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR35" id="ref-link-section-d97101721e5714">35</a></sup> with decoupled weight decay<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Loshchilov, I. &amp; Hutter, F. Decoupled weight decay regularization. In International Conference on Learning Representations (ICLR) (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR36" id="ref-link-section-d97101721e5718">36</a></sup> to optimize the parameters <i>θ</i> of the neural network.</p><h4 id="Sec19">Sample-based MCTS search</h4><p>The sample-based MCTS search is very similar to the one described in Sampled AlphaZero. Specifically, the search consists of a series of simulated trajectories of TensorGame that are aggregated in a tree. The search tree therefore consists of nodes representing states and edges representing actions. Each state-action pair (<i>s</i>, <i>a</i>) stores a set of statistics <span>\(N(s,a),Q(s,a),\hat{\pi }(s,a)\)</span>, where <i>N</i>(<i>s</i>, <i>a</i>) is the visit count, <i>Q</i>(<i>s</i>, <i>a</i>) is the action value and <span>\(\hat{\pi }(s,a)\)</span> is the empirical policy probability. Each simulation traverses the tree from the root state <i>s</i><sub>0</sub> until a leaf state <i>s</i><sub>L</sub> is reached by recursively selecting in each state <i>s</i> an action <i>a</i> that has not been frequently explored, has high empirical policy probability and high value. Concretely, actions within the tree are selected by maximizing over the probabilistic upper confidence tree bound<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hubert, T. et al. Learning and planning in complex action spaces. In International Conference on Machine Learning 4476–4486 (PMLR, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR21" id="ref-link-section-d97101721e5908">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR37" id="ref-link-section-d97101721e5911">37</a></sup></p><div id="Equa"><p><span>$$\mathop{{\rm{argmax}}}\limits_{a}Q(s,a)+c(s)\cdot \hat{\pi }(s,a)\frac{\sqrt{{\sum }_{b}N(s,b)}}{1+N(s,a)},$$</span></p></div><p>where <i>c</i>(<i>s</i>) is an exploration factor controlling the influence of the empirical policy <span>\(\hat{\pi }(s,a)\)</span> relative to the values <i>Q</i>(<i>s</i>, <i>a</i>) as nodes are visited more often. In addition, a transposition table is used to recombine different action sequences if they reach the exact same tensor. This can happen particularly often in TensorGame as actions are commutative. Finally, when a leaf state <i>s</i><sub>L</sub> is reached, it is evaluated by the neural network, which returns <i>K</i> actions {<i>a</i><sub><i>i</i></sub>} sampled from <i>π</i>(<i>a</i><span>∣</span><i>s</i><sub>L</sub>), alongside the empirical distribution <span>\(\hat{\pi }(a| {s}_{{\rm{L}}})=\frac{1}{K}{\sum }_{i}{\delta }_{a,{a}_{i}}\)</span> and a value <i>v</i>(<i>s</i><sub>L</sub>) constructed from <i>z</i>(<span>⋅</span><span>∣</span><i>s</i><sub>L</sub>). Differently from AlphaZero and Sampled AlphaZero, we chose <i>v</i> not to be the mean of the distribution of returns <i>z</i>(<span>⋅</span><span>∣</span><i>s</i><sub><i>L</i></sub>) as is usual in most reinforcement learning agents, but instead to be a risk-seeking value, leveraging the facts that TensorGame is a deterministic environment and that we are primarily interested in finding the best trajectory possible. The visit counts and values on the simulated trajectory are then updated in a backward pass as in Sampled AlphaZero.</p><h4 id="Sec20">Policy improvement</h4><p>After simulating <i>N</i>(<i>s</i>) trajectories from state <i>s</i> using MCTS, the normalized visit counts of the actions at the root of the search tree <i>N</i>(<i>s</i>, <i>a</i>)/<i>N</i>(<i>s</i>) form a sample-based improved policy. Differently from AlphaZero and Sampled AlphaZero, we use an adaptive temperature scheme to smooth the normalized visit counts distribution as some states can accumulate an order of magnitude more visits than others because of sub-tree reuse and transposition table. Concretely, we define the improved policy as <span>\({\mathcal{I}}\hat{\pi }(s,a)={N}^{1/\tau (s)}(s,a)/{\sum }_{b}{N}^{1/\tau (s)}(s,b)\)</span> where <span>\(\tau (s)=\log N(s)/\log \bar{N}\,{\rm{if}}\,N &gt; \bar{N}\)</span> and 1 otherwise, with <span>\(\bar{N}\)</span> being a hyperparameter. For training, we use <span>\({\mathcal{I}}\hat{\pi }\)</span> directly as a target for the network policy <i>π</i>. For acting, we additionally discard all actions that have a value lower than the value of the most visited action, and sample proportionally to <span>\({\mathcal{I}}\hat{\pi }\)</span> among those remaining high-value actions.</p><h4 id="Sec21">Learning one agent for multiple target tensors</h4><p>We train a single agent to decompose the different tensors <span>\({{\mathscr{T}}}_{n,m,p}\)</span> in a given arithmetic (standard or modular). As the network works with fixed-size inputs, we pad all tensors (with zeros) to the size of the largest tensor we consider (<span>\({{\mathscr{T}}}_{5}\)</span>, of size 25 × 25 × 25). At the beginning of each game, we sample uniformly at random a target <span>\({{\mathscr{T}}}_{n,m,p}\)</span>, and play TensorGame. Training a single agent on different targets leads to better results thanks to the transfer between targets. All our results reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig3">3</a> are obtained using multiple runs of this multi-target setting. We also train a single agent to decompose tensors in both arithmetics. Owing to learned transfer between the two arithmetics, this agent discovers a different distribution of algorithms (of the same ranks) in standard arithmetic than the agent trained on standard arithmetic only, thereby increasing the overall diversity of discovered algorithms.</p><h4 id="Sec22">Synthetic demonstrations</h4><p>The synthetic demonstrations buffer contains tensor-factorization pairs, where the factorizations <span>\({\{({{\bf{u}}}^{(r)},{{\bf{v}}}^{(r)},{{\bf{w}}}^{(r)})\}}_{r=1}^{R}\)</span> are first generated at random, after which the tensor <span>\({\mathscr{D}}={\sum }_{r=1}^{R}{{\bf{u}}}^{(r)}\otimes {{\bf{v}}}^{(r)}\otimes {{\bf{w}}}^{(r)}\)</span> is formed. We create a dataset containing 5 million such tensor-factorization pairs. Each element in the factors is sampled independently and identically distributed (i.i.d.) from a given categorical distribution over <i>F</i> (all possible values that can be taken). We discarded instances whose decompositions were clearly suboptimal (contained a factor with <b>u</b> = <b>0</b>, <b>v</b> = <b>0</b>, or <b>w</b> = <b>0</b>).</p><p>In addition to these synthetic demonstrations, we further add to the demonstration buffer previous games that have achieved large scores to reinforce the good moves made by the agent in these games.</p><h4 id="Sec23">Change of basis</h4><p>The rank of a bilinear operation does not depend on the basis in which the tensor representing it is expressed, and for any invertible matrices <b>A</b>, <b>B</b> and <b>C</b> we have <span>\({\rm{Rank}}\,({\mathscr{T}})={\rm{Rank}}\,({{\mathscr{T}}}^{({\bf{A}},{\bf{B}},{\bf{C}})})\)</span>, where <span>\({{\mathscr{T}}}^{({\bf{A}},{\bf{B}},{\bf{C}})}\)</span> is the tensor after change of basis given by</p><div id="Equ3"><p><span>$${{\mathscr{T}}}_{ijk}^{({\bf{A}},{\bf{B}},{\bf{C}})}=\mathop{\sum }\limits_{a=1}^{S}\mathop{\sum }\limits_{b=1}^{S}\mathop{\sum }\limits_{c=1}^{S}{{\bf{A}}}_{ia}{{\bf{B}}}_{jb}{{\bf{C}}}_{kc}{{\mathscr{T}}}_{abc}.$$</span></p><p>
                    (3)
                </p></div><p>Hence, exhibiting a rank-<i>R</i> decomposition of the matrix multiplication tensor <span>\({{\mathscr{T}}}_{n}\)</span> expressed in any basis proves that the product of two <i>n</i> × <i>n</i> matrices can be computed using <i>R</i> scalar multiplications. Moreover, it is straightforward to convert such a rank-<i>R</i> decomposition into a rank-<i>R</i> decomposition in the canonical basis, thus yielding a practical algorithm of the form shown in Algorithm <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Sec3">1</a>. We leverage this observation by expressing the matrix multiplication tensor <span>\({{\mathscr{T}}}_{n}\)</span> in a large number of randomly generated bases (typically 100,000) in addition to the canonical basis, and letting AlphaTensor play games in all bases in parallel.</p><p>This approach has three appealing properties: (1) it provides a natural exploration mechanism as playing games in different bases automatically injects diversity into the games played by the agent; (2) it exploits properties of the problem as the agent need not succeed in all bases—it is sufficient to find a low-rank decomposition in any of the bases; (3) it enlarges coverage of the algorithm space because a decomposition with entries in a finite set <i>F</i> = {−2, −1, 0, 1, 2} found in a different basis need not have entries in the same set when converted back into the canonical basis.</p><p>In full generality, a basis change for a 3D tensor of size <i>S</i> × <i>S</i> × <i>S</i> is specified by three invertible <i>S</i> × <i>S</i> matrices <b>A</b>, <b>B</b> and <b>C</b>. However, in our procedure, we sample bases at random and impose two restrictions: (1) <b>A</b> = <b>B</b> = <b>C</b>, as this performed better in early experiments, and (2) unimodularity (<span>\(\det {\bf{A}}\in \{-1,+1\}\)</span>), which ensures that after converting an integral factorization into the canonical basis it still contains integer entries only (this is for representational convenience and numerical stability of the resulting algorithm). See Supplementary Information for the exact algorithm.</p><h4 id="Sec24">Signed permutations</h4><p>In addition to playing (and training on) games in different bases, we also utilize a data augmentation mechanism whenever the neural network is queried in a new MCTS node. At acting time, when the network is queried, we transform the input tensor by applying a change of basis—where the change of basis matrix is set to a random signed permutation. We then query the network on this transformed input tensor, and finally invert the transformation in the network’s policy predictions. Although this data augmentation procedure can be applied with any generic change of basis matrix (that is, it is not restricted to signed permutation matrices), we use signed permutations mainly for computational efficiency. At training time, whenever the neural network is trained on an (input, policy targets, value target) triplet (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig2">2</a>), we apply a randomly chosen signed permutation to both the input and the policy targets, and train the network on this transformed triplet. In practice, we sample 100 signed permutations at the beginning of an experiment, and use them thereafter.</p><h4 id="Sec25">Action canonicalization</h4><p>For any <i>λ</i><sub>1</sub>, <i>λ</i><sub>2</sub>, <i>λ</i><sub>3</sub> <span>∈</span> {−1, +1} such that <i>λ</i><sub>1</sub><i>λ</i><sub>2</sub><i>λ</i><sub>3</sub> = 1, the actions (<i>λ</i><sub>1</sub><b>u</b>, <i>λ</i><sub>2</sub><b>v</b>, <i>λ</i><sub>3</sub><b>w</b>) and (<b>u</b>, <b>v</b>, <b>w</b>) are equivalent because they lead to the same rank-one tensor (<i>λ</i><sub>1</sub><b>u</b>) <span>⊗</span> (<i>λ</i><sub>2</sub><b>v</b>) <span>⊗</span> (<i>λ</i><sub>3</sub><b>w</b>) = <b>u</b> <span>⊗</span> <b>v</b> <span>⊗</span> <b>w</b>. To prevent the network from wasting capacity on predicting multiple equivalent actions, during training we always present targets (<b>u</b>, <b>v</b>, <b>w</b>) for the policy head in a canonical form, defined as having the first non-zero element of <b>u</b> and the first non-zero element of <b>v</b> strictly positive. This is well defined because <b>u</b> or <b>v</b> cannot be all zeros (if they are to be part of a minimal rank decomposition), and for any (<b>u</b>, <b>v</b>, <b>w</b>) there are unique <i>λ</i><sub>1</sub>, <i>λ</i><sub>2</sub>, <i>λ</i><sub>3</sub> <span>∈</span> {−1, +1} (with <i>λ</i><sub>1</sub><i>λ</i><sub>2</sub><i>λ</i><sub>3</sub> = 1) that transform it into canonical form. In case the network predicts multiple equivalent actions anyway, we merge them together (summing their empirical policy probabilities) before inserting them into the MCTS tree.</p><h4 id="Sec26">Training regime</h4><p>We train AlphaTensor on a TPU v3, with a total batch size of 2,048. We use 64 TPU cores, and train for 600,000 iterations. On the actor side, the games are played on standalone TPU v4, and we use 1,600 actors. In practice, the procedure  takes a week to converge.</p><h3 id="Sec27">Neural network</h3><p>The architecture is composed of a torso, followed by a policy head that predicts a distribution over actions, and a value head that predicts a distribution of the returns from the current state (see Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig8">3</a>).</p><h4 id="Sec28">Input</h4><p>The input to the network contains all the relevant information of the current state and is composed of a list of tensors and a list of scalars. The most important piece of information is the current 3D tensor <span>\({{\mathscr{S}}}_{t}\)</span> of size <i>S</i> × <i>S</i> × <i>S</i>. (For simplicity, in the description here we assume that all the three dimensions of the tensor are equal in size. The generalization to different sizes is straightforward.) In addition, the model is given access to the last <i>h</i> actions (<i>h</i> being a hyperparameter usually set to 7), represented as <i>h</i> rank-1 tensors that are concatenated to the input. The list of scalars includes the time index <i>t</i> of the current action (where 0 ≤ <i>t</i> &lt; <i>R</i><sub>limit</sub>).</p><h4 id="Sec29">Torso</h4><p>The torso of the network is in charge of mapping both scalars and tensors from the input to a representation that is useful to both policy and value heads. Its architecture is based on a modification of transformers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Vaswani, A. Attention is all you need. In International Conference on Neural Information Processing Systems Vol 30, 5998–6008 (Curran Associates, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR23" id="ref-link-section-d97101721e7865">23</a></sup>, and its main signature is that it operates over three <i>S</i> × <i>S</i> grids projected from the <i>S</i> × <i>S</i> × <i>S</i> input tensors. Each grid represents two out of the three modes of the tensor. Defining the modes of the tensor as <span>\({\mathcal{U}},{\mathcal{V}},{\mathcal{W}}\)</span>, the rows and columns of the first grid are associated to <span>\({\mathcal{U}}\)</span> and <span>\({\mathcal{V}}\)</span>, respectively, the rows and columns of the second grid are associated to <span>\({\mathcal{W}}\)</span> and <span>\({\mathcal{U}}\)</span>, and the rows and columns of the third grid are associated to <span>\({\mathcal{V}}\)</span> and <span>\({\mathcal{W}}\)</span>. Each element of each grid is a feature vector, and its initial value is given by the elements of the input tensors along the grid’s missing mode. These feature vectors are enriched by concatenating an <i>S</i> × <i>S</i> × 1 linear projection from the scalars. This is followed by a linear layer projecting these feature vectors into a 512-dimensional space.</p><p>The rest of the torso is a sequence of attention-based blocks with the objective of propagating information between the three grids. Each of those blocks has three stages, one for every pair of grids. In each stage, the grids involved are concatenated, and axial attention<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Ho, J., Kalchbrenner, N., Weissenborn, D. &amp; Salimans, T. Axial attention in multidimensional transformers. Preprint at 
                  https://arxiv.org/abs/1912.12180
                  
                 (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR24" id="ref-link-section-d97101721e8034">24</a></sup> is performed over the columns. It is noted that in each stage we perform in parallel <i>S</i> self-attention operations of 2<i>S</i> elements in each. The representation sent to the policy head corresponds to the 3<i>S</i><sup>2 </sup>512-dimensional feature vectors produced by the last layer of the torso. A detailed description of the structure of the torso is specified in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig9">4</a> (top) and Appendix A.1.1 in Supplementary Information.</p><h4 id="Sec30">Policy head</h4><p>The policy head uses the transformer architecture<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Vaswani, A. Attention is all you need. In International Conference on Neural Information Processing Systems Vol 30, 5998–6008 (Curran Associates, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR23" id="ref-link-section-d97101721e8059">23</a></sup> to model an autoregressive policy. Factors are decomposed into <i>k</i> tokens of dimensionality <i>d</i> such that <i>k</i> × <i>d</i> = 3<i>S</i>. The transformer conditions on the tokens already generated and cross-attends to the features produced by the torso. At training time, we use teacher-forcing, that is, the ground truth actions are decomposed into tokens and taken as inputs into the causal transformer in such a way that the prediction of a token depends only on the previous tokens. At inference time, <i>K</i> actions are sampled from the head. The feature representation before the last linear layer of the initial step (that is, the only step that is not conditioned on the ground truth) is used as an input to the value head, described below. Details of the architecture are presented in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig9">4</a> (centre) and Appendix A.1.2 in Supplementary Information.</p><h4 id="Sec31">Value head</h4><p>The value head is composed of a four-layer multilayer perceptron whose last layer produces <i>q</i> outputs corresponding to the <span>\(\frac{1}{2q},\frac{3}{2q},\ldots \frac{2q-1}{2q}\)</span> quantiles. In this way, the value head predicts the distribution of returns from this state in the form of values predicted for the aforementioned quantiles<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Dabney, W., Rowland, M., Bellemare, M. &amp; Munos, R. Distributional reinforcement learning with quantile regression. In AAAI Conference on Artificial Intelligence Vol. 32, 2892–2901 (AAAI Press, 2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR34" id="ref-link-section-d97101721e8173">34</a></sup>. At inference time, we encourage the agent to be risk-seeking by using the average of the predicted values for quantiles over 75%. A detailed description of the value head is presented in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-022-05172-4#Fig9">4</a> (bottom) and Appendix A.1.3 in Supplementary Information.</p><h3 id="Sec32">Related work</h3><p>The quest for efficient matrix multiplication algorithms started with Strassen’s breakthrough in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Strassen, V. Gaussian elimination is not optimal. Numer. Math. 13, 354–356 (1969)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR2" id="ref-link-section-d97101721e8189">2</a></sup>, which showed that one can multiply 2 × 2 matrices using 7 scalar multiplications, leading to an algorithm of complexity <span>\({\mathcal{O}}({n}^{2.81})\)</span>. This led to the development of a very active field of mathematics attracting worldwide interest, which studies the asymptotic complexity of matrix multiplication (see refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bürgisser, P., Clausen, M. &amp; Shokrollahi, A. Algebraic Complexity Theory Vol. 315 (Springer Science &amp; Business Media, 2013)." href="#ref-CR3" id="ref-link-section-d97101721e8237">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bläser, M. Fast matrix multiplication. Theory Comput. 5, 1–60 (2013)." href="#ref-CR4" id="ref-link-section-d97101721e8237_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="#ref-CR5" id="ref-link-section-d97101721e8237_2">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Pan, V. Y. Fast feasible and unfeasible matrix multiplication. Preprint at 
                  https://arxiv.org/abs/1804.04102
                  
                 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR6" id="ref-link-section-d97101721e8240">6</a></sup>). So far, the best known complexity for matrix multiplication is <span>\({\mathcal{O}}({n}^{2.37286})\)</span> (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Alman, J. &amp; Williams, V. V. A refined laser method and faster matrix multiplication. In ACM-SIAM Symposium on Discrete Algorithms 522–539 (SIAM, 2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR12" id="ref-link-section-d97101721e8288">12</a></sup>), which improves over ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Le Gall, F. Powers of tensors and fast matrix multiplication. In International Symposium on Symbolic and Algebraic Computation 296–303 (ACM, 2014)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR11" id="ref-link-section-d97101721e8293">11</a></sup>, and builds on top of fundamental results in the field<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schönhage, A. Partial and total matrix multiplication. SIAM J. Comput. 10, 434–455 (1981)." href="#ref-CR8" id="ref-link-section-d97101721e8297">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Coppersmith, D. &amp; Winograd, S. Matrix multiplication via arithmetic progressions. In ACM Symposium on Theory of Computing 1–6 (ACM, 1987)." href="#ref-CR9" id="ref-link-section-d97101721e8297_1">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Strassen, V. The asymptotic spectrum of tensors and the exponent of matrix multiplication. In 27th Annual Symposium on Foundations of Computer Science 49–54 (IEEE, 1986)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR10" id="ref-link-section-d97101721e8300">10</a></sup>. However, this does not yield practical algorithms, as such approaches become advantageous only for astronomical matrix sizes. Hence, a significant body of work aims at exhibiting explicit factorizations of matrix multiplication tensors, as these factorizations provide practical algorithms. After Strassen’s breakthrough showing that <span>\(\text{rank}\,({{\mathscr{T}}}_{2})\le 7\)</span>, efficient algorithms for larger matrix sizes were found<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. Bull. Am. Math. Soc. 82, 126–128 (1976)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR15" id="ref-link-section-d97101721e8354">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hopcroft, J. E. &amp; Kerr, L. R. On minimizing the number of multiplications necessary for matrix multiplication. SIAM J. Appl. Math. 20, 30–36 (1971)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR16" id="ref-link-section-d97101721e8357">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Smirnov, A. V. The bilinear complexity and practical algorithms for matrix multiplication. Comput. Math. Math. Phys. 53, 1781–1795 (2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR18" id="ref-link-section-d97101721e8360">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Sedoglavic, A. A non-commutative algorithm for multiplying (7 × 7) matrices using 250 multiplications. Preprint at 
                  https://arxiv.org/abs/1712.07935
                  
                 (2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR26" id="ref-link-section-d97101721e8363">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Sedoglavic, A. A non-commutative algorithm for multiplying 5x5 matrices using 99 multiplications. Preprint at 
                  https://arxiv.org/abs/1707.06860
                  
                 (2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR38" id="ref-link-section-d97101721e8366">38</a></sup>. Most notably, Laderman showed in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. Bull. Am. Math. Soc. 82, 126–128 (1976)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR15" id="ref-link-section-d97101721e8370">15</a></sup> that 3 × 3 matrix multiplications can be performed with 23 scalar multiplications. In addition to providing individual low-rank factorizations, an important research direction aims at understanding the space of matrix multiplication algorithms—as opposed to exhibiting individual low-rank factorizations—by studying the symmetry groups and diversity of factorizations (see ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Landsberg, J. M. Geometry and Complexity Theory 169 (Cambridge Univ. Press, 2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR5" id="ref-link-section-d97101721e8374">5</a></sup> and references therein). For example, the symmetries of 2 × 2 matrix multiplication were studied in refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="de Groote, H. F. On varieties of optimal algorithms for the computation of bilinear mappings II. optimal algorithms for 2 × 2-matrix multiplication. Theor. Comput. Sci. 7, 127–148 (1978)." href="#ref-CR39" id="ref-link-section-d97101721e8379">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Burichenko, V. P. On symmetries of the Strassen algorithm. Preprint at 
                  https://arxiv.org/abs/1408.6273
                  
                 (2014)." href="#ref-CR40" id="ref-link-section-d97101721e8379_1">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chiantini, L., Ikenmeyer, C., Landsberg, J. M. &amp; Ottaviani, G. The geometry of rank decompositions of matrix multiplication I: 2 × 2 matrices. Exp. Math. 28, 322–327 (2019)." href="#ref-CR41" id="ref-link-section-d97101721e8379_2">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Grochow, J. A. &amp; Moore, C. Designing Strassen’s algorithm. Preprint at 
                  https://arxiv.org/abs/1708.09398
                  
                 (2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR42" id="ref-link-section-d97101721e8382">42</a></sup>, where Strassen’s algorithm was shown to be essentially unique. The case of 3 × 3 was studied in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Ballard, G., Ikenmeyer, C., Landsberg, J. M. &amp; Ryder, N. The geometry of rank decompositions of matrix multiplication II: 3 × 3 matrices. J. Pure Appl. Algebra 223, 3205–3224 (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR43" id="ref-link-section-d97101721e8386">43</a></sup>, whereas a symmetric factorization for all <i>n</i> is provided in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Grochow, J. A. &amp; Moore, C. Matrix multiplication algorithms from group orbits. Preprint at 
                  https://arxiv.org/abs/1612.01527
                  
                 (2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR44" id="ref-link-section-d97101721e8393">44</a></sup>.</p><p>On the computational front, continuous optimization has been the main workhorse for decomposing tensors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Vervliet, N., Debals, O., Sorber, L., Van Barel, M. &amp; De Lathauwer, L. Tensorlab 3.0 (2016); 
                  https://www.tensorlab.net/
                  
                " href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR17" id="ref-link-section-d97101721e8400">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Kolda, T. G. &amp; Bader, B. W. Tensor decompositions and applications. SIAM Rev. 51, 455–500 (2009)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR45" id="ref-link-section-d97101721e8403">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Bernardi, A., Brachat, J., Comon, P. &amp; Mourrain, B. General tensor decomposition, moment matrices and applications. J. Symb. Comput. 52, 51–71 (2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR46" id="ref-link-section-d97101721e8406">46</a></sup>, and in particular matrix multiplication tensors. Such continuous optimization procedures (for example, alternating least squares), however, yield approximate solutions, which correspond to inexact matrix multiplication algorithms with floating point operations. To circumvent this issue, regularization procedures have been proposed, such as ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Smirnov, A. V. The bilinear complexity and practical algorithms for matrix multiplication. Comput. Math. Math. Phys. 53, 1781–1795 (2013)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR18" id="ref-link-section-d97101721e8410">18</a></sup>, to extract exact decompositions. Unfortunately, such approaches often require  substantial human intervention and expertise to decompose large tensors. A different line of attack was explored in refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Elser, V. A network that learns Strassen multiplication. J. Mach. Learn. Res. 17, 3964–3976 (2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR47" id="ref-link-section-d97101721e8414">47</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Tschannen, M., Khanna, A. &amp; Anandkumar, A, StrassenNets: deep learning with a multiplication budget. In International Conference on Machine Learning 4985–4994 (PMLR, 2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR48" id="ref-link-section-d97101721e8417">48</a></sup>, based on learning the continuous weights of a two-layer network that mimics the structure of the matrix multiplication operation. This method, which is trained through supervised learning of matrix multiplication examples, finds approximate solutions to 2 × 2 and 3 × 3 matrix multiplications. In ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Tschannen, M., Khanna, A. &amp; Anandkumar, A, StrassenNets: deep learning with a multiplication budget. In International Conference on Machine Learning 4985–4994 (PMLR, 2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR48" id="ref-link-section-d97101721e8421">48</a></sup>, a quantization procedure is further used to obtain an exact decomposition for 2 × 2. Unlike continuous optimization-based approaches, AlphaTensor directly produces algorithms from the desired set of valid algorithms, and is flexible in that it allows us to optimize a wide range of (even non-differentiable) objectives. This unlocks tackling broader settings (for example, optimization in finite fields, optimization of runtime), as well as larger problems (for example, <span>\({{\mathscr{T}}}_{4}\)</span> and <span>\({{\mathscr{T}}}_{5}\)</span>) than those previously considered. Different from continuous optimization, a boolean satisfiability (SAT) based  formulation of the problem of decomposing 3 × 3 matrix multiplication was recently proposed in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Heule, M. J., Kauers, M. &amp; Seidl, M. New ways to multiply 3 × 3-matrices. J. Symb. Comput. 104, 899–916 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR20" id="ref-link-section-d97101721e8484">20</a></sup>, which adds thousands of new decompositions of rank 23 to the list of known 3 × 3 factorizations. The approach relies on a state-of-the-art SAT solving procedure, where several assumptions and simplifications are made on the factorizations to reduce the search space. As is, this approach is, however, unlikely to scale to larger tensors, as the search space grows very quickly with the size.</p><p>On the practical implementation front, ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Benson, A. R. &amp; Ballard, G. A framework for practical parallel fast matrix multiplication. ACM SIGPLAN Not. 50, 42–53 (2015)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR31" id="ref-link-section-d97101721e8491">31</a></sup> proposed several ideas to speed up implementation of fast matrix multiplication algorithms on central processing units (CPUs). Different fast algorithms are then compared and benchmarked, and the potential speed-up of such algorithms is shown against standard multiplication. Other works focused on getting the maximal performance out of a particular fast matrix multiplication algorithm (Strassen’s algorithm with one or two levels of recursion) on a CPU<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Huang, J., Smith, T. M., Henry, G. M. &amp; Van De Geijn, R. A. Strassen’s algorithm reloaded. In International Conference for High Performance Computing, Networking, Storage and Analysis 690–701 (IEEE, 2016)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR32" id="ref-link-section-d97101721e8495">32</a></sup> or a GPU<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Huang, J., Yu, C. D. &amp; Geijn, R. A. V. D. Strassen’s algorithm reloaded on GPUs. ACM Trans. Math. Softw. 46, 1–22 (2020)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR49" id="ref-link-section-d97101721e8499">49</a></sup>. These works show that, despite popular belief, such algorithms are of practical value. We see writing a custom low-level implementation of a given algorithm to be distinct from the focus of this paper—developing new efficient algorithms—and we believe that the algorithms we discovered can further benefit from a more efficient implementation by experts.</p><p>Beyond matrix multiplication and bilinear operations, a growing amount of research studies the use of optimization and machine learning to improve the efficiency of computational operations. There are three levels of abstractions at which this can be done: (1) in the hardware design, for example, chip floor planning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Mirhoseini, A. et al. A graph placement methodology for fast chip design. Nature 594, 207–212 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR50" id="ref-link-section-d97101721e8506">50</a></sup>, (2) at the hardware–software interface, for example, program super-optimization of a reference implementation for specific hardware<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Bunel, R., Desmaison, A., Kohli, P., Torr, P. H. &amp; Kumar, M. P. Learning to superoptimize programs. In International Conference on Learning Representations (ICLR) (2017)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR51" id="ref-link-section-d97101721e8510">51</a></sup>, and (3) on the algorithmic level, for example, program induction<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Li, Y., Gimeno, F., Kohli, P. &amp; Vinyals, O. Strong generalization and efficiency in neural programs. Preprint at 
                  https://arxiv.org/abs/2007.03629
                  
                 (2020)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR52" id="ref-link-section-d97101721e8514">52</a></sup>, algorithm selection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Lagoudakis, M. G. et al. Algorithm selection using reinforcement learning. In International Conference on Machine Learning 511–518 (Morgan Kaufmann Publishers, 2000)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR53" id="ref-link-section-d97101721e8518">53</a></sup> or meta-learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Schmidhuber, J. Evolutionary Principles in Self-Referential Learning. On Learning now to Learn: The Meta-Meta-Meta...-Hook. Diploma thesis, Technische Univ. Munchen (1987)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR54" id="ref-link-section-d97101721e8522">54</a></sup>. Our work focuses on the algorithmic level of abstraction, although AlphaTensor is also flexible to discover efficient algorithms for specific hardware. Different from previous works, we focus on discovering matrix multiplication algorithms that are provably correct, without requiring initial reference implementations. We conclude by relating our work broadly to existing reinforcement learning methods for scientific discovery. Within mathematics, reinforcement learning was applied, for example, to theorem proving<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kaliszyk, C., Urban, J., Michalewski, H. &amp; Olšák, M. Reinforcement learning of theorem proving. In International Conference on Neural Information Processing Systems 8836–8847 (Curran Associates, 2018)." href="#ref-CR55" id="ref-link-section-d97101721e8527">55</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Piotrowski, B. &amp; Urban, J. ATPboost: learning premise selection in binary setting with ATP feedback. In International Joint Conference on Automated Reasoning 566–574 (Springer, 2018)." href="#ref-CR56" id="ref-link-section-d97101721e8527_1">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bansal, K., Loos, S., Rabe, M., Szegedy, C. &amp; Wilcox, S. HOList: an environment for machine learning of higher order logic theorem proving. In International Conference on Machine Learning 454–463 (PMLR, 2019)." href="#ref-CR57" id="ref-link-section-d97101721e8527_2">57</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Zombori, Z., Urban, J. &amp; Brown, C. E. Prolog technology reinforcement learning prover. In International Joint Conference on Automated Reasoning 489–507 (Springer, 2020)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR58" id="ref-link-section-d97101721e8530">58</a></sup>, and to finding counterexamples refuting conjectures in combinatorics and graph theory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Wagner, A. Z. Constructions in combinatorics via neural networks. Preprint at 
                  https://arxiv.org/abs/2104.14516
                  
                 (2021)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR59" id="ref-link-section-d97101721e8534">59</a></sup>. Reinforcement learning was further shown to be useful in many areas in science, such as molecular design<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Popova, M., Isayev, O. &amp; Tropsha, A. Deep reinforcement learning for de novo drug design. Sci. Adv. 4, eaap7885 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR60" id="ref-link-section-d97101721e8538">60</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Zhou, Z., Kearnes, S., Li, L., Zare, R. N. &amp; Riley, P. Optimization of molecules via deep reinforcement learning. Sci. Rep. 9, 10752 (2019)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR61" id="ref-link-section-d97101721e8541">61</a></sup> and synthesis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Segler, M. H., Preuss, M. &amp; Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic AI. Nature 555, 604–610 (2018)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR62" id="ref-link-section-d97101721e8545">62</a></sup> and optimizing quantum dynamics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Dalgaard, M., Motzoi, F., Sørensen, J. J. &amp; Sherson, J. Global optimization of quantum dynamics with AlphaZero deep exploration. npj Quantum Inf. 6, 6 (2020)." href="https://www.nature.com/articles/s41586-022-05172-4#ref-CR63" id="ref-link-section-d97101721e8549">63</a></sup>.</p></div></div></section>
                </div><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. <i>Science</i> <b>362</b>, 1140–1144 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3888768" aria-label="MathSciNet reference 1">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXisVegu7rM" aria-label="CAS reference 1">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aar6404" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aar6404" aria-label="Article reference 1">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20general%20reinforcement%20learning%20algorithm%20that%20masters%20chess%2C%20shogi%2C%20and%20Go%20through%20self-play&amp;journal=Science&amp;doi=10.1126%2Fscience.aar6404&amp;volume=362&amp;pages=1140-1144&amp;publication_year=2018&amp;author=Silver%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="2."><p id="ref-CR2">Strassen, V. Gaussian elimination is not optimal. <i>Numer. Math.</i> <b>13</b>, 354–356 (1969).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=248973" aria-label="MathSciNet reference 2">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF02165411" data-track-action="article reference" href="https://doi.org/10.1007%2FBF02165411" aria-label="Article reference 2">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Gaussian%20elimination%20is%20not%20optimal&amp;journal=Numer.%20Math.&amp;doi=10.1007%2FBF02165411&amp;volume=13&amp;pages=354-356&amp;publication_year=1969&amp;author=Strassen%2CV">
                    Google Scholar</a> 
                </p></li><li data-counter="3."><p id="ref-CR3">Bürgisser, P., Clausen, M. &amp; Shokrollahi, A. <i>Algebraic Complexity Theory</i> Vol. 315 (Springer Science &amp; Business Media, 2013).</p></li><li data-counter="4."><p id="ref-CR4">Bläser, M. Fast matrix multiplication. <i>Theory Comput.</i> <b>5</b>, 1–60 (2013).</p></li><li data-counter="5."><p id="ref-CR5">Landsberg, J. M. <i>Geometry and Complexity Theory</i> 169 (Cambridge Univ. Press, 2017).</p></li><li data-counter="6."><p id="ref-CR6">Pan, V. Y. Fast feasible and unfeasible matrix multiplication. Preprint at <a href="https://arxiv.org/abs/1804.04102">https://arxiv.org/abs/1804.04102</a> (2018).</p></li><li data-counter="7."><p id="ref-CR7">Lim, L.-H. Tensors in computations. <i>Acta Numer.</i> <b>30</b>, 555–764 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=4298222" aria-label="MathSciNet reference 7">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S0962492921000076" data-track-action="article reference" href="https://doi.org/10.1017%2FS0962492921000076" aria-label="Article reference 7">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Tensors%20in%20computations&amp;journal=Acta%20Numer.&amp;doi=10.1017%2FS0962492921000076&amp;volume=30&amp;pages=555-764&amp;publication_year=2021&amp;author=Lim%2CL-H">
                    Google Scholar</a> 
                </p></li><li data-counter="8."><p id="ref-CR8">Schönhage, A. Partial and total matrix multiplication. <i>SIAM J. Comput.</i> <b>10</b>, 434–455 (1981).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=623057" aria-label="MathSciNet reference 8">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1137/0210032" data-track-action="article reference" href="https://doi.org/10.1137%2F0210032" aria-label="Article reference 8">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Partial%20and%20total%20matrix%20multiplication&amp;journal=SIAM%20J.%20Comput.&amp;doi=10.1137%2F0210032&amp;volume=10&amp;pages=434-455&amp;publication_year=1981&amp;author=Sch%C3%B6nhage%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="9."><p id="ref-CR9">Coppersmith, D. &amp; Winograd, S. Matrix multiplication via arithmetic progressions. In <i>ACM Symposium on Theory of Computing</i> 1–6 (ACM, 1987).</p></li><li data-counter="10."><p id="ref-CR10">Strassen, V. The asymptotic spectrum of tensors and the exponent of matrix multiplication. In <i>27th Annual Symposium on Foundations of Computer Science</i> 49–54 (IEEE, 1986).</p></li><li data-counter="11."><p id="ref-CR11">Le Gall, F. Powers of tensors and fast matrix multiplication. In <i>International Symposium on Symbolic and Algebraic Computation</i> 296–303 (ACM, 2014).</p></li><li data-counter="12."><p id="ref-CR12">Alman, J. &amp; Williams, V. V. A refined laser method and faster matrix multiplication. In <i>ACM-SIAM Symposium on Discrete Algorithms</i> 522–539 (SIAM, 2021).</p></li><li data-counter="13."><p id="ref-CR13">Gauss, C. F. <i>Theoria Motus Corporum Coelestium in Sectionibus Conicis Solum Ambientium</i> (Perthes and Besser, 1809).</p></li><li data-counter="14."><p id="ref-CR14">Hillar, C. J. &amp; Lim, L.-H. Most tensor problems are NP-hard. <i>J. ACM</i> <b>60</b>, 1–39 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3144915" aria-label="MathSciNet reference 14">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1145/2512329" data-track-action="article reference" href="https://doi.org/10.1145%2F2512329" aria-label="Article reference 14">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Most%20tensor%20problems%20are%20NP-hard&amp;journal=J.%20ACM&amp;doi=10.1145%2F2512329&amp;volume=60&amp;pages=1-39&amp;publication_year=2013&amp;author=Hillar%2CCJ&amp;author=Lim%2CL-H">
                    Google Scholar</a> 
                </p></li><li data-counter="15."><p id="ref-CR15">Laderman, J. D. A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. <i>Bull. Am. Math. Soc.</i> <b>82</b>, 126–128 (1976).</p></li><li data-counter="16."><p id="ref-CR16">Hopcroft, J. E. &amp; Kerr, L. R. On minimizing the number of multiplications necessary for matrix multiplication. <i>SIAM J. Appl. Math.</i> <b>20</b>, 30–36 (1971).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=274293" aria-label="MathSciNet reference 16">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1137/0120004" data-track-action="article reference" href="https://doi.org/10.1137%2F0120004" aria-label="Article reference 16">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20minimizing%20the%20number%20of%20multiplications%20necessary%20for%20matrix%20multiplication&amp;journal=SIAM%20J.%20Appl.%20Math.&amp;doi=10.1137%2F0120004&amp;volume=20&amp;pages=30-36&amp;publication_year=1971&amp;author=Hopcroft%2CJE&amp;author=Kerr%2CLR">
                    Google Scholar</a> 
                </p></li><li data-counter="17."><p id="ref-CR17">Vervliet, N., Debals, O., Sorber, L., Van Barel, M. &amp; De Lathauwer, L. <i>Tensorlab 3.0</i> (2016); <a href="https://www.tensorlab.net/">https://www.tensorlab.net/</a></p></li><li data-counter="18."><p id="ref-CR18">Smirnov, A. V. The bilinear complexity and practical algorithms for matrix multiplication. <i>Comput. Math. Math. Phys.</i> <b>53</b>, 1781–1795 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3146566" aria-label="MathSciNet reference 18">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1134/S0965542513120129" data-track-action="article reference" href="https://doi.org/10.1134%2FS0965542513120129" aria-label="Article reference 18">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20bilinear%20complexity%20and%20practical%20algorithms%20for%20matrix%20multiplication&amp;journal=Comput.%20Math.%20Math.%20Phys.&amp;doi=10.1134%2FS0965542513120129&amp;volume=53&amp;pages=1781-1795&amp;publication_year=2013&amp;author=Smirnov%2CAV">
                    Google Scholar</a> 
                </p></li><li data-counter="19."><p id="ref-CR19">Sedoglavic, A. &amp; Smirnov, A. V. The tensor rank of 5x5 matrices multiplication is bounded by 98 and its border rank by 89. In <i>Proc. 2021 on International Symposium on Symbolic and Algebraic Computation</i> 345–351 (ACM, 2021).</p></li><li data-counter="20."><p id="ref-CR20">Heule, M. J., Kauers, M. &amp; Seidl, M. New ways to multiply 3 × 3-matrices. <i>J. Symb. Comput.</i> <b>104</b>, 899–916 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=4180152" aria-label="MathSciNet reference 20">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jsc.2020.10.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jsc.2020.10.003" aria-label="Article reference 20">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20ways%20to%20multiply%203%E2%80%89%C3%97%E2%80%893-matrices&amp;journal=J.%20Symb.%20Comput.&amp;doi=10.1016%2Fj.jsc.2020.10.003&amp;volume=104&amp;pages=899-916&amp;publication_year=2021&amp;author=Heule%2CMJ&amp;author=Kauers%2CM&amp;author=Seidl%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="21."><p id="ref-CR21">Hubert, T. et al. Learning and planning in complex action spaces. In <i>International Conference on Machine Learning</i> 4476–4486 (PMLR, 2021).</p></li><li data-counter="22."><p id="ref-CR22">Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling. In <i>International Joint Conferences on Artificial Intelligence</i> Vol. 95, 1114–1120 (Morgan Kaufmann Publishers, 1995).</p></li><li data-counter="23."><p id="ref-CR23">Vaswani, A. Attention is all you need. In <i>International Conference on Neural Information Processing Systems</i> Vol 30, 5998–6008 (Curran Associates, 2017).</p></li><li data-counter="24."><p id="ref-CR24">Ho, J., Kalchbrenner, N., Weissenborn, D. &amp; Salimans, T. Axial attention in multidimensional transformers. Preprint at <a href="https://arxiv.org/abs/1912.12180">https://arxiv.org/abs/1912.12180</a> (2019).</p></li><li data-counter="25."><p id="ref-CR25">Drevet, C.-É., Islam, M. N. &amp; Schost, É. Optimization techniques for small matrix multiplication. <i>Theor. Comput. Sci.</i> <b>412</b>, 2219–2236 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2815855" aria-label="MathSciNet reference 25">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tcs.2010.12.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tcs.2010.12.012" aria-label="Article reference 25">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20techniques%20for%20small%20matrix%20multiplication&amp;journal=Theor.%20Comput.%20Sci.&amp;doi=10.1016%2Fj.tcs.2010.12.012&amp;volume=412&amp;pages=2219-2236&amp;publication_year=2011&amp;author=Drevet%2CC-%C3%89&amp;author=Islam%2CMN&amp;author=Schost%2C%C3%89">
                    Google Scholar</a> 
                </p></li><li data-counter="26."><p id="ref-CR26">Sedoglavic, A. A non-commutative algorithm for multiplying (7 × 7) matrices using 250 multiplications. Preprint at <a href="https://arxiv.org/abs/1712.07935">https://arxiv.org/abs/1712.07935</a> (2017).</p></li><li data-counter="27."><p id="ref-CR27">Battaglia, P. W. et al. Relational inductive biases, deep learning, and graph networks. Preprint at <a href="https://arxiv.org/abs/1806.01261">https://arxiv.org/abs/1806.01261</a> (2018).</p></li><li data-counter="28."><p id="ref-CR28">Balog, M., van Merriënboer, B., Moitra, S., Li, Y. &amp; Tarlow, D. Fast training of sparse graph neural networks on dense hardware. Preprint at <a href="https://arxiv.org/abs/1906.11786">https://arxiv.org/abs/1906.11786</a> (2019).</p></li><li data-counter="29."><p id="ref-CR29">Ye, K. &amp; Lim, L.-H. Fast structured matrix computations: tensor rank and Cohn–Umans method. <i>Found. Comput. Math.</i> <b>18</b>, 45–95 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3749414" aria-label="MathSciNet reference 29">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s10208-016-9332-x" data-track-action="article reference" href="https://doi.org/10.1007%2Fs10208-016-9332-x" aria-label="Article reference 29">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Fast%20structured%20matrix%20computations%3A%20tensor%20rank%20and%20Cohn%E2%80%93Umans%20method&amp;journal=Found.%20Comput.%20Math.&amp;doi=10.1007%2Fs10208-016-9332-x&amp;volume=18&amp;pages=45-95&amp;publication_year=2018&amp;author=Ye%2CK&amp;author=Lim%2CL-H">
                    Google Scholar</a> 
                </p></li><li data-counter="30."><p id="ref-CR30">Bradbury, J. et al. JAX: composable transformations of Python+NumPy programs. <i>GitHub</i> <a href="http://github.com/google/jax">http://github.com/google/jax</a> (2018).</p></li><li data-counter="31."><p id="ref-CR31">Benson, A. R. &amp; Ballard, G. A framework for practical parallel fast matrix multiplication. <i>ACM SIGPLAN Not.</i> <b>50</b>, 42–53 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1145/2858788.2688513" data-track-action="article reference" href="https://doi.org/10.1145%2F2858788.2688513" aria-label="Article reference 31">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20framework%20for%20practical%20parallel%20fast%20matrix%20multiplication&amp;journal=ACM%20SIGPLAN%20Not.&amp;doi=10.1145%2F2858788.2688513&amp;volume=50&amp;pages=42-53&amp;publication_year=2015&amp;author=Benson%2CAR&amp;author=Ballard%2CG">
                    Google Scholar</a> 
                </p></li><li data-counter="32."><p id="ref-CR32">Huang, J., Smith, T. M., Henry, G. M. &amp; Van De Geijn, R. A. Strassen’s algorithm reloaded. In <i>International Conference for High Performance Computing, Networking, Storage and Analysis</i> 690–701 (IEEE, 2016).</p></li><li data-counter="33."><p id="ref-CR33">Abadi, M. et al. Tensorflow: a system for large-scale machine learning. In <i>USENIX Symposium On Operating Systems Design And Implementation</i> 265–283 (USENIX, 2016).</p></li><li data-counter="34."><p id="ref-CR34">Dabney, W., Rowland, M., Bellemare, M. &amp; Munos, R. Distributional reinforcement learning with quantile regression. In <i>AAAI Conference on Artificial Intelligence</i> Vol. 32, 2892–2901 (AAAI Press, 2018).</p></li><li data-counter="35."><p id="ref-CR35">Kingma, D. P., &amp; Ba, J. Adam: a method for stochastic optimization. In <i>International Conference on Learning Representations (ICLR)</i> (2015).</p></li><li data-counter="36."><p id="ref-CR36">Loshchilov, I. &amp; Hutter, F. Decoupled weight decay regularization. In <i>International Conference on Learning Representations (ICLR)</i> (2019).</p></li><li data-counter="37."><p id="ref-CR37">Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. <i>Nature</i> <b>529</b>, 484–489 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12is7w%3D" aria-label="CAS reference 37">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature16961" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature16961" aria-label="Article reference 37">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Mastering%20the%20game%20of%20Go%20with%20deep%20neural%20networks%20and%20tree%20search&amp;journal=Nature&amp;doi=10.1038%2Fnature16961&amp;volume=529&amp;pages=484-489&amp;publication_year=2016&amp;author=Silver%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="38."><p id="ref-CR38">Sedoglavic, A. A non-commutative algorithm for multiplying 5x5 matrices using 99 multiplications. Preprint at <a href="https://arxiv.org/abs/1707.06860">https://arxiv.org/abs/1707.06860</a> (2017).</p></li><li data-counter="39."><p id="ref-CR39">de Groote, H. F. On varieties of optimal algorithms for the computation of bilinear mappings II. optimal algorithms for 2 × 2-matrix multiplication. <i>Theor. Comput. Sci.</i> <b>7</b>, 127–148 (1978).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=509013" aria-label="MathSciNet reference 39">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0304-3975(78)90045-2" data-track-action="article reference" href="https://doi.org/10.1016%2F0304-3975%2878%2990045-2" aria-label="Article reference 39">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20varieties%20of%20optimal%20algorithms%20for%20the%20computation%20of%20bilinear%20mappings%20II.%20optimal%20algorithms%20for%202%E2%80%89%C3%97%E2%80%892-matrix%20multiplication&amp;journal=Theor.%20Comput.%20Sci.&amp;doi=10.1016%2F0304-3975%2878%2990045-2&amp;volume=7&amp;pages=127-148&amp;publication_year=1978&amp;author=Groote%2CHF">
                    Google Scholar</a> 
                </p></li><li data-counter="40."><p id="ref-CR40">Burichenko, V. P. On symmetries of the Strassen algorithm. Preprint at <a href="https://arxiv.org/abs/1408.6273">https://arxiv.org/abs/1408.6273</a> (2014).</p></li><li data-counter="41."><p id="ref-CR41">Chiantini, L., Ikenmeyer, C., Landsberg, J. M. &amp; Ottaviani, G. The geometry of rank decompositions of matrix multiplication I: 2 × 2 matrices. <i>Exp. Math.</i> <b>28</b>, 322–327 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3985837" aria-label="MathSciNet reference 41">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1080/10586458.2017.1403981" data-track-action="article reference" href="https://doi.org/10.1080%2F10586458.2017.1403981" aria-label="Article reference 41">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20geometry%20of%20rank%20decompositions%20of%20matrix%20multiplication%20I%3A%202%E2%80%89%C3%97%E2%80%892%20matrices&amp;journal=Exp.%20Math.&amp;doi=10.1080%2F10586458.2017.1403981&amp;volume=28&amp;pages=322-327&amp;publication_year=2019&amp;author=Chiantini%2CL&amp;author=Ikenmeyer%2CC&amp;author=Landsberg%2CJM&amp;author=Ottaviani%2CG">
                    Google Scholar</a> 
                </p></li><li data-counter="42."><p id="ref-CR42">Grochow, J. A. &amp; Moore, C. Designing Strassen’s algorithm. Preprint at <a href="https://arxiv.org/abs/1708.09398">https://arxiv.org/abs/1708.09398</a> (2017).</p></li><li data-counter="43."><p id="ref-CR43">Ballard, G., Ikenmeyer, C., Landsberg, J. M. &amp; Ryder, N. The geometry of rank decompositions of matrix multiplication II: 3 × 3 matrices. <i>J. Pure Appl. Algebra</i> <b>223</b>, 3205–3224 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3926208" aria-label="MathSciNet reference 43">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jpaa.2018.10.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jpaa.2018.10.014" aria-label="Article reference 43">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20geometry%20of%20rank%20decompositions%20of%20matrix%20multiplication%20II%3A%203%E2%80%89%C3%97%E2%80%893%20matrices&amp;journal=J.%20Pure%20Appl.%20Algebra&amp;doi=10.1016%2Fj.jpaa.2018.10.014&amp;volume=223&amp;pages=3205-3224&amp;publication_year=2019&amp;author=Ballard%2CG&amp;author=Ikenmeyer%2CC&amp;author=Landsberg%2CJM&amp;author=Ryder%2CN">
                    Google Scholar</a> 
                </p></li><li data-counter="44."><p id="ref-CR44">Grochow, J. A. &amp; Moore, C. Matrix multiplication algorithms from group orbits. Preprint at <a href="https://arxiv.org/abs/1612.01527">https://arxiv.org/abs/1612.01527</a> (2016).</p></li><li data-counter="45."><p id="ref-CR45">Kolda, T. G. &amp; Bader, B. W. Tensor decompositions and applications. <i>SIAM Rev.</i> <b>51</b>, 455–500 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2535056" aria-label="MathSciNet reference 45">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1137/07070111X" data-track-action="article reference" href="https://doi.org/10.1137%2F07070111X" aria-label="Article reference 45">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Tensor%20decompositions%20and%20applications&amp;journal=SIAM%20Rev.&amp;doi=10.1137%2F07070111X&amp;volume=51&amp;pages=455-500&amp;publication_year=2009&amp;author=Kolda%2CTG&amp;author=Bader%2CBW">
                    Google Scholar</a> 
                </p></li><li data-counter="46."><p id="ref-CR46">Bernardi, A., Brachat, J., Comon, P. &amp; Mourrain, B. General tensor decomposition, moment matrices and applications. <i>J. Symb. Comput.</i> <b>52</b>, 51–71 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3018128" aria-label="MathSciNet reference 46">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jsc.2012.05.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jsc.2012.05.012" aria-label="Article reference 46">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20tensor%20decomposition%2C%20moment%20matrices%20and%20applications&amp;journal=J.%20Symb.%20Comput.&amp;doi=10.1016%2Fj.jsc.2012.05.012&amp;volume=52&amp;pages=51-71&amp;publication_year=2013&amp;author=Bernardi%2CA&amp;author=Brachat%2CJ&amp;author=Comon%2CP&amp;author=Mourrain%2CB">
                    Google Scholar</a> 
                </p></li><li data-counter="47."><p id="ref-CR47">Elser, V. A network that learns Strassen multiplication. <i>J. Mach. Learn. Res.</i> <b>17</b>, 3964–3976 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=3543522" aria-label="MathSciNet reference 47">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="math reference" href="http://www.emis.de/MATH-item?1367.68222" aria-label="MATH reference 47">MATH</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20network%20that%20learns%20Strassen%20multiplication&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=17&amp;pages=3964-3976&amp;publication_year=2016&amp;author=Elser%2CV">
                    Google Scholar</a> 
                </p></li><li data-counter="48."><p id="ref-CR48">Tschannen, M., Khanna, A. &amp; Anandkumar, A, StrassenNets: deep learning with a multiplication budget. In <i>International Conference on Machine Learning</i> 4985–4994 (PMLR, 2018).</p></li><li data-counter="49."><p id="ref-CR49">Huang, J., Yu, C. D. &amp; Geijn, R. A. V. D. Strassen’s algorithm reloaded on GPUs. <i>ACM Trans. Math. Softw.</i> <b>46</b>, 1–22 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=4095187" aria-label="MathSciNet reference 49">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1145/3372419" data-track-action="article reference" href="https://doi.org/10.1145%2F3372419" aria-label="Article reference 49">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Strassen%E2%80%99s%20algorithm%20reloaded%20on%20GPUs&amp;journal=ACM%20Trans.%20Math.%20Softw.&amp;doi=10.1145%2F3372419&amp;volume=46&amp;pages=1-22&amp;publication_year=2020&amp;author=Huang%2CJ&amp;author=Yu%2CCD&amp;author=Geijn%2CRAVD">
                    Google Scholar</a> 
                </p></li><li data-counter="50."><p id="ref-CR50">Mirhoseini, A. et al. A graph placement methodology for fast chip design. <i>Nature</i> <b>594</b>, 207–212 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXht1yhsbzE" aria-label="CAS reference 50">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-021-03544-w" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-021-03544-w" aria-label="Article reference 50">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20graph%20placement%20methodology%20for%20fast%20chip%20design&amp;journal=Nature&amp;doi=10.1038%2Fs41586-021-03544-w&amp;volume=594&amp;pages=207-212&amp;publication_year=2021&amp;author=Mirhoseini%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="51."><p id="ref-CR51">Bunel, R., Desmaison, A., Kohli, P., Torr, P. H. &amp; Kumar, M. P. Learning to superoptimize programs. In <i>International Conference on Learning Representations (ICLR)</i> (2017).</p></li><li data-counter="52."><p id="ref-CR52">Li, Y., Gimeno, F., Kohli, P. &amp; Vinyals, O. Strong generalization and efficiency in neural programs. Preprint at <a href="https://arxiv.org/abs/2007.03629">https://arxiv.org/abs/2007.03629</a> (2020).</p></li><li data-counter="53."><p id="ref-CR53">Lagoudakis, M. G. et al. Algorithm selection using reinforcement learning. In <i>International Conference on Machine Learning</i> 511–518 (Morgan Kaufmann Publishers, 2000).</p></li><li data-counter="54."><p id="ref-CR54">Schmidhuber, J. <i>Evolutionary Principles in Self-Referential Learning. On Learning now to Learn: The Meta-Meta-Meta...-Hook</i>. Diploma thesis, Technische Univ. Munchen (1987).</p></li><li data-counter="55."><p id="ref-CR55">Kaliszyk, C., Urban, J., Michalewski, H. &amp; Olšák, M. Reinforcement learning of theorem proving. In <i>International Conference on Neural Information Processing Systems</i> 8836–8847 (Curran Associates, 2018).</p></li><li data-counter="56."><p id="ref-CR56">Piotrowski, B. &amp; Urban, J. ATPboost: learning premise selection in binary setting with ATP feedback. In <i>International Joint Conference on Automated Reasoning</i> 566–574 (Springer, 2018).</p></li><li data-counter="57."><p id="ref-CR57">Bansal, K., Loos, S., Rabe, M., Szegedy, C. &amp; Wilcox, S. HOList: an environment for machine learning of higher order logic theorem proving. In <i>International Conference on Machine Learning</i> 454–463 (PMLR, 2019).</p></li><li data-counter="58."><p id="ref-CR58">Zombori, Z., Urban, J. &amp; Brown, C. E. Prolog technology reinforcement learning prover. In <i>International Joint Conference on Automated Reasoning</i> 489–507 (Springer, 2020).</p></li><li data-counter="59."><p id="ref-CR59">Wagner, A. Z. Constructions in combinatorics via neural networks. Preprint at <a href="https://arxiv.org/abs/2104.14516">https://arxiv.org/abs/2104.14516</a> (2021).</p></li><li data-counter="60."><p id="ref-CR60">Popova, M., Isayev, O. &amp; Tropsha, A. Deep reinforcement learning for de novo drug design. <i>Sci.</i> <i>Adv.</i> <b>4</b>, eaap7885 (2018).</p></li><li data-counter="61."><p id="ref-CR61">Zhou, Z., Kearnes, S., Li, L., Zare, R. N. &amp; Riley, P. Optimization of molecules via deep reinforcement learning. <i>Sci. Rep.</i> <b>9</b>, 10752 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41598-019-47148-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-019-47148-x" aria-label="Article reference 61">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20of%20molecules%20via%20deep%20reinforcement%20learning&amp;journal=Sci.%20Rep.&amp;doi=10.1038%2Fs41598-019-47148-x&amp;volume=9&amp;publication_year=2019&amp;author=Zhou%2CZ&amp;author=Kearnes%2CS&amp;author=Li%2CL&amp;author=Zare%2CRN&amp;author=Riley%2CP">
                    Google Scholar</a> 
                </p></li><li data-counter="62."><p id="ref-CR62">Segler, M. H., Preuss, M. &amp; Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic AI. <i>Nature</i> <b>555</b>, 604–610 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXmsVGqt7c%3D" aria-label="CAS reference 62">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature25978" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature25978" aria-label="Article reference 62">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Planning%20chemical%20syntheses%20with%20deep%20neural%20networks%20and%20symbolic%20AI&amp;journal=Nature&amp;doi=10.1038%2Fnature25978&amp;volume=555&amp;pages=604-610&amp;publication_year=2018&amp;author=Segler%2CMH&amp;author=Preuss%2CM&amp;author=Waller%2CMP">
                    Google Scholar</a> 
                </p></li><li data-counter="63."><p id="ref-CR63">Dalgaard, M., Motzoi, F., Sørensen, J. J. &amp; Sherson, J. Global optimization of quantum dynamics with AlphaZero deep exploration. <i>npj Quantum Inf.</i> <b>6</b>, 6 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41534-019-0241-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41534-019-0241-0" aria-label="Article reference 63">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20optimization%20of%20quantum%20dynamics%20with%20AlphaZero%20deep%20exploration&amp;journal=npj%20Quantum%20Inf.&amp;doi=10.1038%2Fs41534-019-0241-0&amp;volume=6&amp;publication_year=2020&amp;author=Dalgaard%2CM&amp;author=Motzoi%2CF&amp;author=S%C3%B8rensen%2CJJ&amp;author=Sherson%2CJ">
                    Google Scholar</a> 
                </p></li><li data-counter="64."><p id="ref-CR64">Fast matrix multiplication algorithms catalogue. <i>Université de Lille</i> <a href="https://fmm.univ-lille.fr/">https://fmm.univ-lille.fr/</a> (2021).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed.springer.com/v2/references/10.1038/s41586-022-05172-4?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div></div>
  </body>
</html>
