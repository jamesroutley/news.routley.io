<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://hengyiwang.github.io/projects/spanner">Original</a>
    <h1>3D Reconstruction with Spatial Memory</h1>
    
    <div id="readability-page-1" class="page"><div>
          
          <p>
            We present Spann3R, a novel approach for dense 3D reconstruction from ordered or unordered image collections. 
          </p>
          <p>
            Built on the DUSt3R paradigm, Spann3R uses a transformer-based architecture to directly regress pointmaps 
            from images without any prior knowledge of the scene or camera parameters. Unlike DUSt3R, which predicts per 
            image-pair pointmaps each expressed in its local coordinate frame, Spann3R can predict per-image pointmaps expressed 
            in a global coordinate system, thus eliminating the need for optimization-based global alignment.
          </p>
          <p>
            The key idea of Spann3R is to manage an external spatial memory that learns to keep track of all previous relevant 3D 
            information. Spann3R then queries this spatial memory to predict the 3D structure of the next frame in a global 
            coordinate system. Taking advantage of DUSt3R&#39;s pre-trained weights, and further fine-tuning on a subset of datasets, Spann3R shows 
            competitive performance and generalization ability on various unseen datasets and is able to process ordered image 
            collections in real-time.
          </p>
        <br/>

        </div></div>
  </body>
</html>
