<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://the.scapegoat.dev/thoughts-about-the-ethics-of-large-language-models/">Original</a>
    <h1>Thoughts about the ethics of Large Language Models</h1>
    
    <div id="readability-page-1" class="page"><div>
<div><p><img alt="drawing by me after numerous explorations using midjourney into retro mainframe zombie, computer flower head, ink drawing brushwork, junji ito, moebius, horror manga, cyborg flower cyclops" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/manuel-1678023977-0.jpeg"/></p>
<p>Two weeks after ChatGPT came out and I had my &#34;lol this is fun&#34; time, I decided to use it as fully and honestly as I could for the entire week, as a tool like any other. Tools are often unintuitive; a good tool often requires you to practice a lot before its quality comes to shine—many tools can seriously hurt you if you don&#39;t know how to use them. It definitely feels the same with ChatGPT. 3 months later and I still think I am only scratching at the surface at what concretely large language models offer for my field of work: programming.</p>

<p>I love tools, I have used and built many in my life—in fact, I think my &#34;goal&#34; in life is to build tools for other people. There is nothing more fulfilling than seeing someone use something I built to build something that absolutely floors me. There is nothing more fulfilling than seeing someone thoroughly enjoy and cherish a tool I built because it makes them feel like they are doing better work.</p>
<p>While I didn&#39;t think of formulating my personal ethics before picking up writing (I do now because I discovered that writing is itself a tool to sharpen ideas), I think I had a clear direction for most of my life. Save for one freelance job, I always rejected working for companies that weren&#39;t building tools for users (vs say, tools for companies, or just plain nonsense, like ad-tech). Discovering Ivan Illich and his &#34;Tools for Conviviality&#34; last year allowed me to realize that these are concepts that you can articulate and communicate.</p>
<p>While I haven&#39;t even made it halfway through Illich&#39;s book, the first couple of chapters nail what my ethics are: tools and machines should be built and used to empower humans to live richer, more creative, more free lives. Tools should be built to augment human craft, not replace it.</p>
<h2 id="my-standpoint-on-large-language-models">My standpoint on large language models</h2>
<p>I think that large language models (I will never be able to say &#34;AI&#34; because it is such a ridiculous, misleading, polarizing, disingenuous term) have an incredible potential for augmenting human craft. I genuinely didn&#39;t think this way of transforming natural language would appear during my lifetime. These models are a paradigm shift in how I work and write software (both professionally and in open-source). I am building tools that more than anything I&#39;ve built so far, would allow me to share the joy and importance of knowledge and intellectual work, and allow others to do the same. I will write more about why I think that and how I use them to that effect (here&#39;s two examples in the meantime: <a href="https://share.descript.com/view/w2gXSYanYMp">Refactoring with ChatGPT</a> and <a href="https://share.descript.com/view/YGc8nnsL52G">Documenting a shell script with Copilot</a> )</p>
<p>It also means that I find how these tools are released (especially ChatGPT and Bing Chat) and the overall discourse of &#34;replacing customer support&#34;, &#34;a search engine that answers your questions&#34;, &#34;replacing artists&#34; absolutely abhorrent. These things don&#39;t make art, they don&#39;t answer questions, and they absolutely don&#39;t replace humans providing meaningful customer support. They can certainly help people do these things, but by themselves, they will just fool people into thinking there was meaning where there is none, and allow grifters to pretend the same. There is a complete 180 between a human using a large language model powered tool to provide better support because they now have more agency, and something taking agency from a human (to the point of replacing them entirely) and packaging it into a sterile chatbot.</p>
<p>As subtle as the difference between these two use cases might seem, to me, they are two entirely incompatible sides of the same medal. One side is building tools to empower humans, the other is building tools to disenfranchise humans, both workers and consumers. That subtlety makes talking about it hard, especially in my heavily &#34;anti-capitalist&#34; circles. The assumption is that LLMs are only there to replace workers and enrich techno robber barons, so any mention of a productive use of LLMs immediately leads to angry callouts and mob dogpiling (I am putting anti-capitalist in quotes because I certainly don&#39;t appreciate being called a tech-bro by someone who is a principal engineer at Microsoft, of all companies. Yeah, that stuck...).</p>
<h2 id="what-i-am-doing-about-it">What I am doing about it</h2>
<p>As an individual, as a tool-builder, as a techno-optimist, I think the biggest impact I can make in order to make the world a slightly better place is to share how I use these tools to enrich my life, my work, creatively and intellectually, because it is not something written about much, and it is not an easy tool to steer.</p>
<p>I also am building opensource tooling <em>and</em> making it not just nice enough to use, but come packaged with a strong ethical stance, so that you can&#39;t just take it and then build a chatbot with it without coming into contact with some material that will hopefully make you think twice about what you are doing. What that looks like is still a bit unclear to me, but it&#39;s proper dada (see <a href="https://github.com/go-go-golems">GO GO GOLEMS</a> ).</p>
<p>It also means that I will consistently call out bullshit in the AI-pilled circles I hang out in (because part of being serious about a field that is overhyped is that you come in contact with a lot of BS and grift and exploitation). People are enthusiastic about these technologies for a lot of reasons, and their worldview is heavily shaped by the framing of the companies behind these models—most of them are already victims of the future the companies building these tools wish to unleash upon us, so it is often easy to start an earnest conversation. It is infinitely more productive than telling people that they are gullible fools, or harbor evil intentions.</p>
<p>If I can change the minds of 20 people in an AI-hype discord by dropping a few spicy links, then I&#39;ll definitely hang out on AI-hype discords. Conversely, if I can show people that think LLMs are just random words strung together that these tools can help grassroots organizations build more accessible documentation, websites, more secure software; that they can free you from sacrificing your cognitive potential on the altar of capitalist bullshit work, then that&#39;s where you will find me too.</p>
<p>(This article was written entirely without LLMs because I just want to get it out. Otherwise, I would have spent quite a bit more time revising and editing it with wordtune and chatGPT, because I think they do make my writing better. The drawing is an ink sketch by me after numerous explorations using midjourney into retro mainframe zombie, computer flower head, ink drawing brushwork, junji ito, moebius, horror manga, cyborg flower cyclops)</p>
</div>
</div></div>
  </body>
</html>
