<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=43964505">Original</a>
    <h1>Launch HN: ParaQuery (YC X25) – GPU Accelerated Spark/SQL</h1>
    
    <div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>Hey HN! I&#39;m Win, founder of ParaQuery (<a href="https://paraquery.com">https://paraquery.com</a>), a fully-managed, GPU-accelerated Spark + SQL solution. We deliver BigQuery&#39;s ease of use (or easier) while being significantly more cost-efficient and performant.</p><p>Here&#39;s a short demo video demonstrating ParaQuery (vs. BigQuery) on a simple ETL job: <a href="https://www.youtube.com/watch?v=uu379YnccGU" rel="nofollow">https://www.youtube.com/watch?v=uu379YnccGU</a></p><p>It&#39;s well known that GPUs are very good for many SQL and dataframe tasks, at least by researchers and GPU companies like NVIDIA. So much so that, in 2018, NVIDIA launched the RAPIDS program and the Spark-RAPIDS plugin (<a href="https://github.com/NVIDIA/spark-rapids">https://github.com/NVIDIA/spark-rapids</a>). I actually found out because, at the time, I was trying to craft a CUDA-based lambda calculus interpreter…one of several ideas I didn&#39;t manage to implement, haha.</p><p>There seems to be a perception among at least some engineers that GPUs are only good for AI, graphics, and maybe image processing (maybe! someone actually told me they thought GPUs are bad for image processing!) Traditional data processing doesn’t come to mind. But actually GPUs are good for this as well!</p><p>At a high level, big data processing is a high-throughput, massively parallel workload. GPUs are a type of hardware specialized for this, are highly programmable, and (now) happen to be highly available on the cloud! Even better, GPU <i>memory</i> is tuned for bandwidth over raw latency, which only improves their throughput capabilities compared to a CPU. And by just playing with cloud cost calculators for a couple of minutes, it&#39;s clear that GPUs are cost-effective even on the major clouds.</p><p>To be honest, I thought using GPUs for SQL processing would have taken off by now, but it hasn&#39;t. So, just over a year ago, I started working on actually deploying a cloud-based data platform powered by GPUs (i.e. Spark-RAPIDS), spurred by a friend-of-a-friend(-of-a-friend) who happened to have BigQuery cost concerns at his startup. After getting a proof of concept done and a letter of intent... well, nothing happened! Even after over half a year. But then, something magical did happen: their cloud credits ran out!</p><p>And now, they&#39;re saving over 60% off of their BigQuery bill by using ParaQuery, while also being 2x faster -- with zero data migration needed (courtesy of Spark&#39;s GCS connector). By the way, I&#39;m not sure about other people&#39;s experiences but... we&#39;re pretty far from being IO-bound (to the surprise of many engineers I&#39;ve spoken to).</p><p>I think that the future of high-throughput compute is computing on high-throughput hardware. If you think so too, or you have scaling data challenges, you can sign up here: <a href="https://paraquery.com/waitlist">https://paraquery.com/waitlist</a>. Sorry for the waitlist, but we&#39;re not ready for a self-serve experience just yet—it would front-load significant engineering and hardware cost. But we’ll get there, so stay tuned!</p><p>Thanks for reading! What have your experiences been with huge ETL / processing loads? Was cost or performance an issue? And what do you think about GPU acceleration (GPGPU)? Did you think GPUs were simply expensive? Would love to just talk about tech here!</p></div></td></div></div>
  </body>
</html>
