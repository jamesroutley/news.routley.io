<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://xuanwo.io/2023/04-rust-std-fs-slower-than-python/">Original</a>
    <h1>Rust std fs slower than Python</h1>
    
    <div id="readability-page-1" class="page"><div><p>I&#39;m about to share a lengthy tale that begins with <a href="https://github.com/apache/incubator-opendal">opendal</a> <code>op.read()</code> and concludes with an unexpected twist. This journey was quite enlightening for me, and I hope it will be for you too. I&#39;ll do my best to recreate the experience, complete with the lessons I&#39;ve learned along the way. Let&#39;s dive in!</p><blockquote><p>All the code snippets and scripts are available in <a href="https://github.com/Xuanwo/when-i-find-rust-is-slow">Xuanwo/when-i-find-rust-is-slow</a></p></blockquote><h2 id="tldr">TL;DR</h2><p>Jump to <a href="#conclusion">Conclusion</a> if you want to know the answer ASAP.</p><h2 id="opendal-python-binding-is-slower-than-python">OpenDAL Python Binding is slower than Python?</h2><p><a href="https://github.com/apache/incubator-opendal">OpenDAL</a> is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. We provided python binding for OpenDAL via <a href="https://github.com/PyO3/pyo3">pyo3</a>.</p><p>One day, @beldathas reports a case to me at <a href="https://discord.com/channels/1081052318650339399/1174840499576770560">discord</a> that OpenDAL&#39;s python binding is slower than python:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> <span>pathlib</span>
</span></span><span><span><span>import</span> <span>timeit</span>
</span></span><span><span>
</span></span><span><span><span>import</span> <span>opendal</span>
</span></span><span><span>
</span></span><span><span>root <span>=</span> pathlib<span>.</span>Path(__file__)<span>.</span>parent
</span></span><span><span>op <span>=</span> opendal<span>.</span>Operator(<span>&#34;fs&#34;</span>, root<span>=</span><span>str</span>(root))
</span></span><span><span>filename <span>=</span> <span>&#34;lorem_ipsum_150mb.txt&#34;</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>read_file_with_opendal</span>() <span>-&gt;</span> <span>bytes</span>:
</span></span><span><span>    <span>with</span> op<span>.</span>open(filename, <span>&#34;rb&#34;</span>) <span>as</span> fp:
</span></span><span><span>        result <span>=</span> fp<span>.</span>read()
</span></span><span><span>    <span>return</span> result
</span></span><span><span>
</span></span><span><span><span>def</span> <span>read_file_with_normal</span>() <span>-&gt;</span> <span>bytes</span>:
</span></span><span><span>    <span>with</span> <span>open</span>(root <span>/</span> filename, <span>&#34;rb&#34;</span>) <span>as</span> fp:
</span></span><span><span>        result <span>=</span> fp<span>.</span>read()
</span></span><span><span>    <span>return</span> result
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>&#34;__main__&#34;</span>:
</span></span><span><span>    <span>print</span>(<span>&#34;normal: &#34;</span>, timeit<span>.</span>timeit(read_file_with_normal, number<span>=</span><span>100</span>))
</span></span><span><span>    <span>print</span>(<span>&#34;opendal: &#34;</span>, timeit<span>.</span>timeit(read_file_with_opendal, number<span>=</span><span>100</span>))
</span></span></code></pre></div><p>The result shows that</p><div><pre tabindex="0"><code data-lang="shell"><span><span><span>(</span>venv<span>)</span> $ python benchmark.py
</span></span><span><span>normal:  4.470868484000675
</span></span><span><span>opendal:  8.993250704006641
</span></span></code></pre></div><p>Well, well, well. I&#39;m somewhat embarrassed by these results. Here are a few quick hypotheses:</p><ul><li>Does Python have an internal cache that can reuse the same memory?</li><li>Does Python possess some trick to accelerate file reading?</li><li>Does PyO3 introduce additional overhead?</li></ul><p>I&#39;ve refactored the code to:</p><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/python-fs-read/test.py">python-fs-read</a>:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>with</span> <span>open</span>(<span>&#34;/tmp/file&#34;</span>, <span>&#34;rb&#34;</span>) <span>as</span> fp:
</span></span><span><span>    result <span>=</span> fp<span>.</span>read()
</span></span><span><span><span>assert</span> <span>len</span>(result) <span>==</span> <span>64</span> <span>*</span> <span>1024</span> <span>*</span> <span>1024</span>
</span></span></code></pre></div><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/python-opendal-read/test.py">python-opendal-read</a>:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> <span>opendal</span>
</span></span><span><span>
</span></span><span><span>op <span>=</span> opendal<span>.</span>Operator(<span>&#34;fs&#34;</span>, root<span>=</span><span>str</span>(<span>&#34;/tmp&#34;</span>))
</span></span><span><span>
</span></span><span><span>result <span>=</span> op<span>.</span>read(<span>&#34;file&#34;</span>)
</span></span><span><span><span>assert</span> <span>len</span>(result) <span>==</span> <span>64</span> <span>*</span> <span>1024</span> <span>*</span> <span>1024</span>
</span></span></code></pre></div><p>The result shows that python is much faster than opendal:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Benchmark 1: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      15.9 ms ±   0.7 ms    <span>[</span>User: 5.6 ms, System: 10.1 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    14.9 ms …  21.6 ms    <span>180</span> runs
</span></span><span><span>  
</span></span><span><span>Benchmark 2: python-opendal-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      32.9 ms ±   1.3 ms    <span>[</span>User: 6.1 ms, System: 26.6 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    31.4 ms …  42.6 ms    <span>85</span> runs
</span></span><span><span>  
</span></span><span><span>Summary
</span></span><span><span>  python-fs-read/test.py ran
</span></span><span><span>    2.07 ± 0.12 <span>times</span> faster than python-opendal-read/test.py
</span></span></code></pre></div><p>The Python binding for OpenDAL seems to be slower than Python itself, which isn&#39;t great news. Let&#39;s investigate the reasons behind this.</p><h2 id="opendal-fs-service-is-slower-than-python">OpenDAL Fs Service is slower than Python?</h2><p>This puzzle involves numerous elements such as rust, opendal, python, pyo3, among others. Let&#39;s focus and attempt to identify the root cause.</p><p>I implement the same logic via opendal fs service in rust:</p><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/rust-opendal-fs-read/src/main.rs">rust-opendal-fs-read</a>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span>std::io::Read;<span>
</span></span></span><span><span><span></span><span>use</span><span> </span>opendal::services::Fs;<span>
</span></span></span><span><span><span></span><span>use</span><span> </span>opendal::Operator;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span>()<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>cfg<span> </span><span>=</span><span> </span>Fs::default();<span>
</span></span></span><span><span><span>    </span>cfg.root(<span>&#34;/tmp&#34;</span>);<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span>op<span> </span><span>=</span><span> </span>Operator::new(cfg).unwrap().finish().blocking();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>bs<span> </span><span>=</span><span> </span>vec![<span>0</span>;<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>];<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>f<span> </span><span>=</span><span> </span>op.reader(<span>&#34;file&#34;</span>).unwrap();<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>ts<span> </span><span>=</span><span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>loop</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>buf<span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span>bs[ts<span>..</span>];<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>f.read(buf).unwrap();<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>n<span> </span><span>as</span><span> </span><span>usize</span>;<span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span>n<span> </span><span>==</span><span> </span><span>0</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>break</span><span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>ts<span> </span><span>+=</span><span> </span>n;<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>assert_eq!(ts,<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>However, the result shows that opendal is slower than python even when opendal is implemented in rust:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Benchmark 1: rust-opendal-fs-read/target/release/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      23.8 ms ±   2.0 ms    <span>[</span>User: 0.4 ms, System: 23.4 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    21.8 ms …  34.6 ms    <span>121</span> runs
</span></span><span><span> 
</span></span><span><span>Benchmark 2: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      15.6 ms ±   0.8 ms    <span>[</span>User: 5.5 ms, System: 10.0 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    14.4 ms …  20.8 ms    <span>166</span> runs
</span></span><span><span> 
</span></span><span><span>Summary
</span></span><span><span>  python-fs-read/test.py ran
</span></span><span><span>    1.52 ± 0.15 <span>times</span> faster than rust-opendal-fs-read/target/release/test
</span></span></code></pre></div><p>While <code>rust-opendal-fs-read</code> performs slightly better than <code>python-opendal-read</code>, indicating room for improvement in the binding &amp; pyo3, these aren&#39;t the core issues. We need to delve deeper.</p><p>Ah, opendal fs service is slower than python.</p><h2 id="rust-std-fs-is-slower-than-python">Rust std fs is slower than Python?</h2><p>OpenDAL implement fs service via <a href="https://doc.rust-lang.org/std/fs/index.html">std::fs</a>. Could there be additional costs incurred by OpenDAL itself?</p><p>I implement the same logic via rust <code>std::fs</code>:</p><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/rust-std-fs-read/src/main.rs">rust-std-fs-read</a>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span>std::io::Read;<span>
</span></span></span><span><span><span></span><span>use</span><span> </span>std::fs::OpenOptions;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span>()<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>bs<span> </span><span>=</span><span> </span>vec![<span>0</span>;<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>];<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>f<span> </span><span>=</span><span> </span>OpenOptions::new().read(<span>true</span>).open(<span>&#34;/tmp/file&#34;</span>).unwrap();<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>ts<span> </span><span>=</span><span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>loop</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>buf<span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span>bs[ts<span>..</span>];<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>f.read(buf).unwrap();<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>n<span> </span><span>as</span><span> </span><span>usize</span>;<span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span>n<span> </span><span>==</span><span> </span><span>0</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>break</span><span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>ts<span> </span><span>+=</span><span> </span>n;<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>assert_eq!(ts,<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>But....</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Benchmark 1: rust-std-fs-read/target/release/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      23.1 ms ±   2.5 ms    <span>[</span>User: 0.3 ms, System: 22.8 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    21.0 ms …  37.6 ms    <span>124</span> runs
</span></span><span><span> 
</span></span><span><span>Benchmark 2: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      15.2 ms ±   1.1 ms    <span>[</span>User: 5.4 ms, System: 9.7 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    14.3 ms …  21.4 ms    <span>178</span> runs
</span></span><span><span>
</span></span><span><span>Summary
</span></span><span><span>  python-fs-read/test.py ran
</span></span><span><span>    1.52 ± 0.20 <span>times</span> faster than rust-std-fs-read/target/release/test
</span></span></code></pre></div><p>Wow, Rust&#39;s std fs is slower than Python? How can that be? No offense intended, but how is that possible?</p><h2 id="rust-std-fs-is-slower-than-python-really">Rust std fs is slower than Python? Really!?</h2><p>I can&#39;t believe the results: rust std fs is surprisingly slower than Python.</p><p>I learned how to use <code>strace</code> for syscall analysis. <a href="https://strace.io/"><code>strace</code></a> is a Linux syscall tracer that allows us to monitor syscalls and understand their processes.</p><p>The strace will encompass all syscalls dispatched by the program. Our attention should be on aspects associated with <code>/tmp/file</code>. Each line of the strace output initiates with the syscall name, followed by input arguments and output.</p><p>For example:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>openat<span>(</span>AT_FDCWD, <span>&#34;/tmp/file&#34;</span>, O_RDONLY|O_CLOEXEC<span>)</span> <span>=</span> <span>3</span>
</span></span></code></pre></div><p>Means we invoke the <code>openat</code> syscall using arguments <code>AT_FDCWD</code>, <code>&#34;/tmp/file&#34;</code>, and <code>O_RDONLY|O_CLOEXEC</code>. This returns output <code>3</code>, which is the file descriptor referenced in the subsequent syscall.</p><p>Alright, we&#39;ve mastered <code>strace</code>. Let&#39;s put it to use!</p><p>strace of <code>rust-std-fs-read</code>:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; strace ./rust-std-fs-read/target/release/test
</span></span><span><span>...
</span></span><span><span>mmap<span>(</span>NULL, 67112960, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0<span>)</span> <span>=</span> 0x7f290dd40000
</span></span><span><span>openat<span>(</span>AT_FDCWD, <span>&#34;/tmp/file&#34;</span>, O_RDONLY|O_CLOEXEC<span>)</span> <span>=</span> <span>3</span>
</span></span><span><span>read<span>(</span>3, <span>&#34;\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\&#34;\353\204\220s\2|7C\205\265\6\263&#34;</span>..., 67108864<span>)</span> <span>=</span> <span>67108864</span>
</span></span><span><span>read<span>(</span>3, <span>&#34;&#34;</span>, 0<span>)</span>                          <span>=</span> <span>0</span>
</span></span><span><span>close<span>(</span>3<span>)</span>                                <span>=</span> <span>0</span>
</span></span><span><span>munmap<span>(</span>0x7f290dd40000, 67112960<span>)</span>        <span>=</span> <span>0</span>
</span></span><span><span>...
</span></span></code></pre></div><p>strace of <code>python-fs-read</code>:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; strace ./python-fs-read/test.py
</span></span><span><span>...
</span></span><span><span>openat<span>(</span>AT_FDCWD, <span>&#34;/tmp/file&#34;</span>, O_RDONLY|O_CLOEXEC<span>)</span> <span>=</span> <span>3</span>
</span></span><span><span>newfstatat<span>(</span>3, <span>&#34;&#34;</span>, <span>{</span><span>st_mode</span><span>=</span>S_IFREG|0644, <span>st_size</span><span>=</span>67108864, ...<span>}</span>, AT_EMPTY_PATH<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span>ioctl<span>(</span>3, TCGETS, 0x7ffe9f844ac0<span>)</span>        <span>=</span> -1 ENOTTY <span>(</span>Inappropriate ioctl <span>for</span> device<span>)</span>
</span></span><span><span>lseek<span>(</span>3, 0, SEEK_CUR<span>)</span>                   <span>=</span> <span>0</span>
</span></span><span><span>lseek<span>(</span>3, 0, SEEK_CUR<span>)</span>                   <span>=</span> <span>0</span>
</span></span><span><span>newfstatat<span>(</span>3, <span>&#34;&#34;</span>, <span>{</span><span>st_mode</span><span>=</span>S_IFREG|0644, <span>st_size</span><span>=</span>67108864, ...<span>}</span>, AT_EMPTY_PATH<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span>mmap<span>(</span>NULL, 67112960, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0<span>)</span> <span>=</span> 0x7f13277ff000
</span></span><span><span>read<span>(</span>3, <span>&#34;\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\&#34;\353\204\220s\2|7C\205\265\6\263&#34;</span>..., 67108865<span>)</span> <span>=</span> <span>67108864</span>
</span></span><span><span>read<span>(</span>3, <span>&#34;&#34;</span>, 1<span>)</span>                          <span>=</span> <span>0</span>
</span></span><span><span>close<span>(</span>3<span>)</span>                                <span>=</span> <span>0</span>
</span></span><span><span>rt_sigaction<span>(</span>SIGINT, <span>{</span><span>sa_handler</span><span>=</span>SIG_DFL, <span>sa_mask</span><span>=[]</span>, <span>sa_flags</span><span>=</span>SA_RESTORER|SA_ONSTACK, <span>sa_restorer</span><span>=</span>0x7f132be5c710<span>}</span>, <span>{</span><span>sa_handler</span><span>=</span>0x7f132c17ac36, <span>sa_mask</span><span>=[]</span>, <span>sa_flags</span><span>=</span>SA_RESTORER|SA_ONSTACK, <span>sa_restorer</span><span>=</span>0x7f132be5c710<span>}</span>, 8<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span>munmap<span>(</span>0x7f13277ff000, 67112960<span>)</span>        <span>=</span> <span>0</span>
</span></span><span><span>...
</span></span></code></pre></div><p>From analyzing strace, it&#39;s clear that <code>python-fs-read</code> has more syscalls than <code>rust-std-fs-read</code>, with both utilizing <code>mmap</code>. So why python is faster than rust?</p><h3 id="why-we-are-using-mmap-here">Why we are using <code>mmap</code> here?</h3><p>I initially believed <code>mmap</code> was solely for mapping files to memory, enabling file access through memory. However, <code>mmap</code> has other uses too. It&#39;s commonly used to allocate large regions of memory for applications.</p><p>This can be seen in the strace results:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>mmap<span>(</span>NULL, 67112960, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0<span>)</span> <span>=</span> 0x7f13277ff000
</span></span></code></pre></div><p>This syscall means</p><ul><li><code>NULL</code>: the first arg means start address of the memory region to map. <code>NULL</code> will let OS to pick up a suitable address for us.</li><li><code>67112960</code>: The size of the memory region to map. We are allocating 64MiB + 4KiB memory here, the extra page is used to store the metadata of this memory region.</li><li><code>PROT_READ|PROT_WRITE</code>: The memory region is readable and writable.</li><li><code>MAP_PRIVATE|MAP_ANONYMOUS</code>:<ul><li><code>MAP_PRIVATE</code> means changes to this memory region will not be visible to other processes mapping the same region, and are not carried through to the underlying file (if we have).</li><li><code>MAP_ANONYMOUS</code> means we are allocating anonymous memory that not related to a file.</li></ul></li><li><code>-1</code>: The file descriptor of the file to map. <code>-1</code> means we are not mapping a file.</li><li><code>0</code>: The offset in the file to map from. Use <code>0</code> here since we are not mapping a file.</li></ul><h3 id="but-i-dont-use-mmap-in-my-code">But I don&#39;t use <code>mmap</code> in my code.</h3><p>The <code>mmap</code> syscall is dispatched by <code>glibc</code>. We utilize <code>malloc</code> to solicit memory from the system, and in response, <code>glibc</code> employs both the <code>brk</code> and <code>mmap</code> syscalls to allocate memory according to our request size. If the requested size is sufficiently large, then <code>glibc</code> opts for using <code>mmap</code>, which helps mitigate memory fragmentation issues.</p><p>By default, all Rust programs compiled with target <code>x86_64-unknown-linux-gnu</code> use the <code>malloc</code> provided by <code>glibc</code>.</p><h3 id="does-python-has-the-same-memory-allocator-with-rust">Does python has the same memory allocator with rust?</h3><p>Python, by default, utilizes <a href="https://docs.python.org/3/c-api/memory.html#default-memory-allocators"><code>pymalloc</code></a>, a memory allocator optimized for small allocations. Python features three memory domains, each representing different allocation strategies and optimized for various purposes.</p><p><code>pymalloc</code> has the following behavior:</p><blockquote><p>Python has a <code>pymalloc</code> allocator optimized for small objects (smaller or equal to 512 bytes) with a short lifetime. It uses memory mappings called “arenas” with a fixed size of either 256 KiB on 32-bit platforms or 1 MiB on 64-bit platforms. It falls back to PyMem_RawMalloc() and PyMem_RawRealloc() for allocations larger than 512 bytes.</p></blockquote><h2 id="rust-is-slower-than-python-with-default-memory-allocator">Rust is slower than Python with default memory allocator?</h2><p>I suspect that <code>mmap</code> is causing this issue. What would occur if I switched to <code>jemalloc</code>?</p><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/rust-std-fs-read-with-jemalloc/src/main.rs">rust-std-fs-read-with-jemalloc</a>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span>std::io::Read;<span>
</span></span></span><span><span><span></span><span>use</span><span> </span>std::fs::OpenOptions;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[global_allocator]</span><span>
</span></span></span><span><span><span></span><span>static</span><span> </span><span>GLOBAL</span>: <span>jemallocator</span>::Jemalloc<span> </span><span>=</span><span> </span>jemallocator::Jemalloc;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span>()<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>bs<span> </span><span>=</span><span> </span>vec![<span>0</span>;<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>];<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>f<span> </span><span>=</span><span> </span>OpenOptions::new().read(<span>true</span>).open(<span>&#34;/tmp/file&#34;</span>).unwrap();<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>ts<span> </span><span>=</span><span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>loop</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>buf<span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span>bs[ts<span>..</span>];<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>f.read(buf).unwrap();<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>n<span> </span><span>=</span><span> </span>n<span> </span><span>as</span><span> </span><span>usize</span>;<span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span>n<span> </span><span>==</span><span> </span><span>0</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>break</span><span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>ts<span> </span><span>+=</span><span> </span>n;<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>assert_eq!(ts,<span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Wooooooooooooooow?!</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Benchmark 1: rust-std-fs-read-with-jemalloc/target/release/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:       9.7 ms ±   0.6 ms    <span>[</span>User: 0.3 ms, System: 9.4 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:     9.0 ms …  12.4 ms    <span>259</span> runs
</span></span><span><span> 
</span></span><span><span>Benchmark 2: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      15.8 ms ±   0.9 ms    <span>[</span>User: 5.9 ms, System: 9.8 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    15.0 ms …  21.8 ms    <span>169</span> runs
</span></span><span><span>
</span></span><span><span>Summary
</span></span><span><span>  rust-std-fs-read-with-jemalloc/target/release/test ran
</span></span><span><span>    1.64 ± 0.14 <span>times</span> faster than python-fs-read/test.py
</span></span></code></pre></div><p>What?! I understand that <code>jemalloc</code> is a proficient memory allocator, but how can it be this exceptional? This is baffling.</p><h2 id="rust-is-slower-than-python-only-on-my-machine">Rust is slower than Python only on my machine!</h2><p>As more friends joined the discussion, we discovered that rust runs slower than python only on my machine.</p><p>My CPU:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; lscpu
</span></span><span><span>Architecture:            x86_64
</span></span><span><span>  CPU op-mode<span>(</span>s<span>)</span>:        32-bit, 64-bit
</span></span><span><span>  Address sizes:         <span>48</span> bits physical, <span>48</span> bits virtual
</span></span><span><span>  Byte Order:            Little Endian
</span></span><span><span>CPU<span>(</span>s<span>)</span>:                  <span>32</span>
</span></span><span><span>  On-line CPU<span>(</span>s<span>)</span> list:   0-31
</span></span><span><span>Vendor ID:               AuthenticAMD
</span></span><span><span>  Model name:            AMD Ryzen <span>9</span> 5950X 16-Core Processor
</span></span><span><span>    CPU family:          <span>25</span>
</span></span><span><span>    Model:               <span>33</span>
</span></span><span><span>    Thread<span>(</span>s<span>)</span> per core:  <span>2</span>
</span></span><span><span>    Core<span>(</span>s<span>)</span> per socket:  <span>16</span>
</span></span><span><span>    Socket<span>(</span>s<span>)</span>:           <span>1</span>
</span></span><span><span>    Stepping:            <span>0</span>
</span></span><span><span>    Frequency boost:     enabled
</span></span><span><span>    CPU<span>(</span>s<span>)</span> scaling MHz:  53%
</span></span><span><span>    CPU max MHz:         5083.3979
</span></span><span><span>    CPU min MHz:         2200.0000
</span></span><span><span>    BogoMIPS:            6787.49
</span></span><span><span>    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm con
</span></span><span><span>                         stant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f
</span></span><span><span>                         16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpex
</span></span><span><span>                         t perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap
</span></span><span><span>                          clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local user_shstk clzero irperf xsaveerptr rdpru wb
</span></span><span><span>                         noinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl
</span></span><span><span>                         umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm debug_swap
</span></span><span><span>Virtualization features:
</span></span><span><span>  Virtualization:        AMD-V
</span></span><span><span>Caches <span>(</span>sum of all<span>)</span>:
</span></span><span><span>  L1d:                   <span>512</span> KiB <span>(</span><span>16</span> instances<span>)</span>
</span></span><span><span>  L1i:                   <span>512</span> KiB <span>(</span><span>16</span> instances<span>)</span>
</span></span><span><span>  L2:                    <span>8</span> MiB <span>(</span><span>16</span> instances<span>)</span>
</span></span><span><span>  L3:                    <span>64</span> MiB <span>(</span><span>2</span> instances<span>)</span>
</span></span><span><span>NUMA:
</span></span><span><span>  NUMA node<span>(</span>s<span>)</span>:          <span>1</span>
</span></span><span><span>  NUMA node0 CPU<span>(</span>s<span>)</span>:     0-31
</span></span><span><span>Vulnerabilities:
</span></span><span><span>  Gather data sampling:  Not affected
</span></span><span><span>  Itlb multihit:         Not affected
</span></span><span><span>  L1tf:                  Not affected
</span></span><span><span>  Mds:                   Not affected
</span></span><span><span>  Meltdown:              Not affected
</span></span><span><span>  Mmio stale data:       Not affected
</span></span><span><span>  Retbleed:              Not affected
</span></span><span><span>  Spec rstack overflow:  Vulnerable
</span></span><span><span>  Spec store bypass:     Vulnerable
</span></span><span><span>  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers
</span></span><span><span>  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected
</span></span><span><span>  Srbds:                 Not affected
</span></span><span><span>  Tsx async abort:       Not affected
</span></span></code></pre></div><p>My memory:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; sudo dmidecode --type memory
</span></span><span><span><span># dmidecode 3.5</span>
</span></span><span><span>Getting SMBIOS data from sysfs.
</span></span><span><span>SMBIOS 3.3.0 present.
</span></span><span><span>
</span></span><span><span>Handle 0x0014, DMI <span>type</span> 16, <span>23</span> bytes
</span></span><span><span>Physical Memory Array
</span></span><span><span>        Location: System Board Or Motherboard
</span></span><span><span>        Use: System Memory
</span></span><span><span>        Error Correction Type: None
</span></span><span><span>        Maximum Capacity: <span>64</span> GB
</span></span><span><span>        Error Information Handle: 0x0013
</span></span><span><span>        Number Of Devices: <span>4</span>
</span></span><span><span>
</span></span><span><span>Handle 0x001C, DMI <span>type</span> 17, <span>92</span> bytes
</span></span><span><span>Memory Device
</span></span><span><span>        Array Handle: 0x0014
</span></span><span><span>        Error Information Handle: 0x001B
</span></span><span><span>        Total Width: <span>64</span> bits
</span></span><span><span>        Data Width: <span>64</span> bits
</span></span><span><span>        Size: <span>16</span> GB
</span></span><span><span>        Form Factor: DIMM
</span></span><span><span>        Set: None
</span></span><span><span>        Locator: DIMM <span>0</span>
</span></span><span><span>        Bank Locator: P0 CHANNEL A
</span></span><span><span>        Type: DDR4
</span></span><span><span>        Type Detail: Synchronous Unbuffered <span>(</span>Unregistered<span>)</span>
</span></span><span><span>        Speed: <span>3200</span> MT/s
</span></span><span><span>        Manufacturer: Unknown
</span></span><span><span>        Serial Number: <span>04904740</span>
</span></span><span><span>        Asset Tag: Not Specified
</span></span><span><span>        Part Number: LMKUFG68AHFHD-32A
</span></span><span><span>        Rank: <span>2</span>
</span></span><span><span>        Configured Memory Speed: <span>3200</span> MT/s
</span></span><span><span>        Minimum Voltage: 1.2 V
</span></span><span><span>        Maximum Voltage: 1.2 V
</span></span><span><span>        Configured Voltage: 1.2 V
</span></span><span><span>        Memory Technology: DRAM
</span></span><span><span>        Memory Operating Mode Capability: Volatile memory
</span></span><span><span>        Firmware Version: Unknown
</span></span><span><span>        Module Manufacturer ID: Bank 9, Hex 0xC8
</span></span><span><span>        Module Product ID: Unknown
</span></span><span><span>        Memory Subsystem Controller Manufacturer ID: Unknown
</span></span><span><span>        Memory Subsystem Controller Product ID: Unknown
</span></span><span><span>        Non-Volatile Size: None
</span></span><span><span>        Volatile Size: <span>16</span> GB
</span></span><span><span>        Cache Size: None
</span></span><span><span>        Logical Size: None
</span></span></code></pre></div><p>So I tried the following things:</p><h3 id="enable-mitigations">Enable Mitigations</h3><p>CPUs possess numerous vulnerabilities that could expose private data to attackers, with <code>Spectre</code> being one of the most notable. The Linux kernel has developed various mitigations to counter these vulnerabilities and they are enabled by default. However, these mitigations can impose additional system costs. Therefore, the Linux kernel also offers a <code>mitigations</code> flag for users who wish to disable them.</p><p>I used to disable all <code>mitigations</code> like the following:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>title Arch Linux
</span></span><span><span>linux /vmlinuz-linux-zen
</span></span><span><span>initrd /amd-ucode.img
</span></span><span><span>initrd /initramfs-linux-zen.img
</span></span><span><span>options <span>root</span><span>=</span><span>&#34;PARTUUID=206e7750-2b89-419d-978e-db0068c79c52&#34;</span> rw <span>mitigations</span><span>=</span>off
</span></span></code></pre></div><p>Enable it back didn&#39;t change the result.</p><h3 id="tune-transparent-hugepage">Tune Transparent Hugepage</h3><p><a href="https://www.kernel.org/doc/html/next/admin-guide/mm/transhuge.html">Transparent Hugepage</a> can significantly impact performance. Most modern distributions enable it by default.</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; cat /sys/kernel/mm/transparent_hugepage/enabled
</span></span><span><span><span>[</span>always<span>]</span> madvise never
</span></span></code></pre></div><p>Switching to <code>madvise</code> or <code>never</code> alters the absolute outcome, but the relative ratio remains consistent.</p><h3 id="tune-cpu-core-affinity">Tune CPU Core Affinity</h3><p><a href="https://github.com/ZheaoLi">@Manjusaka</a> guesses this related to <code>CPU Core Spacing</code>.</p><p>I tried to use <a href="https://docs.rs/core_affinity/latest/core_affinity/">core_affinity</a> to bind process to specific CPU, but the result is the same.</p><h3 id="measure-syscall-latency-by-ebpf">Measure syscall latency by eBPF</h3><p><a href="https://github.com/ZheaoLi">@Manjusaka</a> also created <a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/scripts/read-latency.py">an eBPF program</a> for me to gauge the latency of read syscalls. The findings indicate that Rust is also slower than Python at syscall level.</p><blockquote><p>There&#39;s another lengthy tale about this eBPF program that @Manjusaka should share in a post!</p></blockquote><div><pre tabindex="0"><code data-lang="shell"><span><span><span># python fs read</span>
</span></span><span><span>Process <span>57555</span> <span>read</span> file <span>8134049</span> ns
</span></span><span><span>Process <span>57555</span> <span>read</span> file <span>942</span> ns
</span></span><span><span>
</span></span><span><span><span># rust std fs read</span>
</span></span><span><span>Process <span>57634</span> <span>read</span> file <span>24636975</span> ns
</span></span><span><span>Process <span>57634</span> <span>read</span> file <span>1052</span> ns
</span></span></code></pre></div><p>Observation: On my computer, Rust operates slower than Python and it doesn&#39;t appear to be related to the software.</p><h2 id="c-is-slower-than-python">C is slower than Python?</h2><p>I&#39;m quite puzzled and can&#39;t pinpoint the difference. I suspect it might have something to do with the CPU, but I&#39;m unsure which aspect: cache? frequency? core spacing? core affinity? architecture?</p><p>Following the guidance from the Telegram group <a href="https://t.me/rust_zh">@rust_zh</a>, I&#39;ve developed a C version:</p><p><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow/blob/main/c-fs-read/test.c">c-fs-read</a>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define FILE_SIZE 64 * 1024 * 1024  </span><span>// 64 MiB
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>    FILE <span>*</span>file;
</span></span><span><span>    <span>char</span> <span>*</span>buffer;
</span></span><span><span>    <span>size_t</span> result;
</span></span><span><span>
</span></span><span><span>    file <span>=</span> <span>fopen</span>(<span>&#34;/tmp/file&#34;</span>, <span>&#34;rb&#34;</span>);
</span></span><span><span>    <span>if</span> (file <span>==</span> <span>NULL</span>) {
</span></span><span><span>        <span>fputs</span>(<span>&#34;Error opening file&#34;</span>, stderr);
</span></span><span><span>        <span>return</span> <span>1</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    buffer <span>=</span> (<span>char</span> <span>*</span>)<span>malloc</span>(<span>sizeof</span>(<span>char</span>) <span>*</span> FILE_SIZE);
</span></span><span><span>    <span>if</span> (buffer <span>==</span> <span>NULL</span>) {
</span></span><span><span>        <span>fputs</span>(<span>&#34;Memory error&#34;</span>, stderr);
</span></span><span><span>        <span>fclose</span>(file);
</span></span><span><span>        <span>return</span> <span>2</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    result <span>=</span> <span>fread</span>(buffer, <span>1</span>, FILE_SIZE, file);
</span></span><span><span>    <span>if</span> (result <span>!=</span> FILE_SIZE) {
</span></span><span><span>        <span>fputs</span>(<span>&#34;Reading error&#34;</span>, stderr);
</span></span><span><span>        <span>fclose</span>(file);
</span></span><span><span>        <span>free</span>(buffer);
</span></span><span><span>        <span>return</span> <span>3</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>fclose</span>(file);
</span></span><span><span>    <span>free</span>(buffer);
</span></span><span><span>
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>But...</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Benchmark 1: c-fs-read/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      23.8 ms ±   0.9 ms    <span>[</span>User: 0.3 ms, System: 23.6 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    23.0 ms …  27.1 ms    <span>120</span> runs
</span></span><span><span>
</span></span><span><span>Benchmark 2: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      19.1 ms ±   0.3 ms    <span>[</span>User: 8.6 ms, System: 10.4 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    18.6 ms …  20.6 ms    <span>146</span> runs
</span></span><span><span>
</span></span><span><span>Summary
</span></span><span><span>  python-fs-read/test.py ran
</span></span><span><span>    1.25 ± 0.05 <span>times</span> faster than c-fs-read/test
</span></span></code></pre></div><p>The C version is also slower than Python! Does python have magic?</p><h2 id="c-is-slower-than-python-with-specified-offset">C is slower than Python with specified offset!</h2><p>At this time, <a href="https://github.com/lilydjwg">@lilydjwg</a> has joined the discussion and noticed a difference in the memory region offset between C and Python.</p><blockquote><p><code>strace -e raw=read,mmap ./program</code> is used to print the undecoded arguments for the syscalls: the pointer address.</p></blockquote><p>strace for <code>c-fs-read</code>:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; strace -e <span>raw</span><span>=</span>read,mmap ./c-fs-read/test
</span></span><span><span>...
</span></span><span><span>mmap<span>(</span>0, 0x4001000, 0x3, 0x22, 0xffffffff, 0<span>)</span> <span>=</span> 0x7f96d1a18000
</span></span><span><span>read<span>(</span>0x3, 0x7f96d1a18010, 0x4000000<span>)</span>    <span>=</span> 0x4000000
</span></span><span><span>close<span>(</span>3<span>)</span>                                <span>=</span> <span>0</span>
</span></span></code></pre></div><p>strace for <code>python-fs-read</code></p><div><pre tabindex="0"><code data-lang="shell"><span><span>&gt; strace -e <span>raw</span><span>=</span>read,mmap ./python-fs-read/test.py
</span></span><span><span>...
</span></span><span><span>mmap<span>(</span>0, 0x4001000, 0x3, 0x22, 0xffffffff, 0<span>)</span> <span>=</span> 0x7f27dcfbe000
</span></span><span><span>read<span>(</span>0x3, 0x7f27dcfbe030, 0x4000001<span>)</span>    <span>=</span> 0x4000000
</span></span><span><span>read<span>(</span>0x3, 0x7f27e0fbe030, 0x1<span>)</span>          <span>=</span> <span>0</span>
</span></span><span><span>close<span>(</span>3<span>)</span>                                <span>=</span> <span>0</span>
</span></span></code></pre></div><p>In <code>c-fs-read</code>, <code>mmap</code> returns <code>0x7f96d1a18000</code>, but read syscall use <code>0x7f96d1a18010</code> as the start address, the offset is <code>0x10</code>. In <code>python-fs-read</code>, <code>mmap</code> returns <code>0x7f27dcfbe000</code>, and read syscall use <code>0x7f27dcfbe030</code> as the start address, the offset is <code>0x30</code>.</p><p>So <a href="https://github.com/lilydjwg">@lilydjwg</a> tried to calling <code>read</code> with the same offset:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>:<span>)</span> ./bench c-fs-read c-fs-read-with-offset python-fs-read
</span></span><span><span><span>[</span><span>&#39;hyperfine&#39;</span>, <span>&#39;c-fs-read/test&#39;</span>, <span>&#39;c-fs-read-with-offset/test&#39;</span>, <span>&#39;python-fs-read/test.py&#39;</span><span>]</span>
</span></span><span><span>Benchmark 1: c-fs-read/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      23.7 ms ±   0.8 ms    <span>[</span>User: 0.2 ms, System: 23.6 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    23.0 ms …  25.5 ms    <span>119</span> runs
</span></span><span><span>
</span></span><span><span>  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might <span>help</span> to use the <span>&#39;--warmup&#39;</span> or <span>&#39;--prepare&#39;</span> options.
</span></span><span><span>
</span></span><span><span>Benchmark 2: c-fs-read-with-offset/test
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:       8.9 ms ±   0.4 ms    <span>[</span>User: 0.2 ms, System: 8.8 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:     8.3 ms …  10.6 ms    <span>283</span> runs
</span></span><span><span>
</span></span><span><span>Benchmark 3: python-fs-read/test.py
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:      19.1 ms ±   0.3 ms    <span>[</span>User: 8.6 ms, System: 10.4 ms<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:    18.6 ms …  20.0 ms    <span>147</span> runs
</span></span><span><span>
</span></span><span><span>Summary
</span></span><span><span>  c-fs-read-with-offset/test ran
</span></span><span><span>    2.15 ± 0.11 <span>times</span> faster than python-fs-read/test.py
</span></span><span><span>    2.68 ± 0.16 <span>times</span> faster than c-fs-read/test
</span></span></code></pre></div><p>!!!</p><p>Applying an offset to <code>buffer</code> in <code>c-fs-read</code> enhances its speed, outperforming Python! Additionally, we&#39;ve verified that this issue is replicable on both the <code>AMD Ryzen 9 5900X</code> and <code>AMD Ryzen 7 5700X</code>.</p><p>The new information led me to other reports about a similar issue, <a href="https://users.rust-lang.org/t/std-read-slow/85424">Std::fs::read slow?</a>. In this post, <a href="https://github.com/ambiso">@ambiso</a> discovered that syscall performance is linked to the offset of the memory region. He noted that this CPU slows down when writing from the first <code>0x10</code> bytes of each page:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>offset milliseconds
</span></span><span><span> ...
</span></span><span><span> <span>14</span>   <span>130</span>
</span></span><span><span> <span>15</span>   <span>130</span>
</span></span><span><span> <span>16</span>    <span>46</span>   &lt;----- 0x10!
</span></span><span><span> <span>17</span>    <span>48</span>
</span></span><span><span> ...
</span></span></code></pre></div><h2 id="amd-ryzen-9-5900x-is-slow-with-specified-offset">AMD Ryzen 9 5900X is slow with specified offset!</h2><p>We&#39;ve confirmed that this issue is related to the CPU. However, we&#39;re still unsure about its potential reasons. <a href="https://github.com/ZheaoLi">@Manjusaka</a> has invited kernel developer <a href="https://github.com/ryncsn">@ryncsn</a> to join the discussion.</p><p>He can reproduce the same outcome using our <code>c-fs-read</code> and <code>c-fs-read-with-offset</code> demos on <code>AMD Ryzen 9 5900HX</code>. He also attempted to profile the two programs using <code>perf</code>.</p><p>Without offset:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>perf stat -d -d -d --repeat <span>20</span> ./a.out
</span></span><span><span> Performance counter stats <span>for</span> <span>&#39;./a.out&#39;</span> <span>(</span><span>20</span> runs<span>)</span>:
</span></span><span><span>
</span></span><span><span>             30.89 msec task-clock                       <span>#    0.968 CPUs utilized               ( +-  1.35% )</span>
</span></span><span><span>                 <span>0</span>      context-switches                 <span>#    0.000 /sec</span>
</span></span><span><span>                 <span>0</span>      cpu-migrations                   <span>#    0.000 /sec</span>
</span></span><span><span>               <span>598</span>      page-faults                      <span>#   19.362 K/sec                       ( +-  0.05% )</span>
</span></span><span><span>        90,321,344      cycles                           <span>#    2.924 GHz                         ( +-  1.12% )  (40.76%)</span>
</span></span><span><span>           599,640      stalled-cycles-frontend          <span>#    0.66% frontend cycles idle        ( +-  2.19% )  (42.11%)</span>
</span></span><span><span>           398,016      stalled-cycles-backend           <span>#    0.44% backend cycles idle         ( +- 22.41% )  (41.88%)</span>
</span></span><span><span>        43,349,705      instructions                     <span>#    0.48  insn per cycle</span>
</span></span><span><span>                                                  <span>#    0.01  stalled cycles per insn     ( +-  1.32% )  (41.91%)</span>
</span></span><span><span>         7,526,819      branches                         <span>#  243.701 M/sec                       ( +-  5.01% )  (41.22%)</span>
</span></span><span><span>            37,541      branch-misses                    <span>#    0.50% of all branches             ( +-  4.62% )  (41.12%)</span>
</span></span><span><span>       127,845,213      L1-dcache-loads                  <span>#    4.139 G/sec                       ( +-  1.14% )  (39.84%)</span>
</span></span><span><span>         3,172,628      L1-dcache-load-misses            <span>#    2.48% of all L1-dcache accesses   ( +-  1.34% )  (38.46%)</span>
</span></span><span><span>   &lt;not supported&gt;      LLC-loads
</span></span><span><span>   &lt;not supported&gt;      LLC-load-misses
</span></span><span><span>           654,651      L1-icache-loads                  <span>#   21.196 M/sec                       ( +-  1.71% )  (38.72%)</span>
</span></span><span><span>             2,828      L1-icache-load-misses            <span>#    0.43% of all L1-icache accesses   ( +-  2.35% )  (38.67%)</span>
</span></span><span><span>            15,615      dTLB-loads                       <span>#  505.578 K/sec                       ( +-  1.28% )  (38.82%)</span>
</span></span><span><span>            12,825      dTLB-load-misses                 <span>#   82.13% of all dTLB cache accesses  ( +-  1.15% )  (38.88%)</span>
</span></span><span><span>                <span>16</span>      iTLB-loads                       <span>#  518.043 /sec                        ( +- 27.06% )  (38.82%)</span>
</span></span><span><span>             2,202      iTLB-load-misses                 <span># 13762.50% of all iTLB cache accesses  ( +- 23.62% )  (39.38%)</span>
</span></span><span><span>         1,843,493      L1-dcache-prefetches             <span>#   59.688 M/sec                       ( +-  3.36% )  (39.40%)</span>
</span></span><span><span>   &lt;not supported&gt;      L1-dcache-prefetch-misses
</span></span><span><span>
</span></span><span><span>          0.031915 +- 0.000419 seconds <span>time</span> elapsed  <span>(</span> +-  1.31% <span>)</span>
</span></span></code></pre></div><p>With offset:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>perf stat -d -d -d --repeat <span>20</span> ./a.out
</span></span><span><span> Performance counter stats <span>for</span> <span>&#39;./a.out&#39;</span> <span>(</span><span>20</span> runs<span>)</span>:
</span></span><span><span>
</span></span><span><span>             15.39 msec task-clock                       <span>#    0.937 CPUs utilized               ( +-  3.24% )</span>
</span></span><span><span>                 <span>1</span>      context-switches                 <span>#   64.972 /sec                        ( +- 17.62% )</span>
</span></span><span><span>                 <span>0</span>      cpu-migrations                   <span>#    0.000 /sec</span>
</span></span><span><span>               <span>598</span>      page-faults                      <span>#   38.854 K/sec                       ( +-  0.06% )</span>
</span></span><span><span>        41,239,117      cycles                           <span>#    2.679 GHz                         ( +-  1.95% )  (40.68%)</span>
</span></span><span><span>           547,465      stalled-cycles-frontend          <span>#    1.33% frontend cycles idle        ( +-  3.43% )  (40.60%)</span>
</span></span><span><span>           413,657      stalled-cycles-backend           <span>#    1.00% backend cycles idle         ( +- 20.37% )  (40.50%)</span>
</span></span><span><span>        37,009,429      instructions                     <span>#    0.90  insn per cycle</span>
</span></span><span><span>                                                  <span>#    0.01  stalled cycles per insn     ( +-  3.13% )  (40.43%)</span>
</span></span><span><span>         5,410,381      branches                         <span>#  351.526 M/sec                       ( +-  3.24% )  (39.80%)</span>
</span></span><span><span>            34,649      branch-misses                    <span>#    0.64% of all branches             ( +-  4.04% )  (39.94%)</span>
</span></span><span><span>        13,965,813      L1-dcache-loads                  <span>#  907.393 M/sec                       ( +-  3.37% )  (39.44%)</span>
</span></span><span><span>         3,623,350      L1-dcache-load-misses            <span>#   25.94% of all L1-dcache accesses   ( +-  3.56% )  (39.52%)</span>
</span></span><span><span>   &lt;not supported&gt;      LLC-loads
</span></span><span><span>   &lt;not supported&gt;      LLC-load-misses
</span></span><span><span>           590,613      L1-icache-loads                  <span>#   38.374 M/sec                       ( +-  3.39% )  (39.67%)</span>
</span></span><span><span>             1,995      L1-icache-load-misses            <span>#    0.34% of all L1-icache accesses   ( +-  4.18% )  (39.67%)</span>
</span></span><span><span>            16,046      dTLB-loads                       <span>#    1.043 M/sec                       ( +-  3.28% )  (39.78%)</span>
</span></span><span><span>            14,040      dTLB-load-misses                 <span>#   87.50% of all dTLB cache accesses  ( +-  3.24% )  (39.78%)</span>
</span></span><span><span>                <span>11</span>      iTLB-loads                       <span>#  714.697 /sec                        ( +- 29.56% )  (39.77%)</span>
</span></span><span><span>             3,657      iTLB-load-misses                 <span># 33245.45% of all iTLB cache accesses  ( +- 14.61% )  (40.30%)</span>
</span></span><span><span>           395,578      L1-dcache-prefetches             <span>#   25.702 M/sec                       ( +-  3.34% )  (40.10%)</span>
</span></span><span><span>   &lt;not supported&gt;      L1-dcache-prefetch-misses
</span></span><span><span>
</span></span><span><span>          0.016429 +- 0.000521 seconds <span>time</span> elapsed  <span>(</span> +-  3.17% <span>)</span>
</span></span></code></pre></div><p>He found the value of <code>L1-dcache-prefetches</code> and <code>L1-dcache-loads</code> differs a lot.</p><ul><li><code>L1-dcache-prefetches</code> is the prefetches of CPU L1 data cache.</li><li><code>L1-dcache-loads</code> is the loads of CPU L1 data cache.</li></ul><p>Without a specified offset, the CPU will perform more loads and prefetches of <code>L1-dcache</code>, resulting in increased syscall time.</p><p>He did a further research over the hotspot ASM:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>Samples: 15K of event <span>&#39;cycles:P&#39;</span>, Event count <span>(</span>approx.<span>)</span>: <span>6078132137</span>
</span></span><span><span>  Children      Self  Command    Shared Object         Symbol
</span></span><span><span>-   94.11%     0.00%  a.out      <span>[</span>kernel.vmlinux<span>]</span>      <span>[</span>k<span>]</span> entry_SYSCALL_64_after_hwframe                                                                                                                        ◆
</span></span><span><span>   - entry_SYSCALL_64_after_hwframe                                                                                                                                                                              ▒
</span></span><span><span>      - 94.10% do_syscall_64                                                                                                                                                                                     ▒
</span></span><span><span>         - 86.66% __x64_sys_read                                                                                                                                                                                 ▒
</span></span><span><span>              ksys_read                                                                                                                                                                                          ▒
</span></span><span><span>            - vfs_read                                                                                                                                                                                           ▒
</span></span><span><span>               - 85.94% shmem_file_read_iter                                                                                                                                                                     ▒
</span></span><span><span>                  - 77.17% copy_page_to_iter                                                                                                                                                                     ▒
</span></span><span><span>                     - 75.80% _copy_to_iter                                                                                                                                                                      ▒
</span></span><span><span>                        + 19.41% asm_exc_page_fault                                                                                                                                                              ▒
</span></span><span><span>                       0.71% __might_fault                                                                                                                                                                       ▒
</span></span><span><span>                  + 4.87% shmem_get_folio_gfp                                                                                                                                                                    ▒
</span></span><span><span>                    0.76% folio_mark_accessed                                                                                                                                                                    ▒
</span></span><span><span>         + 4.38% __x64_sys_munmap                                                                                                                                                                                ▒
</span></span><span><span>         + 1.02% 0xffffffffae6f6fe8                                                                                                                                                                              ▒
</span></span><span><span>         + 0.79% __x64_sys_execve                                                                                                                                                                                ▒
</span></span><span><span>         + 0.58% __x64_sys_mmap                                                                                                                                                                                  ▒
</span></span></code></pre></div><p>Inside <code>_copy_to_iter</code>, the ASM will be:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>       │     copy_user_generic<span>()</span>:
</span></span><span><span>  2.19 │       mov    %rdx,%rcx
</span></span><span><span>       │       mov    %r12,%rsi
</span></span><span><span> 92.45 │       rep    movsb %ds:<span>(</span>%rsi<span>)</span>,%es:<span>(</span>%rdi<span>)</span>
</span></span><span><span>  0.49 │       nop
</span></span><span><span>       │       nop
</span></span><span><span>       │       nop
</span></span></code></pre></div><p>The key difference here is the performance of <code>rep movsb</code>.</p><h2 id="amd-ryzen-9-5900x-is-slow-with-fsrm">AMD Ryzen 9 5900X is slow with FSRM!</h2><p>At this time, one of my friend sent me a link about <a href="https://bugs.launchpad.net/ubuntu/+source/glibc/+bug/2030515">Terrible memcpy performance on Zen 3 when using rep movsb</a>. In which also pointed to <code>rep movsb</code>:</p><blockquote><p>I&#39;ve found this using a memcpy benchmark at <a href="https://github.com/ska-sa/katgpucbf/blob/69752be58fb8ab0668ada806e0fd809e782cc58b/scratch/memcpy_loop.cpp">https://github.com/ska-sa/katgpucbf/blob/69752be58fb8ab0668ada806e0fd809e782cc58b/scratch/memcpy_loop.cpp</a> (compiled with the adjacent Makefile). To demonstrate the issue, run</p><p>./memcpy_loop -b 2113 -p 1000000 -t mmap -S 0 -D 1 0</p><p>This runs:</p><ul><li>2113-byte memory copies</li><li>1,000,000 times per timing measurement</li><li>in memory allocated with mmap</li><li>with the source 0 bytes from the start of the page</li><li>with the destination 1 byte from the start of the page</li><li>on core 0.</li></ul><p>It reports about 3.2 GB/s. Change the -b argument to 2111 and it reports over 100 GB/s. So the REP MOVSB case is about 30× slower!</p></blockquote><p><code>FSRM</code>, short for <code>Fast Short REP MOV</code>, is an innovation originally by Intel, recently incorporated into AMD as well, to enhance the speed of <code>rep movsb</code> and <code>rep movsd</code>. It&#39;s designed to boost the efficiency of copying large amounts of memory. CPUs that declare support for it will use <code>FSRM</code> as a default in <code>glibc</code>.</p><p><a href="https://github.com/ryncsn">@ryncsn</a> has conducted further research and discovered that it&#39;s not related to L1 prefetches.</p><blockquote><p>It seems that <code>rep movsb</code> performance poorly when DATA IS PAGE ALIGNED, and perform better when DATA IS NOT PAGE ALIGNED, this is very funny...</p></blockquote><h2 id="conclusion">Conclusion</h2><p>In conclusion, the issue isn&#39;t software-related. Python outperforms C/Rust due to an AMD CPU bug. (I can finally get some sleep now.)</p><p>However, our users continue to struggle with this problem. Unfortunately, features like <code>FSRM</code> will be implemented in <code>ucode</code>, leaving us no choice but to wait for AMD&#39;s response. An alternative solution could be not using <code>FSRM</code> or providing a flag to disable it. Rust developers might consider switching to <code>jemallocator</code> for improved performance - a beneficial move even without the presence of AMD CPU bugs.</p><p>I spent nearly three days addressing this issue, which began with complaints from <a href="https://github.com/apache/incubator-opendal">opendal</a> users and eventually led me to the CPU&#39;s ucode.</p><p>This journey taught me a lot about <code>strace</code>, <code>perf</code> and <code>eBPF</code>. It was my first time using <code>eBPF</code> for diagnostics. I also explored various unfruitful avenues such as studying the implementations of rust&#39;s <code>std::fs</code> and Python &amp; CPython&#39;s read implementation details. Initially, I hoped to resolve this at a higher level but found it necessary to delve deeper.</p><p>A big thank you to everyone who contributed to finding the answer:</p><ul><li>@beldathas from opendal&#39;s discord for identifying the problem.</li><li>The team at <a href="https://github.com/datafuselabs">@datafuselabs</a> for their insightful suggestions.</li><li>Our friends over at <a href="https://t.me/rust_zh">@rust_zh</a> for their advice and reproduction efforts.</li><li><a href="https://github.com/ZheaoLi">@Manjusaka</a> for reproducing the issue and use eBPF to investigate, which helped narrow down the problem to syscall itself.</li><li><a href="https://github.com/lilydjwg">@lilydjwg</a> for pinpointing the root cause: a <code>0x20</code> offset in memory</li><li><a href="https://github.com/ryncsn">@ryncsn</a> for his thorough analysis</li><li>And a friend who shared useful links about FSRM</li></ul><p>Looking forward to our next journey!</p><h2 id="reference">Reference</h2><ul><li><a href="https://github.com/Xuanwo/when-i-find-rust-is-slow">Xuanwo/when-i-find-rust-is-slow</a> has all the code snippets and scripts.</li><li><a href="https://users.rust-lang.org/t/std-read-slow/85424">Std::fs::read slow?</a> is a report from rust community</li><li><a href="https://bugs.launchpad.net/ubuntu/+source/glibc/+bug/2030515">Terrible memcpy performance on Zen 3 when using rep movsb</a> is a report to ubuntu glibc</li><li><a href="https://github.com/apache/incubator-opendal/issues/3665">binding/python: rust std fs is slower than python fs</a></li></ul></div></div>
  </body>
</html>
