<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://utcc.utoronto.ca/~cks/space/blog/web/AggressiveStealthyWebSpider">Original</a>
    <h1>An aggressive, stealthy web spider operating from Microsoft IP space</h1>
    
    <div id="readability-page-1" class="page"><div><h2>An aggressive, stealthy web spider operating from Microsoft IP space</h2>

	<p><small>January 17, 2023</small></p>
</div><div><p>For a few days, I&#39;ve been noticing some anomalies in some metrics
surrounding <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>, but nothing stood out as
particularly wrong and my usual habit of looking at the top IP
addresses requesting URLs from here didn&#39;t turn up anything. Then
today I randomly wound up looking at the user-agents of things
making requests here and <a href="https://mastodon.social/@cks/109706216407437239">found something unpleasant under the
rock I&#39;d just turned over</a>:</p>

<blockquote><p>Today I discovered that there appears to be a large scale
stealth web crawler operating out of Microsoft IP space with
the forged user-agent &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X
10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1
Safari/605.1.15&#39;, which I believe is a legitimate UA. Current status:
working out how to block this in Apache .htaccess.</p>
</blockquote>

<p>By the time I noticed it today this spider had made somewhere over
25,000 requests today in somewhat over twelve hours, or at least
with that specific user agent (it&#39;s hard to see if it used other
ones with all of the volume). It made these requests from over 5,800
different IPs; over 600 of these IPs are on the <a href="https://www.spamhaus.org/sbl/query/SBLCSS">SBL CSS</a> and one of them is <a href="https://www.spamhaus.org/sbl/query/SBL545445">SBL
545445</a> (a /32 phish
server). All of these IP addresses are in various networks in
<a href="https://bgp.potaroo.net/cgi-bin/as-report?as=AS8075">Microsoft&#39;s AS 8075</a>, and of course
none of them have reverse DNS. As you can tell from the significant
number of IPs, most IPs do only a few requests and even the active
ones did no more than 20 (today, by the time I cut them off). This
is a volume level that will fly under the radar for anyone&#39;s per-IP
ratelimiting.</p>

<p>(<a href="https://mastodon.social/@ascherbaum/109706281766589128">Another person reported a similar experience including the low
volume per IP</a>.
Also, I assume that there is some Microsoft cloud feature for changing
your outgoing IP all the time that this spider is exploiting, as opposed
to the spider operator having that many virtual machines churning away in
Microsoft&#39;s cloud.)</p>

<p>This spider seems to have only shown up about five or six days ago.
Before then this user agent has no particular prominence in my logs,
but then in the past couple of days it&#39;s go up to almost 50,000
requests a day. At that request volume most of it is spidering or
re-spidering uselessly duplicated content; <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>
doesn&#39;t have that many unique pages.</p>

<p>This user agent is for Safari 15.1, which was released more than a
year ago (apparently <a href="https://support.apple.com/en-us/HT212875">October 27th, 2021</a>, or maybe <a href="https://en.wikipedia.org/wiki/Safari_version_history#Safari_15">a few days
before</a>),
and as such is rather out of date by now. Safari on macOS is up to
<a href="https://en.wikipedia.org/wiki/Safari_version_history#Safari_16">Safari 16</a>,
and Safari 15 was (eventually) updated to 15.6.1. I don&#39;t know why
this spider picked such an out of date user agent to forge, but
it&#39;s convenient; any actual person still running Safari 15.1 needs
to update it anyway to pick up security fixes.</p>

<p>(For the moment, the best I could do with my eccentric setup here
was to block anyone using the user agent. Blocking by IP address
range is annoying, seeing as today&#39;s lot of IP addresses are spread
over 20 /16s.)</p>

<h3>Sidebar: On the forging of user agents</h3>

<p>On the Fediverse, <a href="https://mathstodon.xyz/@nobrowser/109706808857423992">I was asked</a> if it wasn&#39;t
the case that all user-agent strings were forged in some sense,
since these days they&#39;re mostly about a statement of compatibility.
<a href="https://mastodon.social/@cks/109706953317367613">My off the cuff answer</a>
encapsulates something that I want to repeat here:</p>

<blockquote><p>There is a widespread de facto standard that spiders, crawlers, and
other automated agents must report themselves in their user-agent
instead of pretending to be browsers.</p>

<p>To put it one way, humans may impersonate each other, but machines do
not get to impersonate humans. Machines who try to are immediately
assumed to be up to no good, with ample historical reasons to make
such an assumption.</p>
</blockquote>

<p>(See also <a href="https://utcc.utoronto.ca/~cks/space/blog/web/UserAgentContentsView">my views on your <code>User-Agent</code> header should include and
why</a>.)</p>

<p>The other thing about this is that compatibility is a matter for
browsers, not spiders. If your spider claims to be &#39;compatible&#39;
with Googlebot, what you&#39;re really asking for is any special treatment
people give Googlebot.</p>

<p>(<a href="https://utcc.utoronto.ca/~cks/space/blog/web/SpiderUserAgentMaybeTooClever">Sometimes this backfires, if people are refusing things to
Googlebot</a>.)</p>
</div></div>
  </body>
</html>
