<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.ericgoldman.org/archives/2022/06/will-california-eliminate-anonymous-web-browsing-comments-on-ca-ab-2273-the-age-appropriate-design-code-act.htm">Original</a>
    <h1>Will California Eliminate Anonymous Web Browsing? (Comments on CA AB 2273)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Iâ€™m continuing my coverage of dangerous Internet bills in the California legislature. This job is especially challenging during an election year, when legislators rally behind the â€œprotect the kidsâ€ mantra to pursue billsÂ  that are likely to hurt, or at least not help, kids. Todayâ€™s example is <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220AB2273">AB 2273, the Age-Appropriate Design Code Act</a> (AADC),</p>
<p>Before we get overwhelmed by the billâ€™s details, Iâ€™ll highlight three crucial concerns:</p>
<p>First, the bill pretextually claims to protect children, but it will change the Internet for EVERYONE. In order to determine who is a child, websites and apps will have to authenticate the age of ALL consumers before they can use the service. NO ONE WANTS THIS. It will erect barriers to roaming around the Internet. Bye bye casual browsing. To do the authentication, businesses will be forced to collect personal information they donâ€™t want to collect and consumers donâ€™t want to give, and that data collection creates extra privacy and security risks for everyone. Furthermore, age authentication usually also requires identity authentication, and that will end anonymous/unattributed online activity.</p>
<p>Second, even if businesses treated all consumers (i.e., adults) to the heightened obligations required for children, businesses still could not comply with this bill. Thatâ€™s because this bill is based on the U.K. <a href="https://ico.org.uk/for-organisations/guide-to-data-protection/ico-codes-of-practice/age-appropriate-design-code/">Age-Appropriate Design Code</a>. European laws are often aspirational and standards-based (instead of rule-based), because European regulators and regulated businesses engage in dialogues, and the regulators reward good tries, even if they arenâ€™t successful. We donâ€™t do â€œA-for-Effortâ€ laws in the U.S., and generally we rely on rules, not standards, to provide certainty to businesses and reduce regulatory overreach and censorship.</p>
<p>Third, this bill reaches topics well beyond childrenâ€™s privacy. Instead, the bill repeatedly implicates general consumer protection concerns and, most troublingly, content moderation topics. This turns the bill into a trojan horse for comprehensive regulation of Internet services and would turn the privacy-centric California Privacy Protection Agency/CPPA) into the general purpose Internet regulator.</p>
<p>So the big takeaway: this billâ€™s protect-the-children framing is designed to mislead everyone about the billâ€™s scope. The bill will dramatically degrade the Internet experience for everyone and will empower a new censorship-focused regulator who has no interest or expertise in balancing complex and competing interests.</p>
<div id="attachment_23887"><p><a href="https://blog.ericgoldman.org/wp-content/uploads/2022/05/van-on-fire-in-arkansas.gif"><img aria-describedby="caption-attachment-23887" loading="lazy" src="https://blog.ericgoldman.org/wp-content/uploads/2022/05/van-on-fire-in-arkansas.gif" alt="" width="640" height="360"/></a></p><p id="caption-attachment-23887">Click on the image to see the animation</p></div>
<p><strong>What the Bill Says</strong></p>
<p><em>Whoâ€™s Covered</em></p>
<p>The bill applies to a â€œbusiness that provides an online service, product, or feature likely to be accessed by a child.â€ â€œChildâ€ is defined as under-18, so the bill treats teens and toddlers identically.</p>
<p>The phrase â€œlikely to be accessed by a child means it is reasonable to expect, based on the nature of the content, the associated marketing, the online context, or academic or internal research, that the service, product, or feature would be accessed by children.â€ Compare how COPPA handles this issue; it applies when services know (not anticipate) users are under-13 or direct their services to an under-13 audience. In contrast, the bill says that if itâ€™s reasonable to expect ONE under-18 user, the business must comply with its requirements. With that overexpansive framing, few websites and apps can reasonably expect that under-18s will NEVER use their services. Thus, I believe all websites/apps are covered by this law so long as they clear the CPRA quantitative thresholds for being a â€œbusiness.â€ [Note: itâ€™s not clear how this bill situates into the CPRA, but I think the CPRAâ€™s â€œbusinessâ€ definition applies.]</p>
<p><em>Whatâ€™s Required</em></p>
<p>The bill starts with this aspirational statement: â€œCompanies that develop and provide online services, products, or features that children are likely to access should consider the best interests of children when designing, developing, and providing that service, product, or feature.â€ The â€œshould considerâ€ grammar is the kind of regulatory aspiration found in European law. Does this statement have legal consequences or not? I vote it does not because â€œshouldâ€ is not a compulsory obligation. So what is it doing here?</p>
<p>More generally, this provision tries to anchor the bill in the notion that businesses owe a â€œduty of loyaltyâ€ or fiduciary duty to their consumers. This duty-based approach to privacy regulation is trendy in privacy circles, but if adopted, it would exponentially expand regulatory oversight of businessesâ€™ decisions. Regulators (and private plaintiffs) can always second-guess a businessâ€™ decision; a duty of â€œloyaltyâ€ gives the regulators the unlimited power to insist that the business made wrong calls and impose punishments accordingly. We usually see fiduciary/loyalty obligations in the professional services context where the professional service provider must put an individual customerâ€™s needs before its own profit. Expanding this concept to mass-market businesses with millions of consumers would take us into uncharted regulatory territory.</p>
<p>The bill would obligate regulated businesses to:</p>
<ul>
<li>Do data protection impact assessments (DPIAs) for any features likely to be accessed by kids (i.e., all features), provide a â€œreport of the assessmentâ€ to the CPPA, and update the DPIA at least every 2 years.</li>
<li>â€œEstablish the age of consumers with a reasonable level of certainty appropriate to the risks that arise from the data management practices of the business, or apply the privacy and data protections afforded to children to all consumers.â€ As discussed below, this is a poison pill for the Internet. This also exposes part of the true agenda here: if a business canâ€™t do what the bill requires (a common consequence), the bill drives businesses to adopt the most restrictive regulation for everyone, including adults.</li>
<li>Configure default settings to a â€œhigh level of privacy protection,â€ whatever that means. I think this meant to say that kids should automatically get the highest privacy settings offered by the business, whatever that level is, but itâ€™s not what it says. Instead, this becomes an aspirational statement about what constitutes a â€œhigh levelâ€ of protection.</li>
<li>All disclosures must be made â€œconcisely, prominently, and using clear language suited to the age of children likely to accessâ€ the service. The disclosures in play are â€œprivacy information, terms of service, policies, and community standards.â€ Note how this reaches all consumer disclosures, not just those that are privacy-focused. This is the first of several times weâ€™ll see the billâ€™s power grab beyond privacy. Also, if a single toddler is â€œlikelyâ€ to access the service, must all disclosures must be written at toddlersâ€™ reading level?</li>
<li>Provide an â€œobvious signalâ€ if parents can monitor their kidsâ€™ activities online. How does this intersect with COPPA?</li>
<li>â€œEnforce published terms, policies, and community standards established by the business, including, but not limited to, privacy policies and those concerning children.â€ ğŸš¨ This language unambiguously governs all consumer disclosures, not just privacy-focused ones. Interpreted literally, itâ€™s ludicrous to mandate businesses enforce every provision in their TOSes. If a consumer breaches a TOS by scraping content or posting violative content, does this provision require businesses to sue the consumer for breach of contract? More generally, this provision directly overlaps AB 587, which requires businesses to disclose their editorial policies and gives regulators the power to investigate and enforce any perceived or alleged deviations how services moderate content. See <a href="https://blog.ericgoldman.org/archives/2022/06/will-california-clone-and-revise-some-terrible-ideas-from-florida-texas-social-media-censorship-laws-analysis-of-ca-ab587.htm">my excoriation of AB 587</a>. This provision is a trojan horse for government censorship that has nothing to do with protecting the kids or even privacy. Plus, even if it werenâ€™t an unconstitutional provision, the CPPA, with its privacy focus, lacks the expertise to monitor/enforce content moderation decisions.</li>
<li>â€œProvide prominent, accessible, and responsive tools to help children, or where applicable their parent or guardian, exercise their privacy rights and report concerns.â€ Not sure what this means, especially in light of the CPRAâ€™s detailed provisions about how consumers can exercise privacy rights.</li>
</ul>
<p>The bill would also obligate regulated businesses not to:</p>
<ul>
<li>â€œUse the personal information of any child in a way that the business knows or has reason to know the online service, product, or feature more likely than not causes or contributes to a more than de minimis risk of harm to the physical health, mental health, or well-being of a child.â€ This provision cannot be complied with. It appears that businesses must change their services if a single child might suffer any of these harms, which is always? This provision especially seems to target UGC features, where people always say mean things that upset other users. Knowing that, what exactly are UGC services supposed to do differently? I assume the paradigmatic example are the concerns about kidsâ€™ social media addiction, but like the 587 discussion above, the legislature is separately considering an entire bill on that topic (AB 2408), and this one-sentence treatment of such a complicated and censorial objective isnâ€™t helpful.</li>
<li>â€œProfile a child by default.â€ â€œProfileâ€ is not defined in the bill. The term â€œprofileâ€ is used 3x in the CPRA but also not defined. So what does this mean?</li>
<li>â€œCollect, sell, share, or retain any personal information that is not necessary to provide a service, product, or feature with which a child is actively and knowingly engaged.â€ This partially overlaps COPPA.</li>
<li>â€œIf a business does not have actual knowledge of the age of a consumer, it shall not collect, share, sell, or retain any personal information that is not necessary to provide a service, product, or feature with which a consumer is actively and knowingly engaged.â€ Note how the bill switches to the phrase â€œactual knowledgeâ€ about age rather than the threshold â€œlikely to be accessed by kids.â€ This provision will affect many adults.</li>
<li>â€œUse the personal information of a child for any reason other than the reason or reasons for which that personal information was collected. If the business does not have actual knowledge of the age of the consumer, the business shall not use any personal information for any reason other than the reason or reasons for which that personal information was collected.â€ Same point about actual knowledge.</li>
<li>Sell/share a childâ€™s PI unless needed for the service.</li>
<li>â€œCollect, sell, or share any precise geolocation information of children by defaultâ€ unless needed for the serviceâ€“and only if providing â€œan obvious sign to the child for the duration of that collection.â€</li>
<li>â€œUse dark patterns or other techniques to lead or encourage consumers to provide personal information beyond what is reasonably expected for the service the child is accessing and necessary to provide that service or product to forego privacy protections, or to otherwise take any action that the business knows or has reason to know the online service or product more likely than not causes or contributes to a more than de minimis risk of harm to the childâ€™s physical health, mental health, or well-being.â€ No one knows what the term â€œdark patternsâ€ means, and now the bill would also restrict â€œother techniquesâ€ that arenâ€™t dark patterns? Also see my earlier point about the â€œde minimis risk of harmâ€ requirement.</li>
<li>â€œUse any personal information collected or processed to establish age or age range for any other purpose, or retain that personal information longer than necessary to establish age. Age assurance shall be proportionate to the risks and data practice of a service, product, or feature.â€ The bill expressly acknowledges that businesses canâ€™t authenticate age without collecting PIâ€“including PI the business would choose not to collect but for this bill. This is like the CCPA/CPRAâ€™s problems with â€œverifiable consumer requestâ€â€“to verify the consumer, the business has to ask for PI, sometimes more invasively than the PI the consumer is making the request about. Â¯\_(ãƒ„)_/Â¯</li>
</ul>
<p><em>New Taskforce</em></p>
<p>The bill would create a new government entity, the â€œCalifornia Childrenâ€™s Data Protection Taskforce,â€ composed of â€œCalifornians with expertise in the areas of privacy, physical health, mental health, and well-being, technology, and childrenâ€™s rightsâ€ as appointed by the CPPA. The taskforceâ€™s job is â€œto evaluate best practices for the implementation of this title, and to provide support to businesses, with an emphasis on small and medium businesses, to comply with this title.â€</p>
<p>The scope of this taskforce likely exceeds privacy topics. For example, the taskforce is charged with developing best practices for â€œAssessing and mitigating risks to children that arise from the use of an online service, product, or featureâ€â€“this scope isnâ€™t limited to privacy risks. Indeed, it likely reaches servicesâ€™ editorial decisions. The CPPA is charged with constituting and supervising this taskforce even though it lacks expertise on non-privacy-related topics.</p>
<p><em>New Regulations</em></p>
<p>The bill obligates the CPPA to come up with regulations supporting this bill by April 1, 2024. Given the CADOJâ€™s and CPPAâ€™s track record of missing statutorily required timelines for rule-making, how likely is this schedule? ğŸ¤£</p>
<p><strong>Problems With the Bill</strong></p>
<p><i>Unwanted Consequences of Age and Identity Authentication</i>. Structurally, the law tries to sort the online population into kids and adults for different regulatory treatment. The desire to distinguish between children and adults online has a venerable regulatory history. The first Congressional law to crack down on the Internet, the Communications Decency Act, had the same requirement. It was struck down as unconstitutional because of the infeasibility. Yet, after 25 years, <a href="https://www.wsj.com/articles/why-age-verification-is-difficult-for-websites-11645829728">age authentication still remains a vexing technical and social challenge</a>.</p>
<p>Counterproductively, age-authentication processes are generally privacy invasive. There are two primary ways to do it: (1) demand the consumer disclose lots of personal information, or (2) use facial recognition and collect highly sensitive face information (and more). Businesses donâ€™t want to invade their consumersâ€™ privacy these ways, and COPPA doesnâ€™t require such invasiveness either.</p>
<p>Also, itâ€™s typically impossible to do age-authentication without also doing identity-authentication so that the consumer can establish a persistent identity with the service. Otherwise, every consumer (kids and adults) will have to authentication their age each time they access a service, which will create friction and discourage usage. But if businesses authenticate identity, and not just age, then the bill creates even greater privacy and security risks as consumers will have to disclose even more PI.</p>
<p>Furthermore, identity authentication functionally eliminates anonymous online activity and all unattributed activity and content on the Internet. This would hurt many communities, such as minorities concerned about revealing their identity (e.g., LGBTQ), pregnant women seeking information about abortions, and whistleblowers. This also raises obvious First Amendment concerns.</p>
<p><em>Enforcement</em>. The bill doesnâ€™t specify the enforcement mechanisms. Instead, it wades into an obvious and avoidable tension in California law. On the one hand, the CPRA expressly negates private rights of action (except for certain data security breaches). If this bill is part of the CPRAâ€“which the introductory language impliesâ€“then it should be subject to the CPRAâ€™s enforcement limits. CADOJ and CPPA have exclusive enforcement authority over the CPRA, and thereâ€™s no private right of action/PRA. On the other hand, California B&amp;P 17200 allows for PRAs for any legal violation, including violations of other California statutes. So unless the bill is cabined by the CPRAâ€™s enforcement limit, the bill will be subject to PRAs through 17200. So which is it?Â  Â¯\_(ãƒ„)_/Â¯</p>
<p><em>Adding to the CPPAâ€™s Workload.Â </em>The <a href="https://blog.ericgoldman.org/archives/2022/05/my-comments-on-the-california-consumer-privacy-rights-act-cpra-rulemaking.htm">CPPA is already overwhelmed</a>. It canâ€™t make its rule-making deadline of July 1, 2022 (missing it by months). That means businesses will have to comply with the voluminous rules with inadequate compliance time. Once that initial rule-making is done, the CPPA will then have to build a brand-new administrative enforcement function and start bringing, prosecuting, and adjudicating enforcements. That will be another demanding, complex, and time-consuming project for the CPPA. So itâ€™s preposterous that the California legislature would add MORE to the CPPAâ€™s agenda, when it clearly cannot handle the work that the California voters have already instructed it to do.</p>
<p><em>Trade Secret Problems</em>. Requiring businesses to report about their DPIAs for every feature they launch potentially discloses lots of trade secretsâ€“which may blow their trade secret protection. It certainly provides a rich roadmap for plaintiffs to mine.</p>
<p><em>Conflict with COPPA.Â </em>The bill does not provide any exceptions for parental consent to the businessâ€™ privacy practices. Instead, the bill takes power away from parents. Does this conflict with COPPA such that COPPA would preempt it? No doubt the billâ€™s basic scheme rejects COPPAâ€™s parental control model.</p>
<p>Iâ€™ll also note that any PRA may compound the preemption problem. â€œAllowing private plaintiffs to bring suits for violations of conduct regulated by COPPA, even styled in the form of state law claims, with no obligation to cooperate with the FTC, is inconsistent with the treatment of COPPA violations as outlined in the COPPA statute.â€ Hubbard v. Google LLC, 546 F. Supp. 3d 986 (N.D. Cal. 2021).</p>
<p><em>Conflict with CPRAâ€™s Amendment Process. </em>The legislature may amend the CPRA by majority vote only if it enhances consumer privacy rights. As Iâ€™ve <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3896176">explained before</a>, this is a trap because I believe the amendments must <em>uniformly</em> enhance consumer privacy rights. In other words, if some consumers get greater privacy rights, but other consumers get less privacy rights, then the legislature cannot make the amendment via majority vote. In this case, the AADC undermines consumer privacy by exposing both children and adults to new privacy and security risks through the authentication process. Thus, the bill, if passed, could be struck down as exceeding the legislatureâ€™s authority.</p>
<p>In addition, the bill says â€œIf a conflict arises between commercial interests and the best interests of children, companies should prioritizes the privacy, safety, and well-being of children over commercial interests.â€ A reminder of what the CPRA actually says: â€œThe rights of consumers and the responsibilities of businesses should be implemented with the goal of strengthening consumer privacy, while <em>giving attention to the impact on business and innovation</em>.â€ By disregarding the CPRAâ€™s instructions to consider impacts on businesses, this also exceeds the legislatureâ€™s authority.</p>
<p><em>Dormant Commerce Clause</em>. The bill creates numerous potential DCC problems. Most importantly, businesses necessarily will have authenticate the age of all consumers, both in and outside of California. This means that the bill would govern how businesses based outside of California interact with non-Californians, which the DCC does not permit.</p>
<p><strong>Conclusion</strong></p>
<p>Due to its scope and likely impact, this bill is one of the most consequential bills in the California legislature this year. The Internet as we know it hangs in the balance. If your legislator isnâ€™t paying proper attention to those consequences (spoiler: they arenâ€™t), you should give them a call.</p>
<p><strong>Prior CCPA/CPRA Posts</strong></p>
<p>* <a title="Can Facebook Stop Data Snarfers?â€“Meta v. BrandTotal" href="https://blog.ericgoldman.org/archives/2022/06/can-facebook-stop-data-snarfers-meta-v-brandtotal.htm" rel="bookmark">Can Facebook Stop Data Snarfers?â€“Meta v. BrandTotal</a></p>

								
</div></div>
  </body>
</html>
