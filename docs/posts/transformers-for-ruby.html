<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/ankane/transformers-ruby">Original</a>
    <h1>Transformers for Ruby</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">ðŸ™‚ State-of-the-art <a href="https://github.com/huggingface/transformers">transformers</a> for Ruby</p>
<p dir="auto"><a href="https://github.com/ankane/transformers-ruby/actions"><img src="https://github.com/ankane/transformers-ruby/actions/workflows/build.yml/badge.svg" alt="Build Status"/></a></p>

<p dir="auto">First, <a href="https://github.com/ankane/torch.rb#installation">install Torch.rb</a>.</p>
<p dir="auto">Then add this line to your applicationâ€™s Gemfile:</p>


<ul dir="auto">
<li><a href="#models">Models</a></li>
<li><a href="#pipelines">Pipelines</a></li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">sentence-transformers/all-MiniLM-L6-v2</h3><a id="user-content-sentence-transformersall-minilm-l6-v2" aria-label="Permalink: sentence-transformers/all-MiniLM-L6-v2" href="#sentence-transformersall-minilm-l6-v2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="sentences = [&#34;This is an example sentence&#34;, &#34;Each sentence is converted&#34;]

model = Transformers::SentenceTransformer.new(&#34;sentence-transformers/all-MiniLM-L6-v2&#34;)
embeddings = model.encode(sentences)"><pre><span>sentences</span> <span>=</span> <span>[</span><span>&#34;This is an example sentence&#34;</span><span>,</span> <span>&#34;Each sentence is converted&#34;</span><span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>&#34;sentence-transformers/all-MiniLM-L6-v2&#34;</span><span>)</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>)</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">sentence-transformers/multi-qa-MiniLM-L6-cos-v1</h3><a id="user-content-sentence-transformersmulti-qa-minilm-l6-cos-v1" aria-label="Permalink: sentence-transformers/multi-qa-MiniLM-L6-cos-v1" href="#sentence-transformersmulti-qa-minilm-l6-cos-v1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="query = &#34;How many people live in London?&#34;
docs = [&#34;Around 9 Million people live in London&#34;, &#34;London is known for its financial district&#34;]

model = Transformers::SentenceTransformer.new(&#34;sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;)
query_emb = model.encode(query)
doc_emb = model.encode(docs)
scores = Torch.mm(Torch.tensor([query_emb]), Torch.tensor(doc_emb).transpose(0, 1))[0].cpu.to_a
doc_score_pairs = docs.zip(scores).sort_by { |d, s| -s }"><pre><span>query</span> <span>=</span> <span>&#34;How many people live in London?&#34;</span>
<span>docs</span> <span>=</span> <span>[</span><span>&#34;Around 9 Million people live in London&#34;</span><span>,</span> <span>&#34;London is known for its financial district&#34;</span><span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>&#34;sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;</span><span>)</span>
<span>query_emb</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>query</span><span>)</span>
<span>doc_emb</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>docs</span><span>)</span>
<span>scores</span> <span>=</span> <span>Torch</span><span>.</span><span>mm</span><span>(</span><span>Torch</span><span>.</span><span>tensor</span><span>(</span><span>[</span><span>query_emb</span><span>]</span><span>)</span><span>,</span> <span>Torch</span><span>.</span><span>tensor</span><span>(</span><span>doc_emb</span><span>)</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span><span>)</span><span>[</span><span>0</span><span>]</span><span>.</span><span>cpu</span><span>.</span><span>to_a</span>
<span>doc_score_pairs</span> <span>=</span> <span>docs</span><span>.</span><span>zip</span><span>(</span><span>scores</span><span>)</span><span>.</span><span>sort_by</span> <span>{</span> |<span>d</span><span>,</span> <span>s</span>| -<span>s</span> <span>}</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">mixedbread-ai/mxbai-embed-large-v1</h3><a id="user-content-mixedbread-aimxbai-embed-large-v1" aria-label="Permalink: mixedbread-ai/mxbai-embed-large-v1" href="#mixedbread-aimxbai-embed-large-v1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="def transform_query(query)
  &#34;Represent this sentence for searching relevant passages: #{query}&#34;
end

docs = [
  transform_query(&#34;puppy&#34;),
  &#34;The dog is barking&#34;,
  &#34;The cat is purring&#34;
]

model = Transformers::SentenceTransformer.new(&#34;mixedbread-ai/mxbai-embed-large-v1&#34;)
embeddings = model.encode(docs)"><pre><span>def</span> <span>transform_query</span><span>(</span><span>query</span><span>)</span>
  <span>&#34;Represent this sentence for searching relevant passages: <span><span>#{</span><span>query</span><span>}</span></span>&#34;</span>
<span>end</span>

<span>docs</span> <span>=</span> <span>[</span>
  <span>transform_query</span><span>(</span><span>&#34;puppy&#34;</span><span>)</span><span>,</span>
  <span>&#34;The dog is barking&#34;</span><span>,</span>
  <span>&#34;The cat is purring&#34;</span>
<span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>&#34;mixedbread-ai/mxbai-embed-large-v1&#34;</span><span>)</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>docs</span><span>)</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">opensearch-project/opensearch-neural-sparse-encoding-v1</h3><a id="user-content-opensearch-projectopensearch-neural-sparse-encoding-v1" aria-label="Permalink: opensearch-project/opensearch-neural-sparse-encoding-v1" href="#opensearch-projectopensearch-neural-sparse-encoding-v1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docs = [&#34;The dog is barking&#34;, &#34;The cat is purring&#34;, &#34;The bear is growling&#34;]

model_id = &#34;opensearch-project/opensearch-neural-sparse-encoding-v1&#34;
model = Transformers::AutoModelForMaskedLM.from_pretrained(model_id)
tokenizer = Transformers::AutoTokenizer.from_pretrained(model_id)
special_token_ids = tokenizer.special_tokens_map.map { |_, token| tokenizer.vocab[token] }

feature = tokenizer.(docs, padding: true, truncation: true, return_tensors: &#34;pt&#34;, return_token_type_ids: false)
output = model.(**feature)[0]

values, _ = Torch.max(output * feature[:attention_mask].unsqueeze(-1), dim: 1)
values = Torch.log(1 + Torch.relu(values))
values[0.., special_token_ids] = 0
embeddings = values.to_a"><pre><span>docs</span> <span>=</span> <span>[</span><span>&#34;The dog is barking&#34;</span><span>,</span> <span>&#34;The cat is purring&#34;</span><span>,</span> <span>&#34;The bear is growling&#34;</span><span>]</span>

<span>model_id</span> <span>=</span> <span>&#34;opensearch-project/opensearch-neural-sparse-encoding-v1&#34;</span>
<span>model</span> <span>=</span> <span>Transformers</span>::<span>AutoModelForMaskedLM</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_id</span><span>)</span>
<span>tokenizer</span> <span>=</span> <span>Transformers</span>::<span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_id</span><span>)</span>
<span>special_token_ids</span> <span>=</span> <span>tokenizer</span><span>.</span><span>special_tokens_map</span><span>.</span><span>map</span> <span>{</span> |<span>_</span><span>,</span> <span>token</span>| <span>tokenizer</span><span>.</span><span>vocab</span><span>[</span><span>token</span><span>]</span> <span>}</span>

<span>feature</span> <span>=</span> <span>tokenizer</span><span>.</span><span>(</span><span>docs</span><span>,</span> <span>padding</span>: <span>true</span><span>,</span> <span>truncation</span>: <span>true</span><span>,</span> <span>return_tensors</span>: <span>&#34;pt&#34;</span><span>,</span> <span>return_token_type_ids</span>: <span>false</span><span>)</span>
<span>output</span> <span>=</span> <span>model</span><span>.</span><span>(</span>**<span>feature</span><span>)</span><span>[</span><span>0</span><span>]</span>

<span>values</span><span>,</span> <span>_</span> <span>=</span> <span>Torch</span><span>.</span><span>max</span><span>(</span><span>output</span> * <span>feature</span><span>[</span><span>:attention_mask</span><span>]</span><span>.</span><span>unsqueeze</span><span>(</span>-<span>1</span><span>)</span><span>,</span> <span>dim</span>: <span>1</span><span>)</span>
<span>values</span> <span>=</span> <span>Torch</span><span>.</span><span>log</span><span>(</span><span>1</span> + <span>Torch</span><span>.</span><span>relu</span><span>(</span><span>values</span><span>)</span><span>)</span>
<span>values</span><span>[</span><span>0</span>..<span>,</span> <span>special_token_ids</span><span>]</span> <span>=</span> <span>0</span>
<span>embeddings</span> <span>=</span> <span>values</span><span>.</span><span>to_a</span></pre></div>

<p dir="auto">Named-entity recognition</p>
<div dir="auto" data-snippet-clipboard-copy-content="ner = Transformers.pipeline(&#34;ner&#34;)
ner.(&#34;Ruby is a programming language created by Matz&#34;)"><pre><span>ner</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;ner&#34;</span><span>)</span>
<span>ner</span><span>.</span><span>(</span><span>&#34;Ruby is a programming language created by Matz&#34;</span><span>)</span></pre></div>
<p dir="auto">Sentiment analysis</p>
<div dir="auto" data-snippet-clipboard-copy-content="classifier = Transformers.pipeline(&#34;sentiment-analysis&#34;)
classifier.(&#34;We are very happy to show you the ðŸ¤— Transformers library.&#34;)"><pre><span>classifier</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;sentiment-analysis&#34;</span><span>)</span>
<span>classifier</span><span>.</span><span>(</span><span>&#34;We are very happy to show you the ðŸ¤— Transformers library.&#34;</span><span>)</span></pre></div>
<p dir="auto">Question answering</p>
<div dir="auto" data-snippet-clipboard-copy-content="qa = Transformers.pipeline(&#34;question-answering&#34;)
qa.(question: &#34;Who invented Ruby?&#34;, context: &#34;Ruby is a programming language created by Matz&#34;)"><pre><span>qa</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;question-answering&#34;</span><span>)</span>
<span>qa</span><span>.</span><span>(</span><span>question</span>: <span>&#34;Who invented Ruby?&#34;</span><span>,</span> <span>context</span>: <span>&#34;Ruby is a programming language created by Matz&#34;</span><span>)</span></pre></div>
<p dir="auto">Feature extraction</p>
<div dir="auto" data-snippet-clipboard-copy-content="extractor = Transformers.pipeline(&#34;feature-extraction&#34;)
extractor.(&#34;We are very happy to show you the ðŸ¤— Transformers library.&#34;)"><pre><span>extractor</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;feature-extraction&#34;</span><span>)</span>
<span>extractor</span><span>.</span><span>(</span><span>&#34;We are very happy to show you the ðŸ¤— Transformers library.&#34;</span><span>)</span></pre></div>
<p dir="auto">Image classification</p>
<div dir="auto" data-snippet-clipboard-copy-content="classifier = Transformers.pipeline(&#34;image-classification&#34;)
classifier.(URI(&#34;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&#34;))"><pre><span>classifier</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;image-classification&#34;</span><span>)</span>
<span>classifier</span><span>.</span><span>(</span><span>URI</span><span>(</span><span>&#34;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&#34;</span><span>)</span><span>)</span></pre></div>
<p dir="auto">Image feature extraction</p>
<div dir="auto" data-snippet-clipboard-copy-content="extractor = Transformers.pipeline(&#34;image-feature-extraction&#34;)
extractor.(URI(&#34;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&#34;))"><pre><span>extractor</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>&#34;image-feature-extraction&#34;</span><span>)</span>
<span>extractor</span><span>.</span><span>(</span><span>URI</span><span>(</span><span>&#34;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&#34;</span><span>)</span><span>)</span></pre></div>

<p dir="auto">This library follows the <a href="https://huggingface.co/docs/transformers/index" rel="nofollow">Transformers Python API</a>. Only a few model architectures are currently supported:</p>
<ul dir="auto">
<li>BERT</li>
<li>DistilBERT</li>
<li>ViT</li>
</ul>

<p dir="auto">View the <a href="https://github.com/ankane/transformers-ruby/blob/master/CHANGELOG.md">changelog</a></p>

<p dir="auto">Everyone is encouraged to help improve this project. Here are a few ways you can help:</p>
<ul dir="auto">
<li><a href="https://github.com/ankane/transformers-ruby/issues">Report bugs</a></li>
<li>Fix bugs and <a href="https://github.com/ankane/transformers-ruby/pulls">submit pull requests</a></li>
<li>Write, clarify, or fix documentation</li>
<li>Suggest or add new features</li>
</ul>
<p dir="auto">To get started with development:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ankane/transformers-ruby.git
cd transformers-ruby
bundle install
bundle exec rake download:files
bundle exec rake test"><pre>git clone https://github.com/ankane/transformers-ruby.git
<span>cd</span> transformers-ruby
bundle install
bundle <span>exec</span> rake download:files
bundle <span>exec</span> rake <span>test</span></pre></div>
</article></div></div>
  </body>
</html>
