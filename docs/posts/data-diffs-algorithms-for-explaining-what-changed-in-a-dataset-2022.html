<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.marcua.net/2022/02/20/data-diffs-algorithms-for-explaining-what-changed-in-a-dataset.html">Original</a>
    <h1>Data diffs: Algorithms for explaining what changed in a dataset (2022)</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>tl;dr: <a href="#two-ways-to-ask-for-explanations">part 1</a> explains what an explanation algorithm is, and <a href="#an-open-source-implementation-of-diff">part 2</a> describes an open source SQL data differ.</em></p>

<h2 id="why-did-this-happen-what-changed">“Why did this happen?” “What changed?”</h2>

<p>In the data world, most reporting starts by asking <em>how much?</em>: “how many new customers purchase each week?” or “what is the monthly cost of medical care for this group?”</p>

<p>Inevitably the initial reports result in questions about <em>why?</em>: “why did we see less purchases last week?” and “why are the medical costs for this group increasing?”</p>

<p>The academic community has an answer to such <em>why?</em> questions: explanation algorithms. An explanation algorithm looks at columns/properties of your dataset and identifies high-likelihood explanations (called “predicates” in database-speak). For example, the algorithms might find that you got less customers in the segment of people who saw a new marketing campaign, or that the medical costs for the group you’re studying can largely be attributed to costly treatments in a subgroup.</p>

<p>The academic interest is founded in real pain. When a journalist, researcher, or organization asks <em>why?</em>, the resulting data anlysis largely goes into issuing ad hoc GROUP BY queries or unscientifically creating pivot tables to try to slice and dice datasets to explain some change in a dataset over time. Companies like <a href="https://sisudata.com/">Sisu</a> (founded by Peter Bailis, one of the authors of the DIFF paper discussed below) are built on the premise that data consumers are increasingly asking <em>why?</em></p>

<p>You can rephrase lots of different questions in the form of an explanation question. This is an area I’ve been interested in for a while, especially as it might help people like journalists and social scientists better identify interesting trends. In <a href="https://blog.marcua.net/2015/06/02/a-data-differ-to-help-journalists.html">A data differ to help journalists</a> (2015), I said:</p>

<blockquote>
  <p>It would be nice to have a utility that, given two datasets (e.g., two csv files) that are schema-aligned, returns a report of how they differ from one-another in various ways. The utility could take hints of interesting grouping or aggregate columns, or just randomly explore the pairwise combinations of (grouping, aggregate) and sort them by various measures like largest deviation from their own group/across groups.</p>
</blockquote>

<p>At the time of that post, I hadn’t yet connected the dots between the desire for such a system and the active work going on in the research world. Thanks to database researchers, that connection now exists! In this post, I’ll first cover two approaches to explanation algorithms, and then introduce an open source implementation of one of them in my <a href="https://github.com/marcua/datools">datools library</a>.</p>

<h2 id="two-ways-to-ask-for-explanations">Two ways to ask for explanations</h2>

<p>In 2013, Eugene Wu and Sam Madden introduced <a href="http://sirrice.github.io/files/papers/scorpion-vldb13.pdf">Scorpion</a>, a system that explains why an aggregate (e.g., the customer count last week) is higher or lower than other example data. Figure 1 in their paper explains the problem quite nicely. They imagine a user looking at a chart, in this case of aggregate temperatures from a collection of sensors, and highlighting some outliers to ask “compared to the other points on this chart, why are these points so high?”</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.marcua.net/assets/images/diff/scorpion-figure1.png" alt="A figure from the Scorpion paper that shows how a user might highlight outliers on a chart"/></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A figure that shows how a user might highlight outliers on a chart (source: Scorpion paper)</td>
    </tr>
  </tbody>
</table>

<p>Scorpion has two nice properties. First, it operates on aggregates: it’s not until you look at some weekly or monthly statistics that you notice that something is off and search for an explanation. Second, it’s performant on a pretty wide variety of aggregates, with optimizations for the most common ones (e.g., sums, averages, counts, standard deviations). I believe that of all the explanation algorithms, Scorpion pairs the most intuitive phrasing of the question (“why so high/low?”) with the most intuitive experience (highlighting questionable results on a visualization).</p>

<p>The challenge in implementing Scorpion is that, as presented, it does its processing outside of the database that stores the data. Specifically, the way Scorpion partitions and merges subsets of the data to identify an explanation requires decision trees and clustering algorithms that traditionally execute outside of the database<sup id="fnref:madlib" role="doc-noteref"><a href="#fn:madlib" rel="footnote">1</a></sup>. It is also specific to aggregates, which are commonly the source of <em>why</em> questions, but aren’t the only places that question arises.</p>

<p>This is where <a href="http://www.bailis.org/papers/diff-vldb2019.pdf">DIFF</a> comes in. In 2019, Firas Abuzaid, Peter Kraft, Sahaana Suri, Edward Gan, Eric Xu, Atul Shenoy, Asvin Ananthanarayan, John Sheu, Erik Meijer, Xi Wu, Jeff Naughton, Peter Bailis, and Matei Zaharia introduced an explanation algorithm in the form of a database operator called DIFF that can be expressed in SQL. If you’re so inclined, here’s the syntax for the DIFF operator:</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.marcua.net/assets/images/diff/diff-figure1.png" alt="The syntax for the DIFF operator "/></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>The syntax for the DIFF operator (source: DIFF paper)</td>
    </tr>
  </tbody>
</table>

<p>An example with SQL might help in understanding how it works:</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.marcua.net/assets/images/diff/diff-example.png" alt="A simple example of the DIFF operator in action (source: DIFF paper)"/></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A simple example of the DIFF operator in action (source: DIFF paper)</td>
    </tr>
  </tbody>
</table>

<p>In this example, the DIFF operator compares the crash logs of an application from this week to those of last week, considering columns like application version, device, and operating system for an explanation. The most likely explanation happened 20x more this week than last week (<code>risk_ratio = 20.0</code>), and explains 75% of this week’s crashes (<code>support = 75%</code>).</p>

<p>DIFF requires that we do some mental gymnastics to transform “why was X so high?” into “how are these two groups different?”. It also requires the user to wrap their head around statistics like risk ratios and support. In exchange for that mental overhead, DIFF is exciting for its praticality. As the example shows, DIFF’s authors envision it being expressed in SQL, which means it could be implemented on top of most relational databases. While a contribution of the paper is a specialized and efficient implementation of DIFF that databases don’t have today, it can also be implemented entirely in the database as a series of SQL GROUP BY/JOIN/WHERE operators.</p>

<p>If you have a relational database, love SQL, and want to run an explanation algorithim, DIFF is exciting because those three things are all you need. Luckily for you, dear reader, I had a relational database, loved SQL, and wanted to run an explanation algorithm.</p>

<h2 id="an-open-source-implementation-of-diff">An open source implementation of DIFF</h2>
<p>Over the past few months, I’ve been implementing DIFF as a thin Python wrapper that generates the SQL necessary to compute the difference between two schema-aligned queries. <a href="https://github.com/marcua/datools/blob/main/datools/explanations.py">The core of the implementation to do this</a>, including comments, requires a little under 300 lines of code. To see a full example of the tool in action, you can check out this <a href="https://github.com/marcua/datools/blob/main/examples/diff/intel-sensor.ipynb">Jupyter Notebook</a>, but I’ll show snippets below to give you a sense of how it works.</p>

<p>First, we need a dataset. For that, I took inspiration from the Scorpion paper’s experiments, one of which relied on <a href="http://db.csail.mit.edu/labdata/labdata.html">sensor data from Intel</a> collected by my grad school advisor Sam Madden (and a few collaborators). Using Simon Willison’s excellent <a href="https://sqlite-utils.datasette.io/en/stable/">sqlite-utils</a> library, I load the data into SQLite and inspect it:</p>

<div><div><pre><code><span># Retrieve and slightly transform the data</span>
wget http://db.csail.mit.edu/labdata/data.txt.gz
<span>gunzip </span>data.txt.gz
<span>sed</span> <span>-i</span> <span>&#39;1s/^/day time_of_day epoch moteid temperature humidity light voltage\n/&#39;</span> data.txt
<span>head </span>data.txt

<span># Get it in SQLite</span>
pip <span>install </span>sqlite-utils
sqlite-utils insert intel-sensor.sqlite readings data.txt <span>--csv</span> <span>--sniff</span> <span>--detect-types</span>
sqlite-utils schema intel-sensor.sqlite
</code></pre></div></div>

<p>That last <code>sqlite-utils schema</code> shows us what the newly generated <code>readings</code> table looks like:</p>
<div><div><pre><code><span>CREATE</span> <span>TABLE</span> <span>&#34;readings&#34;</span> <span>(</span>
   <span>[</span><span>day</span><span>]</span> <span>TEXT</span><span>,</span>
   <span>[</span><span>time_of_day</span><span>]</span> <span>TEXT</span><span>,</span>
   <span>[</span><span>epoch</span><span>]</span> <span>INTEGER</span><span>,</span>
   <span>[</span><span>moteid</span><span>]</span> <span>INTEGER</span><span>,</span>
   <span>[</span><span>temperature</span><span>]</span> <span>FLOAT</span><span>,</span>
   <span>[</span><span>humidity</span><span>]</span> <span>FLOAT</span><span>,</span>
   <span>[</span><span>light</span><span>]</span> <span>FLOAT</span><span>,</span>
   <span>[</span><span>voltage</span><span>]</span> <span>FLOAT</span>
<span>);</span>
</code></pre></div></div>

<p>OK! So we have a row for each sensor reading, with the <code>day</code> and <code>time_of_day</code> it happened, an <code>epoch</code> to time-align readings from different sensors, a <code>moteid</code> (the ID of the sensor, otherwise known as a mote), and then the types of things that sensors tend to sense: <code>temperature</code>, <code>humidity</code>, <code>light</code>, and <code>voltage</code>.</p>

<p>In the Scorpion paper (Sections 8.1 and 8.4), a user notices that various sensors placed throughout a lab detect too-high temperature values (reading <a href="https://github.com/sirrice/scorpion/blob/ba1af715ebc33bc4c4a63612d63debd8650ee1cf/scorpion/tests/gentestdata.py#L80">the experiment code</a>, this happens in the days between 2004-03-01 and 2004-03-10). A natural question is why this happened. The Scorpion algorithm discovers that <code>moteid = 15</code> (a sensor with ID 15) was having a bad few days.</p>

<p>Can we replicate this result with DIFF? Let’s see! The DIFF implementation is part of a library I’ve been building called <code>datools</code>, which is a collection of tools I use for various data analyses. Let’s install datools:</p>



<p>Now let’s use it!</p>

<div><div><pre><code><span>from</span> <span>sqlalchemy</span> <span>import</span> <span>create_engine</span>
<span>from</span> <span>datools.explanations</span> <span>import</span> <span>diff</span>
<span>from</span> <span>datools.models</span> <span>import</span> <span>Column</span>

<span>engine</span> <span>=</span> <span>create_engine</span><span>(</span><span>&#39;sqlite:///intel-sensor.sqlite&#39;</span><span>)</span>

<span>candidates</span> <span>=</span> <span>diff</span><span>(</span>
        <span>engine</span><span>=</span><span>engine</span><span>,</span>
        <span>test_relation</span><span>=</span><span>&#39;SELECT moteid, temperature, humidity, light, voltage FROM readings WHERE temperature &gt; 100 AND day &gt; &#34;2004-03-01&#34; and day &lt; &#34;2004-03-10&#34;&#39;</span><span>,</span>
        <span>control_relation</span><span>=</span><span>&#39;SELECT moteid, temperature, humidity, light, voltage FROM readings WHERE temperature &lt;= 100 AND day &gt; &#34;2004-03-01&#34; and day &lt; &#34;2004-03-10&#34;&#39;</span><span>,</span>
        <span>on_column_values</span><span>=</span><span>{</span><span>Column</span><span>(</span><span>&#39;moteid&#39;</span><span>),},</span>
        <span>on_column_ranges</span><span>=</span><span>{},</span>
        <span>min_support</span><span>=</span><span>0.05</span><span>,</span>
        <span>min_risk_ratio</span><span>=</span><span>2.0</span><span>,</span>
        <span>max_order</span><span>=</span><span>1</span><span>)</span>
<span>for</span> <span>candidate</span> <span>in</span> <span>candidates</span><span>:</span>
    <span>print</span><span>(</span><span>candidate</span><span>)</span>
</code></pre></div></div>

<p>What’s <code>diff</code> have to say?</p>

<div><div><pre><code><span>Explanation</span><span>(</span><span>predicates</span><span>=</span><span>(</span><span>Predicate</span><span>(</span><span>moteid</span> <span>=</span> <span>15</span><span>),),</span> <span>risk_ratio</span><span>=</span><span>404.8320855614973</span><span>)</span>
<span>Explanation</span><span>(</span><span>predicates</span><span>=</span><span>(</span><span>Predicate</span><span>(</span><span>moteid</span> <span>=</span> <span>18</span><span>),),</span> <span>risk_ratio</span><span>=</span><span>200.5765335449176</span><span>)</span>
</code></pre></div></div>

<p>Wow! <code>moteid = 15</code> is the top predicate that <code>datools.diff</code> identified as being the difference between the <code>test_relation</code> and <code>control_relation</code>! With a <code>risk_ratio = 404.83</code>, we learn that sensor 15 is about 400 times more likely to appear in the set of records with high temperature readings than in the set of records with low temperature readings. Hooray for replicating the Scorpion result! Poor sensor 15!</p>

<p>Let’s break that call to <code>diff</code> down a bit so we understand what’s going on:</p>
<ul>
  <li><code>engine</code>: a <a href="https://www.sqlalchemy.org/">SQLAlchemy</a> engine that’s connected to some database, in this case the SQLite database.</li>
  <li><code>test_relation</code>: the “test set,” which is a query with records that show a particular condition. In our case, it’s the higher-temperature records during the period of interest. This could alternatively be a SQL query for “patients with high medical costs” or “customers who purchased.”</li>
  <li><code>control_relation</code>: the “control set,” which is a query with records that don’t show that particular condition. In our case, it’s the lower-temperature records during the period of interest. This could alternatively be a SQL query for “patients who don’t have high medical costs” or “leads who haven’t purchased.”</li>
  <li><code>on_column_values</code>: these are set-valued columns you want to consider as explanations. In our case, we’re considering the <code>moteid</code> column, so we can identify a specific sensor thats misbehaving.</li>
  <li><code>on_column_ranges</code>: these are range-valued columns you want to consider as explanations. <code>diff</code> will bucket these columns into 15 equi-sized buckets, which works well for continuous variables like <code>{Column(&#39;humidity&#39;), Column(&#39;light&#39;), Column(&#39;voltage&#39;),}</code>. In this example, we don’t provide any (more on why later), but in the Jupyter Notebook, you can see this in action.</li>
  <li><code>min_support</code>: The smallest fraction ([0, 1]) of the test set that the explanation should explain. For example, <code>min_support=0.05</code> says that if an explanation doesn’t include at least 5% of the test set, we don’t want to know about it.</li>
  <li><code>min_risk_ratio</code>: The smallest risk ratio that the explanation should cover. For example, <code>min_risk_ratio=2.0</code> says that if an explanation isn’t at least 2 times as likely to appear in the test set than in the control set, we don’t want to know about it.</li>
  <li><code>max_order</code>: How many columns to consider for a joint explanation. For example, in the Scorpion paper, the authors find that not just sensor 15 (one-column explanation), but sensor 15 under certain light and voltage conditions (three column-explanation), is the best explanation for outlier readings. To analyze three-column explanations, you’d set <code>max_order=3</code>. Sadly and hopefully temporarily, while <code>max_order</code> is the most fun, interesting, and challenging-to-implement parameter of the DIFF paper, <code>datools.diff</code> only supports <code>max_order=1</code> for now.</li>
</ul>

<p>An astute reader will note that I coaxed the results in my example a bit by asking DIFF to consider only <code>moteid</code> explanations (<code>on_column_values={Column(&#39;moteid&#39;),}</code>). The Scorpion paper considers the other columns as well and still gets the strongest signal from <code>moteid</code>. In the <a href="https://github.com/marcua/datools/blob/main/examples/diff/intel-sensor.ipynb">Jupyter Notebook</a>, we dive into this more deeply and run into an issue replicating the Scorpion results with <code>diff</code>. I offer some hypotheses for this in the notebook, but to have a more informed opinion, we’ll have to wait until <code>datools.diff</code> supports <code>max_order &gt; 1</code>.</p>

<h2 id="where-to-go-from-here">Where to go from here?</h2>
<p>Before we go off and celebrate the replication of the Scorpion paper’s findings with the DIFF paper’s algorithm, you should know that it’s not all roses. Luckily, I’m just as excited about improving <code>datools.diff</code> as I was when I first wrote it, so consider the list below to be both limitations of the current version and a roadmap for the library. If you’re curious, <a href="https://github.com/marcua/datools/projects/1">this project board</a> tracks the things I’m working on most actively.</p>

<ul>
  <li><strong>Make <code>diff</code> work on more than just SQLite</strong>. <code>diff</code> generates SQL, and I’d love for that SQL to run on any database. This is largely a matter of improving the test harness to provision other databases and fixing whatever breaks. The next few databases I’m targeting are DuckDB, Postgres, and Redshift, but if you’re interested in collaborating on something else, I’d love to help.</li>
  <li><strong>Support <code>max_order &gt; 1</code></strong>. One of the DIFF paper’s contributions is in how to spar with the combinatorial explosion you encounter in looking for multi-column explanations. I’d love to support at least 2- or 3-column explanations.</li>
  <li><strong>Use <code>diff</code> on more datasets</strong>. If you’ve got a dataset (especially a public one) you’re hoping to try this on, let me know!</li>
  <li><strong>Replicate <code>diff</code> on Scorpion’s analysis after implementing higher-order explanations</strong>. The full Jupyter Notebook shows that <code>diff</code> can’t yet replicate Scorpion’s results when we ask it to consider more columns than <code>moteid</code>. The notebook offers explanations ranging from “DIFF and Scorpion are different algorithms and have different tradeoffs” to “Why are we considering an output measure as an explanation?” I think it’s worth revisiting this after implementing <code>max_order &gt; 1</code>, so that we can see how <code>datools.diff</code> handles more complex explanations.</li>
  <li><strong>Share more about <code>datools</code></strong>. <code>diff</code> is part of the <code>datools</code> package, but I haven’t told you much about <code>datools</code>. Countless words have been spilled about how SQL, despite being here to stay, also has its rough edges. <code>datools</code> smooths some of these rough edges out<sup id="fnref:datools-example" role="doc-noteref"><a href="#fn:datools-example" rel="footnote">3</a></sup>.</li>
</ul>

<h2 id="thank-you">Thank you</h2>
<p><a href="http://www.cs.columbia.edu/~ewu/">Eugene Wu</a> not only introduced me to the concept of explanation algorithms, but also patiently guided me through starts and stops as I tried to implement various papers. <a href="http://www.bailis.org">Peter Bailis</a> not only showed that the need for explanation algorithms is felt broadly, but also supportively contextualized DIFF relative to even more recent state-of-the-art solutions. I’m grateful to both of them for their feedback.</p>





  </div>
</article>

      </div>
    </div></div>
  </body>
</html>
