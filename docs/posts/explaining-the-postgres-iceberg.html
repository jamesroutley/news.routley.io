<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://avestura.dev/blog/explaining-the-postgres-meme">Original</a>
    <h1>Explaining the Postgres iceberg</h1>
    
    <div id="readability-page-1" class="page"><div><p>I spend a significant amount of my time online, and on a regular day,
I am either learning about STEM topics, indulging in memes, or both. On one such day,
I came across a meme that truly caught my attention. It sparked numerous questions above my
head, leading to a moment of deafening silence within me:</p>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%271280%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>I already knew that data
storage and retrieval ain&#39;t ever been one of my strong suits, but after seeing this meme it kind of
made me unsecure as I had basically zero effing clue about a huge portion of it.
I felt the urge that I have to know what this is all about, so I have decided to learn from
multiple sources.</p>
<p>One of the best ways to learn something is to explain it, and this blog post
aims to do exactly that. Let&#39;s review and explain every part of this meme,
while unraveling its meaning and secrets.</p>
<div><h4>CREDITS</h4><p>Shout out to <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/largedatabank">Jordan Lewis</a> (and friends) for
creating this meme. This was initially <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/largedatabank/status/1559651463919452161">published in a tweet on twitter</a>
and then went viral on other social platforms. I&#39;ve personally seen it on a Telegram group,
and didn&#39;t know about the origin of it while I was writing this blog post until I&#39;ve
finished writing about the half of it.</p></div>
<div><h4>ATTENTION</h4><p>The meme is called &#34;The SQL Iceberg&#34; and it is a general SQL meme, not a
PostgreSQL one. However, as we want to analyze it while wearing our PostgreSQL hat, I think
it is safe to title this post &#34;Explaining The Postgres Meme&#34;, because it is hard
to target all or even major database management systems in one blog post for such a
highly detailed photo.
The creators of this meme happen to be the developers of CockroachDB, which is a
<a target="_blank" rel="noopener noreferrer" href="https://www.cockroachlabs.com/docs/stable/postgresql-compatibility">highly compatible database with PostgreSQL</a>,
so we are probably not much far from what they had in mind when creating this meme.</p><p>EDIT: Midway through writing this blog post, I discovered the origin of this meme
and watched the creator&#39;s explanations. It seems that the content of this post aligns
closely with the creator&#39;s intentions.</p></div>
<h2 id="levels"><a href="#levels" aria-hidden="true" tabindex="-1"><span></span></a>Levels</h2>
<p>Let&#39;s name each level in the meme:</p>
<ul>
<li><a href="#level-0-sky-zone">Level 0: Sky Zone</a>: <code>CREATE TABLE</code>, <code>JOIN</code>, <code>NULL</code>, ...</li>
<li><a href="#level-1-surface-zone">Level 1: Surface Zone</a>: ACID, outer joins, normal forms, ...</li>
<li><a href="#level-2-sunlight-zone">Level 2: Sunlight Zone</a>: Connection pools, LATERAL Join, Stored Procedures, ...</li>
<li><a href="#level-3-twilight-zone">Level 3: Twilight Zone</a>: Isolation levels, ZigZag Join, Triggers, ...</li>
<li><a href="#level-4-midnight-zone">Level 4: Midnight Zone</a>: Denormalization, <code>SELECT FOR UPDATE</code>, star schemas, ...</li>
<li><a href="#level-5-abyssal-zone">Level 5: Abyssal Zone</a>: <code>MATCH PARTIAL</code> foreign keys, <code>null::jsonb IS NULL = false</code>, ...</li>
<li><a href="#level-6-hadal-zone">Level 6: Hadal Zone</a>: volcano model, join ordering is NP Hard, ...</li>
<li><a href="#level-7-pitch-black-zone">Level 7: Pitch Black Zone</a>: <code>NULL</code>, the halloween problem, fsyncgate, ...</li>
</ul>
<h2 id="level-0-sky-zone"><a href="#level-0-sky-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 0: Sky Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27152%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Sky Zone! These are the very high level concepts which everyone seem to have
encountered while working with Relational Database Management Systems like PostgreSQL.
Without any further ado, let&#39;s get into the topics on the sky level.</p>
<h3 id="data-types"><a href="#data-types" aria-hidden="true" tabindex="-1"><span></span></a>Data Types</h3>
<p>PostgreSQL supports a large number of different data types varying from
numeric, monetary, arrays, json, and xml to things like geometric, network address,
and composite types. Here is <a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/docs/current/datatype.html">a long list of supported data types is PostgreSQL</a>.</p>
<p>This query shows the types that are interesting to an application developer.
It results <strong>87</strong> different data types on PostgreSQL version 14.1:</p>

<p>As an example, if you want to store the audit logs of the actions done by admin users and
need to store their IPs, you can use the <code>inet</code> type in PostgreSQL instead of storing it as <code>text</code>.
This will help you to store those data more efficiently, and validate them more easily, compared
to a system that doesn&#39;t support such a type (e.g. Sqlite).</p>
<h3 id="create-table"><a href="#create-table" aria-hidden="true" tabindex="-1"><span></span></a><code>CREATE TABLE</code></h3>
<p>SQL (Structured Query Language) is composed of several areas, and each of them has a specific
sub-language.</p>
<p>One of these sub-languages is called <strong>DDL</strong> which stands for <em>data definition language</em>. It consists of
statements like <code>CREATE</code>, <code>ALTER</code>, and <code>DROP</code>, which are used to defined on-disk data structures.</p>
<p>Here is an example of a create table query:</p>

<p>This will create an <code>audit_log</code> table with columns such as <code>id</code>, <code>ip</code>, <code>action</code>, etc.</p>
<h3 id="select-insert-update-delete"><a href="#select-insert-update-delete" aria-hidden="true" tabindex="-1"><span></span></a><code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code></h3>
<p><strong>DML</strong> is another one of SQL sub-languages and stands for <em>data manipulation language</em>. It
covers the <code>insert</code>, <code>update</code>, and <code>delete</code> statements which are used to feed data into the
database system.</p>
<p><code>select</code> also helps us to retrieve data from the database. This is probably one of the simplest
select queries in SQL:</p>

<p>Here are some of the examples of such DML queries:</p>

<p>The <code>table table_name</code> command can also be used to select an entire table. This sql command:</p>

<p>is equivalent to</p>

<h3 id="order-by"><a href="#order-by" aria-hidden="true" tabindex="-1"><span></span></a><code>ORDER BY</code></h3>
<p>SQL does not guarantee any kind of ordering of the result set of any query, unless you specify an
<code>order by</code> clause.</p>

<h3 id="limit-and-offset"><a href="#limit-and-offset" aria-hidden="true" tabindex="-1"><span></span></a><code>LIMIT</code> and <code>OFFSET</code></h3>
<p><code>LIMIT</code> and <code>OFFSET</code> allow you to retrieve just a portion of the rows that are generated
by the rest of the query. The below query returns audit logs number 100 to 109:</p>

<div><h4>Beware: This method for pagination might be slow!</h4><p>In many cases, using offset will slow down the performance of your query as the database
must count all rows from the beginning until it reaches the requested page. For more information,
read the <a href="#keyset-pagination">Keyset pagination</a> section.</p></div>
<h3 id="group-by"><a href="#group-by" aria-hidden="true" tabindex="-1"><span></span></a><code>GROUP BY</code></h3>
<p>The <code>group by</code> clause introduces <em>Aggregates</em> (aka Map/Reduce) in PostgreSQL, which enables us to
map our rows into different groups and then reduce the result set into a single value.</p>
<p>Assuming we have a <code>Student</code> table definition with <code>id</code>, <code>class_no</code> and <code>grade</code> columns, we can
find the average grade of each class using this query:</p>

<p>Note that the <code>Student</code> table defined this way for demonstration purposes only.</p>
<h3 id="null"><a href="#null" aria-hidden="true" tabindex="-1"><span></span></a><code>NULL</code></h3>
<p>In PostgreSQL, <code>NULL</code> means <em>undefined</em> value, or simply not knowing the value, rather than the absence of a value.
That is why <code>true = NULL</code>, <code>false = NULL</code>, and <code>NULL = NULL</code> checks all result in a <code>NULL</code>.</p>

<h3 id="indexes"><a href="#indexes" aria-hidden="true" tabindex="-1"><span></span></a>Indexes</h3>
<p>When used correctly, Indexes in PostgreSQL allow you to access your data much faster
because they prevent the need for a sequential scan when an index is present.
Additionally, certain constraints like <code>PRIMARY KEY</code> and <code>UNIQUE</code> are only possible
using a backing index.</p>
<p>Here is a simple query to create an index on <code>last_name</code> column of <code>student</code> table
using <code>GiST</code> method.</p>



<h3 id="join"><a href="#join" aria-hidden="true" tabindex="-1"><span></span></a><code>JOIN</code></h3>
<p>Queries can access multiple tables at once, or access the same table in such a way that multiple
rows of the table are being processed at the same time. Queries that access multiple tables
(or multiple instances of the same table) at one time are called join queries.</p>
<p>We can also see joins as a way to craft new <em>Relations</em> from a pair of existing ones. A
<em>relation</em> in PostgreSQL is a set of data having a common set of properties.</p>
<p>The simple query below retrieves the admin user with its role name:</p>

<p>There are multiple kinds of joins, including but not limited to:</p>
<ul>
<li><strong>Inner Joins</strong>: Only keep the rows that satisfy the join condition for both side of involved relations (left and right).</li>
<li><strong>Left/Right/Full Outer Joins</strong>: Retrieve all records from table even for those with no matching value in either left, right, or both side of the relations.</li>
<li><strong>Cross Join</strong>: A cartesian product of left and right relations, giving all the possible combinations from the left table rows
joined with the right table rows.</li>
</ul>
<p>There are also some other types of joins which we will discuss in deeper levels.</p>
<h3 id="foreign-keys"><a href="#foreign-keys" aria-hidden="true" tabindex="-1"><span></span></a>Foreign Keys</h3>
<p>Foreign key constraints help you to maintain the <em>referential integrity</em> of your data.
Assuming you have <code>Author</code> and <code>Book</code> tables, you can reference Author from the Book
table, and PostgreSQL will make sure that the referencing author exists in the Author table
when inserting a row into the Book table:</p>

<p>PostgreSQL enforces the presence of either a <code>unique</code> or <code>primary key</code> constraint on the
target column of the target table.</p>
<h3 id="orms"><a href="#orms" aria-hidden="true" tabindex="-1"><span></span></a>ORMs</h3>
<p>Object-relational Mapping (ORM, O/RM, and also known as O/R Mapping tool) is a technique for
mapping data to and from relational databases and an object-oriented programming
language. ORMs help programmer to interact and alter the data within the database
using the language constructs defined in an object-oriented programming language.
In other words, ORM acts as a bridge between the object-oriented world, and the mathematical
relational world.</p>

<h2 id="level-1-surface-zone"><a href="#level-1-surface-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 1: Surface Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27152%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Surface Zone! Now that we have got past the sky level, we can get familiar with
some of the more advanced features and concepts and dive deeper into the fundamental
components and functionalities of PostgreSQL .
These topics will give you a solid grounding and understanding of the database system.</p>
<h3 id="transactions"><a href="#transactions" aria-hidden="true" tabindex="-1"><span></span></a>Transactions</h3>
<p>A transaction turns a bundle of steps/actions into a single &#34;all or nothing&#34; operation.
The intermediate steps are not visible to other concurrently running transactions.
Generally speaking, a transaction represents any change in a database.</p>
<p>In PostgreSQL, a transaction is surrounded by <code>BEGIN</code> and <code>COMMIT</code> commands.
PostgreSQL treats every SQL statement as being executed within a transaction.
If you do not issue a <code>BEGIN</code> command, then each individual statement has an implicit <code>BEGIN</code>
and (if successful) <code>COMMIT</code> wrapped around it. The below example
shows transferring of a coin from Player1 to Player2 in the database of a video game server
(the example is oversimplified):</p>

<p>Here we want to make sure that either all the updates are applied to database, or none of
them happen. We do not want a system failure decrease coins from Player1, but no coin is added
to Player2&#39;s inventory. Grouping a set of operations into a transaction gives us such
guarantee.</p>
<h3 id="acid"><a href="#acid" aria-hidden="true" tabindex="-1"><span></span></a>ACID</h3>
<p>ACID is an acronym for Atomicity, Consistency, Isolation, and Durability. These are
a set of properties of database transactions intended to guarantee data
validity despite errors, power failures, and other mishaps.</p>
<p>A database transaction should be ACID by definition:</p>
<ul>
<li><strong>Atomicity:</strong> A transaction must either be complete in its entirety, or have no effect.  Atomicity
guarantees that each transaction is treated as a single &#34;unit&#34;.</li>
<li><strong>Consistency:</strong> Ensures that a transaction can only bring the database
from one consistent state to another, and prevent database corruption by an illegal transaction.
As an example, a transaction should not allow a <code>NOT NULL</code> column to have a <code>NULL</code> value after a <code>COMMIT</code>.</li>
<li><strong>Isolation:</strong> Transactions are often executed concurrently (multiple reads and writes at a time).
As we have stated in the previous section, the intermediate steps are not visible to other
concurrently running transactions, which means a concurrently executed transaction shouldn&#39;t
have a different result compared to when the transactions were executed sequentially.</li>
<li><strong>Durability:</strong> The database management system is not allowed to miss any committed transaction
after a restart or any kind of crash. All the committed transactions should be written on
non-volatile memory.</li>
</ul>
<h3 id="query-plans-and-explain"><a href="#query-plans-and-explain" aria-hidden="true" tabindex="-1"><span></span></a>Query plans and EXPLAIN</h3>
<p>Every database system needs a <em>planner</em> to create a <em>query plan</em> out of your SQL queries.
A good query planner is critical for good performance. In PostgreSQL, the <code>EXPLAIN</code> command is
used to know what query plan is created for the input query.</p>

<p>For a more complex query like this:</p>

<p>We get more information on things like how is PostgreSQL trying to find the record
(using a sequential scan or hash, etc), costs, timing, and performance information.
Below information is obtained using <code>EXPLAIN ANALYZE</code> command. Using <code>ANALYSE</code> option alongside
<code>EXPLAIN</code> shows the exact row counts and true run time along with estimates provided by the
<code>EXPLAIN</code>:</p>

<table><thead><tr><th>#</th><th>Node</th><th>Timings</th><th></th><th>Rows</th><th></th><th></th><th>Loops</th><th></th></tr></thead><tbody><tr><td></td><td></td><td>Exclusive</td><td>Inclusive</td><td>Rows X</td><td>Actual</td><td>Plan</td><td></td><td></td></tr><tr><td></td><td>1.</td><td>Hash Inner Join (cost=18.1..55.28 rows=648 width=202) (actual=0.019..0.022 rows=3 loops=1) Hash Cond: ((w.city)::text = (c.name)::text)</td><td>0.007 ms</td><td>0.022 ms</td><td>↑ 216</td><td>3</td><td>648</td><td>1</td></tr><tr><td></td><td>2.</td><td>Seq Scan on weather as w (cost=0..13.6 rows=360 width=186) (actual=0.008..0.008 rows=3 loops=1)</td><td>0.008 ms</td><td>0.008 ms</td><td>↑ 120</td><td>3</td><td>360</td><td>1</td></tr><tr><td></td><td>3.</td><td>Hash (cost=13.6..13.6 rows=360 width=194) (actual=0.007..0.007 rows=3 loops=1) Buckets: 1024 Batches: 1 Memory Usage: 9 kB</td><td>0.003 ms</td><td>0.007 ms</td><td>↑ 120</td><td>3</td><td>360</td><td>1</td></tr><tr><td></td><td>4.</td><td>Seq Scan on city as c (cost=0..13.6 rows=360 width=194) (actual=0.003..0.004 rows=3 loops=1)</td><td>0.004 ms</td><td>0.004 ms</td><td>↑ 120</td><td>3</td><td>360</td><td>1</td></tr></tbody></table>
<p>If you have pgAdmin installed, it can show you a graphical output as well:</p>
<p><img src="http://ablwr.github.io/static/images/posts/postgres-meme/explain-plan.svg" alt="Explain Plan from pgAdmin"/></p><h3 id="inverted-indexes"><a href="#inverted-indexes" aria-hidden="true" tabindex="-1"><span></span></a>Inverted Indexes</h3>
<p>An inverted index is an index structure storing a set of <code>(key, posting list)</code> pairs, where
<em>posting list</em> is a set of row IDs in which the key occurs.</p>
<p>Inverted indexes are used when we want to index composite values (called an <em>item</em>), where each
element value in the item is a key. As an example, a document is an item, and the word we&#39;re
searching for inside the document is the key.</p>
<p><img maxwidth="400" src="http://ablwr.github.io/static/images/posts/postgres-meme/inverted-index.svg" alt="Explain Plan from pgAdmin"/></p><p>PostgreSQL supports GIN, which stands for Generalized Inverted Index.
GIN is generalized in the sense that the GIN access method code does not need to know
the specific operations that it accelerates.</p>

<p>There are many ways in which one can implement pagination to read only a portion of
the rows from the database. As we have suggested in the <code>OFFSET</code>/<code>LIMIT</code> section,
in many cases using offset will slow down the performance of your query as the database
must count all rows from the beginning until it reaches the requested page. One way to
overcome this is to use the Keyset pagination:</p>

<p>Here instead of skipping records, we simply use <code>keyset_column &gt; x</code> where <code>x</code> is the last record
from the previous page we have fetched.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://use-the-index-luke.com/sql/partial-results/fetch-next-page">Paging Through Results by Markus Winand</a></li>
</ul>
<h3 id="computed-columns"><a href="#computed-columns" aria-hidden="true" tabindex="-1"><span></span></a>Computed Columns</h3>
<p>A computed or a generated column in a table is a column which its value is a function of
other column in the same row. In other words, a computed column for columns is what a view
is for tables. The value of a
computed column can be read, but it can not be directly written.
A computed/generated column is defined using <code>GENERATED ALWAYS AS</code> in PostgreSQL:</p>

<h3 id="stored-columns"><a href="#stored-columns" aria-hidden="true" tabindex="-1"><span></span></a>Stored Columns</h3>
<p>A generated column can either be <code>stored</code> or <code>virtual</code>:</p>
<ul>
<li>Stored: computed when it is written (inserted or updated) and occupies storage as if it were a normal column</li>
<li>Virtual: occupies no storage and is computed when it is read</li>
</ul>
<p>Thus, a virtual generated column is similar to a view and a stored generated
column is similar to a materialized view (except that it is always updated automatically).</p>
<p>If you have tried the previous query you might have faced an error. This is because at
the time of writing this post PostgreSQL only implements stored generated columns, therefore
you need to mark the column using <code>STORED</code>:</p>

<h3 id="order-by-aggregates"><a href="#order-by-aggregates" aria-hidden="true" tabindex="-1"><span></span></a><code>ORDER BY</code> Aggregates</h3>
<p>An aggregate function computes a single result from a set of input values. Some of the most
famous aggregate functions are <code>min</code>, <code>max</code>, <code>sum</code>, and <code>avg</code> which are used to calculate
minimum, maximum, sum, and the average of a set of results. The query below calculates
the average of high and low temperatures from the weather records in the weather table:</p>

<p>The input of some aggregate functions are introduced by <code>ORDER BY</code>.
These functions are sometimes referred to as “inverse distribution” functions. As an
example, the below query shows the median rank of all players for each game server:</p>

<h3 id="window-functions"><a href="#window-functions" aria-hidden="true" tabindex="-1"><span></span></a>Window Functions</h3>
<p>Window Functions are very powerful tools that let you process several values of the result set
at a time. This might be similar to what we can achieve with aggregate functions,
however, window functions do not cause rows to become grouped into a single output
row like non-window aggregate calls would.</p>
<p>A window function call always contains an <code>OVER</code> clause directly following the
window function&#39;s name and argument(s):</p>

<p>When using Window Functions, understanding the concept of <strong>window frame</strong> is necessary.
For each row, there is a set of rows within its partition called its window frame.
Some window functions act only on the rows of the window frame, rather than of the whole partition.</p>
<p>In general, these are the window frame rules of thumb:</p>
<ul>
<li>If <code>ORDER BY</code> is supplied then the frame consists of all rows from the start of the partition up through the current row (plus any following rows that are equal to the current row according to the <code>ORDER BY</code> clause)</li>
<li>When <code>ORDER BY</code> is omitted the default frame consists of all rows in the partition</li>
</ul>


<h3 id="outer-joins"><a href="#outer-joins" aria-hidden="true" tabindex="-1"><span></span></a>Outer Joins</h3>
<p>As we have mentioned earlier, an outer join retrieve all records from table even for
those with no matching value in either left, right, or both side of the relations.</p>

<p>Above query shows a left outer join because the table mentioned on the left
of the join operator (weather) will have each of its rows at least once in the output,
whereas the table on the right (cities) will only have those rows that match a row on
the left table.</p>
<p>In PostgreSQL, <code>left outer join</code>, <code>right outer join</code>, and <code>full outer join</code> are used to do outer joins.</p>
<h3 id="ctes"><a href="#ctes" aria-hidden="true" tabindex="-1"><span></span></a>CTEs</h3>
<p><code>WITH</code> queries, or Common Table Expressions (CTEs) can be thought of as defining
temporary tables that exist just for one query. Using a <code>WITH</code> clause, we can define an
auxiliary statement which can be attached to a primary statement.</p>
<p>In the query below, we first define two auxiliary tables called <code>hottest_weather_of_city</code>, and
<code>not_so_hot_cities</code>, and then we use them in the primary <code>select</code> query:</p>

<p>In short, Common Table Expressions is just another name for <code>WITH</code> clauses.</p>
<h3 id="normal-forms"><a href="#normal-forms" aria-hidden="true" tabindex="-1"><span></span></a>Normal Forms</h3>
<p>Database normalization is the process of structuring a relational database in accordance
with a series of so-called normal forms to reduce data redundancy and improve data integrity.</p>
<p>There are several levels of normalization, and a higher level of database normalization
cannot be achieved unless the previous levels have been satisfied.</p>
<p>Here are some of the normal forms:</p>
<ul>
<li><strong>1NF:</strong> Columns cannot contain relations or composite values (each cell is single-values),
and there are no duplicated rows in the table</li>
<li><strong>2NF:</strong> Non-key columns are dependent on all of the key (it should not be dependent on a part of the composite key).
In other words, there are no partial dependencies.</li>
<li><strong>3NF:</strong> Table has no transitive dependencies.</li>
</ul>
<p>Other normals forms like EKNF, BCNF, 4NF, 5NF, DKNF, and 6NF are not covered in this blog post.
You can read more about them at <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Database_normalization#Normal_forms">the Wikipedia page of normal forms</a>.</p>
<h2 id="level-2-sunlight-zone"><a href="#level-2-sunlight-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 2: Sunlight Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27177%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Sunlight Zone! As we descend further, we&#39;ll explore more advanced
features and techniques in PostgreSQL. Get ready to bask in the glow of knowledge
and expand your database skills.</p>
<h3 id="connection-pools"><a href="#connection-pools" aria-hidden="true" tabindex="-1"><span></span></a>Connection Pools</h3>
<p>Connecting to a database server consists of several time-consuming steps (create a socket, initial handshake, parse connection string, authentication, etc).
Connection pools are a way to further improve performance by pooling users’ connections
to a database. The idea is to decrease the total number of connections that must be opened.
Whenever a client wants to connect to the database, an open connection from the pool is reused
instead of creating a new one.</p>
<p><img src="http://ablwr.github.io/static/images/posts/postgres-meme/connection-pool.svg" alt="Explain Plan from pgAdmin"/></p><p>There are many tools and libraries for different programming languages which can help
you create connection pools, as well as server-side connection pooling software
that works for all connection types, not just within a single software stack.
You can create or debug connection pools with tools like Amazon RDS Proxy, <code>pgpool</code>, <code>pgbouncer</code>, <code>pg_crash</code>, etc.</p>
<h3 id="the-dual-table"><a href="#the-dual-table" aria-hidden="true" tabindex="-1"><span></span></a>The DUAL Table</h3>
<p>The DUAL table is a single-row single-column dummy table which was initially added
as an underlying object in the Oracle database systems by Charles Weiss. This table is used
for situations when you want to <code>select</code> something but no <code>from</code> clause is needed.
In Oracle, <code>FROM</code> clause is mandatory, so you would need the <code>dual</code> table. However, in PostgreSQL, creating
such table is not required as you can <code>select</code> without a <code>from</code> clause.</p>

<p>That being said, this table can be created in postgres as a view to ease porting problems
from Oracle to PostgreSQL.
This allows code to remain somewhat compatible with Oracle SQL without annoying the
Postgres parser:</p>

<h3 id="lateral-joins"><a href="#lateral-joins" aria-hidden="true" tabindex="-1"><span></span></a>LATERAL Joins</h3>
<p>PostgreSQL added the LATERAL join technique since PostgreSQL 9.3. Using lateral joins, you can
look at the left hand table:</p>

<p>In the above query, the inner subquery became a <em>correlated subquery</em> to the outer <code>select</code> query.
Without lateral, each subquery is evaluated independently and as a result, cannot cross-reference any
other <code>FROM</code> item. You would get this error if you haven&#39;t used <code>LATERAL</code>:</p>

<h3 id="recursive-ctes"><a href="#recursive-ctes" aria-hidden="true" tabindex="-1"><span></span></a>Recursive CTEs</h3>
<p><code>WITH</code> clauses can be used with the optional <code>RECURSIVE</code> option.
This modifier changes <code>WITH</code> from a mere syntactic convenience into a feature that accomplishes
things not otherwise possible in standard SQL. Using <code>RECURSIVE</code>, a <code>WITH</code> query can refer to its own output.
The below query creates the fibonacci sequence:</p>

<h3 id="orms-create-bad-queries"><a href="#orms-create-bad-queries" aria-hidden="true" tabindex="-1"><span></span></a>ORMs create bad queries</h3>
<p>As mentioned in previous sections, ORMs are essentially abstractions built on top of SQL
to simplify interactions with your database. Some people use ORMs to write code
using the language structures provided by their programming language, rather than
crafting SQL queries themselves. The ORM serves as a layer between the relational
database and the application, generating the necessary queries.</p>
<p>On the downside, ORMs abstract away database features, can be more challenging
to debug than raw queries, and occasionally generate suboptimal queries that are
significantly slower than well-written SQL for the same task. One well-known issue
is the N+1 query problem.</p>
<p>Let&#39;s assume we want to retrieve a blog post along with its comments. A common mistake
we often encounter is the N+1 query problem:
One <code>select</code> query to fetch the post and n additional queries to select
comments for each post (n + 1 queries in total). This is easy
to fix in raw SQL with a simple join. However, when using an ORM, you have less control
on the generated queries, and it can sometimes be challenging to determine
whether you&#39;ve encountered this problem or not without using a profiler:</p>

<h3 id="stored-procedures"><a href="#stored-procedures" aria-hidden="true" tabindex="-1"><span></span></a>Stored Procedures</h3>
<p>Stored procedures are server-side procedures with names that are typically written in
various languages, with SQL being the most common. The following displays the definition
of a procedure in SQL:</p>

<p>Stored procedures are invoked using the <code>CALL</code> statement:</p>

<p>One distinguishing feature of PostgreSQL compared to other database systems is that
it allows you to write your procedures in any programming language you prefer. This is
in contrast to most database engines that restrict you to using only a
predefined set of languages.</p>
<p>Additional languages can be easily integrated into the PostgreSQL server
using the <code>CREATE LANGUAGE</code> command:</p>

<p>Functions are a concept similar to stored procedures, but they are distinct entities. Traditionally, people used the term &#34;Stored Procedure&#34; to refer to both, but there are differences between them. One key distinction is that functions can return values, whereas stored procedures do not. However, this is not the only difference.</p>
<p>One of the most significant differences between stored procedures and functions is
that functions can be used within a <code>SELECT</code> statement, but they cannot start or commit
transactions:</p>

<p>On the other hand, stored procedures can start and commit transactions, but they can not be used
inside select statements.</p>

<p>In short:</p>
<ul>
<li>Functions have return values, but stored procedures do not.</li>
<li>Functions can be used in <code>select</code> statements, but stored procedures do not.</li>
<li>Functions can not start or commit transactions, but stored procedures can.</li>
</ul>
<p>There&#39;s also a concept called <code>Trigger Functions</code>, but we will talk about them when we&#39;re
deeper in the ocean!</p>
<h3 id="cursors"><a href="#cursors" aria-hidden="true" tabindex="-1"><span></span></a>Cursors</h3>
<p>The idea behind <code>CURSOR</code> is that the data is generated only when needed (via a <code>FETCH</code>).
This mechanism allows us to consume the result set while the database is generating
the results. In contrast, it avoids waiting for the database engine to complete its
work and send all the results at once:</p>


<h3 id="there-are-no-non-nullable-types"><a href="#there-are-no-non-nullable-types" aria-hidden="true" tabindex="-1"><span></span></a>There are no non-nullable types</h3>
<p>As mentioned previously, SQL&#39;s <code>null</code> is a marker, not a value.
SQL <code>null</code> means unknown, and not having nullable types means we can control the
nullability of columns solely through the use of <code>not null</code> check constraints.</p>
<p>This approach results in flexible data types where any user of the database can input data into the system,
even if the data for a column with such a data type is missing or unknown.</p>
<p>PostgreSQL permits the creation of user-defined types using <code>CREATE TYPE</code>, and it&#39;s
possible to specify a default for the data type in case a user desires columns of that
data type to default to something other than a <code>null</code> value. However, it remains
valid to set the column value to <code>null</code> if there are no <code>not null</code> check constraints defined.</p>
<h3 id="optimizers-dont-work-without-table-statistics"><a href="#optimizers-dont-work-without-table-statistics" aria-hidden="true" tabindex="-1"><span></span></a>Optimizers don&#39;t work without table statistics</h3>
<p>As previously mentioned, PostgreSQL strives to generate an optimal execution
plan for your SQL queries. Various plans can produce the same result set, but a
well-designed planner/optimizer can produce a faster and more efficient execution plan.</p>
<p>Query optimization is an art of science, and in order to come up with a good plan, PostgreSQL
needs data. PostgreSQL uses a <em>cost-based optimizer</em> which utilizes data statistics, not static rules.
The planner/optimizer <em>estimates</em> the cost of each step in the plan, and picks a plan that
has the least cost for the system.
Additionally, PostgreSQL switches to a <em>Genetic Query Optimizer</em> when the number
of joins exceeds a defined threshold (set by the <code>geqo_threshold</code> variable).
This is because among all relational operators, joins are often the most complex
and challenging to process and optimize.</p>
<p>As a result, PostgreSQL is equipped with a <em>cumulative statistics system</em> which collects and
reports information related to the database server activities. These statistics can come in
handy for the optimizer. You can read more about the statistics that PostgreSQL collect at
<a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/docs/current/monitoring-stats.html">The Cumulative Statistics System</a>.</p>
<h3 id="plan-hints"><a href="#plan-hints" aria-hidden="true" tabindex="-1"><span></span></a>Plan hints</h3>
<p>As we already know, PostgreSQL does its best to come up with a good plan execution using
statistics, estimates, and guessing. While this approach is generally effective for
optimizing user queries, there are situations where users may want to provide
hints to the database engine to manually influence certain decisions in execution plans.</p>
<p>These hints can make their way to the planner/optimizer using approaches like
the <code>pg_hint_plan</code> project and adding SQL Comments before the queries:</p>

<p>The comment <code>/*+ SeqScan(users) */</code> instructs the planner to utilize a sequential
scan when searching for items in the &#34;users&#34; table. Similarly, hints for joins can
be provided using <code>HashJoin(weather city)</code> syntax within the comment.</p>
<h3 id="mvcc-garbage-collection"><a href="#mvcc-garbage-collection" aria-hidden="true" tabindex="-1"><span></span></a>MVCC Garbage Collection</h3>
<p>MVCC stands for Multiversion Concurrency Control. Every database engine needs to somehow
manage concurrent access to data, and PostgreSQL as an advanced database engine is no
exception. As the name suggests, MVCC is the concurrency control mechanism inside Postgres.
Multiversion means that each statement sees it&#39;s own version of the database (aka snapshot) as
it was sometimes ago. This prevents statements from viewing inconsistent data.</p>
<p>MVCC enables the read and write locks not to conflict with each other, so reading
never blocks writing and writing never blocks reading (and PostgreSQL was the first
database to be designed with this feature).</p>
<p>Keeping multiple copies/versions of data produces garbage data that takes a lot of space
on the disk which degrades the performance of the database in the long run. Postgres uses
<code>VACUUM</code> to garbage-collect data. <code>VACUUM</code> reclaims storage occupied by dead tuples,
which are tuples that are deleted or obsoleted by an update are not physically
removed from their table. It is necessary to do <code>VACUUM</code> periodically, especially on
frequently-updated tables, hence why PostgreSQL includes an “autovacuum” facility
which can automate routine vacuum maintenance.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://cloud.google.com/blog/products/databases/deep-dive-into-postgresql-vacuum-garbage-collector">Google Cloud Blogs: A deep dive into VACUUM FAQs</a></li>
</ul>
<h2 id="level-3-twilight-zone"><a href="#level-3-twilight-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 3: Twilight Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27156%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Twilight Zone! Things are starting to get intriguing as we venture into more
complex database concepts. Brace yourself for a deeper understanding of PostgreSQL&#39;s
inner workings.</p>
<h3 id="count-vs-count1"><a href="#count-vs-count1" aria-hidden="true" tabindex="-1"><span></span></a><code>COUNT(*)</code> vs <code>COUNT(1)</code></h3>
<p>The <code>COUNT</code> function is an aggregate function that can take the form of either <code>count(*)</code>
— which counts the total number of input rows — or <code>count(expression)</code> — which counts the
number of input rows where the value of the expression is not <code>null</code>.</p>

<p><code>count(1)</code> has no <em>functional</em> difference with <code>count(*)</code> as every row is being counted as
constant 1:</p>

<p>However, an ongoing myth claims that:</p>
<blockquote>
<p>using <code>count(1)</code> is better than <code>count(*)</code> because
<code>count(*)</code> unnecessarily selects all the columns.</p>
</blockquote>
<p>The above statement ↑ is wrong. In PostgreSQL, <code>count(*)</code> is faster as it is an special
hard-coded syntax with no arguments for <code>count</code> aggregate function. <code>count(1)</code> is
specifically slower as it follows the <code>count(expression)</code> syntax and it needs to check if constant 1 is
not equal to <code>null</code> for each row.</p>
<h3 id="isolation-levels-and-phantom-reads"><a href="#isolation-levels-and-phantom-reads" aria-hidden="true" tabindex="-1"><span></span></a>Isolation Levels and Phantom Reads</h3>
<p>As we have mentioned earlier, the I in ACID stands for Isolation. A transaction
must be isolated from other concurrent transactions running in the database.
As an example, when you want to backup your database using tools like <code>pg_dump</code>,
you don&#39;t want your backup to be affected by other write operations in the system.</p>
<p>The SQL standard defines 4 levels of transaction isolation. These isolation level are
defined in terms of <em>phenomena</em>, and each of these levels either prohibits these <em>phenomena</em>,
or does not guarantee of them not happening. The phenomena are listed below:</p>
<ul>
<li><strong>dirty read:</strong> A transaction reads data written by a concurrent uncommitted transaction.</li>
<li><strong>nonrepeatable read</strong>: A transaction re-reads data it has previously read and finds
that data has been modified by another transaction (that committed since the initial read).</li>
<li><strong>phantom read</strong>: A transaction re-executes a query returning a set of rows that satisfy
a search condition and finds that the set of rows satisfying the condition has
changed due to another recently-committed transaction.</li>
<li><strong>serialization anomaly</strong>: The result of successfully committing a group of transactions
is inconsistent with all possible orderings of running those transactions one at a time.
Write skew is the simplest form of serialization anomaly.</li>
</ul>
<p>The four isolation levels in databases are:</p>
<ul>
<li><code>Read uncommitted</code></li>
<li><code>Read committed</code></li>
<li><code>Repeatable read (aka Snapshot Isolation, or Anomaly Serializable)</code></li>
<li><code>Serializable (aka Serializable Snapshot Isolation)</code></li>
</ul>
<p>It&#39;s important to note that PostgreSQL does not implement the <code>read uncommitted</code> isolation level.
Instead, PostgreSQL&#39;s <em>Read Uncommitted</em> mode behaves like <em>Read Committed</em>.
This is because it is the only sensible way to map the standard isolation levels to
PostgreSQL&#39;s multiversion concurrency control architecture.
This approach aligns with the SQL Standard because the
standard defines the minimum guarantees, not the maximum ones. Therefore, PostgreSQL can and does
disallow <em>phantom reads</em> even in the <em>repeatable read</em> isolation level:</p>
<table><thead><tr><th>Isolation Level</th><th>Dirty Read</th><th>Nonrepeatable Read</th><th>Phantom Read</th><th>Serialization Anomaly</th></tr></thead><tbody><tr><td>Read uncommitted</td><td>⚠️ Possible (✅ not in PG)</td><td>⚠️ Possible</td><td>⚠️ Possible</td><td>⚠️ Possible</td></tr><tr><td>Read committed</td><td>✅ Not possible</td><td>⚠️ Possible</td><td>⚠️ Possible</td><td>⚠️ Possible</td></tr><tr><td>Repeatable read</td><td>✅ Not possible</td><td>✅ Not possible</td><td>⚠️ Possible (✅ not in PG)</td><td>⚠️ Possible</td></tr><tr><td>Serializable</td><td>✅ Not possible</td><td>✅ Not possible</td><td>✅ Not possible</td><td>✅ Not possible</td></tr></tbody></table>
<p>The term &#34;Serializable&#34; execution means that a transaction can run as if it has a
&#34;serial execution,&#34; where no concurrent operation is affecting it.</p>

<h3 id="write-skew"><a href="#write-skew" aria-hidden="true" tabindex="-1"><span></span></a>Write skew</h3>
<p>Write skew is the simplest form of serialization anomaly, and the Serializable
isolation level protects you from it. However, the Repeatable Read isolation level
does not provide the same protection against write skew.</p>
<p>Assume a table with a column which has either <code>Black</code> or <code>White</code> as the value.
Two users concurrently try to make all rows contain matching color values,
but their attempts go in opposite directions. One is trying to update all white rows
to black and the other is trying to update all black rows to white.</p>
<p>In such a case, two concurrent transactions each determine what they are writing based
on reading a data set (rows with black/white column), and that dataset overlaps what
the other is writing. In this case we can get a state which could not occur if either
had run before the other</p>
<p>If these updates are run serially, all colors will match: one of the transactions
turn all rows to white, and the other turns all rows to black. If they are run concurrently
in <code>REPEATABLE READ</code> mode, the values will be switched, which is not consistent with any
serial order of runs. If they are run concurrently in <code>SERIALIZABLE</code> mode, PostgreSQL&#39;s
Serializable Snapshot Isolation (SSI) will notice
the write skew and roll back one of the transactions.</p>
<p>Read more:</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://wiki.postgresql.org/wiki/SSI">PostgreSQL&#39;s Serializable Snapshot Isolation (SSI) vs plain Snapshot Isolation (SI)</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://wiki.postgresql.org/wiki/Serializable">PostgreSQL&#39;s Serializable Wiki</a></li>
</ul>
<h3 id="serializable-restarts-require-retry-loops-on-all-statements"><a href="#serializable-restarts-require-retry-loops-on-all-statements" aria-hidden="true" tabindex="-1"><span></span></a>Serializable restarts require retry loops on all statements</h3>
<p>Restarting a serializable transaction requires retry on all the statements of
the transaction, not just the failed one. And if the generated transaction on the backend
relies on computed values outside of the sql code, those codes needs to be re-executed as
well:</p>

<h3 id="partial-indexes"><a href="#partial-indexes" aria-hidden="true" tabindex="-1"><span></span></a>Partial Indexes</h3>
<p>A <em>partial index</em> is an index built over a subset of a table specified using a <code>where</code> clause,
and is useful when you know that the column values are unique only in certain
circumstances. One major use-case for partial indexes is for the times that you don&#39;t want to
put common items in the index, as their frequent changes can increase the size of index
and slow the index down because of the recurring updates.</p>
<p>As an example, let&#39;s assume that most of your customers have the same nationality (at least 25% or so),
and there are just a handful of different values in the table, it could be a good idea to
create a partial index on the column:</p>

<h3 id="generator-functions-zip-when-cross-joined"><a href="#generator-functions-zip-when-cross-joined" aria-hidden="true" tabindex="-1"><span></span></a>Generator functions zip when cross joined</h3>
<p>Generator functions, also known as <em>Set Returning Functions (SRF)</em>, are functions that can
return more than one row. Unlike many other databases in which only scalar values
can appear in <code>select</code> clauses, PostgreSQL allows set-returning functions to appear in
<code>select</code>. One of the most famous generator functions is the <code>generate_series</code> functions which
accepts <code>start</code>, <code>stop</code>, and <code>step (optional)</code> parameters, and generates a series of values
from start to stop with a step size. This function can generate different types of
series including <code>integer</code>, <code>bigint</code>, <code>numeric</code>, and even <code>timestamp</code>:</p>

<p>In SQL, you can cross join two table using either of these two syntaxes:</p>

<p>And for functions, you can call them using either of these two syntaxes:</p>

<p>Combining these two syntaxes, when we execute the same cross join syntax for generator functions using
<code>select * from f()</code> and <code>select f()</code> syntaxes, one of them turns into a zip operation
instead of a cross join:</p>

<p>In the second case we get the result from two
generator functions side by side (this is called the <code>zip</code> of two results),
instead of a cartesian product. This is because a <code>join</code> plan can not be created
without a <code>from</code>/<code>merge</code> clause (omitted <code>from</code> clause is intended for computing the results
of simple expressions), and PostgreSQL creates a so called <code>ProjectSet</code> node
in the plan to project(display) the items coming from the generator functions.</p>
<h3 id="sharding"><a href="#sharding" aria-hidden="true" tabindex="-1"><span></span></a>Sharding</h3>
<p>Sharding in database is the ability to horizontally partition data across one more
database shards. While partitioning feature allows a table to be partitioned into multiple
tables, sharding allows a table to be partitioned in a way so parts of it live on
external foreign servers.</p>
<p>PostgreSQL uses the Foreign Data Wrappers (FDW) approach to implement sharding, but it is
still in progress.</p>
<p><img maxwidth="400" src="http://ablwr.github.io/static/images/posts/postgres-meme/sharding-fdw.svg" alt="FDW Sharding"/></p><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/citusdata/citus">Citus</a> is an open-source extension for
PostgreSQL which enables it to achieve horizontal scalability through sharding and replication.
One key advantage of Citus is that it is not a fork of PostgreSQL but an extension,
which allows it to stay in sync with the community release.
In contrast, many other forks of PostgreSQL often lag behind the community release
in terms of updates and features.</p>
<h3 id="zigzag-join"><a href="#zigzag-join" aria-hidden="true" tabindex="-1"><span></span></a>ZigZag Join</h3>
<p>We&#39;ve previously discussed <em>logical</em> joins, including left join, right join, inner join,
cross join, and full joins. These joins are <em>logical</em> in a sense that they are simple
joins that we write in our SQL codes. There is another category of joins called <em>physical</em> joins.
Physical joins represent the actual join operations that the database performs to join your data.
These include Nested Loop Join, Hash Join, and Merge Join. You can use <code>explain</code> functionality to see
which kind of physical join your database is using in the plan to execute the logical
join you have defined in your SQL.</p>
<p>ZigZag join is a physical join strategy, and can be thought of as a more performant nested loop join.
Assume we have a table like this:</p>

<p>And we have a <code>select</code> query like this:</p>

<p>Normally this would be a tough task for a database without a Zig-Zag join, because using
one of the secondary indexes and the primary index in our join plan, we still need to fetch many
records if we&#39;re having such a situation:</p>
<ul>
<li>there are many vehicles with tires = 0, or wings = 1</li>
<li>but not many vehicles with both tires = 0 and wings = 1.</li>
</ul>
<p>ZigZag join can make use of both indexes to reduce the number of fetched records:</p>
<p><img maxwidth="600" src="http://ablwr.github.io/static/images/posts/postgres-meme/zigzag.svg" alt="Zig Zag Join"/></p><p>In the zig-zag join shown in the image above, we continually switch between the
secondary indexes while comparing with the primary index:</p>
<ol>
<li>We first look at the tires index for values of <code>tires = 0</code>. The first <code>id</code> is equal to <code>1</code>.
Therefore, we need to jump (zig) to the other index and look for rows where <code>id = 1 (match)</code> or
<code>id &gt; 1 (skip)</code>. So in general, we jump to the row where <code>id &gt;= 1</code>.</li>
<li>Zig to the wings index, and as <code>id = 1</code>, we have found a match. We can safely lookup
the next record of the same index.</li>
<li>The next record has the <code>id = 2</code>. We zag to the tires index where <code>id &gt;= 2</code>.</li>
<li>The current record has <code>id = 10</code>. It&#39;s not a match, but we&#39;ve already skipped a lot of
records.</li>
<li>We zig to the wings index again, looking for records where <code>id &gt;= 10</code></li>
<li>And so on...</li>
</ol>
<h3 id="merge"><a href="#merge" aria-hidden="true" tabindex="-1"><span></span></a>MERGE</h3>
<p>Merge conditionally inserts, updates, or delete rows of a table using a <em>data source</em>:</p>

<p>Using <code>merge</code> we simplify multiple procedural language statements into a single
merge statement.</p>
<h3 id="triggers"><a href="#triggers" aria-hidden="true" tabindex="-1"><span></span></a>Triggers</h3>
<p>Triggers are a mechanism in PostgreSQL that can execute a function before, after, or
instead of the operation when a certain event is occurred on a table. These events
can be either of <code>insert</code>, <code>update</code>, <code>delete</code>, or <code>truncate</code>.
Trigger functions have access to special variables that store data both before
and after an edit, hence why they are more powerful than <code>check</code> constraints:</p>

<p>As you can see, the <code>when</code> clause can refer to columns of the old and/or new row values
by writing <code>OLD.column_name</code> or <code>NEW.column_name</code> respectively.</p>
<h3 id="grouping-sets-cube-rollup"><a href="#grouping-sets-cube-rollup" aria-hidden="true" tabindex="-1"><span></span></a>Grouping sets, Cube, Rollup</h3>
<p>Imagine you want to see the sum of the salaries of a different departments based on the
gender of the employees. One way to do this is to have multiple <code>group by</code> clauses and
then <code>union</code> the result rows together:</p>

<p>However, this would be a pain if we want to report the sum of salaries for
different groups of data. Grouping sets allow us to define a set of groupings and write a
simpler query. The equivalent of the above query using grouping sets would be:</p>

<p>There are two types of grouping sets, each with its own syntax sugar due to their
common usages: <code>rollup</code> and <code>cube</code>.</p>

<p>is equivalent of:</p>

<p>and</p>

<p>is equivalent of:</p>

<p>Grouping sets can also be combined together:</p>

<h2 id="level-4-midnight-zone"><a href="#level-4-midnight-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 4: Midnight Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27161%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Midnight Zone! In this level, we&#39;ll delve into the depths of PostgreSQL.
Prepare to navigate the challenges and professional topics of a modern database system.</p>
<h3 id="denormalization"><a href="#denormalization" aria-hidden="true" tabindex="-1"><span></span></a>Denormalization</h3>
<p>One of the first steps of designing a database application
is going thorough the normalization process (1NF, 2NF, ...) in order to reduce
data redundancy and improve data integrity. Even though relational database, specially Postgres,
are well optimized for having many primary keys and foreign keys in tables, and are
capable of joining between many tables and handling many constraints, a heavily normalized
schema might still be challenging to deal with because of performance penalties.</p>
<p>In such a scenario, if maintaining a fully normalized table becomes challenging, the database designer
can go thorough a process known as <em>denormalization</em>. In other words, it improves the
read performance of your data, with the cost of reducing the write performance, as you
may need to write multiple copies of your data.</p>
<p>PostgreSQL natively supports many denormalized data types including <code>array</code>, composite types
created via <code>create type</code>, <code>enum</code>, <code>xml</code>, and <code>json</code> types. Materialized views are
also used to implement faster reads with slower writes trade-off.
A materialized view is a view that is stored on disk.
You can create a denormalized and materialized view of your data for fast reads, and then
use <code>refresh materialized view my_view</code> to refresh this cache.</p>
<h3 id="nulls-in-check-constraints-are-truthy"><a href="#nulls-in-check-constraints-are-truthy" aria-hidden="true" tabindex="-1"><span></span></a><code>NULL</code>s in <code>CHECK</code> constraints are truthy</h3>
<p>As we have mentioned earlier, <code>null</code> in SQL means not knowing the value,
rather than the absence of a value, and such a select will return <code>null</code>:</p>

<p>If we create a column with a check constraint on it like this:</p>

<p>and then we try to insert a row where the <code>age</code> equals 15, we will get this error:</p>

<p>However, this <code>insert</code> will succeed:</p>

<p>It&#39;s might not make sense to assume something satisfies a check constraint when you
don&#39;t know the value of it (<code>null</code>), but in SQL we have to let the row thorough because
<code>null</code>s in <code>check</code> constraints are truthy.</p>
<h3 id="transaction-contention"><a href="#transaction-contention" aria-hidden="true" tabindex="-1"><span></span></a>Transaction Contention</h3>
<p>Resource contention is a conflict over access to a shared resource like RAM, network interface,
storage, etc. In case of SQL databases, a resource contention can appear in form of
transaction contentions, and that is when multiple transactions want to write to a
row at the same time. A transaction contention might require delays, retries, or halts to fix
as they might cause deadlocks/livelocks. This is actually configurable using the <code>deadlock_timeout</code>
config.</p>
<p>A contention usually slows down your database without leaving many clues for you to
debug them, and the negative effect gets worse when you have multiple nodes or clusters. That
being said, tools like Postgres-BDR might provides tools to diagnose and correct
contention problems.</p>
<h3 id="select-for-update"><a href="#select-for-update" aria-hidden="true" tabindex="-1"><span></span></a><code>SELECT FOR UPDATE</code></h3>
<p><code>select</code> clause is used to read data from database, but sometimes you want to select
rows in order to write them. If any of the below <em>lock strengths</em> are specified:</p>
<ul>
<li><code>select ... for update</code></li>
<li><code>select ... for no key update</code></li>
<li><code>select ... for share</code></li>
<li><code>select ... for key share</code></li>
</ul>
<p>the <code>select</code> statement locks the entire selected rows (not just the columns) against
concurrent updates:</p>

<p>This is sometimes known as <em>pessimistic locking</em>. You should be careful when using explicit
locking, because if you perform long-running works in a transaction, the database
will lock the rows for the entirety of time:</p>

<p>You can switch to <em>optimistic locking</em> in such cases. Optimistic locking assumes that
others won&#39;t update the same record and verifies this during update time, rather
than locking the record throughout the entire processing duration on the client side.</p>
<h3 id="timestamptz-doesnt-store-a-timezone"><a href="#timestamptz-doesnt-store-a-timezone" aria-hidden="true" tabindex="-1"><span></span></a><code>timestamptz</code> doesn&#39;t store a timezone</h3>
<p>If we run this query:</p>

<p>we will realize that <code>timestamp</code> and <code>timestamp with time zone</code> types have the same size,
which means PostgreSQL doesn&#39;t actually store the timezone for <code>timestamptz</code>. All it does
is that it formats the same value using a different timezone:</p>

<h3 id="star-schemas"><a href="#star-schemas" aria-hidden="true" tabindex="-1"><span></span></a>Star Schemas</h3>
<p>Star schema is a database modeling approach adopted by relational data warehouses.
It requires modelers to classify their model tables as either <em>dimension</em> or <em>fact</em>.
The star schema consists of one or more fact tables referencing to any number of
dimension tables.</p>
<p>In data warehousing, a <em>fact</em> table consists of measurements, metrics or facts
of a business process, while a dimension table is a structure that categorizes
facts and measures in order to enable users to answer business questions.
Commonly used dimensions are people, products, place and time.</p>
<p><img maxwidth="600" src="http://ablwr.github.io/static/images/posts/postgres-meme/star-schemas.svg" alt="Zig Zag Join"/></p><h3 id="sargability"><a href="#sargability" aria-hidden="true" tabindex="-1"><span></span></a>Sargability</h3>
<p>In relational databases, a condition (or predicate) in a query is said to be <em>sargable</em>
if the DBMS engine can take advantage of an index to speed up the execution of the query.
The ideal SQL search condition has the general form:</p>

<p>A common thing that can make a query non-sargible is using an indexed column inside a
function, for example using this query:</p>

<p>instead of the equivalent sargible one:</p>

<p>Or as another example:</p>

<p>SARG is a contraction for Search ARGument. In the early days, IBM researchers named
these kinds of search conditions &#34;sargable predicates&#34;.
In later days, Microsoft and Sybase redefined &#34;sargable&#34; to mean &#34;can be
looked up via the index.&#34;</p>
<h3 id="ascending-key-problem"><a href="#ascending-key-problem" aria-hidden="true" tabindex="-1"><span></span></a>Ascending Key Problem</h3>
<p>Assume that we have such a time-series event table:</p>

<p>In this situation, the primary key or index of such tables are continuously
increasing over time and the rows are always being added to the end of table.
This can result in data fragmentation as the end of the table is the only spot
being written, and the inserting point is not evenly distributed among the rows.</p>
<p>This can lead to various issues, such as contention at the end of the table, making it
challenging to distribute and shard the table, and slower data retrievals due
to the lack of table statistics at the end.</p>
<p>As mentioned earlier, a database system relies on statistics to generate more
optimal execution plans. It&#39;s important to note that statistics for the most
recently inserted rows are not included in the database statistics, e.g. <code>pg_stat_database</code>.</p>
<p>One way to fix the ascending key problem in PostgreSQL is to use the block range index (BRIN index).
These indexes give performance improvements when the data is naturally ordered as it
is added to the table, such as <code>t timestamp</code> columns or a naturally auto incremented columns.</p>

<h3 id="ambiguous-network-errors"><a href="#ambiguous-network-errors" aria-hidden="true" tabindex="-1"><span></span></a>Ambiguous Network Errors</h3>
<p>Various types of network errors can occur when working with databases, such as
disconnecting from the database during a transaction. In such cases,
it&#39;s your responsibility to verify whether your interaction with the
database was successful or not.</p>
<p>Ambiguous network errors may not provide clear indications of where the process was
interrupted, or even if a network problem exists. If you are running a streaming replication,
a young connection in the <code>pg_stat_replication</code> table might be a sign of a network problem or
other kind of reliability issues.</p>
<h3 id="utf8mb4"><a href="#utf8mb4" aria-hidden="true" tabindex="-1"><span></span></a><code>utf8mb4</code></h3>
<p><code>utf8mb4</code> stands for &#34;UTF-8 Multibyte 4&#34; and is a MySQL type. It has nothing to do with
PostgreSQL or the SQL standard.</p>
<p>Historically, MySQL has used <code>utf8</code> as an alias for <code>utf8mb3</code>. That means that it can
only store <em>Basic Multilingual Plane</em> unicode characters (3 byte unicode characters).
If you want to be able to store all unicode characters, you need to explicitly use
<code>utf8mb4</code> type.</p>
<p>Beginning with MySQL 8.0.28, <code>utf8mb3</code> is used exclusively in the output of <code>show</code> statements and in
Information Schema tables when this character set is meant.</p>
<p>At some point in the MySQL history <code>utf8</code> is expected to become a reference to <code>utf8mb4</code>.
To avoid ambiguity about the meaning of <code>utf8</code>, MySQL users (and MariaDB users, because
MariaDB is a fork of MySQL) should consider specifying <code>utf8mb4</code> explicitly
for character set references instead of <code>utf8</code>.</p>
<h2 id="level-5-abyssal-zone"><a href="#level-5-abyssal-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 5: Abyssal Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27141%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Abyssal Zone! Here, we&#39;ll explore the abyss of PostgreSQL&#39;s concepts.
Things that you might haven&#39;t heard before!</p>
<h3 id="cost-models-dont-reflect-reality"><a href="#cost-models-dont-reflect-reality" aria-hidden="true" tabindex="-1"><span></span></a>Cost models don&#39;t reflect reality</h3>
<p>When explaining a query, you can enable the &#34;cost&#34; option, which provides you with
the estimated statement execution cost. This cost represents the planner&#39;s
estimate of how long it will take to execute the statement, typically
measured in cost units, conventionally indicating disk page fetches.</p>
<p>The planner uses the table statistics to come up with the
best plan it can with the lowest cost. However, that computed cost can be utterly wrong
as it&#39;s just an estimated value, or could be based on the wrong statistics
(as we&#39;ve seen in the ascending key problem).</p>
<h3 id="nulljsonb-is-null--false"><a href="#nulljsonb-is-null--false" aria-hidden="true" tabindex="-1"><span></span></a><code>null::jsonb IS NULL</code> = <code>false</code></h3>
<p><code>NULL</code> in SQL means not knowing the value, while JSON&#39;s <code>null</code> is JavaScript&#39;s <code>null</code> and
represents the intentional absence of any value. This is why JSON&#39;s <code>null</code> in
PostgreSQL&#39;s <code>jsonb</code> data-type is not equivalent to SQL&#39;s <code>null</code>:</p>

<h3 id="tpcc-requires-wait-times"><a href="#tpcc-requires-wait-times" aria-hidden="true" tabindex="-1"><span></span></a>TPCC requires wait times</h3>
<p>TPC-C stands for &#34;Transaction Processing Performance Council - Benchmark C&#34; and is an
online transaction processing benchmark hosted at <a target="_blank" rel="noopener noreferrer" href="https://www.tpc.org/tpcc/">tpc.org</a>.
TPC-C involves a mix of five concurrent transactions of different types and complexity
either executed on-line or queued for deferred execution. The database is
comprised of nine types of tables with a wide range of record and population sizes.
TPC-C is measured in transactions per minute (tpmC).</p>
<p>TPC-C benchmarks includes two type of wait times: The keying time represents the time spent
entering data at the terminal (pressing keys on the keyboard) and the think time
represents the time spent, by the operator, to read the result of the transaction at
the terminal before requesting another transaction. Each transaction has a minimum keying
time and a minimum think time.</p>
<p>These times will help the benchmark to be closer to real-world scenarios. Benchmarking
transactions without wait-time will make the system under test slower and slower overtime
as the system internals will have no free resources to operate.</p>
<p><code>pgbench</code> is the command-line tool used to benchmark PostgreSQL databases, and it supports TPC and
many different command-line arguments including wait-time/schedule-lag-time.</p>
<h3 id="deferrable-initially-immediate"><a href="#deferrable-initially-immediate" aria-hidden="true" tabindex="-1"><span></span></a>DEFERRABLE INITIALLY IMMEDIATE</h3>
<p>Constraints on columns can be either <code>deferred</code> or <code>immediate</code>.
Immediate constraints are checked at the end of each statement, while deferred constraints are
not checked until transaction commit. Each constraint has its own <code>IMMEDIATE</code> or <code>DEFERRED</code> mode.</p>
<p>Upon creation, a constraint is given one of three characteristics:</p>
<ul>
<li><code>not deferrable</code> (default, equivalent to <code>immediate</code>): the constraint is checked immediately after
each statement. This behavior can NOT be changed using the <code>set constraint</code> command. e.g. <code>set constraint pk_name deferred;</code></li>
<li><code>deferrable initially immediate</code>: the constraint is checked immediately after
each statement, however, this behavior can later be altered using the <code>set constraint</code> command.</li>
<li><code>deferrable initially deferred</code>: the constraints are not checked until transaction commit.
This behavior can later be altered using the <code>set constraint</code> command.</li>
</ul>

<p>As you see in the SQL code above, <code>deferrable initially immediate</code> is specified while
defining the schema of the table, not on runtime.</p>
<h3 id="explain-approximates-select-count"><a href="#explain-approximates-select-count" aria-hidden="true" tabindex="-1"><span></span></a>EXPLAIN approximates <code>SELECT COUNT(*)</code></h3>
<p>Using <code>explain</code> with <code>select count(*)</code> can give you an estimate of how many rows PostgreSQL
think are in your table using table statistics.</p>

<p>If you don&#39;t need an exact count, the current statistic from the catalog table
<code>pg_class</code> might be good enough and is much faster to retrieve for big tables:</p>

<h3 id="match-partial-foreign-keys"><a href="#match-partial-foreign-keys" aria-hidden="true" tabindex="-1"><span></span></a>MATCH PARTIAL Foreign Keys</h3>
<p><code>match full</code>, <code>match partial</code>, and <code>match simple</code>(default) are three table column
constraints for the foreign keys. Foreign keys are supposed
to guarantee the <em>referential integrity</em> of our database, and in order to do so, database
needs to know how to match the referencing column value with the referenced column value
in case of <code>null</code>s.</p>
<ul>
<li><code>match full</code>: will not allow one column of a multi-column foreign key to be <code>null</code>
unless all foreign key columns are <code>null</code>; if they are all <code>null</code>, the row is not required
to have a match in the referenced table.</li>
<li><code>match simple</code>(default): allows any of the foreign key columns to be <code>null</code>; if any
of them are <code>null</code>, the row is not required to have a match in the referenced table.</li>
<li><code>match partial</code>: if all referencing columns are <code>null</code>, then the row of the referencing
table passes the constraint check. If at least one referencing columns is not null,
then the row passes the constraint check if and only if there is a row of the
referenced table that matches all the non-null referencing columns. This is not yet implemented
in PostgreSQL, but a workaround is to use
<code>not null</code> constraints on the referencing column(s) to prevent these cases from arising.</li>
</ul>
<h3 id="causal-reverse"><a href="#causal-reverse" aria-hidden="true" tabindex="-1"><span></span></a>Causal Reverse</h3>
<p>Causal reverse is a transaction anomaly that can be encountered even with
Serializable isolation levels. To address this anomaly, a higher level of
serializability known as <em>Strict Serializability</em> is required.</p>
<p>Here is a simple example for the causal reverse anomaly:</p>
<ol>
<li>Thomas executes <code>select * from events</code>, doesn&#39;t get a respond yet.</li>
<li>Ava executes <code>insert into events (id, time, content) values (1, &#39;2023-09-01 02:01:16.679037&#39;, &#39;hello&#39;)</code> and commit.</li>
<li>Emma executes <code>insert into events (id, time, content) values (2, &#39;2023-09-01 02:02:56.819018&#39;, &#39;hi&#39;)</code> and commit.</li>
<li>Thomas gets the respond of the <code>select</code> query from step 1. He gets the Emma&#39;s row, but not
Ava&#39;s.</li>
</ol>
<p>In the causal reverse anomaly, a later write which was caused by an earlier write,
time-travels to a point in the serial order prior to the earlier write.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="http://dbmsmusings.blogspot.com/2019/06/correctness-anomalies-under.html">Correctness Anomalies Under Serializable Isolation</a></li>
</ul>
<h2 id="level-6-hadal-zone"><a href="#level-6-hadal-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 6: Hadal Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27153%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Hadal Zone! As we reach extreme depths, we&#39;ll discuss specialized
PostgreSQL topics like learned indexes, TXID Exhaustion, and more!</p>
<h3 id="vectorized-doesnt-mean-simd"><a href="#vectorized-doesnt-mean-simd" aria-hidden="true" tabindex="-1"><span></span></a>Vectorized doesn&#39;t mean SIMD</h3>
<p>SIMD stands for &#34;Single instruction, multiple data&#34;, and is a type of parallel processing
when a single CPU instruction is simultaneously applied to multiple different data streams.</p>
<p><img maxwidth="800" src="http://ablwr.github.io/static/images/posts/postgres-meme/simd.svg" alt="SIMD"/></p><p>The term &#34;Vector&#34; and &#34;Vectorized&#34; usually come with the term &#34;SIMD&#34; in computer
literature. Vector programming (aka Array programming) refers to solutions that allow us
to apply operations to an entire set of values at once.  As a matter of fact, the extension
instruction set which was added to the x86 instruction set architecture to perofrm
SIMD is called <em>Advanced Vector Extensions (AVX)</em>.</p>
<p>SIMD is one approach to leverage vector computations and not the only way. That being said,
<a target="_blank" rel="noopener noreferrer" href="https://doxygen.postgresql.org/simd_8h_source.html">PostgreSQL vectors are backed by SIMD cpu instructions</a>.</p>
<h3 id="nulls-are-equal-in-distinct-but-unequal-in-unique"><a href="#nulls-are-equal-in-distinct-but-unequal-in-unique" aria-hidden="true" tabindex="-1"><span></span></a><code>NULL</code>s are equal in <code>DISTINCT</code> but unequal in <code>UNIQUE</code></h3>
<p>Assume you have a table called <code>unique_items</code> with such a definition:</p>

<p>PostgreSQL will prevent you to insert duplicate <code>&#39;hi&#39;</code> values, as the second one
would violate the unique constraint:</p>

<p>However, we can insert as many <code>null</code>s as we want:</p>

<p>This means that to SQL, <code>null</code> values are not the same, as they are unknown values.</p>
<p>But now if we <code>select distinct</code> items of the <code>unique_items</code> table, we will get this result:</p>

<p>All of the <code>null</code> values are shown as a single item, as if PostgreSQL grouped all the unknown
values in one value.</p>
<h3 id="volcano-model"><a href="#volcano-model" aria-hidden="true" tabindex="-1"><span></span></a>Volcano Model</h3>
<p>&#34;Volcano - An Extensible and Parallel Query Evaluation System&#34; is a research paper by
Goetz Graefe that was published in the IEEE Transactions on Knowledge and Data Engineering
(Volume: 6, Issue: 1) on February 1994. This evaluation system is called Volcano Model,
Volcano iterator model, or sometimes simply referred to as the Iterator model.</p>
<p>Each relational-algebraic operator produces a tuple stream, and a consumer can iterate
over its input streams. The tuple stream interface is essentially: <code>open</code>, <code>next</code>, and
<code>close</code>; all operators offer the same interface, and the implementation is opaque.</p>
<p>Each <code>next</code> call produces a new tuple from the stream, if one is available.
To obtain the query output, one &#34;next-next-next&#34;s on the final RA operator;
that one will in turn use &#34;next&#34;s on its inputs to pull tuples allowing it to
produce output tuples, etc. Some &#34;next&#34;s will take an extremely long time, since many
&#34;next&#34;s on previous operators will be required before they emit any output.</p>
<p>Example: <code>select max(v) from t</code> may need to go trough all of <code>t</code> in order to find that
maximum.</p>
<p>A highly simplified pseudocode of the volcano iteration model:</p>


<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://cs-people.bu.edu/mathan/reading-groups/papers-classics/volcano.pdf">Volcano-An Extensible and Parallel Query Evaluation System</a></li>
</ul>
<h3 id="join-ordering-is-np-hard"><a href="#join-ordering-is-np-hard" aria-hidden="true" tabindex="-1"><span></span></a>Join ordering is NP Hard</h3>
<p>When you have multiple joins in your SQL query, the database engine needs to find
an order to perform the joins. Finding the best join order is an NP-hard problem.
This is why database engines use estimates, statistics, and soft computing approaches to find an order
since finding the optimal solution would take forever.</p>
<p>This is a simplified table of problem classes:</p>
<table><thead><tr><th>Problem Class</th><th>Verify Solution</th><th>Find Solution</th><th>Example</th></tr></thead><tbody><tr><td>P</td><td>😁 Easy</td><td>😁 Easy</td><td>Multiply numbers</td></tr><tr><td>NP</td><td>😁 Easy</td><td>😥 Hard</td><td>8 Queens</td></tr><tr><td>NP-hard</td><td>😥 Hard</td><td>😭 Hard</td><td>Best next move in Chess</td></tr></tbody></table>
<p>NP-hard problems are at least as hard as the hardest problems in NP. That means
if P ≠ NP (which is probabely the case, at least for now), NP-hard problems could not be
solved in polynomial time.</p>
<p><img maxwidth="800" src="http://ablwr.github.io/static/images/posts/postgres-meme/np-hard-complete.svg" alt="SIMD"/></p><blockquote>
<p>If P=NP, then the world would be a profoundly different place than we usually
assume it to be. There would be no special value in “creative leaps,”
no fundamental gap between solving a problem and recognizing the solution once
it&#39;s found. Everyone who could appreciate a symphony would be Mozart; everyone
who could follow a step-by-step argument would be Gauss; everyone who
could recognize a good investment strategy would be Warren Buffett.</p>
<ul>
<li>Scott Aaronson</li>
</ul>
</blockquote>
<h3 id="database-cracking"><a href="#database-cracking" aria-hidden="true" tabindex="-1"><span></span></a>Database Cracking</h3>
<p>Cracking is a technique that shifts the cost of index maintenance from updates
to query processing. The query pipeline optimizers are used to massage the query plans to
crack and to propagate this information. The technique allows for improved access times
and self-organized behavior.</p>
<p>In other words, Database cracking is an approach for data indexing and index maintainance in
a self-organized way. In a database system where database cracking is used, an
incoming query requesting all elements which satisfy a certain condition <code>c</code> does not
only return a result but it also causes a reodering of the physical database so that
all elements satisfying <code>c</code> are stored in a contiguous memery space. Therefore the
physical database is devided into multiple parts (cracked).</p>
<p>By using this mechanism
the database reorganizes itself in the most favourable way according to the workload
which is put on it.</p>
<p><img maxwidth="500" src="http://ablwr.github.io/static/images/posts/postgres-meme/database-cracking.svg" alt="SIMD"/></p><ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://db.in.tum.de/teaching/ws1718/seminarHauptspeicherdbs/paper/werner.pdf">Database Cracking by David Werner</a></li>
</ul>
<h3 id="wcoj"><a href="#wcoj" aria-hidden="true" tabindex="-1"><span></span></a>WCOJ</h3>
<p>Traditional <em>binary join</em> algorithms such as hash join operate over two relations
at a time (<code>r1 join r2</code>); joins between more than two relations are implemented by
repeatedly applying binary joins (<code>r1 join (r2 join r3)</code>).</p>
<p>WCOJ (Worst-Case Optimal Join) is a kind of join algorithm whose running
time is worst-case optimal for all natural join queries, and is asymptotically
faster in worst case than any join algorithm based on such iterated binary joins.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1203.1952.pdf">Worst-case Optimal Join Algorithms</a></li>
</ul>
<h3 id="learned-indexes"><a href="#learned-indexes" aria-hidden="true" tabindex="-1"><span></span></a>Learned Indexes</h3>
<p>Learned Indexes are indexing strategies that utilize artificial intelligence approaches
and deep-learning models to outperform cache-optimized
B-Trees and reduce memory usage.
Google and MIT engineers developed such a model and published their work as a pioneer
paper with the title
&#34;The Case for Learned Index Structures&#34;. The key idea is that
a model can learn the sort order or structure of lookup keys and use this signal
to effectively predict the position or existence of records.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1712.01208.pdf">The Case for Learned Index Structures</a></li>
</ul>
<h3 id="txid-exhaustion"><a href="#txid-exhaustion" aria-hidden="true" tabindex="-1"><span></span></a>TXID Exhaustion</h3>
<p>Transaction ID Exhaustion, often referred to as the &#34;Wraparound Problem,&#34;
arises due to the limited number of transaction IDs available and the absence
of regular database maintenance, known as vacuuming.</p>
<p>PostgreSQL&#39;s MVCC transaction semantics depend on being able to compare transaction ID (XID)
numbers: a row version with an insertion XID greater than the current transaction&#39;s XID
is “in the future” and should not be visible to the current transaction.
But since transaction IDs have limited size (32 bits) a cluster that runs for a long time
(more than 4 billion transactions) would suffer transaction ID wraparound: the XID
counter wraps around to zero, and all of a sudden transactions that were in the past
appear to be in the future — which means their output become invisible.
In short, catastrophic data loss. (Actually the data is still there, but that&#39;s cold comfort if you cannot get at it.)</p>
<p>To avoid this, it is necessary to vacuum every table in every database at least once
every two billion transactions.</p>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-WRAPAROUND">Routine Vacuuming: Preventing Transaction ID Wraparound Failures</a></li>
</ul>
<h2 id="level-7-pitch-black-zone"><a href="#level-7-pitch-black-zone" aria-hidden="true" tabindex="-1"><span></span></a>Level 7: Pitch Black Zone</h2>
<div><p><span><span><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27153%27/%3e"/></span><img alt="The Legendary Postgres meme" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic"/></span></p></div>
<p>Welcome to Pitch Black Zone! Congratulations on your journey to the deepest reaches of
PostgreSQL knowledge. Brace yourself for esoteric and cutting-edge topics,
where only the boldest dare to venture!</p>
<h3 id="the-halloween-problem"><a href="#the-halloween-problem" aria-hidden="true" tabindex="-1"><span></span></a>The halloween problem</h3>
<p>Halloween Problem is a database error that a database system developer needs to be
aware of.</p>
<p>On the Halloween day of 1976, a couple of computer engineers were working on a query that was
supposed to give a 10% raise to every employee who earned less than $25,000:</p>

<p>This query would run successfully in their database, but when finished
all the employees in the database earned at least $25,000.
This is because the updated rows were also visible to the query execution engine,
and as the match criteria in the <code>where</code> clause was still true, the database continued
to increase their salaries until they are over $25,000.</p>
<p>This could even cause an infinite loop in some cases where updates continually
place the updated record ahead of the scan performing the update operation.</p>
<h3 id="dee-and-dum"><a href="#dee-and-dum" aria-hidden="true" tabindex="-1"><span></span></a>Dee and Dum</h3>
<ul>
<li>Table <code>dee</code> is the table that has no columns but a single row.
It plays the role of <code>True</code>.</li>
<li>Table <code>dum</code> is the table that has no columns and no rows.
It plays the role of <code>False</code>.</li>
</ul>
<p>These theoretical tables and terminology was created by Hugh Darwen.
You can read more about the implmentation of these tables in PostgreSQL
at <a target="_blank" rel="noopener noreferrer" href="https://blog.jooq.org/creating-tables-dum-and-dee-in-postgresql/">Creating Tables Dum and Dee in PostgreSQL by Lukas Eder</a>.
PostgreSQL trigger functions are used to enforce these rules.</p>
<h3 id="serial-is-non-transactional"><a href="#serial-is-non-transactional" aria-hidden="true" tabindex="-1"><span></span></a><code>SERIAL</code> is non-transactional</h3>
<p>Serial types in PostgreSQL are used to create autoincrementing columns.
These data types (<code>smallserial</code>, <code>serial</code>, and <code>bigserial</code>) are not true types,
but merely a syntactic sugar for creating unique identifier columns:</p>

<p>Because <code>serial</code> types are implemented using sequences, there may be &#34;holes&#34; or gaps
in the sequence of values which appears in the column, even if no rows are ever deleted.</p>
<p>A value allocated from the sequence is still &#34;used up&#34; even if a row containing
that value is never successfully inserted into the table column. This may happen,
for example, if the inserting transaction rolls back. This is why <code>serial</code> types are considered
non-transactional as they won&#39;t rollback their value in case of a transaction rollback.</p>

<h3 id="allballs"><a href="#allballs" aria-hidden="true" tabindex="-1"><span></span></a>allballs</h3>
<p>The <code>&#39;allballs&#39;</code> string will turn into the midnight time (<code>00:00:00</code>) when converted to
<code>time</code>.
This is because &#34;allballs&#34; is an slang for &#34;all zeros&#34;.
This slang was historically used in military communications.</p>

<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/message-id/6EE64EF3AB31D5448D0007DD34EEB3412A75D9%40Herge.rcsinc.local">PostgreSQL mailing list: Why is &#39;allballs&#39; accepted as a literal for time?</a></li>
</ul>
<h3 id="fsyncgate"><a href="#fsyncgate" aria-hidden="true" tabindex="-1"><span></span></a>fsyncgate</h3>
<p><code>fsync</code> is an OS system call, and in Linux it is used to synchronize a file&#39;s in-core
state with storage device. In other words, this system call ensures that the data written
to a file is indeed written on
the storage device and persisted by transfering/flushing all modified in-core data of
the file to the disk or other permanent storage device.</p>
<p>The term &#34;fsyncgate 2018&#34; is referred to the scandals and controversies around the
reliability issues of the <code>fsync</code> system call on the PostgreSQL mailing list and elsewhere (
or as some people say, how &#34;PostgreSQL used fsync incorrectly for 20 years&#34;).</p>
<p>The issue was raised by Craig Ringer. Quoted from the mailing list:</p>
<blockquote>
<p>Hi all</p>
<p>Some time ago I ran into an issue where a user encountered data corruption
after a storage error. PostgreSQL played a part in that corruption by
allowing checkpoint what should&#39;ve been a fatal error.</p>
<p>TL;DR: Pg should PANIC on fsync() EIO return. Retrying fsync() is not OK at
least on Linux. When fsync() returns success it means &#34;all writes since the
last fsync have hit disk&#34; but we assume it means &#34;all writes since the last
SUCCESSFUL fsync have hit disk&#34;.</p>
<p>...</p>
</blockquote>
<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/message-id/flat/CAMsr%2BYHh%2B5Oq4xziwwoEfhoTZgr07vdGG%2Bhu%3D1adXx59aTeaoQ%40mail.gmail.com">PostgreSQL mailing list: PostgreSQL&#39;s handling of fsync() errors is unsafe and risks data loss at least on XFS</a></li>
</ul>
<h3 id="every-sql-operator-is-actually-a-join"><a href="#every-sql-operator-is-actually-a-join" aria-hidden="true" tabindex="-1"><span></span></a>Every SQL operator is actually a join</h3>
<p>Every SQL operator can be represented using a join.
One way to think about joins is that they &#34;look stuff up&#34; in a relation.</p>

<p>For example in the above query, rather than computing <code>age * age</code> explicitly,
we could also just look it up in
the <code>squares</code> function table (with columns <code>x</code> and <code>xx</code>):</p>

<ul>
<li>Read more: <a target="_blank" rel="noopener noreferrer" href="https://justinjaffray.com/join-the-ultimate-projection">JOIN: The Ultimate Projection</a></li>
</ul>
<h3 id="null-1"><a href="#null-1" aria-hidden="true" tabindex="-1"><span></span></a><code>NULL</code></h3>
<p><code>NULL</code> can be tricky sometimes. Don&#39;t you think?</p>
<h2 id="conclusion"><a href="#conclusion" aria-hidden="true" tabindex="-1"><span></span></a>Conclusion</h2>
<p>We&#39;ve seen a cool meme on the internet and we&#39;ve tried to understand it.
This was a journey from the skies on top of the SQL iceberg, to the deepest parts of the ocean
where everything was pitch-black. We&#39;ve looked at each part of this meme while wearing our
PostgreSQL hat to see how these topics are related to the PostgreSQL implementation of
SQL and relational databases.</p>
<p>Yet again, shout out to Jordan Lewis and his friends for creating
this cool and informative meme.</p>
<h2 id="references"><a href="#references" aria-hidden="true" tabindex="-1"><span></span></a>References</h2>
<p>Resources I&#39;ve used to write this blog post:</p>
<ul>
<li>PostgreSQL Documentations. [Online]. <a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/docs/">postgresql.org/docs</a></li>
<li>Fontaine, D. (2019b). The Art of PostgreSQL: Turn Thousands of Lines of Code Into Simple Queries.</li>
<li>Schönig, H. (2023). Mastering PostgreSQL 15: Advanced techniques to build and manage scalable, reliable, and fault-tolerant database applications. Packt Publishing Ltd.</li>
<li>Dombrovskaya, H., Novikov, B., &amp; Bailliekova, A. (2021). PostgreSQL query Optimization: The Ultimate Guide to Building Efficient Queries. Apress.</li>
<li>Riggs, S., &amp; Ciolli, G. (2022). PostgreSQL 14 Administration Cookbook: Over 175 Proven Recipes for Database Administrators to Manage Enterprise Databases Effectively.</li>
<li>Use the Index, Luke! A Guide to Database Performance for Developers. [Online]. <a target="_blank" rel="noopener noreferrer" href="https://use-the-index-luke.com/">use-the-index-luke.com</a></li>
<li>Gulutzan, P., &amp; Pelzer, T. (2003). SQL Performance Tuning. Addison-Wesley Professional.</li>
<li>Cockroach Labs Blog. [Online]. <a target="_blank" rel="noopener noreferrer" href="https://www.cockroachlabs.com/blog/">Cockroach Labs Blog</a></li>
<li>Justin Jaffray&#39;s Blog. [Online]. <a target="_blank" rel="noopener noreferrer" href="https://justinjaffray.com/posts">Justin Jaffray&#39;s Blog</a></li>
</ul></div></div>
  </body>
</html>
