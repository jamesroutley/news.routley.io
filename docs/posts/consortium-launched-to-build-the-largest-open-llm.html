<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.utu.fi/en/news/press-release/university-of-turku-and-silogen-launch-consortium-to-build-the-worlds-largest">Original</a>
    <h1>Consortium launched to build the largest open LLM</h1>
    
    <div id="readability-page-1" class="page"><div><p>To ensure digital sovereignty and democratise access to LLMs, SiloGen and TurkuNLP research group at the University of Turku launch a consortium with a key focus to develop the world’s largest open source language model, covering all official European languages. </p>

<p>In addition to compute access totaling approximately 15 million GPU hours, the initiative is dedicated to ensure that data utilized in these models accurately represent European languages, also covering the English-speaking world. The initiative is conducted in close collaboration with key European institutions and agencies, and is committed to adhering to European regulations. Beyond Europe, the open source initiative will democratise access to LLMs and enable the development of use-case specific downstream applications.</p>

<p>The consortium, led by SiloGen and the TurkuNLP research group at the University of Turku, stands apart from many other initiatives in that it uniquely combines resources to build LLMs:</p>

<ul><li>World-class LLM team, including professors and leading scholars like <strong>Filip Ginter</strong>, <strong>Jussi Karlgren</strong>, <strong>Sampo Pyysalo</strong>, <strong>Magnus Sahlgren</strong>, <strong>Aarne Talman</strong> among others, as well as others involved out of Silo AI’s more than 150 PhDs and 300 AI experts, </li>
	<li>Data resources covering all European languages and code, including <a href="https://hplt-project.org/">High-Performance Language Technology (HPLT) data</a>, and other collected and curated data, and </li>
	<li>Access to compute, including software infrastructure to train LLMs and access to the<a href="https://www.lumi-supercomputer.eu/"> LUMI supercomputer </a>and other hardware and cloud services for LLM training.</li>
</ul><p>In addition to a world-class team, the consortium has access to, and experience with, the LUMI supercomputer, which as one of the European High-Performance Computing (EuroHPC) undertakings is the third largest supercomputer in the world and the largest in Europe. Having built LLMs on LUMI for more than a year, the team has developed a distinctive software layer for training LLMs effectively and efficiently on the AMD-based hardware. As part of the EU-funded HPLT project, the data for this initiative has been collected and curated since early 2022 to provide a representative basis for LLM development. Combining all of this with a total of 15 million GPU hours, Silo AI and TurkuNLP are uniquely positioned to train a family of language models, including the world&#39;s largest open LLM.</p>

<p><img alt="Sampo Pyysalo lähikuvassa." data-entity-type="file" data-entity-uuid="2d0ab279-5ba5-494c-9bc6-3d56fa27050d" src="https://www.utu.fi/sites/default/files/inline-images/Sampo.Pyysalo-248.jpg" width="1000" height="740" loading="lazy"/></p>

<p><em>University Research Fellow in data analysis Sampo Pyysalo is the principal investigator of the High Performance Language Technologies consortium at Turku.</em></p>

<p>“LLMs are rapidly reshaping how we access information and interact with technology. As their impact grows, it is increasingly important to assure that the models are developed in a transparent and reproducible manner and made openly available to ensure accountability and equal access to the technology. From a European perspective, it is also critical that models are designed from the outset to prioritize multilinguality and an equitable approach to all languages. The High Performance Language Technologies (HPLT) project is addressing these goals through the creation of open European data resources and language models and delighted to partner in this consortium with SiloGen and Silo AI, an industry leader with shared goals&#34;, says Sampo Pyysalo, University of Turku Research Fellow and HPLT principal investigator..</p>

<p><img alt="Peter Sarlin lähikuvassa." data-entity-type="file" data-entity-uuid="0b39d04b-d7b0-40b5-8661-43ca59ded0e5" src="https://www.utu.fi/sites/default/files/inline-images/Peter%20Sarlin%2C%20CEO%20and%20Founder%20of%20Silo%20AI.jpg" width="1000" height="701" loading="lazy"/></p>

<p><em>Peter Sarlin is the CEO and co-founder of Silo AI.</em></p>

<p>“We are honored to contribute to the development of open LLMs. The development of base models aligned with European values is imperative for our digital sovereignty. This initiative helps to ensure that underlying models are based on data and information representing the citizens and organisations of the region, and overall compliance with regulation, data privacy and other vital concerns. And eventually we need sovereignty on how downstream applications and value creation happen. This requires trusted and secure approaches to independent base models that enable fine-tuning for domain-specific needs. This way we can ensure digital sovereignty, while advancing technological development,” says <strong>Peter Sarlin</strong>, CEO and co-founder of Silo AI.</p>

<p>The TurkuNLP research group’s extensive experience in NLP and LLMs aligns with Silo AI’s and SiloGen’s commitment to contribute to world-class research on generative AI. The alignment, combined with the resources of the consortium, provides a robust foundation for redefining the boundaries of what is possible in the world of open source language models. Together with the LLM development platform, this opens a unique path for companies to create value using independent, trusted and secure base models with a possibility to finetune, instruct and control LLMs for domain-specific needs.</p>

<p><strong>TurkuNLP research group</strong></p>

<p><strong>Silo AI </strong></p>

<p><strong>SiloGen</strong></p>
</div></div>
  </body>
</html>
