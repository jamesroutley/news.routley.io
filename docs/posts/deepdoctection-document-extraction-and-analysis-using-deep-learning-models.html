<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/deepdoctection/deepdoctection">Original</a>
    <h1>DeepDoctection: Document extraction and analysis using deep learning models</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepdoctection/deepdoctection/blob/master/docs/tutorials/_imgs/dd_logo.png"><img src="https://github.com/deepdoctection/deepdoctection/raw/master/docs/tutorials/_imgs/dd_logo.png" alt="Deep Doctection Logo" width="60%"/></a>
  </p><h3 tabindex="-1" dir="auto"><a id="user-content---a-document-ai-package--" aria-label="Heading link" href="#--a-document-ai-package--"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>
  A Document AI Package
  </h3>

<p dir="auto"><strong>deep</strong>doctection is a Python library that orchestrates document extraction and document layout analysis tasks using deep learning models. It does
not implement models but enables you to build pipelines using highly acknowledged libraries for object detection, OCR
and selected NLP tasks and provides an integrated framework for fine-tuning, evaluating and running models. For more
specific text processing tasks use one of the many other great NLP libraries.</p>
<p dir="auto"><strong>deep</strong>doctection focuses on applications and is made for those who want to solve real world problems related to
document extraction from PDFs or scans in various image formats.</p>
<p dir="auto">Check the demo of a document layout analysis pipeline with OCR on
<g-emoji alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png">ðŸ¤—</g-emoji> <a href="https://huggingface.co/spaces/deepdoctection/deepdoctection" rel="nofollow"><strong>Hugging Face spaces</strong></a>.</p>

<p dir="auto"><strong>deep</strong>doctection provides model wrappers of supported libraries for various tasks to be integrated into
pipelines. Its core function does not depend on any specific deep learning library. Selected models for the following
tasks are currently supported:</p>
<ul dir="auto">
<li>Document layout analysis including table recognition in Tensorflow with <a href="https://github.com/tensorpack"><strong>Tensorpack</strong></a>,
or PyTorch with <a href="https://github.com/facebookresearch/detectron2/tree/main/detectron2"><strong>Detectron2</strong></a>,</li>
<li>OCR with support of <a href="https://github.com/tesseract-ocr/tesseract"><strong>Tesseract</strong></a>, <a href="https://github.com/mindee/doctr"><strong>DocTr</strong></a>
(Tensorflow and PyTorch implementations available) and a wrapper to an API for a commercial solution,</li>
<li>Text mining for native PDFs with  <a href="https://github.com/jsvine/pdfplumber"><strong>pdfplumber</strong></a>,</li>
<li>Language detection with <a href="https://github.com/facebookresearch/fastText"><strong>fastText</strong></a>,</li>
<li>Deskewing and rotating images with jdeskew.</li>
<li>Document and token classification with all <a href="https://github.com/microsoft/unilm">LayoutLM</a> models
provided by the <a href="https://github.com/huggingface/transformers"><strong>Transformer</strong></a> library.
(Yes, you can use any LayoutLM-model with any of the provided OCR-or pdfplumber tools straight away!). Check the notebook repo or
the documentation on how to train a model on your custom task or how to setup a pipeline.</li>
<li>Table detection and table structure recognition with
<a href="https://github.com/microsoft/table-transformer"><strong>table-transformer</strong></a>. You can try a pipeline using
<a href="https://github.com/deepdoctection/deepdoctection/discussions/116" data-hovercard-type="discussion" data-hovercard-url="/deepdoctection/deepdoctection/discussions/116/hovercard"><strong>this script</strong></a>.</li>
</ul>
<p dir="auto"><strong>deep</strong>doctection provides on top of that methods for pre-processing inputs to models like cropping or resizing and to
post-process results, like validating duplicate outputs, relating words to detected layout segments or ordering words
into contiguous text. You will get an output in JSON format that you can customize even further by yourself.</p>
<p dir="auto">Have a look at the <a href="https://github.com/deepdoctection/notebooks/blob/main/Get_Started.ipynb"><strong>introduction notebook</strong></a> in the
<a href="https://github.com/deepdoctection/notebooks">notebook repo</a> for an easy start.</p>
<p dir="auto">Check the <a href="https://github.com/deepdoctection/deepdoctection/releases"><strong>release notes</strong></a> for recent updates.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-models" aria-label="Heading link" href="#models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Models</h2>
<p dir="auto"><strong>deep</strong>doctection or its support libraries provide pre-trained models that are in most of the cases available at the
<a href="https://huggingface.co/deepdoctection" rel="nofollow"><strong>Hugging Face Model Hub</strong></a> or that will be automatically downloaded once
requested. For instance, you can find pre-trained object detection models from the Tensorpack or Detectron2 framework
for coarse layout analysis, table cell detection and table recognition.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-datasets-and-training-scripts" aria-label="Heading link" href="#datasets-and-training-scripts"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Datasets and training scripts</h2>
<p dir="auto">Training is a substantial part to get pipelines ready on some specific domain, let it be document layout analysis,
document classification or NER. <strong>deep</strong>doctection provides training scripts for models that are based on trainers
developed from the library that hosts the model code. Moreover, <strong>deep</strong>doctection hosts code to some well established
datasets like <strong>Publaynet</strong> that makes it easy to experiment. It also contains mappings from widely used data
formats like COCO and it has a dataset framework (akin to <a href="https://github.com/huggingface/datasets"><strong>datasets</strong></a> so that
setting up training on a custom dataset becomes very easy. <a href="https://github.com/deepdoctection/notebooks/blob/main/Datasets_and_Eval.ipynb"><strong>This notebook</strong></a>
shows you how to do this.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-evaluation" aria-label="Heading link" href="#evaluation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Evaluation</h2>
<p dir="auto"><strong>deep</strong>doctection comes equipped with a framework that allows you to evaluate predictions of a single or multiple
models in a pipeline against some ground truth. Check again <a href="https://github.com/deepdoctection/notebooks/blob/main/Datasets_and_Eval.ipynb"><strong>here</strong></a> how it is
done.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-inference" aria-label="Heading link" href="#inference"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Inference</h2>
<p dir="auto">Having set up a pipeline it takes you a few lines of code to instantiate the pipeline and after a for loop all pages will
be processed through the pipeline.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import deepdoctection as dd
from IPython.core.display import HTML
from matplotlib import pyplot as plt

analyzer = dd.get_dd_analyzer()  # instantiate the built-in analyzer similar to the Hugging Face space demo

df = analyzer.analyze(path = &#34;/path/to/your/doc.pdf&#34;)  # setting up pipeline
df.reset_state()                 # Trigger some initialization

doc = iter(df)
page = next(doc) 

image = page.viz()
plt.figure(figsize = (25,17))
plt.axis(&#39;off&#39;)
plt.imshow(image)"><pre><span>import</span> <span>deepdoctection</span> <span>as</span> <span>dd</span>
<span>from</span> <span>IPython</span>.<span>core</span>.<span>display</span> <span>import</span> <span>HTML</span>
<span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>

<span>analyzer</span> <span>=</span> <span>dd</span>.<span>get_dd_analyzer</span>()  <span># instantiate the built-in analyzer similar to the Hugging Face space demo</span>

<span>df</span> <span>=</span> <span>analyzer</span>.<span>analyze</span>(<span>path</span> <span>=</span> <span>&#34;/path/to/your/doc.pdf&#34;</span>)  <span># setting up pipeline</span>
<span>df</span>.<span>reset_state</span>()                 <span># Trigger some initialization</span>

<span>doc</span> <span>=</span> <span>iter</span>(<span>df</span>)
<span>page</span> <span>=</span> <span>next</span>(<span>doc</span>) 

<span>image</span> <span>=</span> <span>page</span>.<span>viz</span>()
<span>plt</span>.<span>figure</span>(<span>figsize</span> <span>=</span> (<span>25</span>,<span>17</span>))
<span>plt</span>.<span>axis</span>(<span>&#39;off&#39;</span>)
<span>plt</span>.<span>imshow</span>(<span>image</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/blob/master/docs/tutorials/_imgs/dd_rm_sample.png"><img src="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/raw/master/docs/tutorials/_imgs/dd_rm_sample.png" alt="text"/></a></p>
<div data-snippet-clipboard-copy-content="HTML(page.tables[0].html)"><pre><code>HTML(page.tables[0].html)
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/blob/master/docs/tutorials/_imgs/dd_rm_table.png"><img src="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/raw/master/docs/tutorials/_imgs/dd_rm_table.png" alt="table"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/blob/master/docs/tutorials/_imgs/dd_rm_text.png"><img src="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/raw/master/docs/tutorials/_imgs/dd_rm_text.png" alt="table"/></a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-documentation" aria-label="Heading link" href="#documentation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<p dir="auto">There is an extensive <a href="https://deepdoctection.readthedocs.io/en/latest/index.html#" rel="nofollow"><strong>documentation</strong></a> available
containing tutorials, design concepts and the API. We want to present things as comprehensively and understandably
as possible. However, we are aware that there are still many areas where significant improvements can be made in terms
of clarity, grammar and correctness. We look forward to every hint and comment that increases the quality of the
documentation.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-requirements" aria-label="Heading link" href="#requirements"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Requirements</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/blob/master/docs/tutorials/_imgs/requirements_deepdoctection.png"><img src="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/raw/master/docs/tutorials/_imgs/requirements_deepdoctection.png" alt="requirements"/></a></p>
<p dir="auto">Everything in the overview listed below the <strong>deep</strong>doctection layer are necessary requirements and have to be installed
separately.</p>
<ul dir="auto">
<li>Linux or macOS. (Windows is not supported but there is a <a href="https://ideasimagerystory.substack.com/deepdoctection/deepdoctection/blob/master/docker/pytorch-cpu-jupyter/Dockerfile">Dockerfile</a> available)</li>
<li>Python &gt;= 3.8</li>
<li>PyTorch &gt;= 1.8 <strong>or</strong> Tensorflow &gt;= 2.9 and CUDA. If you want to run the models provided by Tensorpack a GPU is
required. You can run on PyTorch with a CPU only.</li>
<li><strong>deep</strong>doctection uses Python wrappers for <a href="https://poppler.freedesktop.org/" rel="nofollow">Poppler</a> to convert PDF documents into
images.</li>
<li>With respect to the Deep Learning framework, you must decide between <a href="https://www.tensorflow.org/install?hl=en" rel="nofollow">Tensorflow</a>
and <a href="https://pytorch.org/get-started/locally/" rel="nofollow">PyTorch</a>.</li>
<li><a href="https://github.com/tesseract-ocr/tesseract">Tesseract</a> OCR engine will be used through a Python wrapper. The core
engine has to be installed separately.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-installation" aria-label="Heading link" href="#installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">We recommend using a virtual environment. You can install the package via pip or from source. Bug fixes or enhancements
will be deployed to PyPi every 4 to 6 weeks.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-install-with-pip-from-pypi" aria-label="Heading link" href="#install-with-pip-from-pypi"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Install with pip from PyPi</h3>
<p dir="auto">Depending on which Deep Learning library you have available, use the following installation option:</p>
<p dir="auto">For <strong>Tensorflow</strong>, run</p>
<div data-snippet-clipboard-copy-content="pip install deepdoctection[tf]"><pre><code>pip install deepdoctection[tf]
</code></pre></div>
<p dir="auto">For <strong>PyTorch</strong>,</p>
<p dir="auto">first install <strong>Detectron2</strong> separately as it is not distributed via PyPi. Check the instruction
<a href="https://detectron2.readthedocs.io/en/latest/tutorials/install.html" rel="nofollow">here</a>. Then run</p>
<div data-snippet-clipboard-copy-content="pip install deepdoctection[pt]"><pre><code>pip install deepdoctection[pt]
</code></pre></div>
<p dir="auto">This will install <strong>deep</strong>doctection with all dependencies listed above the <strong>deep</strong>doctection layer. Use this setting,
if you want to get started or want to explore all features.</p>
<p dir="auto">If you want to have more control with your installation and are looking for fewer dependencies then
install <strong>deep</strong>doctection with the basic setup only.</p>
<div data-snippet-clipboard-copy-content="pip install deepdoctection"><pre><code>pip install deepdoctection
</code></pre></div>
<p dir="auto">This will ignore all model libraries (layers above the <strong>deep</strong>doctection layer in the diagram) and you
will be responsible to install them by yourself. Note, that you will not be able to run any pipeline with this setup.</p>
<p dir="auto">For further information, please consult the <a href="https://deepdoctection.readthedocs.io/en/latest/manual/install.html" rel="nofollow"><strong>full installation instructions</strong></a>.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-installation-from-source" aria-label="Heading link" href="#installation-from-source"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation from source</h3>
<p dir="auto">Download the repository or clone via</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/deepdoctection/deepdoctection.git"><pre><code>git clone https://github.com/deepdoctection/deepdoctection.git
</code></pre></div>
<p dir="auto">To get started with <strong>Tensorflow</strong>, run:</p>
<div data-snippet-clipboard-copy-content="cd deepdoctection
pip install &#34;.[tf]&#34;"><pre><code>cd deepdoctection
pip install &#34;.[tf]&#34;
</code></pre></div>
<p dir="auto">Installing the full <strong>PyTorch</strong> setup from source will also install <strong>Detectron2</strong> for you:</p>
<div data-snippet-clipboard-copy-content="cd deepdoctection
pip install &#34;.[source-pt]&#34;"><pre><code>cd deepdoctection
pip install &#34;.[source-pt]&#34;
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-credits" aria-label="Heading link" href="#credits"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Credits</h2>
<p dir="auto">We thank all libraries that provide high quality code and pre-trained models. Without, it would have been impossible
to develop this framework.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-problems" aria-label="Heading link" href="#problems"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Problems</h2>
<p dir="auto">We try hard to eliminate bugs. We also know that the code is not free of issues. We welcome all issues relevant to this
repo and try to address them as quickly as possible.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-if-you-like-deepdoctection-" aria-label="Heading link" href="#if-you-like-deepdoctection-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>If you like <strong>deep</strong>doctection ...</h2>
<p dir="auto">...you can easily support the project by making it more visible. Leaving a star or a recommendation will help.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-license" aria-label="Heading link" href="#license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h2>
<p dir="auto">Distributed under the Apache 2.0 License. Check <a href="https://github.com/deepdoctection/deepdoctection/blob/master/LICENSE">LICENSE</a>
for additional information.</p>
</article>
          </div></div>
  </body>
</html>
