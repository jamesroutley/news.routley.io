<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.scattered-thoughts.net/writing/babys-second-wasm-compiler/">Original</a>
    <h1>Baby&#39;s second wasm compiler</h1>
    
    <div id="readability-page-1" class="page"><article>
  
<p>(<em>This is part of a series on the design of a language. See the list of posts <a href="https://www.scattered-thoughts.net/#zest">here</a></em>.)</p>
<p>The zest compiler today is ~4500 loc with no dependencies except the zig standard library.</p>
<p>It generates wasm of similar quality to an llvm at <code>-O0</code>, although I have some ideas to try later that I hope will push the output closer towards <code>-O1</code>.</p>
<p>There are still some low-hanging optimizations to pick off in the compiler, but within the next year or so I&#39;m expecting compile times to be similar to zig&#39;s new non-llvm wasm backend - somewhere around ~10x faster than an llvm release build and ~3x faster than an llvm debug build.</p>
<p>The language itself is far from complete, but the codegen is now basically done. It supports integers, structs, basic control flow, arithmetic, comparisons, mutable references (2nd class, interior), functions (non-recursive), closures, destructuring, type inference, compile-time evaluation, function specialization etc.</p>
<p>The plan for the rest of the core language features - allocation, strings, list, maps, etc - to be mostly implemented in zest itself. This is standard to c/c++/zig/rust but unusual for a memory-safe language - the only example I know of is <a href="https://github.com/titzer/virgil">virgil</a>.  In <a href="https://www.scattered-thoughts.net/writing/babys-first-wasm-compiler">my first compiler</a> I linked to a runtime written in zig, but the linking was a pita and having to pull in a entirely different language just for the runtime made my minimalist heart ache.</p>
<p>Writing the runtime in the same language will also allow optimization across the runtime boundary, so I can type-specialize runtime functions and eliminate dead runtime code eg if you write a zest program that doesn&#39;t use heap allocation then the resulting wasm won&#39;t contain allocator code.</p>
<hr/>
<p>The compiler pipeline looks like:</p>
<ul>
<li>parse
<ul>
<li>LL(1)</li>
<li>produces sir (syntax intermediate representation)</li>
</ul>
</li>
<li>desugar
<ul>
<li>resolves names</li>
<li>converts closures into regular functions that take an extra argument</li>
<li>desugars destructuring into imperative code</li>
<li>replaces mutable variables with <code>ref</code> values</li>
<li>creates wrappers for each function that can be called dynamically</li>
<li>inserts staging annotations on struct keys</li>
<li>inserts asserts to prevent mutable references from escaping</li>
<li>produces dir (dynamic intermediate representation)</li>
</ul>
</li>
<li>eval
<ul>
<li>an interpreter for the dynamically-typed dialect of zest</li>
</ul>
</li>
<li>infer
<ul>
<li>infers types of each expression</li>
<li>specializes functions to their argument types</li>
<li>does compile-time evaluation by calling into eval</li>
<li>replaces struct keys with static offsets</li>
<li>produces tir (typed intermediate representation)</li>
</ul>
</li>
<li>generate
<ul>
<li>inlines function wrappers</li>
<li>propagates constants</li>
<li>eliminates dead branches and loops</li>
<li>chooses how to represent values (eg on shadow stack vs in a wasm local)</li>
<li>tracks the wasm stack to avoid unnecessary locals</li>
<li>produces wasm</li>
</ul>
</li>
</ul>
<hr/>
<p>Rather than a linear ir, I stuck to a tree of expressions with explicit variables, like wasm. This makes it very easy during codegen to distinguish between an expression (consumed exactly once, in stack order) and variables (consumed zero or more times, at any point in the scope). I&#39;ll explain later why that&#39;s useful.</p>
<p>Rather than use pointers or indices to refer to child expressions, I store the tree as a pre-and-post-order traversal, so each branch has both a begin and end tag. It looks like this:</p>
<pre><code><span>--- SOURCE ---
</span><span>a = 3
</span><span>a + 1
</span><span>
</span><span>--- TOKENS ---
</span><span>zest.TokenData.name
</span><span>zest.TokenData.space
</span><span>zest.TokenData.=
</span><span>zest.TokenData.space
</span><span>zest.TokenData.number
</span><span>zest.TokenData.newline
</span><span>zest.TokenData.name
</span><span>zest.TokenData.space
</span><span>zest.TokenData.+
</span><span>zest.TokenData.space
</span><span>zest.TokenData.number
</span><span>zest.TokenData.eof
</span><span>
</span><span>--- SIR ---
</span><span>block_begin
</span><span>  let_begin
</span><span>    i32 3
</span><span>    indirect
</span><span>    name a mut=false
</span><span>  let_end
</span><span>  block_last
</span><span>  indirect
</span><span>  call_builtin_begin
</span><span>    indirect
</span><span>    name a mut=false
</span><span>    i32 1
</span><span>  call_builtin_end zest.Builtin.add
</span><span>block_end
</span><span>
</span><span>--- DIR ---
</span><span>main = f0
</span><span>f0 = (closure)
</span><span>  local l0
</span><span>  return_begin
</span><span>    assert_has_no_ref_begin
</span><span>      block_begin
</span><span>        local_let_begin
</span><span>          assert_has_no_ref_visible_begin
</span><span>            i32 3
</span><span>          assert_has_no_ref_visible_end
</span><span>        local_let_end l0
</span><span>        block_last
</span><span>        call_builtin_begin
</span><span>          nop_begin
</span><span>            local_get l0
</span><span>          nop_end
</span><span>          i32 1
</span><span>        call_builtin_end zest.Builtin.add
</span><span>      block_end
</span><span>    assert_has_no_ref_end
</span><span>  return_end
</span><span>
</span><span>--- TIR ---
</span><span>main = f0
</span><span>f0 = (closure)
</span><span>  local l0 /i32
</span><span>  return_begin
</span><span>    block_begin
</span><span>      local_let_begin
</span><span>        i32 3
</span><span>      local_let_end l0
</span><span>      block_last
</span><span>      call_builtin_begin
</span><span>        local_get l0
</span><span>        i32 1
</span><span>      call_builtin_end tir.BuiltinTyped.add_i32
</span><span>    block_end
</span><span>  return_end
</span><span>
</span><span>--- WAT ---
</span><span>(module
</span><span>  (type (;0;) (func (result i32)))
</span><span>  (func (;0;) (type 0) (result i32)
</span><span>    (i32.add
</span><span>      (i32.const 3)
</span><span>      (i32.const 1)))
</span><span>  (memory (;0;) 128)
</span><span>  (global (;0;) (mut i32) (i32.const 8388608))
</span><span>  (export &#34;main&#34; (func 0))
</span><span>  (export &#34;memory&#34; (memory 0)))
</span></code></pre>
<p>This is very compact (or will be when I get around to removing padding and interning strings/types). Each expr needs 1-2 bytes of tags and 0-4 bytes of data. That data includes types, which I only need to store on a few tir exprs.</p>
<p>I&#39;m not sure how this compares to zig. Each zig instruction has a 1 byte tag and 8 bytes of data. Instructions like <code>call</code> that take a variable number of operands pay an additional 4 bytes per operand. But in zig&#39;s later irs there are no explicit variables, whereas I have to pay 5 bytes for each <code>local_let</code> and <code>local_get</code>.</p>
<hr/>
<p>Compared to most other compilers though, both zest and zig have tiny irs.</p>
<p>Cranelift instructions are <a href="https://github.com/bytecodealliance/wasmtime/blob/a068bfe06435a048502bf4afc426451dab5294af/cranelift/codegen/src/ir/instructions.rs#L28">16 bytes</a>, plus optional extra operands, plus <a href="https://github.com/bytecodealliance/wasmtime/blob/a068bfe06435a048502bf4afc426451dab5294af/cranelift/codegen/src/ir/layout.rs#L602">16 bytes</a> for their control flow data. </p>
<p>As for llvm, I don&#39;t have enough c++ knowledge to put a size on <a href="https://llvm.org/doxygen/classllvm_1_1Instruction.html">this class hierarchy</a> but the next/prev/parent pointers alone must cost 24 bytes. If those are individually heap-allocated too then there is likely additional overhead from fragmentation.</p>
<p>This is kind of a fork in the road for ir design. If you want to do any kind of code motion or peephole optimization then you need an ir that allows cheap insertion and deletion, which usually means 2+ indices/pointers per instruction for the control-flow graph, and maybe additional indices/pointers to manage the operand lists of instructions like <code>call</code> that take a variable number of operands. </p>
<p>But if you want to go produce code really fast, you want to touch as little memory as possible, and touch it in prefetcher-friendly access patterns rather than jumping around linked lists.</p>
<p>Every book I could find on compilers was about going down the optimization fork. The other fork is less well travelled. I found just a smattering of useful papers:</p>
<ul>
<li><a href="https://bernsteinbear.com/assets/img/46b-codegeneration-in-V8.pdf">One-pass Code Generation in V8</a></li>
<li><a href="https://arxiv.org/pdf/2305.13241">Whose baseline compiler is it anyway?</a></li>
<li><a href="https://link.springer.com/content/pdf/10.1007/s00778-020-00643-4.pdf">Tidy Tuples and Flying Start: fast compilation and fast execution of relational queries in Umbra</a></li>
</ul>
<p>(If you know other good resources, <a href="mailto:jamie@scattered-thoughts.net">let me know</a>!)</p>
<hr/>
<p>The big downside of my tree encoding is that I have to produce the tree in order. In most passes this is fine but during parsing it&#39;s a problem, so in sir I have a pay-as-you-go indirection via <code>Expr{.indirect = offset}</code>. This tells the consuming code to jump to the offset, consume a sub-tree, and then jump back to the next expr after the <code>indirect</code>. </p>
<p>Parsing <code>a + 1</code> looks like this:</p>
<ul>
<li>Consume <code>a</code>. Put <code>Expr{.name = &#34;a&#34;}</code> in the buffer.</li>
<li>Consume <code>+</code>. Move the contents of the buffer to the tree. Put <code>Expr.call_builtin_begin, Expr{.indirect = 0}</code> in the buffer.</li>
<li>Consume <code>1</code>. Put <code>Expr{.i32 = 1}, Expr{.call_builtin_end = .add}</code> in the buffer.</li>
<li>Consume <code>eof</code>. Move the contents of the buffer to the tree. Put <code>Expr{.indirect = 1}</code> in the buffer.</li>
</ul>
<p>And produces:</p>
<pre><code><span>call_builtin_begin
</span><span>  indirect
</span><span>  name a mut=false
</span><span>  i32 1
</span><span>call_builtin_end zest.Builtin.add
</span></code></pre>
<p>This adds 5 bytes to the ir for every infix/postfix expression in the source, which is a little painful, and it also means that I touch every byte in sir twice during parsing. But it still produces fairly significant space savings vs using indices everywhere, and it also only applies to sir - dir and tir don&#39;t have an indirect expr.</p>
<hr/>
<p>Each pass is roughly linear in complexity and (aside from a few edge cases in desugar) touches each expr in its input only once.</p>
<p>Eval uses the tree like a stack machine, ignoring begin tags and accumulating values on a stack. Currently some of the control flow requires scanning forward over subtrees - I might want to store offsets in <code>if_then</code>, <code>if_else</code> and <code>while_body</code> to avoid that.</p>
<p>Type inference happens after function specialization, like zig, and is a simple bidirectional system that conservatively approximates the behaviour of the dynamic type checks in eval. It only deals with concrete types and there is no unification.</p>
<hr/>
<p>Stack overflows in compilers are a nuisance (<a href="https://github.com/MaterializeInc/materialize/issues?q=is%3Aissue+stack+exhaustion+">eg</a>), but transformations of trees of expressions are naturally recursive. Hand-converting them to a manual stack produces hideous code.</p>
<p>My compromise at the moment is that eval and infer use a manual stack, because both could overflow from errors in reasonable programs and I want to provide good errors in that case.</p>
<p>The other passses are recursive but their call stack is bounded by the nesting depth of the source. They only overflow if you are a honggfuzz and keep generating one million nested parentheses instead of finding real bugs. This is annoying but the workarounds are worse. </p>
<p>I did write a version of generate that ran in constant stack space but it was significantly harder to read - when I rewrote it to be recursive I immediately spotted three bugs!</p>
<p>In the long run I think the nicest solution is to self-host the compiler and then use <a href="https://wasmfx.dev/">wasmfx</a> or similar to manually segment the stack in the recursive passes when the recursion depth hits some fixed limit.</p>
<hr/>
<p>In wasm you get one big heap of memory and some mutable local variables. Locals can only hold primitive values (integers, floats, etc) and can&#39;t be pointed to. So for languages that can create pointers to stack-allocated values the usual solution is to designate some fixed portion of the heap as the &#39;shadow stack&#39; and then use a global variable to track the stack pointer. </p>
<p>For each value the compiler has to decide how to represent that value. Currently I have a very conservative strategy. Zest integers are represented directly by wasm integers. All other values are stored on the shadow stack. Mutable variables are always stored on the stack, even if they are integers. </p>
<p>My calling convetion is similar. Integer arguments to functions are passed directly. Other arguments are passed by reference. Functions that return integers do so directly. Functions that return other values take an extra argument pointing to where they should store their result.</p>
<p>This is definitely suboptimal, but it&#39;s simple and it&#39;s easy to change later. Most of the codegen is unaware of these rules - it&#39;s all encoded in:</p>
<pre data-lang="zig"><code data-lang="zig"><span>fn </span><span>wasmRepr</span><span>(</span><span>repr</span><span>: </span><span>Repr</span><span>) </span><span>WasmRepr </span><span>{
</span><span>    </span><span>return switch </span><span>(repr) {
</span><span>        .i32</span><span>,</span><span> .ref </span><span>=&gt;</span><span> .{ .primitive </span><span>= </span><span>wasmAbi</span><span>(repr) }</span><span>,
</span><span>        .string</span><span>,</span><span> .@&#34;struct&#34;</span><span>,</span><span> .@&#34;union&#34;</span><span>,</span><span> .fun</span><span>,</span><span> .only</span><span>,</span><span> .repr </span><span>=&gt;</span><span> .heap</span><span>,
</span><span>    }</span><span>;
</span><span>}
</span></code></pre>
<p>Here&#39;s an example:</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>f = (a) {
</span><span>  b = 1
</span><span>  c = a + b
</span><span>  d = [c]
</span><span>  [d]
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>;; param 0 is `a`
</span><span>;; param 1 is the result pointer
</span><span>(func (;1;) (type 1) (param i32 i32)
</span><span>  (local i32 i32)
</span><span>
</span><span>  ;; allocate 4 bytes on the shadow stack
</span><span>  (local.set 3
</span><span>    (i32.sub
</span><span>      (global.get 0)
</span><span>      (i32.const 4)))
</span><span>
</span><span>  ;; `b` gets constant folded away
</span><span>  
</span><span>  ;; `c` is stored in a local
</span><span>  (local.set 2
</span><span>    (i32.add
</span><span>      (local.get 0)
</span><span>      (i32.const 1)))
</span><span>
</span><span>  ;; `d` is stored on the shadow stack
</span><span>  (i32.store align=1
</span><span>    (local.get 3)
</span><span>    (local.get 2))
</span><span>
</span><span>  ;; `d` is copied into the result pointer
</span><span>  (i32.store align=1
</span><span>    (local.get 1)
</span><span>    (i32.load align=1
</span><span>      (local.get 3))))
</span></code></pre>
<hr/>
<p>The codegen revolves around this function:</p>
<pre data-lang="zig"><code data-lang="zig"><span>fn </span><span>genExpr</span><span>(
</span><span>    </span><span>c</span><span>: </span><span>*</span><span>Compiler</span><span>,
</span><span>    </span><span>f</span><span>: </span><span>*</span><span>wir.FunData</span><span>,
</span><span>    </span><span>tir_f</span><span>: </span><span>tir.FunData</span><span>,
</span><span>    </span><span>dest</span><span>: </span><span>wir.Destination</span><span>,
</span><span>) </span><span>error</span><span>{GenerateError}</span><span>!</span><span>wir.Walue </span><span>{
</span><span>    </span><span>// ...
</span><span>}
</span></code></pre>
<p>It consumes an expression tree, emits some wasm code to compute the value of that tree, and returns an abstract value - a description of where and how the result of that expr can be accessed. I call these abstract values <code>Walue</code>s and I say it to myself in a <a href="https://www.youtube.com/watch?v=w2X7XqYunho&amp;t=41s">wario voice</a>.</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub const </span><span>Walue </span><span>= </span><span>union</span><span>(</span><span>enum</span><span>) {
</span><span>    stack</span><span>: </span><span>wasm.Valtype</span><span>,
</span><span>
</span><span>    </span><span>// local variables
</span><span>    closure</span><span>, 
</span><span>    arg</span><span>: </span><span>tir.Arg</span><span>,
</span><span>    @</span><span>&#34;return&#34;</span><span>, </span><span>// value of the result pointer argument
</span><span>    local</span><span>: </span><span>Local</span><span>,
</span><span>
</span><span>    </span><span>// global variables
</span><span>    shadow</span><span>, </span><span>// value of the shadow stack pointer global
</span><span>
</span><span>    </span><span>// literals
</span><span>    i32</span><span>: </span><span>i32</span><span>,
</span><span>    @&#34;struct&#34;</span><span>: </span><span>struct </span><span>{
</span><span>        repr</span><span>: </span><span>ReprStruct</span><span>,
</span><span>        values</span><span>:</span><span> []</span><span>Walue</span><span>, </span><span>// may not contain .stack
</span><span>    }</span><span>,
</span><span>    fun</span><span>: </span><span>struct </span><span>{
</span><span>        repr</span><span>: </span><span>ReprFun</span><span>,
</span><span>        closure</span><span>: </span><span>*</span><span>Walue</span><span>, </span><span>// may not contain .stack
</span><span>    }</span><span>,
</span><span>
</span><span>    </span><span>// heap addresses
</span><span>    value_at</span><span>: </span><span>struct </span><span>{
</span><span>        ptr</span><span>: </span><span>*</span><span>Walue</span><span>,
</span><span>        repr</span><span>: </span><span>Repr</span><span>,
</span><span>    }</span><span>,
</span><span>    add</span><span>: </span><span>struct </span><span>{
</span><span>        walue</span><span>: </span><span>*</span><span>Walue</span><span>,
</span><span>        offset</span><span>: </span><span>u32</span><span>,
</span><span>    }</span><span>,
</span><span>}</span><span>;
</span></code></pre>
<p>These walues allow the codegen to handle literals lazily. Eg if I call genExpr on a struct expression, it just returns a struct walue instead of actually emitting wasm to create the struct. If it turns out later that I actually do need to allocate the struct, I can do it then. If not, then I saved an allocation.</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>f = (options: [:length, :width]) length + width
</span><span>f(
</span><span>  // It&#39;s pointless to allocate this struct just to destructure it again
</span><span>  options: [length: 4, width: 7],
</span><span>)
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>;; func 0 is `main`
</span><span>(func (;0;) (type 0) (result i32)
</span><span>  ;; no stack allocations here - directly call `f` with constant arguments
</span><span>  (call 1
</span><span>    (i32.const 4)
</span><span>    (i32.const 7)))
</span><span>
</span><span>;; func 1 is `f`
</span><span>(func (;1;) (type 1) (param i32 i32) (result i32)
</span><span>  (i32.add
</span><span>    (local.get 0)
</span><span>    (local.get 1)))
</span></code></pre>
<p>This is where the distinction I mentioned earlier between expressions and variables becomes important. Generating walues lazily can cause more work if I do it more than once, or inside a loop. So a useful heuristic is to be lazy when generating expressions but eager when generating variables.</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>f = (options: [:length, :width]) length * width
</span><span>// Should create options on the shadow stack here...
</span><span>options = [length: 4, width: 7]
</span><span>i mut = 0
</span><span>while {i &lt; 10} {
</span><span>   // ...rather than lazily here!
</span><span>   i@ = f(:options)
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wat
</span><span>(func (;0;) (type 0)
</span><span>  (local i32 i32 i32 i32)
</span><span>
</span><span>  ;; push stack frame
</span><span>  (global.set 0
</span><span>    (local.tee 0
</span><span>      (i32.sub
</span><span>        (global.get 0)
</span><span>        (i32.const 12))))
</span><span>
</span><span>  ;; copy `options` to the shadow stack
</span><span>  (i32.store align=1
</span><span>    (local.get 0)
</span><span>    (i32.const 4))
</span><span>  (i32.store offset=4 align=1
</span><span>    (local.get 0)
</span><span>    (i32.const 7))
</span><span>
</span><span>  ;; initialize `i` on the shadow stack
</span><span>  (i32.store offset=8 align=1
</span><span>    (local.get 0)
</span><span>    (i32.const 0))
</span><span>
</span><span>  ;; while
</span><span>  (block  ;; label = @1
</span><span>    (loop  ;; label = @2
</span><span>
</span><span>      ;; if not(i &lt; 10) break
</span><span>      (br_if 1 (;@1;)
</span><span>        (i32.eqz
</span><span>          (i32.lt_s
</span><span>            (i32.load offset=8 align=1
</span><span>              (local.get 0))
</span><span>            (i32.const 10))))
</span><span>
</span><span>      ;; tmp = f(:options)
</span><span>      (local.set 1
</span><span>        (i32.load align=1
</span><span>          (local.get 0)))
</span><span>      (local.set 2
</span><span>        (i32.load offset=4 align=1
</span><span>          (local.get 0)))
</span><span>      (local.set 3
</span><span>        (call 1
</span><span>          (local.get 1)
</span><span>          (local.get 2)))
</span><span>
</span><span>      ;; i = tmp
</span><span>      (i32.store offset=8 align=1
</span><span>        (local.get 0)
</span><span>        (local.get 3))
</span><span>
</span><span>      ;; continue
</span><span>      (br 0 (;@2;))))
</span><span>
</span><span>  ;; pop stack frame
</span><span>  (global.set 0
</span><span>    (i32.add
</span><span>      (local.get 0)
</span><span>      (i32.const 12))))
</span></code></pre>
<p>Of course being eager can be wasteful if a variable is used only once, or only parts of it are used.</p>
<pre data-lang="zest"><code data-lang="zest"><span>// Copying this to the stack was a waste.
</span><span>options = [length: 4, width: 7]
</span><span>f(:options)
</span><span>
</span><span>// Didn&#39;t even need this struct - could have just constant-folded the whole thing.
</span><span>options = [length: 4, width: 7]
</span><span>area = options.length * options.width
</span></code></pre>
<p>But because I&#39;m doing all this in a single pass I can&#39;t look ahead to see how a variable is used. I could record that information in a previous pass, but the constant-propagation and dead-code elimination that I do during generate can change how variables are used! Near the end of the post I have some ideas for how to improve this.</p>
<hr/>
<p>The codegen for the example above may have been surprising.</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>f = (options: [:length, :width]) length + width
</span><span>f(options: [length: 4, width: 7])
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>;; func 0 is `main`
</span><span>(func (;0;) (type 0) (result i32)
</span><span>  ;; no stack allocations here - directly call `f` with constant arguments
</span><span>  (call 1
</span><span>    (i32.const 4)
</span><span>    (i32.const 7)))
</span><span>
</span><span>;; func 1 is `f`
</span><span>(func (;1;) (type 1) (param i32 i32) (result i32)
</span><span>  (i32.add
</span><span>    (local.get 0)
</span><span>    (local.get 1)))
</span></code></pre>
<p><code>f</code> takes one argument, which is a struct. But the generate code takes two arguments which are both integers. This is because of the way I handle destructuring of function arguments. In the dir the example above actually gets rewritten to something like:</p>
<pre data-lang="zest"><code data-lang="zest"><span>f = (length, width) length + width
</span><span>f-wrapper = (args) {
</span><span>  assert-is-struct(args)
</span><span>  assert(args.len == 1)
</span><span>  options = args.options
</span><span>  assert-is-struct(options)
</span><span>  assert(options.len == 2)
</span><span>  length = options.length
</span><span>  width = options.width
</span><span>  f(length, width)
</span><span>}
</span><span>f-wrapper([options: [length: 4, width: 7]])
</span></code></pre>
<p>This means that the interpreter doesn&#39;t have to know about destructuring.</p>
<p>During type-checking all of the assertions are checked statically - either producing a type error or disappearing from the code entirely. So the tir looks like:</p>
<pre data-lang="zest"><code data-lang="zest"><span>f = (length, width) length + width
</span><span>f-wrapper = (args) {
</span><span>  options = args.options
</span><span>  length = options.length
</span><span>  width = options.width
</span><span>  f(length, width)
</span><span>}
</span><span>f-wrapper([options: [length: 4, width: 7]])
</span></code></pre>
<p>Finally, during codegen all wrapper functions are inline. Constant propagation fuses the creatioin and destructuring of structs, producing:</p>
<pre data-lang="zest"><code data-lang="zest"><span>f = (length, width) length + width
</span><span>f(4, 7)
</span></code></pre>
<p>Right now this is just a cutesy, but I&#39;m planning to add functions to destructuring too, allowing for type casts, default arguments etc.</p>
<pre data-lang="zest"><code data-lang="zest"><span>f = (options: [
</span><span>  :length /i32 /else(0), 
</span><span>  :width /i32 /else(0),
</span><span>]) {
</span><span>  length + width
</span><span>}
</span></code></pre>
<p>These will get optimized away similarly. Type-checking will either generate a compile-time error or insert the cast code in the function wrapper. Then after inlining the cast ends up in the caller. So we can call <code>f</code> with lots of different integer types, as long as they can be cast to i32 safely, but we&#39;ll still only generate one specialization for <code>f</code> because all the casts happen in the caller.</p>
<hr/>
<p>When generating a variable declaration like <code>a = 1</code>, I record the walue and then return it later from any uses of <code>a</code>. This provides some basic constant-propagation through variables.</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>a = 1
</span><span>a
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>(i32.const 1)
</span></code></pre>
<p>But for mutable variables the walue represents their address rather than their value.</p>
<pre><code><span>// zest
</span><span>a mut = 1
</span><span>a
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>(i32.store align=1
</span><span>  (local.get 0)
</span><span>  (i32.const 1))
</span><span>(i32.load align=1
</span><span>  (local.get 0))
</span></code></pre>
<p>In fact, I only ever use walues to represent constant values. This prevents the mapping from variable to walue ever needing to change. </p>
<p>If I actually tracked the value of mutable variables, even abstractly, then I would have to be really careful around assignments, branches, and loops to track different versions of the same variable. This is the problem that <a href="https://en.wikipedia.org/wiki/Static_single-assignment_form">static single assignment</a> solves, but constructing ssa is expensive and most of the analyses over it require approximating fixpoints to deal with loops. I want to see how far I can get using purely linear passes.</p>
<p>(Also maybe using <a href="https://www.scattered-thoughts.net/writing/ruminating-about-mutable-value-semantics">mutable value semantics</a> will somewhat reduce the impact of not using ssa, since it encourages making most values deeply immutable?)</p>
<hr/>
<p>The other key part of <code>genExpr</code> is the <code>Destination</code> argument.</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub const </span><span>Destination </span><span>= </span><span>union</span><span>(</span><span>enum</span><span>) {
</span><span>    nowhere</span><span>,
</span><span>    anywhere</span><span>,
</span><span>    stack</span><span>,
</span><span>    value_at</span><span>: </span><span>*</span><span>Walue</span><span>,
</span><span>}</span><span>;
</span></code></pre>
<p>Rather than generating a walue from a child expr and then copying the walue somewhere else, we just tell the child what destination we&#39;re want it&#39;s result to end up at and then rely on the child to do the copying. This massively reduces the creation of intermediate values.</p>
<p>Most child exprs don&#39;t actually do the copying themselves though - they just return a lazy walue and rely on this catch-all handler at the end of <code>genExpr</code>:</p>
<pre data-lang="zig"><code data-lang="zig"><span>switch </span><span>(dest) {
</span><span>    .nowhere </span><span>=&gt; </span><span>{
</span><span>        </span><span>return </span><span>dropStack</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result)</span><span>;
</span><span>    }</span><span>,
</span><span>    .anywhere </span><span>=&gt; </span><span>{
</span><span>        </span><span>return</span><span> result</span><span>;
</span><span>    }</span><span>,
</span><span>    .stack </span><span>=&gt; </span><span>{
</span><span>        </span><span>const</span><span> repr </span><span>= </span><span>walueRepr</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result)</span><span>;
</span><span>        </span><span>switch </span><span>(</span><span>wasmRepr</span><span>(repr)) {
</span><span>            .primitive </span><span>=&gt; |</span><span>valtype</span><span>| </span><span>{
</span><span>                </span><span>load</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result)</span><span>;
</span><span>                </span><span>return</span><span> .{ .stack </span><span>=</span><span> valtype }</span><span>;
</span><span>            }</span><span>,
</span><span>            .heap </span><span>=&gt; </span><span>{
</span><span>                </span><span>loadPtrTo</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result)</span><span>;
</span><span>                </span><span>return</span><span> .{ .value_at </span><span>=</span><span> .{
</span><span>                    .ptr </span><span>=</span><span> c.</span><span>box</span><span>(</span><span>wir.Walue</span><span>{ .stack </span><span>=</span><span> .i32 </span><span>})</span><span>,
</span><span>                    .repr </span><span>=</span><span> repr</span><span>,
</span><span>                } }</span><span>;
</span><span>            }</span><span>,
</span><span>        }
</span><span>    }</span><span>,
</span><span>    .value_at </span><span>=&gt; |</span><span>ptr</span><span>| </span><span>{
</span><span>        </span><span>store</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result</span><span>,</span><span> ptr</span><span>.*</span><span>)</span><span>;
</span><span>        </span><span>return</span><span> .{ .value_at </span><span>=</span><span> .{ .ptr </span><span>=</span><span> ptr</span><span>,</span><span> .repr </span><span>= </span><span>walueRepr</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> result) } }</span><span>;
</span><span>    }</span><span>,
</span><span>}
</span></code></pre>
<p>But some children can use the destination to avoid intermediate values. For example, when dereferencing a mutable reference we need to copy the contents somewhere to avoid introducing aliasing. But often we can copy to the destination directly instead of allocating stack space.</p>
<pre data-lang="zig"><code data-lang="zig"><span>.ref_deref_begin </span><span>=&gt; </span><span>{
</span><span>    </span><span>const</span><span> ref </span><span>= </span><span>try </span><span>genExpr</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> tir_f</span><span>, </span><span>if </span><span>(dest </span><span>==</span><span> .nowhere</span><span>)</span><span> .nowhere </span><span>else</span><span> .anywhere</span><span>)</span><span>;
</span><span>    </span><span>const</span><span> repr </span><span>= </span><span>take</span><span>(c</span><span>,</span><span> tir_f).ref_deref_end</span><span>;
</span><span>    </span><span>const</span><span> value </span><span>= </span><span>wir.Walue</span><span>{ .value_at </span><span>=</span><span> .{ .ptr </span><span>=</span><span> c.</span><span>box</span><span>(ref)</span><span>,</span><span> .repr </span><span>=</span><span> repr } }</span><span>;
</span><span>    </span><span>switch </span><span>(dest) {
</span><span>        .nowhere</span><span>,</span><span> .stack</span><span>,</span><span> .value_at </span><span>=&gt; </span><span>{
</span><span>            </span><span>// Let the catch-all copy this into the destination.
</span><span>            </span><span>return</span><span> value</span><span>;
</span><span>        }</span><span>,
</span><span>        .anywhere </span><span>=&gt; </span><span>{
</span><span>            </span><span>// Must make a copy into a fresh stack slot to avoid passing around an aliased walue.
</span><span>            </span><span>return </span><span>copy</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> value.value_at)</span><span>;
</span><span>        }</span><span>,
</span><span>    }
</span><span>}</span><span>,
</span></code></pre>
<p>Places where destinations are created:</p>
<ul>
<li>Assignments to mutable variables pass the variables address.</li>
<li>Returning from a function passes the result pointer.</li>
<li>Every expression in a block except the last passes <code>.nowhere</code>.</li>
</ul>
<p>Places where destinations are used to avoid copies:</p>
<ul>
<li>Function calls pass the destination as the result pointer.</li>
<li>Dereferencing mutable references copies into the destination.</li>
</ul>
<p>Several exprs also check if the dest is <code>.nowhere</code> and, if so, avoid generating wasm.</p>
<hr/>
<p>The combination of walues and destinations also works well for chains of field accesses like <code>thing.x.y.z</code>. Generating <code>thing</code> returns a walue representing it&#39;s address, then generating <code>thing.x</code> just adds an offset to that address, and so on. No actual code gets generated until the walue meets a destination, at which point we can produce a single load or copy.</p>
<pre data-lang="zest"><code data-lang="zest"><span>a mut = 0
</span><span>b = [w: 1, x: [y: 2, z: 3]]
</span><span>a@ = b.x.z
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; a mut = 0
</span><span>(i32.store align=1
</span><span>  (local.get 0)
</span><span>  (i32.const 0))
</span><span>
</span><span>;; b = [w: 1, x: [y: 2, z: 3]]
</span><span>(i32.store offset=4 align=1
</span><span>  (local.get 0)
</span><span>  (i32.const 1))
</span><span>(i32.store offset=8 align=1
</span><span>  (local.get 0)
</span><span>  (i32.const 2))
</span><span>(i32.store offset=12 align=1
</span><span>  (local.get 0)
</span><span>  (i32.const 3))
</span><span>
</span><span>;; a@ = b.x.z
</span><span>(i32.store align=1
</span><span>  (local.get 0)
</span><span>  ;; a single load for b.x.z
</span><span>  (i32.load offset=12 align=1
</span><span>    (local.get 0)))
</span></code></pre>
<hr/>
<p>Zig has a similar approach to codegen. Their equivalent to walues is <a href="https://github.com/ziglang/zig/blob/cf90dfd3098bef5b3c22d5ab026173b3c357f2dd//src/arch/wasm/CodeGen.zig#L32">here</a>. Their equivalent to destinations is <a href="https://ziglang.org/documentation/master/#Result-Location-Semantics">result location semantics</a>, which are actually part of the language semantics and so are handled much earlier in the compiler. By the time zig reaches <a href="https://github.com/ziglang/zig/blob/cf90dfd3098bef5b3c22d5ab026173b3c357f2dd//src/Air.zig#L1">air</a> I don&#39;t think there are any struct literals remaining - they get decomposed into writes to the result location. Something like:</p>
<pre data-lang="zig"><code data-lang="zig"><span>// source
</span><span>x </span><span>=</span><span> .{.a </span><span>= </span><span>1</span><span>,</span><span> .b </span><span>= </span><span>2</span><span>}
</span><span>
</span><span>// air
</span><span>x </span><span>= </span><span>undefined
</span><span>x.a </span><span>= </span><span>1
</span><span>x.b </span><span>= </span><span>2
</span></code></pre>
<p>This can cause some problems though:</p>
<pre data-lang="zig"><code data-lang="zig"><span>var</span><span> p </span><span>= </span><span>Pair</span><span>{ .a </span><span>=</span><span> .{ </span><span>1</span><span>, </span><span>2 </span><span>}</span><span>,</span><span> .b </span><span>=</span><span> .{ </span><span>3</span><span>, </span><span>4 </span><span>} }</span><span>;
</span><span>p </span><span>=</span><span> .{ .a </span><span>=</span><span> p.b</span><span>,</span><span> .b </span><span>=</span><span> p.a }</span><span>;
</span><span>std.debug.</span><span>print</span><span>(</span><span>&#34;{}</span><span>\n</span><span>&#34;</span><span>,</span><span> .{p})</span><span>;
</span><span>// prints:
</span><span>// test.Pair{ .a = { 3, 4 }, .b = { 3, 4 } }
</span></code></pre>
<p>The rewrite effectively did this:</p>
<pre data-lang="zig"><code data-lang="zig"><span>// source 
</span><span>p </span><span>=</span><span> .{ .a </span><span>=</span><span> p.b</span><span>,</span><span> .b </span><span>=</span><span> p.a }</span><span>;
</span><span>
</span><span>// air
</span><span>p.a </span><span>=</span><span> p.b
</span><span>p.b </span><span>=</span><span> p.a
</span></code></pre>
<p>This is actually part of the language semantics, so they can just say don&#39;t do that. But as Martin Wickham explains in <a href="https://www.youtube.com/watch?v=dEIsJPpCZYg">attack of the killer features</a> when this is combined with other optimizations like converting pass-by-value to pass-by-reference or passing result locations into functions as result pointers, this kind of aliasing can appear in surprising places. An example like:</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub fn </span><span>flip</span><span>(</span><span>p</span><span>: </span><span>Pair</span><span>) </span><span>Pair </span><span>{
</span><span>    </span><span>return</span><span> .{ .a </span><span>=</span><span> p.b</span><span>,</span><span> .b </span><span>=</span><span> p.a }</span><span>;
</span><span>}
</span><span>
</span><span>pub fn </span><span>main</span><span>() </span><span>!</span><span>void </span><span>{
</span><span>    </span><span>var</span><span> p </span><span>= </span><span>Pair</span><span>{ .a </span><span>=</span><span> .{ </span><span>1</span><span>, </span><span>2 </span><span>}</span><span>,</span><span> .b </span><span>=</span><span> .{ </span><span>3</span><span>, </span><span>4 </span><span>} }</span><span>;
</span><span>    p </span><span>= </span><span>flip</span><span>(p)</span><span>;
</span><span>    std.debug.</span><span>print</span><span>(</span><span>&#34;{}</span><span>\n</span><span>&#34;</span><span>,</span><span> .{p})</span><span>;
</span><span>}
</span></code></pre>
<p>Used to get rewritten to something like:</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub fn </span><span>flip</span><span>(</span><span>p</span><span>: </span><span>*</span><span>const Pair</span><span>, </span><span>result</span><span>: </span><span>*</span><span>Pair</span><span>) </span><span>void </span><span>{
</span><span>    result</span><span>.* =</span><span> .{ .a </span><span>=</span><span> p.b</span><span>,</span><span> .b </span><span>=</span><span> p.a }</span><span>;
</span><span>}
</span><span>
</span><span>pub fn </span><span>main</span><span>() </span><span>!</span><span>void </span><span>{
</span><span>    </span><span>var </span><span>p</span><span>: </span><span>Pair </span><span>= </span><span>undefined</span><span>;
</span><span>    p[</span><span>0</span><span>][</span><span>0</span><span>] </span><span>= </span><span>1</span><span>;</span><span> p[</span><span>0</span><span>][</span><span>1</span><span>] </span><span>= </span><span>2</span><span>;</span><span> p[</span><span>1</span><span>][</span><span>0</span><span>] </span><span>= </span><span>3</span><span>;</span><span> p[</span><span>1</span><span>][</span><span>1</span><span>] </span><span>= </span><span>4</span><span>;
</span><span>    </span><span>flip</span><span>(</span><span>&amp;</span><span>p</span><span>, </span><span>&amp;</span><span>p)</span><span>; </span><span>// surprise aliasing!
</span><span>    std.debug.</span><span>print</span><span>(</span><span>&#34;{}</span><span>\n</span><span>&#34;</span><span>,</span><span> .{p})</span><span>;
</span><span>}
</span></code></pre>
<p>But if I play around with the different backends now I get two different versions of the body of main:</p>
<pre data-lang="zig"><code data-lang="zig"><span>// llvm-debug doesn&#39;t propagate result location to flip&#39;s result pointer
</span><span>var</span><span> p </span><span>= </span><span>Pair</span><span>{ .a </span><span>=</span><span> .{ </span><span>1</span><span>, </span><span>2 </span><span>}</span><span>,</span><span> .b </span><span>=</span><span> .{ </span><span>3</span><span>, </span><span>4 </span><span>} }</span><span>;
</span><span>var </span><span>tmp</span><span>: </span><span>Pair </span><span>= </span><span>undefined</span><span>;
</span><span>flip</span><span>(</span><span>&amp;</span><span>p</span><span>, </span><span>&amp;</span><span>tmp)</span><span>;
</span><span>p </span><span>=</span><span> tmp</span><span>;
</span><span>
</span><span>// zig-debug doesn&#39;t pass p by reference
</span><span>var</span><span> p </span><span>= </span><span>Pair</span><span>{ .a </span><span>=</span><span> .{ </span><span>1</span><span>, </span><span>2 </span><span>}</span><span>,</span><span> .b </span><span>=</span><span> .{ </span><span>3</span><span>, </span><span>4 </span><span>} }</span><span>;
</span><span>const</span><span> tmp </span><span>=</span><span> p</span><span>;
</span><span>flip</span><span>(</span><span>&amp;</span><span>tmp</span><span>, </span><span>&amp;</span><span>p)</span><span>;
</span></code></pre>
<p>So the surprises seem to be limited to places in the source code where the aliasing is directly visible like <code>p = .{ .a = p.b, .b = p.a }</code>. </p>
<p>For zest I don&#39;t want these surprises even when they&#39;re directly visible. So I have a different solution - I don&#39;t propagate destinations through struct literals. So in zest the above example goes something like this:</p>
<pre data-lang="zest"><code data-lang="zest"><span>// original
</span><span>flip = (p) [p.1, p.0]
</span><span>p mut = [[1,2],[3,4]]
</span><span>p@ = flip(p)
</span><span>
</span><span>// rewritten to:
</span><span>flip = (p, result mut) {
</span><span>  tmp0 = p.1
</span><span>  tmp1 = p.0
</span><span>  result.0@ = tmp0
</span><span>  result.1@ = tmp1
</span><span>}
</span><span>p mut = undefined
</span><span>{ p.0.0@ = 1; p.0.1@ = 2; p.1.0@ = 3; p.1.1@ = 4 }
</span><span>flip(p@, p@)
</span></code></pre>
<p>In this case it results in the same amount of copying as the zig example. But if we pick an example with no functions:</p>
<pre data-lang="zest"><code data-lang="zest"><span>// original
</span><span>q@ = [p.1, p.0]
</span><span>
</span><span>// rewritten to:
</span><span>tmp0 = p.1 // pointless copy!
</span><span>tmp1 = p.0 // pointless copy!
</span><span>q.0@ = tmp0
</span><span>q.1@ = tmp1
</span><span>
</span></code></pre>
<p>Now we have two pointless copies for something that would have been totally safe in zig.</p>
<p>In the long run I want to take advantage of the fact that mutable value semantics gives me very cheap alias analysis to detect when a copy is actually needed. That would produce something like:</p>
<pre data-lang="zest"><code data-lang="zest"><span>// original
</span><span>q@ = [p.1, p.0]
</span><span>p@ = [p.1, p.0]
</span><span>
</span><span>// rewritten to:
</span><span>q.0@ = p.1
</span><span>q.1@ = p.0
</span><span>tmp = p.0 // copy before over-writing!
</span><span>p.0@ = p.1
</span><span>p.1@ = tmp
</span></code></pre>
<p>I actually got this working in the generate pass because it&#39;s easy to check if two walues could alias. But I realized that implementation wouldn&#39;t generalize once I added heap allocation and had to take reachability into account (eg the walues for <code>some-list</code> and <code>some-list.{i}</code> are distinct memory locations, but calling <code>f(@some-list)</code> can still mutate <code>some-list.{i}</code>). So I ripped that out and plan to reintroduce it in an earlier layer where I still have complete aliasing information.</p>
<p>In the meantime, the copying is not as pervasive as it might initially seem. Because walues can be struct literals, we only end up producing extra copies when a struct literal contains a dereference of a mutable variable or a call to a function that returns a struct.</p>
<pre data-lang="zest"><code data-lang="zest"><span>p = [[1,2],[3,4]] // literals don&#39;t require copies
</span><span>p2 = [p.1, p.0] // reads from non-mutable variables don&#39;t require copies
</span><span>p3 = [p.0, [p.1.0, foo(p.1.1)]] // functions that return primitives don&#39;t require copies
</span></code></pre>
<hr/>
<p>Wasm loads and store require specifying an alignment. But the spec also says that this is just a hint - the backend is not allowed to trap if the address is not correctly aligned. I don&#39;t understand how this is useful to the backend. Would it test the alignment and switch between a fast path and a slow path? That doesn&#39;t seem worthwhile for what would usually be a single instruction?</p>
<p>For now I&#39;ve just specified 1-byte alignment on everything, and I&#39;m working on x86_64 where unaligned accesses are allowed and are barely slower than aligned accesses. But what happens if I run this on arm where unaligned accesses are still expensive? If I specify larger alignments will the backend actually be able to make use of that hint? If you know, please <a href="mailto:jamie@scattered-thoughts.net">email me</a>!</p>
<hr/>
<p>In my first compiler I used <a href="https://github.com/WebAssembly/binaryen">binaryen</a> to &#39;save time&#39; but in the end I spent a ton of time working around gaps in the binaryen api. </p>
<p>This time I just generated wasm myself by hand. It&#39;s easy! I only have ~200loc dedicated to producing wasm.</p>
<p>Debugging encoding mistakes is tedious, but luckily I don&#39;t mess up the encoding too often. Better tooling would help - gor example wasm2wat won&#39;t print <strong>any</strong> output if there is an encoding mistake <strong>anywhere</strong> in the file, even if I pass <code>--no-check</code>. I want a tool that prints output until it hits an encoding error and then prints out the next 20 or so bytes so I can see what nonsense I put in there.</p>
<hr/>
<p>I have a small pile of hand-written tests which are good for specifying behaviour, but for flushing out codegen bugs I get much more value from fuzzing. The interpreter that I use for compile-time evaluation can also run entire programs, so my fuzz test runs both the interpreter and compiler on the same program and asserts that if the program type-checks then
the compiled program should produce the same result as the interpreter.</p>
<p>My compiler is written in zig which currently doesn&#39;t have any support for coverage instrumentation. I offered some cpu-days to black-box fuzzers but didn&#39;t find even the obvious bugs that I added to make sure fuzzing was working. So what I&#39;m doing now instead is compiling zig to c, then compiling that with clang to get coverage instrumentation, and then doing coverage-guide fuzzing with honggfuzz.</p>
<p>This flushes out all kinds of weird bugs. My favourite so far was that I accidentally used the wrong integer encoding (unsigned instead of signed) for the size of the shadow stack frame. The encodings only differ for numbers over 128, so the fuzzer had to pack a lot of structs onto the stack to trigger that.</p>
<p>For running wasm programs I use deno, because the wasmtime cli can&#39;t yet pass or return values from entry points and zest doesn&#39;t have printing yet. For debugging I use chrome, because firefox&#39;s wasm debugger doesn&#39;t show the value stack.</p>
<hr/>
<p>I don&#39;t have any real zest programs to actually measure yet, but I can get a rough feel for the point on the compile-time/runtime tradeoff curve that I&#39;m steering towards by comparing to zig. </p>
<p>I made <a href="https://github.com/jamii/baby-2nd-bench">this half-assed benchmark</a> using the tokenizer from the zig standard library to count the number of tokens in a 10mloc zig file.</p>
<table><thead><tr><th></th><th>compile time (ms)</th><th>runtime (ms)</th></tr></thead><tbody>
<tr><td>llvm-release-x86_64</td><td>458</td><td>1850</td></tr>
<tr><td>llvm-debug-x86_64</td><td>149</td><td>4306</td></tr>
<tr><td>zig-debug-x86_64</td><td>65</td><td>19633</td></tr>
<tr><td>llvm-release-x86</td><td>645</td><td>1837</td></tr>
<tr><td>llvm-debug-x86</td><td>313</td><td>5129</td></tr>
<tr><td>zig-debug-x86</td><td>-</td><td>-</td></tr>
<tr><td>llvm-release-wasm32 + wasmtime</td><td>300 + 15</td><td>2456</td></tr>
<tr><td>llvm-debug-wasm32 + wasmtime</td><td>230 + 22</td><td><strong>4063</strong></td></tr>
<tr><td>zig-debug-wasm32 + wasmtime</td><td><strong>37 + 19</strong></td><td>12202</td></tr>
</tbody></table>
<p>The numbers in bold are what I&#39;m aiming towards. Somewhere in the vicinity of ~10x better compile times than llvm-release at the cost of ~2x worse runtime.</p>
<hr/>
<p>Why does zig-debug have such poor runtime compared to llvm-debug? Neither of them do any optimization before codegen, and wasmtime can see through many codegen mistakes. I haven&#39;t run any actual experiments, but picking through the output I see a couple of likely suspects.</p>
<p>The first suspect is slow copies. Here is a function that takes an array and just returns it:</p>
<pre data-lang="zig"><code data-lang="zig"><span>const</span><span> n </span><span>= </span><span>2</span><span>;
</span><span>pub fn </span><span>pass</span><span>(</span><span>p</span><span>:</span><span> [</span><span>n</span><span>]</span><span>i32</span><span>) [n]</span><span>i32 </span><span>{
</span><span>    </span><span>return</span><span> p</span><span>;
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; llvm-debug
</span><span>(func $test.pass (type 1) (param i32 i32)
</span><span>  (local i64)
</span><span>  (local.set 2
</span><span>    (i64.load align=4
</span><span>      (local.get 1)))
</span><span>  (i64.store align=4
</span><span>    (local.get 0)
</span><span>    (local.get 2))
</span><span>  (return))
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; zig-debug
</span><span>(func $test.pass (type 0) (param i32 i32)
</span><span>  (memory.copy
</span><span>    (local.get 0)
</span><span>    (local.get 1)
</span><span>    (i32.const 8))
</span><span>  (return))
</span></code></pre>
<p>Llvm-debug generates an aligned 4-byte load and store, whereas zig-debug generates <code>memory.copy</code> which assumes 1-byte alignment and has to check for overlap. If not targeting the bulk-memory extension then instead zig-debug down to 1-byte loads and stores instead.</p>
<pre data-lang="wat"><code data-lang="wat"><span>;; zig-debug (no bulk-memory)
</span><span>(func $test.pass (type 0) (param i32 i32)
</span><span>  (i32.store8
</span><span>    (local.get 0)
</span><span>    (i32.load8_u
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=1
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=1
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=2
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=2
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=3
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=3
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=4
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=4
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=5
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=5
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=6
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=6
</span><span>      (local.get 1)))
</span><span>  (i32.store8 offset=7
</span><span>    (local.get 0)
</span><span>    (i32.load8_u offset=7
</span><span>      (local.get 1)))
</span><span>  (return))
</span></code></pre>
<p>I reran the benchmark above with bulk-memory disabled:</p>
<pre><code><span>| | compile time (ms) | runtime (ms) |
</span><span>|---|---|---|
</span><span>| zig-debug-wasm32 (mvp+bulk-memory) + wasmtime | 36 + 19 | 12202 |
</span><span>| zig-debug-wasm32 (mvp) + wasmtime | 37 + 21 | 6120 |
</span></code></pre>
<p>Getting 2x better performance by disabling bulk-memory certainly suggests that zig-debug is using <code>memory.copy</code> too eagerly.</p>
<p>I think the code responsible is <a href="https://github.com/ziglang/zig/blob/cf90dfd3098bef5b3c22d5ab026173b3c357f2dd//src/arch/wasm/CodeGen.zig#L1576-L1621">here</a> - it seems like a quick fix. Some experiments show that llvm doesn&#39;t switch to <code>memory.copy</code> until n &gt; 16. So for zest I do:</p>
<pre data-lang="zig"><code data-lang="zig"><span>if </span><span>(from_ptr.</span><span>equal</span><span>(to_ptr))
</span><span>    </span><span>return</span><span>;
</span><span>
</span><span>const</span><span> byte_count </span><span>=</span><span> value_at.repr.</span><span>sizeOf</span><span>()</span><span>;
</span><span>if </span><span>(byte_count </span><span>&gt; </span><span>64</span><span>) {
</span><span>    </span><span>load</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> to_ptr)</span><span>;
</span><span>    </span><span>load</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> from_ptr)</span><span>;
</span><span>    </span><span>emitEnum</span><span>(f</span><span>,</span><span> wasm.Opcode.i32_const)</span><span>;
</span><span>    </span><span>emitLebI32</span><span>(f</span><span>, </span><span>@intCast</span><span>(byte_count))</span><span>;
</span><span>    </span><span>emitEnum</span><span>(f</span><span>,</span><span> wasm.Opcode.misc_prefix)</span><span>;
</span><span>    </span><span>emitLebU32</span><span>(f</span><span>,</span><span> wasm.</span><span>miscOpcode</span><span>(wasm.MiscOpcode.memory_copy))</span><span>;
</span><span>    </span><span>emitLebU32</span><span>(f</span><span>, </span><span>0</span><span>)</span><span>; </span><span>// memory from
</span><span>    </span><span>emitLebU32</span><span>(f</span><span>, </span><span>0</span><span>)</span><span>; </span><span>// memory to
</span><span>} </span><span>else </span><span>{
</span><span>    </span><span>var </span><span>offset</span><span>: </span><span>u32 </span><span>= </span><span>0</span><span>;
</span><span>    </span><span>const</span><span> to_add </span><span>= </span><span>asAdd</span><span>(c</span><span>,</span><span> to_ptr)</span><span>;
</span><span>    </span><span>const</span><span> from_add </span><span>= </span><span>asAdd</span><span>(c</span><span>,</span><span> from_ptr)</span><span>;
</span><span>    </span><span>while </span><span>(offset </span><span>&lt;</span><span> byte_count) {
</span><span>        </span><span>const</span><span> remaining </span><span>=</span><span> byte_count </span><span>-</span><span> offset</span><span>;
</span><span>        </span><span>inline for </span><span>(.{
</span><span>            .{ </span><span>8</span><span>,</span><span> wasm.Opcode.i64_load</span><span>,</span><span> wasm.Opcode.i64_store }</span><span>,
</span><span>            .{ </span><span>4</span><span>,</span><span> wasm.Opcode.i32_load</span><span>,</span><span> wasm.Opcode.i32_store }</span><span>,
</span><span>            .{ </span><span>2</span><span>,</span><span> wasm.Opcode.i32_load16_u</span><span>,</span><span> wasm.Opcode.i32_store16 }</span><span>,
</span><span>            .{ </span><span>1</span><span>,</span><span> wasm.Opcode.i32_load8_u</span><span>,</span><span> wasm.Opcode.i32_store8 }</span><span>,
</span><span>        }) </span><span>|</span><span>params</span><span>| </span><span>{
</span><span>            </span><span>const</span><span> chunk</span><span>, </span><span>const</span><span> load_op</span><span>, </span><span>const</span><span> store_op </span><span>=</span><span> params</span><span>;
</span><span>            </span><span>if </span><span>(remaining </span><span>&gt;=</span><span> chunk) {
</span><span>                </span><span>load</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> to_add.walue</span><span>.*</span><span>)</span><span>;
</span><span>                </span><span>load</span><span>(c</span><span>,</span><span> f</span><span>,</span><span> from_add.walue</span><span>.*</span><span>)</span><span>;
</span><span>                </span><span>emitEnum</span><span>(f</span><span>,</span><span> load_op)</span><span>;
</span><span>                </span><span>emitLebU32</span><span>(f</span><span>, </span><span>0</span><span>)</span><span>; </span><span>// align
</span><span>                </span><span>emitLebU32</span><span>(f</span><span>,</span><span> from_add.offset </span><span>+</span><span> offset)</span><span>;
</span><span>                </span><span>emitEnum</span><span>(f</span><span>,</span><span> store_op)</span><span>;
</span><span>                </span><span>emitLebU32</span><span>(f</span><span>, </span><span>0</span><span>)</span><span>; </span><span>// align
</span><span>                </span><span>emitLebU32</span><span>(f</span><span>,</span><span> to_add.offset </span><span>+</span><span> offset)</span><span>;
</span><span>                offset </span><span>+=</span><span> chunk</span><span>;
</span><span>                </span><span>break</span><span>;
</span><span>            }
</span><span>        } </span><span>else unreachable</span><span>;
</span><span>    }
</span><span>}
</span></code></pre>
<p>This is what it looks like in practice:</p>
<pre data-lang="zest"><code data-lang="zest"><span>// zest
</span><span>pass = (c) c
</span><span>pass([1])
</span><span>pass([1,2])
</span><span>pass([1,2,3])
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>;; pass(struct[i32])
</span><span>(func (;1;) (type 1) (param i32 i32)
</span><span>  (i32.store align=1
</span><span>    (local.get 1)
</span><span>    (i32.load align=1
</span><span>      (local.get 0))))
</span><span>;; pass(struct[i32, i32])
</span><span>(func (;2;) (type 1) (param i32 i32)
</span><span>  (i64.store align=1
</span><span>    (local.get 1)
</span><span>    (i64.load align=1
</span><span>      (local.get 0))))
</span><span>;; pass(struct[i32, i32, i32])
</span><span>(func (;3;) (type 1) (param i32 i32)
</span><span>  (i64.store align=1
</span><span>    (local.get 1)
</span><span>    (i64.load align=1
</span><span>      (local.get 0)))
</span><span>  (i32.store offset=8 align=1
</span><span>    (local.get 1)
</span><span>    (i32.load offset=8 align=1
</span><span>      (local.get 0))))
</span></code></pre>
<p>The second suspect is extra copies:</p>
<pre data-lang="zig"><code data-lang="zig"><span>// zig
</span><span>
</span><span>pub fn </span><span>initA</span><span>(</span><span>c</span><span>: </span><span>i32</span><span>) [</span><span>1</span><span>]</span><span>i32 </span><span>{
</span><span>    </span><span>return</span><span> .{c}</span><span>;
</span><span>}
</span><span>
</span><span>pub fn </span><span>initB</span><span>(</span><span>c</span><span>: </span><span>i32</span><span>) [</span><span>1</span><span>]</span><span>i32 </span><span>{
</span><span>    </span><span>const </span><span>tmp</span><span>:</span><span> [</span><span>1</span><span>]</span><span>i32 </span><span>=</span><span> .{c}</span><span>;
</span><span>    </span><span>return</span><span> tmp</span><span>;
</span><span>}
</span><span>
</span><span>pub fn </span><span>initC</span><span>(</span><span>c</span><span>: </span><span>i32</span><span>) [</span><span>1</span><span>]</span><span>i32 </span><span>{
</span><span>    </span><span>const</span><span> tmp </span><span>=</span><span> [</span><span>1</span><span>]</span><span>i32</span><span>{c}</span><span>;
</span><span>    </span><span>return</span><span> tmp</span><span>;
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>
</span><span>(func $test.initA (type 0) (param i32 i32)
</span><span>  (local i32)
</span><span>
</span><span>  ;; calculate offset of &amp;result[0] from &amp;result
</span><span>  (local.set 2
</span><span>    (i32.add
</span><span>      (local.get 0)
</span><span>      (i32.mul
</span><span>        (i32.const 0)
</span><span>        (i32.const 4))))
</span><span> 
</span><span>  ;; result[0] = 1
</span><span>  (i32.store
</span><span>    (local.get 2)
</span><span>    (local.get 1))
</span><span>
</span><span>  (return))
</span><span>
</span><span>(func $test.initB (type 0) (param i32 i32)
</span><span>  (local i32 i32 i32)
</span><span>
</span><span>  ;; push stack frame
</span><span>  (global.set $__stack_pointer
</span><span>    (local.tee 3
</span><span>      (i32.and
</span><span>        (i32.sub
</span><span>          (local.tee 2
</span><span>            (global.get $__stack_pointer))
</span><span>          (i32.const 16))
</span><span>        (i32.const -16))))
</span><span>
</span><span>  ;; calculate offset of &amp;tmp[0] from &amp;tmp
</span><span>  (local.set 4
</span><span>    (i32.add
</span><span>      (local.get 3)
</span><span>      (i32.mul
</span><span>        (i32.const 0)
</span><span>        (i32.const 4))))
</span><span>
</span><span>  ;; set tmp[0] = 1
</span><span>  (i32.store
</span><span>    (local.get 4)
</span><span>    (local.get 1))
</span><span>
</span><span>  ;; tmp2 = tmp
</span><span>  (memory.copy
</span><span>    (i32.add
</span><span>      (local.get 3)
</span><span>      (i32.const 4))
</span><span>    (local.get 3)
</span><span>    (i32.const 4))
</span><span>
</span><span>  ;; result = tmp
</span><span>  (memory.copy
</span><span>    (local.get 0)
</span><span>    (i32.add
</span><span>      (local.get 3)
</span><span>      (i32.const 4))
</span><span>    (i32.const 4))
</span><span>
</span><span>  ;; pop stack frame
</span><span>  (global.set $__stack_pointer
</span><span>    (local.get 2))
</span><span>  (return))
</span><span>
</span><span>
</span><span>(func $test.initC (type 0) (param i32 i32)
</span><span>  (local i32 i32)
</span><span>
</span><span>  ;; push stack frame
</span><span>  (global.set $__stack_pointer
</span><span>    (local.tee 3
</span><span>      (i32.and
</span><span>        (i32.sub
</span><span>          (local.tee 2
</span><span>            (global.get $__stack_pointer))
</span><span>          (i32.const 16))
</span><span>        (i32.const -16))))
</span><span>
</span><span>  ;; tmp[0] = 1
</span><span>  ;; (for some reason the offset is computed statically here)
</span><span>  (i32.store
</span><span>    (local.get 3)
</span><span>    (local.get 1))
</span><span>
</span><span>  ;; result = tmp
</span><span>  (memory.copy
</span><span>    (local.get 0)
</span><span>    (local.get 3)
</span><span>    (i32.const 4))
</span><span>
</span><span>  ;; pop stack frame
</span><span>  (global.set $__stack_pointer
</span><span>    (local.get 2))
</span><span>  (return))
</span></code></pre>
<p>Where is this extra copy in initB coming from? I&#39;m not 100% sure, but it seems to happen whenever casting a literal into a const <a href="https://ziglang.org/documentation/master/#Result-Location-Semantics">result location</a>. This is pretty common in idiomatic zig. I don&#39;t have casts yet, but I&#39;ll keep an eye out for that when I add them.</p>
<pre data-lang="zest"><code data-lang="zest"><span>init-b = (c) {
</span><span>  tmp = [c]
</span><span>  tmp
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>(func (;1;) (type 1) (param i32 i32)
</span><span>  (local i32)
</span><span>
</span><span>  ;; push stack frame
</span><span>  ;; (don&#39;t need to set global stack pointer, since this function doesn&#39;t call any others)
</span><span>  (local.set 2
</span><span>    (i32.sub
</span><span>      (global.get 0)
</span><span>      (i32.const 4)))
</span><span>
</span><span>  ;; tmp[0] = c
</span><span>  (i32.store align=1
</span><span>    (local.get 2)
</span><span>    (i32.load align=1
</span><span>      (local.get 0)))
</span><span>
</span><span>  ;; result[0] = c
</span><span>  (i32.store align=1
</span><span>    (local.get 1)
</span><span>    (i32.load align=1
</span><span>      (local.get 2))))
</span></code></pre>
<hr/>
<p>I also noticed that llvm-debug builds often produce weird pointless stores:</p>
<pre data-lang="zig"><code data-lang="zig"><span>// zig
</span><span>pub fn </span><span>set</span><span>(</span><span>p</span><span>: </span><span>*</span><span>[</span><span>1</span><span>]</span><span>i32</span><span>, </span><span>c</span><span>:</span><span> [</span><span>1</span><span>]</span><span>i32</span><span>) </span><span>void </span><span>{
</span><span>    p</span><span>.* =</span><span> c</span><span>;
</span><span>}
</span></code></pre>
<pre data-lang="wat"><code data-lang="wat"><span>;; wasm
</span><span>(func $test.set (type 1) (param i32 i32)
</span><span>  (local i32 i32 i32 i32 i32 i32)
</span><span>  (local.set 2
</span><span>    (global.get 0))
</span><span>  (local.set 3
</span><span>    (i32.const 16))
</span><span>  (local.set 4
</span><span>    (i32.sub
</span><span>      (local.get 2)
</span><span>      (local.get 3)))
</span><span>  (global.set 0
</span><span>    (local.get 4))
</span><span>  ;; this store is never used!
</span><span>  (i32.store offset=12
</span><span>    (local.get 4)
</span><span>    (local.get 0))
</span><span>  (local.set 5
</span><span>    (i32.load
</span><span>      (local.get 1)))
</span><span>  (i32.store
</span><span>    (local.get 0)
</span><span>    (local.get 5))
</span><span>  (local.set 6
</span><span>    (i32.const 16))
</span><span>  (local.set 7
</span><span>    (i32.add
</span><span>      (local.get 4)
</span><span>      (local.get 6)))
</span><span>  (global.set 0
</span><span>    (local.get 7))
</span><span>  (return))
</span></code></pre>
<p>If I build with <code>-fstrip</code> these pointless stores disappear, along with many of the extra locals:</p>
<pre data-lang="wat"><code data-lang="wat"><span>(func $test.set (type 1) (param i32 i32)
</span><span>  (local i32)
</span><span>  (local.set 2
</span><span>    (i32.load
</span><span>      (local.get 1)))
</span><span>  (i32.store
</span><span>    (local.get 0)
</span><span>    (local.get 2))
</span><span>  (return))
</span></code></pre>
<p>And in the llvm ir the pointless stack slot is referenced by the debug metadata:</p>
<pre><code><span>; Function Attrs: noredzone nounwind
</span><span>define internal fastcc void @test.set(ptr nonnull align 4 %0, ptr nonnull readonly align 4 %1) unnamed_addr #0 !dbg !157 {
</span><span>Entry:
</span><span>  %2 = alloca ptr, align 4
</span><span>  store ptr %0, ptr %2, align 4, !dbg !165
</span><span>  call void @llvm.dbg.declare(metadata ptr %2, metadata !166, metadata !DIExpression()), !dbg !165
</span><span>  call void @llvm.dbg.declare(metadata ptr %1, metadata !167, metadata !DIExpression()), !dbg !165
</span><span>  call void @llvm.memcpy.p0.p0.i32(ptr align 4 %0, ptr align 4 %1, i32 4, i1 false), !dbg !168
</span><span>  ret void, !dbg !168
</span><span>}
</span></code></pre>
<p>So I assume the difference is something to do with making values visible to dwarf calculations. I don&#39;t know how dwarf works with wasm.</p>
<p>All the numbers in the benchmark above are with <code>-fstrip</code>. Turning it off trashes compile times (except for zig-debug-wasm32 which doesn&#39;t produce dwarf yet):</p>
<table><thead><tr><th></th><th>compile time (ms)</th><th>runtime (ms)</th></tr></thead><tbody>
<tr><td>llvm-release-x86_64</td><td>5089</td><td>1831</td></tr>
<tr><td>llvm-debug-x86_64</td><td>980</td><td>4917</td></tr>
<tr><td>zig-debug-x86_64</td><td>270</td><td>19847</td></tr>
<tr><td>llvm-release-wasm32 + wasmtime</td><td>354 + 15</td><td>2500</td></tr>
<tr><td>llvm-debug-wasm32 + wasmtime</td><td>169 + 23</td><td>4300</td></tr>
<tr><td>zig-debug-wasm32 + wasmtime</td><td>38 + 19</td><td>11962</td></tr>
</tbody></table>
<hr/>
<p>Currently I always allocate structs on the shadow stack in case they are passed by reference later. This is bad for loops like:</p>
<pre data-lang="zest"><code data-lang="zest"><span>i mut = 0
</span><span>while {i &lt; string.len} {
</span><span>   // do stuff...
</span><span>}
</span></code></pre>
<p>If <code>string</code> was stored in two wasm locals (<code>string.ptr</code> and <code>string.len</code>) then it&#39;s trivial for the backend to figure out that <code>string.len</code> is constant and that it&#39;s safe to hoist the read out of the loop. But with <code>string</code> stored on the shadow stack the wasm backend has to do clever reasoning about potential aliases, which will probably fail in non-trivial loops.</p>
<p>The difficulty, as I mentioned earlier, is that how best to represent variables depends on how they are used, but constant propagation changes the use of variables. SO doing both at the same time is a problem. It might work better to push some of the work into the infer pass (which I should probably rename to something less specific like analyze). So the breakdown would be:</p>
<ul>
<li>infer
<ul>
<li>do everything that infer currently does</li>
<li>propagate constants and eliminate dead code</li>
<li>inline function wrappers</li>
<li>break struct literals into individual writes (using aliasing information to decide if intermediate copies are needed)</li>
<li>record how each variable is used in the emitted code</li>
</ul>
</li>
<li>generate
<ul>
<li>choose representation for variables
<ul>
<li>if ever passed by reference, store on the shadow stack</li>
<li>otherwise break up into individual wasm locals</li>
</ul>
</li>
<li>use a simpler walue to propagate just addresses/offsets and track the wasm stack</li>
<li>generate wasm</li>
</ul>
</li>
</ul>
<p>This will also remove some redundancy, since the walues used in generate at the moment encode the type of the value. If I push that into gthe infer pass then in the generate pass walues will only have to deal with wasm primitives and heap addresses.</p>
<hr/>
<p>When generating wasm for builtin functions I have two options:</p>
<ol>
<li>If I pass <code>Destination.anywhere</code> to the arguments then they might return constant walues and I can fold the whole function away. But if the first argument returns a constant and the second argument returns <code>Walue.stack</code> then I need to store the second argument into a fresh local, load the first argument, read the second argument from the local, and then emit the function call. Extra locals make me sad!</li>
<li>If I pass <code>Destination.stack</code> to the arguments then they are guaranteed to end up on the stack in the correct order, but they will always return <code>Walue.stack</code> so I miss the chance to propagate constants. </li>
</ol>
<p>I think the solution here is first move constant propagation into the infer pass, then take option 1 above and use the <code>indirect</code> trick in tir so that I can insert a load between the first and second arguments after looking at their walues.</p>
<hr/>
<p>Optimization improvements can wait until later though. Definitely the next thing is to write the runtime and add strings/lists/hashtables, which will get me a lot closer to a language that one might actually use to write interesting programs. (At the moment programs can&#39;t have any side-effects or inputs and must return an integer, which somewhat limits their usefulness.)</p>
<p>Zest currently lives in a private repo because I don&#39;t want to give the impression that this is something people should try to play with, file issues for, send me pull requests for etc. But I&#39;m happy to add individual people who have informed opinions about compilers or language design. <a href="mailto:jamie@scattered-thoughts.net">Email me</a> :)</p>

</article></div>
  </body>
</html>
