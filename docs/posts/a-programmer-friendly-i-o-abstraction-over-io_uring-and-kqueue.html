<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tigerbeetle.com/blog/a-friendly-abstraction-over-iouring-and-kqueue/">Original</a>
    <h1>A programmer-friendly I/O abstraction over io_uring and kqueue</h1>
    
    <div id="readability-page-1" class="page"><div>
  <p>Consider this tale of I/O and performance. We’ll start with blocking
I/O, explore io_uring and kqueue, and take home an event loop very
similar to some software you may find familiar.</p>
<p>This is a twist on King’s talk at <a href="https://www.youtube.com/watch?v=Ul8OO4vQMTw">Software You Can Love Milan
‘22</a>.</p>
<h2 id="classical-approach">Classical approach</h2>
<p>When you want to read from a file you might <code>open()</code> and then call
<code>read()</code> as many times as necessary to fill a buffer of bytes from the
file. And in the opposite direction, you call <code>write()</code> as many times
as needed until everything is written. It’s similar for a TCP client
with sockets, but instead of <code>open()</code> you first call <code>socket()</code> and
then <code>connect()</code> to your server. Fun stuff.</p>
<p>In the real world though you can’t always read everything you want
immediately from a file descriptor. Nor can you always write
everything you want immediately to a file descriptor.</p>
<p>You can <a href="https://stackoverflow.com/questions/12773509/read-is-not-blocking-in-socket-programming/12775464#12775464">switch a file descriptor into non-blocking
mode</a>
so the call won’t block while data you requested is not available. But
system calls are still expensive, incurring context switches and cache
misses. In fact, networks and disks have become so fast that these
costs can start to approach the cost of doing the I/O itself. For the
duration of time a file descriptor is unable to read or write, you
don’t want to waste time continuously retrying read or write system
calls.</p>
<h2 id="batching-and-readiness">Batching and readiness</h2>
<p>So you switch to io_uring on Linux or kqueue on FreeBSD/macOS. (I’m
skipping the generation of epoll/select users.) These APIs let you
submit requests to the kernel to learn about readiness: when a file
descriptor is ready to read or write. You can send readiness requests
in batches (also referred to as queues). Completion events, one for
each submitted request, are available in a separate queue.</p>
<p>Being able to batch I/O like this is especially important for TCP
servers that want to multiplex reads and writes for multiple connected
clients.</p>
<p>However in io_uring, you can even go one step further. Instead of
having to call <code>read()</code> or <code>write()</code> in userland after a readiness
event, you can request that the kernel do the <code>read()</code> or <code>write()</code>
itself with a buffer you provide. Thus almost all of your I/O is done
in the kernel, amortizing the overhead of system calls.</p>
<p>If you haven’t seen io_uring or kqueue before, you’d probably like an
example! Consider this code: a simple, minimal,
not-production-ready TCP echo server.</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span> std <span>=</span> @import(<span>&#34;std&#34;</span>);
</span></span><span><span><span>const</span> os <span>=</span> std.os;
</span></span><span><span><span>const</span> linux <span>=</span> os.linux;
</span></span><span><span><span>const</span> allocator <span>=</span> std.heap.page_allocator;
</span></span><span><span>
</span></span><span><span><span>const</span> State <span>=</span> <span>enum</span>{ accept, recv, send };
</span></span><span><span><span>const</span> Socket <span>=</span> <span>struct</span> {
</span></span><span><span>    handle<span>:</span> os.socket_t,
</span></span><span><span>    buffer<span>:</span> [<span>1024</span>]<span>u8</span>,
</span></span><span><span>    state<span>:</span> State,
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>pub</span> <span>fn</span> main() <span>!</span><span>void</span> {
</span></span><span><span>    <span>const</span> entries <span>=</span> <span>32</span>;
</span></span><span><span>	<span>const</span> flags <span>=</span> <span>0</span>;
</span></span><span><span>    <span>var</span> ring <span>=</span> <span>try</span> linux.IO_Uring.init(entries, flags);
</span></span><span><span>    <span>defer</span> ring.deinit();
</span></span><span><span>
</span></span><span><span>    <span>var</span> server<span>:</span> Socket <span>=</span> <span>undefined</span>;
</span></span><span><span>    server.handle <span>=</span> <span>try</span> os.socket(os.AF.INET, os.SOCK.STREAM, os.IPPROTO.TCP);
</span></span><span><span>    <span>defer</span> os.closeSocket(server.handle);
</span></span><span><span>
</span></span><span><span>    <span>const</span> port <span>=</span> <span>12345</span>;
</span></span><span><span>    <span>var</span> addr <span>=</span> std.net.Address.initIp4(.{<span>127</span>, <span>0</span>, <span>0</span>, <span>1</span>}, port);
</span></span><span><span>    <span>var</span> addr_len<span>:</span> os.socklen_t <span>=</span> addr.getOsSockLen();
</span></span><span><span>
</span></span><span><span>    <span>try</span> os.setsockopt(server.handle, os.SOL.SOCKET, os.SO.REUSEADDR, <span>&amp;</span>std.mem.toBytes(@as(<span>c_int</span>, <span>1</span>)));
</span></span><span><span>    <span>try</span> os.bind(server.handle, <span>&amp;</span>addr.any, addr_len);
</span></span><span><span>	<span>const</span> backlog <span>=</span> <span>128</span>;
</span></span><span><span>    <span>try</span> os.listen(server.handle, backlog); 
</span></span><span><span>
</span></span><span><span>    server.state <span>=</span> .accept;
</span></span><span><span>    _ <span>=</span> <span>try</span> ring.accept(@ptrToInt(<span>&amp;</span>server), server.handle, <span>&amp;</span>addr.any, <span>&amp;</span>addr_len, <span>0</span>);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (<span>true</span>) {
</span></span><span><span>        _ <span>=</span> <span>try</span> ring.submit_and_wait(<span>1</span>);
</span></span><span><span>
</span></span><span><span>        <span>while</span> (ring.cq_ready() <span>&gt;</span> <span>0</span>) {
</span></span><span><span>            <span>const</span> cqe <span>=</span> <span>try</span> ring.copy_cqe();
</span></span><span><span>            <span>var</span> client <span>=</span> @intToPtr(<span>*</span>Socket, @intCast(<span>usize</span>, cqe.user_data));
</span></span><span><span>
</span></span><span><span>            <span>if</span> (cqe.res <span>&lt;</span> <span>0</span>) std.debug.panic(<span>&#34;{}({}): {}&#34;</span>, .{
</span></span><span><span>                client.state,
</span></span><span><span>                client.handle,
</span></span><span><span>                @intToEnum(os.E, <span>-</span>cqe.res),
</span></span><span><span>            });
</span></span><span><span>
</span></span><span><span>            <span>switch</span> (client.state) {
</span></span><span><span>                .accept <span>=&gt;</span> {
</span></span><span><span>                    client <span>=</span> <span>try</span> allocator.create(Socket);
</span></span><span><span>                    client.handle <span>=</span> @intCast(os.socket_t, cqe.res);
</span></span><span><span>                    client.state <span>=</span> .recv;
</span></span><span><span>                    _ <span>=</span> <span>try</span> ring.recv(@ptrToInt(client), client.handle, .{.buffer <span>=</span> <span>&amp;</span>client.buffer}, <span>0</span>);
</span></span><span><span>                    _ <span>=</span> <span>try</span> ring.accept(@ptrToInt(<span>&amp;</span>server), server.handle, <span>&amp;</span>addr.any, <span>&amp;</span>addr_len, <span>0</span>);
</span></span><span><span>                },
</span></span><span><span>                .recv <span>=&gt;</span> {
</span></span><span><span>                    <span>const</span> read <span>=</span> @intCast(<span>usize</span>, cqe.res);
</span></span><span><span>                    client.state <span>=</span> .send;
</span></span><span><span>                    _ <span>=</span> <span>try</span> ring.send(@ptrToInt(client), client.handle, client.buffer[<span>0</span>..read], <span>0</span>);
</span></span><span><span>                },
</span></span><span><span>                .send <span>=&gt;</span> {
</span></span><span><span>                    os.closeSocket(client.handle);
</span></span><span><span>                    allocator.destroy(client);
</span></span><span><span>                },
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>This is a great, minimal example. But notice that this code ties
io_uring behavior directly to business logic (in this case, handling
echoing data between request and response). It is fine for a small
example like this. But in a large application you might want to do I/O
throughout the code base, not just in one place. You might not want to
keep adding business logic to this single loop.</p>
<h2 id="central-io-dispatch">Central I/O dispatch</h2>
<p>Instead, you might want to be able to schedule I/O and pass a callback
(and sometimes with some application context) to be called when the
event is complete.</p>
<p>The interface might look like:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span>io_dispatch.dispatch({ <span>…</span> some big <span>struct</span><span>/</span><span>union</span> with relevant fields <span>for</span> all event types <span>…</span> }, my_callback)
</span></span></code></pre></div><p>This is great! Now your business logic can schedule and handle I/O no
matter where in the code base it is.</p>
<p>Under the hood it can decide whether to use io_uring or kqueue
depending on what kernel it’s running on. The dispatch can also batch
these individual calls through io_uring or kqueue to amortize system
calls. The application no longer needs to know the details.</p>
<p>Additionally, we can use this wrapper to stop thinking about readiness
events, just I/O completion. That is, if we dispatch a read event, the
io_uring implementation would actually ask the kernel to read data
into a buffer. Whereas the kqueue implementation would send a “read”
readiness event, do the read back in userland, and then call our
callback.</p>
<p>And finally, now that we’ve got this central dispatcher, we don’t need
spaghetti code in a loop switching on every possible submission and
completion event.</p>
<h2 id="interacting-with-the-submission-and-completion-queue">Interacting with the submission and completion queue</h2>
<p>Every time we call io_uring or kqueue we both submit event requests
and poll for completion events. The io_uring and kqueue APIs tie these
two actions together in the same system call.</p>
<p>To sync our requests to io_uring or kqueue we’ll build a <code>flush</code>
function that submits requests and polls for completion events. (In
the next section we’ll talk about how the user of the central dispatch
learns about completion events.)</p>
<p>To make <code>flush</code> more convenient, we’ll build a nice wrapper around it
so that we can submit as many requests (and process as many completion
events) as possible. To avoid accidentally blocking indefinitely we’ll
also introduce a time limit. We’ll call the wrapper <code>run_for_ns</code>.</p>
<p>Finally we’ll put the user in charge of setting up a loop to call this
<code>run_for_ns</code> function, independent of normal program execution.</p>
<p>This is now your traditional event loop.</p>
<h2 id="callbacks-and-context">Callbacks and context</h2>
<p>You may have noticed that in the API above we passed a callback. The
idea is that after the requested I/O has completed, our callback
should be invoked. But the question remains: how to track this
callback between the submission and completion queue?</p>
<p>Thankfully, io_uring and kqueue events have user data fields. The user
data field is opaque to the kernel. When a submitted event completes,
the kernel sends a completion event back to userland containing the
user data value from the submission event.</p>
<p>We can store the callback in the user data field by setting it to the
callback’s pointer casted to an integer. When the completion for a
requested event comes up, we cast from the integer in the user data
field back to the callback pointer. Then, we invoke the callback.</p>
<h2 id="getting-more-expressive">Getting more expressive</h2>
<p>As described above, the struct for <code>io_dispatch.dispatch</code> could get
quite large handling all the different kinds of I/O events and their
arguments. We could make our API a little more expressive by creating
wrapper functions for each event type.</p>
<p>So if we wanted to schedule a read function we could call:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span>io_dispatch.read(fd, <span>&amp;</span>buf, nBytesToRead, callback)
</span></span></code></pre></div><p>Or to write, similarly:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span>io_dispatch.write(fd, buf, nBytesToWrite, callback)
</span></span></code></pre></div><h2 id="overflow">Overflow</h2>
<p>One more thing we need to worry about is that the batch we pass to
io_uring or kqueue has a fixed size (technically, kqueue allows any
batch size but using that might introduce unnecessary
allocations). So we’ll build our own queue on top of our I/O
abstraction to keep track of requests that we could not immediately
submit to io_uring or kqueue.</p>
<p>
  To keep this API simple we could allocate for each entry in the
  queue. Or we could modify the <code>io_dispatch.X</code> calls
  slightly to accept a struct that can be used in an <a href="https://www.data-structures-in-practice.com/intrusive-linked-lists/">intrusive
  linked list</a> to contain all request context, including the
  callback. The latter is <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/d15acc663f8882cb02413129e8351bf3238335e6/src/io/linux.zig#L665">what
  we do in TigerBeetle</a>.
</p>
<p>Put another way: every time code calls <code>io_dispatch</code>, we’ll try to
immediately submit the requested event to io_uring or kqueue. But if
there’s no room, we store the event in an overflow queue.</p>
<p>The overflow queue needs to be processed eventually, so we update our
<code>flush</code> function (described in <a href="https://tigerbeetle.com/blog/a-friendly-abstraction-over-iouring-and-kqueue/callbacks-and-context">Callbacks and context</a> above) to
pull as many events from our overflow queue before submitting a batch
to io_uring or kqueue.</p>
<h2 id="a-step-back">A step back</h2>
<p>We’ve now built something similar to
<a href="https://github.com/libuv/libuv">libuv</a>, the I/O library that Node.js
uses. And if you squint, it is basically TigerBeetle’s I/O library!
(And interestingly enough, TigerBeetle’s I/O code was
<a href="https://github.com/oven-sh/bun/blob/e14a3af491ece8d1b0309e76ae3022b4fad91f16/src/io/io_linux.zig#L704">adopted</a>
into Bun! Open-source for the win!)</p>
<p>Let’s check out how the <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/darwin.zig#L436">Darwin
version</a>
of TigerBeetle’s I/O library (with kqueue) differs from the <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/linux.zig#L656">Linux
version</a>. As
mentioned, the complete <code>send</code> call in the Darwin implementation waits
for file descriptor readiness (through kqueue). Once ready, the actual
<code>send</code> call is made back in userland:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>pub</span> <span>fn</span> send(
</span></span><span><span>        self<span>:</span> <span>*</span>IO,
</span></span><span><span>        <span>comptime</span> Context<span>:</span> <span>type</span>,
</span></span><span><span>        context<span>:</span> Context,
</span></span><span><span>        <span>comptime</span> callback<span>:</span> <span>fn</span> (
</span></span><span><span>            context<span>:</span> Context,
</span></span><span><span>            completion<span>:</span> <span>*</span>Completion,
</span></span><span><span>            result<span>:</span> SendError<span>!</span><span>usize</span>,
</span></span><span><span>        ) <span>void</span>,
</span></span><span><span>        completion<span>:</span> <span>*</span>Completion,
</span></span><span><span>        socket<span>:</span> os.socket_t,
</span></span><span><span>        buffer<span>:</span> []<span>const</span> <span>u8</span>,
</span></span><span><span>    ) <span>void</span> {
</span></span><span><span>        self.submit(
</span></span><span><span>            context,
</span></span><span><span>            callback,
</span></span><span><span>            completion,
</span></span><span><span>            .send,
</span></span><span><span>            .{
</span></span><span><span>                .socket <span>=</span> socket,
</span></span><span><span>                .buf <span>=</span> buffer.ptr,
</span></span><span><span>                .len <span>=</span> @intCast(<span>u32</span>, buffer_limit(buffer.len)),
</span></span><span><span>            },
</span></span><span><span>            <span>struct</span> {
</span></span><span><span>                <span>fn</span> do_operation(op<span>:</span> anytype) SendError<span>!</span><span>usize</span> {
</span></span><span><span>                    <span>return</span> os.send(op.socket, op.buf[<span>0</span>..op.len], <span>0</span>);
</span></span><span><span>                }
</span></span><span><span>            },
</span></span><span><span>        );
</span></span><span><span>    }
</span></span></code></pre></div><p>Compare this to the <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/linux.zig#L656">Linux
version</a>
(with io_uring) where the kernel handles everything and there is no
send system call in userland:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>pub</span> <span>fn</span> send(
</span></span><span><span>        self<span>:</span> <span>*</span>IO,
</span></span><span><span>        <span>comptime</span> Context<span>:</span> <span>type</span>,
</span></span><span><span>        context<span>:</span> Context,
</span></span><span><span>        <span>comptime</span> callback<span>:</span> <span>fn</span> (
</span></span><span><span>            context<span>:</span> Context,
</span></span><span><span>            completion<span>:</span> <span>*</span>Completion,
</span></span><span><span>            result<span>:</span> SendError<span>!</span><span>usize</span>,
</span></span><span><span>        ) <span>void</span>,
</span></span><span><span>        completion<span>:</span> <span>*</span>Completion,
</span></span><span><span>        socket<span>:</span> os.socket_t,
</span></span><span><span>        buffer<span>:</span> []<span>const</span> <span>u8</span>,
</span></span><span><span>    ) <span>void</span> {
</span></span><span><span>        completion.<span>*</span> <span>=</span> .{
</span></span><span><span>            .io <span>=</span> self,
</span></span><span><span>            .context <span>=</span> context,
</span></span><span><span>            .callback <span>=</span> <span>struct</span> {
</span></span><span><span>                <span>fn</span> wrapper(ctx<span>:</span> <span>?*</span>anyopaque, comp<span>:</span> <span>*</span>Completion, res<span>:</span> <span>*</span><span>const</span> anyopaque) <span>void</span> {
</span></span><span><span>                    callback(
</span></span><span><span>                        @intToPtr(Context, @ptrToInt(ctx)),
</span></span><span><span>                        comp,
</span></span><span><span>                        @intToPtr(<span>*</span><span>const</span> SendError<span>!</span><span>usize</span>, @ptrToInt(res)).<span>*</span>,
</span></span><span><span>                    );
</span></span><span><span>                }
</span></span><span><span>            }.wrapper,
</span></span><span><span>            .operation <span>=</span> .{
</span></span><span><span>                .send <span>=</span> .{
</span></span><span><span>                    .socket <span>=</span> socket,
</span></span><span><span>                    .buffer <span>=</span> buffer,
</span></span><span><span>                },
</span></span><span><span>            },
</span></span><span><span>        };
</span></span><span><span>        <span>// Fill out a submission immediately if possible, otherwise adds to overflow buffer
</span></span></span><span><span><span></span>        self.enqueue(completion);
</span></span><span><span>    }
</span></span></code></pre></div><p>Similarly, take a look at <code>flush</code> on
<a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/linux.zig#L66">Linux</a>
and
<a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/darwin.zig#L75">macOS</a>
for event processing. Look at <code>run_for_ns</code> on
<a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/linux.zig#L66%5D">Linux</a>
and
<a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/darwin.zig#L75">macOS</a>
for the public API users must call. And finally, look at what puts
this all into practice, the loop calling <code>run_for_ns</code> in src/main.zig.</p>
<h2 id="windows-and-iocp">Windows and IOCP</h2>
<p>We’ve come this far and you might be wondering — what about
cross-platform support for Windows? The good news is that Windows also
has a completion based system similar to io_uring but without
batching, called
<a href="https://learn.microsoft.com/en-us/windows/win32/fileio/i-o-completion-ports">IOCP</a>. And
for bonus points, TigerBeetle provides the <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/9d3552ba137a773d4b81106739e56cba6cd32a03/src/io/windows.zig">same I/O abstraction over
it</a>!
But it’s enough to cover just Linux and macOS in this post. :)</p>
<h2 id="beyond-a-single-thread">Beyond a single thread</h2>
<p>In both this blog post and in TigerBeetle, we implemented a
single-threaded event loop. Keeping I/O code single-threaded in
userspace is beneficial (whether or not I/O processing is
single-threaded in the kernel is not our concern). It’s the simplest
code and best for workloads that are not embarrassingly parallel. It
is also best for determinism, which is integral to the design of
TigerBeetle because it enables us to do Deterministic Simulation
Testing</p>
<p>But there are other valid architectures for other workloads.</p>
<p>For workloads that are embarrassingly parallel, like many web servers,
you could instead use multiple threads where each thread has its own
queue. In optimal conditions, this architecture has the highest I/O
throughput possible.</p>
<p>But if each thread has its own queue, individual threads can become
starved if an uneven amount of work is scheduled on one thread. In the
case of dynamic amounts of work, the better architecture would be to
have a single queue but multiple worker threads doing the work made
available on the queue.</p>
<h2 id="standalone-cross-platform-evented-io-library">Standalone cross-platform evented I/O library?</h2>
<p>Hey, maybe we’ll split this out so you can use it too. It’s written in
Zig so we can easily expose a C API. Any language with a C foreign
function interface (i.e. every language) should work well with
it. Keep an eye on <a href="https://github.com/tigerbeetledb">our GitHub</a>. :)</p>
<p>Additional resources:</p>
<ul>
<li><a href="https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf">https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf</a></li>
<li><a href="https://github.com/ziglang/zig/issues/8224">https://github.com/ziglang/zig/issues/8224</a></li>
<li><a href="https://www.youtube.com/watch?v=lZU6RK0oazM">https://www.youtube.com/watch?v=lZU6RK0oazM</a></li>
<li><a href="https://unixism.net/loti/">https://unixism.net/loti/</a></li>
</ul>

<blockquote><p lang="en" dir="ltr">In our latest post, consider a tale of I/O and performance.</p>— TigerBeetle (@TigerBeetleDB) <a href="https://twitter.com/TigerBeetleDB/status/1595448218149859335?ref_src=twsrc%5Etfw">November 23, 2022</a></blockquote> 

</div></div>
  </body>
</html>
