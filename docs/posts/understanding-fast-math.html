<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pspdfkit.com/blog/2021/understanding-fast-math/">Original</a>
    <h1>Understanding Fast-Math</h1>
    
    <div id="readability-page-1" class="page"><div>
<div>
<article>

<div>
<article>
<span><p>While adding support for Xcode 13 to our <a href="https://pspdfkit.com/pdf-sdk/ios/">iOS PDF SDK</a>, we stumbled upon an interesting issue in our PDF renderer. Everything worked fine in debug builds, but when using the new developer tools to compile in release configuration, some PDF elements were missing. After a lot of <code>printf</code> debugging, it became apparent that a floating-point <a href="https://twitter.com/bukovinski/status/1438481013706039299" target="_blank" rel="noreferrer"><code>NaN</code> check started failing</a>, which eventually led us to the <code>-ffast-math</code> optimization we <a href="https://twitter.com/steipete/status/1438493066181107719" target="_blank" rel="noreferrer">introduced a few years ago</a>. Luckily, we managed to catch this issue during internal QA before it became a problem for our customers. As we clearly underestimated the risks associated with this optimization, it seemed prudent to take a closer look at it. It turns out that, like with almost anything else relating to IEEE floating-point math, it’s a rabbit hole full of surprising behaviors.</p>

<h2 id="what-is-fast-math"><a href="#what-is-fast-math" aria-label="Link to heading"></a>What Is Fast-Math?</h2>
<p><code>-ffast-math</code> is a compiler flag that enables a set of aggressive floating-point optimizations. The flag is shorthand for a collection of different optimization techniques, each having its own compiler flag. The exact set of optimizations differs between compilers, but it generally includes a set of optimizations that leverage algebraic rules that hold for real numbers, but not necessarily for IEEE floats.</p>
<p>Enabling <code>-ffast-math</code> will break strict IEEE compliance for your application and could result in changes in behavior. At best, it might affect the precision of computed numbers. At worst, it might significantly affect the program’s branching and produce completely unexpected results.</p>
<p>In Xcode, the fast-math optimization can be enabled with the <code>GCC_FAST_MATH</code> build setting. You can find it listed as Relax IEEE Compliance in the Xcode Build Settings UI under Apple Clang - Code Generation.</p>
<h3 id="clang"><a href="#clang" aria-label="Link to heading"></a>Clang</h3>
<p>To better understand the optimizations <code>-ffast-math</code> enables, we can look at the <a href="https://clang.llvm.org/docs/UsersManual.html#cmdoption-ffast-math" target="_blank" rel="noreferrer">specific set of behaviors (compiler flags)</a> the option implies when using the Clang compiler:</p>
<ul><li>
<p><code>-ffinite-math-only</code> — Shorthand for <code>-fno-honor-infinities</code> and <code>-fno-honor-nans</code>.</p>
<ul><li>
<p><code>-fno-honor-infinities</code> — The compiler assumes there are no infinities (<code>+/-Inf</code>) in the program (neither in the arguments nor in the results of floating-point arithmetic).</p>
</li><li>
<p><code>-fno-honor-nans</code> — The compiler assumes there are no <code>NaN</code>s in the program (neither in the arguments nor in the results of floating-point arithmetic).</p>
</li></ul></li><li>
<p><code>-fno-math-errno</code> — Enables optimizations that might cause standard C math functions to not set <code>errno</code>. This avoids a write to a thread-local variable and enables inlining of certain math functions.</p>
</li><li>
<p><code>funsafe-math-optimizations</code> — Shorthand for a set of unsafe floating-point optimizations.</p>
<ul><li>
<p><code>-fassociative-math</code> — Enables optimizations leveraging the associative property of real numbers, i.e. (x + y) + z =&gt; x + (y + z). Due to rounding errors, this algebraic law typically doesn’t apply to IEEE floating-point numbers.</p>
</li><li>
<p><code>-freciprocal-math</code> — Allows division operations to be transformed into multiplication by a reciprocal, e.g. x = a / c; y = b / c; =&gt; tmp = 1.0 / c; x = a _ tmp; y = b _ tmp. This can be significantly faster than division, but it can also be <a href="https://stackoverflow.com/questions/10679154/why-is-freciprocal-math-unsafe-in-gcc" target="_blank" rel="noreferrer">less precise</a>.</p>
</li><li>
<p><code>-fno-signed-zeros</code> — Enables optimizations that ignore the sign of floating-point zeros. Without this option, IEEE arithmetic predicts specific behaviors for +0.0 and -0.0 values, which <a href="https://artificial-mind.net/blog/2019/08/09/floating-point-optimizations" target="_blank" rel="noreferrer">prohibit the simplification of expressions like x+0.0 or 0.0*x</a>.</p>
</li><li>
<p><code>-fno-trapping-math</code> — The compiler assumes floating-point exceptions won’t ever actually invoke a signal handler, which enables speculative execution of floating-point expressions and simple optimizations like <a href="https://stackoverflow.com/questions/50374771/what-does-gcc-fno-trapping-math-do" target="_blank" rel="noreferrer">this one</a>.</p>
</li></ul></li><li>
<p><code>-ffp-contract=fast</code> — Enables the use of floating-point contraction instructions, such as <a href="https://en.wikipedia.org/wiki/FMA_instruction_set" target="_blank" rel="noreferrer">fused multiply-add (FMA)</a>. In turn, the floating-point contraction instructions combine two separate floating-point operations into a single operation. Those instructions can affect floating-point precision, because instead of rounding after each operation, the processor may round only once after both operations.</p>
</li></ul>
<p>With Clang (and GCC), you can assume that <code>-ffast-math</code> will also be used when specifying the <code>-Ofast</code> <a href="https://gist.github.com/lolo32/fd8ce29b218ac2d93a9e" target="_blank" rel="noreferrer">optimization level</a>.</p>
<h2 id="dealing-with-finite-math"><a href="#dealing-with-finite-math" aria-label="Link to heading"></a>Dealing with Finite Math</h2>
<p>One of the more controversial optimizations from the list above is <code>-ffinite-math-only</code>, together with its two sub-options, <code>-fno-honor-infinities</code> and <code>-fno-honor-nans</code>. The official <a href="https://clang.llvm.org/docs/UsersManual.html#cmdoption-ffast-math" target="_blank" rel="noreferrer">Clang documentation</a> doesn’t go into too much detail and just defines <code>-ffinite-math-only</code> as allowing “floating-point optimizations that assume arguments and results are not <code>NaN</code>s or +-Inf.”</p>
<p>This option enables <a href="https://stackoverflow.com/questions/10145401/what-are-the-optimizations-facilitated-by-ffinite-math-only" target="_blank" rel="noreferrer">a set of optimizations for arithmetic expressions</a>, which seem intuitive for real numbers but aren’t generally possible when we have to deal with <code>NaN</code> and <code>Inf</code> values in floating-point numbers. The option fits well with <code>-fno-signed-zeros</code> to enable <a href="https://kristerw.github.io/2021/10/19/fast-math/" target="_blank" rel="noreferrer">an ever greater set of optimizations</a>. So far, so good.</p>
<p>The controversy starts when we take a look at the behavior of a function like <code>isnan</code>. How should this check behave when we’re using <code>-ffinite-math-only</code>? Should it make a real check, or should the compiler just optimize it to <code>false</code>? With the current definition of this option, we’re essentially telling the compiler there will never be any <code>NaN</code>s in the program, so it’s technically free to optimize the check to a constant <code>false</code>.</p>
<p>While this optimization might make sense intuitively, provided you first carefully read the compiler documentation for <code>-ffast-math</code> and its suboptions, it also causes quite a few problems. For one, it breaks some reasonable workflows where we’d want to validate input data or where <code>NaN</code>s would be used as memory-efficient sentinels to mark invalid data in floating-point data structures. This is precisely the trap we fell into. Some of our C++ code uses <code>NaN</code>s to indicate invalid values for PDF primitives. Those values are checked with <code>isnan</code>, and branching is done accordingly. The code remained working fine for years after we first introduced the <code>-ffast-math</code> option. But it was always undefined behavior, and all it took was a compiler update to turn it into a regression.</p>
<p>The <code>-ffinite-math-only</code> optimization also causes inconsistencies where <code>isnan</code> checks will behave differently if they’re provided by the compiler or a library with different optimization settings (e.g. <code>libc</code>). There are also other standard APIs that might produce surprising behaviors — e.g. <code>std::numeric_limits&lt;T&gt;::has_quiet_NaN()</code> might still <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84949" target="_blank" rel="noreferrer">claim that <code>NaN</code>s are supported</a> even when the optimization is applied. You could also go so far as to say that <code>double</code> and <code>double</code> under <code>-ffinite-math-only</code> should be <a href="https://gcc.gnu.org/pipermail/gcc-patches/2020-April/544641.html" target="_blank" rel="noreferrer">considered different types</a> due to the differences in behavior you’d see if your project uses <code>-ffinite-math-only</code> selectively.</p>
<p>Another way to look at the logic of having <code>NaN</code> checks optimized out is from a pure performance point of view. It should be fairly safe to assume that code that extensively uses <code>isnan</code>, and could therefore benefit the most by having <code>NaN</code> checks removed, is also the code that most likely cares about the correct output of those checks — and therefore can’t use <code>-ffinite-math-only</code>.</p>
<p>The <code>-ffinite-math-only</code> option could be made safer if we changed the definition of <code>-ffinite-math-only</code> to only apply to arithmetic expressions, but otherwise still allow <code>NaN</code> values. In other words, the assumption of no <code>NaN</code>s would be applied to mathematical expressions and functions, but not to tests like <code>isnan</code>. This alternative has been proposed a few times already — most recently in <a href="https://lists.llvm.org/pipermail/llvm-dev/2021-September/152530.html" target="_blank" rel="noreferrer">this fairly lengthy llvm-dev mailing list thread</a>. In it, you can see that there are certainly good arguments to be made for either behavior, and at least for now, it appears as though the discussion ended in a stalemate.</p>
<h2 id="performance-impact"><a href="#performance-impact" aria-label="Link to heading"></a>Performance Impact</h2>
<p>We could have refactored our code to not use <code>NaN</code>s in this way, or employed a number of workarounds to fix the issue with our <code>isnan</code> checks, like using integer operations to check the bits corresponding to <code>NaN</code>, or selectively disabling <code>-ffinite-math-only</code> in certain files. However, we didn’t do any of that. Instead, we opted to play it safe, and we globally disabled <code>-ffast-math</code>.</p>
<p>The option was introduced before we had reliable performance tests, so I was curious to see what impact this would have. To my surprise, there were no measurable differences outside of the standard deviation we already see when repeating tests multiple times. This isn’t to say that certain floating-point operations didn’t in fact become slower. They most likely did. However, in our case, they don’t seem to be causing any actual bottlenecks.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="Link to heading"></a>Conclusion</h2>
<p>As you can see, <code>-ffast-math</code> is unfortunately not just a harmless optimization that makes your app run faster; it can also effect the correctness of your code. And even if it doesn’t do that right now, it might do that in the future with new compiler revisions.</p>
<p>Unless you see actual performance bottlenecks with your floating-point cancelations, it’s best to avoid <code>-ffast-math</code>. And there’s a good chance it won’t have a significant impact on the performance characteristics of your average program. It didn’t make much of a difference for our renderer, even though it has to deal with a lot of floating-point operations.</p>
<p>If your performance tests do indicate that <code>-ffast-math</code> makes a difference, then be sure to spend some time auditing your floating-point calculations and control flow to avoid the more obvious pitfalls, such as the use of <code>isnan</code> and <code>isinf</code>. In the end, most other issues will still be very hard to notice, so you’ll have to accept a certain amount of risk. For us, the decision was easy — it’s just not worth the trouble.</p>
</span>
</article>
</div>
</article>

</div>
</div><div>
<div>
<p><span>
Free 60-Day Trial
</span>
<span>
Try PSPDFKit in your app today.
</span>
</p>
<p><img src="https://pspdfkit.com/assets/images/illustrations/try-c40cc1f9.png" alt="" width="576" height="600"/>
<a href="https://pspdfkit.com/try/">
Free Trial
</a>
</p></div>
</div></div>
  </body>
</html>
