<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.chosenplaintext.ca/articles/radix-2-51-trick.html">Original</a>
    <h1>The radix 2^51 trick</h1>
    
    <div id="readability-page-1" class="page"><div>
		<p><em><strong>Faster addition and subtraction on modern CPUs</strong></em></p>

<p>Do you remember how to do long addition on paper?</p>

<pre><code> ¹¹ ¹
  6876
+ 3406
------
 10282
</code></pre>

<p>Starting from the “ones” position, we add 6 + 6 = 12, write down a 2 and carry a 1.
We proceed to the left, one position at a time, until there are no more digits
to add.</p>

<p>When implementing addition for large integers (e.g. 2<sup>64</sup> and above), it’s common to write
code that looks quite similar to this algorithm.
Interestingly, there’s a straightforward trick that can speed up this
process enormously on modern CPUs.</p>

<p>But first, a question: why do we start long addition with the “ones”?
Why not start on the left?</p>

<p>The answer, of course, is the carries.
We can’t figure out for sure what a given digit of the answer will be
until we’ve completed all of the additions to the right of that digit.</p>

<p>Imagine if we tried to add left-to-right instead:</p>

<blockquote>
  <p>6 + 3 = 9. So the first digit is 9.</p>
</blockquote>

<p>For mental math, this isn’t too bad (and some people actually prefer it
when working with small enough numbers).
As an algorithm, however, this approach has some fundamental limitations that
become clear when working with larger numbers.
Most importantly, because the later parts of the computation rely on
information from the earlier parts of the computation,
it’s hard to split up and parallelize the work.</p>

<h2 id="what-about-computers">What about computers?</h2>

<p>Computers don’t work in base 10, of course.
Instead, modern desktop and server CPUs expose an interface for operating on
(for the most part) 64-bit integers.</p>

<figure><pre><code data-lang="nasm"><span>; Add the 64-bit value in B to the 64-bit value in A</span>
<span>add</span> <span>A</span><span>,</span> <span>B</span>
<span>; Note: I&#39;ll use letters instead of real register names to keep things simple</span></code></pre></figure>

<p>As long as our numbers fit within a single 64-bit value, things are easy.
But what if we want to add, say, two 256-bit integers, <code>x</code> and <code>y</code>?</p>

<p>The obvious solution would be to break up each 256-bit number into four 64-bit
pieces (commonly referred to as “limbs”).
Place the highest 64 bits of <code>x</code> into register A,
the next 64 bits into register B,
and so on for registers C and D.
Do the same for <code>y</code> with registers E, F, G, H.</p>

<p>Now we can add <code>x</code> and <code>y</code> by adding the corresponding parts:</p>

<figure><pre><code data-lang="nasm"><span>; Equivalent to x += y</span>
<span>add</span> <span>A</span><span>,</span> <span>E</span>
<span>add</span> <span>B</span><span>,</span> <span>F</span>
<span>add</span> <span>C</span><span>,</span> <span>G</span>
<span>add</span> <span>D</span><span>,</span> <span>H</span></code></pre></figure>

<p>But wait, this might give us the wrong result!
If one of the last three additions overflow,
then we need to “carry” that extra 1 up to the next 64-bit piece.
Oh hey, does that sound familiar?</p>

<p>Fortunately, x86 has a dedicated instruction for this called “add with carry”.
<code>adc</code> will automatically check if the previous operation overflowed, adding 1
if needed.
Here’s how the proper code would look:</p>

<figure><pre><code data-lang="nasm"><span>add</span> <span>D</span><span>,</span> <span>H</span>
<span>adc</span> <span>C</span><span>,</span> <span>G</span> <span>; include carry from previous op</span>
<span>adc</span> <span>B</span><span>,</span> <span>F</span> <span>; include carry from previous op</span>
<span>adc</span> <span>A</span><span>,</span> <span>E</span> <span>; include carry from previous op</span></code></pre></figure>

<p>Just like with long addition in base 10,
we start with the least-significant “digits” (D and H)
and work our way up to the most-significant “digits” (A and E),
carrying 1s as needed along the way.</p>

<h2 id="but-now-its-slow">But now it’s slow</h2>

<p>Interestingly, our fixed code is slower than the original (incorrect) code.
Much slower.  Why is this?</p>

<p>The first reason is that <code>adc</code> is just slower to execute than a normal <code>add</code> on
most popular x86 CPUs.
Since <code>adc</code> has a third input (the carry flag),
it’s a more complex instruction than <code>add</code>.
It’s also used less often than <code>add</code>,
so there is less incentive for CPU designers to spend chip area on optimizing
<code>adc</code> performance.</p>

<p>The second reason is more interesting.
Let’s look at the Intel Haswell microarchitecture as an example.</p>

<p>On a Haswell CPU, a single <code>add</code> instruction takes 1 cycle to execute.
However, in ideal conditions, Haswell CPUs can execute up to 4 <code>add</code>
instructions in a single cycle.
How is this possible? Parallelism.
Modern processors look ahead at what instructions are coming up and try to
schedule them so that they can be executed in parallel whenever possible.
Since Haswell CPUs have 8 execution ports, and 4 of those ports can execute an
integer <code>add</code> instruction, a Haswell processor can execute up to 4 <code>add</code>
instructions at once.</p>

<p>In our original adding code, all 4 <code>add</code> instructions were independent of one
another, so it was straightforward for the processor to run them in parallel.
<strong>Now, with <code>adc</code>, each instruction depends on an output from the previous
instruction.</strong>
The processor has no choice but to execute the instructions serially, one after
the other, instead of in parallel.</p>

<p>The performance difference is even more dramatic if we use SIMD (Single
Instruction, Multiple Data) instructions.
For example, a single <code>vpaddq</code> (Vector Packed Add Quadword) instruction does
four 64-bit adds simultaneously.
Combine that with the fact that Haswell processors can execute two <code>vpaddq</code>s
per cycle, and you can see that we’re taking a serious performance hit
in order to handle carries properly.</p>

<h2 id="eliminating-carries-part-1-on-paper">Eliminating carries, part 1: on paper</h2>

<p>Back to base 10 for a minute.
How can we eliminate the need for carries?</p>

<p>Let’s make some changes to how the number system works.
First, we’ll extend the range of digits available.
Instead of 0-9, we will use 0-9, A-Z, and *:</p>

<pre><code>0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ*
</code></pre>

<p>(Yeah, I needed an extra character to make the numbers work out nicely. Bear
with me.)</p>

<p>Although we have 37 digits, we are <em>not</em> using base 37.
Numbers will still have “ones”, “tens”, and “hundreds” positions,
just like a normal base 10 system.
29 still means 29, and 29 + 1 is still 30.
The only difference is that
digits happen to be capable of counting past 9:
29 + 1 could also be written as 2A, 1K, or even U.</p>

<p>With this new, more flexible number system,
we can add without needing any carries!</p>

<pre><code>  672415
+ 736606
--------
  DA8A1B
</code></pre>

<p>This trick won’t work for all numbers in our number system (e.g. 9 + W will
need a carry),
but it will work if the numbers we are adding are
<em>normalized</em>, i.e. all of their digits are 9 or below.
In fact, we can add up to four normalized numbers in this notation before any
carries are possible:</p>

<pre><code>  999   &lt;-- largest possible normalized 3-digit number
  999
  999
+ 999
-----
  ***   &lt;-- valid 3-digit result, no carries
            (recall that * is the highest digit)
</code></pre>

<p>So, with some clever tweaks to the number system, we’ve cheated our way out of
some carries.
Of course, at some point, we will need to convert from the
37-digit base 10 system back to normal base 10.
We can do that by <em>normalizing</em> a number such that each of its digits is
between 0 and 9:</p>

<pre><code>  ¹¹ ¹ ¹
   DA8A1B
= 1409021

note:
D = 10 + 3
A = 10 + 0
B = 10 + 1
</code></pre>

<p>We normalize a number starting at the right,
determining how many “tens” are in each digit,
subtracting those “tens”,
and carrying them to the next digit.
672415 and 736606 do in fact sum to 1409021, so the system works!</p>

<p>The key insight here is that we can use this technique to delay carry
propagation until the end.
We can’t avoid carry propagation altogether, but we can avoid it temporarily.
If we save up the carries that occur during the intermediate additions,
we can propagate them all in one go at the end.</p>

<h2 id="eliminating-carries-part-2-computers">Eliminating carries, part 2: computers</h2>

<p>Carry propagation was at the heart of the performance problems we encountered earlier.
As you’ve probably anticipated by now, we can use this technique to help speed
up big number arithmetic!</p>

<p>Previously, we split a 256-bit number into four 64-bit pieces,
since x86_64 processors operate on 64-bit integers.
One way to understand this is to view the pieces as “digits”
in base 2<sup>64</sup>, since each digit has a value
between 0 and 2<sup>64</sup> - 1 (inclusive).</p>

<p>In base 10, we kept the same base, but extended the range of digits that were
allowed in order to prevent carries from occurring.
Unfortunately, we can’t do that here – a 64-bit integer only has so many
possible values, and we can’t change the hardware.
Instead, we can get the same effect by reducing the size of the base.</p>

<p>Instead of splitting 256 bits into four base 2<sup>64</sup> digits,
we’ll split 256 bits into five base 2<sup>51</sup> digits.
Each digit can still range from 0 to 2<sup>64</sup> - 1,
but the smaller base gives us the flexibility needed to prevent digits from
needing a carry.
This technique is generally referred to as “radix 2<sup>51</sup>
representation” in the cryptography literature.</p>

<p>Here’s how it will look when we split 256 bits across five limbs (i.e.
digits):</p>

<pre><code>|            [--------------------- 52 bits --------------------]|
|             [-------------------- 51 bits --------------------]|
|             [-------------------- 51 bits --------------------]|
|             [-------------------- 51 bits --------------------]|
|             [-------------------- 51 bits --------------------]|
</code></pre>

<p>Each limb has 51 (or 52) bits of the original 256-bit number.
The remaining 12 or 13 bits give us the extra “digits” we need for preventing
carries.
Effectively, the highest bits of each limb are reserved as storage for any
carries that occur during the computation.</p>

<p>In our base 10 example,
37 digits allowed us to add up to four normalized numbers before needing to
propagate carries.
In radix 2<sup>51</sup> representation,
2<sup>64</sup> digits allow us to add up to 2<sup>13</sup> normalized
numbers before we need to worry about the high 13 bits overflowing.</p>

<p><em>Aside: Why 13 bits instead of 12?
For our purposes, we’re going to ignore the carries in the most significant limb,
allowing numbers to wrap when they overflow past 2<sup>256</sup> - 1 (just like
how unsigned addition works in C with normal size integer types).
As a result, we can assign 52 bits to the most significant limb and ignore the
fact that it will run out of room for carries before the other limbs do.</em></p>

<p>With this new representation, our addition code now looks like:</p>

<figure><pre><code data-lang="nasm"><span>; Assume x is split across A, B, C, D, E (A = most significant)</span>
<span>; and assume y is split across F, G, H, I, J (F = most significant)</span>
<span>add</span> <span>A</span><span>,</span> <span>F</span>
<span>add</span> <span>B</span><span>,</span> <span>G</span>
<span>add</span> <span>C</span><span>,</span> <span>H</span>
<span>add</span> <span>D</span><span>,</span> <span>I</span>
<span>add</span> <span>E</span><span>,</span> <span>J</span>
<span>; Parallel goodness, yay!</span></code></pre></figure>

<p>Despite the fact that we now need 5 <code>add</code>s instead of 4,
addition is much faster due to the lack of carries.</p>

<p>Of course, we also need code to normalize a number by propagating carries.</p>

<figure><pre><code data-lang="nasm"><span>; Assume x is split across A, B, C, D, E (A = most significant)</span>
<span>; Register T is for temporary storage</span>

<span>mov</span> <span>T</span><span>,</span> <span>E</span> <span>; Copy E into T</span>
<span>shr</span> <span>T</span><span>,</span> <span>51</span> <span>; Shift out everything except the carries</span>
<span>add</span> <span>D</span><span>,</span> <span>T</span> <span>; Add carries from E into D</span>
<span>and</span> <span>E</span><span>,</span> <span>0x0007FFFFFFFFFFFF</span> <span>; Zero out the carries in E</span>

<span>mov</span> <span>T</span><span>,</span> <span>D</span> <span>; Copy D into T</span>
<span>shr</span> <span>T</span><span>,</span> <span>51</span> <span>; Shift out everything except the carries</span>
<span>add</span> <span>C</span><span>,</span> <span>T</span> <span>; Add carries from D into C</span>
<span>and</span> <span>D</span><span>,</span> <span>0x0007FFFFFFFFFFFF</span> <span>; Zero the carries in D</span>

<span>mov</span> <span>T</span><span>,</span> <span>C</span> <span>; Copy C into T</span>
<span>shr</span> <span>T</span><span>,</span> <span>51</span> <span>; Shift out everything except the carries</span>
<span>add</span> <span>B</span><span>,</span> <span>T</span> <span>; Add carries from C into B</span>
<span>and</span> <span>C</span><span>,</span> <span>0x0007FFFFFFFFFFFF</span> <span>; Zero the carries in C</span>

<span>mov</span> <span>T</span><span>,</span> <span>B</span> <span>; Copy B into T</span>
<span>shr</span> <span>T</span><span>,</span> <span>51</span> <span>; Shift out everything except the carries</span>
<span>add</span> <span>A</span><span>,</span> <span>T</span> <span>; Add carries from B into A</span>
<span>and</span> <span>B</span><span>,</span> <span>0x0007FFFFFFFFFFFF</span> <span>; Zero the carries in B</span>

<span>and</span> <span>A</span><span>,</span> <span>0x000FFFFFFFFFFFFF</span> <span>; Zero the carries in A</span></code></pre></figure>

<p>Amazingly, some quick and dirty benchmarks show that
<strong>radix 2<sup>51</sup> addition already outperforms radix 2<sup>64</sup>
addition on my Haswell CPU for as few as three additions – and that’s
including the cost of converting to and from
radix 2<sup>51</sup> representation</strong>.
The performance savings scale up appropriately as the number of additions
increases.</p>

<h2 id="subtraction">Subtraction</h2>

<p>So far we’ve only looked at addition.
It’s straightforward though to extend this technique to subtraction.
The main difference between addition and subtraction is that subtraction has
<em>negative</em> carries.</p>

<p>Previously, we treated all limbs (and their carries) as unsigned
integers.
To support subtraction, we can treat limbs as <em>signed</em> integers,
allowing individual digits to be either positive or negative.
With this change, each limb can store either a positive or negative carry.</p>

<p>A side effect of this is that the most significant bit of each limb is now
reserved as a sign bit.
This lowers the number of operations we can perform between normalizations from
2<sup>13</sup> to 2<sup>12</sup> – a small sacrifice in most cases.</p>

<p>I find this technique rather fascinating because of how counterintuitive it is:
by spreading data across more registers and using more operations, performance
is actually improved.
I hope you found it as interesting as I did!</p>

	</div></div>
  </body>
</html>
