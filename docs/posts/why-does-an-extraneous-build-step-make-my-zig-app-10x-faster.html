<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mtlynch.io/zig-extraneous-build/">Original</a>
    <h1>Why does an extraneous build step make my Zig app 10x faster?</h1>
    
    <div id="readability-page-1" class="page"><div><p>For the past few months, I‚Äôve been curious about two technologies: the Zig programming language and Ethereum cryptocurrency. To learn more about both, I‚Äôve been using Zig to write a bytecode interpreter for the Ethereum Virtual Machine.</p><p>Zig is a great language for performance optimization, as it gives you fine-grained control over memory and control flow. To motivate myself, I‚Äôve been benchmarking my Ethereum implementation against the official Go implementation.</p><figure><figcaption><p>At the beginning of this process, my hobby Ethereum Zig implementation underperformed the official Go implementation by about 40%.</p></figcaption></figure><p>Recently, I made what I thought was a simple refactoring to my benchmarking script, but my app‚Äôs performance tanked. I identified the relevant change as the difference between these two commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>&#39;60016000526001601ff3&#39;</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>execution time:  58.808¬µs
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>&#39;60016000526001601ff3&#39;</span> | xxd -r -p | ./zig-out/bin/eth-zvm
</span></span><span><span>execution time:  438.059¬µs
</span></span></code></pre></div><p><code>zig build run</code> is just a shortcut command for compiling a binary and executing it. It should be equivalent to the following two commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>zig build
</span></span><span><span>./zig-out/bin/eth-zvm
</span></span></code></pre></div><p>How could an additional build step cause my program to run almost 10x <em>faster</em>?</p><h2 id="creating-a-minimal-reproduction-of-the-phenomenon">Creating a minimal reproduction of the phenomenon<a href="#creating-a-minimal-reproduction-of-the-phenomenon" arialabel="Anchor"> üîóÔ∏é</a></h2><p>To debug the performance mystery, I tried simplifying my app until it was no longer a bytecode interpreter and was just a program that counted the number of bytes it read from stdin:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// src/main.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span>std<span> </span>=<span> </span><span>@import</span>(<span>&#34;std&#34;</span>);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>countBytes(reader:<span> </span>anytype)<span> </span>!<span>u32</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>count:<span> </span><span>u32</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span>(<span>true</span>)<span> </span>{<span>
</span></span></span><span><span><span>        </span>_<span> </span>=<span> </span>reader.readByte()<span> </span><span>catch</span><span> </span>|err|<span> </span><span>switch</span><span> </span>(err)<span> </span>{<span>
</span></span></span><span><span><span>            </span><span>error</span>.EndOfStream<span> </span>=&gt;<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>return</span><span> </span>count;<span>
</span></span></span><span><span><span>            </span>},<span>
</span></span></span><span><span><span>            </span><span>else</span><span> </span>=&gt;<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>return</span><span> </span>err;<span>
</span></span></span><span><span><span>            </span>},<span>
</span></span></span><span><span><span>        </span>};<span>
</span></span></span><span><span><span>        </span>count<span> </span>+=<span> </span><span>1</span>;<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>main()<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>reader<span> </span>=<span> </span>std.io.getStdIn().reader();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>timer<span> </span>=<span> </span><span>try</span><span> </span>std.time.Timer.start();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>start<span> </span>=<span> </span>timer.lap();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>count<span> </span>=<span> </span><span>try</span><span> </span>countBytes(&amp;reader);<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>end<span> </span>=<span> </span>timer.read();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>elapsed_micros<span> </span>=<span> </span><span>@as</span>(<span>f64</span>,<span> </span><span>@floatFromInt</span>(end<span> </span>-<span> </span>start))<span> </span>/<span> </span>std.time.ns_per_us;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>output<span> </span>=<span> </span>std.io.getStdOut().writer();<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>output.print(<span>&#34;bytes:           {}</span><span>\n</span><span>&#34;</span>,<span> </span>.{count});<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>output.print(<span>&#34;execution time:  {d:.3}¬µs</span><span>\n</span><span>&#34;</span>,<span> </span>.{elapsed_micros});<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>With the simplified app, I could still see the performance difference. When I ran the byte counter with <code>zig build run</code>, it ran in 13 microseconds:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>&#39;00010203040506070809&#39;</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  13.549¬µs
</span></span></code></pre></div><p>When I ran the compiled binary directly, it took 12x as long to run, completing in 162 microseconds:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>&#39;00010203040506070809&#39;</span> | xxd -r -p | ./zig-out/bin/count-bytes
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  162.195¬µs
</span></span></code></pre></div><p>My test consisted of three commands in a bash pipeline:</p><ol><li><code>echo</code> prints a sequence of ten hex-encoded bytes (<code>0x00</code>, <code>0x01</code>, ‚Ä¶).</li><li><code>xxd</code> converts <code>echo</code>‚Äôs hex-encoded bytes to binary-encoded bytes.</li><li><code>zig build run</code> compiles and executes my byte counter program, counting the number of binary-encoded bytes that <code>xxd</code> emitted.</li></ol><p>The only difference between <code>zig build run</code> and <code>./zig-out/bin/count-bytes</code> was that the second command runs the already-compiled app, whereas the first one recompiles the app.</p><p>Again, I was dumbfounded.</p><p>How could does an extra compilation step make the program <em>faster</em>? Does a Zig app somehow run quicker when it‚Äôs fresh out of the oven?</p><p>At this point, I was stumped. I had read my source code over and over, and I couldn‚Äôt understand how compiling and running an application could be faster than running the already-compiled binary.</p><p>Zig is still a new language, so there had to be something about Zig I‚Äôd misunderstood. Surely, if experienced Zig programmers looked at my code, they‚Äôd spot my error instantly.</p><p>I <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446?u=mtlynch">posted my question on Ziggit</a>, a discussion forum for Zig. The first few responses said I had a problem with ‚Äúinput buffering‚Äù but they didn‚Äôt have concrete suggestions to fix it or investigate further.</p><p>Andrew Kelly, Zig‚Äôs founder and lead developer made <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446/8?u=mtlynch">a surprise appearance in the thread</a>. He couldn‚Äôt explain the phenomenon I was seeing, but he pointed out that I was making a different performance mistake:</p><p><a href="https://mtlynch.io/zig-extraneous-build/akelly-post.png"><img sizes="(min-width: 768px) 812px, 98vw" srcset="/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_300x0_resize_lanczos_3.png 300w,
/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_600x0_resize_lanczos_3.png 600w,
/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_800x0_resize_lanczos_3.png 800w,
/zig-extraneous-build/akelly-post.png 812w" src="https://mtlynch.io/zig-extraneous-build/akelly-post.png" alt="Looks like you‚Äôre doing 1 syscall per byte read? That‚Äôs going to perform extremely poorly. My guess is that the extra steps of using the build system incidentally introduced some buffering. Not sure why though. The build system is making the child process inherit the file descriptors directly." loading="lazy"/></a></p><p>Finally, my friend <a href="https://www.agwa.name">Andrew Ayer</a> saw my post about this on Mastodon and <a href="https://m.mtlynch.io/@agwa@agwa.name/112039058255070708">solved the mystery</a>:</p><p><a href="https://mtlynch.io/zig-extraneous-build/agwa-masto.png"><img sizes="(min-width: 768px) 580px, 98vw" srcset="/zig-extraneous-build/agwa-masto_hu3331ab99a5fa1e60d0e3808234226068_45232_300x0_resize_lanczos_3.png 300w,
/zig-extraneous-build/agwa-masto.png 580w" src="https://mtlynch.io/zig-extraneous-build/agwa-masto.png" alt="Do you still see the 10x disparity with significantly larger inputs (i.e. &gt; 1MB)? Do you still the disparity if you redirect stdin from a file instead of a pipe? My guess is that when you execute the program directly, xxd and count-bytes start at the same time, so the pipe buffer is empty when count-bytes first tries to read from stdin, requiring it to wait until xxd fills it. But when you use zig build run, xxd gets a head start while the program is compiling, so by the time count-bytes reads from stdin, the pipe buffer has been filled." loading="lazy"/></a></p><p>Andrew Ayer got it exactly right, and I‚Äôll break it down below.</p><p>Sidenote: Andrew Ayer also had the key insight that <a href="https://mtlynch.io/notes/picoshare-perf/#ram-bloat-is-fine-but-crashes-are-not">solved my last performance mystery</a>.</p><h2 id="my-mental-model-of-bash-pipelines-is-wrong">My mental model of bash pipelines is wrong<a href="#my-mental-model-of-bash-pipelines-is-wrong" arialabel="Anchor"> üîóÔ∏é</a></h2><p>I had never thought too carefully about bash pipelines, but Andrew‚Äôs comment made me realize my mental model was wrong.</p><p>Imagine a simple bash pipeline like the following:</p><p>My mental model was that <code>jobA</code> would start and run to completion and then <code>jobB</code> would start with <code>jobA</code>‚Äôs output as its input.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/jobs-serial.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="/zig-extraneous-build/jobs-serial_hu88d6b1301a67af8b3bbc95e6127380c6_1026_300x0_resize_q90_h2_lanczos_2.webp 300w,
/zig-extraneous-build/jobs-serial.webp 570w" src="https://mtlynch.io/zig-extraneous-build/jobs-serial.webp" alt="Gantt chart of jobB starting after jobA finishes" loading="lazy"/></a><figcaption><p>My incorrect mental model of how jobs in a bash pipeline work</p></figcaption></figure><p>It turns out that all commands in a bash pipeline start at the same time.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/jobs-parallel.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="/zig-extraneous-build/jobs-parallel_hu94f5e650d86741a6659cd402fe2ceb69_3624_300x0_resize_q90_h2_lanczos_2.webp 300w,
/zig-extraneous-build/jobs-parallel.webp 570w" src="https://mtlynch.io/zig-extraneous-build/jobs-parallel.webp" alt="Gantt chart of jobA and jobB starting simultaneously, but jobB is longer because it has to wait for jobA&#39;s results" loading="lazy"/></a><figcaption><p>The actual way that jobs in a bash pipeline work</p></figcaption></figure><p>To demonstrate parallel execution in a bash pipeline, I wrote a proof of concept with two simple bash scripts.</p><p><code>jobA</code> starts, sleeps for three seconds, prints to stdout, sleeps for two more seconds, then exits:</p><div><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/usr/bin/env bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>function</span> print_status() {
</span></span><span><span>    <span>local</span> <span>message</span>=<span>&#34;</span><span>$1</span><span>&#34;</span>
</span></span><span><span>    <span>local</span> <span>timestamp</span>=<span>$(</span>date +<span>&#34;%T.%3N&#34;</span><span>)</span>
</span></span><span><span>    <span>echo</span> <span>&#34;</span><span>$timestamp</span><span> </span><span>$message</span><span>&#34;</span> &gt;&amp;<span>2</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>print_status <span>&#39;jobA is starting&#39;</span>
</span></span><span><span>
</span></span><span><span>sleep <span>3</span>
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>&#39;result of jobA is...&#39;</span>
</span></span><span><span>
</span></span><span><span>sleep <span>2</span>
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>&#39;42&#39;</span>
</span></span><span><span>
</span></span><span><span>print_status <span>&#39;jobA is terminating&#39;</span>
</span></span></code></pre></div><p><a href="https://mtlynch.io/zig-extraneous-build/jobA" download="">download jobA</a></p></div><p><code>jobB</code> starts, waits for input on stdin, then prints everything it can read from stdin until stdin closes:</p><div><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/usr/bin/env bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>function</span> print_status() {
</span></span><span><span>    <span>local</span> <span>message</span>=<span>&#34;</span><span>$1</span><span>&#34;</span>
</span></span><span><span>    <span>local</span> <span>timestamp</span>=<span>$(</span>date +<span>&#34;%T.%3N&#34;</span><span>)</span>
</span></span><span><span>    <span>echo</span> <span>&#34;</span><span>$timestamp</span><span> </span><span>$message</span><span>&#34;</span> &gt;&amp;<span>2</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>print_status <span>&#39;jobB is starting&#39;</span>
</span></span><span><span>
</span></span><span><span>print_status <span>&#39;jobB is waiting on input&#39;</span>
</span></span><span><span><span>while</span> <span>read</span> line; <span>do</span>
</span></span><span><span>  print_status <span>&#34;jobB read &#39;</span><span>${</span><span>line</span><span>}</span><span>&#39; from input&#34;</span>
</span></span><span><span><span>done</span> &lt; /dev/stdin
</span></span><span><span>print_status <span>&#39;jobB is done reading input&#39;</span>
</span></span><span><span>
</span></span><span><span>print_status <span>&#39;jobB is terminating&#39;</span>
</span></span></code></pre></div><p><a href="https://mtlynch.io/zig-extraneous-build/jobB" download="">download jobB</a></p></div><p>If I run <code>jobA</code> and <code>jobB</code> in a bash pipeline, exactly 5.009 seconds elapse between the <code>jobB is starting</code> and <code>jobB is terminating</code> messages:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./jobA | ./jobB
</span></span><span><span>09:11:53.326 jobA is starting
</span></span><span><span>09:11:53.326 jobB is starting
</span></span><span><span>09:11:53.328 jobB is waiting on input
</span></span><span><span>09:11:56.330 jobB <span>read</span> <span>&#39;result of jobA is...&#39;</span> from input
</span></span><span><span>09:11:58.331 jobA is terminating
</span></span><span><span>09:11:58.331 jobB <span>read</span> <span>&#39;42&#39;</span> from input
</span></span><span><span>09:11:58.333 jobB is <span>done</span> reading input
</span></span><span><span>09:11:58.335 jobB is terminating
</span></span></code></pre></div><p>If I adjust the execution so that <code>jobA</code> and <code>jobB</code> run in sequence instead of a pipeline, only 0.008 seconds elapse between <code>jobB</code>‚Äôs <code>starting</code> and <code>terminating</code> messages:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./jobA &gt; /tmp/output &amp;&amp; ./jobB &lt; /tmp/output
</span></span><span><span>16:52:10.406 jobA is starting
</span></span><span><span>16:52:15.410 jobA is terminating
</span></span><span><span>16:52:15.415 jobB is starting
</span></span><span><span>16:52:15.417 jobB is waiting on input
</span></span><span><span>16:52:15.418 jobB <span>read</span> <span>&#39;result of jobA is...&#39;</span> from input
</span></span><span><span>16:52:15.420 jobB <span>read</span> <span>&#39;42&#39;</span> from input
</span></span><span><span>16:52:15.421 jobB is <span>done</span> reading input
</span></span><span><span>16:52:15.423 jobB is terminating
</span></span></code></pre></div><h2 id="revisiting-my-byte-counter">Revisiting my byte counter<a href="#revisiting-my-byte-counter" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Once I understood that all commands in a bash pipeline run in parallel, the behavior I was seeing in my byte counter made sense:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>&#39;00010203040506070809&#39;</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  13.549¬µs
</span></span><span><span>
</span></span><span><span>$ <span>echo</span> <span>&#39;00010203040506070809&#39;</span> | xxd -r -p | ./zig-out/bin/count-bytes
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  162.195¬µs
</span></span></code></pre></div><p>It looks like the time to run the <code>echo &#39;00010203040506070809&#39; | xxd -r -p</code> part of the pipeline takes about 150 microseconds. The <code>zig build run</code> step must take at least 150 microseconds.</p><p>By the time the <code>count-bytes</code> application actually begins in the <code>zig build</code> version, it doesn‚Äôt have to wait for the previous jobs to complete. The input is already waiting on stdin.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="/zig-extraneous-build/count-bytes-zig-run_hu6a9d20b88fe604bdafc0746c9fdac319_4000_300x0_resize_q90_h2_lanczos_2.webp 300w,
/zig-extraneous-build/count-bytes-zig-run.webp 570w" src="https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run.webp" alt="Gantt chart where echo, xxd, and zig build run start at the same time, but the execute phase of zig build run starts after echo and xxd are complete" loading="lazy"/></a><figcaption><p>With <code>zig build run</code>, there‚Äôs a delay before my application executes, so previous jobs in the pipeline have already completed by the time <code>count-bytes</code> starts.</p></figcaption></figure><p>When I skip the <code>zig build</code> step and run the compiled binary directly, <code>count-bytes</code> starts immediately and the timer begins. The problem is that <code>count-bytes</code> has to sit around waiting ~150 microseconds for the <code>echo</code> and <code>xxd</code> commands to deliver input to stdin.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/count-bytes-compiled.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="/zig-extraneous-build/count-bytes-compiled_hu57b45cd7d5e7b5c80beccb83ecea8677_5502_300x0_resize_q90_h2_lanczos_2.webp 300w,
/zig-extraneous-build/count-bytes-compiled.webp 570w" src="https://mtlynch.io/zig-extraneous-build/count-bytes-compiled.webp" alt="Gantt chart where echo, xxd, and count-bytes all start at the same time, but count-bytes can&#39;t begin processing input until 150 microseconds after starting, as it&#39;s waiting on results from xxd" loading="lazy"/></a><figcaption><p>When I run <code>count-bytes</code> directly, it has to wait around for ~150 microseconds until <code>echo</code> and <code>xxd</code> feed input to stdin.</p></figcaption></figure><h2 id="fixing-my-benchmark">Fixing my benchmark<a href="#fixing-my-benchmark" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Fixing my benchmark was <a href="https://github.com/mtlynch/eth-zvm/pull/27">simple</a>. Instead of running my application as part of a bash pipeline, I split the preparation stage and the execution stage into separate commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># Convert the hex-encoded input to binary encoding.</span>
</span></span><span><span>$ <span>INPUT_FILE_BINARY</span>=<span>&#34;</span><span>$(</span>mktemp<span>)</span><span>&#34;</span>
</span></span><span><span>$ <span>echo</span> <span>&#39;60016000526001601ff3&#39;</span> | xxd -r -p &gt; <span>&#34;</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Read the binary-encoded input into the virtual machine.</span>
</span></span><span><span>$ ./zig-out/bin/eth-zvm &lt; <span>&#34;</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>&#34;</span>
</span></span><span><span>execution time:  67.378¬µs
</span></span></code></pre></div><p>My benchmark dropped from the 438 microseconds I was seeing before down to just 67 microseconds.</p><figure><figcaption><p>Difference in measured performance of my Zig app after I fixed my benchmarking script</p></figcaption></figure><h2 id="applying-andrew-kellys-performance-fix">Applying Andrew Kelly‚Äôs performance fix<a href="#applying-andrew-kellys-performance-fix" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Recall that Andrew Kelly <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446/8?u=mtlynch">pointed out</a> that I was doing one syscall for every byte I read.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>var</span><span> </span>reader<span> </span>=<span> </span>std.io.getStdIn().reader();<span>
</span></span></span><span><span><span></span>...<span>
</span></span></span><span><span><span></span><span>while</span><span> </span>(<span>true</span>)<span> </span>{<span>
</span></span></span><span><span><span>      </span>_<span> </span>=<span> </span>reader.readByte()<span> </span>{<span> </span><span>// Slow! One syscall per byte
</span></span></span><span><span><span></span><span>          </span>...<span>
</span></span></span><span><span><span>      </span>};<span>
</span></span></span><span><span><span>      </span>...<span>
</span></span></span><span><span><span>  </span>}<span>
</span></span></span></code></pre></div><p>So, every time my application called <code>readByte</code> in the loop, it had to halt execution, request an input read from the OS and then resume when the OS delivered the single byte.</p><p>The fix <a href="https://github.com/mtlynch/eth-zvm/pull/26">was simple</a>. I had to use a buffered reader. Instead of reading a single byte at a time from the OS, I‚Äôd use Zig‚Äôs built-in <code>std.io.bufferedReader</code>, which causes my application to read large chunks of data from the OS. That way, I only have to make a fraction of the syscalls.</p><p>Here‚Äôs the entire change:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>diff --git a/src/main.zig b/src/main.zig
</span></span></span><span><span><span>index d6e50b2..a46f8fa 100644
</span></span></span><span><span><span></span><span>--- a/src/main.zig
</span></span></span><span><span><span></span><span>+++ b/src/main.zig
</span></span></span><span><span><span></span><span>@@ -7,7 +7,9 @@ pub fn main() !void {
</span></span></span><span><span><span></span>     const allocator = gpa.allocator();
</span></span><span><span>     defer _ = gpa.deinit();
</span></span><span><span>
</span></span><span><span><span>-    var reader = std.io.getStdIn().reader();
</span></span></span><span><span><span></span><span>+    const in = std.io.getStdIn();
</span></span></span><span><span><span>+    var buf = std.io.bufferedReader(in.reader());
</span></span></span><span><span><span>+    var reader = buf.reader();
</span></span></span><span><span><span></span>
</span></span><span><span>     var evm = vm.VM{};
</span></span><span><span>     evm.init(allocator);
</span></span></code></pre></div><p>I re-ran my example, and it sped up performance by another 11 microseconds, a modest 16% speedup.</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build -Doptimize=ReleaseFast &amp;&amp; ./zig-out/bin/eth-zvm &lt; <span>&#34;</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>&#34;</span>
</span></span><span><span>execution time:  56.602¬µs
</span></span></code></pre></div><figure><figcaption><p>Buffering input reads increased performance by another 16%.</p></figcaption></figure><h2 id="benchmarking-a-larger-input">Benchmarking a larger input<a href="#benchmarking-a-larger-input" arialabel="Anchor"> üîóÔ∏é</a></h2><p>My Ethereum interpreter currently only supports a small subset of Ethereum‚Äôs opcodes. The most complex computation my interpreter can do at this point is add numbers together.</p><p>For example, here‚Äôs an Ethereum application that counts to three by pushing <code>1</code> to the stack three times and then adding the values together:</p><div><pre tabindex="0"><code data-lang="text"><span><span>PUSH1 1    # Stack now contains [1]
</span></span><span><span>PUSH1 1    # Stack now contains [1, 1]
</span></span><span><span>PUSH1 1    # Stack now contains [1, 1, 1]
</span></span><span><span>ADD        # Stack now contains [2, 1]
</span></span><span><span>ADD        # Stack now contains [3]
</span></span></code></pre></div><p>The largest application I tested in my benchmarks was Ethereum bytecode that counted to 1,000 by adding <code>1</code> values together.</p><p>After Andrew Kelly‚Äôs tip helped me <a href="https://github.com/mtlynch/eth-zvm/pull/26">reduce syscalls</a>, my ‚Äúcount to 1,000‚Äù application‚Äôs runtime dropped from 2,024 microseconds to just 58 microseconds, a 35x speedup. I was now beating the official Ethereum implementation by almost a factor of two.</p><figure><figcaption><p>Buffering my input reads allowed my Zig implementation to run about 2x faster than the official Ethereum implementation on the largest Ethereum application in my test set.</p></figcaption></figure><h2 id="cheating-my-way-to-maximum-performance">Cheating my way to maximum performance<a href="#cheating-my-way-to-maximum-performance" arialabel="Anchor"> üîóÔ∏é</a></h2><p>I was excited to see my Zig implementation finally outperforming the official Go version, but I wanted to see just how much I could leverage Zig to improve performance.</p><p>One common bottleneck in software is memory allocation. The program has to stop and wait for the OS to allocate RAM, which may involve shuffling around data to find enough contiguous space.</p><p>Zig has a memory allocator called the fixed buffer allocator. Instead of the memory allocator requesting memory from the OS, you provide the allocator a fixed buffer of bytes, and it uses only those bytes to allocate memory.</p><p>I can cheat my benchmarks by compiling a version of my Ethereum interpreter that‚Äôs limited to 2 KB of memory allocated from the stack:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>diff --git a/src/main.zig b/src/main.zig
</span></span></span><span><span><span>index a46f8fa..9e462fe 100644
</span></span></span><span><span><span></span><span>--- a/src/main.zig
</span></span></span><span><span><span></span><span>+++ b/src/main.zig
</span></span></span><span><span><span></span><span>@@ -3,9 +3,9 @@ const stack = @import(&#34;stack.zig&#34;);
</span></span></span><span><span><span></span> const vm = @import(&#34;vm.zig&#34;);
</span></span><span><span>
</span></span><span><span> pub fn main() !void {
</span></span><span><span><span>-    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
</span></span></span><span><span><span>-    const allocator = gpa.allocator();
</span></span></span><span><span><span>-    defer _ = gpa.deinit();
</span></span></span><span><span><span></span><span>+    var buffer: [2000]u8 = undefined;
</span></span></span><span><span><span>+    var fba = std.heap.FixedBufferAllocator.init(&amp;buffer);
</span></span></span><span><span><span>+    const allocator = fba.allocator();
</span></span></span><span><span><span></span>
</span></span><span><span>     const in = std.io.getStdIn();
</span></span><span><span>     var buf = std.io.bufferedReader(in.reader());
</span></span></code></pre></div><p>I call this a ‚Äúcheat‚Äù as I‚Äôm optimizing for my specific benchmarks. There are certainly valid Ethereum programs that require more than 2 KB of memory, but I‚Äôm just curious how fast I can go with this optimization.</p><p>Let‚Äôs see what performance looks like if I know my max memory requirement at compile time:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./zig-out/bin/eth-zvm &lt; <span>&#34;</span><span>${</span><span>COUNT_TO_1000_INPUT_BYTECODE_FILE</span><span>}</span><span>&#34;</span>
</span></span><span><span>execution time:  34.4578¬µs
</span></span></code></pre></div><p>Cool! With a fixed memory buffer, my Ethereum implementation runs my ‚Äúcount to 1,000‚Äù bytecode in 34 microseconds, nearly 3x faster than the official Go implementation.</p><figure><figcaption><p>If I know the maximum memory requirements of my Ethereum interpreter at compile time, I can outperform the official implementation by 3x.</p></figcaption></figure><h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor"> üîóÔ∏é</a></h2><p>My takeaway from this experience is to benchmark performance early and often.</p><p>By adding a benchmarking script to my continuous integration and archiving the results, it was easy for me to identify when my measurements changed. Had I relegated benchmarking to a manual, periodic task, it would have been difficult for me to identify exactly what caused the difference in my measurements.</p><p>This experience also underscores the importance of understanding your metrics. Before hitting this bug, I hadn‚Äôt considered that my benchmark included the time waiting for other processes to fill stdin.</p>
</div></div>
  </body>
</html>
