<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.augmentedmind.de/2022/02/20/optimize-docker-image-security/">Original</a>
    <h1>How to optimize the security, size and build speed of Docker images</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="text">
			
<p>This article introduces 12 tips to optimize your Docker image security. For each tip, it explains the underlying attack vector, and one or more mitigation approaches. Tips include avoiding leaking of build secrets, running as non-root user, or how to make sure to use the most recent dependencies and updates.</p>


				
			






<h2 id="introduction">Introduction</h2>



<p><strong>When you are new to Docker, you will most likely create <em>insecure</em> Docker images that make it easy for attackers to take over the container, or possibly even the entire host, which then allows the attacker to infiltrate other infrastructure of your company.</strong></p>



<p><strong>There are many different attack vectors that can be abused to take over your system</strong>, such as:</p>



<ul><li>The started application (specified in the <code>ENTRYPOINT</code> of your <code>Dockerfile</code>) runs as <code>root</code> user. Consequently, once an attacker has exploited a vulnerability and gains shell access, they can take over the <em>host</em> on which the Docker daemon is running.</li><li>Your image is based on an outdated and/or insecure <em>base</em> image, which contains security exploits which are (now) well-known.</li><li>Your image contains tools (such as <code>curl</code>, <code>apt</code>, etc.) that allow an attacker to load further malware into the container, once they have gained some kind of access.</li></ul>



<p><strong>The following sections explain different approaches to optimize your image security. They are sorted by importance/impact, such that the more important ones are listed first.</strong></p>



<h2 id="1-avoid-leaking-build-secrets">1. Avoid leaking build secrets</h2>



<p><strong><em>Build secrets</em> are credentials that are only needed while <em>building</em> your Docker image (not at run-time).</strong> For instance, you might want to include a compiled version of some application into your image whose source code is closed-source, and its Git repo is access-protected. While building the image, you need to clone the Git repo (which requires the build secrets, e.g. SSH access keys to that repo), build the application from source, and then delete the sources (and secrets) again.</p>



<p><strong>“Leaking” a build secret means that you accidentally baked such secrets into one of the layers of your image. This is bad, because <em>anyone</em> who pulls your image can retrieve the credentials.</strong> The problem originates from the fact that Docker images are built layer by layer, in a purely <em>additive</em> way. <strong>Files you delete in a layer are only <em>marked</em> as deleted, but can still be accessed by everyone pulling your image, using advanced tooling.</strong></p>



<p><strong>Use one of the following two approaches to avoid leaking build secrets:</strong></p>



<h3 id="a-multi-stage-builds">A. Multi-stage builds</h3>



<p><strong>Docker Multi-stage builds (<a href="https://docs.docker.com/develop/develop-images/multistage-build/" target="_blank" rel="noreferrer noopener">official docs</a>) have many different use cases</strong>, e.g. <em>speeding up</em> your image build, or <em>reducing the image size</em>. Other articles of this series go into details regarding these other use cases. Anyways, <strong>you can also multi-stage builds to avoid leaking build secrets, as follows:</strong></p>



<ul><li><strong>Create a stage #A into which you <code>COPY</code> the credentials and use them to retrieve other artifacts</strong> (e.g. the Git repo of the above example), <strong>and perform further steps with them</strong> (e.g. compiling an application). <strong>The stage #A build <em>does</em> contain the build secrets!</strong></li><li><strong>Create a stage #B into which you copy only non-secret artefacts from stage #A</strong>, such as a compiled application.</li><li><strong>Only publish/push the stage #B image</strong></li></ul>



<h3 id="b-buildkit-secrets">B. BuildKit secrets</h3>



<div data-id="29ab26"><p>Background info</p><p>If you use <code>docker build</code> for building, there are multiple <em>backends</em> that actually perform the build. The newer and faster backend is BuildKit, which you need to be explicitly enable on <em>Linux</em> by setting the environment variable <code>DOCKER_BUILDKIT=1</code>. Note that BuildKit is enabled by default on Docker for Desktop on Windows/macOS.</p></div>



<p>As explained in the <a href="https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information" target="_blank" rel="noreferrer noopener">docs here</a> (read them for more details), the BuildKit build engine supports additional syntax in the <code>Dockerfile</code>. <strong>To use a build secret, put something like this in your <code>Dockerfile</code>:</strong></p>



<p><code>RUN <strong>--mount=type=secret,id=mysecret,dst=/foobar</strong> &lt;command to run&gt;</code></p>



<p><strong>This makes secrets available to the build container while that <code>RUN</code> statement is executed, but does <em>not</em> put the secret itself</strong> (here: the <code>/foobar</code> folder) <strong>into the built image</strong>. <strong>You need to specify the path to the secret’s <em>source</em> file/folder (located on the host) when running the <code>docker build</code> command</strong>, e.g.</p>



<p>There is one caveat, however: <strong>you cannot build images that require secrets via <code>docker-compose up --build</code></strong>, because Docker-compose does not support the <code>--secret</code> argument for building yet, see <a href="https://github.com/docker/compose/issues/6358" target="_blank" rel="noreferrer noopener">GitHub issue</a>. If you rely on docker-compose builds to work, use approach 1 (Multi-stage builds) instead.</p>



<div data-id="67dd90"><p>Side note: do not push images built on a development machine</p><div><p>You should always build and push images in a <em>clean</em> environment, e.g. a CI/CD pipeline, where the build agent clones your repository into a <em>new</em> directory.</p><p>The problem with using your <em>local development machine</em> for building is that your local “working tree” of the Git repository might be <em>dirty</em>. For instance, it might contain files with secrets that you need during development, e.g. access keys to staging or even production servers. If these files are not excluded via <code>.dockerignore</code>, a statement such as “<code>COPY . .</code>” in your <code>Dockerfile</code> could accidentally lead to leaking these secrets into the final image.</p></div></div>



<h2 id="2-run-as-non-root-user">2. Run as non-root user</h2>



<p>By default, when someones runs your image via “<code>docker run &lt;more arguments&gt; yourImage:yourTag</code>“, the container (and the programs you have in your <code>ENTRYPOINT</code> / <code>CMD</code>) runs as <code>root</code> user (in the container and on the host). This gives an attacker, who gained shell access in your running container using some exploit, the following powers:</p>



<ul><li><em>Unrestricted</em> write-access (due to being <code>root</code>) to all those directories on the host that are explicitly mounted into the container.</li><li>Ability to do everything in the container that a Linux root user can do. For instance, an attacker could install additional tools they need to load even more malware, e.g. via <code>apt-get install</code> (a non-root user could not do this).</li><li><em>If</em> the container of your image was started with <code>docker run <strong>--privileged</strong></code>, the attacker can even take over the entire <em>host</em>.</li></ul>



<p>To avoid this, <strong>you should run your application as non-root user</strong>, that is, some user that you created during the <code>docker build</code> process. <strong>Place the following statements in your <code>Dockerfile</code> somewhere (usually towards the end):</strong></p>


<pre aria-describedby="shcb-language-1" data-shcb-language-name="Dockerfile" data-shcb-language-slug="dockerfile">

<p><code>
<span>RUN</span><span> useradd --create-home appuser</span>

<span>USER</span> appuser</code></p><small id="shcb-language-1"><span>Code language:</span> <span>Dockerfile</span> <span>(</span><span>dockerfile</span><span>)</span></small></pre>


<p><strong>All commands in the <code>Dockerfile</code> that come <em>after</em> the </strong><code><strong><em>USER appuser</em></strong></code><strong> statement</strong> (e.g. <code>RUN</code>, <code>CMD</code>, or <code>ENTRYPOINT</code>) <strong>will be run with this user. There are a few caveats to be aware of:</strong></p>



<ul><li><strong>Files you copied into your image via <code>COPY</code></strong> (or files created by some <code>RUN</code> commands) <strong><em>before</em> switching to the non-root user are owned by <code>root</code>, and are consequently not <em>writable</em> by your application running as non-root.</strong> To fix this problem, move the code that creates and switches to the non-root user closer to the beginning of the <code>Dockerfile</code>.</li><li><strong>Files that your program expects to be somewhere in the user’s <em>home</em> directory (e.g. <code>~/.cache</code>) might now suddenly be missing from your app’s perspective</strong>, if these files were created at the beginning of the <code>Dockerfile</code>, as <code>root</code> user (being stored below <code>/root/</code> and not below <code>/home/appuser/</code>).</li><li><strong>If your application listens to a TCP/UDP port, your app must use ports &gt; 1024</strong>. Ports &lt;= 1024 can only be used either as <code>root</code> user, or with high Linux capabilities, which you should not give to your container just for that purpose.</li></ul>



<h2 id="3-use-the-latest-base-image-build-update-system-packages">3. Use the latest base image build &amp; update system packages</h2>



<p><strong>If you are using a base image</strong> that contains the entire toolset of a real Linux distribution (such as Debian, Ubuntu or alpine images),<strong> including a <em>package manager</em>, it is recommended to use that package manager to install all available package updates.</strong></p>



<div data-id="a9ded1"><p>Background</p><p>Base images are maintained by someone who configured scheduled CI/CD pipelines that build the base image and push it to Docker Hub in regular intervals. You have no control over this interval, and it often happens that security patches are available in the Linux distro’s <em>package registry</em> (e.g. via <code>apt</code>) <em>before</em> that pipeline pushes an updated Docker image to Docker Hub. For instance, even if a base image is pushed once per <em>week</em>, it could still happen that security updates are available a few <em>hours</em> or days after the most recent image was published.</p></div>



<p><strong>Therefore, it’s a good idea to always run package manager commands that update the local package database and install updates, in <em>unattended mode</em></strong>, which does not require user confirmation. <strong>The command differs for each Linux distribution.</strong></p>



<p>For instance, <strong>for Ubuntu, Debian, or derivative distros</strong>, use <strong><code>RUN apt-get update &amp;&amp; apt-get -y upgrade</code></strong></p>



<p><strong>Another important detail is that you need to tell Docker</strong> (or whatever image build tool you use) <strong>to refresh the base image</strong>. Otherwise, <strong>if you reference a base image such as <code>python:3</code> (and Docker already has such a image in its <em>local</em> image cache), Docker won’t even check whether a newer version of <code>python:3</code> exists on Docker Hub. To get rid of this behavior, you should use this command:</strong></p>



<p><code>docker build <strong>--pull</strong> &lt;rest of the build command&gt;</code></p>



<p><strong>This makes sure that Docker will pull updates of the image(s) mentioned in the <code>FROM</code> statement(s) of your <code>Dockerfile</code>, prior to building your image.</strong></p>



<p><strong>You should also be aware of Docker’s <em>layer caching</em> mechanism, which causes your image to become stale, because the layer for the <code>RUN &lt;install apt/etc. updates&gt;</code> command is cached, until the base image maintainer releases a new version of the base image. If you find out that the release frequency of base image is rather low</strong> (e.g. less often than a week), <strong>it is a good idea to regularly</strong> (e.g. once per week) <strong>rebuild your image with disabled layer caching. You can do so by running the following command:</strong></p>



<p><code>docker build --pull <strong>--no-cache</strong> &lt;rest of the build command&gt;</code></p>



<h2 id="4-regularly-update-third-party-dependencies">4. Regularly update third party dependencies</h2>



<p>The <strong>software you write is based on <em>third party dependencies</em></strong>, meaning software made by other people. This includes:</p>



<ul><li>The base Docker image your image is based on, or</li><li>Third party software components you use as part of your application, e.g. installed via <code>pip/npm/gradle/apt</code>/…</li></ul>



<p><strong>Once these dependencies become outdated in your image, this increases the attack surface again, because outdated dependencies often have exploitable security vulnerabilities.</strong></p>



<p><strong>You solve this problem by regularly using SCA tools (Software Composition Analysis), such as <a href="https://docs.renovatebot.com/" rel="noopener">Renovate Bot</a>. These tools (semi-) automatically update your declared third party dependencies to their most recent version</strong>, e.g. in your <code>Dockerfile</code>, Python’s <code>requirements.txt</code>, NPM’s <code>packages.json</code>, etc. You need to design your CI pipelines such that the change made by the SCA tool automatically triggers a re-build of your image.</p>



<p>Such automatically-triggered image rebuilds are particularly useful for projects which are in maintenance-only mode, but where the code shall still be used in production by customers (who expect it to be secure). During the maintenance period, you are no longer developing new features, and no new images would be built, because there are no new commits (made by you) triggering new builds. However, the commits made by the SCA tool do trigger the image builds again.</p>



<p>You can find more details about Renovate bot in my <a href="https://www.augmentedmind.de/2021/07/11/renovate-bot-introduction/" target="_blank" data-type="post" data-id="1807" rel="noreferrer noopener">related blog post</a>.</p>



<h2 id="5-have-your-image-scanned-for-vulnerabilities">5. Have your image scanned for vulnerabilities</h2>



<p><strong>Even if you implemented the above advice, such that your images always use the <em>latest</em> third party dependencies, it can still be <em>insecure</em> (e.g. if a dependency has become abandoned). In this context, “insecure” means that one (or more) of the dependencies have <em>known</em> security vulnerabilities (registered in some CVE database).</strong></p>



<p>For this reason,<strong> there are various tools that you provide your Docker image, and they scan through all contained files to find such vulnerabilities. These tools come in two forms:</strong></p>



<ol><li><strong>CLI tools that you explicitly invoke, e.g. in a CI pipeline</strong>, e.g. <a href="https://aquasecurity.github.io/trivy" target="_blank" rel="noreferrer noopener">Trivy</a> (OSS which is very easy to use in a CI pipeline, see Trivy <a href="https://aquasecurity.github.io/trivy/latest/advanced/integrations/" target="_blank" rel="noreferrer noopener">docs</a>), <a href="https://quay.github.io/clair/" target="_blank" rel="noreferrer noopener">Clair</a> (OSS, but more complex to set up and use than Trivy), or <a href="https://snyk.io" target="_blank" rel="noreferrer noopener">Snyk</a> (integrated into the Docker CLI via “<code>docker scan</code>“, see <a href="https://f.hubspotusercontent10.net/hubfs/1699665/Docker_CLI_Cheat_Sheet_2021-01-12a.pdf" target="_blank" rel="noreferrer noopener">cheat sheet</a>, but there is only a <em>limited</em> free plan!)</li><li><strong>Scanners integrated into the image registry that you push your image into</strong>, e.g. Harbor (which uses Clair or Trivy internally). There are also commercial offerings such as <a href="https://anchore.com/" target="_blank" rel="noreferrer noopener">Anchore</a>.</li></ol>



<p><strong>Because these scanners are generic and try to cover a broad range of package registries, they might not be particularly specialized for the programming language or package registries you use in your project. It can sometimes make sense to investigate which tools your programming language ecosystem offers. For instance, for Python there is the <a href="https://pyup.io/safety/" target="_blank" rel="noreferrer noopener">safety</a> tool which is specialized on Python packages.</strong></p>



<h2 id="6-scan-your-dockerfile-for-violations-against-best-practices">6. Scan your <code>Dockerfile</code> for violations against best practices</h2>



<p><strong>Sometimes problems arise from statements you place in your <code>Dockerfile</code>, which are bad practice (without you realizing it). Use tools such as <a href="https://www.checkov.io/" target="_blank" rel="noreferrer noopener">checkov</a>, <a href="https://github.com/open-policy-agent/conftest" target="_blank" rel="noreferrer noopener">Conftest</a>, <a href="https://github.com/aquasecurity/trivy" target="_blank" rel="noreferrer noopener">trivy</a>, or <a href="https://github.com/hadolint/hadolint" target="_blank" rel="noreferrer noopener">hadolint</a>, which are linters for <code>Dockerfiles</code>.</strong> To make the right choice for the tool, <strong>review </strong>which <strong>default rules/policies</strong> are shipped with it. <strong>For instance, <code>hadolint</code> offers many more rules than <code>checkov</code> or <code>conftest</code>, because it is specialized for <code>Dockerfiles</code>.</strong> The tools also complement each other, therefore it does make sense to run multiple tools, e.g. hadolint and trivy, on your <code>Dockerfiles</code>. <strong>Be prepared, though, that you need to maintain “ignore files” where certain rules are ignored, e.g. due to false positives, or because you are deliberately breaking a rule.</strong></p>



<h2 id="7-use-docker-content-trust-for-docker-hub">7. Use Docker Content Trust for Docker Hub</h2>



<p><strong>To verify that base images you use are really built &amp; pushed by the company behind that image, you can use <em>Docker Content Trust</em> (see <a href="https://docs.docker.com/engine/security/trust/" target="_blank" rel="noreferrer noopener">official docs</a>). Simply set the <code>DOCKER_CONTENT_TRUST</code> environment variable to <code>&#34;1&#34;</code> while running <code>docker build</code>.</strong> The Docker daemon will refuse pulling images that have not been signed by the publisher.</p>



<h2 id="8-scan-your-own-code-for-security-issues">8. Scan your own code for security issues</h2>



<p>Security issues usually arise from issues with <em>other people’s</em> code, that is, popular third party dependencies which are “lucrative” to hack because they are wide-spread. However, <strong>sometimes it is <em>your own</em> code that is to blame. For instance, you might have accidentally implemented SQL inject possibilities, stack overflow bugs, etc.</strong></p>



<p><strong>To find those issues, there are so-called SAST tools (Static Application Security Testing). One the one hand, there are programming-language-specific tools</strong> (which you have to research individually), such as <a href="https://github.com/PyCQA/bandit" target="_blank" rel="noreferrer noopener">bandit</a> for Python, or <a href="https://checkstyle.sourceforge.io/" target="_blank" rel="noreferrer noopener">Checkstyle</a> / <a href="https://spotbugs.github.io/" target="_blank" rel="noreferrer noopener">Spotbugs</a> for Java. <strong>On the other hand there are tool suites (some of which are non-free/commercial) that support <em>multiple</em> programming languages and frameworks, such as <a href="https://www.sonarqube.org/" target="_blank" rel="noreferrer noopener">SonarQube</a></strong> (for which there is also the <a href="https://www.sonarlint.org/" target="_blank" rel="noreferrer noopener">SonarLint</a> IDE plugin). <strong>See <a href="https://owasp.org/www-community/Source_Code_Analysis_Tools" target="_blank" rel="noreferrer noopener">here</a> for a list of SAST tools.</strong></p>



<p><strong>There are two basic approaches for doing security scans in practice:</strong></p>



<ol><li><strong>Continuous (automatic) scanning</strong>: you create a <em>CI job</em> that scans your code on each push. This constantly keeps the security of your code on a high level, but you have to figure out how to ignore false positives (which is a continuous maintenance effort). If you use GitLab, you may also find GitLab’s free <a href="https://docs.gitlab.com/ee/user/application_security/sast/" target="_blank" rel="noreferrer noopener">SAST feature</a> interesting.</li><li><strong>Occasional (manual) scanning</strong>: some security-minded member of your team runs the security check locally, e.g. once per month or before every release, and manually looks over the result.</li></ol>



<h2 id="9-use-docker-slim-to-remove-unnecessary-files">9. Use <code>docker-slim</code> to remove unnecessary files</h2>



<p><strong>The <a href="https://github.com/docker-slim/docker-slim/" target="_blank" rel="noreferrer noopener">docker-slim</a> tool takes large Docker images, runs them temporarily, analyzes which files are really used in the temporary container, and then produces a new, <em>single</em>-layer Docker image where all unused files have been removed. This has two benefits:</strong></p>



<ol><li><strong>The image size is reduced</strong></li><li><strong>The image becomes more secure</strong>, because tools are removed that are not needed (e.g. <code>curl</code>, or the package manager)</li></ol>



<p><strong>Please refer to the <a href="https://www.augmentedmind.de/2022/02/06/optimize-docker-image-size/#use-the-docker-slim-tool" target="_blank" rel="noreferrer noopener"><em>Docker slim</em> section</a> in my previous article for further details.</strong></p>



<h2 id="10-use-minimal-base-images">10. Use <em>minimal</em> base images</h2>



<p>The more software (e.g. CLI tools, etc.) is stored in an image, the larger the attack surface becomes. It’s good practice to use “minimal” images, which are as <em>small</em> in size as possible (which is a good advantage anyway), and contain as few tools as possible. <strong>Minimal images go even beyond what “size-optimized” images (such as <code><a href="https://hub.docker.com/_/alpine" rel="noopener">alpine</a></code> or <code>&lt;something&gt;:&lt;version&gt;-slim</code>, e.g. <code>python:3.8-slim</code>) do: they come without any package manager. This makes it hard for an attacker to load additional tools.</strong></p>



<p><strong>The most secure minimal base image is <a href="https://hub.docker.com/_/scratch" target="_blank" rel="noreferrer noopener"><code>SCRATCH</code></a>, which contains absolutely nothing.</strong> Starting your <code>Dockerfile</code> with <strong><code>FROM SCRATCH</code></strong> is only feasible if you are placing self-contained binaries in the image, that have all dependencies (including C-runtimes) baked in.</p>



<p><strong>If <code>SCRATCH</code> does not work for you, Google’s <a href="https://github.com/GoogleContainerTools/distroless" target="_blank" rel="noreferrer noopener">distroless image</a> can be a good alternative, especially if you are building applications for common programming languages, such as Python or Node.js, or need a minimal base image of <em>Debian</em>.</strong></p>



<p><strong>Unfortunately, minimal images have several caveats to be aware of:</strong></p>



<ul><li><strong>Caveats of <a href="https://github.com/GoogleContainerTools/distroless" target="_blank" rel="noreferrer noopener">distroless</a>:</strong><ul><li>Using the programming-language-specific images published by Google on <code><a href="http://gcr.io" rel="noopener">gcr.io</a></code> is <em>not</em> recommended, because there is only a <code>latest</code> version tag, as well as tags for <em>major</em> versions (e.g. “3” for python, or “12” for Node). You have no control over the specific language run-time versions (e.g. whether Python 3.8.3 or 3.8.4 etc. is used), which breaks the reproducibility of your image builds.</li><li>Customizing (and building your own) distroless images is quite involved: you need to get acquainted with the Bazel build system and build the images yourself<ul><li>Note: if the only customization you need is to run code as <em>non-root</em> user, there is a <code>nonroot</code> user by default in every distroless base image, see <a href="https://github.com/GoogleContainerTools/distroless/issues/235" target="_blank" rel="noreferrer noopener">here</a> for details.</li></ul></li></ul></li><li><strong>Caveats of minimal base images in general:</strong><ul><li>Debugging containers using your minimal base images is tricky, because useful tools (such as <code>/bin/sh</code>) are now missing<ul><li>For Docker, you can run a second debugging-container (that does have a shell and debugging tools, e.g. <code>alpine:latest</code>) and make it share the <em>PID namespace</em> of your minimal container, e.g. via <code>docker run -it --rm --pid=container:&lt;minimal-container-id&gt; --cap-add SYS_PTRACE alpine sh</code></li><li>For Kubernetes, you can use <em>ephemeral containers</em>, see e.g. <a href="https://loft.sh/blog/using-kubernetes-ephemeral-containers-for-troubleshooting/" target="_blank" rel="noreferrer noopener">here</a></li></ul></li></ul></li></ul>



<h2 id="11-use-trusted-base-images">11. Use <em>trusted</em> base images</h2>



<p><strong>A <em>trusted</em> image is one that has been <em>audited</em> by someone (either your own organization, or someone else), e.g. with a security level. This can be particularly important to regulated industries </strong>(banking, aerospace, etc.) <strong>with high security requirements and regulations.</strong></p>



<p>While the auditing could be done by yourself, by building trusted images yourself from scratch, this is discouraged, because you, the image builder, has to ensure that all auditing-related tasks are done and properly documented (e.g. documenting the list of packages in the image, executed CVE-checks and their results, etc.). This is a lot of work. Instead, <strong>it is recommended to outsource this task, using <em>commercial</em> “trusted registries”, which offer a selected set of trusted images, e.g. <a href="https://developers.redhat.com/products/rhel/ubi" target="_blank" rel="noreferrer noopener">RedHat’s Universal Base Images</a> (UBI). RedHat’s UBIs are now also available on Docker Hub for free.</strong></p>



<div data-id="a9ded1"><p>Background</p><div><p>Images hosted on Docker Hub are not audited. They are provided “as-is”. They might be insecure (even contain malware), and no one will notify you about it. Using an insecure base images from Docker Hub images will therefore also make <em>your</em> image insecure.</p><p>Also, you should not confuse auditing with Docker’s <em>content trust</em>, mentioned above! Content trust only confirms the identity of the source (the image uploader), and does not state any facts about the image security.</p></div></div>



<h2 id="12-test-whether-your-image-works-with-reduced-capabilities">12. Test whether your image works with reduced <em>capabilities</em></h2>



<p><strong>Linux <em>capabilities</em> are a Linux kernel feature that allow you to control which kernel features an application may use. Examples are whether a process may send signals</strong> (e.g. <code>SIGKILL</code>), <strong>configure network interfaces, mount a disk, or debug processes. See <a href="https://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noreferrer noopener">here</a> for the complete list. In general, the fewer capabilities your application needs, the better.</strong></p>



<p><strong>Anyone who starts a container of your image can give (or take away) these capabilities</strong>, e.g. with a call such as “<code>docker run <strong>--cap-drop=ALL</strong> &lt;image&gt;</code>“. <strong>By default, Docker drops all capabilities except for those <a href="https://github.com/moby/moby/blob/master/oci/caps/defaults.go#L6-L19" target="_blank" rel="noreferrer noopener">defined here</a>. Your application might not need all of them.</strong></p>



<p><strong>As a best practice, try starting a container of your image, dropping <em>all</em> capabilities</strong> (using <code><strong>--cap-drop=ALL</strong></code>) <strong>and see whether it still works. If it does not, figure which capabilities are missing, whether you really need them, and if you do, document which capabilities your image needs (and why), which increases trust with whoever runs your image.</strong></p>



<h2 id="conclusion">Conclusion</h2>



<p>Making your image secure is no walk in the park. It takes time to evaluate and implement each practice. The list in this article should save you time, because it already did the work of collecting and prioritizing the necessary steps.</p>



<p>Fortunately, securing your application is an <em>iterative</em> process. You can start small, and implement one step at a time. You do need buy-in from management, though. This is sometimes tricky, especially if your manager is resistant to advice, and if they tend to extrapolate from past experiences (<em>“we, or our customers, have never been hacked before, so why should this happen to us now? We need features instead!”</em>). There are several options you have to convince your manager to allocate resources to security. For instance, if you have a direct channel to your customers (for which you build the software), convince <em>them</em> that they need security, so that they ask for security as a “feature”. Alternatively, find reports of security breaches in your industry (e.g. where a direct competitor was affected), to demonstrate that hacking attacks <em>do</em> actually happen, even in your industry, and that they have severe (financial) repercussions.</p>



<p><strong>Do you know any further tips for strengthening the image security? Let me know in the comments!</strong></p>
		</div></div>
  </body>
</html>
