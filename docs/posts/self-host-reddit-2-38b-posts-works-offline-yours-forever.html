<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/19-84/redd-archiver">Original</a>
    <h1>Show HN: Self-host Reddit ‚Äì 2.38B posts, works offline, yours forever</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="http://unlicense.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/f56402b65984387744b74789a0f5878c88867bccd32059aff5f72a9df726c441/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d556e6c6963656e73652d626c75652e737667" alt="License: Unlicense" data-canonical-src="https://img.shields.io/badge/license-Unlicense-blue.svg"/></a>
<a href="https://www.python.org/downloads/" rel="nofollow"><img src="https://camo.githubusercontent.com/b413597d37ccc8eae784ee4f9979e61fe739bbdcd0f6247e4aa0d68c6f1659ca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e372b2d626c75652e737667" alt="Python 3.7+" data-canonical-src="https://img.shields.io/badge/python-3.7+-blue.svg"/></a>
<a href="https://www.postgresql.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/dddcfe8d0d1074a2f5d1e5beed134242fa669f7256804926cc28c472ff8437fa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506f737467726553514c2d72657175697265642d626c75652e737667" alt="PostgreSQL Required" data-canonical-src="https://img.shields.io/badge/PostgreSQL-required-blue.svg"/></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/9b8a63eb5a126d3f3cbb0562344d18b70c87ad94abe2d66bbf324e05c489cfb2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d312e302e302d627269676874677265656e2e737667" alt="Version 1.0.0" data-canonical-src="https://img.shields.io/badge/version-1.0.0-brightgreen.svg"/></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/e8843ce331d1dd0e934d491d5309eab745b9546e838c9566ba718290ab52827e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d526564646974253230253743253230566f61742532302537432532305275717175732d6f72616e67652e737667" alt="Multi-Platform" data-canonical-src="https://img.shields.io/badge/platforms-Reddit%20%7C%20Voat%20%7C%20Ruqqus-orange.svg"/></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/2fa061a2680c6ce892ccf3da22b0f52b9a8c9cad6c540e665572176ad8051b07/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d43502d3239253230746f6f6c732d707572706c652e737667" alt="MCP Server" data-canonical-src="https://img.shields.io/badge/MCP-29%20tools-purple.svg"/></a></p>
<p dir="auto">Transform compressed data dumps into browsable HTML archives with flexible deployment options. Redd-Archiver supports offline browsing via sorted index pages OR full-text search with Docker deployment. Features mobile-first design, multi-platform support, and enterprise-grade performance with PostgreSQL full-text indexing.</p>
<p dir="auto"><strong>Supported Platforms</strong>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>Status</th>
<th>Available Posts</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines (Pushshift)</td>
<td>‚úÖ Full support</td>
<td>2.38B posts (40,029 subreddits, through Dec 31 2024)</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td>‚úÖ Full support</td>
<td>3.81M posts, 24.1M comments (22,637 subverses, complete archive)</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td>‚úÖ Full support</td>
<td>500K posts (6,217 guilds, complete archive)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><em>Tracked content: <strong>2.384 billion posts across 68,883 communities</strong> (Reddit full Pushshift dataset through Dec 31 2024, Voat/Ruqqus complete archives)</em></p>
<p dir="auto"><strong>Version 1.0</strong> features multi-platform archiving, REST API with 30+ endpoints, MCP server for AI integration, and PostgreSQL-backed architecture for large-scale processing.</p>

<p dir="auto"><strong>Try the live demo:</strong> <a href="https://online-archives.github.io/redd-archiver-example/" rel="nofollow">Browse Example Archive ‚Üí</a></p>
<p dir="auto"><strong>New to Redd-Archiver? Start here:</strong> <a href="https://github.com/19-84/redd-archiver/blob/main/QUICKSTART.md">QUICKSTART.md</a></p>
<p dir="auto">Get running in 2-15 minutes with our step-by-step guide covering:</p>
<ul dir="auto">
<li>Local testing (5 minutes)</li>
<li>Tor homelab deployment (2 minutes) - no domain or port forwarding needed!</li>
<li>Production HTTPS (15 minutes)</li>
<li>Example data testing</li>
</ul>
<hr/>

<div dir="auto"><h3 tabindex="-1" dir="auto">üåê Multi-Platform Support</h3><a id="user-content--multi-platform-support" aria-label="Permalink: üåê Multi-Platform Support" href="#-multi-platform-support"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Archive content from multiple link aggregator platforms in a single unified archive:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>CLI Flag</th>
<th>URL Prefix</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines</td>
<td><code>--subreddit</code></td>
<td><code>/r/</code></td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td><code>--subverse</code></td>
<td><code>/v/</code></td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td><code>--guild</code></td>
<td><code>/g/</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li><strong>Automatic Detection</strong>: Platform auto-detected from file extensions</li>
<li><strong>Unified Search</strong>: PostgreSQL FTS searches across all platforms</li>
<li><strong>Mixed Archives</strong>: Combine Reddit, Voat, and Ruqqus in single archive</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">ü§ñ MCP Server (AI Integration)</h3><a id="user-content--mcp-server-ai-integration" aria-label="Permalink: ü§ñ MCP Server (AI Integration)" href="#-mcp-server-ai-integration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">29 MCP tools auto-generated from OpenAPI for AI assistants:</p>
<ul dir="auto">
<li><strong>Full Archive Access</strong>: Query posts, comments, users, search via Claude Desktop or Claude Code</li>
<li><strong>Token Overflow Prevention</strong>: Built-in LLM guidance with field selection and truncation</li>
<li><strong>5 MCP Resources</strong>: Instant access to stats, top posts, subreddits, search help</li>
<li><strong>Claude Code Ready</strong>: Copy-paste configuration for immediate use</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &#34;mcpServers&#34;: {
    &#34;reddarchiver&#34;: {
      &#34;command&#34;: &#34;uv&#34;,
      &#34;args&#34;: [&#34;--directory&#34;, &#34;/path/to/mcp_server&#34;, &#34;run&#34;, &#34;python&#34;, &#34;server.py&#34;],
      &#34;env&#34;: { &#34;REDDARCHIVER_API_URL&#34;: &#34;http://localhost:5000&#34; }
    }
  }
}"><pre>{
  <span>&#34;mcpServers&#34;</span>: {
    <span>&#34;reddarchiver&#34;</span>: {
      <span>&#34;command&#34;</span>: <span><span>&#34;</span>uv<span>&#34;</span></span>,
      <span>&#34;args&#34;</span>: [<span><span>&#34;</span>--directory<span>&#34;</span></span>, <span><span>&#34;</span>/path/to/mcp_server<span>&#34;</span></span>, <span><span>&#34;</span>run<span>&#34;</span></span>, <span><span>&#34;</span>python<span>&#34;</span></span>, <span><span>&#34;</span>server.py<span>&#34;</span></span>],
      <span>&#34;env&#34;</span>: { <span>&#34;REDDARCHIVER_API_URL&#34;</span>: <span><span>&#34;</span>http://localhost:5000<span>&#34;</span></span> }
    }
  }
}</pre></div>
<p dir="auto">See <a href="https://github.com/19-84/redd-archiver/blob/main/mcp_server/README.md">MCP Server Documentation</a> for complete setup guide.</p>

<ul dir="auto">
<li><strong>üì± Mobile-First Design</strong>: Responsive layout optimized for all devices with touch-friendly navigation</li>
<li><strong>üîç Advanced Search System (Server Required)</strong>: PostgreSQL full-text search optimized for Tor network. Search by keywords, subreddit, author, date, score. <em>Requires Docker deployment - offline browsing uses sorted index pages.</em></li>
<li><strong>‚ö° JavaScript Free</strong>: Complete functionality without JS, pure CSS interactions</li>
<li><strong>üé® Theme Support</strong>: Built-in light/dark theme toggle with CSS-only implementation</li>
<li><strong>‚ôø Accessibility</strong>: WCAG compliant with keyboard navigation and screen reader support</li>
<li><strong>üöÑ Performance</strong>: Optimized CSS (29KB), designed for low-bandwidth networks</li>
</ul>

<ul dir="auto">
<li><strong>üèóÔ∏è Modular Architecture</strong>: 18 specialized modules for maintainability and extensibility</li>
<li><strong>üóÑÔ∏è PostgreSQL Backend</strong>: Large-scale processing with constant memory usage regardless of dataset size</li>
<li><strong>‚ö° Lightning-Fast Search</strong>: PostgreSQL full-text search with GIN indexing</li>
<li><strong>üåê REST API v1</strong>: 30+ endpoints with MCP/AI optimization for programmatic access to posts, comments, users, statistics, search, aggregations, and exports</li>
<li><strong>üßÖ Tor-Optimized</strong>: Zero JavaScript, server-side search, no external dependencies</li>
<li><strong>üìä Rich Statistics</strong>: Comprehensive analytics dashboard with file size tracking</li>
<li><strong>üîó SEO Optimized</strong>: Complete meta tags, XML sitemaps, and structured data</li>
<li><strong>üíæ Streaming Processing</strong>: Memory-efficient with automatic resume capability</li>
<li><strong>üìà Progress Tracking</strong>: Real-time transfer rates, ETAs, and database metrics</li>
<li><strong>üèÜ Instance Registry</strong>: Leaderboard system with completeness-weighted scoring for distributed archives</li>
</ul>

<ul dir="auto">
<li><strong>üè† Local/Homelab</strong>: HTTP on localhost or LAN (2 commands)</li>
<li><strong>üåê Production HTTPS</strong>: Automated Let&#39;s Encrypt setup (5 minutes)</li>
<li><strong>üßÖ Tor Hidden Service</strong>: .onion access, zero networking config (2 minutes)</li>
<li><strong>üîÄ Dual-Mode</strong>: HTTPS + Tor simultaneously</li>
<li><strong>üìÑ Static Hosting</strong>: GitHub/Codeberg Pages for small archives (browse-only, no search)</li>
</ul>

<p dir="auto">Redd-Archiver generates static HTML files that can be browsed offline OR deployed with full-text search:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Mode</th>
<th>Search</th>
<th>Server</th>
<th>Setup Time</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Offline Browsing</strong></td>
<td>‚ùå Browse-only</td>
<td>None</td>
<td>0 min</td>
<td>USB drives, local archives, offline research</td>
</tr>
<tr>
<td><strong>Static Hosting</strong></td>
<td>‚ùå Browse-only</td>
<td>GitHub/Codeberg Pages</td>
<td>10 min</td>
<td>Free public hosting (size limits)</td>
</tr>
<tr>
<td><strong>Docker Local</strong></td>
<td>‚úÖ PostgreSQL FTS</td>
<td>localhost</td>
<td>5 min</td>
<td>Development, testing</td>
</tr>
<tr>
<td><strong>Docker + Tor</strong></td>
<td>‚úÖ PostgreSQL FTS</td>
<td>.onion hidden service</td>
<td>2 min</td>
<td>Private sharing, no port forwarding</td>
</tr>
<tr>
<td><strong>Docker + HTTPS</strong></td>
<td>‚úÖ PostgreSQL FTS</td>
<td>Public domain</td>
<td>15 min</td>
<td>Production public archives</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Offline Browsing Features</strong>:</p>
<ul dir="auto">
<li>Sorted index pages (by score, comments, date)</li>
<li>Pagination for large subreddits</li>
<li>Full comment threads and user pages</li>
<li>Works by opening HTML files directly</li>
</ul>
<p dir="auto"><strong>With Search Server</strong>:</p>
<ul dir="auto">
<li>PostgreSQL full-text search with GIN indexing</li>
<li>Search by keywords, subreddit, author, date, score</li>
<li>Sub-second results, Tor-compatible</li>
<li>Requires Docker deployment</li>
</ul>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">üö® Get Involved: Help Preserve Internet History</h2><a id="user-content--get-involved-help-preserve-internet-history" aria-label="Permalink: üö® Get Involved: Help Preserve Internet History" href="#-get-involved-help-preserve-internet-history"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Internet content disappears every day. Communities get banned, platforms shut down, and valuable discussions vanish. <strong>You can help prevent this.</strong></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">üì• Download &amp; Mirror Data Now</h3><a id="user-content--download--mirror-data-now" aria-label="Permalink: üì• Download &amp; Mirror Data Now" href="#-download--mirror-data-now"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Don&#39;t wait for content to disappear.</strong> Download these datasets today:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Size</th>
<th>Posts</th>
<th>Download</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>3.28TB</td>
<td>2.38B posts</td>
<td><a href="https://academictorrents.com/details/1614740ac8c94505e4ecb9d88be8bed7b6afddd4" rel="nofollow">Academic Torrents</a> ¬∑ Magnet Link</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>~15GB</td>
<td>3.8M posts</td>
<td><a href="https://archive.org/details/voat-archive-2021" rel="nofollow">Archive.org</a> ‚Ä†</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>~752MB</td>
<td>500K posts</td>
<td><a href="https://archive.org/details/ruqqus-archive-2021" rel="nofollow">Archive.org</a> ‚Ä°</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">‚Ä† <strong>Voat Performance Tip</strong>: Use <a href="https://github.com/19-84/redd-archiver/blob/main/tools/README_VOAT_SPLITTER.md">pre-split files</a> for 1000x faster imports (2-5 min vs 30+ min per subverse)
‚Ä° <strong>Ruqqus</strong>: Docker image includes p7zip for automatic .7z decompression</p>
<p dir="auto"><strong>Every mirror matters.</strong> Store locally, seed torrents, share with researchers. Be part of the preservation network.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">üåê Join the Registry: Deploy Your Instance</h3><a id="user-content--join-the-registry-deploy-your-instance" aria-label="Permalink: üåê Join the Registry: Deploy Your Instance" href="#-join-the-registry-deploy-your-instance"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Already running an archive?</strong> Register it on our public leaderboard:</p>
<ol dir="auto">
<li>Deploy your instance (<a href="https://github.com/19-84/redd-archiver/blob/main/QUICKSTART.md">Quick Start</a> - 2-15 minutes)</li>
<li>Submit via <a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/register-instance.yml">Registry Template</a></li>
<li>Join coordinated preservation efforts with other teams</li>
</ol>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li>Public visibility and traffic</li>
<li>Coordinated archiving to avoid duplication</li>
<li>Team collaboration opportunities</li>
<li>Leaderboard recognition</li>
</ul>
<p dir="auto">üëâ <strong><a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/register-instance.yml">Register Your Instance Now ‚Üí</a></strong></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">üÜï Submit New Data Sources</h3><a id="user-content--submit-new-data-sources" aria-label="Permalink: üÜï Submit New Data Sources" href="#-submit-new-data-sources"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Found a new platform dataset?</strong> Help expand the archive network:</p>
<ul dir="auto">
<li>Lemmy databases</li>
<li>Hacker News archives</li>
<li>Alternative Reddit archives</li>
<li>Other link aggregator platforms</li>
</ul>
<p dir="auto">üëâ <strong><a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/submit-data-source.yml">Submit Data Source ‚Üí</a></strong></p>
<p dir="auto"><strong>Why submit?</strong></p>
<ul dir="auto">
<li>Makes data discoverable for other archivists</li>
<li>Prevents duplicate preservation efforts</li>
<li>Builds comprehensive multi-platform archive ecosystem</li>
<li>Tracks data availability before platforms disappear</li>
</ul>
<hr/>


<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/01-dashboard.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/01-dashboard.png" alt="Dashboard"/></a></p>
<p dir="auto">Main landing page showing archive overview with statistics for 9,592 posts across Reddit, Voat, and Ruqqus. Features customizable branding (site name, project URL), responsive cards, activity metrics, and content statistics. <em>(Works offline)</em></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/02-subreddit-index.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/02-subreddit-index.png" alt="Subreddit Index"/></a></p>
<p dir="auto">Post listing with sorting options (score, comments, date), pagination, and badge coloring. Includes navigation and theme toggle. <em>(Works offline - sorted by score/comments/date)</em></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/03-post-page.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/03-post-page.png" alt="Post Page"/></a></p>
<p dir="auto">Individual post displaying nested comment threads with collapsible UI, user flair, and timestamps. Comments include anchor links for direct navigation from user pages. <em>(Works offline)</em></p>

<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/05-mobile-dashboard.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/05-mobile-dashboard.png" width="375" alt="Mobile Dashboard"/></a>
</p>
<p dir="auto">Fully optimized for mobile devices with touch-friendly navigation and responsive layout.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/07-search-form.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/07-search-form.png" alt="Search Form"/></a></p>
<p dir="auto">PostgreSQL full-text search with Google-style operators. Supports filtering by subreddit, author, date range, and score. <em>(Requires Docker deployment)</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/08-search-results.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/08-search-results.png" alt="Search Results"/></a></p>
<p dir="auto">Search results with highlighted excerpts using PostgreSQL <code>ts_headline()</code>. Sub-second response times with GIN indexing. <em>(Server-based, Tor-compatible)</em></p>
<blockquote>
<p dir="auto"><strong>Sample Archive</strong>: Multi-platform archive featuring programming and technology communities from Reddit, Voat, and Ruqqus ¬∑ <a href="https://github.com/19-84/redd-archiver/blob/main/screenshots">See all screenshots ‚Üí</a></p>
</blockquote>


<ul dir="auto">
<li><strong>Python 3.7 or higher</strong></li>
<li><strong>PostgreSQL 12+</strong> (required for v1.0+)</li>
<li>4GB+ RAM (PostgreSQL uses constant memory)</li>
<li>Disk space: ~1.5-2x your input .zst file size for PostgreSQL database</li>
</ul>

<p dir="auto">Redd-Archiver uses modern, performance-focused dependencies:</p>
<p dir="auto"><strong>Core:</strong></p>
<ul dir="auto">
<li><code>psycopg[binary,pool]==3.2.3</code> - PostgreSQL adapter with connection pooling</li>
<li><code>zstandard==0.23.0</code> - Fast .zst decompression</li>
<li><code>psutil==6.1.1</code> - System resource monitoring</li>
</ul>
<p dir="auto"><strong>HTML Generation:</strong></p>
<ul dir="auto">
<li><code>jinja2&gt;=3.1.6</code> - Modern template engine with inheritance</li>
<li><code>rcssmin&gt;=1.1.2</code> - CSS minification for smaller file sizes</li>
</ul>
<p dir="auto"><strong>Performance:</strong></p>
<ul dir="auto">
<li><code>orjson&gt;=3.11.4</code> - Fast JSON parsing</li>
</ul>

<div dir="auto"><h4 tabindex="-1" dir="auto">Option 1: Docker (Recommended)</h4><a id="user-content-option-1-docker-recommended" aria-label="Permalink: Option 1: Docker (Recommended)" href="#option-1-docker-recommended"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/19-84/redd-archiver.git
cd redd-archiver

# Create required directories
mkdir -p data output logs tor-public

# Copy environment template and configure
cp .env.example .env
# Edit .env with your settings (change default passwords!)

# Start PostgreSQL container
docker-compose up -d

# Install Python dependencies
pip install -r requirements.txt

# Configure database connection
export DATABASE_URL=&#34;postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver&#34;

# Run the archive generator
python reddarc.py /path/to/data/ --output my-archive/"><pre>git clone https://github.com/19-84/redd-archiver.git
<span>cd</span> redd-archiver

<span><span>#</span> Create required directories</span>
mkdir -p data output logs tor-public

<span><span>#</span> Copy environment template and configure</span>
cp .env.example .env
<span><span>#</span> Edit .env with your settings (change default passwords!)</span>

<span><span>#</span> Start PostgreSQL container</span>
docker-compose up -d

<span><span>#</span> Install Python dependencies</span>
pip install -r requirements.txt

<span><span>#</span> Configure database connection</span>
<span>export</span> DATABASE_URL=<span><span>&#34;</span>postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver<span>&#34;</span></span>

<span><span>#</span> Run the archive generator</span>
python reddarc.py /path/to/data/ --output my-archive/</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Option 2: Local PostgreSQL</h4><a id="user-content-option-2-local-postgresql" aria-label="Permalink: Option 2: Local PostgreSQL" href="#option-2-local-postgresql"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/19-84/redd-archiver.git
cd redd-archiver

# Install PostgreSQL (Ubuntu/Debian)
sudo apt update &amp;&amp; sudo apt install postgresql postgresql-contrib

# Or on macOS
brew install postgresql@16 &amp;&amp; brew services start postgresql@16

# Create database
sudo -u postgres createuser redd-archiver
sudo -u postgres createdb -O redd-archiver redd-archiver
sudo -u postgres psql -c &#34;ALTER USER redd-archiver WITH PASSWORD &#39;your_password_here&#39;;&#34;

# Install Python dependencies
pip install -r requirements.txt

# Configure database connection
export DATABASE_URL=&#34;postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver&#34;

# Run the archive generator
python reddarc.py /path/to/data/ --output my-archive/"><pre>git clone https://github.com/19-84/redd-archiver.git
<span>cd</span> redd-archiver

<span><span>#</span> Install PostgreSQL (Ubuntu/Debian)</span>
sudo apt update <span>&amp;&amp;</span> sudo apt install postgresql postgresql-contrib

<span><span>#</span> Or on macOS</span>
brew install postgresql@16 <span>&amp;&amp;</span> brew services start postgresql@16

<span><span>#</span> Create database</span>
sudo -u postgres createuser redd-archiver
sudo -u postgres createdb -O redd-archiver redd-archiver
sudo -u postgres psql -c <span><span>&#34;</span>ALTER USER redd-archiver WITH PASSWORD &#39;your_password_here&#39;;<span>&#34;</span></span>

<span><span>#</span> Install Python dependencies</span>
pip install -r requirements.txt

<span><span>#</span> Configure database connection</span>
<span>export</span> DATABASE_URL=<span><span>&#34;</span>postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver<span>&#34;</span></span>

<span><span>#</span> Run the archive generator</span>
python reddarc.py /path/to/data/ --output my-archive/</pre></div>

<p dir="auto">Review the CHANGELOG.md for version updates and changes.</p>


<p dir="auto">Redd-Archiver processes data dumps from multiple platforms:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>Data Sources</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines</td>
<td><a href="https://academictorrents.com/details/1614740ac8c94505e4ecb9d88be8bed7b6afddd4" rel="nofollow">Pushshift Complete Dataset</a> ¬∑ Magnet Link ¬∑ 3.28TB ¬∑ 2.38B posts ¬∑ 40K subreddits</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td><a href="https://archive.org/details/voat-archive-2021" rel="nofollow">Voat Archive 2021</a> ¬∑ 22,637 subverses ¬∑ 3.8M posts ¬∑ 24M comments ¬∑ Complete archive</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td><a href="https://archive.org/details/ruqqus-archive-2021" rel="nofollow">Ruqqus Archive 2021</a> ¬∑ 6,217 guilds ¬∑ Complete archive</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><h3 tabindex="-1" dir="auto">2. Identify High-Priority Communities (Optional)</h3><a id="user-content-2-identify-high-priority-communities-optional" aria-label="Permalink: 2. Identify High-Priority Communities (Optional)" href="#2-identify-high-priority-communities-optional"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Scanner Tools</strong> help you identify which communities to archive first based on priority scores:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Scan Reddit data (generates subreddits_complete.json)
python tools/find_banned_subreddits.py /path/to/reddit-data/ --output tools/subreddits_complete.json

# Scan Voat data (generates subverses.json)
python tools/scan_voat_subverses.py /path/to/voat-data/ --output tools/subverses.json

# Scan Ruqqus data (generates guilds.json)
python tools/scan_ruqqus_guilds.py /path/to/ruqqus-data/ --output tools/guilds.json"><pre><span><span>#</span> Scan Reddit data (generates subreddits_complete.json)</span>
python tools/find_banned_subreddits.py /path/to/reddit-data/ --output tools/subreddits_complete.json

<span><span>#</span> Scan Voat data (generates subverses.json)</span>
python tools/scan_voat_subverses.py /path/to/voat-data/ --output tools/subverses.json

<span><span>#</span> Scan Ruqqus data (generates guilds.json)</span>
python tools/scan_ruqqus_guilds.py /path/to/ruqqus-data/ --output tools/guilds.json</pre></div>
<p dir="auto"><strong>What the scanners do</strong>:</p>
<ul dir="auto">
<li>Calculate archive priority scores (0-100) for each community</li>
<li>Track post counts, activity periods, deletion rates, NSFW content</li>
<li>Identify restricted, quarantined, or banned communities (highest priority)</li>
<li>Sort communities by archival importance</li>
</ul>
<p dir="auto"><strong>Example output</strong>:</p>
<ul dir="auto">
<li><strong>Reddit</strong>: 40,029 subreddits from 2.38B posts analyzed</li>
<li><strong>Voat</strong>: 15,545 subverses from 3.81M posts + 24.1M comments analyzed</li>
<li><strong>Ruqqus</strong>: 6,217 guilds from 500K posts analyzed</li>
<li><strong>Status breakdown</strong> (Reddit): 26,552 active, 8,642 restricted, 4,803 inactive, 32 quarantined</li>
</ul>
<p dir="auto"><strong>Use cases</strong>:</p>
<ul dir="auto">
<li><strong>Targeted archiving</strong>: Archive high-risk communities first (restricted, quarantined)</li>
<li><strong>Storage planning</strong>: Identify largest communities before downloading</li>
<li><strong>Historical research</strong>: Find communities with high deletion/removal rates</li>
</ul>
<p dir="auto"><strong>Output files</strong> (included in <code>tools/</code> directory):</p>
<ul dir="auto">
<li><code>subreddits_complete.json</code> - Reddit subreddit statistics (40,029 communities, 46MB)</li>
<li><code>subverses.json</code> - Voat subverse statistics (22,585 communities, 14MB)</li>
<li><code>guilds.json</code> - Ruqqus guild statistics (6,217 communities, 3.6MB)</li>
</ul>
<p dir="auto">View the <a href="https://github.com/19-84/redd-archiver/blob/main/tools/README.md">complete data catalog</a> to browse all communities and their priority scores.</p>

<p dir="auto">Ensure DATABASE_URL is set (see Installation above):</p>
<div dir="auto" data-snippet-clipboard-copy-content="export DATABASE_URL=&#34;postgresql://reddarchiver:password@localhost:5432/reddarchiver&#34;"><pre><span>export</span> DATABASE_URL=<span><span>&#34;</span>postgresql://reddarchiver:password@localhost:5432/reddarchiver<span>&#34;</span></span></pre></div>

<p dir="auto"><strong>Reddit Archives (.zst files):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-discovery (processes all .zst files in directory)
python reddarc.py /path/to/pushshift-data/ --output my-archive/

# Single subreddit
python reddarc.py /data --subreddit privacy \
  --comments-file /data/privacy_comments.zst \
  --submissions-file /data/privacy_submissions.zst \
  --output my-archive/"><pre><span><span>#</span> Auto-discovery (processes all .zst files in directory)</span>
python reddarc.py /path/to/pushshift-data/ --output my-archive/

<span><span>#</span> Single subreddit</span>
python reddarc.py /data --subreddit privacy \
  --comments-file /data/privacy_comments.zst \
  --submissions-file /data/privacy_submissions.zst \
  --output my-archive/</pre></div>
<p dir="auto"><strong>Voat Archives (SQL dumps):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import Voat subverses
python reddarc.py /data --subverse voatdev,pics --output my-archive/ --import-only

# Export HTML after import
python reddarc.py /data --output my-archive/ --export-from-database"><pre><span><span>#</span> Import Voat subverses</span>
python reddarc.py /data --subverse voatdev,pics --output my-archive/ --import-only

<span><span>#</span> Export HTML after import</span>
python reddarc.py /data --output my-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>Ruqqus Archives (.7z files):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import Ruqqus guilds
python reddarc.py /data --guild Quarantine,News --output my-archive/ --import-only

# Export HTML after import
python reddarc.py /data --output my-archive/ --export-from-database"><pre><span><span>#</span> Import Ruqqus guilds</span>
python reddarc.py /data --guild Quarantine,News --output my-archive/ --import-only

<span><span>#</span> Export HTML after import</span>
python reddarc.py /data --output my-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>Multi-Platform Mixed Archive:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import from multiple platforms into single archive
python reddarc.py /reddit-data --subreddit privacy --output unified-archive/ --import-only
python reddarc.py /voat-data --subverse technology --output unified-archive/ --import-only
python reddarc.py /ruqqus-data --guild Tech --output unified-archive/ --import-only

# Generate HTML for all platforms
python reddarc.py /any-path --output unified-archive/ --export-from-database"><pre><span><span>#</span> Import from multiple platforms into single archive</span>
python reddarc.py /reddit-data --subreddit privacy --output unified-archive/ --import-only
python reddarc.py /voat-data --subverse technology --output unified-archive/ --import-only
python reddarc.py /ruqqus-data --guild Tech --output unified-archive/ --import-only

<span><span>#</span> Generate HTML for all platforms</span>
python reddarc.py /any-path --output unified-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>With filtering and SEO:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="python reddarc.py /data/ --output my-archive/ \
  --min-score 100 --min-comments 50 \
  --base-url https://example.com \
  --site-name &#34;My Archive&#34;"><pre>python reddarc.py /data/ --output my-archive/ \
  --min-score 100 --min-comments 50 \
  --base-url https://example.com \
  --site-name <span><span>&#34;</span>My Archive<span>&#34;</span></span></pre></div>
<p dir="auto"><strong>Import/Export workflow (for large datasets):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import data to PostgreSQL (no HTML generation)
python reddarc.py /data/ --output my-archive/ --import-only

# Export HTML from PostgreSQL (no data import)
python reddarc.py /data/ --output my-archive/ --export-from-database"><pre><span><span>#</span> Import data to PostgreSQL (no HTML generation)</span>
python reddarc.py /data/ --output my-archive/ --import-only

<span><span>#</span> Export HTML from PostgreSQL (no data import)</span>
python reddarc.py /data/ --output my-archive/ --export-from-database</pre></div>

<p dir="auto">Multiple deployment options available:</p>
<p dir="auto"><strong>Local/Development</strong> (HTTP):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose up -d
# Access: http://localhost"><pre>docker compose up -d
<span><span>#</span> Access: http://localhost</span></pre></div>
<p dir="auto"><strong>Production HTTPS</strong> (Let&#39;s Encrypt):</p>
<div dir="auto" data-snippet-clipboard-copy-content="./docker/scripts/init-letsencrypt.sh
# Access: https://your-domain.com"><pre>./docker/scripts/init-letsencrypt.sh
<span><span>#</span> Access: https://your-domain.com</span></pre></div>
<p dir="auto"><strong>Homelab/Tor</strong> (.onion hidden service):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose -f docker-compose.yml -f docker-compose.tor-only.yml --profile tor up -d
# Access: http://[your-address].onion (via Tor Browser)
# No port forwarding or domain required!"><pre>docker compose -f docker-compose.yml -f docker-compose.tor-only.yml --profile tor up -d
<span><span>#</span> Access: http://[your-address].onion (via Tor Browser)</span>
<span><span>#</span> No port forwarding or domain required!</span></pre></div>
<p dir="auto"><strong>Dual-Mode</strong> (HTTPS + Tor):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose --profile production --profile tor up -d
# Access: Both https://your-domain.com and http://[address].onion"><pre>docker compose --profile production --profile tor up -d
<span><span>#</span> Access: Both https://your-domain.com and http://[address].onion</span></pre></div>
<p dir="auto"><strong>Static Hosting</strong> (GitHub/Codeberg Pages):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Generate archive locally, push to GitHub/Codeberg
python reddarc.py /data --output archive/
cd archive/
git init &amp;&amp; git add . &amp;&amp; git commit -m &#34;Initial archive&#34;
git remote add origin https://github.com/username/repo.git
git push -u origin main
# Enable Pages in repository settings"><pre><span><span>#</span> Generate archive locally, push to GitHub/Codeberg</span>
python reddarc.py /data --output archive/
<span>cd</span> archive/
git init <span>&amp;&amp;</span> git add <span>.</span> <span>&amp;&amp;</span> git commit -m <span><span>&#34;</span>Initial archive<span>&#34;</span></span>
git remote add origin https://github.com/username/repo.git
git push -u origin main
<span><span>#</span> Enable Pages in repository settings</span></pre></div>
<p dir="auto"><strong>See deployment guides</strong>:</p>
<ul dir="auto">
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docker/README.md">Docker Deployment Guide</a> - Complete Docker setup with HTTPS and Tor</li>
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docs/TOR_DEPLOYMENT.md">Tor Deployment Guide</a> - Tor hidden service for homelab and privacy</li>
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docs/STATIC_DEPLOYMENT.md">Static Deployment Guide</a> - GitHub Pages / Codeberg Pages (browse-only)</li>
</ul>

<p dir="auto"><strong>Processing Control:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--hide-deleted-comments    # Hide [deleted]/[removed] comments in output
--no-user-pages           # Skip user page generation (saves memory)
--dry-run                 # Preview discovered files without processing
--force-rebuild           # Ignore resume state and rebuild from scratch
--force-parallel-users    # Override auto-detection for parallel processing"><pre>--hide-deleted-comments    <span><span>#</span> Hide [deleted]/[removed] comments in output</span>
--no-user-pages           <span><span>#</span> Skip user page generation (saves memory)</span>
--dry-run                 <span><span>#</span> Preview discovered files without processing</span>
--force-rebuild           <span><span>#</span> Ignore resume state and rebuild from scratch</span>
--force-parallel-users    <span><span>#</span> Override auto-detection for parallel processing</span></pre></div>
<p dir="auto"><strong>Logging:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--log-file &lt;path&gt;         # Custom log file location (default: output/.archive-error.log)
--log-level DEBUG         # Set logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)"><pre>--log-file <span>&lt;</span>path<span>&gt;</span>         <span><span>#</span> Custom log file location (default: output/.archive-error.log)</span>
--log-level DEBUG         <span><span>#</span> Set logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)</span></pre></div>
<p dir="auto"><strong>Performance Tuning:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--debug-memory-limit 8.0      # Override memory limit in GB (default: auto-detect)
--debug-max-connections 8     # Override DB connection pool size (default: auto-detect)
--debug-max-workers 4         # Override parallel workers (default: auto-detect)"><pre>--debug-memory-limit 8.0      <span><span>#</span> Override memory limit in GB (default: auto-detect)</span>
--debug-max-connections 8     <span><span>#</span> Override DB connection pool size (default: auto-detect)</span>
--debug-max-workers 4         <span><span>#</span> Override parallel workers (default: auto-detect)</span></pre></div>
<p dir="auto"><strong>Environment Variables:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Required
DATABASE_URL=postgresql://user:pass@host:5432/reddarchiver

# Optional Performance Tuning (auto-detected if not set)
REDDARCHIVER_MAX_DB_CONNECTIONS=8       # Connection pool size
REDDARCHIVER_MAX_PARALLEL_WORKERS=4     # Parallel processing workers
REDDARCHIVER_USER_BATCH_SIZE=2000       # User page batch size
REDDARCHIVER_QUEUE_MAX_BATCHES=10       # Queue backpressure control
REDDARCHIVER_CHECKPOINT_INTERVAL=10     # Progress save frequency
REDDARCHIVER_USER_PAGE_WORKERS=4        # User page generation workers"><pre><span><span>#</span> Required</span>
DATABASE_URL=postgresql://user:pass@host:5432/reddarchiver

<span><span>#</span> Optional Performance Tuning (auto-detected if not set)</span>
REDDARCHIVER_MAX_DB_CONNECTIONS=8       <span><span>#</span> Connection pool size</span>
REDDARCHIVER_MAX_PARALLEL_WORKERS=4     <span><span>#</span> Parallel processing workers</span>
REDDARCHIVER_USER_BATCH_SIZE=2000       <span><span>#</span> User page batch size</span>
REDDARCHIVER_QUEUE_MAX_BATCHES=10       <span><span>#</span> Queue backpressure control</span>
REDDARCHIVER_CHECKPOINT_INTERVAL=10     <span><span>#</span> Progress save frequency</span>
REDDARCHIVER_USER_PAGE_WORKERS=4        <span><span>#</span> User page generation workers</span></pre></div>

<p dir="auto">Redd-Archiver features a clean modular architecture with specialized components:</p>

<div data-snippet-clipboard-copy-content="reddarc.py              # Main CLI entry point
search_server.py        # Flask search API server
version.py              # Version metadata

core/                   # Core processing &amp; database
‚îú‚îÄ‚îÄ postgres_database.py    # PostgreSQL backend
‚îú‚îÄ‚îÄ postgres_search.py      # PostgreSQL FTS implementation
‚îú‚îÄ‚îÄ write_html.py           # HTML generation coordinator
‚îú‚îÄ‚îÄ watchful.py             # .zst streaming utilities
‚îú‚îÄ‚îÄ incremental_processor.py # Incremental processing
‚îî‚îÄ‚îÄ importers/              # Multi-platform importers
    ‚îú‚îÄ‚îÄ base_importer.py        # Abstract base class
    ‚îú‚îÄ‚îÄ reddit_importer.py      # .zst JSON Lines parser
    ‚îú‚îÄ‚îÄ voat_importer.py        # SQL dump coordinator
    ‚îú‚îÄ‚îÄ voat_sql_parser.py      # SQL INSERT parser
    ‚îî‚îÄ‚îÄ ruqqus_importer.py      # .7z JSON Lines parser

api/                    # REST API v1
‚îú‚îÄ‚îÄ __init__.py             # Blueprint registration
‚îî‚îÄ‚îÄ routes.py               # 30+ API endpoints

mcp_server/             # MCP Server for AI integration
‚îú‚îÄ‚îÄ server.py               # FastMCP server (29 tools)
‚îú‚îÄ‚îÄ README.md               # MCP documentation
‚îî‚îÄ‚îÄ tests/                  # MCP server tests

utils/                  # Utility functions
‚îú‚îÄ‚îÄ console_output.py       # Console output formatting
‚îú‚îÄ‚îÄ error_handling.py       # Error handling utilities
‚îú‚îÄ‚îÄ input_validation.py     # Input validation
‚îú‚îÄ‚îÄ regex_utils.py          # Regular expression utilities
‚îú‚îÄ‚îÄ search_operators.py     # Search query parsing
‚îî‚îÄ‚îÄ simple_json_utils.py    # JSON utilities

processing/             # Data processing modules
‚îú‚îÄ‚îÄ parallel_user_processing.py  # Parallel user page generation
‚îú‚îÄ‚îÄ batch_processing_utils.py    # Batch processing utilities
‚îî‚îÄ‚îÄ incremental_statistics.py    # Statistics tracking

monitoring/             # Performance &amp; monitoring
‚îú‚îÄ‚îÄ performance_monitor.py      # Performance monitoring
‚îú‚îÄ‚îÄ performance_phases.py       # Phase tracking
‚îú‚îÄ‚îÄ performance_timing.py       # Timing utilities
‚îú‚îÄ‚îÄ auto_tuning_validator.py    # Auto-tuning validation
‚îú‚îÄ‚îÄ streaming_config.py         # Auto-detecting configuration
‚îî‚îÄ‚îÄ system_optimizer.py         # System optimization"><pre><code>reddarc.py              # Main CLI entry point
search_server.py        # Flask search API server
version.py              # Version metadata

core/                   # Core processing &amp; database
‚îú‚îÄ‚îÄ postgres_database.py    # PostgreSQL backend
‚îú‚îÄ‚îÄ postgres_search.py      # PostgreSQL FTS implementation
‚îú‚îÄ‚îÄ write_html.py           # HTML generation coordinator
‚îú‚îÄ‚îÄ watchful.py             # .zst streaming utilities
‚îú‚îÄ‚îÄ incremental_processor.py # Incremental processing
‚îî‚îÄ‚îÄ importers/              # Multi-platform importers
    ‚îú‚îÄ‚îÄ base_importer.py        # Abstract base class
    ‚îú‚îÄ‚îÄ reddit_importer.py      # .zst JSON Lines parser
    ‚îú‚îÄ‚îÄ voat_importer.py        # SQL dump coordinator
    ‚îú‚îÄ‚îÄ voat_sql_parser.py      # SQL INSERT parser
    ‚îî‚îÄ‚îÄ ruqqus_importer.py      # .7z JSON Lines parser

api/                    # REST API v1
‚îú‚îÄ‚îÄ __init__.py             # Blueprint registration
‚îî‚îÄ‚îÄ routes.py               # 30+ API endpoints

mcp_server/             # MCP Server for AI integration
‚îú‚îÄ‚îÄ server.py               # FastMCP server (29 tools)
‚îú‚îÄ‚îÄ README.md               # MCP documentation
‚îî‚îÄ‚îÄ tests/                  # MCP server tests

utils/                  # Utility functions
‚îú‚îÄ‚îÄ console_output.py       # Console output formatting
‚îú‚îÄ‚îÄ error_handling.py       # Error handling utilities
‚îú‚îÄ‚îÄ input_validation.py     # Input validation
‚îú‚îÄ‚îÄ regex_utils.py          # Regular expression utilities
‚îú‚îÄ‚îÄ search_operators.py     # Search query parsing
‚îî‚îÄ‚îÄ simple_json_utils.py    # JSON utilities

processing/             # Data processing modules
‚îú‚îÄ‚îÄ parallel_user_processing.py  # Parallel user page generation
‚îú‚îÄ‚îÄ batch_processing_utils.py    # Batch processing utilities
‚îî‚îÄ‚îÄ incremental_statistics.py    # Statistics tracking

monitoring/             # Performance &amp; monitoring
‚îú‚îÄ‚îÄ performance_monitor.py      # Performance monitoring
‚îú‚îÄ‚îÄ performance_phases.py       # Phase tracking
‚îú‚îÄ‚îÄ performance_timing.py       # Timing utilities
‚îú‚îÄ‚îÄ auto_tuning_validator.py    # Auto-tuning validation
‚îú‚îÄ‚îÄ streaming_config.py         # Auto-detecting configuration
‚îî‚îÄ‚îÄ system_optimizer.py         # System optimization
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">HTML Modules (18 specialized modules)</h3><a id="user-content-html-modules-18-specialized-modules" aria-label="Permalink: HTML Modules (18 specialized modules)" href="#html-modules-18-specialized-modules"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="html_modules/
‚îú‚îÄ‚îÄ html_seo.py                # SEO, meta tags, sitemaps
‚îú‚îÄ‚îÄ html_pages_jinja.py        # Jinja2-based page generation
‚îú‚îÄ‚îÄ html_statistics.py         # Analytics and metrics
‚îú‚îÄ‚îÄ dashboard_helpers.py       # Dashboard utility functions
‚îú‚îÄ‚îÄ html_field_generation.py   # Dynamic field generation
‚îú‚îÄ‚îÄ jinja_filters.py           # Custom Jinja2 filters
‚îú‚îÄ‚îÄ html_pages.py              # Core page generation
‚îú‚îÄ‚îÄ html_comments.py           # Comment threading system
‚îú‚îÄ‚îÄ __init__.py                # Public API exports
‚îú‚îÄ‚îÄ jinja_env.py               # Jinja2 environment setup
‚îú‚îÄ‚îÄ html_utils.py              # File operations, utilities
‚îú‚îÄ‚îÄ html_dashboard_jinja.py    # Jinja2 dashboard rendering
‚îú‚îÄ‚îÄ css_minifier.py            # CSS minification
‚îú‚îÄ‚îÄ html_scoring.py            # Dynamic score badges
‚îú‚îÄ‚îÄ html_templates.py          # Template management
‚îú‚îÄ‚îÄ html_url.py                # URL processing, domains
‚îú‚îÄ‚îÄ html_dashboard.py          # Dashboard generation
‚îî‚îÄ‚îÄ html_constants.py          # Configuration values"><pre><code>html_modules/
‚îú‚îÄ‚îÄ html_seo.py                # SEO, meta tags, sitemaps
‚îú‚îÄ‚îÄ html_pages_jinja.py        # Jinja2-based page generation
‚îú‚îÄ‚îÄ html_statistics.py         # Analytics and metrics
‚îú‚îÄ‚îÄ dashboard_helpers.py       # Dashboard utility functions
‚îú‚îÄ‚îÄ html_field_generation.py   # Dynamic field generation
‚îú‚îÄ‚îÄ jinja_filters.py           # Custom Jinja2 filters
‚îú‚îÄ‚îÄ html_pages.py              # Core page generation
‚îú‚îÄ‚îÄ html_comments.py           # Comment threading system
‚îú‚îÄ‚îÄ __init__.py                # Public API exports
‚îú‚îÄ‚îÄ jinja_env.py               # Jinja2 environment setup
‚îú‚îÄ‚îÄ html_utils.py              # File operations, utilities
‚îú‚îÄ‚îÄ html_dashboard_jinja.py    # Jinja2 dashboard rendering
‚îú‚îÄ‚îÄ css_minifier.py            # CSS minification
‚îú‚îÄ‚îÄ html_scoring.py            # Dynamic score badges
‚îú‚îÄ‚îÄ html_templates.py          # Template management
‚îú‚îÄ‚îÄ html_url.py                # URL processing, domains
‚îú‚îÄ‚îÄ html_dashboard.py          # Dashboard generation
‚îî‚îÄ‚îÄ html_constants.py          # Configuration values
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Jinja2 Templates (15 templates)</h3><a id="user-content-jinja2-templates-15-templates" aria-label="Permalink: Jinja2 Templates (15 templates)" href="#jinja2-templates-15-templates"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="templates_jinja2/
‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îî‚îÄ‚îÄ base.html              # Master layout template
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_card.html    # Dashboard statistics cards
‚îÇ   ‚îú‚îÄ‚îÄ footer.html            # Site footer
‚îÇ   ‚îú‚îÄ‚îÄ global_summary.html    # Global statistics summary
‚îÇ   ‚îú‚îÄ‚îÄ navigation.html        # Site navigation bar
‚îÇ   ‚îú‚îÄ‚îÄ post_card.html         # Post display card
‚îÇ   ‚îú‚îÄ‚îÄ user_comment.html      # User comment display
‚îÇ   ‚îî‚îÄ‚îÄ user_post.html         # User post display
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îú‚îÄ‚îÄ comment_macros.html    # Comment rendering macros
‚îÇ   ‚îî‚îÄ‚îÄ reddit_macros.html     # Reddit-specific macros
‚îî‚îÄ‚îÄ pages/
    ‚îú‚îÄ‚îÄ global_search.html     # Global search page
    ‚îú‚îÄ‚îÄ index.html             # Dashboard homepage
    ‚îú‚îÄ‚îÄ link.html              # Individual post page
    ‚îú‚îÄ‚îÄ subreddit.html         # Subreddit listing page
    ‚îî‚îÄ‚îÄ user.html              # User profile page"><pre><code>templates_jinja2/
‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îî‚îÄ‚îÄ base.html              # Master layout template
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_card.html    # Dashboard statistics cards
‚îÇ   ‚îú‚îÄ‚îÄ footer.html            # Site footer
‚îÇ   ‚îú‚îÄ‚îÄ global_summary.html    # Global statistics summary
‚îÇ   ‚îú‚îÄ‚îÄ navigation.html        # Site navigation bar
‚îÇ   ‚îú‚îÄ‚îÄ post_card.html         # Post display card
‚îÇ   ‚îú‚îÄ‚îÄ user_comment.html      # User comment display
‚îÇ   ‚îî‚îÄ‚îÄ user_post.html         # User post display
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îú‚îÄ‚îÄ comment_macros.html    # Comment rendering macros
‚îÇ   ‚îî‚îÄ‚îÄ reddit_macros.html     # Reddit-specific macros
‚îî‚îÄ‚îÄ pages/
    ‚îú‚îÄ‚îÄ global_search.html     # Global search page
    ‚îú‚îÄ‚îÄ index.html             # Dashboard homepage
    ‚îú‚îÄ‚îÄ link.html              # Individual post page
    ‚îú‚îÄ‚îÄ subreddit.html         # Subreddit listing page
    ‚îî‚îÄ‚îÄ user.html              # User profile page
</code></pre></div>

<div data-snippet-clipboard-copy-content="sql/
‚îú‚îÄ‚îÄ schema.sql                 # PostgreSQL table definitions
‚îú‚îÄ‚îÄ indexes.sql                # Performance indexes (GIN, B-tree)
‚îú‚îÄ‚îÄ fix_statistics.sql         # Statistics maintenance queries
‚îî‚îÄ‚îÄ migrations/
    ‚îî‚îÄ‚îÄ 003_add_total_activity_column.sql  # Schema migration"><pre><code>sql/
‚îú‚îÄ‚îÄ schema.sql                 # PostgreSQL table definitions
‚îú‚îÄ‚îÄ indexes.sql                # Performance indexes (GIN, B-tree)
‚îú‚îÄ‚îÄ fix_statistics.sql         # Statistics maintenance queries
‚îî‚îÄ‚îÄ migrations/
    ‚îî‚îÄ‚îÄ 003_add_total_activity_column.sql  # Schema migration
</code></pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">üîç PostgreSQL Full-Text Search</h2><a id="user-content--postgresql-full-text-search" aria-label="Permalink: üîç PostgreSQL Full-Text Search" href="#-postgresql-full-text-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Lightning-Fast Database Search</h3><a id="user-content-lightning-fast-database-search" aria-label="Permalink: Lightning-Fast Database Search" href="#lightning-fast-database-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Redd-Archiver v1.0 uses PostgreSQL full-text search with GIN indexing for blazing-fast search capabilities:</p>
<p dir="auto"><strong>Key Features:</strong></p>
<ul dir="auto">
<li><strong>Database-Powered</strong>: Native PostgreSQL indexing with constant memory usage</li>
<li><strong>Large-Scale</strong>: Efficiently search large datasets (tested with hundreds of GB)</li>
<li><strong>Relevance Ranking</strong>: PostgreSQL <code>ts_rank()</code> for intelligent result ordering</li>
<li><strong>Highlighted Excerpts</strong>: <code>ts_headline()</code> shows matching content in context</li>
<li><strong>Advanced Filters</strong>: Search by subreddit, author, date range, score</li>
<li><strong>Concurrent Queries</strong>: Handle multiple search requests simultaneously</li>
</ul>

<p dir="auto">PostgreSQL search is exposed via <code>postgres_search.py</code> (CLI) and <code>search_server.py</code> (Web API):</p>
<p dir="auto"><strong>Command-Line Interface:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Search command-line interface
python postgres_search.py &#34;your query&#34; --subreddit technology --limit 50

# Example: Search for posts about &#34;machine learning&#34; with high scores
python postgres_search.py &#34;machine learning&#34; --min-score 100 --limit 20"><pre><span><span>#</span> Search command-line interface</span>
python postgres_search.py <span><span>&#34;</span>your query<span>&#34;</span></span> --subreddit technology --limit 50

<span><span>#</span> Example: Search for posts about &#34;machine learning&#34; with high scores</span>
python postgres_search.py <span><span>&#34;</span>machine learning<span>&#34;</span></span> --min-score 100 --limit 20</pre></div>
<p dir="auto"><strong>Web API</strong> (‚úÖ Implemented):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start search server with Docker Compose (recommended)
docker-compose up -d reddarchiver-search-server

# Or run directly
export DATABASE_URL=&#34;postgresql://user:pass@localhost:5432/reddarchiver&#34;
python search_server.py

# Access at http://localhost:5000"><pre><span><span>#</span> Start search server with Docker Compose (recommended)</span>
docker-compose up -d reddarchiver-search-server

<span><span>#</span> Or run directly</span>
<span>export</span> DATABASE_URL=<span><span>&#34;</span>postgresql://user:pass@localhost:5432/reddarchiver<span>&#34;</span></span>
python search_server.py

<span><span>#</span> Access at http://localhost:5000</span></pre></div>
<p dir="auto"><strong>Features:</strong></p>
<ul dir="auto">
<li>RESTful search API with JSON responses</li>
<li>Real-time search with PostgreSQL FTS</li>
<li>Rate limiting and CSRF protection</li>
<li>Health check endpoint: <code>GET /health</code></li>
<li>Search endpoint: <code>GET /search?q=query&amp;subreddit=optional&amp;limit=50</code></li>
<li>Result highlighting with <code>ts_headline()</code></li>
<li>Search suggestions and trending searches</li>
</ul>


<p dir="auto">Full-featured API with 30+ endpoints for programmatic access and MCP/AI integration:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Category</th>
<th>Endpoints</th>
<th>Key Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>System</strong> (5)</td>
<td><code>/health</code>, <code>/stats</code>, <code>/schema</code>, <code>/openapi.json</code></td>
<td>Health checks, statistics, capability discovery, OpenAPI spec</td>
</tr>
<tr>
<td><strong>Posts</strong> (13)</td>
<td><code>/posts</code>, <code>/posts/{id}</code>, <code>/posts/{id}/comments</code>, <code>/posts/{id}/context</code>, <code>/posts/{id}/comments/tree</code>, <code>/posts/{id}/related</code>, <code>/posts/random</code>, <code>/posts/aggregate</code>, <code>/posts/batch</code></td>
<td>List, single, comments, context, tree, related, random, aggregate, batch</td>
</tr>
<tr>
<td><strong>Comments</strong> (7)</td>
<td><code>/comments</code>, <code>/comments/{id}</code>, <code>/comments/random</code>, <code>/comments/aggregate</code>, <code>/comments/batch</code></td>
<td>List, single, random, aggregate, batch</td>
</tr>
<tr>
<td><strong>Users</strong> (8)</td>
<td><code>/users</code>, <code>/users/{username}</code>, <code>/users/{username}/summary</code>, <code>/users/{username}/posts</code>, <code>/users/{username}/comments</code>, <code>/users/aggregate</code>, <code>/users/batch</code></td>
<td>List, profiles, summary, activity, aggregate, batch</td>
</tr>
<tr>
<td><strong>Subreddits</strong> (4)</td>
<td><code>/subreddits</code>, <code>/subreddits/{name}</code>, <code>/subreddits/{name}/summary</code></td>
<td>List, statistics, summary</td>
</tr>
<tr>
<td><strong>Search</strong> (3)</td>
<td><code>/search</code>, <code>/search/explain</code></td>
<td>Full-text search with operators, query debugging</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>MCP/AI-Optimized Features</strong>:</p>
<ul dir="auto">
<li><strong>Field Selection</strong>: <code>?fields=id,title,score</code> for token optimization</li>
<li><strong>Truncation Controls</strong>: <code>?max_body_length=500&amp;include_body=false</code> for response size management</li>
<li><strong>Export Formats</strong>: <code>?format=csv|ndjson</code> for data analysis</li>
<li><strong>Batch Endpoints</strong>: Reduce N requests to 1 with <code>/posts|comments|users/batch</code></li>
<li><strong>Context Endpoints</strong>: Single-call discussion retrieval with <code>/posts/{id}/context</code></li>
<li><strong>Search Operators</strong>: Google-style syntax (<code>&#34;exact&#34;</code>, <code>OR</code>, <code>-exclude</code>, <code>sub:</code>, <code>author:</code>, <code>score:</code>)</li>
</ul>
<p dir="auto">Rate limited to 100 requests/minute. See <a href="https://github.com/19-84/redd-archiver/blob/main/docs/API.md">API Documentation</a> for complete reference.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Instance Registry &amp; Leaderboard</h3><a id="user-content-instance-registry--leaderboard" aria-label="Permalink: Instance Registry &amp; Leaderboard" href="#instance-registry--leaderboard"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Redd-Archiver supports a distributed registry system for tracking archive instances:</p>
<ul dir="auto">
<li><strong>Instance Metadata</strong>: Configure via environment variables or CLI flags (<code>--site-name</code>, <code>--contact</code>, <code>--team-id</code>)</li>
<li><strong>Leaderboard Generator</strong>: Automated scoring based on archive completeness and content risk</li>
<li><strong>Team Grouping</strong>: Group multiple instances under a team ID for coordinated archiving</li>
</ul>
<p dir="auto">See <a href="https://github.com/19-84/redd-archiver/blob/main/docs/REGISTRY_SETUP.md">Registry Setup Guide</a> for configuration.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">üìà Performance &amp; Optimization</h2><a id="user-content--performance--optimization" aria-label="Permalink: üìà Performance &amp; Optimization" href="#-performance--optimization"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">PostgreSQL Backend Performance (v1.0+)</h3><a id="user-content-postgresql-backend-performance-v10" aria-label="Permalink: PostgreSQL Backend Performance (v1.0+)" href="#postgresql-backend-performance-v10"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Constant Memory Usage:</strong></p>
<ul dir="auto">
<li><strong>4GB RAM</strong>: Process large datasets efficiently (tested with hundreds of GB)</li>
<li><strong>8GB RAM</strong>: Optimal for concurrent operations</li>
<li><strong>16GB+ RAM</strong>: Ideal for parallel user page generation</li>
</ul>
<p dir="auto"><strong>Database Storage:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Input (.zst)</th>
<th>PostgreSQL DB</th>
<th>HTML Output</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>93.6MB</td>
<td>~150MB</td>
<td>1.4GB</td>
<td>r/technology</td>
</tr>
<tr>
<td>100MB</td>
<td>~160MB</td>
<td>~1.5GB</td>
<td>Small archives</td>
</tr>
<tr>
<td>500MB</td>
<td>~800MB</td>
<td>~7.5GB</td>
<td>Research projects</td>
</tr>
<tr>
<td>2GB</td>
<td>~3.2GB</td>
<td>~30GB</td>
<td>Large collections</td>
</tr>
<tr>
<td>100GB</td>
<td>~160GB</td>
<td>~1.5TB</td>
<td>Enterprise-scale</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Processing Speed:</strong></p>
<ul dir="auto">
<li><strong>Data Import</strong>: Fast streaming ingestion to PostgreSQL</li>
<li><strong>HTML Generation</strong>: Efficient database-backed rendering</li>
<li><strong>Search Index</strong>: Instant with PostgreSQL GIN indexes</li>
<li><strong>Performance</strong>: Scales with dataset size, optimized for large archives</li>
</ul>

<p dir="auto">Performance varies based on dataset size, query complexity, and hardware:</p>
<ul dir="auto">
<li><strong>PostgreSQL FTS</strong>: Fast indexed search for large datasets</li>
<li><strong>GIN Indexes</strong>: Optimized index lookups for text search</li>
<li><strong>Concurrent Queries</strong>: Supports multiple simultaneous searches with connection pooling</li>
<li><strong>Memory Efficient</strong>: Constant memory usage with streaming results</li>
</ul>

<p dir="auto"><strong>PostgreSQL v1.0 Features</strong>:</p>
<ul dir="auto">
<li><strong>Large-Scale Processing</strong>: Efficiently handle large datasets (tested with hundreds of GB)</li>
<li><strong>Constant Memory</strong>: 4GB RAM regardless of dataset size</li>
<li><strong>Fast Search</strong>: PostgreSQL FTS with GIN indexing</li>
<li><strong>Resume Capability</strong>: Database-backed progress tracking</li>
<li><strong>Concurrent Processing</strong>: Multi-connection pool for parallel operations</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">üîÄ Scaling for Very Large Archives</h2><a id="user-content--scaling-for-very-large-archives" aria-label="Permalink: üîÄ Scaling for Very Large Archives" href="#-scaling-for-very-large-archives"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">Redd-Archiver has been tested with archives up to hundreds of gigabytes. For optimal performance:</p>
<ul dir="auto">
<li><strong>Tested scale</strong>: Hundreds of GB per instance</li>
<li><strong>Memory usage</strong>: Constant 4GB RAM regardless of dataset size</li>
<li><strong>Database</strong>: PostgreSQL handles large datasets efficiently</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Horizontal Scaling Strategy</h3><a id="user-content-horizontal-scaling-strategy" aria-label="Permalink: Horizontal Scaling Strategy" href="#horizontal-scaling-strategy"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For very large archive collections (multiple terabytes), deploy <strong>multiple instances divided by topic</strong>:</p>
<p dir="auto"><strong>Architecture</strong>:</p>
<div data-snippet-clipboard-copy-content="‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Instance 1     ‚îÇ     ‚îÇ  Instance 2     ‚îÇ     ‚îÇ  Instance 3     ‚îÇ
‚îÇ  Technology     ‚îÇ     ‚îÇ  Gaming         ‚îÇ     ‚îÇ  Science        ‚îÇ
‚îÇ  Subreddits     ‚îÇ     ‚îÇ  Subreddits     ‚îÇ     ‚îÇ  Subreddits     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"><pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Instance 1     ‚îÇ     ‚îÇ  Instance 2     ‚îÇ     ‚îÇ  Instance 3     ‚îÇ
‚îÇ  Technology     ‚îÇ     ‚îÇ  Gaming         ‚îÇ     ‚îÇ  Science        ‚îÇ
‚îÇ  Subreddits     ‚îÇ     ‚îÇ  Subreddits     ‚îÇ     ‚îÇ  Subreddits     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li><strong>Efficient search</strong>: Each database stays manageable size</li>
<li><strong>Distributed load</strong>: Parallel processing across instances</li>
<li><strong>Topic organization</strong>: Logical grouping of related content</li>
<li><strong>Independent scaling</strong>: Scale individual topics as needed</li>
</ul>
<p dir="auto"><strong>Deployment Options</strong>:</p>
<ol dir="auto">
<li><strong>Single server</strong>: Multiple Docker Compose stacks with different ports</li>
<li><strong>Multiple servers</strong>: One instance per physical/virtual machine</li>
<li><strong>Topic-based domains</strong>: tech.archive.com, gaming.archive.com, etc.</li>
</ol>
<p dir="auto"><strong>Example Multi-Instance Setup</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Instance 1: Technology topics (port 8080)
cd /archives/tech
docker compose up -d

# Instance 2: Gaming topics (port 8081)
cd /archives/gaming
docker compose -f docker-compose.yml up -d

# Instance 3: Science topics (port 8082)
cd /archives/science
docker compose -f docker-compose.yml up -d"><pre><span><span>#</span> Instance 1: Technology topics (port 8080)</span>
<span>cd</span> /archives/tech
docker compose up -d

<span><span>#</span> Instance 2: Gaming topics (port 8081)</span>
<span>cd</span> /archives/gaming
docker compose -f docker-compose.yml up -d

<span><span>#</span> Instance 3: Science topics (port 8082)</span>
<span>cd</span> /archives/science
docker compose -f docker-compose.yml up -d</pre></div>
<p dir="auto"><strong>When to Use</strong>:</p>
<ul dir="auto">
<li>Archive collection exceeds 500GB</li>
<li>Search performance degrades with single instance</li>
<li>Logical topic divisions exist in your archive</li>
<li>Want to distribute load across multiple servers</li>
</ul>


<ul dir="auto">
<li>Studying online discourse and community dynamics</li>
<li>Analyzing social movements and trends</li>
<li>Preserving internet culture</li>
</ul>

<ul dir="auto">
<li>Backing up subreddits before potential removal</li>
<li>Creating offline-accessible community resources</li>
<li>Distributing knowledge repositories</li>
</ul>

<ul dir="auto">
<li>Pattern analysis in deleted/removed content</li>
<li>User behavior studies</li>
<li>Content moderation research</li>
</ul>


<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docker/README.md">Docker Deployment Guide</a></strong> - Complete Docker setup including PostgreSQL, nginx, HTTPS, and Tor</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/TOR_DEPLOYMENT.md">Tor Deployment Guide</a></strong> - Tor hidden service setup for homelab and privacy deployments</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/STATIC_DEPLOYMENT.md">Static Deployment Guide</a></strong> - GitHub Pages and Codeberg Pages deployment (browse-only, no search)</li>
</ul>

<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/API.md">REST API Documentation</a></strong> - Complete API reference with 30+ endpoints</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/mcp_server/README.md">MCP Server Documentation</a></strong> - AI integration with Claude Desktop/Claude Code</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/REGISTRY_SETUP.md">Registry Setup Guide</a></strong> - Instance registry configuration</li>
</ul>

<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></strong> - Development guidelines and contribution procedures</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/SECURITY.md">SECURITY.md</a></strong> - Security policy and vulnerability reporting</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a></strong> - Unlicense (public domain)</li>
</ul>

<p dir="auto">We welcome contributions! Please see <a href="https://github.com/19-84/redd-archiver/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for development guidelines, code structure, and testing procedures.</p>
<p dir="auto">Key areas for contribution:</p>
<ul dir="auto">
<li>PostgreSQL query optimizations</li>
<li>Additional export formats</li>
<li>Enhanced search features</li>
<li>Documentation improvements</li>
</ul>
<p dir="auto">See our modular architecture (18 specialized modules) for easy entry points to contribute.</p>
<hr/>

<p dir="auto">This is free and unencumbered software released into the public domain. See the <a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a> file (Unlicense) for details.</p>
<p dir="auto">Anyone is free to copy, modify, publish, use, compile, sell, or distribute this software for any purpose, commercial or non-commercial, and by any means.</p>

<p dir="auto">This project leverages public datasets from the following sources:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/pushshift/api">Pushshift</a></strong> - Reddit data access and archival infrastructure</li>
<li><strong><a href="https://github.com/Watchful1/PushshiftDumps">Watchful1&#39;s PushshiftDumps</a></strong> - Comprehensive data dump tools and torrent management</li>
<li><strong><a href="https://github.com/ArthurHeitmann/arctic_shift">Arctic Shift</a></strong> - Making Reddit data accessible to researchers and the public</li>
<li><strong><a href="https://archive.org/details/ruqqus-public-dataset" rel="nofollow">Ruqqus Public Dataset</a></strong> - 752 MB Ruqqus archive (comments and submissions)</li>
<li><strong><a href="https://archive.org/details/searchvoat.co" rel="nofollow">SearchVoat Archive</a></strong> - 16.8 GB Voat.co complete backup</li>
</ul>

<p dir="auto">This project builds upon the work of several excellent archival projects:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/libertysoft3/reddit-html-archiver">reddit-html-archiver</a></strong> by libertysoft3 - Original inspiration and foundation for static HTML generation</li>
<li><strong><a href="https://github.com/Yakabuff/redarc">redarc</a></strong> - Self-hosted Reddit archiving with PostgreSQL and full-text search</li>
<li><strong><a href="https://github.com/sys-nyx/red-arch">red-arch</a></strong> - Static website generator for Reddit subreddit archives</li>
<li><strong><a href="https://github.com/ArthurHeitmann/zst_blocks_format">zst_blocks_format</a></strong> - Efficient block-based compression format for processing large datasets</li>
</ul>

<ul dir="auto">
<li><strong>GitHub Issues</strong>: <a href="https://github.com/19-84/redd-archiver/issues">Report bugs or request features</a></li>
<li><strong>GitHub Discussions</strong>: <a href="https://github.com/19-84/redd-archiver/discussions">Ask questions or share ideas</a></li>
<li><strong>Security Issues</strong>: <a href="https://github.com/19-84/redd-archiver/security/advisories/new">Report via GitHub Security Advisories</a></li>
</ul>

<p dir="auto"><strong>Redd-Archiver was built by one person over 6 months</strong> as a labor of love to preserve internet history before it disappears forever.</p>
<p dir="auto">This isn&#39;t backed by a company or institution‚Äîjust an individual committed to keeping valuable discussions accessible. Your support helps:</p>
<ul dir="auto">
<li>Continue development and bug fixes</li>
<li>Maintain documentation and support</li>
<li>Cover infrastructure costs (servers, storage, bandwidth)</li>
<li>Preserve more data sources and platforms</li>
</ul>
<p dir="auto">Every donation, no matter the size, helps keep this preservation effort alive.</p>

<div data-snippet-clipboard-copy-content="bc1q8wpdldnfqt3n9jh2n9qqmhg9awx20hxtz6qdl7"><pre><code>bc1q8wpdldnfqt3n9jh2n9qqmhg9awx20hxtz6qdl7
</code></pre></div>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/qr-codes/btc.jpg"><img src="https://github.com/19-84/redd-archiver/raw/main/qr-codes/btc.jpg" width="400" alt="Bitcoin QR Code"/></a>
  </p>

<div data-snippet-clipboard-copy-content="42zJZJCqxyW8xhhWngXHjhYftaTXhPdXd9iJ2cMp9kiGGhKPmtHV746EknriN4TNqYR2e8hoaDwrMLfv7h1wXzizMzhkeQi"><pre><code>42zJZJCqxyW8xhhWngXHjhYftaTXhPdXd9iJ2cMp9kiGGhKPmtHV746EknriN4TNqYR2e8hoaDwrMLfv7h1wXzizMzhkeQi
</code></pre></div>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/qr-codes/xmr.jpg"><img src="https://github.com/19-84/redd-archiver/raw/main/qr-codes/xmr.jpg" width="400" alt="Monero QR Code"/></a>
  </p>
<p dir="auto"><strong>Thank you for supporting internet archival efforts!</strong> Every contribution helps maintain and improve this project.</p>
<hr/>
<p dir="auto">This software is provided &#34;as is&#34; under the Unlicense. See <a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a> for details. Users are responsible for compliance with applicable laws and terms of service when processing data.</p>
</article></div></div>
  </body>
</html>
