<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://organicdonut.com/2024/06/cuda-one/">Original</a>
    <h1>CUDA ‚Äì One</h1>
    
    <div id="readability-page-1" class="page"><div>
			<p>First, some backstory. I was laid off from Google in January and I‚Äôve taken the last six months off, mostly <a href="https://solidarityglassworks.com/">working on art glass</a> and taking care of my kids (one of whom was just born in April, and is sleeping on my chest as I write this). I‚Äôm slowly starting to look for work again, with a target start date of early September 2024. If you‚Äôre hiring or know people who are, <a href="https://erty.me/resume">please check out my r√©sum√©</a>.</p>
<p>A friend of mine recently let me know about a really interesting job opportunity, which will require working with code written in (with?) CUDA. The job is ML related, so I‚Äôll be focusing my learning in that direction.</p>
<p>I don‚Äôt know anything about CUDA. Time to learn! And, why not blog about the process as I go along.</p>
<p>First step: come up with some resources to help me learn. I googled something like ‚Äúlearn cuda‚Äù and found <a href="https://www.reddit.com/r/MachineLearning/comments/w52iev/d_what_are_some_good_resources_to_learn_cuda/?rdt=49400">this Reddit post on the /r/MachineLearning subreddit</a>. It looks like I‚Äôll probably be learning a couple of related topics as I go through this journey:</p>

<p><strong>CUDA</strong></p>
<p>This is the goal. It looks like CUDA is a language + toolkit for writing massively parallel programs on graphics cards, that aren‚Äôt necessarily for graphics. Basically, making the GPU compute whatever we want. If we use this for, say, matrix multiplications, we can accelerate training of ML models.</p>
<p><strong>Python and C++ </strong></p>
<p>C++ ? I haven‚Äôt written C++ since college a decade ago. I think I remember some of it, but I‚Äôve always been intimidated by the size of the language, the number of ‚Äúcorrect‚Äù ways to write it, and the amount of magic introduced by macros. I also don‚Äôt like the whole .h / .cc thing, but I suppose I‚Äôll just have to get used to that.</p>
<p>I‚Äôm pretty good at Python, having written several tens of thousands of lines of it at Google, so I‚Äôm not super worried about that.</p>
<p><strong>PyTorch or TensorFlow</strong></p>
<p>Some folks on the Reddit post linked above recommend a <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html‚Äò">specific tutorial on the PyTorch website</a>, which looks interesting. It seems like PyTorch is a ML library written in Python (based on Torch, which was written in Lua).</p>
<p>PyTorch is Meta, now under Linux. TensorFlow is Google. Both use C++, Python, and CUDA.</p>
<p><strong>Matrix Math</strong></p>
<p>In college, I was only briefly introduced to matrix math, and most of that exposure was a graphics course that I audited. Based on my brief reading about all of this, it seems like the major advantage of using graphics cards to train ML is that they can do matrix math¬†<em>really, really fast.¬†</em>It‚Äôs up to me to brush up on this while I explore the other things. I don‚Äôt yet have a specific study plan for this.</p>
<p><strong>Parallelism</strong></p>
<p>According to redditor surge_cell in that previously linked thread, ‚ÄúThere are three basic concepts ‚Äì thread synchronization, shared memory and memory coalescing which CUDA coder should know in and out of [sic]‚Äù. I‚Äôve done some work with threading and parallelism, but not recently. Most of my work at Google was asynchronous, but I didn‚Äôt have to manage the threading and coalescing myself (e.g. <code>async</code> in JS)</p>
<h2><strong>Resources</strong></h2>
<p>Ok ‚Äì so, what am I actually going to do?</p>
<p>I browsed some YouTube videos, but the ones that I‚Äôve watched so far have been pretty high level. It looks like NVIDIA has some CUDA training videos ‚Ä¶ from 12 years ago. I‚Äôm sure the language is quite different now. I also want deeper training than free YouTube videos will likely provide, so I need to identify resources to use that will give me a deep knowledge of the architecture, languages, and toolkits.</p>
<p>First, I‚Äôll try to do the <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">Custom CUDA extensions for PyTorch</a> tutorial. See how far I can get and make notes of what I get stuck on.</p>
<p>Second, One of the Reddit posts recommended a book called Programming Massively Parallel Processors by Hwu, Kirk, and Hajj, so I picked up a copy of that (4th Ed). I‚Äôm going to start working through that. It looks like there are exercises so I‚Äôll be able to actually practice what I‚Äôm applying, which will be fun.</p>
<p>Finally, I‚Äôll try implementing my own text prediction model in ML. I know you can do this cheaply by using something like <a href="https://huggingface.co/">ü§ó (aka HuggingFace)</a> but the point here is to learn CUDA, and using someone else‚Äôs pretrained model is not going to teach me CUDA. I‚Äôm optimizing for learning, not for accurate or powerful models.</p>
<p><b>Questions</b></p>
<p>There‚Äôs a lot I don‚Äôt know, but here are my immediate questions.</p>
<ol>
<li>I have an NVIDIA card in my windows computer, but I don‚Äôt have a toolchain set up to write CUDA code for it. I‚Äôm also not used to developing C++ on windows, so I‚Äôll need to figure out how to get that running as well. I have a feeling this won‚Äôt be particularly tricky, it‚Äôll just take time.</li>
<li>I have a lot of unknown unknowns about CUDA ‚Äì I‚Äôm not even sure what I don‚Äôt know about it. I think I‚Äôll have more questions here as I get into the materials and textbooks.</li>
<li>It seems like there‚Äôs a few parts of ML with various difficulties. If you use a pretrained model, it seems pretty trivial (~20 lines of python) to make it do text prediction or what have you. But training the models is really, really difficult and involves getting a lot of training data. Or, perhaps not difficult, but expensive and time consuming. Designing the ML pipeline seems moderately difficult, and is probably where I‚Äôll spend most of my time. But I need to understand more about this.</li>
</ol>
<p><strong>That‚Äôs it for Day One</strong></p>
<p>If you‚Äôre reading this and you see something I‚Äôve done wrong already, or know of a resource that helped you learn the tools that I‚Äôm talking about here, please do reach out!</p>
<p>From Grand Rapids,</p>
					</div></div>
  </body>
</html>
