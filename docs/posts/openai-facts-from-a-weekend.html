<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://thezvi.wordpress.com/2023/11/20/openai-facts-from-a-weekend/">Original</a>
    <h1>OpenAI: Facts from a Weekend</h1>
    
    <div id="readability-page-1" class="page"><div id="post-23596">
											<h2><a href="https://thezvi.wordpress.com/2023/11/20/openai-facts-from-a-weekend/" rel="bookmark">OpenAI: Facts from a Weekend</a></h2>					
					<!-- .entry-meta -->

					<div>
						
<p>Approximately four GPTs and seven years ago, OpenAI’s founders brought forth on this corporate landscape a new entity, conceived in liberty, and dedicated to the proposition that all men might live equally when AGI is created.</p>



<p>Now we are engaged in a great corporate war, testing whether that entity, or any entity so conceived and so dedicated, can long endure.</p>



<p>What matters is not theory but practice. What happens when the chips are down?</p>



<p>So what happened? What prompted it? What will happen now?</p>



<p>To a large extent, even more than usual, we do not know. We should not pretend that we know more than we do.</p>



<p>Rather than attempt to interpret here or barrage with an endless string of reactions and quotes, I will instead do my best to stick to a compilation of the key facts.</p>



<p>(Note: All times stated here are eastern by default.)</p>



<h4>Just the Facts, Ma’am</h4>



<p>What do we know for sure, or at least close to sure?</p>



<p><a target="_blank" rel="noreferrer noopener" href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/?utm_medium=social&amp;utm_source=twitter&amp;utm_social-type=owned&amp;utm_brand=ars">Here is OpenAI’s corporate structure</a>, giving the board of the 501c3 the power to hire and fire the CEO. It is explicitly dedicated to its nonprofit mission, over and above any duties to shareholders of secondary entities. Investors were warned that there was zero obligation to ever turn a profit:</p>



<figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F670b7ae4-2aea-4ef2-b110-ee1730ebc0c1_873x652.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F670b7ae4-2aea-4ef2-b110-ee1730ebc0c1_873x652.jpeg" alt="A block diagram of OpenAI&#39;s unusual structure, provided by OpenAI." title="A block diagram of OpenAI&#39;s unusual structure, provided by OpenAI."/></a></figure>



<figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a170554-ea1e-4c68-827f-87f35617a08b_661x355.png" target="_blank" rel="noreferrer noopener"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a170554-ea1e-4c68-827f-87f35617a08b_661x355.png" alt="Image" title="Image"/></a></figure>



<p>Here are the most noteworthy things we know happened, as best I can make out.</p>



<ol>
<li>On Friday afternoon at 3:28pm, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/OpenAI/status/1725611900262588813">the OpenAI board fired Sam Altman</a>, appointing CTO Mira Murati as temporary CEO effective immediately. They did so over a Google Meet that did not include then-chairmen Greg Brockman.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/gdb/status/1725667410387378559">Greg Brockman, Altman’s old friend and ally, was removed as chairman of the board but the board said he would stay on as President. In response, he quit</a>.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/nabeelqu/status/1725941746419302819">The board told almost no one</a>. <a target="_blank" rel="noreferrer noopener" href="https://www.axios.com/2023/11/17/microsoft-openai-sam-altman-ouster">Microsoft got one minute of warning</a>.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/?utm_medium=social&amp;utm_source=twitter&amp;utm_social-type=owned&amp;utm_brand=ars">Mira Murati is the only other person we know was told, which happened on Thursday night</a>.</li>



<li>From the announcement by the board: “Mr. Altman’s departure follows a deliberative review process by the board, which concluded that he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities. The board no longer has confidence in his ability to continue leading OpenAI.”</li>



<li>In a statement, the board of directors said: “OpenAI was deliberately structured to advance our mission: to ensure that artificial general intelligence benefits all humanity. The board remains fully committed to serving this mission. We are grateful for Sam’s many contributions to the founding and growth of OpenAI. At the same time, we believe new leadership is necessary as we move forward. As the leader of the company’s research, product, and safety functions, Mira is exceptionally qualified to step into the role of interim CEO. We have the utmost confidence in her ability to lead OpenAI during this transition period.”</li>



<li>OpenAI’s board of directors at this point: OpenAI chief scientist Ilya Sutskever, independent directors Quora CEO Adam D’Angelo, technology entrepreneur Tasha McCauley, and Georgetown Center for Security and Emerging Technology’s Helen Toner.</li>



<li>Usually a 501c3’s board must have a majority of people not employed by the company. Instead, OpenAI’s said that a majority did not have a stake in the company, due to Sam Altman having zero equity.</li>



<li>In response to many calling this a ‘board coup’: “You can call it this way,” <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/conorsen/status/1725752872267055361">Sutskever said about the coup allegation.</a> “And I can understand why you chose this word, but I disagree with this. This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity.” AGI stands for artificial general intelligence, a term that refers to software that can reason the way humans do.When Sutskever was asked whether “these backroom removals are a good way to govern the most important company in the world?” he answered: “I mean, fair, I agree that there is a not ideal element to it. 100%.”</li>



<li>Other than that, the board said nothing in public. I am willing to outright say that, whatever the original justifications, the removal attempt was insufficiently considered and planned and massively botched. Either they had good reasons that justified these actions and needed to share them, or they didn’t.</li>



<li>There had been various clashes between Altman and the board. We don’t know what all of them were. We do know the board felt Altman was moving too quickly, without sufficient concern for safety, with too much focus on building consumer products, while founding additional other companies. ChatGPT was a great consumer product, but supercharged AI development counter to OpenAI’s stated non-profit mission.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://www.theinformation.com/articles/openais-86-billion-share-sale-in-jeopardy-following-altman-firing?utm_source=ti_app">OpenAI was previously planning an oversubscribed share sale at a valuation of $86 billion</a> that was to close a few weeks later.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/jeremyphoward/status/1725968386902147243">Board member Adam D’Angelo said in a Forbes in January</a>: There’s no outcome where this organization is one of the big five technology companies. This is something that’s fundamentally different, and my hope is that we can do a lot more good for the world than just become another corporation that gets that big.</li>



<li>Sam Altman on October 16: “4 times in the history of OpenAI––the most recent time was in the last couple of weeks––I’ve gotten to be in the room when we push the veil of ignorance back and the frontier of discovery forward. Getting to do that is the professional honor of a lifetime.” There was speculation that events were driven in whole or in part by secret capabilities gains within OpenAI, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/SpencerKSchiff/status/1725684028924125660">possibly from a system called Gobi</a>, perhaps even related to the joking claim ‘AI has been achieved internally’ but we have no concrete evidence of that.</li>



<li>Ilya Sutskever co-leads the Superalignment Taskforce, has very short timelines for when we will get AGI, and is very concerned about AI existential risk.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthew_pines/status/1726332673885605997">Sam Altman was involved in starting multiple new major tech companies</a>. He was looking to <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthew_pines/status/1726333220973867103">raise tens of billions from Saudis to start a chip compan</a>y. He was in other discussions for an AI hardware company.</li>



<li>Sam Altman has stated time and again, including to Congress, that he takes existential risk from AI seriously. He was part of the creation of OpenAI’s corporate structure. He signed the CAIS letter. OpenAI spent six months on safety work before releasing GPT-4. He understands the stakes. One can question OpenAI’s track record on safety, many did including those who left to found Anthropic. But this was not a pure ‘doomer vs. accelerationist’ story.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1726248463355281633">Sam Altman is very good at power games such as fights for corporate control</a>. Over the years he earned the loyalty of his employees, many of whom moved in lockstep, using strong strategic ambiguity. Hand very well played.</li>



<li>Essentially all of VC, tech, founder, financial Twitter united to condemn the board for firing Altman and for how they did it, as did many employees, calling upon Altman to either return to the company or start a new company and steal all the talent. The prevailing view online was that no matter its corporate structure, it was unacceptable to fire Altman, who had built the company, or to endanger OpenAI’s value by doing so. That it was good and right and necessary for employees, shareholders, partners and others to unite to take back control.</li>



<li>Talk in those circles is that this will completely discredit EA or ‘doomerism’ or any concerns over the safety of AI, forever. Yes, they say this every week, but this time it was several orders of magnitude louder and more credible. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/NateSilver538/status/1726614811931509147">New York Times somehow gets this backwards</a>. Whatever else this is, it’s a disaster.</li>



<li>By contrast, those concerned about existential risk, and some others, pointed out that the unique corporate structure of OpenAI was designed for exactly this situation. They also mostly noted that the board clearly handled decisions and communications terribly, but that there was much unknown, and tried to avoid jumping to conclusions.</li>



<li>Thus we are now answering the question: What is the law? Do we have law? Where does the power ultimately lie? Is it the charismatic leader that ultimately matters? Who you hire and your culture? Can a corporate structure help us, or do commercial interests and profit motives dominate in the end?</li>



<li>Great pressure was put upon the board to reinstate Altman. They were given two 5pm Pacific deadlines, on Saturday and Sunday, to resign. Microsoft’s aid, and that of its CEO Satya Nadella, was enlisted in this. We do not know what forms of leverage Microsoft did or did not bring to that table.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama/status/1726099792600903681">Sam Altman tweets ‘I love the openai team so much.’</a> Many at OpenAI respond with hearts, including Mira Murati.</li>



<li>Invited by employees including Mira Murati and other top executives, Sam Altman visited the OpenAI offices on Sunday. He tweeted ‘<a target="_blank" rel="noreferrer noopener" href="http://First and last time i ever wear one of these.">First and last time i ever wear one of these</a>’ with a picture of his visitors pass.</li>



<li>The board does not appear to have been at the building at the time.</li>



<li>Press reported that the board had agreed to resign in principle, <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/articles/2023-11-19/openai-negotiations-to-reinstate-altman-hit-snag-over-board-role">but that snags were hit over who the replacement board would be</a>, and over whether or not they would need to issue a statement absolving Altman of wrongdoing, which could be legally perilous for them given their initial statement.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/articles/2023-11-20/openai-s-murati-aims-to-re-hire-altman-brockman-after-exits">Bloomberg reported on Sunday 11:16pm</a> that temporary CEO Mira Murati aimed to rehire Altman and Brockman, while board sought alternative CEO.</li>



<li>OpenAI board <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ashleevance/status/1726469283734274338">hires former Twitch CEO Emmett Shear</a> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/i/web/status/1726526112019382275">to be the new CEO</a>. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/i/web/status/1726526112019382275">He issues his initial statement here</a>. I know a bit about him. If the board needs to hire a new CEO from outside that takes existential risk seriously, he seems to me like a truly excellent pick, I cannot think of a clearly better one. The job set for him may or may not be impossible. Shear’s PPS in his note: PPS: “Before I took the job, I checked on the reasoning behind the change. The board did *not* remove Sam over any specific disagreement on safety, their reasoning was completely different from that. I’m not crazy enough to take this job without board support for commercializing our awesome models.”</li>



<li>New CEO Emmett Shear <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1703178063306203397">has made statements in favor of slowing down AI development</a>, although not a stop. His p(doom) is between 5% and 50%. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/panickssery/status/1726473367992332624">He has said</a> ‘My AI safety discourse is 100% “you are building an alien god that will literally destroy the world when it reaches the critical threshold but be apparently harmless before that.”’ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/orthonormalist/status/1726472744429125876">Here is a thread and video link with more</a>, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/thiagovscoelho/status/1726506818476634249">transcript here</a> or <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/rowancheung/status/1726473420299534491">a captioned clip</a>. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1725985465109774754">Here he is tweeting a 2×2 faction chart a few days ago</a>.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/satyanadella/status/1726509045803336122?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1726509045803336122%7Ctwgr%5E18f2910d36a21704dc1dea625ecaf8c8156f5039%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fmarginalrevolution.com%2Fmarginalrevolution%2F2023%2F11%2Fsolving-for-the-equilibrium.html">Microsoft CEO Satya Nadella posts 2:53am Monday morning</a>: We remain committed to our partnership with OpenAI and have confidence in our product roadmap, our ability to continue to innovate with everything we announced at Microsoft Ignite, and in continuing to support our customers and partners. We look forward to getting to know Emmett Shear and OAI’s new leadership team and working with them. And we’re extremely excited to share the news that <strong>Sam Altman and Greg Brockman, together with colleagues, will be joining Microsoft</strong> to lead a new advanced AI research team. We look forward to moving quickly to provide them with the resources needed for their success.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama/status/1726510261509779876">Sam Altman retweets the above with ‘the mission continues</a>.’ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/gdb/status/1726530200484372688">Brockman confirms.</a> Other leadership to include Jackub Pachocki the GPT-4 lead, Szymon Sidor and Aleksander Madry.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/satyanadella/status/1726516824597258569">Nadella continued in reply</a>: I’m super excited to have you join as CEO of this new group, Sam, setting a new pace for innovation. We’ve learned a lot over the years about how to give founders and innovators space to build independent identities and cultures within Microsoft, including GitHub, Mojang Studios, and LinkedIn, and I’m looking forward to having you do the same.</li>



<li><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ilyasut/status/1726590052392956028">Ilya Sutskever posts 8:15am Monday morning</a>: I deeply regret my participation in the board’s actions. I never intended to harm OpenAI. I love everything we’ve built together and I will do everything I can to reunite the company. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama/status/1726594398098780570">Sam retweets with three heart emojis</a>. Jan Leike, the other head of the superalignment team, Tweeted that he worked through the weekend on the crisis, and that the board should resign.</li>



<li>Microsoft stock was down -1% after hours on Friday, was back to roughly its previous value on Monday morning and at the open. All priced in. Neither Google or S&amp;P made major moves either.</li>



<li><a href="https://twitter.com/ashleevance/status/1726604794918539410" target="_blank" rel="noreferrer noopener">505 of 770 employees of OpenAI, including Ilya Sutskever, sign a letter telling the board to resign and reinstate Altman and Brockman</a> (<a href="https://twitter.com/lilianweng/status/1726634736943280270" target="_blank" rel="noreferrer noopener">later claimed to be up to about 650</a>), threatening to otherwise move to Microsoft to work in the new subsidiary under Altman, which will have a job for every OpenAI employee. Full text of the letter that was posted: To the Board of Directors at OpenAI,OpenAl is the world’s leading Al company. We, the employees of OpenAl, have developed the best models and pushed the field to new frontiers. Our work on Al safety and governance shapes global norms. The products we built are used by millions of people around the world. Until now, the company we work for and cherish has never been in a stronger position.The process through which you terminated Sam Altman and removed Greg Brockman from the board has jeopardized all of this work and undermined our mission and company. Your conduct has made it clear you did not have the competence to oversee OpenAI.When we all unexpectedly learned of your decision, the leadership team of OpenAl acted swiftly to stabilize the company. They carefully listened to your concerns and tried to cooperate with you on all grounds. Despite many requests for specific facts for your allegations, you have never provided any written evidence. They also increasingly realized you were not capable of carrying out your duties, and were negotiating in bad faith.The leadership team suggested that the most stabilizing path forward – the one that would best serve our mission, company, stakeholders, employees and the public – would be for you to resign and put in place a qualified board that could lead the company forward in stability. Leadership worked with you around the clock to find a mutually agreeable outcome. Yet within two days of your initial decision, you again replaced interim CEO Mira Murati against the best interests of the company. You also informed the leadership team that allowing the company to be destroyed “would be consistent with the mission.”Your actions have made it obvious that you are incapable of overseeing OpenAl. We are unable to work for or with people that lack competence, judgement and care for our mission and employees. We, the undersigned, may choose to resign from OpenAl and join the newly announced Microsoft subsidiary run by Sam Altman and Greg Brockman. Microsoft has assured us that there are positions for all OpenAl employees at this new subsidiary should we choose to join. We will take this step imminently, unless all current board members resign, and the board appoints two new lead independent directors, such as Bret Taylor and Will Hurd, and reinstates Sam Altman and Greg Brockman.1. Mira Murati2. Brad Lightcap3. Jason Kwon4. Wojciech Zaremba5. Alec Radford6. Anna Makanju7. Bob McGrew8. Srinivas Narayanan9. Che Chang10. Lillian Weng11. Mark Chen12. Ilya Sutskever</li>



<li>There is talk that OpenAI might completely disintegrate as a result, that ChatGPT might not work a few days from now, and so on.</li>



<li>It is very much not over, and still developing.</li>



<li>There is still a ton we do not know.</li>



<li>This weekend was super stressful for everyone. Most of us, myself included, sincerely wish none of this had happened. Based on what we know, there are no villains in the actual story that matters here. Only people trying their best under highly stressful circumstances with huge stakes and wildly different information and different models of the world and what will lead to good outcomes. In short, to all who were in the arena for this on any side, or trying to process it, rather than spitting bile: ❤️.</li>
</ol>



<p>Later, when we know more, I will have many other things to say, many reactions to quote and react to. For now, everyone please do the best you can to stay sane and help the world get through this as best you can.</p>
											</div><!-- .entry-content -->

		
						<div><p>
							This entry was posted in <a href="https://thezvi.wordpress.com/category/uncategorized/" rel="category tag">Uncategorized</a>. Bookmark the <a href="https://thezvi.wordpress.com/2023/11/20/openai-facts-from-a-weekend/" title="Permalink to OpenAI: Facts from a Weekend" rel="bookmark">permalink</a>.													</p></div><!-- .entry-utility -->
					</div></div>
  </body>
</html>
