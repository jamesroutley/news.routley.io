<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://fantasticanachronism.com/2022/10/10/against-effective-altruism/">Original</a>
    <h1>Against Effective Altruism</h1>
    
    <div id="readability-page-1" class="page"><div><p>You&#39;re (probably) all theological anti-realists; just apply the same reasoning to the existence of moral facts! If the magical invisible sky god is obviously fake, why do you accept magical invisible sky moral facts? Just take the standard &#34;rationalist&#34; toolkit, apply it to realism, and it disappears in a puff of smoke. The arguments can just be copy pasted: for example, one of the classic (and most powerful) arguments from the New Atheism internet wars was that theists are really atheists about every god except their own. The moral realist is an anti-realist about all moral claims except the ones he happens to like! What is the base rate of moral truth, and why do you believe your inside view is enough to overcome that?</p><p>Realist arguments always come across as utterly absurd because their task is 1) extremely simple and obvious, and 2) impossible. All they have to do is say &#34;we used methods x, y, z to uncover moral facts a, b, c, and you can replicate the procedure independently to verify our results&#34;. But it&#39;s never like that, it&#39;s always some interminable verbcel nonsense to cover up the fact that they don&#39;t actually have any access to the moral facts that their theory says they <em>should</em> have access to!</p><p>Whenever I hear the word &#34;intuition&#34; out of the mouth of a philosopher I reach for my Browning!<span><a href="#fn10280584171" rel="footnote"><sup id="fnref10280584171">1</sup></a></span></p><p>It comes down to this:</p><ul><li>Naturalism: no evidence</li><li>Non-naturalism: magic</li></ul><p>Often they&#39;ll back off and come up with excuses about why moral facts aren&#39;t accessible in that way, but that just wrecks the whole thing. Even if realism <em>is</em> true, if there&#39;s no reliable empirical access to moral facts, then that&#39;s functionally equivalent to anti-realism. Any defense based on the immunity of moral propositions to empirical investigation also makes it impossible to find the truth. Your metaethics either has to have a way to determine what&#39;s true in ethics, or you&#39;re practically a nihilist.</p><p>Traditionally the problem has been solved with an appeal to God but EAs are, to a first approximation, 100% atheist. You can&#39;t pull an <em>Euthyphro</em> any more, so WHAT&#39;S YOUR MORAL EPISTEMOLOGY MOTHERFUCKER? Why do epistemic standards seem to suddenly disappear when it comes to utilitarianism? Why am I constantly being asked to believe in the existence of these ontologically redundant entities?</p><p>The <em>theologians</em> at least have the decency to offer <em>some</em> kind of story: ask them about the origin of God and they might invoke the cosmological argument or the principle of sufficient reason. Ask a <em>moralogian</em> about the origin of moral facts and all you&#39;ll get in return is a stupefied bovine expression. The <em>theologians</em> can <em>at least</em> appeal to miracles. The <em>moralogians</em> appeal to <em>nothing</em> and expect you to accept it! Is the origin of moral facts natural, or supernatural? If natural, can we engineer our own? Why or why not? The universe, fundamentally, is dumb. You are positing the existence of entities that are very much not dumb. Where the hell did they come from?</p><p>Above all the <em>moralogian</em> is conspicuously shameless. Even in the 13th century, a man like Aquinas (who would not meet a single doubter in his entire life) felt it necessary to justify his faith and present arguments in favor of the existence of God. Today&#39;s moralogian on the other hand feels no such compulsion, although he is beset on all sides by skeptics! The EA.org <a href="https://concepts.effectivealtruism.org/concepts/metaethics/" target="_blank" rel="noopener">page on meta-ethics</a> speaks for itself:</p><p><img src="https://fantasticanachronism.com/images/ea_metaethics-2d336ac89426625e4aeb100c0088e407.png"/></p><p>Is this an excess of certainty, or is it because deep down the moralogian knows he has no real arguments?</p><p>And the moralogians are not stuck in airy castles of thought, they operate in the real world. The neoconservatives, for example, are a showcase of what happens when the moralogian takes hold of the reins of foreign policy—and it is a consistent ideology that genuinely seeks to spread the values it values. Buckhardt wrote that the foreign policy of Italian states of the Renaissance, free as it was from &#34;moral scruples&#34;, gave him &#34;the impression of a bottomless abyss&#34;. But who today could not prefer that naked self-interest to the neocon disaster of democracy and human rights? The effective altruists have yet to screw up that badly, but just look at the people who want to eliminate all wildlife and you have a good preview of what is possible—&#34;<a href="https://www.goodreads.com/quotes/10177384-man-your-head-is-haunted-you-have-wheels-in-your" target="_blank" rel="noopener">Man, your head is haunted!</a>&#34;</p><p>Peter Singer offers one of the most memorable instances of intellectual cowardice in the entire history of philosophy. Like any reasonable person, he used to be an anti-realist. Then he read Parfit and realized that anti-realism meant utilitarianism was not the case (not sure why it took Parfit to point that out to him). Instead of abandoning utilitarianism, he became a realist just to salvage his ideology! Pathetic.</p><p>Hilariously, Parfit later abandoned realism for what he calls &#34;non-realist cognitivism&#34;, which is basically the Sam Harris view except with bigger words.<span><a href="#fn10280584172" rel="footnote"><sup id="fnref10280584172">2</sup></a></span> Part 7 of vol. 3 of <em>On What Matters</em> is an incredible trainwreck, worth skimming just to see what kind of pretzel shapes people will contort themselves into in order to avoid accepting the obvious. At least Parfit understands that adding a magical normative layer on top of reality is completely incompatible with the scientific <em>weltanschauung</em>.</p><p>&#34;But Alvaro, your instrumental goals are sort of like morality, maybe we could just re-brand...&#34; Just let it go, man.</p><p>You&#39;re not actually a utilitarian anyway. At best it&#39;s a kind of ideal. That&#39;s why you <em>tithe</em> 10%. Just go with the 90% of your intuition that says &#34;this shit is whack, yo&#34;. How do ideologies avoid purity spirals? <a href="https://handsandcities.com/2021/03/07/care-and-demandingness/" target="_blank" rel="noopener">Heuristics against demandingness</a>. It’s one heuristic battling another! Why not go all the way with the one that’s winning?</p><p>So you&#39;re probably not a realist, and probably not a utilitarian either...where does this EA compulsion come from? You must have been memed into it. Don&#39;t feel bad, it happens to all of us, that&#39;s how these things work.</p><blockquote><p>Nature has never generated a terminal value except through hypertrophy of an instrumental value. To look outside nature for sovereign purposes is not an undertaking compatible with techno-scientific integrity, or one with the slightest prospect of success.</p></blockquote><p>Banger tweet Mr. Land, as the */acc transsexual teenagers of twitter dot com like to say.</p><p>Instead of getting tangled up in all this philosophy mumbo jumbo we can just pulverize the question with Bulverism.<span><a href="#fn10280584173" rel="footnote"><sup id="fnref10280584173">3</sup></a></span></p><p>What is morality <em>for</em>, exactly? What does it mean for altruism to be &#34;effective&#34;? EAs take it for granted that the most effective altruism is the altruism that helps its <em>targets</em> the most. I would argue that altruism is really meant to help the altru<em>ist</em>, not the altru<em>ee</em>. That&#39;s the only way it could have evolved. So here&#39;s my pitch to you: effective altruism is the altruism that raises your status the most. The conspicuous lack of caring about the &#34;effectiveness&#34; of altruism among normal people is a hint! <a href="https://www.nytimes.com/2011/10/11/arts/music/metropolitan-operas-donations-hit-a-record-182-million.html" target="_blank" rel="noopener">Hundreds of millions per year for the NY Metropolitan Opera?</a> Sure, why not! They&#39;re not misfiring, <em>you are</em>.</p><p>Of course the problem with optimizing for status is that if you&#39;re <em>seen</em> as optimizing for status rather than having a plausible excuse<span><a href="#fn10280584174" rel="footnote"><sup id="fnref10280584174">4</sup></a></span>, it&#39;s bad—the altruism that increases your status the most is also the one that you can credibly signal that you <em>actually believe in</em>. Thus we get Triversian self-deception where the altruist &#34;really means it&#34; (but of course if he really meant it he wouldn&#39;t be giving 10%). So <em>Actual</em> Effective Altruism is simply too gauche to exist. If you hang around the Bay Aryan rationalists then EA may well satisfy those goals (and I&#39;m sure there are many in EA purely for cynical reasons). But if you&#39;re not part of that crowd...</p><p>Scott Alexander <a href="https://slatestarcodex.com/2018/07/24/value-differences-as-differently-crystallized-metaphysical-heuristics/" target="_blank" rel="noopener">writes</a> that &#34;all of our values are unjustifiable crystallizations of heuristics at some level&#34;, and then continues specifically on utilitarianism:</p><blockquote><div><p>To be absolutely brutal about it:</p><p>EXPLICIT MODEL: Helping others will key me in to networks of reciprocal altruism and raise my status in the community</p></div></blockquote><p>It&#39;s spot on! How someone can write that and go on believing in utilitarianism is beyond me, and Scott offers no explanation.</p><p>Now, you might be thinking &#34;But Alvaro, you idiot, we&#39;re adaptation executors, not fitness maximizers! This is all perfectly alright, you see.&#34; Sure, we&#39;re adaptation executors, but that doesn&#39;t give you a blank check to execute whatever retarded adaptation was bred into your hairy great-....great-grandfather 500,000 years ago, and is now <a href="https://fantasticanachronism.com/2020/03/03/memetic-defoundation/">incompatible with the world you live in</a> (or worse, become enslaved to &#34;unjustified crystallizations&#34; and meticulously engineered hyperstimuli designed to abuse your adaptations). Effective altruism is the coca cola of morality, and <em>you</em> are morally <em>obese</em>!</p><p>The adaptation for helping out people in your community has hypertrophied in the toxic sludge of modern civilization into an absurd ideology about maximizing imaginary sky utilons by helping people you will never meet, or who do not yet (and may never) exist. Given the rapid shift in our environment it&#39;s unsurprising that there are maladaptations in our system; but we can recognize and avoid them. Your &#34;adaptation execution&#34; has been memetically hijacked—where once you would get good things in return for your &#34;altruism&#34; (a stronger community, status, reciprocal altruism, coalition-building, or even &#34;niceness, community, and civilization&#34;), a runaway meme has now convinced you that it&#39;s actually better to get <em>nothing</em>!<span><a href="#fn10280584175" rel="footnote"><sup id="fnref10280584175">5</sup></a></span> You get all the costs of religion, and none of the prosocial benefits! Even worse, the infected are trying to spread this meme to others. Things are in the saddle, and ride <em>you</em>! It&#39;s a particularly dumb version of your typical California cult in which there isn&#39;t <em>even</em> a creepy guy with a harem of underage girls at the top. What&#39;s the point, man?</p><p>There was a type of deer in Ireland whose antlers hypertrophied (probably through sexual selection) to the point that it killed off the entire species. When I look at effective altruists, all I see is overgrown antlers pulling them to the ground.</p><p>The absurdity is heightened because we <em>obviously know where these tendencies come from</em>, regardless of what philosophers try to imagine. We know where the evolved desire to gobble up an entire cake comes from—as you resist the clarion call of the chocolate cake, so you must also resist the call of &#34;effective&#34; altruism. A serious valuing of values can only begin when this baggage is dispensed with and laughed at.</p><p>There are plenty of arguments against utilitarianism&#39;s internal logic: problems with interpersonal comparisons, aggregation, second-order effects, negative utility, average utility, discounting, etc. Whether you go negative, average, rule, or <em>fluorescent</em> there are tons of inescapable and fatal flaws. Empirically, human beings <a href="https://journals.sagepub.com/doi/abs/10.1177/1043463118784888?journalCode=rssa" target="_blank" rel="noopener">don&#39;t have coherent utility functions</a> so what are we even maximizing? Above all, utilitarians ignore the value (and necessity) of suffering—for life and for Life. The fine porcelain of your being was forged in the fires of hell.</p><p>But I don&#39;t think it&#39;s necessary to meet utilitarianism on its own turf, so...<span><a href="#fn10280584176" rel="footnote"><sup id="fnref10280584176">6</sup></a></span></p><p>Let me also say that atheism for the masses, in retrospect, was an enormous error. Organized religion as a social technology is invaluable and the modern atomized welfare state is a pathetic replacement. Atheism for the intellectual class is perfectly alright, but in the age of mass literacy there is really no barrier between them and the rest of society. Was atheism inevitable? Perhaps. But the New Atheists certainly didn&#39;t help. Extrapolating this line of reasoning is left as an exercise to the reader.</p><p>Are there values which are not merely instrumental? In a way—Gnon and all that. Do they have anything to do with the values of effective altrusim? Of course not. But that&#39;s a story for another time.</p></div></div>
  </body>
</html>
