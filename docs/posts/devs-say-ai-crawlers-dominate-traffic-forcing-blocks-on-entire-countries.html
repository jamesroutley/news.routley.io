<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/">Original</a>
    <h1>Devs say AI crawlers dominate traffic, forcing blocks on entire countries</h1>
    
    <div id="readability-page-1" class="page"><article data-id="2084217">
  
  <header>
  <div>
  <div>
    <div>
      

      

      <p>
        AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.
      </p>

      
    </div>

    
  </div>
</div>
</header>


  

  
      
    
    <div>
      <div>

        
        <div>
                      
                      
          
<p>Software developer Xe Iaso <a href="https://xeiaso.net/notes/2025/amazon-crawler/">reached a breaking point</a> earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime. Despite configuring standard defensive measures—adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic—Iaso found that AI crawlers continued evading all attempts to stop them, spoofing user-agents and cycling through residential IP addresses as proxies.</p>
<p>Desperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating &#34;Anubis,&#34; a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site. &#34;It&#39;s futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more,&#34; Iaso wrote in a <a href="https://xeiaso.net/notes/2025/amazon-crawler/">blog post</a> titled &#34;a desperate cry for help.&#34; &#34;I don&#39;t want to have to close off my Gitea server to the public, but I will if I have to.&#34;</p>
<p>Iaso&#39;s story highlights a broader crisis rapidly spreading across the open source community, as what appear to be aggressive AI crawlers increasingly overload community-maintained infrastructure, causing what amounts to persistent distributed denial-of-service (DDoS) attacks on vital public resources. According to a <a href="https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/">comprehensive recent report</a> from LibreNews, some open source projects now see as much as 97 percent of their traffic originating from AI companies&#39; bots, dramatically increasing bandwidth costs, service instability, and burdening already stretched-thin maintainers.</p>
<p>Kevin Fenzi, a member of the Fedora Pagure project&#39;s sysadmin team, <a href="https://www.scrye.com/blogs/nirik/posts/2025/03/15/mid-march-infra-bits-2025/">reported on his blog</a> that the project had to block all traffic from Brazil after repeated attempts to mitigate bot traffic failed. GNOME GitLab implemented Iaso&#39;s &#34;Anubis&#34; system, requiring browsers to solve computational puzzles before accessing content. GNOME sysadmin Bart Piotrowski <a href="https://social.treehouse.systems/@barthalion/114190930216801561">shared</a> on Mastodon that only about 3.2 percent of requests (2,690 out of 84,056) passed their challenge system, suggesting the vast majority of traffic was automated. KDE&#39;s GitLab infrastructure was temporarily knocked offline by crawler traffic originating from Alibaba IP ranges, according to LibreNews, citing a KDE Development chat.</p>

          
                      
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>While Anubis has proven effective at filtering out bot traffic, it comes with drawbacks for legitimate users. When many people access the same link simultaneously—such as when a GitLab link is shared in a chat room—site visitors can face significant delays. Some mobile users have reported waiting up to two minutes for the proof-of-work challenge to complete, according to the news outlet.</p>
<p>The situation isn&#39;t exactly new. In December, Dennis Schubert, who maintains infrastructure for the Diaspora social network, <a href="https://pod.geraspora.de/posts/17342163">described</a> the situation as &#34;literally a DDoS on the entire internet&#34; after discovering that AI companies accounted for 70 percent of all web requests to their services.</p>
<p>The costs are both technical and financial. The Read the Docs project reported that blocking AI crawlers immediately decreased their traffic by 75 percent, going from 800GB per day to 200GB per day. This change saved the project approximately $1,500 per month in bandwidth costs, according to their blog post &#34;AI crawlers need to be more respectful.&#34;</p>
<h2>A disproportionate burden on open source</h2>
<p>The situation has created a tough challenge for open source projects, which rely on public collaboration and typically operate with limited resources compared to commercial entities. Many maintainers have reported that AI crawlers deliberately circumvent standard blocking measures, ignoring robots.txt directives, spoofing user agents, and rotating IP addresses to avoid detection.</p>
<p>As LibreNews reported, Martin Owens from the Inkscape project <a href="https://floss.social/@doctormo/114191332274003577">noted</a> on Mastodon that their problems weren&#39;t just from &#34;the usual Chinese DDoS from last year, but from a pile of companies that started ignoring our spider conf and started spoofing their browser info.&#34; Owens added, &#34;I now have a prodigious block list. If you happen to work for a big company doing AI, you may not get our website anymore.&#34;</p>

          
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>On Hacker News, commenters in threads <a href="https://news.ycombinator.com/item?id=43422413">about the LibreNews</a> post last week and a <a href="https://news.ycombinator.com/item?id=42750420">post on Iaso&#39;s battles</a> in January expressed deep frustration with what they view as AI companies&#39; predatory behavior toward open source infrastructure. While these comments come from forum posts rather than official statements, they represent a common sentiment among developers.</p>
<p>As one Hacker News user <a href="https://news.ycombinator.com/item?id=43422792">put it</a>, AI firms are operating from a position that &#34;goodwill is irrelevant&#34; with their &#34;$100bn pile of capital.&#34; The discussions depict a battle between smaller AI startups that have worked collaboratively with affected projects and larger corporations that have been unresponsive despite allegedly forcing thousands of dollars in bandwidth costs on open source project maintainers.</p>
<p>Beyond consuming bandwidth, the crawlers often hit expensive endpoints, like git blame and log pages, placing additional strain on already limited resources. Drew DeVault, founder of SourceHut, <a href="https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html">reported on his blog</a> that the crawlers access &#34;every page of every git log, and every commit in your repository,&#34; making the attacks particularly burdensome for code repositories.</p>
<p>The problem extends beyond infrastructure strain. As LibreNews points out, some open source projects began receiving AI-generated bug reports as early as December 2023, first <a href="https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/">reported</a> by Daniel Stenberg of the Curl project on his blog in a post from January 2024. These reports appear legitimate at first glance but contain fabricated vulnerabilities, wasting valuable developer time.</p>

<h2>Who is responsible, and why are they doing this?</h2>
<p>AI companies have a history of taking without asking. Before the mainstream breakout of AI image generators and ChatGPT attracted attention to the practice in 2022, the machine learning field regularly compiled datasets with little regard to ownership.</p>
<p>While many AI companies engage in web crawling, the sources suggest varying levels of responsibility and impact. Dennis Schubert&#39;s <a href="https://pod.geraspora.de/posts/17342163">analysis</a> of Diaspora&#39;s traffic logs showed that approximately one-fourth of its web traffic came from bots with an OpenAI user agent, while Amazon accounted for 15 percent and Anthropic for 4.3 percent.</p>

          
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>The crawlers&#39; behavior suggests different possible motivations. Some may be collecting training data to build or refine large language models, while others could be executing real-time searches when users ask AI assistants for information.</p>
<p>The frequency of these crawls is particularly telling. Schubert observed that AI crawlers &#34;don&#39;t just crawl a page once and then move on. Oh, no, they come back every 6 hours because lol why not.&#34; This pattern suggests ongoing data collection rather than one-time training exercises, potentially indicating that companies are using these crawls to keep their models&#39; knowledge current.</p>
<p>Some companies appear more aggressive than others. KDE&#39;s sysadmin team reported that crawlers from Alibaba IP ranges were responsible for temporarily knocking their GitLab offline. Meanwhile, Iaso&#39;s troubles came from Amazon&#39;s crawler. A member of KDE&#39;s sysadmin team told LibreNews that Western LLM operators like OpenAI and Anthropic were at least setting proper user agent strings (which theoretically allows websites to <a href="https://arstechnica.com/information-technology/2023/08/openai-details-how-to-keep-chatgpt-from-gobbling-up-website-data/">block them</a>), while some Chinese AI companies were reportedly more deceptive in their approaches.</p>
<p>It remains unclear why these companies don&#39;t adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don&#39;t overwhelm source websites. Amazon, OpenAI, Anthropic, and Meta did not immediately respond to requests for comment, but we will update this piece if they reply.</p>
<h2>Tarpits and labyrinths: The growing resistance</h2>
<p>In response to these attacks, new defensive tools have emerged to protect websites from unwanted AI crawlers. As Ars <a href="https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/">reported in January</a>, an anonymous creator identified only as &#34;Aaron&#34; designed a tool called &#34;Nepenthes&#34; to trap crawlers in endless mazes of fake content. Aaron explicitly describes it as &#34;aggressive malware&#34; intended to waste AI companies&#39; resources and potentially poison their training data.</p>

          
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>&#34;Any time one of these crawlers pulls from my tarpit, it&#39;s resources they&#39;ve consumed and will have to pay hard cash for,&#34; Aaron explained to Ars. &#34;It effectively raises their costs. And seeing how none of them have turned a profit yet, that&#39;s a big problem for them.&#34;</p>
<p>On Friday, Cloudflare <a href="https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/">announced</a> &#34;AI Labyrinth,&#34; a similar but more commercially polished approach. Unlike Nepenthes, which is designed as an offensive weapon against AI companies, Cloudflare positions its tool as a legitimate security feature to protect website owners from unauthorized scraping, as we reported at the time.</p>
<p>&#34;When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them,&#34; Cloudflare explained in its announcement. The company reported that AI crawlers generate over 50 billion requests to their network daily, accounting for nearly 1 percent of all web traffic they process.</p>
<p>The community is also developing collaborative tools to help protect against these crawlers. The &#34;<a href="https://github.com/ai-robots-txt/ai.robots.txt">ai.robots.txt</a>&#34; project offers an open list of web crawlers associated with AI companies and provides premade robots.txt files that implement the Robots Exclusion Protocol, as well as .htaccess files that return error pages when detecting AI crawler requests.</p>
<p>As it currently stands, both the rapid growth of AI-generated content <a href="https://www.404media.co/ai-slop-is-a-brute-force-attack-on-the-algorithms-that-control-reality/">overwhelming</a> online spaces and aggressive web-crawling practices by AI firms threaten the sustainability of essential online resources. The current approach taken by some large AI companies—<a href="https://www.vintagecomputing.com/index.php/archives/3292/the-pc-is-dead-its-time-to-make-computing-personal-again">extracting</a> vast amounts of data from open-source projects without clear consent or compensation—risks severely damaging the very digital ecosystem on which these AI models depend.</p>
<p>Responsible data collection may be achievable if AI firms collaborate directly with the affected communities. However, prominent industry players have shown little incentive to adopt more cooperative practices. Without meaningful regulation or self-restraint by AI firms, the arms race between data-hungry bots and those attempting to defend open source infrastructure seems likely to escalate further, potentially deepening the crisis for the digital ecosystem that underpins the modern Internet.</p>


          
                  </div>

                  
          






  <div>
    <div>
  <div>
          <p><a href="https://arstechnica.com/author/benjedwards/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/08/benj_ega.png" alt="Photo of Benj Edwards"/></a></p>
  </div>

  <div>
    

    <p>
      Benj Edwards is Ars Technica&#39;s Senior AI Reporter and founder of the site&#39;s dedicated AI beat in 2022. He&#39;s also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.
    </p>
  </div>
</div>
  </div>


  
              </div>

      
      
    </div>
  </article></div>
  </body>
</html>
