<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=36070090">Original</a>
    <h1>Show HN: Visual intuitive explanations of LLM concepts (LLM University)</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Hi HN,</p><p>We&#39;ve just published a lot of original, visual, and intuitive explanations of concepts to introduce people to large language models.</p><p>It&#39;s available for free with no sign-up needed and it includes text articles, some video explanations, and code examples/notebooks as well. And we&#39;re available to answer your questions in a dedicated Discord channel.</p><p>You can find it here: https://llm.university/</p><p>Having written https://jalammar.github.io/illustrated-transformer/, I&#39;ve been thinking about these topics and how best to communicate them for half a decade. But this project is extra special to me because I got to collaborate on it with two of who I think of as some of the best ML educators out there. Luis Serrano of https://www.youtube.com/@SerranoAcademy and Meor Amer, author of &#34;A Visual Introduction to Deep Learning&#34; https://kdimensions.gumroad.com/l/visualdl</p><p>We&#39;re planning to roll out more content to it (let us know what concepts interest you). But as of now, it has the following structure (With some links for highlighted articles for you to audit):</p><p>---</p><p>Module 1: What are Large Language Models</p><p>- Text Embeddings (https://docs.cohere.com/docs/text-embeddings)</p><p>- Similarity between words and sentences (https://docs.cohere.com/docs/similarity-between-words-and-sentences)</p><p>- The attention mechanism</p><p>- Transformer models (https://docs.cohere.com/docs/transformer-models HN Discussion: https://news.ycombinator.com/item?id=35576918)</p><p>- Semantic search</p><p>---</p><p>Module 2: Text representation</p><p>- Classification models (https://docs.cohere.com/docs/classification-models)</p><p>- Classification Evaluation metrics (https://docs.cohere.com/docs/evaluation-metrics)</p><p>- Classification / Embedding API endpoints</p><p>- Semantic search</p><p>- Text clustering</p><p>- Topic modeling (goes over clustering Ask HN posts https://docs.cohere.com/docs/clustering-hacker-news-posts)</p><p>- Multilingual semantic search</p><p>- Multilingual sentiment analysis</p><p>---</p><p>Module 3: Text generation</p><p>- Prompt engineering (https://docs.cohere.com/docs/model-prompting)</p><p>- Use case ideation</p><p>- Chaining prompts</p><p>---</p><p>A lot of the content originates from common questions we get from users of the LLMs we serve at Cohere. So the focus is more on application of LLMs than theory or training LLMs.</p><p>Hope you enjoy it, open to all feedback and suggestions!</p></div></div></div>
  </body>
</html>
