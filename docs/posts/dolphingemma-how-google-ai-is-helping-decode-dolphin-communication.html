<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/ai/dolphingemma/">Original</a>
    <h1>DolphinGemma: How Google AI is helping decode dolphin communication</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    


<section>
  
</section>


    

    
      

<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
  }">
  
  <div>
    <div>
      <div>
        <div>
          
            <p>Apr 14, 2025</p>
          
          
            <p><span aria-hidden="true">·</span></p><p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
        




      </div>
      
        <p>
          DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate — and hopefully find out what they&#39;re saying, too.
        </p>
      
    </div>
  </div>
  
  <div>
    <div>
      
        


  
  
    
  

  
  
    <div>
      
  
    <figure>
        <picture>
            


    

    
        <source media="(max-resolution: 1.5dppx)" sizes="122px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w"/>
    
        <source media="(min-resolution: 1.5dppx)" sizes="244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w"/>
    

    <img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp" alt="thad headshot" sizes=" 122px,  244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w" data-target="image" loading="lazy"/>
    


        </picture>
    </figure>



<div>
  <p>Dr. Thad Starner</p>
  
    <p>
      Google DeepMind Research Scientist and Georgia Tech Professor
    </p>
  
  
</div>

    </div>
  


      

      
      
    </div>
    
      
    
    
  </div>
</div>

    

    
      


  <uni-youtube-player-hero index="0" thumbnail-alt="DolphinGemma text over a picture of dolphins" component-title="DolphinGemma: How Google AI is helping decode dolphin communication" video-id="T8GdEVVvXyE" video-type="video" image="DolphinGemma_SocialExplainers_16x9_DolphinGemma" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16.width-1000.format-webp.webp">
  </uni-youtube-player-hero>


    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="DolphinGemma: How Google AI is helping decode dolphin communication" listen-to-article="Listen to article" data-date-modified="2025-04-14T17:08:29.525540+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="6q2c0">For decades, understanding the clicks, whistles and burst pulses of dolphins has been a scientific frontier. What if we could not only listen to dolphins, but also understand the patterns of their complex communication well enough to generate realistic responses?</p><p data-block-key="4o0o1">Today, on National Dolphin Day, Google, in collaboration with researchers at Georgia Tech and the field research of the <a href="https://www.wilddolphinproject.org/">Wild Dolphin Project</a> (WDP), is announcing progress on DolphinGemma: a foundational AI model trained to learn the structure of dolphin vocalizations and generate novel dolphin-like sound sequences. This approach in the quest for interspecies communication pushes the boundaries of AI and our potential connection with the marine world.</p></div>
      </div>
    </div>
  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="6q2c0">Researching dolphin society for decades</h2><p data-block-key="ae8k9">Understanding any species requires deep context, and that&#39;s one of the many things the WDP provides. Since 1985, WDP has conducted the world&#39;s longest-running underwater dolphin research project, studying a specific community of wild Atlantic spotted dolphins (Stenella frontalis) in the Bahamas across generations. This non-invasive, &#34;In Their World, on Their Terms&#34; approach yields a rich, unique dataset: decades of underwater video and audio meticulously paired with individual dolphin identities, life histories and observed behaviors.</p></div>
      </div>
    </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Dolphins swimming in the water" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="27106">A pod of Atlantic spotted dolphins, Stenella frontalis</p>
    </div>
  
  
    <p><img alt="Dolphins swimming in the water" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="iocbw">A primary focus for WDP is observing and analyzing the dolphins&#39; natural communication and social interactions. Working underwater allows researchers to directly link sounds to specific behaviors in ways surface observation cannot. For decades, they have correlated sound types with behavioral contexts. Here are some examples:</p><ul><li data-block-key="fu0nf">Signature whistles (unique names) that can be used by mothers and calves to reunite</li><li data-block-key="b63q5">Burst-pulse &#34;squawks&#34; often seen during fights</li><li data-block-key="bseip">Click &#34;buzzes&#34; often used during courtship or chasing sharks</li></ul><p data-block-key="2ar36">Knowing the individual dolphins involved is crucial for accurate interpretation. The ultimate goal of this observational work is to understand the structure and potential meaning within these natural sound sequences — seeking patterns and rules that might indicate language. This long-term analysis of natural communication forms the bedrock of WDP&#39;s research and provides essential context for any AI analysis.</p></div>
      </div>
    </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="s704z">Left: A mother spotted dolphin observes her calf while foraging. She will use her unique signature whistle to call the calf back after he is finished. Right: Spectrogram to visualize the whistle.</p>
    </div>
  
  
    <p><img alt="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="iocbw">Introducing DolphinGemma</h2><p data-block-key="2m8ks">Analyzing dolphins&#39; natural, complex communication is a monumental task, and WDP&#39;s vast, labeled dataset provides a unique opportunity for cutting-edge AI.</p><p data-block-key="bgerj">Enter DolphinGemma. Developed by Google, this AI model makes use of specific Google audio technologies: the SoundStream tokenizer efficiently represents dolphin sounds, which are then processed by a model architecture suited for complex sequences. This ~400M parameter model is optimally-sized to run directly on the Pixel phones WDP uses in the field.</p></div>
      </div>
    </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="30sb2">Left: Whistles (left) and burst pulses (right) generated during early testing of DolphinGemma.</p>
    </div>
  
  
    <p><img alt="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="3p158">This model builds upon insights from <a href="https://ai.google.dev/gemma">Gemma</a>, Google’s collection of lightweight, state-of-the-art open models that are built from the same research and technology that powers our Gemini models. Trained extensively on WDP’s acoustic database of wild Atlantic spotted dolphins, DolphinGemma functions as an audio-in, audio-out model, processes sequences of natural dolphin sounds to identify patterns, structure and ultimately predict the likely subsequent sounds in a sequence, much like how large language models for human language predict the next word or token in a sentence.</p><p data-block-key="a754e">WDP is beginning to deploy DolphinGemma this field season with immediate potential benefits. By identifying recurring sound patterns, clusters and reliable sequences, the model can help researchers uncover hidden structures and potential meanings within the dolphins&#39; natural communication — a task previously requiring immense human effort. Eventually, these patterns, augmented with synthetic sounds created by the researchers to refer to objects with which the dolphins like to play, may establish a shared vocabulary with the dolphins for interactive communication.</p></div>
      </div>
    </div>
  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="3p158">Using Pixel phones to listen to and analyze dolphin sounds</h2><p data-block-key="7vd3s">In addition to analyzing natural communication, WDP is also pursuing a distinct, parallel path: exploring potential two-way interaction using technology in the ocean. This effort led to the development of the <a href="https://www.wilddolphinproject.org/our-research/chat-research/">CHAT</a> (Cetacean Hearing Augmentation Telemetry) system, in partnership with the Georgia Institute of Technology. CHAT is an underwater computer designed not to directly decipher the dolphins&#39; complex natural language, but to establish a simpler, shared vocabulary.</p><p data-block-key="6avcn">The concept first relies on associating novel, synthetic whistles (created by CHAT, distinct from natural dolphin sounds) with specific objects the dolphins enjoy, like sargassum, seagrass or scarves the researchers use. By demonstrating the system between humans, researchers hope the naturally curious dolphins will learn to mimic the whistles to request these items. Eventually, as more of the dolphins’ natural sounds are understood, they can also be added to the system.</p></div>
      </div>
    </div>
  

  
    
  
    


  <uni-youtube-player-article index="10" thumbnail-alt="CHAT explainer video" video-id="YhopeQKbpZA" video-type="video">
  </uni-youtube-player-article>


  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="3p158">To enable two-way interaction, the CHAT system first needs to:</p><ol><li data-block-key="9is9o">Hear the mimic accurately amid ocean noise.</li><li data-block-key="5qsu4">Identify which whistle was mimicked in real-time.</li><li data-block-key="48nl7">Inform the researcher (via bone-conducting headphones that work underwater) which object the dolphin &#34;requested.&#34;</li><li data-block-key="2f5o">Enable the researcher to respond quickly by offering the correct object, reinforcing the connection.</li></ol><p data-block-key="c9b4">A Google Pixel 6 handled the high-fidelity analysis of dolphin sounds in real time. The upcoming generation, centered around a Google Pixel 9 (research slated for summer 2025), builds on this effort by integrating speaker/microphone functions and using the phone&#39;s advanced processing to run both deep learning models and template matching algorithms simultaneously.</p></div>
      </div>
    </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="pdphj">Left: Dr. Denise Herzing wearing “Chat Senior, 2012”, Right: Georgia Tech PhD Student Charles Ramey wearing “Chat Junior, 2025”</p>
    </div>
  
  
    <p><img alt="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <p data-block-key="su54v">Using Pixel smartphones dramatically reduces the need for custom hardware, improves system maintainability, lowers power consumption and shrinks the device&#39;s cost and size — crucial advantages for field research in the open ocean. Meanwhile, DolphinGemma’s predictive power can help CHAT anticipate and identify potential mimics earlier in the vocalization sequence, increasing the speed at which researchers can react to the dolphins and making interactions more fluid and reinforcing.</p>
      </div>
    </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Pixel phone inside a case hooked up to cables" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="qfo9j">A Google Pixel 9 inside the latest CHAT system hardware.</p>
    </div>
  
  
    <p><img alt="Pixel phone inside a case hooked up to cables" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;DolphinGemma: How Google AI is helping decode dolphin communication&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="su54v">Sharing DolphinGemma with the research community</h2><p data-block-key="2ad01">Recognizing the value of collaboration in scientific discovery, we’re planning to share DolphinGemma as an open model this summer. While trained on Atlantic spotted dolphin sounds, we anticipate its potential utility for researchers studying other cetacean species, like bottlenose or spinner dolphins. Fine-tuning may be required for different species&#39; vocalizations, and the open nature of the model facilitates this adaptation.</p><p data-block-key="40nps">By providing tools like DolphinGemma, we hope to give researchers worldwide the tools to mine their own acoustic datasets, accelerate the search for patterns and collectively deepen our understanding of these intelligent marine mammals.</p><p data-block-key="e2jq7">The journey to understanding dolphin communication is long, but the combination of dedicated field research by WDP, engineering expertise from Georgia Tech and the power of Google&#39;s technology is opening exciting new possibilities. We&#39;re not just listening anymore. We&#39;re beginning to understand the patterns within the sounds, paving the way for a future where the gap between human and dolphin communication might just get a little smaller.</p><p data-block-key="esrl0">You can learn more about the<a href="https://www.wilddolphinproject.org/"> Wild Dolphin Project</a> on their website.</p></div>
      </div>
    </div>
  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
