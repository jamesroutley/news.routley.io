<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2505.09814">Original</a>
    <h1>X X^t can be faster</h1>
    
    <div id="readability-page-1" class="page"><div>
            <p><em>Originally published on <a href="https://railsatscale.com/2025-05-14-merge-zjit/">Rails At Scale</a>.</em></p>

<p>Following <a href="https://www.slideshare.net/slideshow/zjit-building-a-next-generation-ruby-jit/278807093">Maxime’s presentation at RubyKaigi 2025</a>, the Ruby
developers meeting, and <a href="https://bugs.ruby-lang.org/issues/21221">Matz-san’s approval</a>, ZJIT has been
merged into Ruby. Hurray! In this post, we will give a high-level overview of
the project, which is very early in development.</p>

<p>ZJIT is a new just-in-time (JIT) Ruby compiler built into the reference Ruby
implementation, <a href="https://en.wikipedia.org/wiki/YARV">YARV</a>, by the same compiler group that brought you YJIT.
We (Maxime Chevalier-Boisvert, Takashi Kokubun, Alan Wu, Max Bernstein, and
Aiden Fox Ivey) have been working on ZJIT since the beginning of this year.</p>

<p>It’s different from YJIT in several ways:</p>

<ul>
  <li>Instead of compiling YARV bytecode directly to the low-level IR (LIR), it
uses an high-level SSA-based intermediate representation (HIR)</li>
  <li>Instead of compiling one basic block at a time, it compiles one entire method
at a time</li>
  <li>Instead of using <a href="https://arxiv.org/abs/1411.0352">lazy basic block versioning (LBBV)</a> to profile types,
it reads historical type information from the profiled interpreter</li>
  <li>Instead of doing optimizations while lowering YARV to LIR, it has a
high-level modular optimizer that works on HIR</li>
</ul>

<p>The main difference is that the team is making the intentional choice to build
a more traditional “textbook” compiler so it is easy for the community to
contribute to.</p>

<p>There are some interesting tradeoffs. For example, while YJIT’s architecture
allows for easy interprocedural type-based specialization, ZJIT’s architecture
gives more code at once to the optimizer.</p>

<p>Let’s talk about the ZJIT architecture.</p>

<h2 id="current-architecture">Current architecture</h2>

<p>At a high level, ZJIT takes in YARV bytecode, builds an IR, does some
optimizations, and emits machine code. Simplified, it looks like this:</p>

<figure>

<figcaption>How Ruby code flows through the compiler.</figcaption>
</figure>

<p>We’ll take the following sample Ruby program and bring it through the full
compiler pipeline:</p>

<div><div><pre><code><span># add.rb</span>
<span>def</span> <span>add</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>)</span>
  <span>left</span> <span>+</span> <span>right</span>
<span>end</span>

<span>p</span> <span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<span>p</span> <span>add</span><span>(</span><span>3</span><span>,</span> <span>4</span><span>)</span>
</code></pre></div></div>

<p>Let’s start by getting a feel for YARV.</p>

<h3 id="yarv">YARV</h3>

<p>The Ruby VM has compiled two functions to YARV bytecode. First we see the
top-level function (omitted for brevity with <code>...</code>) and then the <code>add</code>
instruction sequence (ISEQ). There’s a lot going on but it’s important to note
that YARV is a <a href="https://en.wikipedia.org/wiki/Stack_machine">stack machine</a> with local variables. Most
instructions pop their inputs from the stack and push their results onto the
stack.</p>

<p>For example, in <code>add</code>, <code>getlocal_WC_0</code> (offsets <code>0000</code> and <code>0002</code>) is a
specialized instruction that reads the <code>left</code> local from slot 0 (see the third
column) and pushes it onto the stack. Same with <code>right</code> at slot 1. Then it
calls into a specialized <code>+</code> handler, <code>opt_plus</code> (offset <code>0004</code>), which reads
the arguments off the stack and pushes the result back onto the stack.</p>

<div><div><pre><code><span>$</span><span> </span>ruby <span>--dump</span><span>=</span>insns add.rb
<span>...
</span><span>
== disasm: #&lt;ISeq:add@add.rb:2 (2,0)-(4,3)&gt;
local table (size: 2, argc: 2 [opts: 0, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])
[ 2] left@0&lt;Arg&gt;[ 1] right@1&lt;Arg&gt;
0000 getlocal_WC_0                          left@0                    (   3)[LiCa]
0002 getlocal_WC_0                          right@1
0004 opt_plus                               &lt;calldata!mid:+, argc:1, ARGS_SIMPLE&gt;[CcCr]
0006 leave
</span><span>$</span><span>
</span></code></pre></div></div>

<p>The opcode <code>opt_plus</code> is a generic method lookup and call operation but it also
has several fast-path cases inlined into the VM’s instruction handler. It has
code for handling the common case of adding two small integers (fixnums) with a
fallback to the generic send.</p>

<div><div><pre><code><span>static</span> <span>VALUE</span>
<span>vm_opt_plus</span><span>(</span><span>VALUE</span> <span>recv</span><span>,</span> <span>VALUE</span> <span>obj</span><span>)</span>
<span>{</span>
    <span>// fast path for fixnum + fixnum</span>
    <span>if</span> <span>(</span><span>FIXNUM_2_P</span><span>(</span><span>recv</span><span>,</span> <span>obj</span><span>)</span> <span>&amp;&amp;</span>
        <span>BASIC_OP_UNREDEFINED_P</span><span>(</span><span>BOP_PLUS</span><span>,</span> <span>INTEGER_REDEFINED_OP_FLAG</span><span>))</span> <span>{</span>
        <span>return</span> <span>rb_fix_plus_fix</span><span>(</span><span>recv</span><span>,</span> <span>obj</span><span>);</span>
    <span>}</span>
    <span>// ... some other common cases like float + float ...</span>
    <span>// ... fallback code for someone having redefined `Integer#+` ...</span>
<span>}</span>
</code></pre></div></div>

<p>Importantly, it’s not enough for <code>opt_plus</code> to check the types of its
arguments. The opcode handler also has to make sure (via a “bop check”<sup id="fnref:bop" role="doc-noteref"><a href="#fn:bop" rel="footnote">1</a></sup>)
that <code>Integer#+</code> has not been redefined. If the <code>Integer#+</code> has been changed,
it must fall back to the generic operation so the VM can call into the newly
redefined method.</p>

<p>After running the bytecode function some number of times in the interpreter (a
configurable number), ZJIT will change some opcodes to modified versions that
profile their arguments. For example, <code>opt_plus</code> will get rewritten to
<code>zjit_opt_plus</code>. This modified version records the types of the opcode’s input
values on the stack into a special location that ZJIT knows about.</p>

<p>After a more calls to the function (some other configurable number), ZJIT will
compile it. Let’s see what happens to <code>opt_plus</code> in HIR, the first part of the
compiler pipeline. If you’re following along, from here on out, you’ll need to
have a Ruby configured with <code>--enable-zjit</code> (see <a href="https://github.com/ruby/ruby/blob/master/doc/zjit.md">the docs</a>).</p>

<h3 id="hir">HIR</h3>

<p>In the bytecode, which is tersely encoded, jumps are offsets, some control-flow
is implicit, and most dataflow is via the stack.</p>

<p>By contrast, HIR looks more like a graph. Jumps have pointers to their targets
and there’s no stack: instructions that use data have pointers directly to the
instructions that create the data.</p>

<p>Every function has a list of basic blocks. Every basic block has a list of
instructions. Every instruction is addressable by its ID (<code>InsnId</code>, looks like
<code>v12</code>), has a type (after the <code>InsnId</code>), has an opcode, and has some operands.</p>

<p>To show what I mean, here is the text representation of the HIR constructed
directly from the bytecode (note how ZJIT has to be enabled with <code>--zjit</code>):</p>

<div><div><pre><code><span>$</span><span> </span>ruby <span>--zjit</span> <span>--zjit-dump-hir-init</span> add.rb
<span>HIR:
fn add:
bb0(v0:BasicObject, v1:BasicObject):
  v4:BasicObject = SendWithoutBlock v0, :+, v1
  Return v4
</span><span>$</span><span>
</span></code></pre></div></div>

<p>The HIR text representation may on the surface look similar to the bytecode but
that’s only really because they are both text. A more accurate depiction of
HIR’s graph-like nature is this diagram:</p>

<figure>

<figcaption>
Arrows indicate pointers from uses to the data used. Many instructions such as
<code>SendWithoutBlock</code> and <code>Send</code> produce output data. We
refer to this output data by the name of the instruction that produced it. This
is why the <code>Return</code> instruction points to the <code>Send</code>.
</figcaption>
</figure>

<p>(We also see that <code>opt_plus</code> has been turned back into a generic method send to
<code>:+</code>. This is because (as mentioned earlier) under the hood, many <code>opt_xyz</code>
instructions such as <code>opt_plus</code> are <code>opt_send_without_block</code> in disguise and we
do our type optimization later in the compiler pipeline.)</p>

<p>Let’s pick apart this example:</p>

<ul>
  <li><code>v4:BasicObject = SendWithoutBlock v0, :+, v1</code> is an instruction</li>
  <li><code>v4</code> is the both the ID of the instruction and name of its output data</li>
  <li>The output has type <code>BasicObject</code> (or subclass)</li>
  <li>It is a send operation, specifically <code>opt_send_without_block</code></li>
  <li>The self is <code>v0</code></li>
  <li>The method name is <code>:+</code></li>
  <li>The operands are both <code>v0</code> and <code>v1</code></li>
</ul>

<p>Then the HIR goes through our optimization pipeline.</p>

<p>After some optimization, the HIR looks quite different. We no longer see a
generic send operation but instead see type-specialized code:</p>

<div><div><pre><code><span>$</span><span> </span>ruby <span>--zjit</span> <span>--zjit-dump-hir</span> add.rb
<span>HIR:
fn add:
bb0(v0:BasicObject, v1:BasicObject):
  PatchPoint BOPRedefined(INTEGER_REDEFINED_OP_FLAG, BOP_PLUS)
  v7:Fixnum = GuardType v0, Fixnum
  v8:Fixnum = GuardType v1, Fixnum
  v9:Fixnum = FixnumAdd v7, v8
  Return v9
</span><span>$</span><span>
</span></code></pre></div></div>

<p>The optimizer has inserted <code>GuardType</code> instructions that each check at run-time
if their operands are <code>Fixnum</code>. If it is not a fixnum, the generated code will
jump into the interpreter as a fallback. This way, we only need to generate
specialized code—the <code>FixnumAdd</code>.</p>

<p>But this talk of <code>GuardType</code> and <code>FixnumAdd</code> is still pretty symbolic and
high-level. Let’s go one step further in the compiler pipeline into LIR.</p>

<h3 id="lir">LIR</h3>

<p>LIR is meant to be a multi-platform assembler. The only fancy feature it really
provides is a register allocator. When we transform HIR into LIR, we mostly
focus on transforming our high-level operations into an assembly-like language.
To make this easier, we allocate as many virtual LIR registers as we like. Then
the register allocator maps those onto physical registers and stack locations.</p>

<p>Here’s the <code>add</code> function in LIR:</p>

<div><div><pre><code><span>$</span><span> </span>ruby <span>--zjit</span> <span>--zjit-dump-lir</span> add.rb
<span>LIR:
fn add:
Assembler
    000 Label() -&gt; None
    001 FrameSetup() -&gt; None
    002 LiveReg(A64Reg { num_bits: 64, reg_no: 0 }) -&gt; Out64(0)
    003 LiveReg(A64Reg { num_bits: 64, reg_no: 1 }) -&gt; Out64(1)
</span><span># The first GuardType
</span><span>    004 Test(Out64(0), 1_u64) -&gt; None
    005 Jz() target=SideExit(FrameState { iseq: 0x1049ca480, insn_idx: 4, pc: 0x6000002b2520, stack: [InsnId(0), InsnId(1)], locals: [InsnId(0), InsnId(1)] }) -&gt; None
</span><span># The second GuardType
</span><span>    006 Test(Out64(1), 1_u64) -&gt; None
    007 Jz() target=SideExit(FrameState { iseq: 0x1049ca480, insn_idx: 4, pc: 0x6000002b2520, stack: [InsnId(0), InsnId(1)], locals: [InsnId(0), InsnId(1)] }) -&gt; None
</span><span># The FixnumAdd; side-exit if it overflows Fixnum
</span><span>    008 Sub(Out64(0), 1_i64) -&gt; Out64(2)
    009 Add(Out64(2), Out64(1)) -&gt; Out64(3)
    010 Jo() target=SideExit(FrameState { iseq: 0x1049ca480, insn_idx: 4, pc: 0x6000002b2520, stack: [InsnId(0), InsnId(1)], locals: [InsnId(0), InsnId(1)] }) -&gt; None
    011 Add(A64Reg { num_bits: 64, reg_no: 19 }, 38_u64) -&gt; Out64(4)
    012 Mov(A64Reg { num_bits: 64, reg_no: 19 }, Out64(4)) -&gt; None
    013 Mov(Mem64[Reg(20) + 16], A64Reg { num_bits: 64, reg_no: 19 }) -&gt; None
    014 FrameTeardown() -&gt; None
    015 CRet(Out64(3)) -&gt; None
</span><span>$</span><span>
</span></code></pre></div></div>

<p>It is much more explicit about what is going on than the HIR. In it we see some
lower-level details such as:</p>

<ul>
  <li><code>FrameSetup</code> and <code>FrameTeardown</code>, which correspond to native frame base
pointer operations</li>
  <li><code>Test</code>, which is a single bit test instruction</li>
  <li>Explicit conditional jumps to side-exit into the interpreter, such as <code>Jz</code>
and <code>Jo</code></li>
  <li><code>Sub</code> and <code>Add</code>, which are single math instructions</li>
</ul>

<p>In LIR output for other functions, we might see some high-level HIR
constructions turned into calls to C runtime (helper) functions.</p>

<p>It’s not noticeable in this example, but another difference between HIR and LIR
is that LIR is one big linear block: unlike HIR, it does not have multiple basic blocks.</p>

<p>Last, from LIR, we go to assembly.</p>

<h3 id="assembly-asm">Assembly (ASM)</h3>

<p>The assembly listing is a little bit long for the blog post but I will show an
interesting snippet that illustrates the utility of <code>GuardType</code> and
<code>FixnumAdd</code>:</p>

<div><div><pre><code><span>$</span><span> </span>ruby <span>--zjit</span> <span>--zjit-dump-disasm</span> add.rb
<span>...
# Insn: v7 GuardType v0, Fixnum
</span><span>0x6376b7ad400f: test dil, 1
0x6376b7ad4013: je 0x6376b7ad4000
</span><span># Insn: v8 GuardType v1, Fixnum
</span><span>0x6376b7ad4019: test sil, 1
0x6376b7ad401d: je 0x6376b7ad4005
</span><span># Insn: v9 FixnumAdd v7, v8
</span><span>0x6376b7ad4023: sub rdi, 1
0x6376b7ad4027: add rdi, rsi
0x6376b7ad402a: jo 0x6376b7ad400a
</span><span>...
</span><span>$</span><span>
</span></code></pre></div></div>

<p>You can see that <code>GuardType</code> and <code>FixnumAdd</code> only require a couple of very fast
machine instructions each. This is the value of type specialization!</p>

<p>This assembly snippet shows x86 instructions, but ZJIT also has an ARM backend.
The generated code looks very similar in ARM.</p>

<h2 id="future-plans-and-conclusion">Future plans and conclusion</h2>

<p>It is still very early in the ZJIT project. While we encourage reading the
source and trying local experiments, we are not yet running ZJIT in production
and caution you to also avoid doing so. It is an exciting and bumpy road ahead!</p>

<p>For this reason, we will continue maintaining YJIT for now and Ruby 3.5 will
ship with both YJIT and ZJIT. In parallel, we will improve ZJIT until it is on
par (features and performance) with YJIT.</p>

<p>We’re currently working on a couple more features that will make the JIT run
real code. For starters, we are implementing side-exits. Right now, if
<code>GuardType</code> observes a type that it doesn’t expect, it aborts. Ideally we would
be able to actually jump into the interpreter.</p>

<p>Side exits will enable us to do two exciting things:</p>

<ol>
  <li>Run the Ruby test suite, giving us a correctness baseline</li>
  <li>Run yjit-bench and other production applications, giving us a performance baseline</li>
</ol>

<p>Then we’ll get to work on profiling and seeing what optimizations are most
impactful.</p>

<p>Thanks for reading this post! We’ll make more information and documentation
available soon.</p>
<div role="doc-endnotes">
  <ol>
    <li id="fn:bop" role="doc-endnote">
      <p>This is because it’s possible to redefine (almost?) any method in Ruby,
including built-in ones such as <code>Integer#+</code> (“<strong>b</strong>asic <strong>op</strong>erations”,
hence “bop”).</p>

      <p>The developers of the YARV VM want to include shortcuts for common
operations such as adding small numbers (“fixnums”), but want to still
support falling back to very dynamic behavior. <a href="#fnref:bop" role="doc-backlink">↩</a></p>
    </li>
  </ol>
</div>

        </div></div>
  </body>
</html>
