<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/beehive-lab/TornadoVM">Original</a>
    <h1>TornadoVM: A practical and efficient heterogeneous programming framework</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<p><a target="_blank" rel="noopener noreferrer" href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/etc/tornadoVM_Logo.jpg"><img width="250" height="250" src="https://blog.bridge.watch/beehive-lab/TornadoVM/raw/master/etc/tornadoVM_Logo.jpg"/></a></p>
<p dir="auto">TornadoVM is a plug-in to OpenJDK and GraalVM that allows programmers to automatically run Java programs on
heterogeneous hardware. TornadoVM currently targets OpenCL-compatible devices and it runs on multi-core CPUs, dedicated
GPUs (NVIDIA, AMD), integrated GPUs (Intel HD Graphics and ARM Mali), and FPGAs (Intel and Xilinx).</p>

<p dir="auto"><strong>Website</strong>: <a href="https://www.tornadovm.org" rel="nofollow">tornadovm.org</a></p>
<p dir="auto">For a quick introduction please read the following <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/15_FAQ.md">FAQ</a>.</p>
<p dir="auto"><strong>Current Release:</strong> TornadoVM 0.12 - 17/11/2021 : See <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/CHANGELOG.md#tornadovm-0.12">CHANGELOG</a></p>
<p dir="auto">Previous Releases can be found <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/Releases.md">here</a></p>
<h2 dir="auto"><a id="user-content-1-installation" aria-hidden="true" href="#1-installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>1. Installation</h2>
<p dir="auto">In Linux and Mac OSx, TornadoVM can be installed automatically with the <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/INSTALL.md#a-automatic-installation">installation script</a>. For example:</p>
<div data-snippet-clipboard-copy-content="./scripts/tornadovmInstaller.sh 
TornadoVM installer for Linux and OSx
Usage:
       --jdk8           : Install TornadoVM with OpenJDK 8
       --jdk11          : Install TornadoVM with OpenJDK 11
       --jdk17          : Install TornadoVM with OpenJDK 17
       --graal-jdk-11   : Install TornadoVM with GraalVM and JDK 11 (GraalVM 21.3.0)
       --graal-jdk-17   : Install TornadoVM with GraalVM and JDK 16 (GraalVM 21.3.0)
       --corretto-11    : Install TornadoVM with Corretto JDK 11
       --corretto-17    : Install TornadoVM with Corretto JDK 16
       --mandrel-11     : Install TornadoVM with Mandrel 21.3.0 (JDK 11)
       --mandrel-17     : Install TornadoVM with Mandrel 21.3.0 (JDK 17)
       --windows-jdk-11 : Install TornadoVM with Windows JDK 11
       --windows-jdk-17 : Install TornadoVM with Windows JDK 17
       --opencl         : Install TornadoVM and build the OpenCL backend
       --ptx            : Install TornadoVM and build the PTX backend
       --spirv          : Install TornadoVM and build the SPIR-V backend
       --help           : Print this help"><pre>./scripts/tornadovmInstaller.sh 
TornadoVM installer <span>for</span> Linux and OSx
Usage:
       --jdk8           <span>:</span> Install TornadoVM with OpenJDK 8
       --jdk11          <span>:</span> Install TornadoVM with OpenJDK 11
       --jdk17          <span>:</span> Install TornadoVM with OpenJDK 17
       --graal-jdk-11   <span>:</span> Install TornadoVM with GraalVM and JDK 11 (GraalVM 21.3.0)
       --graal-jdk-17   <span>:</span> Install TornadoVM with GraalVM and JDK 16 (GraalVM 21.3.0)
       --corretto-11    <span>:</span> Install TornadoVM with Corretto JDK 11
       --corretto-17    <span>:</span> Install TornadoVM with Corretto JDK 16
       --mandrel-11     <span>:</span> Install TornadoVM with Mandrel 21.3.0 (JDK 11)
       --mandrel-17     <span>:</span> Install TornadoVM with Mandrel 21.3.0 (JDK 17)
       --windows-jdk-11 <span>:</span> Install TornadoVM with Windows JDK 11
       --windows-jdk-17 <span>:</span> Install TornadoVM with Windows JDK 17
       --opencl         <span>:</span> Install TornadoVM and build the OpenCL backend
       --ptx            <span>:</span> Install TornadoVM and build the PTX backend
       --spirv          <span>:</span> Install TornadoVM and build the SPIR-V backend
       --help           <span>:</span> Print this <span>help</span></pre></div>
<p dir="auto"><strong>NOTE</strong> Select the desired backend:</p>
<ul dir="auto">
<li><code>--opencl</code>: Enables the OpenCL backend (requires OpenCL drivers)</li>
<li><code>--ptx</code>: Enables the PTX backend (requires NVIDIA CUDA drivers)</li>
<li><code>--spirv</code>: Enables the SPIRV backend (requires Intel Level Zero drivers)</li>
</ul>
<p dir="auto">Alternatively, TornadoVM can be installed either manually <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/INSTALL.md#b-manual-installation">from source</a> or
by <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/13_INSTALL_WITH_DOCKER.md">using Docker</a>.</p>
<p dir="auto">You can also run TornadoVM on Amazon AWS CPUs, GPUs, and FPGAs following the
instructions <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/17_AWS.md">here</a>.</p>
<h2 dir="auto"><a id="user-content-2-usage-instructions" aria-hidden="true" href="#2-usage-instructions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>2. Usage Instructions</h2>
<p dir="auto">TornadoVM is currently being used to accelerate machine learning and deep learning applications, computer vision,
physics simulations, financial applications, computational photography, and signal processing.</p>
<p dir="auto">We have a use-case, <a href="https://github.com/beehive-lab/kfusion-tornadovm">kfusion-tornadovm</a>, for accelerating a
computer-vision application implemented in Java using the Tornado-API to run on GPUs.</p>
<p dir="auto">We also have a set
of <a href="https://github.com/beehive-lab/TornadoVM/tree/master/examples/src/main/java/uk/ac/manchester/tornado/examples">examples</a>
that includes NBody, DFT, KMeans computation and matrix computations.</p>
<p dir="auto"><strong>Additional Information</strong></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs">Documentation</a></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/4_BENCHMARKS.md">Benchmarks</a></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/5_REDUCTIONS.md">Reductions</a></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/6_TORNADO_FLAGS.md">Execution Flags</a></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/7_FPGA.md">FPGA execution</a></p>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/9_PROFILER.md">Profiler Usage</a></p>
<h2 dir="auto"><a id="user-content-3-programming-model" aria-hidden="true" href="#3-programming-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>3. Programming Model</h2>
<p dir="auto">TornadoVM exposes to the programmer task-level, data-level and pipeline-level parallelism via a light Application
Programming Interface (API). In addition, TornadoVM uses single-source property, in which the code to be accelerated and
the host code live in the same Java program.</p>
<p dir="auto">Compute-kernels in TornadoVM can be programmed using two different approaches:</p>
<h4 dir="auto"><a id="user-content-a-loop-parallelism" aria-hidden="true" href="#a-loop-parallelism"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>a) Loop-parallelism</h4>
<p dir="auto">Compute kernels are written in a sequential form (tasks programmed for a single thread execution). To express
parallelism, TornadoVM exposes two annotations that can be used in loops and parameters: a) <code>@Parallel</code> for annotating
parallel loops; and b) <code>@Reduce</code> for annotating parameters used in reductions.</p>
<p dir="auto">The following code snippet shows a full example to accelerate Matrix-Multiplication using TornadoVM and the
loop-parallel API:</p>
<div data-snippet-clipboard-copy-content="public class Compute {
    private static void mxmLoop(Matrix2DFloat A, Matrix2DFloat B, Matrix2DFloat C, final int size) {
        for (@Parallel int i = 0; i &lt; size; i++) {
            for (@Parallel int j = 0; j &lt; size; j++) {
                float sum = 0.0f;
                for (int k = 0; k &lt; size; k++) {
                    sum += A.get(i, k) * B.get(k, j);
                }
                C.set(i, j, sum);
            }
        }
    }

    public void run(Matrix2DFloat A, Matrix2DFloat B, Matrix2DFloat C, final int size) {
        TaskSchedule ts = new TaskSchedule(&#34;s0&#34;)
                .streamIn(A, B)                               // Stream data from host to device
                .task(&#34;t0&#34;, Compute::mxmLoop, A, B, C, size)  // Each task points to an existing Java method
                .streamOut(C);                                // sync arrays with the host side
        ts.execute();   // It will execute the code on the default device (e.g. a GPU)
    }
}"><pre><span>public</span> <span>class</span> <span>Compute</span> {
    <span>private</span> <span>static</span> <span>void</span> <span>mxmLoop</span>(<span>Matrix2DFloat</span> <span>A</span>, <span>Matrix2DFloat</span> <span>B</span>, <span>Matrix2DFloat</span> <span>C</span>, <span>final</span> <span>int</span> <span>size</span>) {
        <span>for</span> (<span>@Parallel</span> <span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> size; i<span>++</span>) {
            <span>for</span> (<span>@Parallel</span> <span>int</span> j <span>=</span> <span>0</span>; j <span>&lt;</span> size; j<span>++</span>) {
                <span>float</span> sum <span>=</span> <span>0.0f</span>;
                <span>for</span> (<span>int</span> k <span>=</span> <span>0</span>; k <span>&lt;</span> size; k<span>++</span>) {
                    sum <span>+=</span> <span>A</span><span>.</span>get(i, k) <span>*</span> <span>B</span><span>.</span>get(k, j);
                }
                <span>C</span><span>.</span>set(i, j, sum);
            }
        }
    }

    <span>public</span> <span>void</span> <span>run</span>(<span>Matrix2DFloat</span> <span>A</span>, <span>Matrix2DFloat</span> <span>B</span>, <span>Matrix2DFloat</span> <span>C</span>, <span>final</span> <span>int</span> <span>size</span>) {
        <span>TaskSchedule</span> ts <span>=</span> <span>new</span> <span>TaskSchedule</span>(<span><span>&#34;</span>s0<span>&#34;</span></span>)
                .streamIn(<span>A</span>, <span>B</span>)                               <span><span>//</span> Stream data from host to device</span>
                .task(<span><span>&#34;</span>t0<span>&#34;</span></span>, <span>Compute</span><span>::</span>mxmLoop, <span>A</span>, <span>B</span>, <span>C</span>, size)  <span><span>//</span> Each task points to an existing Java method</span>
                .streamOut(<span>C</span>);                                <span><span>//</span> sync arrays with the host side</span>
        ts<span>.</span>execute();   <span><span>//</span> It will execute the code on the default device (e.g. a GPU)</span>
    }
}</pre></div>
<h4 dir="auto"><a id="user-content-b-kernel-parallelism" aria-hidden="true" href="#b-kernel-parallelism"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>b) Kernel Parallelism</h4>
<p dir="auto">Another way to express compute-kernels in TornadoVM is via the kernel-parallel API. To do so, TornadoVM exposes
a <code>KernelContext</code> with which the application can directly access the thread-id, allocate memory in local memory
(shared memory on NVIDIA devices), and insert barriers. This model is similar to programming compute-kernels in OpenCL
and CUDA. Therefore, this API is more suitable for GPU/FPGA expert programmers that want more control or want to port
existing CUDA/OpenCL compute kernels into TornadoVM.</p>
<p dir="auto">The following code-snippet shows the Matrix Multiplication example using the kernel-parallel API:</p>
<div data-snippet-clipboard-copy-content="public class Compute {
    private static void mxmKernel(KernelContext context, Matrix2DFloat A, Matrix2DFloat B, Matrix2DFloat C, final int size) {
        int idx = context.threadIdx;
        int jdx = context.threadIdy;
        float sum = 0;
        for (int k = 0; k &lt; size; k++) {
            sum += A.get(idx, k) * B.get(k, jdx);
        }
        C.set(idx, jdx, sum);
    }

    public void run(Matrix2DFloat A, Matrix2DFloat B, Matrix2DFloat C, final int size) {
        // When using the kernel-parallel API, we need to create a Grid and a Worker

        WorkerGrid workerGrid = new WorkerGrid2D(size, size);    // Create a 2D Worker
        GridScheduler gridScheduler = new GridScheduler(&#34;s0.t0&#34;, workerGrid);  // Attach the worker to the Grid
        KernelContext context = new KernelContext();             // Create a context
        workerGrid.setLocalWork(32, 32, 1);                      // Set the local-group size

        TaskSchedule ts = new TaskSchedule(&#34;s0&#34;)
                .streamIn(A, B)                                 // Stream data from host to device
                .task(&#34;t0&#34;, Compute::mxmKernel, context, A, B, C, size)  // Each task points to an existing Java method
                .streamOut(C);                                  // sync arrays with the host side
        ts.execute(gridScheduler);   // Execute with a GridScheduler
    }
}"><pre><span>public</span> <span>class</span> <span>Compute</span> {
    <span>private</span> <span>static</span> <span>void</span> <span>mxmKernel</span>(<span>KernelContext</span> <span>context</span>, <span>Matrix2DFloat</span> <span>A</span>, <span>Matrix2DFloat</span> <span>B</span>, <span>Matrix2DFloat</span> <span>C</span>, <span>final</span> <span>int</span> <span>size</span>) {
        <span>int</span> idx <span>=</span> context<span>.</span>threadIdx;
        <span>int</span> jdx <span>=</span> context<span>.</span>threadIdy;
        <span>float</span> sum <span>=</span> <span>0</span>;
        <span>for</span> (<span>int</span> k <span>=</span> <span>0</span>; k <span>&lt;</span> size; k<span>++</span>) {
            sum <span>+=</span> <span>A</span><span>.</span>get(idx, k) <span>*</span> <span>B</span><span>.</span>get(k, jdx);
        }
        <span>C</span><span>.</span>set(idx, jdx, sum);
    }

    <span>public</span> <span>void</span> <span>run</span>(<span>Matrix2DFloat</span> <span>A</span>, <span>Matrix2DFloat</span> <span>B</span>, <span>Matrix2DFloat</span> <span>C</span>, <span>final</span> <span>int</span> <span>size</span>) {
        <span><span>//</span> When using the kernel-parallel API, we need to create a Grid and a Worker</span>

        <span>WorkerGrid</span> workerGrid <span>=</span> <span>new</span> <span>WorkerGrid2D</span>(size, size);    <span><span>//</span> Create a 2D Worker</span>
        <span>GridScheduler</span> gridScheduler <span>=</span> <span>new</span> <span>GridScheduler</span>(<span><span>&#34;</span>s0.t0<span>&#34;</span></span>, workerGrid);  <span><span>//</span> Attach the worker to the Grid</span>
        <span>KernelContext</span> context <span>=</span> <span>new</span> <span>KernelContext</span>();             <span><span>//</span> Create a context</span>
        workerGrid<span>.</span>setLocalWork(<span>32</span>, <span>32</span>, <span>1</span>);                      <span><span>//</span> Set the local-group size</span>

        <span>TaskSchedule</span> ts <span>=</span> <span>new</span> <span>TaskSchedule</span>(<span><span>&#34;</span>s0<span>&#34;</span></span>)
                .streamIn(<span>A</span>, <span>B</span>)                                 <span><span>//</span> Stream data from host to device</span>
                .task(<span><span>&#34;</span>t0<span>&#34;</span></span>, <span>Compute</span><span>::</span>mxmKernel, context, <span>A</span>, <span>B</span>, <span>C</span>, size)  <span><span>//</span> Each task points to an existing Java method</span>
                .streamOut(<span>C</span>);                                  <span><span>//</span> sync arrays with the host side</span>
        ts<span>.</span>execute(gridScheduler);   <span><span>//</span> Execute with a GridScheduler</span>
    }
}</pre></div>
<p dir="auto">Additionally, the two modes of expressing parallelism (kernel and loop parallelization) can be combined in the same
task-schedule object.</p>
<h2 dir="auto"><a id="user-content-4-dynamic-reconfiguration" aria-hidden="true" href="#4-dynamic-reconfiguration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>4. Dynamic Reconfiguration</h2>
<p dir="auto">Dynamic reconfiguration is the ability of TornadoVM to perform live task migration between devices, which means that
TornadoVM decides where to execute the code to increase performance (if possible). In other words, TornadoVM switches
devices if it can detect that a specific device can yield better performance (compared to another). With the
task-migration, the TornadoVM&#39;s approach is to only switch device if it detects an application can be executed faster
than the CPU execution using the code compiled by C2 or Graal-JIT, otherwise it will stay on the CPU. So TornadoVM can
be seen as a complement to C2 and Graal. This is because there is no single hardware to best execute all workloads
efficiently. GPUs are very good at exploiting SIMD applications, and FPGAs are very good at exploiting pipeline
applications. If your applications follow those models, TornadoVM will likely select heterogeneous hardware. Otherwise,
it will stay on the CPU using the default compilers (C2 or Graal).</p>
<p dir="auto">To use the dynamic reconfiguration, you can execute using TornadoVM policies. For example:</p>
<div data-snippet-clipboard-copy-content="// TornadoVM will execute the code in the best accelerator.
ts.execute(Policy.PERFORMANCE);"><pre><span><span>//</span> TornadoVM will execute the code in the best accelerator.</span>
ts<span>.</span>execute(<span>Policy</span><span><span>.</span>PERFORMANCE</span>);</pre></div>
<p dir="auto">Further details and instructions on how to enable this feature can be found here.</p>
<ul dir="auto">
<li>Dynamic
reconfiguration: <a href="https://dl.acm.org/doi/10.1145/3313808.3313819" rel="nofollow">https://dl.acm.org/doi/10.1145/3313808.3313819</a></li>
</ul>
<h2 dir="auto"><a id="user-content-5-how-to-use-it-in-your-projects" aria-hidden="true" href="#5-how-to-use-it-in-your-projects"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>5. How to Use it in your Projects?</h2>
<p dir="auto">You can import the API and start using TornadoVM. Set this in the <code>pom.xml</code> file.</p>
<div data-snippet-clipboard-copy-content="
&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;universityOfManchester-graal&lt;/id&gt;
        &lt;url&gt;https://raw.githubusercontent.com/beehive-lab/tornado/maven-tornadovm&lt;/url&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;

&lt;dependencies&gt;
&lt;dependency&gt;
    &lt;groupId&gt;tornado&lt;/groupId&gt;
    &lt;artifactId&gt;tornado-api&lt;/artifactId&gt;
    &lt;version&gt;0.12&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;tornado&lt;/groupId&gt;
    &lt;artifactId&gt;tornado-matrices&lt;/artifactId&gt;
    &lt;version&gt;0.12&lt;/version&gt;
&lt;/dependency&gt;
&lt;/dependencies&gt;"><pre>&lt;<span>repositories</span>&gt;
    &lt;<span>repository</span>&gt;
        &lt;<span>id</span>&gt;universityOfManchester-graal&lt;/<span>id</span>&gt;
        &lt;<span>url</span>&gt;https://raw.githubusercontent.com/beehive-lab/tornado/maven-tornadovm&lt;/<span>url</span>&gt;
    &lt;/<span>repository</span>&gt;
&lt;/<span>repositories</span>&gt;

&lt;<span>dependencies</span>&gt;
&lt;<span>dependency</span>&gt;
    &lt;<span>groupId</span>&gt;tornado&lt;/<span>groupId</span>&gt;
    &lt;<span>artifactId</span>&gt;tornado-api&lt;/<span>artifactId</span>&gt;
    &lt;<span>version</span>&gt;0.12&lt;/<span>version</span>&gt;
&lt;/<span>dependency</span>&gt;
&lt;<span>dependency</span>&gt;
    &lt;<span>groupId</span>&gt;tornado&lt;/<span>groupId</span>&gt;
    &lt;<span>artifactId</span>&gt;tornado-matrices&lt;/<span>artifactId</span>&gt;
    &lt;<span>version</span>&gt;0.12&lt;/<span>version</span>&gt;
&lt;/<span>dependency</span>&gt;
&lt;/<span>dependencies</span>&gt;</pre></div>
<p dir="auto">To run TornadoVM, you need to either install the TornadoVM extension for GraalVM/OpenJDK, or run with our
Docker <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/12_INSTALL_WITH_DOCKER.md">images</a>.</p>
<h2 dir="auto"><a id="user-content-6-additional-resources" aria-hidden="true" href="#6-additional-resources"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>6. Additional Resources</h2>
<p dir="auto"><a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/16_RESOURCES.md">Here</a> you can find videos, presentations, and articles and artefacts describing
TornadoVM and how to use it.</p>
<h2 dir="auto"><a id="user-content-7-academic-publications" aria-hidden="true" href="#7-academic-publications"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>7. Academic Publications</h2>
<p dir="auto">Selected publications and citations can be found <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/assembly/src/docs/14_PUBLICATIONS.md">here</a>.</p>
<h2 dir="auto"><a id="user-content-8-acknowledgments" aria-hidden="true" href="#8-acknowledgments"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>8. Acknowledgments</h2>
<p dir="auto">This work is partially funded by <a href="https://www.intel.com/content/www/us/en/homepage.html" rel="nofollow">Intel corporation</a>
the <a href="https://www.elegant-h2020.eu/" rel="nofollow">EU Horizon 2020 ELEGANT 957286</a> grant. In addition, it has been supported
by <a href="https://e2data.eu" rel="nofollow">EU Horizon 2020 E2Data 780245</a>, the <a href="https://acticloud.eu" rel="nofollow">EU Horizon 2020 ACTiCLOUD 732366</a>,
and <a href="http://apt.cs.manchester.ac.uk/projects/PAMELA/" rel="nofollow">EPSRC PAMELA EP/K008730/1</a>, and AnyScale Apps EP/L000725/1 grants.</p>
<h2 dir="auto"><a id="user-content-9-contributions-and-collaborations" aria-hidden="true" href="#9-contributions-and-collaborations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>9. Contributions and Collaborations</h2>
<p dir="auto">We welcome collaborations! Please see how to contribute to the project in the <a href="https://blog.bridge.watch/beehive-lab/TornadoVM/blob/master/CONTRIBUTING.md">CONTRIBUTING</a> page.</p>
<h3 dir="auto"><a id="user-content-write-your-questions-and-proposals" aria-hidden="true" href="#write-your-questions-and-proposals"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Write your questions and proposals:</h3>
<p dir="auto">Additionally, you can open new proposals on the Github discussions
page:<a href="https://github.com/beehive-lab/TornadoVM/discussions">https://github.com/beehive-lab/TornadoVM/discussions</a></p>
<h3 dir="auto"><a id="user-content-mailing-list" aria-hidden="true" href="#mailing-list"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Mailing List:</h3>
<p dir="auto">A mailing list is also available to discuss TornadoVM related issues: <a href="mailto:tornado-support@googlegroups.com">tornado-support@googlegroups.com</a></p>
<h3 dir="auto"><a id="user-content-collaborations" aria-hidden="true" href="#collaborations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Collaborations:</h3>
<p dir="auto">For Academic &amp; Industry collaborations, please contact <a href="https://www.tornadovm.org/contact-us" rel="nofollow">here</a>.</p>
<h2 dir="auto"><a id="user-content-10-tornadovm-team" aria-hidden="true" href="#10-tornadovm-team"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>10. TornadoVM Team</h2>
<p dir="auto">Visit our <a href="https://tornadovm.org" rel="nofollow">website</a> to meet the <a href="https://www.tornadovm.org/about-us" rel="nofollow">team</a>.</p>
<h2 dir="auto"><a id="user-content-11-licenses" aria-hidden="true" href="#11-licenses"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>11. Licenses</h2>
<p dir="auto">To use TornadoVM, you can link the TornadoVM API to your application which is under the CLASSPATH Exception of GPLv2.0.</p>
<p dir="auto">Each TornadoVM module is licensed as follows:</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>License</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tornado-API</td>
<td><a href="https://github.com/beehive-lab/TornadoVM/blob/master/LICENSE_GPLv2CEl"><img src="https://camo.githubusercontent.com/48c61f406a408b3cc124389b6fed7001c3ecdb337b94df076b60efeadc443b7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076322d626c75652e737667" alt="License: GPL v2" data-canonical-src="https://img.shields.io/badge/License-GPL%20v2-blue.svg"/></a> + CLASSPATH Exception</td>
</tr>
<tr>
<td>Tornado-Runtime</td>
<td><a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/48c61f406a408b3cc124389b6fed7001c3ecdb337b94df076b60efeadc443b7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076322d626c75652e737667" alt="License: GPL v2" data-canonical-src="https://img.shields.io/badge/License-GPL%20v2-blue.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Assembly</td>
<td><a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/48c61f406a408b3cc124389b6fed7001c3ecdb337b94df076b60efeadc443b7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076322d626c75652e737667" alt="License: GPL v2" data-canonical-src="https://img.shields.io/badge/License-GPL%20v2-blue.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Drivers</td>
<td><a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/48c61f406a408b3cc124389b6fed7001c3ecdb337b94df076b60efeadc443b7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076322d626c75652e737667" alt="License: GPL v2" data-canonical-src="https://img.shields.io/badge/License-GPL%20v2-blue.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Drivers-OpenCL-Headers</td>
<td><a href="https://github.com/KhronosGroup/OpenCL-Headers/blob/master/LICENSE"><img src="https://camo.githubusercontent.com/348dda97049423b1052a121e0613b4deb66b7e0d0e4ab512880f1ab1c2f7f17f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542532302d6f72616e67652e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT%20-orange.svg"/></a></td>
</tr>
<tr>
<td>Tornado-scripts</td>
<td><a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/48c61f406a408b3cc124389b6fed7001c3ecdb337b94df076b60efeadc443b7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c25323076322d626c75652e737667" alt="License: GPL v2" data-canonical-src="https://img.shields.io/badge/License-GPL%20v2-blue.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Annotation</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667"><img src="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-red.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Unittests</td>
<td><a href="https://github.com/beehive-lab/TornadoVM/blob/master/LICENSE_APACHE2"><img src="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-red.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Benchmarks</td>
<td><a href="https://github.com/beehive-lab/TornadoVM/blob/master/LICENSE_APACHE2"><img src="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-red.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Examples</td>
<td><a href="https://github.com/beehive-lab/TornadoVM/blob/master/LICENSE_APACHE2"><img src="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-red.svg"/></a></td>
</tr>
<tr>
<td>Tornado-Matrices</td>
<td><a href="https://github.com/beehive-lab/TornadoVM/blob/master/LICENSE_APACHE2"><img src="https://camo.githubusercontent.com/323a77cd6e3a9d8c44e1bed13f0785c9c8be3e916ff273047689ef81b59f0a54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d7265642e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-red.svg"/></a></td>
</tr>
<tr>
<td>JNI Libraries (OpenCL, PTX and LevelZero)</td>
<td><a href="https://mit-license.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/348dda97049423b1052a121e0613b4deb66b7e0d0e4ab512880f1ab1c2f7f17f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542532302d6f72616e67652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-MIT%20-orange.svg"/></a></td>
</tr>
</tbody>
</table>
</article>
        </div></div>
  </body>
</html>
