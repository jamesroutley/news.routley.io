<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ngrok.com/blog-post/how-we-built-ngroks-data-platform">Original</a>
    <h1>How we built ngrok&#39;s data platform</h1>
    
    <div id="readability-page-1" class="page"><div><div fs-richtext-element="rich-text"><p>At ngrok, we manage an extensive data lake with an engineering team of one (me!).</p><p>This article is a look at how we built it, what we learned, as well as some selective deep dives I found interesting enough to be worth sharing in more detail, since they’ll bridge the gap between what people usually understand by the term “data engineering” and how we run data here at ngrok.</p><p>Some of this might even be useful (or, at the very least, interesting!) for your own data platform endeavors, whether your team is big or small.</p><h2>Data we store</h2><p>First of all, as an ngrok user, it&#39;s important to understand what data we store and what we use it for, especially when talking about building a data platform. I want to be as transparent and upfront as possible about this, since talking about storing and processing data will always raise valid privacy concerns.</p><p>My colleague Ari recently wrote in-depth about what <a href="https://ngrok.com/blog-post/data-at-ngrok">personal data of customers we store</a> and you can always find up to date compliance data in our <a href="https://trust.ngrok.com/">Trust Center</a>.</p><h3>What we store</h3><p>But to give you a more concise overview, we generally store and process:</p><ul role="list"><li>Data from our globally distributed Postgres instances, which contains customer data, such as account IDs, user to account mappings, certificates, domains and similar data.</li><li>Data from our metering and usage cluster which tracks the usage of resources.</li><li>Subscription and payment information (<em>excluding</em> credit card information).</li><li>Third-party data, such as support interactions from Zendesk.</li><li>Metadata about movement of events through the various components that make up ngrok&#39;s infrastructure.</li><li>Purpose-built product signals, also as real-time events (more on those two later!).</li></ul><p><strong>Note that we do not store any data about the traffic content flowing through your tunnels—we only ever look at metadata</strong>. While you have the ability to enable full capture mode of all <em>your</em> traffic and can <a href="https://ngrok.com/docs/obs/traffic-inspection/#full-capture-mode">opt in to</a> this service, we never store or analyze this data in our data platform. Instead, we use Clickhouse with a short data retention period in a completely separate platform and strong access controls to store this information and make it available to customers.</p><p>I hope this demystifies our data processing efforts a bit, so we can talk about the engineering side of things.</p><h2>Why data engineering is different at ngrok (and probably not what you think)</h2><p>We hired the first full time data person (it’s me!) in the summer of 2023. Before we filled that position, the data platform was set up by our CTO, Peter. Because of that, our data engineering (DE) team (or rather, our data role) is part of the Office of the CTO and effectively works horizontally across our engineering organization.</p><p>One artifact of having such a small team, our DE work is much closer aligned to holistic backend engineering work than the term &#34;data engineering&#34; often implies. </p><p>While I’m primarily responsible for the Data Platform and all associated services and tooling, I frequently find myself working on the actual ngrok products (as opposed to “just” the data lake). That includes architecture proposals and designs that span multiple teams and services and are mostly tangentially related to the “core” data work. And yes, I do write a fair bit of Go because of it.</p><p>As such, the majority of the data modeling work (i.e., SQL) is done by subject matter experts, which is very different to DE roles in many other organizations. In other words, I write very little SQL on a day to day basis and won’t usually be the person that writes a data model.  </p><p>Within those subject matter experts, some people write reusable, well-structured dbt models, while other people focus on ad hoc analysis (based on these models) via our BI tooling in Superset. It’s worth noting that our entire organization has access to Superset and most data models and sources!</p><p>For instance, our growth team implements a huge amount of our actual data models and knows the business, product, and finance side much better than I do. They’re much better equipped to build sensible, complex, and maintainable data models that properly answer business questions. </p><p>In addition to that, we have a small-but-mighty infrastructure team that owns and operates our core infrastructure, such as Kubernetes, as well as the developer tools that are instrumental in keeping <em>every</em> engineering team (and, of course, ngrok itself!) running smoothly.</p><p>This particular setup—viewing DE as a very technical, general-purpose distributed system SWE discipline and making the people who know best what real-world scenarios they want to model—makes our setup work in practice. </p><h2>Our data platform architecture</h2><p>Now that you know how our (data) engineering org is structured, let’s talk about what we actually built and maintain and how it evolved over time.</p><p>ngrok as a product is a large, distributed, worldwide networking system with very high uptime guarantees, huge traffic volumes, and a large set of inherently eventually consistent (and often, ephemeral) data that can be difficult to interpret. Think about how a TCP connection works, and what steps are involved with making and routing it!</p><p>In other words, even our basic architecture was a bit more complex than “just copy your Postgres database somewhere to query it offline.”</p><h3>ngrok&#39;s data architecture in the past</h3><p>Despite that, our original architecture was utilitarian and relied more heavily on AWS tools than our contemporary architecture, which is very open-source focused. </p><p>Its primary goal was to get the most important data sets we needed—Postgres, important external data, as well as some events—to effectively run finance reporting, abuse, and support.</p><p>On the <strong>batch</strong> ingestion side, we used <a href="https://airbyte.com/">Airbyte</a> open source on Kubernetes to ingest third-party data via their respective APIs. We utilized the <a href="https://ngrok.com/docs/http/oauth/">ngrok OAuth module</a> to do authentication (as we do for all our open-source services that require an ingress controller). </p><p>Airbyte wrote JSON files, where we determined the schema with manual runs of a Glue parser and several Python scripts to create the target schemas, as well as another Glue job to write the target schema as Iceberg.</p><p>At the time, we did not have an orchestrator available and relied on Glue internal schedules. This meant we had no alerting or any integration with on-call tools.</p><p>We used AWS DMS here to get our core Postgres data, writing <code>parquet</code> data to S3. This was a once-a-day batch job.</p><p>On the <strong>streaming</strong> side, we streamed event metadata via <a href="https://aws.amazon.com/firehose/">AWS Firehose</a>, writing JSON data to 2 different S3 locations.</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5ad4d164a1823bfd96722_AD_4nXfYyBtcqFhu7pqpNygGwL3lAUmYOmSD_hHRwR8oHKL2XehTo_cQ2R2-C-a1LRGuAOrLSqZXWPORD-y9K445_E7XQmd6H5pMH141Y-Er0qLnz4SqOmlclRwcDNbwWlYMBsk4IbNyokm2-2BkFLBqMk_UEeI.png" loading="lazy" alt=""/></p></figure><p>For <strong>analytics</strong>, all our data was (and still is) eventually stored as <a href="https://iceberg.apache.org/">Apache Iceberg</a> and generally queried via AWS Athena, although the legacy architecture did have some datasets that were based on raw JSON in the mix. We used AWS Glue as a meta store.</p><p>Our SQL models were actually SQL <em>views</em> directly in Athena, with no version control or lineage, that were directly created in production and queried via <a href="https://preset.io/">Preset</a> (which is the managed cloud version of Superset).</p><h3>Expensive queries and unreasonable models</h3><p>Our eventing system, which is core to understand system behavior, relied on a very pricy AWS Firehose pipeline, as the way we split and organized events required us to both write JSON data (creating hundreds of TiB of data), as well as maintain data platform specific Go code in otherwise purely customer facing services (see the later section on <a href="https://ngrok.com/blog-post/how-we-built-ngroks-data-platform#scaling-apache-flink-scala-and-protobuf-to-650-gbday">Apache Flink, Scala, and Protobuf</a>). </p><p>Some of the data became straight up <strong>impossible to query</strong> (or very expensive), as queries would time-out despite tuning with partitions and other tricks. The entire system was on borrowed time from the start. </p><p>It was also hard to impossible to reason about our models, since we lacked any of dbt‘s (or a comparable tool&#39;s) creature comforts, such as lineage, documentation, version control, auditing, tests, and so on.</p><p>Without expecting you to be able to grok the details here, imagine getting asked why a certain field looks suspicious (if not to say, wrong), at the very end of this lineage tree:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5d7ac250e4813d857a27f_66f5d7a54f68c947eb236d78_fry-lineage-tree(1).png" loading="lazy" alt=""/></p></figure><p>…without having this lineage tree available, of course.</p><p>On a similar vein, not having a central orchestrator, alerting, and auditing for our data jobs was an operational challenge (you can learn more about how we solved those two issues <a href="https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform">here</a>).</p><p>Our data stack was also not integrated very deeply in our Go monorepo and tooling, missing things like Datadog monitors and metrics, good test coverage, or style guides and enforcements via CI (see the <a href="#collaborating-on-data-and-infra-in-a-go-monorepo">Working in a go monorepo</a> section).</p><p>Lastly (at least for the scope of this article), Airbyte and Glue have been a challenge to get right, but we’ll tell you how we did a few <a href="#wrestling-schemas-and-structs-between-airbyte-and-glue">sections from now</a>.</p><h3>ngrok&#39;s data architecture now</h3><p>Our modern data platform is more heavily based around open-source tools we self-host on Kubernetes, dogfooding ngrok, with some AWS native tools in the mix.</p><p>To solve these challenges, a simplified, contemporary view of our current architecture looks like this.</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b443bca0929628977694_AD_4nXeesX1V23GIlojpvnKKGgezRvIO8obStqkECKBYFnORDls08RPlz51sBerc0szjpeEGcrkKIvQaRVxwsxKSX6BwEyEJ1tp8NK4xTSton0K8tnFTbtr-7JdWJVcxKLmU2jaiLSrmM5h6VdUc4nxeMg1H3EqS.png" loading="lazy" alt=""/></p></figure><p>All our <strong>batch</strong> ingestion is now run and orchestrated via Dagster, which I’ve <a href="https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform">written about previously</a>. We still use <a href="https://airbyte.com/">Airbyte</a> and still use ngrok to do so, but write directly to Glue and maintain our schemas as Terraform by querying the Glue API.</p><p>For <strong>streaming</strong> data (which is where most of our volume and complexity comes from), we now run <a href="https://flink.apache.org/">Apache Flink</a> to consume Protobuf messages directly from Kafka, rather than rely on Firehose and internal services. We’ll also cover this in more detail in a bit.</p><p>Our database ingestion is still using DMS, but now mostly relies on streaming writes, which are faster and more efficient (when responding to a support request, you don’t want yesterday’s data!).</p><p>For <strong>analytics</strong>, we heavily rely on dbt now, as well as self-host the open-source version of <a href="https://superset.apache.org/">Apache Superset</a>. We also added a hosted version of the <a href="https://docs.getdbt.com/docs/build/documentation">dbt docs</a>, of course also dogfooded behind an ngrok endpoint.</p><h2>Technical deep-dives and problem-solving</h2><p>While we cannot get into <em>all</em> the details of all the challenges we solved in the past 12 or so months, here are some challenges I found especially interesting as a software engineer.</p><h3>Collaborating on data and infra in a Go monorepo</h3><p>Most of ngrok&#39;s code base is written in Go and exists in a monorepo. We run <a href="https://bazel.build/">Bazel</a> for build tooling, as well as Nix as a package manager. This allows us to have reproducible developer environments, as well as reasonably fast compile, build, and by proxy, CI times.</p><p>As most of our data infrastructure exists in Python and Scala, we had to adapt our workflow to this environment, as it is important to us to integrate the data environment with the rest of the engineering organization at ngrok. </p><p>Speaking from experience, having a completely separate data engineering team or department will eventually result in a fragmented engineering environment, with many bespoke paths that are not applicable to all team members, usually causing huge support and maintenance burdens on individual teams (e.g., maintaining two or more iterations of a CI/CD system).</p><p>Having one deployment system all engineers use is much easier and can be maintained by one infrastructure team:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b45c4af04a7348c9e74c_AD_4nXereSxb1LwbF3gQkWmaRIiaTWnLerkCOe1LQC7UkXb1fHsoBFVsObM61xQOrKuUxci1VFe8EJJifGOqG9Kp4CrkcnYMklYglRboEOYzE4T4y_ZO-mYYaPMB665HXIK_bTfjnVrqSHR5Las7xKwwypB19ZaF.png" loading="lazy" alt=""/></p></figure><p>I find this is often an artifact of the DE roles not being equipped with the necessary knowledge of more generic SWE tools, and general SWEs not being equipped with knowledge of data-specific tools and workflows.</p><p>Speaking of, especially in smaller companies, equipping all engineers with the technical tooling and knowledge to work on all parts of the platform (including data) is a big advantage, since it allows people not usually on your team to help on projects as needed. Standardized tooling is a part of that equation.</p><p>For instance, we have an internal, Go-based developer CLI, called <code>nd</code>, that does a lot of heavy lifting (think “abstract <code>kubectl</code> commands for half a dozen clusters”). We also use it to run diffs between a developer’s branch and expected state, for instance to enforce formatting and code styles. Our CI runners run NixOS. </p><p>So, for our data work, enforcing standards around dbt models involved a custom Nix package for <a href="https://pypi.org/project/shandy-sqlfmt/">shandy-sqlfmt</a>, which we use as a standard for formatting all our dbt models, as well as integration into our <code>nd</code> tool, so developers (as well as CI) have access to <code>nd sql fmt</code>, just as they have <code>nd go fmt</code>.</p><p>While this <em>does</em> involve additional work for me, it ensures data tooling is never the “odd one out” and ramping onto data work (or vice versa) is much less of a cognitive shift.</p><p>Other integrations we&#39;ve added over time include:</p><ul role="list"><li>Bespoke, modern Python tooling (not only for our data tools), such as <code>poetry</code> and <code>ruff</code>, as well as enforcement of style and static analysis via CI.</li><li>Smart <code>sbt</code> caches for Scala, since Scala + Bazel is not something we’ve explored in depth.</li><li>Datadog monitors and metrics, including custom metric interfaces for all our data tools.</li><li>Integration in our on-call tooling, such as Slack alerts, OpsGenie integration, and others.</li><li>Various custom Nix derivations.</li></ul><h3>Wrestling schemas and structs between Airbyte and Glue</h3><p>A more &#34;data specific&#34; challenge we&#39;ve dealt with are complex schemas in Airbyte that often don’t match the actual data or are otherwise incompatible with our query engine, which is something I’m sure a lot of you are familiar with.</p><p>With a team of one, I can’t reasonably write individual jobs for individual tables or sources that handle all corner cases, as we simply have too large and diverse a set of data sources. Myself and others <em>have</em> to rely on code-gen and automated processing. This holds true for all data tools, not just Airbyte.</p><p>Originally, we wrote JSON files to S3, which supported the arbitrary data and schema changes that might happen, and ran AWS Glue <a href="https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html">crawlers</a> on top of these files to detect the schema and create &#34;raw&#34; tables. </p><p>JSON is conceptually nice for this, since it can deal with arbitrary schemas. For example, using <a href="https://docs.airbyte.com/integrations/destinations/s3#parquet">a parquet writer</a> to S3 would rely on the source schema to be 100% accurate and has to deal with an array of <a href="https://docs.airbyte.com/understanding-airbyte/json-avro-conversion">limitations</a>. Glue crawlers, on paper, support table versions and table evolutions.</p><p>But we quickly realized that these crawlers were very unreliable, especially with changing schemas or differences between <code>dev</code> and <code>prod</code>. This resulted in schemas that either couldn&#39;t be queried outright or reported incorrect data.</p><p>We experimented with custom schema detection logic, which gave us more control over parameters like sample size, look back windows, and corner cases, but found that burdensome to manage, despite using existing libraries.</p><p>A part of this was AWS Glue&#39;s odd way of storing <code>structs</code>, which are (deceptively so) depicted as arbitrarily deep JSON objects in the Glue web UI:</p><pre contenteditable="false"><code><span>{
</span><span>  </span><span>&#34;payment_method_configuration_details&#34;</span><span>: {
</span><span>    </span><span>&#34;id&#34;</span><span>: </span><span>&#34;string&#34;</span><span>,
</span><span>    </span><span>&#34;parent&#34;</span><span>: </span><span>&#34;string&#34;</span><span>
</span>  }
}
</code></pre><pre contenteditable="false"><code><span>{
</span><span>  </span><span>&#34;Name&#34;</span><span>: </span><span>&#34;payment_method_configuration_details&#34;</span><span>,
</span><span>  </span><span>&#34;Type&#34;</span><span>: </span><span>&#34;struct&lt;id:string,parent:string&gt;&#34;</span><span>
</span>}
</code></pre><pre contenteditable="false"><code><span>CREATE</span><span> </span><span>EXTERNAL</span><span> </span><span>TABLE</span><span> `...`(
</span><span>  `status` string COMMENT </span><span>&#39;from deserializer&#39;</span><span>, 
</span><span>  `payment_method_configuration_details` struct</span><span>&lt;</span><span>id:string,parent:string</span><span>&gt;</span><span> COMMENT </span><span>&#39;from deserializer&#39;</span><span>, 
</span></code></pre><p>It’s also arguably not a problem we <em>should</em> need to solve.</p><p>So, we settled on using the <a href="https://docs.airbyte.com/integrations/destinations/s3-glue">Airbyte Glue</a> destination connector, which would create the tables <em>directly</em> on Glue based on the <em>reported</em> schema of the source. This eliminates the additional hop (and point of failure) of running a crawler entirely and ensures we get at least a valid Glue table (albeit not necessarily a valid Athena table).</p><p>But it still does not solve the issue of fields being reported incorrectly at times, usually directly by the API. </p><p>For instance, the table <code>stripe.charges</code> cannot be queried due to Athena returning a <code>TYPE_NOT_FOUND: Unknown type: row</code> error. Trying to get a DDL will yield a <code>java.lang.IllegalArgumentException: Error: name expected at the position 204</code>. Keep in mind that this was entirely set up by Airbyte, with no human involvement or custom code run yet.</p><p>Position 204, for those that are curious, looks like this: <code>total_count:decimal(38)&gt;:boolean:struct&lt;&gt;:</code></p><p>This <code>struct&lt;&gt;</code> field can&#39;t be queried in Athena. </p><p>To solve this, we now have a post-processing step that turns each <code>struct</code> field into a custom tree data structure, maps or removes invalid types at arbitrary depth (such as <code>struct&lt;&gt;</code>), and generates a terraform representation of each table, so we get uniform environments between <code>dev</code> and <code>prod</code>.</p><p>It also does an additional step by creating a flattened table that will map each nested field into a flat field with the appropriate type. We do this to maximize compatibility with Iceberg and make queries more ergonomic for users.</p><p>This works by querying the Glue API and some basic DSA. For instance, the following field might present as:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b58a45ad187d0e21c138_AD_4nXeNLfZZI-46_knQ9jRrw4jecER1YNMusOiLSmgMBImh8QrrdxsayanRiTzMd4UZYru3WSFUYy0GOSRWE1VfarzAiLjPTcr2LbJ144LcmsT9pJoM_V1jFg5O_7-fwH3R6X9CXvzktm8qNZW52mvlKKEZ56VA.png" loading="lazy" alt=""/></p></figure><p>But <em>really</em> contain the following data, as reported to Glue (note the object under <code>subscription_items</code>):</p><pre contenteditable="false"><code><span>{
</span><span>  </span><span>&#34;pending_update&#34;</span><span>: {
</span><span>    </span><span>&#34;trial_end&#34;</span><span>: </span><span>&#34;int&#34;</span><span>,
</span><span>    </span><span>&#34;expires_at&#34;</span><span>: </span><span>&#34;int&#34;</span><span>,
</span><span>    </span><span>&#34;trial_from_plan&#34;</span><span>: </span><span>&#34;boolean&#34;</span><span>,
</span><span>    </span><span>&#34;subscription_items&#34;</span><span>: [
</span>      {
<span>        </span><span>&#34;id&#34;</span><span>: </span><span>&#34;string&#34;</span><span>,
</span><span>        </span><span>&#34;price&#34;</span><span>: {
</span><span>          </span><span>&#34;id&#34;</span><span>: </span><span>&#34;string&#34;</span><span>,
</span><span>          </span><span>&#34;type&#34;</span><span>: </span><span>&#34;string&#34;</span><span>,
</span><span>          </span><span>// ...</span><span>
</span>  }
}
</code></pre><p>For instance, a <code>struct&lt;&gt;</code> or simply a field that has a name that’s invalid in Athena, but valid in Glue). Invalid names like <code>&#34;street-name&#34;</code> or <code>&#34;1streetname&#34;</code> need to be escaped with <code>&#34;</code> in Athena, but cannot be used in nested <a href="https://aws.amazon.com/blogs/big-data/create-tables-in-amazon-athena-from-nested-json-and-mappings-using-jsonserde/">fields</a>, which are very common in JSON.</p><p>Airbyte also doesn’t have a <code>bigint</code> type, but Athena does; if a schema reports an Athena <code>Integer</code> type, we generally map it to a <code>bigint</code> to be safe, since a value &gt;= 2^32 will cause Athena queries to fail. We also normalize other types, such as <code>decimal(38)</code>.</p><p>All of this results in parsed (stripped) tree similar to this, with types attached on the nodes:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b5eb4af04a7348cb4928_66f5b5e45c7adfabdfed07ca_blog-ngrok-data-platform-diagram.png" loading="lazy" alt=""/></p></figure><p>Which we can now traverse and mutate, e.g. change names, types, or set deletion tombstones. </p><p>This would yield a field in the &#34;raw&#34; table as:</p><pre contenteditable="false"><code><span>columns {
</span><span>  name    = </span><span>&#34;pending_update&#34;</span><span>
</span><span>  type    = </span><span>&#34;struct&lt;trial_end:bigint,expires_at:bigint,trial_from_plan:boolean,subscription_items:array&lt;struct&lt; //...</span></code></pre><pre contenteditable="false"><code><span>columns {
</span><span>    name    = </span><span>&#34;pending_update_billing_cycle_anchor&#34;</span><span>
</span><span>    type    = </span><span>&#34;bigint&#34;</span><span>
</span>    parameters = {
<span>      </span><span>&#34;iceberg.field.current&#34;</span><span>: </span><span>&#34;true&#34;</span><span>,
</span><span>      </span><span>&#34;iceberg.field.id&#34;</span><span>: </span><span>&#34;67&#34;</span><span>,
</span><span>      </span><span>&#34;iceberg.field.optional&#34;</span><span>: </span><span>&#34;true&#34;</span><span>
</span>    }
  }
</code></pre><ul role="list"><li>We can rely on a provided schema by the source as much as possible by directly writing from Airbyte to Glue.</li><li>We have generated code that we can version control for both the raw as well as the target table.</li><li>We eliminate any potential differences between <code>dev</code> and <code>prod</code>, since we rely on the sources&#39; reported schema.</li></ul><p>And, perhaps most importantly, it makes this process manageable for our specific team setup. Our next step is to terraform the entire Airbyte process.</p><p>While this is arguably just as complicated as running custom JSON schema parsers, we found that investing the time into building a proper data structure once and adjusting the ruleset where needed down the line was very much worth it, rather than trying to beat Glue crawlers or external JSON parser libraries into submission.</p><h3>Scaling Apache Flink, Scala, and Protobuf to 650 GB/day</h3><p>Another technically challenging, albeit interesting component, is our streaming integration with our core codebase.</p><p>We stream a subset of our Protobuf messages to Apache Iceberg via Kafka and Flink and make them available to query—in fact, it&#39;s one of our core sources to fight abuse (more on that in a second). Our Flink jobs are all written in Scala 3, relying on <a href="https://github.com/flink-extended/flink-scala-api"><code>flink-extended/flink-scala-api</code></a>.</p><p>Between our regular services, we interact via GRPC and talk Protobuf, which perhaps isn&#39;t the most common format in the data world. However, hooking our data processing tools directly into Protobuf has several advantages:</p><ul role="list"><li>Protobuf&#39;s schema evolution is one-directional; Apache Iceberg actually supports a lot more evolutions than Protobuf does, making sure our schemas stay in sync with the business&#39; schemas</li><li>Old messages are always compatible with newer ones, meaning we never run into distributed ordering messages (i.e., processing a message with an old schema for a new table)</li><li>Protobuf, albeit oddly opinionated, is relatively straightforward and has great Scala support via <a href="https://scalapb.github.io/">scalapb</a></li><li>It&#39;s a very efficient format on the wire, making it so that our pipelines can process tens or hundreds of thousands of events per second</li></ul><p>Our main job consumes an average of ~9,000-15,000 events/s and at about ~691 bytes per message. Over time, this works out to roughly ~1,000,000,000 events or ~650 GB per day, split across ~55 message types, each with a different schema. Our other, more specialized streaming jobs are in the lower millions a day.</p><p>From a technical perspective, this was a fun challenge to solve. We achieve the entire process by, in essence, sending a wrapper message called <code>SubscriptionEvent</code> that contains an <code>EventType</code> (an <code>enum</code>) that describes the content of the wrapper and a <code>[]byte</code> field that contains the actual target Protobuf (one of the aforementioned 55 message types). Newer pipelines skip that wrapper message, but this system predates the data platform.</p><ol role="list"><li>We generate all Protobuf Scala classes with some custom mappings to ensure all types are compatible with Iceberg (<code>one-ofs</code>, for instance, are not!), using <code>scalapb</code>.</li><li>We generate a slightly customized <code>avro</code> schema (mostly to add metadata), <code>serializers</code>, <code>deserializers</code>, and so on, for each target message and store them as Scala objects (so this isn’t done at runtime).</li></ol><p>In the pipeline:</p><ol role="list"><li>We read the raw <em>wrapper</em> message from Kafka.</li><li>We split it by the <code>EventType</code> and parse the <em>target</em> Protobuf type by parsing the <code>[]byte</code> field on the message and yield an output tag to route messages by type.</li><li>We use previously generated <code>avro</code> schema and use the <code>FlinkWriter</code> for Iceberg to write the data, based on the job&#39;s checkpoint interval.</li></ol><p>Or, in Scala terms:</p><pre contenteditable="false"><code><span>pipeline[</span><span>A</span><span> &lt;: </span><span>GeneratedMessage</span><span>: </span><span>TypeInformation</span><span> : </span><span>EventTyper</span><span> : </span><span>SerializableTimestampAssigner</span><span> : </span><span>ProtoHandler</span><span>]</span></code></pre><p>One of the key elements in this is a typeclass called <code>ProtoHandle</code> that provides a <code>ProtoHandle</code>:</p><pre contenteditable="false"><code><span>trait</span><span> </span><span>ProtoHandle</span><span>[
</span><span>    </span><span>A</span><span>,
</span><span>    </span><span>B</span><span> &lt;: </span><span>GeneratedMessage</span><span>: </span><span>EventTyper</span><span>: </span><span>AvroMeta</span><span>
</span><span>] </span><span>extends</span><span> </span><span>Serializable</span><span> </span><span>{
</span><span>  </span><span>type</span><span> </span><span>ValueType</span><span> </span><span>= </span><span>A</span><span>
</span><span>  </span><span>def</span><span> </span><span>derivedSchema</span><span>: </span><span>AvroSchema</span><span>
</span><span>  </span><span>protected</span><span> </span><span>def</span><span> </span><span>encoder</span><span>: </span><span>MetaRecordEncoder</span><span>[</span><span>A</span><span>]
</span><span>  </span><span>def</span><span> </span><span>encode</span><span>(msg: </span><span>A</span><span>, schema: </span><span>AvroSchema</span><span>, metadata: </span><span>AvroMetadata</span><span>): </span><span>Record</span><span>
</span><span></span><span>// …</span><span>
</span>  }
</code></pre><p>For efficiency reasons by front loading a lot of heavily lifting to compile time, we code generate all known <code>ProtoHandle</code>s based on the <code>enum</code>:</p><pre contenteditable="false"><code><span>case</span><span> </span><span>object</span><span> </span><span>CAComp</span><span> </span><span>extends</span><span> </span><span>CompanionComp</span><span>[</span><span>CA</span><span>] </span><span>{
</span><span>  </span><span>private</span><span> </span><span>val</span><span> </span><span>T</span><span> = </span><span>CA</span><span>
</span><span>  </span><span>private</span><span> </span><span>val</span><span> coreSchema: </span><span>Schema</span><span> = </span><span>AvroSchema</span><span>[</span><span>CA</span><span>]
</span><span>  </span><span>private</span><span> </span><span>val</span><span> schema: </span><span>Schema</span><span> = coreSchema.withMetadata
</span><span>  </span><span>private</span><span> </span><span>val</span><span> enc: </span><span>AvroEncoder</span><span>[</span><span>CA</span><span>] = </span><span>AvroEncoder</span><span>[</span><span>CA</span><span>]
</span><span>  </span><span>private</span><span> </span><span>val</span><span> ti: </span><span>TypeInformation</span><span>[</span><span>CA</span><span>] = deriveTypeInformation[</span><span>CA</span><span>]
</span><span>  </span><span>override</span><span> </span><span>val</span><span> handle: </span><span>ProtoHandle</span><span>[</span><span>CA</span><span>, </span><span>SubscriptionEvent</span><span>] = </span><span>SubscriptionEventProtoHandle</span><span>(
</span><span>    </span><span>T</span><span>.messageCompanion,
</span>    schema,
    enc,
    ti
  )
}
</code></pre><p>We now have one correct, working <code>avro</code> schema + encoder for each possible Protobuf message.</p><blockquote>Note: Some of the type signatures look a bit <em>wild</em>—that&#39;s an artifact of the nested Protobufs  and can only be partially simplified.</blockquote><p>We can then expose this mapping as <code>Map[FlinkEventTag, ProtoHandle[_, SubscriptionEvent]]</code> to the job.</p><p>For each mapping, we can now:</p><ul role="list"><li>Create the table or update its schema during the job&#39;s startup by relying on Iceberg&#39;s schema evolution.</li><li>Add a sink dynamically to a <code>Ref</code> of an incoming data stream.</li></ul><p>Or, expressed in code:</p><pre contenteditable="false"><code><span>trait</span><span> </span><span>FlinkWriter</span><span>[</span><span>A</span><span>, </span><span>B</span><span>: </span><span>IcebergTableNamer</span><span>] </span><span>extends</span><span> </span><span>Serializable</span><span> </span><span>{
</span><span>  </span><span>// Builds/updates tables and returns a cached map of all remote schemas</span><span>
</span><span>  </span><span>def</span><span> </span><span>buildTablesAndCacheSchemas</span><span>(): </span><span>Map</span><span>[</span><span>B</span><span>, </span><span>AvroSchema</span><span>]
</span><span>  </span><span>// Sink assigner. Mutates the DataStream[A] ref</span><span>
</span><span>  </span><span>def</span><span> </span><span>addSinksToStream</span><span>(
</span><span>      cfg: </span><span>Config</span><span>,
</span><span>      schemas: </span><span>Map</span><span>[</span><span>B</span><span>, </span><span>AvroSchema</span><span>],
</span><span>      env: </span><span>Ref</span><span>[</span><span>DataStream</span><span>[</span><span>A</span><span>]]
</span><span>  ): </span><span>List</span><span>[</span><span>DataStreamSink</span><span>[</span><span>Void</span><span>]]
</span>}
</code></pre><blockquote>Note: We do not (yet!) use an effect system and <code>Ref</code> is just a hint that we mutate a reference in a function: <code>type Ref[A] = A</code>.</blockquote><h3>Fighting abuse with meta signals</h3><p>One of the ways we actually use this data is to understand, fight, and ultimately prevent abusive behavior like the <a href="https://www.helpnetsecurity.com/2024/08/28/pioneer-kitten-iranian-hackers-partnering-with-ransomware-affiliates/">state-sponsored Pioneer Kitten group</a>.</p><p>While a lot of our processes around abuse detection are automated, some require human intervention. </p><p>Oftentimes, we’ll get abuse reports (via abuse@ngrok.com) and need to verify that these are accurate before we take action (such as banning an account). To do that, we can verify the reported abusive events match a certain account’s behavior on our platform.</p><p>If we suspect IP <code>198.51.100.1</code> to have hosted a phishing scam on port <code>443</code> via URL <code>anexampleofabusewedontwant.ngrok.app</code> on 2024-09-01, we can query our metadata similar to this:</p><pre contenteditable="false"><code><span>select</span><span> </span><span>case</span><span>
</span><span>    </span><span>when</span><span> event_type </span><span>=</span><span> </span><span>&#39;ENDPOINT_CREATED&#39;</span><span> </span><span>then</span><span> </span><span>&#39;created&#39;</span><span>
</span><span>    </span><span>when</span><span> event_type </span><span>=</span><span> </span><span>&#39;ENDPOINT_DELETED&#39;</span><span> </span><span>then</span><span> </span><span>&#39;deleted&#39;</span><span> </span><span>else</span><span> </span><span>&#39;unknown&#39;</span><span>
</span><span>  </span><span>end</span><span> </span><span>as</span><span> action,
</span>  account_id,
  event_timestamp,
  url,
  geo_location
<span></span><span>from</span><span> meta_events__audit_event_endpoint e
</span><span></span><span>where</span><span> account_id </span><span>=</span><span> </span><span>&#39;bad_actor_id&#39;</span><span> </span><span>and</span><span> </span><span>-- … other filters</span></code></pre><p>On a similar note, in the event an account gets banned incorrectly and reaches out to our support team, they can query similar tables to do the same report in reverse and unban users. </p><h2>Build your own ngrok data platform (or work on ours!)</h2><p>While there are a lot of topics we didn&#39;t cover in this article, I hope it provided both a good high-level overview about data engineering work at ngrok, as well as some details on specific challenges we faced and solved.</p><p>To do your own digging on ngrok data, try exploring <a href="https://ngrok.com/docs/api/resources/event-subscriptions/">event subscriptions</a> or <a href="https://ngrok.com/docs/obs/traffic-inspection/">Traffic Inspector</a> to get insight into your own traffic data flowing through ngrok.</p><p>Or, if you prefer to work on and with our actual data platform, we’re currently <a href="https://boards.greenhouse.io/ngrokinc/jobs/5314175004">hiring a Senior Software Engineer, Trust &amp; Abuse</a>! </p><p>We’d love to chat about what additional challenges and improvement you’d want to dig into as an ngrokker. And, as always, you can ask questions about our data platform and beyond on our <a href="https://github.com/ngrok/ngrok">community repo</a>.</p></div></div></div>
  </body>
</html>
