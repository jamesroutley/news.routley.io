<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms.html">Original</a>
    <h1>Codifying a ChatGPT workflow into a malleable GUI</h1>
    
    <div id="readability-page-1" class="page"><p>Wouldn&#39;t it be neat if you could use LLMs to create little personal utility apps as the need arises? Here&#39;s a story where I did just that...</p><div><p>In my previous post, <a href="https://unum-cloud.github.io/2023/03/25/llm-end-user-programming.html">Malleable software in the age of LLMs</a>, I laid out a theory for how LLMs might enable a new era of people creating their own personal software:</p>

<blockquote>
<p>I think it‚Äôs likely that soon all computer users will have the ability to develop small software tools from scratch, and to describe modifications they‚Äôd like made to software they‚Äôre already using.</p>

<p>In other words, LLMs will represent a step change in tool support for end-user programming: the ability of normal people to fully harness the general power of computers without resorting to the complexity of normal programming. Until now, that vision has been bottlenecked on turning fuzzy informal intent into formal, executable code; now that bottleneck is rapidly opening up thanks to LLMs.</p>
</blockquote>

<p>Today I‚Äôll <strong>share a real example where I found it useful to build custom personal software with an LLM</strong>. Earlier this week, I used GPT-4 to code an app that helps me draft text messages in English and translate them to Japanese. The basic idea: I paste in the context for the text thread and write my response in English; I get back a translation into Japanese. The app has a couple other neat features, too: I can drag a slider to tweak the formality of the language, and I can highlight any phrase to get a more detailed explanation.</p>

<p>The whole thing is ugly and thrown together in no time, but it has exactly the features I need, and I‚Äôve found it quite useful for planning an upcoming trip to Japan.</p>

<p><img src="https://unum-cloud.github.io/images/article_images/texting-app-teaser.png?1690475570" alt=""/></p>

<p>The app uses the GPT-4 API to do the actual translations. So there are two usages of LLMs going on here: I used an LLM to code the app, and then the app also uses an LLM when it runs to do the translations. Sorry if that‚Äôs confusing, 2023 is weird.</p>

<p>You may ask: why bother making an app for this? Why not just ask ChatGPT to do the translations? I‚Äôm glad you asked‚Äîthat‚Äôs what this post is all about! In fact, I started out doing these translations in ChatGPT, but <strong>I ended up finding this GUI nicer to use than raw ChatGPT for several reasons</strong>:</p>

<ul>
<li>It encodes a prescriptive workflow so I don‚Äôt need to fuss with prompts as much.</li>
<li>It offers convenient direct manipulation affordances like text boxes and sliders.</li>
<li>It makes it easier to share a workflow with other people.</li>
</ul>

<p>(Interestingly, these are similar to the reasons that so many startups are building products wrapping LLM prompts‚Äîthe difference here is that I‚Äôm just building the tool for myself, and not trying to make a product.)</p>

<p>A key point is that making this personal GUI is only worth it because <strong>GPT also lowers the cost of making and iterating on the GUI!</strong> Even though I‚Äôm a programmer, I wouldn‚Äôt have made this tool without LLM support. It‚Äôs not only the time savings, it‚Äôs also the fact that I don‚Äôt need to turn on my ‚Äúprogrammer brain‚Äù to make these tools; I can think at a higher level and let the LLM handle the details.</p>

<p>There are also tradeoffs to consider when moving from ChatGPT into a GUI tool: the resulting workflow is more rigid and less open-ended than a ChatGPT session. In a sense this is the whole point of a GUI. But the GUI isn‚Äôt necessarily as limiting as it might seem, because remember, it‚Äôs <em>malleable</em>‚ÄîI built it myself using GPT and can quickly make further edits. This is a very different situation that using a fixed app that someone else made! Below I‚Äôll share one example of how I edited this tool on the fly as I was using it.</p>

<p>Overall I think this experience suggests an intriguing workflow of <strong>codifying a ChatGPT workflow into a malleable GUI</strong>: starting out with ChatGPT, exploring the most useful way to solve a task, and then once you‚Äôve landed on a good approach, codifying that approach in a GUI tool that you can use in a repeatable way going forward.</p>

<p>Alright, on to the story of how this app came about.</p>

<hr/>

<h2 id="chatgpt-is-a-good-translator-usually">ChatGPT is a good translator (usually üôÉ)</h2>

<p>I‚Äôm going on a trip to Japan soon and have been on some text threads where I need to communicate in Japanese. I grew up in Japan but my writing is rusty and painfully slow these days. One particular challenge for me is using the appropriate level of formality with extended family and other family acquaintances‚ÄîI have fluent schoolyard Japanese but the nuances of formal grown-up Japanese can be tricky.</p>

<p>I started using ChatGPT to make this process faster by asking it to produce draft messages in Japanese based on my English input. I quickly realized <strong>there are some neat benefits to ChatGPT vs. a traditional translation app</strong>. I can give it the full context of the text thread so it can incorporate that into its translation. I can steer it with prompting: asking it to tweak the formality or do a less word-for-word translation. I can ask follow-up questions about the meaning of a word. These capabilities were all gamechangers for this task; they really show why smart chatbots can be so useful!</p>

<p>You may be wondering: how good were the translations? I‚Äôd say: good enough to be spectacularly useful to me, <em>given that I can verify and edit</em>. Often they were basically perfect. Sometimes they were wrong in huge, hilarious ways‚Äîflipping the meaning of a sentence, or swapping the name of a train station for another one (sigh, LLMs‚Ä¶).</p>

<p>In practice these mistakes didn‚Äôt matter too much though. I‚Äôm slow at writing in Japanese but can read basic messages easily, so I just fix the errors and they aren‚Äôt dealbreakers. <strong>When creation is slow and verification is fast, it‚Äôs a sweet spot for using an LLM.</strong></p>

<h2 id="honing-the-workflow">Honing the workflow</h2>

<p>As I translated more messages and saw ways that the model failed, I developed some little prompting tricks that seemed to produce better translations. Things like this:</p>

<blockquote>
<p>Below is some context for a text message thread:</p>

<p>‚Ä¶paste thread‚Ä¶</p>

<p>Now translate my message below to japanese. make it sound natural in the flow of this conversation. don‚Äôt translate word for word, translate the general meaning.</p>

<p>‚Ä¶write message‚Ä¶</p>
</blockquote>

<p>I also learned some typical follow-up requests I would often make after receiving the initial translation: things like asking to adjust the formality level up or down.</p>

<p>Once I had landed on these specific prompt patterns, it made my interactions more scripted. Each time I would need to dig up my prompt text for this task, copy-paste it in, and fill in the blanks for this particular translation. When asking follow-up questions I‚Äôd also copy-paste phrasings from previous chats that had proven successful. <strong>At this point it didn‚Äôt feel like an open-ended conversation anymore; it felt like I was tediously executing a workflow made up of specific chat prompts.</strong></p>

<p>I also found myself wanting to have more of a feeling of a solid tool that I could return to. ChatGPT chats feels a bit amorphous and hard to return to: where do I store my prompts? How do I even remember what useful workflows I‚Äôve come up with? I basically wanted a window I could pop open and get a quick translation.</p>

<h2 id="making-a-gui-with-gpt">Making a GUI with GPT</h2>

<p>So, I asked GPT-4 to build me a GUI codifying this workflow. The app is a frontend-only React.js web app. It‚Äôs hosted on <a href="https://replit.com/">Replit</a>, which makes it easy to spin up a new project in one click and then share a link with people. (You can see the current code <a href="https://replit.com/@GeoffreyLitt/TextMessageTranslator#src/App.jsx">here</a> if you‚Äôre curious.) I just copy-pasted the GPT-generated code into Replit.</p>

<p><img src="https://unum-cloud.github.io/images/article_images/texting-replit.png?1690475570" alt=""/></p>

<p>The initial version of the app was very simple: it basically just accepted a text input and then made a request to the GPT-4 API asking for a natural-sounding translation. The early designs generated by ChatGPT were super primitive:</p>

<p><img src="https://unum-cloud.github.io/images/article_images/early-designs.png?1690475570" alt=""/></p>

<p>Asking it for a ‚Äúprofessional and modern‚Äù redesign helped get the design looking passable. I then asked GPT to add a <em>formality slider</em> to the app. The new app requests three translations of varying formality, and then lets the user drag a slider to instantly choose between them üòé</p>

<video autoplay="" loop="" controls="controls" preload="auto" muted="muted" data-video="0" type="video/mp4" src="/images/article_images/text-app.mp4" width="100%"></video>

<p>GPT-4 did most of the coding of the UI. I didn‚Äôt measure how long it took, but subjectively, the whole thing felt pretty effortless; <strong>it felt more like asking a friend to build an app for me than building it myself</strong>, and I never engaged my detailed programmer brain. I still haven‚Äôt looked very closely at the code. GPT generally produced good results on every iteration. At one point it got confused about how to call the OpenAI API, but pasting in some recent documentation got it sorted out. I‚Äôve included some of the coding prompts I used at the <a href="#appendix">bottom of this post</a> if you‚Äôre curious about the details.</p>

<p>At the same time, it‚Äôs important to note that <strong>my programming background did substantially help the process along</strong> and I don‚Äôt think it would have gone that well if I didn‚Äôt know how to make React UIs. I was able to give the LLM a detailed spec, which was natural for me to write. For example: I suggested storing the OpenAI key as a user-provided setting in the app UI rather than putting it in the code, because that would let us keep the app frontend-only. I also helped fix some minor bugs.</p>

<p>I do believe it‚Äôs possible to get to the point where an LLM can support non-programmers in building custom GUIs (and that‚Äôs in fact one of my main research goals at the moment). But it‚Äôs a much harder goal than supporting programmers, and will require a lot more work on tooling. More on this later.</p>

<h2 id="iterating-on-the-fly">Iterating on the fly</h2>

<p>A few times I noticed that the Japanese translations included phrases I didn‚Äôt understand. Once this need came up a few times, I decided to add it as a feature in my GUI. <strong>I asked GPT to modify the code so that I can select a phrase and click a button to get an explanation in context:</strong></p>

<p><img src="https://unum-cloud.github.io/images/article_images/explain-phrase.png?1690475570" alt=""/></p>

<p>This tight iteration loop felt awesome. Going from wanting the feature to having it in my app was accomplished in minutes with very little effort. This shows the benefit of having a <em>malleable GUI</em> which I control and I can quickly edit using an LLM. My feature requests aren‚Äôt trapped in a feedback queue, I can just build them for myself. It‚Äôs not the best-designed interaction ever, but it gets the job done.</p>

<p>I‚Äôve found that having the button there encourages me to ask for explanations more often. Before, when I was doing the translations in ChatGPT, I would need to explicitly think to write a follow-up message asking for an explanation. Now I have a button reminding me to do it, and the button also uses a high-quality prompt that I‚Äôve developed.</p>



<p>My brother asked me to try the tool. I sent him the Replit link and he was able to use it.</p>

<p>I think sharing a GUI is probably way more effective than trying to share a complex ChatGPT workflow with various prompts patched together. The UI encodes what I‚Äôve learned about doing this particular task effectively, and provides clear affordances that anyone can pick up quickly.</p>

<h2 id="from-chatbot-to-gui">From chatbot to GUI</h2>

<p>What general lessons can we take away from my experience here? I think it gestures at two big ideas.</p>

<p>The first one is that <strong>chatbots are not always the best interface for a task</strong>, even one like translation that involves lots of natural language and text. Amelia Wattenberger wrote a <a href="https://wattenberger.com/thoughts/boo-chatbots">great piece</a> explaining some of the reasons. It‚Äôs worth reading the whole thing, but here‚Äôs a key excerpt about the value of affordances:</p>

<blockquote>
<p>Good tools make it clear how they should be used. And more importantly, how they should not be used. If we think about a good pair of gloves, it‚Äôs immediately obvious how we should use them. They‚Äôre hand-shaped! We put them on our hands. And the specific material tells us more: metal mesh gloves are for preventing physical harm, rubber gloves are for preventing chemical harm, and leather gloves are for looking cool on a motorcycle.</p>

<p>Compare that to looking at a typical chat interface. The only clue we receive is that we should type characters into the textbox. The interface looks the same as a Google search box, a login form, and a credit card field.</p>
</blockquote>

<p>This principle clearly holds when designing a product that other people are going to use. But perhaps surprisingly, in my experience, <strong>affordances are actually useful even when designing a tool for myself!</strong> Good affordances can help my future self remember how to use the tool. The ‚Äúexplain phrase‚Äù button reminds me that I should ask about words I don‚Äôt know.</p>

<p>I also find that making a UI makes a tool more memorable. My custom GUI is a visually distinctive artifact that lives at a URL; this helps me remember that I have the tool and can use it. Having a UI makes my tool feel more like a reusable artifact than a ChatGPT prompt.</p>

<p>Now, it‚Äôs not quite as simple as ‚ÄúGUI good, chatbot bad&#34;‚Äîthere are tradeoffs. For my translation use case, I found ChatGPT super helpful for my initial explorations. The open-endedness of the chatbot gave it a huge leg up over Google Translate, a more traditional application with more limited capabilities and clearer affordances. I was able to explore a wide space of useful features and find the ones that I wanted to keep using.</p>

<p>I think this suggests a natural workflow: <strong>start in chat, and then codify a UI if it‚Äôs getting annoying doing the same chat workflow repeatedly.</strong></p>

<p>By the way, one more thing: there are obviously many other visual affordances to consider besides the ones I used in this particular example. For example, here‚Äôs another example of a GPT-powered GUI tool I built a couple months ago, where I can drag-and-drop in a file and see useful conversions of that file into different formats:</p>

<blockquote><p lang="en" dir="ltr">I wanted to convert a JSON file of a chat transcript into nice markdown text for sharing w/ people‚Ä¶</p>‚Äî Geoffrey Litt (@geoffreylitt) <a href="https://twitter.com/geoffreylitt/status/1654246096212992004?ref_src=twsrc%5Etfw">May 4, 2023</a></blockquote> 



<p>Another takeaway: <strong>it feels great to use a tiny GUI made just for my own needs</strong>. It does only what I want it to do, nothing more. The design isn‚Äôt going to win any awards or get VC funding, but it‚Äôs good enough for what I want. When I come across more things that the app needs to do, I can add them.</p>

<p>Robin Sloan has this delightful idea that <a href="https://www.robinsloan.com/notes/home-cooked-app/">an app can be a home-cooked meal</a>:</p>

<blockquote>
<p>When you liberate programming from the requirement to be professional and scalable, it becomes a different activity altogether, just as cooking at home is really nothing like cooking in a commercial kitchen. I¬†can report to you: not only is this different activity rewarding in almost exactly the same way that cooking for someone you love is rewarding, there‚Äôs another feeling, too, specific to this realm. I¬†have struggled to find words for this, but/and I¬†think it might be the crux of the whole¬†thing:</p>

<p>This messaging app I¬†built for, and with, my family, it won‚Äôt change unless we want it to change. There will be no sudden redesign, no flood of ads, no pivot to chase a userbase inscrutable to us. It might go away at some point, but that will be our decision. What is this feeling? Independence? Security? Sovereignty?</p>

<p>Is it simply‚Äâ‚Ä¶‚Äâthe feeling of being¬†home?</p>
</blockquote>

<p>Software doesn‚Äôt always need to be mass-produced like restaurant food, it can be produced intimately at small scale. My translator app feels this way to me.</p>

<p>In this example, using GPT-4 to code and edit the app is what enabled the feeling of malleability for me. It feels magical describing an app and having it appear on-screen within seconds. Little React apps seem to be the kind of simple code that GPT-4 is good at producing. You could even argue that it‚Äôs &#34;just regurgitating other code it‚Äôs already seen‚Äù, but I don‚Äôt care‚Äîit made me the tool that I wanted.</p>

<p>I‚Äôm a programmer and I could have built this app manually myself without too much trouble. And yet, I don‚Äôt think I would have. The LLM is an order of magnitude faster than me at getting the first draft out and producing new iterations, this makes me much more likely to just give it a shot. This reminds me of how Simon Willison says that <a href="https://simonwillison.net/2023/Mar/27/ai-enhanced-development/">AI-enhanced development makes him more ambitious with his projects</a>:</p>

<blockquote>
<p>In the past I‚Äôve had plenty of ideas for projects which I‚Äôve ruled out because they would take a day‚Äîor days‚Äîof work to get to a point where they‚Äôre useful. I have enough other stuff to build already!</p>

<p>But if ChatGPT can drop that down to an hour or less, those projects can suddenly become viable.</p>

<p>Which means I‚Äôm building all sorts of weird and interesting little things that previously I wouldn‚Äôt have invested the time in.</p>
</blockquote>

<p>Simon‚Äôs description applies perfectly to my example.</p>

<p>It‚Äôs not just about the initial creation, it‚Äôs also about the fast iteration loop. I discussed the possibility of LLMs updating a GUI app in my <a href="https://unum-cloud.github.io/2023/03/25/llm-end-user-programming.html">previous post</a>:</p>

<blockquote>
<p>Next, consider LLMs applied to the app model. <strong>What if we started with an interactive analytics application, but this time we had a team of LLM developers at our disposal?</strong> As a start, we could ask the LLM questions about how to use the application, which could be easier than reading documentation.</p>

<p>But more profoundly than that, the LLM developers could go beyond that and <em>update</em> the application. When we give feedback about adding a new feature, our request wouldn‚Äôt get lost in an infinite queue. They would respond immediately, and we‚Äôd have some back and forth to get the feature implemented. Of course, the new functionality doesn‚Äôt need to be shipped to everyone; it can just be enabled for our team. This is economically viable now because we‚Äôre not relying on a centralized team of human developers to make the change.</p>

<p><img src="https://unum-cloud.github.io/images/article_images/llm-eup/llm-app.png?1690475570" alt=""/></p>
</blockquote>

<p>It simply feels good to be using a GUI app, have an idea for how it could be different, and then have that new version running within seconds.</p>

<p>There‚Äôs a caveat worth acknowleding here: the story I shared in this post only worked under specific conditions. The app I made is extremely simple in functionality; a more complex app would be much harder to modify.</p>

<p>And I‚Äôm pretty confident that the coding workflow I shared in this post only worked because I‚Äôm a programmer. The LLM makes me much, much faster at building these simple kinds of utilities, but my programming knowledge still feels essential to keeping the process running. I‚Äôm writing fairly detailed technical specs, I‚Äôm making architectural choices, I‚Äôm occasionally directly editing the code or fixing a bug. The app is so small and simple that it‚Äôs easy for me to keep up with what‚Äôs going on.</p>

<p>I yearn for non-programmers to also experience software this way, as a malleable artifact they can change in the natural course of use. LLMs are clearly a big leap forward on this dimension, but there‚Äôs also a lot of work ahead. We‚Äôll need to find ways for LLMs to work with non-programmers to specify intent, to help them understand what‚Äôs going on, and to fix things when they go wrong.</p>

<p>I‚Äôm optimistic that a combination of better tooling and improved models can get us there, at least for simpler use cases like my translator tool. I guess there‚Äôs only one way to find out ü§ì (<a href="https://buttondown.email/geoffreylitt">Subscribe to my email newsletter</a> if you want to follow along with my research in this area.)</p>

<hr/>

<h2 id="recently">Recently‚Ä¶</h2>

<p>In the past few months I‚Äôve given a couple talks relevant to the themes in this post.</p>

<p>In April I spoke at <a href="https://www.causalislands.com/">Causal Islands</a> about <a href="https://www.inkandswitch.com/potluck/">Potluck</a>, a programmable notes prototype I worked on with Max Schoening, Paul Shen, and Paul Sonnentag at Ink &amp; Switch. In my talk I share a bunch of demos from our published essay, but I also show some newer demos of integrating LLMs to help author spreadsheets. (The embed below will jump you right to the LLM demos)</p>

<iframe width="100%" height="315" src="https://www.youtube.com/embed/bJ3i4K3hefI?start=1359" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>Also: a couple weeks ago, I presented my PhD thesis defense at MIT! I gave a talk called Building Personal Software with Reactive Databases. I talk about what makes spreadsheets great, and show a few projects I‚Äôve worked on that aim to make it easier to build software using techniques from spreadsheets and databases.</p>

<iframe width="100%" height="315" src="https://www.youtube.com/embed/CPKsS3SJU4o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<hr/>



<p>If you‚Äôre interested in diving deeper into ways of interacting with LLMs besides chatbots, I strongly recommend the following readings:</p>

<ul>
<li><a href="https://idl.cs.washington.edu/files/2019-AgencyPlusAutomation-PNAS.pdf">Agency plus automation: Designing artificial intelligence into interactive systems</a> by Jeffrey Heer</li>
<li><a href="https://magrawala.substack.com/p/unpredictable-black-boxes-are-terrible">Unpredictable Black Boxes are Terrible Interfaces</a> by Maneesh Agrawala</li>
<li><a href="https://dl.acm.org/doi/10.1145/267505.267514">Direct manipulation vs. interface agents</a>, a 1997 debate between Ben Shneiderman and Pattie Maes</li>
</ul>

<p>And for a more abstract angle on the example in this post, check out my previous post, <a href="https://unum-cloud.github.io/2023/03/25/llm-end-user-programming.html">Malleable software in the age of LLMs</a>!</p>

<hr/>

<h2 id="appendix-prompts">Appendix: prompts</h2>

<p>Here are some of the prompts I used to make the translator app.</p>

<p>First, my general system prompt for UI coding:</p>

<blockquote>
<p>You are a helpful AI coding assistant. Make sure to follow the user‚Äôs instructions precisely and to the letter. Always reason aloud about your plans before writing the final code.</p>

<p>Write code in ReactJS. Keep the whole app in one file. Only write a frontend, no backend.</p>

<p>If the specification is clear, you can generate code immediately. If there are ambiguities, ask key clarifying questions before proceeding.</p>

<p>When the user asks you to make edits, suggest minimal edits to the code, don‚Äôt regenerate the whole file.</p>
</blockquote>

<p>Initial prompt for the texting app:</p>

<blockquote>
<p>I‚Äôd like you to make me an app that helps me participate in a text message conversation in Japanese by using an LLM to translate. Here‚Äôs the basic idea:</p>

<ul>
<li>I paste in a transcript of a text message thread into a box</li>
<li>I write the message I want to reply with (in english) into a different box</li>
<li>I click a button</li>
<li>the app shows me a Japanese translation of my message as output; there‚Äôs a copy button so i can copy-paste it easily.</li>
<li>the app talks to openai gpt-4 to do the translation. the prompt can be something like ‚Äúhere‚Äôs a text thread in japanese: <thread>. now translate my new message below to japanese. make it sound natural in the flow of this conversation. don‚Äôt translate word for word, translate the general meaning.‚Äù use the openai js library, some sample code pasted below.</thread></li>
<li>the user can paste in their openai key in a settings pane, it gets stored in localstorage</li>
</ul>
</blockquote>

<p>One of the iterative edits for the texting app:</p>

<blockquote>
<p>make the following edits and output new code:</p>

<ul>
<li>write a css file and style the app to look professional and modern.</li>
<li>arrange the text thread in a tall box on the left, and then the new message and translation vertically stacked to the right</li>
<li>give the app a title: Japanese Texting Helper</li>
<li>hide the openai key behind a settings section that gets toggled open/closed at the bottom of the app</li>
</ul>
</blockquote>
</div></div>
  </body>
</html>
