<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">Original</a>
    <h1>Take It Down Act: A Flawed Attempt to Protect Victims That&#39;ll Lead to Censorship</h1>
    
    <div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div>
    <div><div><div><p><span>Congress has begun debating the TAKE IT DOWN Act (</span><a href="https://www.congress.gov/bill/119th-congress/senate-bill/146"><span>S. 146</span></a><span>), a bill that seeks to speed up the removal of a troubling type of online content: non-consensual intimate imagery, or NCII. In recent years, concerns have also grown about the use of digital tools to alter or create such images, </span><a href="https://www.eff.org/deeplinks/2019/06/congress-should-not-rush-regulate-deepfakes"><span>sometimes called deepfakes</span></a><span>. <br/></span></p>
<p><span>While protecting victims of these heinous privacy invasions is a legitimate goal, good intentions alone are not enough to make good policy. As currently drafted, the Act mandates a notice-and-takedown system that threatens free expression, user privacy, and due process, without addressing the problem it claims to solve. <br/></span></p>
<h3><b>The Bill Will Lead To Overreach and Censorship</b></h3>
<p><span>S.B. 146 mandates that websites and other online services remove flagged content within 48 hours and requires “reasonable efforts” to identify and remove known copies. Although this provision is designed to allow NCII victims to remove this harmful content, its broad definitions and lack of safeguards will likely lead to people misusing the notice-and-takedown system to remove lawful speech.</span></p>
<p><a href="https://act.eff.org/action/the-take-it-down-act-will-censor-legal-speech-without-helping-victims/">take action</a></p>
<p>&#34;Take It Down&#34; Has No real Safeguards<span> </span><span> </span></p>
<p><span>The takedown provision applies to a much broader category of content—potentially any images involving intimate or sexual content—than the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Lawful content—including satire, journalism, and political speech—could be wrongly censored. The legislation’s tight time frame requires that apps and websites remove content within 48 hours, meaning that online service providers, particularly smaller ones, will have to comply so quickly to avoid legal risk that they won’t be able to verify claims. Instead, automated filters will be used to catch duplicates, but these systems are </span><a href="https://www.eff.org/takedowns/automated-copyright-filter-cant-detect-infringement-or-irony"><span>infamous for flagging legal content</span></a><span>, from fair-use commentary to news reporting.</span></p>
<p><span>TAKE IT DOWN creates a far broader internet censorship regime than the Digital Millennium Copyright Act (DMCA), which has been </span><a href="https://www.eff.org/files/2020/09/04/mcsherry_statement_re_copyright_9.7.2020-final.pdf"><span>widely abused</span></a><span> to </span><a href="https://www.eff.org/takedowns"><span>censor legitimate speech</span></a><span>. But at least the DMCA has an anti-abuse provision and protects services from copyright claims should they comply. This bill contains none of those minimal speech protections and essentially greenlights misuse of its takedown regime.</span></p>
<h3><b>Threats To Encrypted Services <br/></b></h3>
<p><span>The online services that do the best job of protecting user privacy could also be under threat from Take It Down. While the bill exempts email services, it does not provide clear exemptions for private messaging apps, cloud storage, and other end-to-end encrypted (E2EE) services. Services that use end-to-end encryption, by design, are </span><i><span>not able to access or view</span></i><span> unencrypted user content. <br/></span></p>
<p><span>How could such services comply with the takedown requests mandated in this bill? Platforms may respond by abandoning encryption entirely in order to be able to monitor content—turning private conversations into surveilled spaces. <br/></span></p>
<p><span>In fact, victims of NCII often rely on encryption for safety—to communicate with advocates they trust, store evidence, or escape abusive situations. The bill’s failure to protect encrypted communications could harm the very people it claims to help.</span></p>
<h3><b>Victims Of NCII Have Legal Options Under Existing Law</b></h3>
<p><span>An array of criminal and civil laws already exist to address NCII. In addition to 48 states that have specific laws </span><a href="https://www.findlaw.com/criminal/criminal-charges/revenge-porn-laws-by-state.html"><span>criminalizing the distribution of non-consensual pornography</span></a><span>, there are defamation, harassment, and extortion statutes that can all be wielded against people abusing NCII. Since 2022, NCII victims have also been able to bring </span><a href="https://www.justice.gov/atj/sharing-intimate-images-without-consent-know-your-rights"><span>federal civil lawsuits</span></a><span> against those who spread this harmful content. <br/></span></p>
<p><span>As </span><a href="https://www.eff.org/deeplinks/2018/02/we-dont-need-new-laws-faked-videos-we-already-have-them"><span>we explained in 2018</span></a><span>: <br/></span></p>
<blockquote><p><span>If a deepfake is used for criminal purposes, then criminal laws will apply. If a deepfake is used to pressure someone to pay money to have it suppressed or destroyed, extortion laws would apply. For any situations in which deepfakes were used to harass, harassment laws apply. There is no need to make new, specific laws about deepfakes in either of these situations.</span></p>
</blockquote>
<p><span><br/></span><span>In many cases, civil claims could also be brought against those distributing the images under causes of action like False Light invasion of privacy. False light claims commonly address photo manipulation, embellishment, and distortion, as well as deceptive uses of non-manipulated photos for illustrative purposes. <br/></span></p>
<p><span>A false light plaintiff (such as a person harmed by NCII) must prove that a defendant (such as a person who uploaded NCII) published something that gives a false or misleading impression of the plaintiff in such a way to damage the plaintiff’s reputation or cause them great offense. </span></p>
<p><span>Congress should focus on enforcing and improving these existing protections, rather than opting for a broad takedown regime that is bound to be abused. Private platforms can play a part as well, improving reporting and evidence collection systems.  <br/></span></p>

</div></div></div>  </div>

          </article>
    </div></div>
  </body>
</html>
