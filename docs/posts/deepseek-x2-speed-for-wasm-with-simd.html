<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Jan/27/llamacpp-pr/">Original</a>
    <h1>DeepSeek: X2 Speed for WASM with SIMD</h1>
    
    <div id="readability-page-1" class="page"><div>



<p><strong><a href="https://github.com/ggerganov/llama.cpp/pull/11453">ggml : x2 speed for WASM by optimizing SIMD</a></strong> (<a href="https://twitter.com/ggerganov/status/1883888336487723172" title="@ggerganov">via</a>) PR by Xuan-Son Nguyen for <code>llama.cpp</code>:</p>
<blockquote>
<p>This PR provides a big jump in speed for WASM by leveraging SIMD instructions for <code>qX_K_q8_K</code> and <code>qX_0_q8_0</code> dot product functions.</p>
<p>Surprisingly, 99% of the code in this PR is <strong>written by DeekSeek-R1</strong>. The only thing I do is to develop tests and write prompts (with some trails and errors)</p>
</blockquote>
<p>They shared <a href="https://gist.github.com/ngxson/307140d24d80748bd683b396ba13be07">their prompts</a> here, which they ran directly through R1 on <a href="https://chat.deepseek.com/">chat.deepseek.com</a> - it spent 3-5 minutes &#34;thinking&#34; about each prompt.</p>
<p>I&#39;ve been seeing some very promising results from DeepSeek R1 for code as well. Here&#39;s <a href="https://gist.github.com/simonw/5a3ac1454328ca335fee796e57e26b09">a recent transcript</a> where I used it to rewrite the <a href="https://github.com/simonw/llm-groq/blob/c001f3b261f99dfd663d3c8083d11d71c1f870f1/llm_groq.py">llm_groq.py</a> plugin to imitate the cached model JSON pattern used by <a href="https://github.com/simonw/llm-mistral/blob/30fb4fb9f25fe421267560e8216f72d235a1dc89/llm_mistral.py">llm_mistral.py</a>, resulting in <a href="https://github.com/angerman/llm-groq/pull/19">this PR</a>.</p>
<p>I tried the <a href="https://gist.github.com/simonw/c9024b7feffda865ef10138dacfddcdc">same thing against o1</a>, but I think DeepSeek R1 did it better. In particular, from the R1 chain of thought:</p>
<blockquote>
<p>Wait, but in the model_map, &#34;groq-gemma&#34; maps to &#34;gemma-7b-it&#34;. So, perhaps the model_map is needed to map the local model IDs to the actual Groq model names.</p>
<p>But since the model_map is hardcoded, and the API returns available models, perhaps the model_map should be built dynamically from the API response.</p>
<p>Alternatively, perhaps the model_map can be eliminated, and the models are registered based on the fetched models.</p>
<p>Wait, perhaps the model_map is no longer necessary. Instead, when the models are fetched from the API, each model&#39;s &#34;id&#34; is the actual model name used in the Groq API. So, when registering the models, the local model ID is &#34;groq-{id}&#34;, and the groq_model_id is &#34;id&#34;.</p>
</blockquote>
<p>(It thought about <code>model_map</code> a <em>lot</em> before finally deciding to eliminate it, which was also my preferred resolution.)</p>



</div></div>
  </body>
</html>
