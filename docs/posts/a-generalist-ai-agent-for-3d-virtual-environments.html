<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/">Original</a>
    <h1>A generalist AI agent for 3D virtual environments</h1>
    
    <div id="readability-page-1" class="page"><div>
  <p data-block-key="l0lw5">We present new research on a Scalable Instructable Multiworld Agent (SIMA) that can follow natural-language instructions to carry out tasks in a variety of video game settings</p><p data-block-key="bq21g">Video games are a key proving ground for artificial intelligence (AI) systems. Like the real world, games are rich learning environments with responsive, real-time settings and ever-changing goals.</p><p data-block-key="8k0ij">From our <a href="https://www.nature.com/articles/nature14236/" rel="noopener" target="_blank">early work with Atari games</a>, through to our <a href="https://deepmind.google/discover/blog/alphastar-grandmaster-level-in-starcraft-ii-using-multi-agent-reinforcement-learning/" rel="noopener" target="_blank">AlphaStar</a> system that plays StarCraft II at human-grandmaster level, Google DeepMind has a long history in AI and games.</p><p data-block-key="4fn6k">Today, we’re announcing a new milestone - shifting our focus from individual games towards a general, instructable game-playing AI agent.</p><p data-block-key="e4a4e">In a new <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/sima-generalist-ai-agent-for-3d-virtual-environments/Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf" rel="noopener" target="_blank">technical report</a>, we introduce SIMA, short for Scalable Instructable Multiworld Agent, a generalist AI agent for 3D virtual settings. We partnered with game developers to train SIMA on a variety of video games. This research marks the first time an agent has demonstrated it can understand a broad range of gaming worlds, and follow natural-language instructions to carry out tasks within them, as a human might. </p><p data-block-key="cish1">This work isn&#39;t about achieving high game scores. Learning to play even one video game is a technical feat for an AI system, but learning to follow instructions in a variety of game settings could unlock more helpful AI agents for any environment. Our research shows how we can translate the capabilities of advanced AI models into useful, real-world actions through a language interface. We hope that SIMA and other agent research can use video games as sandboxes to better understand how AI systems may become more helpful.</p><h2 data-block-key="38m1q">Learning from video games</h2>
</div><div>
  <p data-block-key="l0lw5">To expose SIMA to many environments, we’ve built a number of partnerships with game developers for our research. We collaborated with eight game studios to train and test SIMA on nine different video games, such as <i>No Man’s Sky</i> by Hello Games and <i>Teardown</i> by Tuxedo Labs. Each game in SIMA’s portfolio opens up a new interactive world, including a range of skills to learn, from simple navigation and menu use, to mining resources, flying a spaceship, or crafting a helmet.</p><p data-block-key="7rpvr">We also used four research environments - including a new environment we built with <a href="https://deepmind.google/discover/blog/using-unity-to-help-solve-intelligence/">Unity</a> called the Construction Lab, where agents need to build sculptures from building blocks which test their object manipulation and intuitive understanding of the physical world.</p><p data-block-key="33d7q">By learning from different gaming worlds, SIMA captures how language ties in with game-play behavior. Our first approach was to record pairs of human players across the games in our portfolio, with one player watching and instructing the other. We also had players play freely, then rewatch what they did and record instructions that would have led to their game actions. </p>
</div><div>
  <h2 data-block-key="l0lw5">SIMA: a versatile AI agent</h2><p data-block-key="315hi">SIMA is an AI agent that can perceive and understand a variety of environments, then take actions to achieve an instructed goal. It comprises a model designed for precise image-language mapping and a video model that predicts what will happen next on-screen. We finetuned these models on training data specific to the 3D settings in the SIMA portfolio.</p><p data-block-key="dbg69">Our AI agent doesn’t need access to a game&#39;s source code, nor bespoke APIs. It requires just two inputs: the images on screen, and simple, natural-language instructions provided by the user. SIMA uses keyboard and mouse outputs to control the games’ central character to carry out these instructions. This simple interface is what humans use, meaning SIMA can potentially interact with any virtual environment.</p><p data-block-key="1rl4v">The current version of SIMA is evaluated across 600 basic skills, spanning navigation (e.g. &#34;turn left&#34;), object interaction (&#34;climb the ladder&#34;), and menu use (&#34;open the map&#34;). We’ve trained SIMA to perform simple tasks that can be completed within about 10 seconds.</p>
</div><div>
  <p data-block-key="l0lw5">We want our future agents to tackle tasks that require high-level strategic planning and multiple sub-tasks to complete, such as “Find resources and build a camp”. This is an important goal for AI in general, because while Large Language Models have given rise to powerful systems that can capture knowledge about the world and generate plans, they currently lack the ability to take actions on our behalf.</p><h2 data-block-key="56aia">Generalizing across games and more</h2><p data-block-key="7iffp">We show an agent trained on many games was better than an agent that learned how to play just one. In our evaluations, SIMA agents trained on a set of nine 3D games from our portfolio significantly outperformed all specialized agents trained solely on each individual one. What’s more, an agent trained in all but one game performed nearly as well on that unseen game as an agent trained specifically on it, on average. Importantly, this ability to function in brand new environments highlights SIMA’s ability to generalize beyond its training. This is a promising initial result, however more research is required for SIMA to perform at human levels in both seen and unseen games.</p><p data-block-key="abqit">Our results also show that SIMA’s performance relies on language. In a control test where the agent was not given any language training or instructions, it behaves in an appropriate but aimless manner. For example, an agent may gather resources, a frequent behavior, rather than walking where it was instructed to go.</p>
</div><div>
  <h2 data-block-key="l0lw5">Advancing AI agent research</h2><p data-block-key="6sav5">SIMA’s results show the potential to develop a new wave of generalist, language-driven AI agents. This is early-stage research and we look forward to further building on SIMA across more training environments and incorporating more capable models.</p><p data-block-key="4b660">As we expose SIMA to more training worlds, the more generalizable and versatile we expect it to become. And with more advanced models, we hope to improve SIMA’s understanding and ability to act on higher-level language instructions to achieve more complex goals. </p><p data-block-key="8o4j9">Ultimately, our research is building towards more general AI systems and agents that can understand and safely carry out a wide range of tasks in a way that is helpful to people online and in the real world.</p>
</div><div>
  <div>
    <div>
      <p data-block-key="4n7e8">We would like to thank all the paper authors: Maria Abi Raad, Arun Ahuja, Catarina Barros, Frederic Besse, Andrew Bolt, Adrian Bolton, Bethanie Brownfield, Gavin Buttimore, Max Cant, Sarah Chakera, Stephanie Chan, Jeff Clune, Adrian Collister, Vikki Copeman, Alex Cullum, Ishita Dasgupta, Julia Di Trapani, Yani Donchev, Martin Engelcke, Ryan Faulkner, Frankie Garcia, Charles Gbadamosi, Zhitao Gong, Lucy Gonzales, Karol Gregor, Arne Olav Hallingstad, Tim Harley, Sam Haves, Felix Hill, Ed Hirst, Drew Hudson, Steph Hughes-Fitt, Danilo J. Rezende,Mimi Jasarevic, Laura Kampis, Rosemary Ke, Thomas Keck, Junkyung Kim, Oscar Knagg, Kavya Kopparapu,Andrew Lampinen, Shane Legg, Alexander Lerchner, Marjorie Limont, Yulan Liu, Maria Loks-Thompson, Joseph Marino, Kathryn Martin Cussons, Loic Matthey, Siobhan Mcloughlin, Piermaria Mendolicchio, Hamza Merzic, Anna Mitenkova, Alexandre Moufarek, Valeria Oliveira, Yanko Oliveira, Hannah Openshaw, Renke Pan, Aneesh Pappu, Alex Platonov, Ollie Purkiss, David Reichert, John Reid, Pierre Harvey Richemond, Tyson Roberts, Giles Ruscoe, Jaume Sanchez Elias, Tasha Sandars, Daniel P. Sawyer, Tim Scholtes, Guy Simmons, Daniel Slater, Hubert Soyer, Heiko Strathmann, Peter Stys, Allison Tam, Tayfun Terzi, Davide Vercelli, Bojan Vujatovic, Marcus Wainwright, Jane X. Wang, Zhengdong Wang, Daan Wierstra, Duncan Williams, Nathaniel Wong, Sarah York, and Nick Young.</p><p data-block-key="5ehes">Special thanks to all of the game developers who partnered with us: Coffee Stain (<i>Valheim, Satisfactory, Goat Simulator 3),</i> Foulball Hangover (<i>Hydroneer),</i> Hello Games (<i>No Man&#39;s Sky),</i> Keen Software House (<i>Space Engineer),</i> RubberbandGames (<i>Wobbly Life),</i> Strange Loop Games (<i>Eco) and</i> Tuxedo Labs &amp; Saber Interactive (<i>Teardown).</i></p>
    </div>
  </div>
</div></div>
  </body>
</html>
