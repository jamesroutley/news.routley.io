<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mitchellh.com/writing/my-ai-adoption-journey">Original</a>
    <h1>My AI Adoption Journey</h1>
    
    <div id="readability-page-1" class="page"><div><details open=""><summary>Table of Contents</summary></details>
<p>My experience adopting any meaningful tool is that I&#39;ve necessarily
gone through three phases: (1) a period of inefficiency (2) a period
of adequacy, then finally (3) a period of workflow and life-altering
discovery.</p>
<p>In most cases, I have to force myself through phase 1 and 2 because
I usually have a workflow I&#39;m already happy and comfortable with.
Adopting a tool feels like work, and I <em>do not</em> want to
put in the effort, but I usually do in an effort to be a well-rounded
person of my craft.</p>
<p>This is my journey of how I found value in AI tooling and what I&#39;m
trying next with it. In an ocean of overly dramatic, hyped takes,
I hope this represents a more nuanced, measured approach to my views
on AI and how they&#39;ve changed over time.</p>
<div><p>This blog post was fully written by hand, in my own words. I hate that I have to say that but
especially given the subject matter, I want to be explicit about it.</p></div>
<hr/>
<h2 id="step-1-drop-the-chatbot"><a href="#step-1-drop-the-chatbot" aria-hidden="true" tabindex="-1"><span></span></a>Step 1: Drop the Chatbot</h2>
<p>Immediately cease trying to perform meaningful work via a chatbot
(e.g. ChatGPT, Gemini on the web, etc.). Chatbots have real value
and are a daily part of my AI workflow, but their utility in coding
is highly limited because you&#39;re mostly hoping they come up with the
right results based on their prior training, and correcting them
involves a human (you) to tell them they&#39;re wrong repeatedly. It is
inefficient.</p>
<p>I think everyone&#39;s first experience with AI is a chat interface.
And I think everyone&#39;s first experience trying to code with AI has
been asking a chat interface to write code.</p>
<p>While I was still a heavy AI skeptic, my first &#34;oh wow&#34; moment
was pasting a screenshot of Zed&#39;s command palette into Gemini, asking
it to reproduce it with SwiftUI, and being truly flabbergasted that it
did it <em>very well</em>. The command palette that ships for macOS in Ghostty
today is only very lightly modified from what Gemini produced for me
in seconds.</p>
<p>But when I tried to reproduce that behavior for other tasks, I was left
disappointed. In the context of brownfield projects, I found the chat
interface produced poor results very often, and I found myself very
frustrated copying and pasting code and command output to and from
the interface. It was very obviously far less efficient than me doing
the work myself.</p>
<p>To find value, you <em>must</em> use an <strong>agent</strong>. An agent is the industry-adopted
term for an LLM that can chat and invoke external behavior in a loop<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>
At a bare minimum, the agent must have the ability to: read files,
execute programs, and make HTTP requests.</p>
<hr/>
<h2 id="step-2-reproduce-your-own-work"><a href="#step-2-reproduce-your-own-work" aria-hidden="true" tabindex="-1"><span></span></a>Step 2: Reproduce Your Own Work</h2>
<p>The next phase on my journey I tried
<a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/claude-code">Claude Code</a>. I&#39;ll cut to the
chase: I initially wasn&#39;t impressed. I just wasn&#39;t getting good results
out of my sessions. I felt I had to touch up everything it produced and
this process was taking more time than if I had just done it myself.
I read blog posts, watched videos, but just wasn&#39;t that impressed.</p>
<p>Instead of giving up, I <strong>forced myself to reproduce all my manual commits
with agentic ones.</strong> I literally did the work twice. I&#39;d do the work manually,
and then I&#39;d fight an agent to produce identical results in terms of quality
and function (without it being able to see my manual solution, of course).</p>
<p>This was <em>excruciating</em>, because it got in the way of simply getting things
done. But I&#39;ve been around the block with non-AI tools enough to know that
friction is natural, and I can&#39;t come to a firm, defensible conclusion
without exhausting my efforts.</p>
<p>But, expertise formed. I quickly discovered for myself from first principles
what others were already saying, but discovering it myself resulted in
a stronger fundamental understanding.</p>
<ol>
<li>Break down sessions into separate clear, actionable tasks. Don&#39;t try
to &#34;draw the owl&#34; in one mega session.</li>
<li>For vague requests, split the work into separate planning vs. execution
sessions.</li>
<li>If you give an agent a way to verify its work, it more often than
not fixes its own mistakes and prevents regressions.</li>
</ol>
<p>More generally, I also found the edges of what agents -- at the time --
were good at, what they weren&#39;t good at, and for the tasks they were good at
how to achieve the results I wanted.</p>
<p>All of this led to significant efficiency gains, to the point where I was
starting to naturally use agents in a way that I felt was no slower than
doing it myself (but I still didn&#39;t feel it was any faster, since I was mostly
babysitting an agent).</p>
<p>The negative space here is worth reiterating: part of the efficiency gains
here were understanding when <em>not</em> to reach for an agent. Using an agent
for something it&#39;ll likely fail at is obviously a big waste of time and
having the knowledge to avoid that completely leads to time savings<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.</p>
<p>At this stage, I was finding adequate value with agents that I was happy
to use them in my workflow, but still didn&#39;t feel like I was seeing any
net efficiency gains. I didn&#39;t care though, I was content at this point
with AI as a tool.</p>
<hr/>
<h2 id="step-3-end-of-day-agents"><a href="#step-3-end-of-day-agents" aria-hidden="true" tabindex="-1"><span></span></a>Step 3: End-of-Day Agents</h2>
<p>To try to find some efficiency, I next started up a new pattern:
<strong>block out the last 30 minutes of every day to kick off one or more agents.</strong>
My hypothesis was that <em>perhaps</em> I could gain some efficiency if the agent
can make some <em>positive progress</em> in the times I can&#39;t work anyways.
Basically: instead of trying to do more in the time I have, try to do
more in the time I don&#39;t have.</p>
<p>Similar to the previous task, I at first found this both unsuccessful
and annoying. But, I once again quickly found different categories of work
that were really helpful:</p>
<ul>
<li><strong>Deep research sessions</strong> where I&#39;d ask agents to survey some
field, such as finding all libraries in a specific language with
a specific license type and producing multi-page summaries for each
on their pros, cons, development activity, social sentiment, etc.</li>
<li><strong>Parallel agents attempting different vague ideas I had but didn&#39;t
have time to get started on.</strong> I didn&#39;t expect them to produce something
I&#39;d ever ship here, but perhaps could illuminate some unknown unknowns
when I got to the task the next day.</li>
<li><strong>Issue and PR triage/review.</strong> Agents are good at using <code>gh</code> (GitHub CLI),
so I manually scripted a quick way to spin up a bunch in parallel to
triage issues. I would NOT allow agents to respond, I just wanted
reports the next day to try to guide me towards high value or low effort
tasks.</li>
</ul>
<p>To be clear, I did not go as far as others went to have agents running
in loops all night. In most cases, agents completed their tasks in less than
half an hour. But, the latter part of the working day, I&#39;m usually tired
and coming out of flow and find myself too personally inefficient, so
shifting my effort to spinning up these agents I found gave me a &#34;warm start&#34;
the next morning that got me working more quickly than I would&#39;ve otherwise.</p>
<p>I was happy, and I was starting to feel like I was doing more than I was
doing prior to AI, if only slightly.</p>
<hr/>
<h2 id="step-4-outsource-the-slam-dunks"><a href="#step-4-outsource-the-slam-dunks" aria-hidden="true" tabindex="-1"><span></span></a>Step 4: Outsource the Slam Dunks</h2>
<p>By this point, I was getting very confident about what tasks my AI was
and wasn&#39;t great at. I had really high confidence with certain tasks that
the AI would achieve a mostly-correct solution. So the next step on my
journey was: <strong>let agents do all of that work while I worked on other tasks.</strong></p>
<p>More specifically, I would start each day by taking the results of my
prior night&#39;s triage agents, filter them manually to find the issues that
an agent will almost certainly solve well, and then keep them going
in the background (one at a time, not in parallel).</p>
<p>Meanwhile, <strong>I&#39;d work on something else.</strong> I wasn&#39;t going to social media
(any more than usual without AI), I wasn&#39;t watching videos, etc. I was
in my own, normal, pre-AI deep thinking mode working on something I
wanted to work on or had to work on.</p>
<p><strong>Very important at this stage: turn off agent desktop notifications.</strong>
Context switching is very expensive. In order to remain efficient, I
found that it was my job as a human to be in control of when I interrupt
the agent, not the other way around. Don&#39;t let the agent notify you.
During natural breaks in your work, tab over and check on it, then
carry on.</p>
<p>Importantly, I think the &#34;work on something else&#34; helps counteract
the highly publicized <a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/research/AI-assistance-coding-skills">Anthropic skill formation paper</a>.
Well, you&#39;re trading off: not forming skills for the tasks you&#39;re
delegating to the agent while continuing to form skills naturally
in the tasks you continue to work on manually.</p>
<p>At this point I was firmly in the &#34;no way I can go back&#34; territory.
I felt more efficient, but even if I wasn&#39;t, the thing I liked the most
was that I could now focus my coding and thinking on tasks I really loved
while still adequately completing the tasks I didn&#39;t.</p>
<hr/>
<h2 id="step-5-engineer-the-harness"><a href="#step-5-engineer-the-harness" aria-hidden="true" tabindex="-1"><span></span></a>Step 5: Engineer the Harness</h2>
<p>At risk of stating the obvious: agents are much more efficient when they
produce the right result the first time, or at worst produce a result that
requires minimal touch-ups. The most sure-fire way to achieve this is
to give the agent fast, high quality tools to automatically tell it
when it is wrong.</p>
<p>I don&#39;t know if there is a broad industry-accepted term for this yet,
but I&#39;ve grown to calling this &#34;harness engineering.&#34; It is the idea that
anytime you find an agent makes a mistake, you take the time to engineer
a solution such that the agent never makes that mistake again. I don&#39;t need
to invent any new terms here; if another one exists, I&#39;ll jump on the
bandwagon.</p>
<p>This comes in two forms:</p>
<ol>
<li>
<p><strong>Better implicit prompting (AGENTS.md).</strong> For simple things, like
the agent repeatedly running the wrong commands or finding the wrong
APIs, update the <code>AGENTS.md</code> (or equivalent). Here is
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghostty-org/ghostty/blob/ca07f8c3f775fe437d46722db80a755c2b6e6399/src/inspector/AGENTS.md">an example from Ghostty</a>.
Each line in that file is based on a bad agent behavior, and it almost
completely resolved them all.</p>
</li>
<li>
<p><strong>Actual, programmed tools.</strong> For example, scripts to take screenshots,
run filtered tests, etc etc. This is usually paired with an AGENTS.md
change to let it know about this existing.</p>
</li>
</ol>
<p><strong>This is where I&#39;m at today.</strong> I&#39;m making an earnest effort whenever I see
an agent do a Bad Thing to prevent it from ever doing that bad thing again.
Or, conversely, I&#39;m making an earnest effort for agents to be able to
verify they&#39;re doing a Good Thing.</p>
<hr/>
<h2 id="step-6-always-have-an-agent-running"><a href="#step-6-always-have-an-agent-running" aria-hidden="true" tabindex="-1"><span></span></a>Step 6: Always Have an Agent Running</h2>
<p>Simultaneous to step 5, I&#39;m also operating under the goal of
<strong>having an agent running at all times.</strong> If an agent isn&#39;t running,
I ask myself &#34;is there something an agent could be doing for me right now?&#34;</p>
<p>I particularly like to combine this with slower, more thoughtful
models like Amp&#39;s <a target="_blank" rel="noopener noreferrer" href="https://ampcode.com/news/deep-mode">deep mode</a> (which
is basically just GPT-5.2-Codex) which can take upwards of 30+ minutes
to make small changes. The flip side of that is that it does tend to
produce very good results.</p>
<p><strong>I&#39;m not [yet?] running multiple agents, and currently don&#39;t really want to.</strong>
I find having the one agent running is a good balance for me right now
between being able to do deep, manual work I find enjoyable, and babysitting
my kind of stupid and yet mysteriously productive robot friend.</p>
<p>The &#34;have an agent running at all times&#34; goal is still just a goal.
I&#39;d say right now I&#39;m maybe effective at having a background agent running
10 to 20% of a normal working day. But, I&#39;m actively working to improve that.</p>
<div><p><strong>I don&#39;t want to run agents for the sake of running agents.</strong> I only want to run them when there
is a task I think would be truly helpful to me. Part of the challenge of this goal is improving my
own workflows and tools so that I can have a constant stream of high quality work to do that I can
delegate. Which, even without AI, is important!</p></div>
<hr/>
<h2 id="today"><a href="#today" aria-hidden="true" tabindex="-1"><span></span></a>Today</h2>
<p>And that&#39;s where I&#39;m at today.</p>
<p>Through this journey, I&#39;ve personally reached a point where I&#39;m having
success with modern AI tooling and I believe I&#39;m approaching it with the
proper measured view that is grounded in reality. I really don&#39;t care
one way or the other if AI is here to stay<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup>, I&#39;m a software craftsman
that just wants to build stuff for the love of the game.</p>
<p>The whole landscape is moving so rapidly that I&#39;m sure I&#39;ll look back
at this post very quickly and laugh at my naivete. But, as they say,
if you can&#39;t be embarassed about your past self, you&#39;re probably not
growing. I just hope I&#39;ll grow in the right direction!</p>
<p>I have no skin in the game here<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup>, and there are of course other
reasons behind utility to avoid using AI. I fully respect anyone&#39;s
individual decisions regarding it. I&#39;m not here to convince you! For
those interested, I just wanted to share my personal approach to navigating
these new tools and give a glimpse about how I approach new tools
<em>in general</em>, regardless of AI.</p>
</div></div>
  </body>
</html>
