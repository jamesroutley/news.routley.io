<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://allenai.org/blog/olmo3">Original</a>
    <h1>Olmo 3: Charting a path through the model flow to lead open-source AI</h1>
    
    <div id="readability-page-1" class="page"><div id="main-content"><section></section><section><div><p>Language models are often treated as snapshots—brief captures of a long and carefully curated development process. But sharing only the end result obscures the rich context needed to modify, adapt, and extend a model&#39;s capabilities. Many meaningful adjustments require integrating domain-specific knowledge deep within the development pipeline, not merely at the final stage. To truly advance open AI development and research, the entire <em>model flow</em> – not just its endpoint – should be accessible and customizable. The model flow is the full lifecycle of an LM: every stage, checkpoint, dataset, and dependency required to create and modify it. By exposing this complete process, the goal is to engender greater trust and enable more effective adaptation, collaboration, and innovation.</p><p>With today&#39;s release of <strong>Olmo 3</strong>, we&#39;re empowering the open source community with not only state-of-the-art open models, but the entire model flow and full traceability back to training data.</p><p>At its center is <strong>Olmo 3-Think (32B)</strong>, the best fully open 32B-scale thinking model that for the first time lets you inspect intermediate reasoning traces and trace those behaviors back to the data and training decisions that produced them. Olmo 3 is a family of compact, dense models at 7 billion and 32 billion parameters that can run on everything from laptops to research clusters.</p><ul><li><strong>Olmo 3-Base (7B, 32B) </strong>is our most powerful base model yet. When evaluated on our expanded, diverse evaluation suite, Olmo 3-Base delivers the strongest performance among fully open base models – where training data, code, and weights are all publicly available, like Stanford&#39;s Marin and Swiss AI&#39;s Apertus – and achieves competitive performance with some of the best open-weights base models of comparable size and architecture, including Qwen 2.5 and Gemma 3. Achieving strong results in programming, reading comprehension, and math problem solving, Olmo 3-Base maintains performance at extended context lengths (~up to 65K tokens)—providing a versatile foundation for continued pretraining, targeted fine-tuning, and reinforcement learning and making it easy to build in specialized capabilities like reasoning, tool use (function calling), and instruction following through post-training.</li><li><strong>Olmo 3-Think (7B, 32B) </strong>is our flagship post-trained reasoning set built on Olmo 3-Base. At a time when few organizations are releasing truly open models at this scale, <strong>Olmo 3-Think (32B)</strong> serves as a workhorse for RL research, long-horizon reasoning, and other advanced experiments that require substantial compute. On our suite of reasoning benchmarks (discussed below), it&#39;s the strongest fully open thinking model we&#39;re aware of, narrowing the gap to the best open-weight models of similar scale – such as Qwen 3 32B – while training on roughly 6x fewer tokens. <strong>Olmo 3-Think (7B)</strong> brings the same design and training approach to an even more efficient form factor, surfacing intermediate thinking steps for complex prompts while making open, inspectable reasoning accessible on more modest hardware.</li><li><strong>Olmo 3-Instruct (7B)</strong> is a chat and quick-response focused post-train of Olmo 3-Base that handles multi-turn, instruction-following, tool use, and more. In our evaluations, it matches or outperforms open-weight models including Qwen 2.5, Gemma 3, and Llama 3.1, and narrows the gap with Qwen 3 model families at a similar scale—delivering a strong, fully open alternative for high-quality conversational and tool-using agents.</li><li><strong>Olmo 3-RL Zero (7B)</strong>, is a fully open reinforcement learning pathway built on Olmo 3-Base, designed to bootstrap complex reasoning behaviors and enable clear benchmarking of RL algorithms. We release four series of checkpoints from domain-focused training on math, code, instruction following, and general chat, enabling careful study of reinforcement learning with verifiable rewards (RLVR).</li></ul><p>Instead of a single set of frozen weights, Olmo 3 offers multiple, fully documented paths through development: the Instruct path for everyday chat and tool use, the RL Zero path for RL experimentation from base models, and the Think/reasoning path for models that leverage inference-time scaling to unlock complex reasoning and agentic behaviors. Each path is a concrete example of how to shape behavior from the same base model, and you’re free to fork or remix them—start with Olmo 3-Base, explore your own supervised fine-tuning (SFT) or direct preference optimization (DPO) recipe for instruct-style use cases, or plug in a new RL objective to probe different tradeoffs. The flow itself becomes a rich, reusable object—not just a record of how we built Olmo 3, but a scaffold for how you can build your own systems.</p><div><div><svg viewBox="0 0 1400 340" xmlns:xlink="http://www.w3.org/1999/xlink" role="img" aria-labelledby="flow-chart-title"><title id="flow-chart-title">Olmo 3 Model Flow</title><defs><marker id="arrow-head" markerWidth="8" markerHeight="8" refX="6" refY="3" orient="auto"><path d="M0,0 L0,6 L7,3 z" fill="var(--colors-dark-teal-100)"></path></marker></defs><g role="button" tabindex="0" aria-label="Pretraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="30" y="130" width="150" height="48" rx="24" fill="var(--colors-pink-100)"></rect><text x="105" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="105" dy="0">Pretraining</tspan></text></g><g role="button" tabindex="0" aria-label="Midtraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="228" y="130" width="150" height="48" rx="24" fill="var(--colors-pink-100)"></rect><text x="303" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="303" dy="0">Midtraining</tspan></text></g><g role="button" tabindex="0" aria-label="Long context" style="--highlight-stroke:var(--colors-teal-100)"><rect x="426" y="130" width="150" height="48" rx="24" fill="var(--colors-contrast-pink)"></rect><text x="501" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="501" dy="0">Long context</tspan></text></g><line x1="180" y1="154" x2="218" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line><line x1="378" y1="154" x2="416" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line><text x="501" y="115" text-anchor="middle">Olmo 3 Base</text><g><g><g role="button" tabindex="0" aria-label="Instruct SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="656" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="731" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="731" dy="0">Instruct SFT</tspan></text></g><line x1="806" y1="44" x2="844" y2="44" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="854" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="929" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="929" dy="0">Instruct DPO</tspan></text></g><line x1="1004" y1="44" x2="1042" y2="44" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">Instruct RL</tspan></text></g></g><text x="1242" y="50">Olmo 3 Instruct</text></g><g><path d="M 576 154 H 606 V 154 H 646" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path><g><g role="button" tabindex="0" aria-label="Thinking SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="656" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="731" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="731" dy="0">Thinking SFT</tspan></text></g><line x1="806" y1="154" x2="844" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="854" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="929" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="929" dy="0">Thinking DPO</tspan></text></g><line x1="1004" y1="154" x2="1042" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">Thinking RL</tspan></text></g></g><text x="1242" y="160">Olmo 3 Think</text></g><g><path d="M 501 178 V 264 H 1042" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path><g><g role="button" tabindex="0" aria-label="RL Zero" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="240" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="264" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">RL Zero</tspan></text></g></g><text x="1242" y="270">Olmo 3 RL Zero</text></g><path d="M 731 130 V 68" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path></svg><svg viewBox="0 0 900 1100" xmlns:xlink="http://www.w3.org/1999/xlink" role="img" aria-labelledby="flow-chart-title"><title id="flow-chart-title">Olmo 3 Model Flow</title><defs><marker id="arrow-head-vertical" markerWidth="8" markerHeight="8" refX="6" refY="3" orient="auto"><path d="M0,0 L0,6 L7,3 z" fill="var(--colors-dark-teal-100)"></path></marker></defs><g role="button" tabindex="0" aria-label="Pretraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="40" width="320" height="90" rx="24" fill="var(--colors-pink-100)"></rect><text x="510" y="85" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Pretraining</tspan></text></g><g role="button" tabindex="0" aria-label="Midtraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="240" width="320" height="90" rx="24" fill="var(--colors-pink-100)"></rect><text x="510" y="285" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Midtraining</tspan></text></g><g role="button" tabindex="0" aria-label="Long context" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="440" width="320" height="90" rx="24" fill="var(--colors-contrast-pink)"></rect><text x="510" y="485" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Long context</tspan></text></g><line x1="510" y1="130" x2="510" y2="232" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line><line x1="510" y1="330" x2="510" y2="432" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line><text x="510" y="25" text-anchor="middle">Olmo 3 Base</text><g><g><g role="button" tabindex="0" aria-label="Instruct SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct SFT</tspan></text></g><line x1="140" y1="770" x2="140" y2="822" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="830" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="870" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct DPO</tspan></text></g><line x1="140" y1="910" x2="140" y2="962" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="970" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="1010" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct RL</tspan></text></g></g><text x="140" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 Instruct</text></g><g><path d="M 510 530 V 682" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path><g><g role="button" tabindex="0" aria-label="Thinking SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking SFT</tspan></text></g><line x1="490" y1="770" x2="490" y2="822" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="830" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="870" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking DPO</tspan></text></g><line x1="490" y1="910" x2="490" y2="962" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="970" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="1010" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking RL</tspan></text></g></g><text x="490" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 Think</text></g><g><path d="M 670 485 H 760 V 682" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path><g><g role="button" tabindex="0" aria-label="RL Zero" style="--highlight-stroke:var(--colors-pink-100)"><rect x="630" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="760" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="760" dy="0">RL Zero</tspan></text></g></g><text x="760" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 RL Zero</text></g><path d="M 360 730 H 315 V 730 H 270" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path></svg><div role="region" aria-live="polite"><p>Click on any stage to learn more about it and download artifacts.</p></div></div></div><p>The Olmo 3 checkpoints we&#39;re releasing represent our initial paths targeting our goals around reasoning, tool use, and general capabilities – we have exciting plans for other ways to leverage Olmo 3-Base 32B. But because we&#39;re releasing the entire flow, you can intervene at any point: swap in domain-specific data during mid-training, adjust post-training for your use case, or build on an earlier checkpoint that better suits your needs. </p><p>As with <a data-current="false" href="https://allenai.org/blog/olmo-open-language-model-87ccfc95f580"><span>Olmo</span><svg><use href="#arrow-angled-svg"></use></svg></a> and <a data-current="false" href="https://allenai.org/blog/olmo2"><span>Olmo 2,</span><svg><use href="#arrow-angled-svg"></use></svg></a> we’re releasing all components of the Olmo 3 flow – data, code, model weights, and checkpoints – under permissive open source licenses.  </p><p><a data-current="false" href="https://playground.allenai.org?utm_source=ai2-blog&amp;utm_medium=referral&amp;utm_campaign=olmo3_launch"><span>Try Olmo 3</span><svg><use href="#arrow-angled-svg"></use></svg></a><strong> | </strong><a data-current="false" href="https://huggingface.co/collections/allenai/olmo-3-68e80f043cc0d3c867e7efc6"><span>Download the models &amp; data</span><svg><use href="#arrow-angled-svg"></use></svg></a> <strong>| </strong><a data-current="false" href="http://allenai.org/papers/olmo3"><span>Read the report</span><svg><use href="#arrow-angled-svg"></use></svg></a></p><h3><strong>Strong performance across the board</strong></h3><p>We run the Olmo 3 checkpoints through a broad, updated benchmark suite, grouping dozens of industry-standard tasks (plus a few new ones we introduce) into several capability clusters. Together, the clustered suite and these held-out tasks give us a capability profile of Olmo 3—a clear picture of how well it solves math problems, codes, uses tools, answers general-knowledge questions, and more. </p><p>At a high level, the Olmo 3 family delivers the strongest fully open base and thinking models we’re aware of. Olmo 3-Base 32B outperforms other fully open base models, and Olmo 3-Think 32B emerges as the strongest fully open thinking model.</p><p>Our results were made possible by rigorous data curation at every stage of training, a carefully designed training recipe for each model, and a set of new algorithmic and infrastructure advances across data processing, training, and reinforcement learning. We also introduce an enhanced reinforcement learning framework that guides the development of our models and is particularly essential for our thinking models. To design the training recipe and coordinate targeted improvements across a wide range of capabilities at each stage of the model training pipeline, our development framework balances distributed innovation with centralized evaluation.</p><p><strong>Olmo 3-Base, </strong>with a<strong> </strong>training pipeline that first focuses on broad coverage over diverse text, code, and math, then concentrates on harder distributions to sharpen programming, quantitative reasoning, and reading comprehension, is clearly the strongest set of <em><strong>fully</strong></em> open base models in our evaluations. It’s also arguably the best 32B model in the entire ecosystem of models with open weights, performing impressively in programming, reading comprehension, math problem solving, and long-context benchmarks like RULER, which tests information retrieval from lengthy texts. Olmo 3-Base (7B) and Olmo 3-Base (32) maintain quality at extended context lengths and integrate cleanly with RL workflows, providing a robust foundation for continued pretraining and post-training.</p><p><strong>Olmo 3-Think, </strong>which<strong> </strong>turns the Base into a reasoning model by training on multi-step problems spanning math, code, and general problem solving, then running the thinking SFT → thinking DPO → RLVR model flow to elicit high-quality reasoning traces, competes with or exceeds several open-weight reasoning models of similar sizes. On math benchmarks, Olmo 3-Think (7B) matches Qwen 3 8B on MATH and comes within a few points on AIME 2024 and 2025, and also leads all comparison models on HumanEvalPlus for coding—performing strongly on MBPP and LiveCodeBench to demonstrate particular strength in code-intensive reasoning. On broader reasoning tasks like BigBench Hard and AGI Eval English, Olmo 3-Think (7B) remains competitive with Qwen 3 8B reasoning and Qwen 3 VL 8B Thinker while staying fully open and slightly smaller. </p><p>For the 32B model, Olmo 3-Think scales these trends up and becomes one of the strongest fully open reasoning models in its class. Olmo 3-Think (32B) either wins or sits within roughly two points of the best open-weight model on MATH, OMEGA, BigBenchHard, HumanEvalPlus, PopQA, and IFEval. It ties Qwen 3 VL 32B Thinking for the top score on the OMEGA suite while staying clearly ahead of Gemma 3 27B Instruct and competitive with DeepSeek R1 Distill 32B on math and reasoning. On broader knowledge and QA, Olmo 3-Think (32B) is effectively neck-and-neck with the Qwen 3 models on PopQA. And in instruction following, Olmo 3-Think (32B) tops this subset on IFEval and remains solid on IFBench and AlpacaEval 2 LC—offering a strong default for reasoning workloads at the 32B scale.</p><p><strong>Olmo 3-Instruct</strong>, which produces shorter sequences than the corresponding Olmo 3-Think models to improve inference efficiency and is designed to focus on general chat, tool use, and synthetic data generation, outperforms comparably-sized open-weight models. Olmo 3-Instruct ties or surpasses Qwen 2.5, Gemma 3, and Llama 3.1 in our evaluations, and competes with the Qwen 3 family at similar scale, delivering strong function calling performance and instruction-following capabilities in a fully open 7B model.</p><h3><strong>The Olmo 3 architecture and training stages</strong></h3><p>Olmo 3 uses a decoder-only transformer architecture and multi-stage training pipeline. Pretraining runs in three stages—an initial large-scale training run that builds broad capabilities; a mid-training phase that focuses on harder material like math, code, and reading comprehension; and a final long-context extension stage that trains the model on very long documents. Together with architectural enhancements, this yields a more capable, efficient base for the Olmo 3 family.</p><p>Post-training then specializes the pretrained model for different use cases. Building on Olmo 2, each pathway follows a three-stage recipe – SFT, preference tuning with DPO, and RLVR – but in Olmo 3, we expose this as a fully documented model flow with complete customization over each training stage and dataset mix.</p><p>Instead of releasing only the final weights, we provide checkpoints from each major training milestone: the base pretrained model, the mid-trained model after targeted skill enhancement, the long-context-extended version, plus post-training checkpoints for the Olmo 3-Think, Olmo 3-Instruct, and Olmo 3-RL Zero flows. You can study how capabilities emerge over time, run ablations on specific stages, and fork the model at whatever point best fits your data, compute, and goals.</p><h3><strong>Expanded training data</strong></h3><p>Compared to Olmo 2, we scaled data collection and significantly strengthened our dataset curation methods. Continuing our commitment to full transparency, we’re releasing several new, higher-quality datasets that cover every stage of base model training and post-training—from initial learning to specialized skills like complex reasoning and long-context understanding. This means anyone can see exactly what data shaped the model’s capabilities, reproduce our results, and reuse these datasets to train their own AI systems.</p><p>Olmo 3 is pretrained on <strong>Dolma 3</strong>, a new ~9.3-trillion-token corpus drawn from web pages, science PDFs processed with <a data-current="false" href="https://olmocr.allenai.org/"><span>olmOCR</span><svg><use href="#arrow-angled-svg"></use></svg></a>, codebases, math problems and solutions, and encyclopedic text. From this pool, we construct <strong>Dolma 3 Mix</strong>, a 5.9-trillion-token (~6T) pretraining mix with a higher proportion of coding and mathematical data than earlier Dolma releases, plus much stronger decontamination via extensive deduplication, quality filtering, and careful control over data mixing. We follow established web standards in collecting training data and don’t collect from sites that explicitly disallow it, including paywalled content.</p><p>On top of this, we introduce two Dolma 3-based mixes for later stages of base model training. <strong>Dolma 3 Dolmino </strong>is our mid-training mix: 100B training tokens sampled from a ~2.2T-token pool of high-quality math, science, code, instruction-following, and reading-comprehension data, including reasoning traces that also enable RL directly on the base model. <strong>Dolma 3 Longmino</strong> is our long-context mix: ~50B training tokens drawn from a 639B-token pool of long documents combined with mid-training data to teach Olmo 3 to track information over very long inputs (like reports, logs, and multi-chapter documents).</p><p>We also introduce <strong>Dolci</strong>, a new post-training data suite tailored specifically for reasoning, tool use, and instruction following. Dolci provides separate mixes for each stage of post-training: SFT, DPO, and RLVR. For SFT, Dolci aggregates state-of-the-art datasets that advance step-by-step reasoning, tool use, and high-quality conversational behavior; for DPO, it supplies high-quality contrastive preference data; and for RL, it includes hard, diverse prompts across math, coding, instruction following, and general chat. </p><p>Together, Dolma 3 and Dolci give Olmo 3 a fully open data curriculum from first token to final post-trained checkpoint.</p><h3><strong>Efficient training stack</strong></h3><p>We pretrained Olmo 3 on a cluster of up to 1,024 H100 GPUs; we achieved training throughput of 7.7K tokens per device per second for Olmo 3-Base (7B). We mid-trained on 128 H100 GPUs, and post-trained on a set of 256 H100s.</p><p>For Olmo 3, building on the work we did for Olmo 2, we were able to significantly improve the efficiency of our post-training code. By moving SFT from Open Instruct (our post-training codebase, prioritizing flexibility) to Olmo Core (our pretraining codebase, designed to maximize efficiency), we increased throughput (tokens/second) by 8x. Similarly, by incorporating <a data-current="false" href="https://arxiv.org/abs/2509.19128"><span>in-flight weight updates</span><svg><use href="#arrow-angled-svg"></use></svg></a>, <a data-current="false" href="https://www.anyscale.com/blog/continuous-batching-llm-inference"><span>continuous batching</span><svg><use href="#arrow-angled-svg"></use></svg></a>, and a lot of threading improvements, we made our RL training 4x more efficient—resulting in training runs that are significantly cheaper and faster. </p><p>A note on our 32B models: We believe 32B sits in a sweet spot for research and tinkering. 32B models are big enough to support strong, competitive performance, but still small enough that a wide audience can fine-tune and deploy them on accessible hardware.</p><p>For more details, including ablations, please read our <a data-current="false" href="https://allenai.org/papers/olmo3"><span>technical report</span><svg><use href="#arrow-angled-svg"></use></svg></a>. </p><h3><strong>Transparency at the core</strong></h3><p>A core goal of Olmo 3 is not just to <em>open</em> the model flow, but to make it <em>actionable</em> for people who want to understand and improve model behavior. Olmo 3 integrates with <a data-current="false" href="https://allenai.org/blog/olmotrace"><span><strong>OlmoTrace</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a>, our tool for tracing model outputs back to training data in real time.</p><p>For example, in the Ai2 Playground, you can ask Olmo 3-Think (32B) to answer a general-knowledge question, then use OlmoTrace to inspect where and how the model may have learned to generate parts of its response. This closes the gap between training data and model behavior: you can see not only what the model is doing, but why—and adjust data or training decisions accordingly.</p><p>To further promote transparency and explainability, we’re making every training and fine-tuning dataset available for download, all under a permissive license that allows for custom deployment and reuse. The datasets come in a range of mixes to accommodate different storage and hardware constraints, from several billion tokens all the way up to 6 trillion.</p><p>Our new tooling for data processing allows you to de-contaminate, tokenize, and de-duplicate data in the same way we did for Olmo 3’s corpora. All the tooling is open source, enabling you to replicate our training curves or run controlled ablations across data mixes and objectives. </p><p>Our Olmo utilities and software cover the whole development cycle:</p><ul><li><a data-current="false" href="https://github.com/allenai/OLMo-core"><span><strong>Olmo-core</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a state-of-the-art framework for distributed model training.</li><li><a data-current="false" href="https://github.com/allenai/open-instruct"><span><strong>Open Instruct</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is our post-training pipeline. </li><li><a data-current="false" href="https://github.com/allenai/datamap-rs"><span><strong>datamap-rs</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a pure-Rust toolkit for large-scale cleaning.</li><li><a data-current="false" href="https://github.com/allenai/duplodocus"><span><strong>duplodocus</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> for ultra-efficient fuzzy de-duplication.</li><li><a data-current="false" href="https://github.com/allenai/olmes"><span><strong>OLMES</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a toolkit for reproducible evals. It includes our brand-new eval collection <strong>OlmoBaseEval</strong>, which we used for Olmo 3 base model development.</li><li><a data-current="false" href="https://github.com/allenai/decon"><span><strong>decon</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> removes test sets from training data.</li></ul><p>Importantly, our tooling allows you to instrument complex tasks and analyze intermediate traces to understand where the models succeed—or struggle. Because the Olmo 3 data recipes, training pipeline, and checkpoints are open, independent teams can connect model behavior back to measurable properties. </p><h3><strong>Ready to deploy and use</strong></h3><p>Together, the Olmo 3 family makes it easier to build trustworthy features quickly, whether for research, education, or applications. By making every development step available and inspectable, we&#39;re enabling entirely new categories of research. You can run experiments on any training phase, understand exactly how different techniques contribute to model capabilities, and build on our work at whatever stage makes sense for your project.</p><p>For scientists, the fully open flow exposes the model’s inner workings, so you can instrument experiments across coding, reasoning, RL, and tool use. </p><p>If you care about AI you can study, audit, and improve, Olmo 3 is for you. Try the demos in the Ai2 Playground, explore the documentation, and build on the released weights and checkpoints. Then tell us what you discover—we invite the community to validate, critique, and extend our findings.</p><p>True openness in AI isn&#39;t just about access—it&#39;s about trust, accountability, and shared progress. We believe the models shaping our future should be fully inspectable, not black boxes. Olmo 3 represents a different path: one where anyone can understand, verify, and build upon the AI systems that increasingly influence our world. This is what open-first means—not just releasing weights, but sharing the complete knowledge needed to advance AI responsibly: the flow.</p><p><a data-current="false" href="https://playground.allenai.org?utm_source=ai2-blog&amp;utm_medium=referral&amp;utm_campaign=olmo3_launch"><span>Try Olmo 3</span><svg><use href="#arrow-angled-svg"></use></svg></a><strong> | </strong><a data-current="false" href="https://huggingface.co/collections/allenai/olmo-3-68e80f043cc0d3c867e7efc6"><span>Download the models &amp; data</span><svg><use href="#arrow-angled-svg"></use></svg></a> <strong>| </strong><a data-current="false" href="http://allenai.org/papers/olmo3"><span>Read the report</span><svg><use href="#arrow-angled-svg"></use></svg></a></p></div></section><section><div><p>Deep dive with Olmo lead researchers Hanna Hajishirzi and Noah Smith on how – and why – we built Olmo 3, and what comes next:</p></div><figure><p><a target="_blank" rel="noopener noreferrer" aria-label="View Olmo 3 | A family of leading fully open LMs and complete model flow on YouTube" href="https://youtube.com/watch?v=7A2_YPtN1Eo"><span><img alt="" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=3840&amp;q=75 3840w" src="https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=3840&amp;q=75"/><span><svg><use href="#play-svg"></use></svg></span></span></a></p></figure></section><section><h2>Subscribe to receive monthly updates about the latest Ai2 news.</h2></section></div></div>
  </body>
</html>
