<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/simonw/1991-WWW-NeXT-Implementation">Original</a>
    <h1>1991 WWW-NeXT Implementation</h1>
    
    <div id="readability-page-1" class="page"><article>
      <p>Starting my batch at the Recurse Center, I knew one of the things I wanted to learn was the basics of database internals. My goal was to answer a basic question: “what does a database look like physically, from the perspective of files on disk?”</p>
<h2>B+Trees</h2>
<p>I started with <a href="https://build-your-own.org/database/">“Build Your Own Database From Scratch In Go”</a>. By working through the first half of the book in Rust, I learned:</p>
<ul>
<li>“Logs” in databases mean something pretty different from what I’m used to. Instead of storing information about a program’s operation history, a “write ahead log” is a data structure you can safely append incoming operations to. This allows concurrent operations to be safely stored in a durable fashion, even if the process crashes mid-write.</li>
<li>To build a persistent key/value store, it’s important to use a data structure where changes are atomic (again to be resilient to crashes mid-write). There are <a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree">LSM-trees</a>; all I know about them is that the acronym expands to Log-Structured Merge. There are also <a href="https://en.wikipedia.org/wiki/B%2B_tree">B+Trees</a>, which I’ve gotten up close and personal with.</li>
<li>For efficient manipulation of files on disk, it’s important to keep in mind segment sizes. The smallest possible disk read is often a few kilobytes; reading or writing less than that at a time is inefficient IO. Also, memory-mapping is the best approach if you need random access to disk.</li>
</ul>
<p>Following along, I <a href="https://github.com/ryanisaacg/catalog">built a memory-mapped B+Tree in Rust</a> to make sure I understood the concepts. A B+Tree consists of internal nodes with variable numbers of children and leaf nodes with data. Each node has a key, and the key type can be ordered between them. Internal nodes store the key ranges of their children, allowing them to determine which children to recurse to when finding a node. There’s also a rebalancing algorithm to split up nodes that get too large and condense nodes that get too small, to ensure that the height of the tree remains small (and thus fast to traverse).</p>
<p>I think my implementation doesn’t fully rebalance itself (making it inefficient), but it does correctly handle get/insert/remove operations. Using <code>mmap</code> means that the file is automatically updated under the hood, which is how some real database systems work. Unfortunately <code>mmap</code> is super unergonomic in Rust, because I’m taking a byte array and doing a bunch of unsafe witchery to map the bytes to data structures. I think my use of <code>MaybeUninit</code> in this code is actually unsound? So I wouldn’t use that B+Tree code as a good example of anything.</p>
<h2>SQLite Format</h2>
<p>In week 2 I joined some of my batchmates in writing SQLite from scratch. I decided to <a href="https://github.com/ryanisaacg/sqlite">go about this in Zig</a>, partially to learn a new language and partially to avoid the memory-mapping problems I had in Rust. The first step is to parse <a href="https://www.sqlite.org/fileformat.html#the_database_header">the database file’s header</a>, which is pretty simple. Things immediately kicked up a notch on the next step, as I began to dig into SQLite’s internal structures. Each SQLite database is represented by pages (4096 bytes in the test database, but it can be configured on a per-DB basis). Each page consists of a header, an array of internal pointers to “cells”, and then the cells themselves. A page is a node in a B+Tree, either a leaf or branch; these trees represent tables and indices in SQLite.</p>
<p>All this actually sounds pretty simple. Let me assure you that there was plenty of room to write frustrating, hard-to-understand bugs along the way:</p>
<ul>
<li>All the integers in the format are big endian. Somehow I managed to read in exactly one value in the header in little endian, which took me hours to track down.</li>
<li>Cells have a variable length, so their locations in the page data cannot be determined except by the cell-offset array.</li>
<li>Pages are 1-indexed. Assuming pages are 0-indexed won’t fail loudly, but it will result in incorrect programs that report odd things.</li>
<li>The cell offsets on the first database page treat the database header as belonging to that page, so their offsets aren’t relative to the page header but rather to byte 0.</li>
</ul>
<p>After I had worked through these initial obstacles, my program was able to enumerate the tables in a SQLite database file and read the <code>sqlite_schema</code> table to determine their names. For now I’ve stopped there, because I feel like I’ve developed a good understanding of the physical basis of database file storage.</p>
<h2>Takeaways</h2>
<p>With what I learned from my projects, I can return to my initial question of “what does a database look like physically?” At its simplest, my answer is two core facts:</p>
<ol>
<li>A key-value store is represented by a tree (probably a B+Tree or an LSM tree) which allows for atomic writes.</li>
<li>Each table in a SQL database can be thought of as a key-value store, with primary keys as keys and rows as values. Each column’s data is contained in the row, or in an overflow section the  row points to.</li>
</ol>
<p>My immediate curiosity is quenched, but the field of database implementation is vast and there are still plenty of things I’d like to learn!</p>
<ul>
<li>How are queries planned? This is sort of the ‘missing middle’ in my mental model of SQL queries. I understand parsing pretty well and I think I now understand what primitives the database has to manipulate its tables, but I’m curious what happens between. This is the question I’m most interested in, and most likely to return to in my batch.
<ul>
<li>Sub-question: is a single-value query like <code>SELECT * FROM mytable WHERE mytable.id = 12345;</code> going through the query planner? Or is this equivalent to a single key lookup operation? Likewise for full-table scans like <code>SELECT * FROM mytable;</code></li>
</ul>
</li>
<li>How are tables with multiple primary keys (like you’d use in an M:N relationship) represented? Are the keys concatenated?</li>
<li>What is an index? I’ve never had cause to use one but I’ve also never worked with large volumes of production data in SQL.</li>
<li>How do databases implement locking? My understanding is that SQLite only allows one writer for the database a time, but larger engines like MySQL or Postgres lock on a much more granular basis.</li>
<li>What determines database performance characteristics? I’ve heard at truly large scales (e.g. Google) SQL doesn’t run fast enough; why is that? Is it a consequence of data layout, or the SQL query language, or the guarantees of the relational model?</li>
<li>How are document databases (like Mongo or Firestore) similar or different to a key/value store or relational database under the hood?</li>
</ul>
<p><em>Thanks to Nicholas Walton and <a href="https://annahope.me/">Anna Hope</a> for feedback on a draft of this post.</em></p>

    </article></div>
  </body>
</html>
