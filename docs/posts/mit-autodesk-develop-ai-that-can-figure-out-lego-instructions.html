<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theregister.com/2022/07/27/lego_machine_learning_ai_framework/">Original</a>
    <h1>MIT, Autodesk develop AI that can figure out Lego instructions</h1>
    
    <div id="readability-page-1" class="page"><div id="body">
<p>Stumped by a Lego set? A new machine learning framework can interpret those instructions for you. </p>
<p>Researchers at Stanford University, MIT&#39;s Computer Science and Artificial Intelligence Lab, and the Autodesk AI Lab have collaborated to develop a novel learning-based framework that can interpret 2D instructions to build 3D objects. </p>
<p>The Manual-to-Executable-Plan Network, or <a href="https://cs.stanford.edu/~rcwang/projects/lego_manual/" rel="nofollow">MEPNet</a>, was tested on computer-generated Lego sets, real Lego set instructions and Minecraft-style voxel building plans, and the researchers said it outperformed existing methods across the board. </p>
<h3>
  <span>MEPNet&#39;s novel idea</span>
</h3>
<p>Interpreting 2D instructions isn&#39;t easy for artificial intelligence. The researchers said there are a couple key problems going from visual instructions that, like Lego sets, consist entirely of images: Identifying correspondence between 2D and 3D objects, and dealing with a lot of basic pieces, like Lego. </p>
<p>Basic Lego bricks, the researchers said, are often assembled into complex forms before being added to the main body of the model. This &#34;increases the difficulty for machines to interpret Lego manuals: it requires inferring 3D poses of unseen objects composed of seen primitives,&#34; the researchers said.</p>

    

<p>Existing methods of parsing manual steps into machine-executable plans mainly consist of two forms, the researchers said: Search-based methods that are simple and accurate but computationally expensive; and learning-based models that are fast but aren&#39;t very good at handling unseen 3D shapes.</p>

        


        

<p>MEPNet, the researchers said, combines both.</p>
<p>Starting with a 3D model of the components, the current state of the Lego set, and 2D manual images, MEPNet &#34;predicts a set of 2D keypoints and masks for each component,&#34; the researchers wrote.</p>
<ul>

<li><a href="https://www.theregister.com/2022/07/25/russian_chessbot_breaks_players_finger/">Russian ChessBot breaks child opponent&#39;s finger</a></li>
</ul>
<ul>

<li><a href="https://www.theregister.com/2022/07/19/touchless_computing_intel/">British boffins make touchless computing tech on the cheap</a></li>
</ul>
<ul>

<li><a href="https://www.theregister.com/2022/07/11/meta_says_its_latest_ai/">Meta&#39;s AI-based Wikipedia successor &#39;may be the next big break in NLP&#39;</a></li>
</ul>
<ul>

<li><a href="https://www.theregister.com/2022/07/09/ai_patent_feature_1/">AI inventors may find it difficult to patent their tech under today&#39;s laws</a></li>
</ul>
<p>Once that&#39;s done, the 2D keypoints &#34;are back-projected to 3D by finding possible connections between the base shape and the new components.&#34; The combination &#34;maintains the efficiency of learning-based models, and generalizes better to unseen 3D components,&#34; the team wrote.</p>
<h3>
  <span>But can it build my Ikea dresser?</span>
</h3>
<p>In the paper, the researchers said their aim is to create machines that help people assemble complex objects, and they include furniture alongside Lego bricks and voxel worlds in their list of applications.</p>
<p>We&#39;ve asked the researchers behind MEPNet about more potential uses of their new framework, but haven&#39;t heard back yet. In the meantime, it might be reasonable to assume MEPNet could build a bookshelf – at least virtually – given the necessary library of components and instructions.</p>

        

<p>All a human would have to do would be to interpret MEPNet&#39;s 3D renderings, which would hopefully be easier than flat-pack furniture instructions.</p>
<p>Those who want to test MEPNet, and are familiar with Pytorch, can find <a href="https://github.com/Relento/lego_release" rel="nofollow">its code on Github</a>. ®</p>                            

                </div></div>
  </body>
</html>
