<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.anandtech.com/show/21277/micron-kicks-off-production-of-hbm3e-memory">Original</a>
    <h1>Micron Kicks Off Production of HBM3E Memory</h1>
    
    <div id="readability-page-1" class="page"><section>
            <section>

                





<div>
    <div>
        <a href="https://danluu.com/show/21277/micron-kicks-off-production-of-hbm3e-memory"></a>
        <p><span>by <a href="#"></a><a href="https://danluu.com/Author/191">Anton Shilov</a> <em>on February 26, 2024 1:00 PM EST</em> </span></p><ul>
            <li>Posted in</li>
            <li><a href="https://danluu.com/tag/memory">Memory</a></li>
                <li><a href="https://danluu.com/tag/micron">Micron</a></li>
                <li><a href="https://danluu.com/tag/nvidia">NVIDIA</a></li>
                <li><a href="https://danluu.com/tag/hbm">HBM</a></li>
                <li><a href="https://danluu.com/tag/hbm3e">HBM3E</a></li>
                <li><a href="https://danluu.com/tag/h200">H200</a></li>
        </ul>
    </div>

    
    
    
</div>


<div>

                <p><img src="https://images.anandtech.com/doci/21277/HBM3-Gen2-Press-Deck_7_25_2023_000005-678_678x452.jpg" alt=""/>
                </p>

            


        <div>
            <p>Micron Technology on Monday said that it had initiated volume production of its HBM3E memory. The company&#39;s HBM3E known good stack dies (KGSDs) will be used for <a href="https://www.anandtech.com/show/21136/nvidia-at-sc23-h200-accelerator-with-hbm3e-and-jupiter-supercomputer-for-2024">Nvidia&#39;s H200 compute GPU</a> for artificial intelligence (AI) and high-performance computing (HPC) applications, which will ship in the second quarter of 2024.</p>

<p>Micron has announced it is mass-producing 24 GB 8-Hi HBM3E devices with a data transfer rate of 9.2 GT/s and a peak memory bandwidth of over 1.2 TB/s per device. Compared to HBM3, HBM3E increases data transfer rate and peak memory bandwidth by a whopping 44%, which is particularly important for bandwidth-hungry processors like Nvidia&#39;s H200.</p>

<p>Nvidia&#39;s H200 product relies on the Hopper architecture and offers the same computing performance as the H100. Meanwhile, it is equipped with 141 GB of HBM3E memory featuring bandwidth of up to 4.8 TB/s, a significant upgrade from 80 GB of HBM3 and up to 3.35 TB/s bandwidth in the case of the H100.</p>

<p>Micron&#39;s memory roadmap for AI is further solidified with the upcoming release of a 36 GB 12-Hi HBM3E product in March 2024. Meanwhile, it remains to be seen where those devices will be used.</p>

<p>Micron uses its 1β (1-beta) process technology to produce its HBM3E, which is a significant achievement for the company as it uses its latest production node for its data center-grade products, which is a testament to the manufacturing technology.</p>

<p>Starting mass production of HBM3E memory ahead of competitors SK Hynix and Samsung is a significant achievement for Micron, which currently holds a 10% market share in the HBM sector. This move is crucial for the company, as it allows Micron to introduce a premium product earlier than its rivals, potentially increasing its revenue and profit margins while gaining a larger market share.</p>

<p>&#34;<em>Micron is delivering a trifecta with this HBM3E milestone: time-to-market leadership, best-in-class industry performance, and a differentiated power efficiency profile,&#34; said Sumit Sadana, executive vice president and chief business officer at Micron Technology. &#34;AI workloads are heavily reliant on memory bandwidth and capacity, and Micron is very well-positioned to support the significant AI growth ahead through our industry-leading HBM3E and HBM4 roadmap, as well as our full portfolio of DRAM and NAND solutions for AI applications.</em>&#34;</p>

<p>Source: <a href="https://investors.micron.com/news-releases/news-release-details/micron-commences-volume-production-industry-leading-hbm3e">Micron</a></p>

        </div>
        
            
            
            
            
            


</div>

    



            </section>



        

        

    </section></div>
  </body>
</html>
