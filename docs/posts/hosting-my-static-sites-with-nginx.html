<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jvns.ca/blog/2022/01/24/hosting-my-static-sites-with-nginx/">Original</a>
    <h1>Hosting my static sites with nginx</h1>
    
    

<p>Hello! Recently I&rsquo;ve been thinking about putting my static sites on servers
that I run myself instead of using managed services like Netlify or GitHub
Pages.</p>

<p>Originally I thought that running my own servers would require a lot of
maintenance and be a huge pain, but I was chatting with Wesley about what kind
of maintainance <a href="https://blog.wesleyac.com/posts/how-i-run-my-servers">their servers</a> require, and
they convinced me that it might not be that bad.</p>

<p>So I decided to try out moving all my static sites to a $5/month server to see
what it was like.</p>

<p>Everything in here is pretty standard but I wanted to write down what I did
anyway because there are a surprising number of decisions and I like to see
what choices other people make.</p>

<h3 id="the-constraint-only-static-sites">the constraint: only static sites</h3>

<p>To keep things simple, I decided that this server would only run <code>nginx</code> and
only serve static sites. I have about 10 static sites right now, mostly projects for <a href="https://wizardzines.com">wizard zines</a>.</p>

<p>I decided to use a $5/month DigitalOcean droplet, which should very easily be
able to handle my existing traffic (about 3 requests per second and 100GB
of bandwidth per month). Right now it&rsquo;s using about 1% of its CPU. I picked
DigitalOcean because it was what I&rsquo;ve used before.</p>

<p>Also all the sites were already behind a CDN so they&rsquo;re still behind the same
CDN.</p>

<h3 id="problem-1-getting-a-clean-git-repo-for-each-build">problem 1: getting a clean Git repo for each build</h3>

<p>This was the most interesting problem so let&rsquo;s talk about it first!</p>

<p>Building the static sites might seem pretty easy &ndash; each one of them already
has a working build script.</p>

<p>But I have pretty bad hygiene around files on my laptop &ndash; often I have a bunch of
uncommitted files that I don&rsquo;t want to go onto the live site. So I wanted to
start every build with a clean Git repo. I also wanted this to be <em>fast</em> &ndash; I&rsquo;m
impatient so I wanted to be able to build and deploy most of my sites in less than 10
seconds.</p>

<p>I handled this by hacking together a tiny build system called
<a href="https://github.com/jvns/tinybuild/">tinybuild</a>. It&rsquo;s
basically a 4-line bash script, but with extra some command line arguments and
error checking. Here are the 4 lines of bash:</p>

<pre><code>docker build - -t tinybuild &lt; Dockerfile
CONTAINER_ID=$(docker run -v &quot;$PWD&quot;:/src -v &quot;./deploy:/artifact&quot; -d -t tinybuild /bin/bash)
docker exec $CONTAINER_ID bash -c &quot;git clone /src /build &amp;&amp; cd /build &amp;&amp; bash /src/scripts/build.sh&quot;
docker exec $CONTAINER_ID bash -c &quot;mv /build/public/* /artifact&quot;
</code></pre>

<p>These 4 lines:</p>

<ol>
<li>Build a Dockerfile with all the dependencies for that build</li>
<li>Clone my repo into <code>/build</code> in the container, so that I always start with a clean Git repo</li>
<li>Run the build script (<code>/src/scripts/build.sh</code>)</li>
<li>Copy the build artifacts into <code>./deploy</code> in the local directory</li>
</ol>

<p>Then once I have <code>./deploy</code>, I can rsync the result onto the server</p>

<p>It&rsquo;s fast because:</p>

<ul>
<li>the <code>docker build -</code> means I don&rsquo;t send any state from the repository to
the Docker daemon. This matters because one of my repos is 1GB (it has a lot
of PDFs in it) and sending all that to the Docker daemon takes forever</li>
<li>the <code>git clone</code> is from the local filesystem and I have a SSD so it&rsquo;s fast even for a 1GB repo</li>
<li>most of the build scripts just run <code>hugo</code> or <code>cat</code> so they&rsquo;re fast. The <code>npm</code> build scripts take maybe 30 seconds.</li>
</ul>

<h3 id="apparently-local-git-clones-make-hard-links">apparently local git clones make hard links</h3>

<p>A tiny interesting fact: I tried to do <code>git clone --depth 1</code> to speed up my git
clone, but git gave me this warning:</p>

<pre><code>warning: --depth is ignored in local clones; use file:// instead.
</code></pre>

<p>I think what&rsquo;s going on here is that git makes hard links of all the objects to
make a local clone (which is a lot faster than copying). So I guess with the
hard links approach <code>--depth 1</code> doesn&rsquo;t make sense for some reason? And
<code>file://</code> forces git to copy all objects instead, which is actually slower.</p>

<h3 id="bonus-now-my-builds-are-faster-than-they-used-to-be">bonus: now my builds are faster than they used to be!</h3>

<p>One nice thing about this is that my build/deploy time is less than it was on
Netlify. For <code>jvns.ca</code> it&rsquo;s about 7 seconds to build and deploy the site
instead of about a minute previously.</p>

<h3 id="running-the-builds-on-my-laptop-seems-nice">running the builds on my laptop seems nice</h3>

<p>I&rsquo;m the only person who develops all of my sites, so doing all the builds in a
Docker container on my computer seems to make sense. My computer is pretty fast
and all the files are already right there! No giant downloads! And doing it in
a Docker container keeps the build isolated.</p>

<h3 id="example-build-scripts">example build scripts</h3>

<p>Here are the build scripts for this blog (<code>jvns.ca</code>).</p>

<p><strong>Dockerfile</strong></p>

<pre><code>FROM ubuntu:20.04

RUN apt-get update &amp;&amp; apt-get install -y git
RUN apt-get install -y wget python2
RUN wget https://github.com/gohugoio/hugo/releases/download/v0.40.1/hugo_0.40.1_Linux-64bit.tar.gz
RUN wget https://github.com/sass/dart-sass/releases/download/1.49.0/dart-sass-1.49.0-linux-x64.tar.gz
RUN tar -xf dart-sass-1.49.0-linux-x64.tar.gz
RUN tar -xf hugo_0.40.1_Linux-64bit.tar.gz
RUN mv hugo /usr/bin/hugo
RUN mv dart-sass/sass /usr/bin/sass
</code></pre>

<p><strong>build-docker.sh</strong>:</p>

<pre><code>set -eu
scripts/parse_titles.py
sass sass/:static/stylesheets/
hugo
</code></pre>

<p><strong>deploy.sh</strong>:</p>

<pre><code>set -eu
tinybuild -s scripts/build-docker.sh \
          -l &quot;$PWD/deploy&quot; \
          -c /build/public

rsync-showdiff ./deploy/ root@staticsites:/var/www/jvns.ca
rm -rf ./deploy
</code></pre>

<h3 id="problem-2-getting-rsync-to-just-show-me-which-files-it-updated">problem 2: getting rsync to just show me which files it updated</h3>

<p>When I started using rsync to sync the files, it would list every single file
instead of just files that had changed. I think this was because I was
generating new files for every build, so the timestamps were always newer than
the files on the server.</p>

<p>I did a bunch of Googling and figured out this incantation to get rsync to just
show me files that were updated;</p>

<pre><code>rsync -avc --out-format='%n' &quot;$@&quot; | grep --line-buffered -v '/$'
</code></pre>

<p>I put that in a script called <code>rsync-showdiff</code> so I could reuse it. There might
be a better way, but this seems to work.</p>

<h3 id="problem-3-configuration-management">problem 3: configuration management</h3>

<p>All I needed to do to set up the server was:</p>

<ul>
<li>install nginx</li>
<li>create directories in /var/www for each site, like <code>/var/www/jvns.ca</code></li>
<li>create an nginx configuration for each site, like <code>/etc/nginx/sites-enabled/jvns.ca.conf</code></li>
<li>deploy the files (with my deploy script above)</li>
</ul>

<p>I wanted to use some kind of configuration management to do this because that&rsquo;s how I&rsquo;m
used to managing servers. I&rsquo;ve used Puppet a lot in the past at work, but I don&rsquo;t
really <em>like</em> using Puppet. So I decided to use Ansible even though I&rsquo;d never
used it before because it seemed simpler than using Puppet. Here&rsquo;s <a href="https://gist.github.com/jvns/06754e9e65b49dd461fefa071dd4aace">my current Ansible configuration</a>,
minus some of the templates it depends on.</p>

<p>I didn&rsquo;t use any Ansible plugins because I wanted to maximize the probability
that I would actually be able to run this thing in 3 years.</p>

<p>The most complicated thing in there is probably the <code>reload nginx</code> handler,
which makes sure that the configuration is still valid after I make an nginx
configuration update.</p>

<h3 id="problem-4-replacing-a-lambda-function">problem 4: replacing a lambda function</h3>

<p>I was using one Netlify lambda function to calculate purchasing power parity
(&ldquo;PPP&rdquo;) for countries that have a weaker currency relative to the US on <a href="https://wizardzines.com">https://wizardzines.com</a>. Basically it
gets your country using IP geolocation and then returns a discount code if
you&rsquo;re in a country that has a discount code. (like 70% off for India, for
example). So I needed to replace it.</p>

<p>I handled this by rewriting the (very small) program in Go, copying the
static binary to the server, and adding a <code>proxy_pass</code> for that site.</p>

<p>The program just looks up the country code from the <a href="https://support.cloudflare.com/hc/en-us/articles/200168236-Configuring-Cloudflare-IP-Geolocation">geolocation HTTP header</a>
in a hashmap, so it doesn&rsquo;t seem like it should cause maintenance problems.</p>

<h3 id="a-very-simple-nginx-config">a very simple nginx config</h3>

<p>I used the same nginx config file for templates for almost all my sites:</p>

<pre><code>server {
	listen 80;
	listen [::]:80;

	root /var/www/{{item.dir}};
	index index.html index.htm;
	server_name {{item.server}};

    location / {
        # First attempt to serve request as file, then
        # as directory, then fall back to displaying a 404.
        try_files $uri $uri/ =404;
    }
}
</code></pre>

<p>The <code>{{item.dir}}</code> is an Ansible thing.</p>

<p>I also added support for custom 404 pages (<code>error_page /404.html</code>) in the main <code>nginx.conf</code>.</p>

<p>I&rsquo;ll probably add TLS support with certbot later. My CDN handles TLS to the
client, I just need to make the connection between the CDN and the origin
server use TLS</p>

<p>Also I don&rsquo;t know if there are problems with using such a simple nginx config.
Maybe I&rsquo;ll learn about them!</p>

<h3 id="bonus-i-can-find-404s-more-easily">bonus: I can find 404s more easily</h3>

<p>Another nice bonus of this setup is that it&rsquo;s easier to see what&rsquo;s happening
with my site &ndash; I can just look at the nginx logs!</p>

<p>I ran <code>grep 404 /var/log/nginx/access.log</code> to figure out if I&rsquo;d broken
anything during the migration, and I actually ended up finding a lot of
links that had been broken for many years, but that I&rsquo;d just never noticed.</p>

<p>Netlify&rsquo;s analytics has a &ldquo;Top resources not found&rdquo; that shows you the most
common 404s, but I don&rsquo;t think there&rsquo;s any way to see <em>all</em> 404s.</p>

<h3 id="a-small-factor-costs">a small factor: costs</h3>

<p>Part of my motivation for this switch was &ndash; I was getting close to the Netlify
free tier&rsquo;s bandwidth limit (100GB/month), and Netlify charges $20/100GB for
additional bandwidth. Digital Ocean charges $1/100GB for additional bandwidth
(20x less), and my droplet comes with 1TB of bandwidth. So the bandwidth
pricing feels a lot more reasonable to me.</p>

<h3 id="we-ll-see-how-it-goes">we&rsquo;ll see how it goes!</h3>

<p>All my static sites are running on my own server now. I don&rsquo;t really know what
this will be like to maintain, we&rsquo;ll see how it goes &ndash; maybe I&rsquo;ll like it!
maybe I&rsquo;ll hate it! I definitely like the faster build times and that I can
easily look at my nginx logs.</p>

  </body>
</html>
