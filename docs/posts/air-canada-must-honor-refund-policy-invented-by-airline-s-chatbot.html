<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/">Original</a>
    <h1>Air Canada must honor refund policy invented by airline&#39;s chatbot</h1>
    
    <div id="readability-page-1" class="page"><div>
            <h4>
      Blame game    —
</h4>
            
            <h2 itemprop="description">Air Canada appears to have quietly killed its costly chatbot support.</h2>
            <section>

  


  
</section>        </div><section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GettyImages-1453660913-800x533.jpg" alt="Air Canada must honor refund policy invented by airline’s chatbot"/>
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 16:single/related:3be96e65dcfb5c467dc970978b485c40 --><!-- empty -->
<p>After months of resisting, Air Canada was <a href="https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html">forced</a> to give a partial refund to a grieving passenger who was misled by an airline chatbot inaccurately explaining the airline&#39;s bereavement travel policy.</p>
<p>On the day Jake Moffatt&#39;s grandmother died, Moffat immediately visited Air Canada&#39;s website to book a flight from Vancouver to Toronto. Unsure of how Air Canada&#39;s bereavement rates worked, Moffatt asked Air Canada&#39;s chatbot to explain.</p>
<p>The chatbot provided inaccurate information, encouraging Moffatt to book a flight immediately and then request a refund within 90 days. In reality, Air Canada&#39;s policy explicitly stated that the airline will not provide refunds for bereavement travel after the flight is booked. Moffatt dutifully attempted to follow the chatbot&#39;s advice and request a refund but was shocked that the request was rejected.</p>
<p>Moffatt tried for months to convince Air Canada that a refund was owed, sharing a screenshot from the chatbot that clearly claimed:</p>
<blockquote><p>If you need to travel immediately or have already travelled and would like to submit your ticket for a reduced bereavement rate, kindly do so within 90 days of the date your ticket was issued by completing our Ticket Refund Application form.</p></blockquote>
<p>Air Canada argued that because the chatbot response elsewhere linked to a page with the actual bereavement travel policy, Moffatt should have known bereavement rates could not be requested retroactively. Instead of a refund, the best Air Canada would do was to promise to update the chatbot and offer Moffatt a $200 coupon to use on a future flight.</p>                                            
                                                        
<p>Unhappy with this resolution, Moffatt refused the coupon and filed a small claims complaint in Canada&#39;s Civil Resolution Tribunal.</p>
<p>According to Air Canada, Moffatt never should have trusted the chatbot and the airline should not be liable for the chatbot&#39;s misleading information because Air Canada essentially argued that &#34;the chatbot is a separate legal entity that is responsible for its own actions,&#34; a <a href="https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html">court order</a> said.</p>
<p>Experts <a href="https://vancouversun.com/news/local-news/air-canada-told-it-is-responsible-for-errors-by-its-website-chatbot">told the Vancouver Sun</a> that Moffatt&#39;s case appeared to be the first time a Canadian company tried to argue that it wasn&#39;t liable for information provided by its chatbot.</p>
<p>Tribunal member Christopher Rivers, who decided the case in favor of Moffatt, called Air Canada&#39;s defense &#34;remarkable.&#34;</p>
<p>&#34;Air Canada argues it cannot be held liable for information provided by one of its agents, servants, or representatives—including a chatbot,&#34; Rivers wrote. &#34;It does not explain why it believes that is the case&#34; or &#34;why the webpage titled &#39;Bereavement travel&#39; was inherently more trustworthy than its chatbot.&#34;</p>
<p>Further, Rivers found that Moffatt had &#34;no reason&#34; to believe that one part of Air Canada&#39;s website would be accurate and another would not.</p>
<p>Air Canada &#34;does not explain why customers should have to double-check information found in one part of its website on another part of its website,&#34; Rivers wrote.</p>
<p>In the end, Rivers ruled that Moffatt was entitled to a partial refund of $650.88 in Canadian dollars (CAD) off the original fare (about $482 USD), which was $1,640.36 CAD (about $1,216 USD), as well as additional damages to cover interest on the airfare and Moffatt&#39;s tribunal fees.</p>
<p>Air Canada told Ars it will comply with the ruling and considers the matter closed.</p>
<h2>Air Canada’s chatbot appears to be disabled</h2>
<p>When Ars visited Air Canada&#39;s website on Friday, there appeared to be no chatbot support available, suggesting that Air Canada has disabled the chatbot.</p>                                            
                                                        
<p>Air Canada did not respond to Ars&#39; request to confirm whether the chatbot is still part of the airline&#39;s online support offerings.</p>
<p>Last March, Air Canada&#39;s chief information officer Mel Crocker <a href="https://www.theglobhttps://www.theglobeandmail.com/business/article-ai-call-centres/">told the Globe and Mail</a> that the airline had launched the chatbot as an AI &#34;experiment.&#34;</p>
<p>Initially, the chatbot was used to lighten the load on Air Canada&#39;s call center when flights experienced unexpected delays or cancellations.</p>
<p>“So in the case of a snowstorm, if you have not been issued your new boarding pass yet and you just want to confirm if you have a seat available on another flight, that’s the sort of thing we can easily handle with AI,” Crocker told the Globe and Mail.</p>
<p>Over time, Crocker said, Air Canada hoped the chatbot would &#34;gain the ability to resolve even more complex customer service issues,&#34; with the airline&#39;s ultimate goal to automate every service that did not require a &#34;human touch.&#34;</p>
<p>If Air Canada can use &#34;technology to solve something that can be automated, we will do that,” Crocker said.</p>
<p>Air Canada was seemingly so invested in experimenting with AI that Crocker told the Globe and Mail that &#34;Air Canada’s initial investment in customer service AI technology was much higher than the cost of continuing to pay workers to handle simple queries.&#34; It was worth it, Crocker said, because &#34;the airline believes investing in automation and machine learning technology will lower its expenses&#34; and &#34;fundamentally&#34; create &#34;a better customer experience.&#34;</p>
<p>It&#39;s now clear that for at least one person, the chatbot created a more frustrating customer experience.</p>
<p>Experts told the Vancouver Sun that Air Canada may have succeeded in avoiding liability in Moffatt&#39;s case if its chatbot had warned customers that the information that the chatbot provided may not be accurate.</p>
<p>Because Air Canada seemingly failed to take that step, Rivers ruled that &#34;Air Canada did not take reasonable care to ensure its chatbot was accurate.&#34;</p>
<p>&#34;It should be obvious to Air Canada that it is responsible for all the information on its website,&#34; Rivers wrote. &#34;It makes no difference whether the information comes from a static page or a chatbot.&#34;</p>

                                                </div>

            
            
            
        </section></div>
  </body>
</html>
