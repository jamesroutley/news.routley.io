<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://edmcman.github.io/blog/2024-01-11--fuzzy-hashing-for-code-comparisons/">Original</a>
    <h1>The performance of hashing for similar function detection</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Imagine that you reverse engineered a piece of malware in pain-staking detail,
only to find that the malware author created a slightly modified version of the
malware the next day.  You wouldn&#39;t want to redo all your hard work.  One way to
avoid this is to use code comparison techniques to try to identify pairs of
functions in the old and new version that are &#34;the same&#34; (which I put in quotes
because it&#39;s a bit of a nebulous concept, as we&#39;ll see).</p><p>There are several tools to help in such situations.  A very popular (formerly)
commercial tool is <a href="https://www.zynamics.com/bindiff.html">zynamics&#39; bindiff</a>,
which is now owned by Google and <a href="https://github.com/google/bindiff">free</a>. CMU
SEI&#39;s <a href="https://github.com/cmu-sei/pharos">Pharos</a> also includes a code
comparison utility called
<a href="https://github.com/cmu-sei/pharos/blob/master/tools/fn2hash/fn2hash.pod">fn2hash</a>,
which is the subject of this blog post.</p><h2 id="exact-hashing"><a href="#exact-hashing" aria-label="exact hashing permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Exact Hashing</h2><p>fn2hash employs several types of hashing, with the most commonly used one called
<em>PIC hashing</em>, where PIC stands for Position Independent Code.  To see why PIC
hashing is important, we&#39;ll actually start by looking at a naive precursor to
PIC hashing, which is to simply hash the instruction bytes of a function.  We&#39;ll
call this <em>exact hashing</em>.</p><p>Let&#39;s look at an example.  I compiled this <a href="https://github.com/edmcman/fuzzyhash-test/blob/main/src/oo.cpp">simple program
oo.cpp</a> with
<code>g++</code>.  Here&#39;s the beginning of the assembly code for the function <code>myfunc</code>
(<a href="https://github.com/edmcman/fuzzyhash-test/blob/main/exp1/oo.gcc.dis#L413">full
code</a>):</p><details open="">
<summary>Assembly code and bytes from oo.gcc</summary><div><div data-language="nasm"><pre><code>





<span><span>0x00401200</span>: <span>41</span> <span>56</span>                      <span>00</span> push     <span>r14</span></span><span>0x00401202</span>: bf <span>60</span> <span>00</span> <span>00</span> <span>00</span>            <span>-</span><span>08</span> mov      <span>edi</span>, <span>0x00000060</span><span>&lt;</span><span>96</span><span>&gt;</span>
<span>0x00401207</span>: <span>41</span> <span>55</span>                     <span>-</span><span>08</span> push     <span>r13</span>
<span>0x00401209</span>: <span>41</span> <span>54</span>                     <span>-</span><span>10</span> push     <span>r12</span>
<span>0x0040120b</span>: <span>55</span>                        <span>-</span><span>18</span> push     <span>rbp</span>
<span>0x0040120c</span>: <span>48</span> <span>83</span> ec <span>08</span>               <span>-</span><span>20</span> sub      <span>rsp</span>, <span>8</span>
<span><span>0x00401210</span>: e8 bb fe ff ff            <span>-</span><span>28</span> call     function <span>0x004010d0</span> <span>&#34;operator new(unsigned long)@plt&#34;</span></span></code></pre></div></div></details><h2 id="exact-bytes"><a href="#exact-bytes" aria-label="exact bytes permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Exact Bytes</h2><p>In the first highlighted line, you can see that the first instruction is a
<code>push r14</code>, which is encoded by the instruction bytes <code>41 56</code>.  If we collect the
encoded instruction bytes for every instruction in the function, we get:</p><details open="">
<summary>Exact bytes in oo.gcc</summary>
<div>
<div><div data-language="text"><pre><code>4156BF6000000041554154554883EC08E8BBFEFFFFBF6000000048C700F02040004889C548C7401010214000C740582A000000E898FEFFFFBF1000000048C700F02040004989C448C7401010214000C740582A000000E875FEFFFFBA0D000000BE48204000BF80404000C74008000000004989C5C6400C0048C700D8204000E82CFEFFFF488B05F52D0000488B40E84C8BB0704140004D85F60F842803000041807E38000F84160200004C89F7E898FBFFFF498B06BE0A000000488B4030483DD01540000F84CFFDFFFF4C89F7FFD00FBEF0E9C2FDFFFF410FBE7643BF80404000E827FEFFFF4889C7E8FFFDFFFF488B4500488B00483DE01740000F85AC0200004889EFFFD0488B4500488B4008483D601640000F84A0FDFFFFBA0D000000BE3A204000BF80404000E8C8FDFFFF488B05912D0000488B40E84C8BB0704140004D85F60F84C402000041807E38000F84820100004C89F7E8C8FBFFFF498B06BE0A000000488B4030483DD01540000F8463FEFFFF4C89F7FFD00FBEF0E956FEFFFF410FBE7643BF80404000E8C3FDFFFF4889C7E89BFDFFFF488B4500488B4008483D601640000F85600200004889EFFFD0E9E7FDFFFFBA0D000000BE1E204000BF80404000E863FDFFFF488B052C2D0000488B40E84C8BB0704140004D85F60F845F02000041807E38000F847D0100004C89F7E868FBFFFF498B06BE0A000000488B4030483DD01540000F8468FEFFFF4C89F7FFD00FBEF0E95BFEFFFF410FBE7643BF80404000E85EFDFFFF4889C7E836FDFFFF488B4510488D7D10488B4008483DE01540000F8506020000FFD0498B0424488B00483DE01740000F8449FEFFFFBA0D000000BE10204000BF80404000E8FAFCFFFF488B05C32C0000488B40E84C8BB0704140004D85F60F84F601000041807E38000F84440100004C89F7E838FBFFFF498B06BE0A000000488B4030483DD01540000F84A1FEFFFF4C89F7FFD00FBEF0E994FEFFFF410FBE7643BF80404000E8F5FCFFFF4889C7E8CDFCFFFF498B0424488B00483DE01740000F85B70100004C89E7FFD0E990FEFFFFBA0D000000BE3A204000BF80404000E896FCFFFF488B055F2C0000488B40E84C8BB0704140004D85F60F8492010000E864FAFFFF0F1F400041807E38000F84100100004C89F7E808FBFFFF498B06BE0A000000488B4030483DD01540000F84D5FEFFFF4C89F7FFD00FBEF0E9C8FEFFFF410FBE7643BF80404000E891FCFFFF4889C7E869FCFFFF4889EFBE60000000E8FC0300004C89E7BE10000000E8EF0300004883C4084C89EFBE100000005D415C415D415EE9D7030000</code></pre></div>
</div></div></details><p>We call this sequence the <em>exact bytes</em> of the function.  We can hash these
bytes to get an <em>exact hash</em>, 62CE2E852A685A8971AF291244A1283A.</p><h2 id="short-comings-of-exact-hashing"><a href="#short-comings-of-exact-hashing" aria-label="short comings of exact hashing permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Short-comings of Exact Hashing</h2><p>The highlighted call at address 0x401210 is a relative call, which means that
the target is specified as an offset from the current instruction (well,
technically the next instruction). If you look at the instruction bytes for this
instruction, it includes the bytes <code>bb fe ff ff</code>, which is 0xfffffebb in little
endian form; interpreted as a signed integer value, this is -325.  If we take
the address of the next instruction (0x401210 + 5 == 0x401215) and then add -325
to it, we get 0x4010d0, which is the address of <code>operator new</code>, the target of
the call.  Yay. So now we know that <code>bb fe ff ff</code> is an offset from the next
instruction. Such offsets are called <em>relative offsets</em> because they are
<em>relative</em> to the address of the next instruction.</p><p>I created a <a href="https://github.com/edmcman/fuzzyhash-test/blob/main/src/oo2.cpp#L62">slightly modified
program (oo2.gcc)</a> by
adding an empty, unused function before <code>myfunc</code>.  You can find the disassembly
of <code>myfunc</code> for this executable
<a href="https://github.com/edmcman/fuzzyhash-test/blob/main/exp1/oo2.gcc.dis#L422">here</a>.</p><p>If we take the exact hash of <code>myfunc</code> in this new executable, we get
05718F65D9AA5176682C6C2D5404CA8D.  Wait, that&#39;s different than the hash for
<code>myfunc</code> in the first executable, 62CE2E852A685A8971AF291244A1283A.  What
happened?  Let&#39;s look at the disassembly.</p><details open="">
<summary>Assembly code and bytes from oo2.gcc</summary>
<div><div data-language="nasm"><pre><code>



<span>0x00401210</span>: <span>41</span> <span>56</span>                      <span>00</span> push     <span>r14</span>
<span>0x00401212</span>: bf <span>60</span> <span>00</span> <span>00</span> <span>00</span>            <span>-</span><span>08</span> mov      <span>edi</span>, <span>0x00000060</span><span>&lt;</span><span>96</span><span>&gt;</span>
<span>0x00401217</span>: <span>41</span> <span>55</span>                     <span>-</span><span>08</span> push     <span>r13</span>
<span>0x00401219</span>: <span>41</span> <span>54</span>                     <span>-</span><span>10</span> push     <span>r12</span>
<span>0x0040121b</span>: <span>55</span>                        <span>-</span><span>18</span> push     <span>rbp</span>
<span>0x0040121c</span>: <span>48</span> <span>83</span> ec <span>08</span>               <span>-</span><span>20</span> sub      <span>rsp</span>, <span>8</span>
<span><span>0x00401220</span>: e8 ab fe ff ff            <span>-</span><span>28</span> call     function <span>0x004010d0</span> <span>&#34;operator new(unsigned long)@plt&#34;</span></span></code></pre></div></div>
</details><p>Notice that <code>myfunc</code> moved from 0x401200 to 0x401210, which also moved the
address of the call instruction from 0x401210 to 0x401220.  Because the call
target is specified as an offset from the (next) instruction&#39;s address, which
changed by 0x10 == 16, the offset bytes for the call changed from <code>bb fe ff ff</code>
(-325) to <code>ab fe ff ff</code> (-341 == -325 - 16).  These changes modify the exact
bytes to:</p><details open="">
<summary>Exact bytes in oo2.gcc</summary>
<div>
<div><div data-language="text"><pre><code>4156BF6000000041554154554883EC08E8ABFEFFFFBF6000000048C700F02040004889C548C7401010214000C740582A000000E888FEFFFFBF1000000048C700F02040004989C448C7401010214000C740582A000000E865FEFFFFBA0D000000BE48204000BF80404000C74008000000004989C5C6400C0048C700D8204000E81CFEFFFF488B05E52D0000488B40E84C8BB0704140004D85F60F842803000041807E38000F84160200004C89F7E888FBFFFF498B06BE0A000000488B4030483DE01540000F84CFFDFFFF4C89F7FFD00FBEF0E9C2FDFFFF410FBE7643BF80404000E817FEFFFF4889C7E8EFFDFFFF488B4500488B00483DF01740000F85AC0200004889EFFFD0488B4500488B4008483D701640000F84A0FDFFFFBA0D000000BE3A204000BF80404000E8B8FDFFFF488B05812D0000488B40E84C8BB0704140004D85F60F84C402000041807E38000F84820100004C89F7E8B8FBFFFF498B06BE0A000000488B4030483DE01540000F8463FEFFFF4C89F7FFD00FBEF0E956FEFFFF410FBE7643BF80404000E8B3FDFFFF4889C7E88BFDFFFF488B4500488B4008483D701640000F85600200004889EFFFD0E9E7FDFFFFBA0D000000BE1E204000BF80404000E853FDFFFF488B051C2D0000488B40E84C8BB0704140004D85F60F845F02000041807E38000F847D0100004C89F7E858FBFFFF498B06BE0A000000488B4030483DE01540000F8468FEFFFF4C89F7FFD00FBEF0E95BFEFFFF410FBE7643BF80404000E84EFDFFFF4889C7E826FDFFFF488B4510488D7D10488B4008483DF01540000F8506020000FFD0498B0424488B00483DF01740000F8449FEFFFFBA0D000000BE10204000BF80404000E8EAFCFFFF488B05B32C0000488B40E84C8BB0704140004D85F60F84F601000041807E38000F84440100004C89F7E828FBFFFF498B06BE0A000000488B4030483DE01540000F84A1FEFFFF4C89F7FFD00FBEF0E994FEFFFF410FBE7643BF80404000E8E5FCFFFF4889C7E8BDFCFFFF498B0424488B00483DF01740000F85B70100004C89E7FFD0E990FEFFFFBA0D000000BE3A204000BF80404000E886FCFFFF488B054F2C0000488B40E84C8BB0704140004D85F60F8492010000E854FAFFFF0F1F400041807E38000F84100100004C89F7E8F8FAFFFF498B06BE0A000000488B4030483DE01540000F84D5FEFFFF4C89F7FFD00FBEF0E9C8FEFFFF410FBE7643BF80404000E881FCFFFF4889C7E859FCFFFF4889EFBE60000000E8FC0300004C89E7BE10000000E8EF0300004883C4084C89EFBE100000005D415C415D415EE9D7030000</code></pre></div></div>
</div>
</details><p>You can look through that and see the differences by eyeballing it.  Just
kidding!  Here&#39;s a visual comparison.  Red represents bytes that are only in
oo.gcc, and green represents bytes in oo2.gcc.  The differences are small
because the offset is only changing by 0x10, but this is enough to break exact
hashing.</p><details open="">
<summary>Difference between exact bytes in oo.gcc and oo2.gcc</summary>
<div>
<pre>4156BF6000000041554154554883EC08E8<span>BB</span><span>AB</span>FEFFFFBF6000000048C700F02040004889C548C7401010214000C740582A000000E8<span>98</span><span>88</span>FEFFFFBF1000000048C700F02040004989C448C7401010214000C740582A000000E8<span>75</span><span>65</span>FEFFFFBA0D000000BE48204000BF80404000C74008000000004989C5C6400C0048C700D8204000E8<span>2C</span><span>1C</span>FEFFFF488B05<span>F5</span><span>E5</span>2D0000488B40E84C8BB0704140004D85F60F842803000041807E38000F84160200004C89F7E8<span>98</span><span>88</span>FBFFFF498B06BE0A000000488B4030483D<span>D0</span><span>E0</span>1540000F84CFFDFFFF4C89F7FFD00FBEF0E9C2FDFFFF410FBE7643BF80404000E8<span>27</span><span>17</span>FEFFFF4889C7E8<span>FF</span><span>EF</span>FDFFFF488B4500488B00483D<span>E0</span><span>F0</span>1740000F85AC0200004889EFFFD0488B4500488B4008483D<span>60</span><span>70</span>1640000F84A0FDFFFFBA0D000000BE3A204000BF80404000E8<span>C8</span><span>B8</span>FDFFFF488B05<span>91</span><span>81</span>2D0000488B40E84C8BB0704140004D85F60F84C402000041807E38000F84820100004C89F7E8<span>C8</span><span>B8</span>FBFFFF498B06BE0A000000488B4030483D<span>D0</span><span>E0</span>1540000F8463FEFFFF4C89F7FFD00FBEF0E956FEFFFF410FBE7643BF80404000E8<span>C3</span><span>B3</span>FDFFFF4889C7E8<span>9B</span><span>8B</span>FDFFFF488B4500488B4008483D<span>60</span><span>70</span>1640000F85600200004889EFFFD0E9E7FDFFFFBA0D000000BE1E204000BF80404000E8<span>63</span><span>53</span>FDFFFF488B05<span>2C</span><span>1C</span>2D0000488B40E84C8BB0704140004D85F60F845F02000041807E38000F847D0100004C89F7E8<span>68</span><span>58</span>FBFFFF498B06BE0A000000488B4030483D<span>D0</span><span>E0</span>1540000F8468FEFFFF4C89F7FFD00FBEF0E95BFEFFFF410FBE7643BF80404000E8<span>5E</span><span>4E</span>FDFFFF4889C7E8<span>36</span><span>26</span>FDFFFF488B4510488D7D10488B4008483D<span>E0</span><span>F0</span>1540000F8506020000FFD0498B0424488B00483D<span>E0</span><span>F0</span>1740000F8449FEFFFFBA0D000000BE10204000BF80404000E8<span>FA</span><span>EA</span>FCFFFF488B05<span>C3</span><span>B3</span>2C0000488B40E84C8BB0704140004D85F60F84F601000041807E38000F84440100004C89F7E8<span>38</span><span>28</span>FBFFFF498B06BE0A000000488B4030483D<span>D0</span><span>E0</span>1540000F84A1FEFFFF4C89F7FFD00FBEF0E994FEFFFF410FBE7643BF80404000E8<span>F5</span><span>E5</span>FCFFFF4889C7E8<span>CD</span><span>BD</span>FCFFFF498B0424488B00483D<span>E0</span><span>F0</span>1740000F85B70100004C89E7FFD0E990FEFFFFBA0D000000BE3A204000BF80404000E8<span>96</span><span>86</span>FCFFFF488B05<span>5F</span><span>4F</span>2C0000488B40E84C8BB0704140004D85F60F8492010000E8<span>64</span><span>54</span>FAFFFF0F1F400041807E38000F84100100004C89F7E8<span>08FB</span><span>F8FA</span>FFFF498B06BE0A000000488B4030483D<span>D0</span><span>E0</span>1540000F84D5FEFFFF4C89F7FFD00FBEF0E9C8FEFFFF410FBE7643BF80404000E8<span>91</span><span>81</span>FCFFFF4889C7E8<span>69</span><span>59</span>FCFFFF4889EFBE60000000E8FC0300004C89E7BE10000000E8EF0300004883C4084C89EFBE100000005D415C415D415EE9D7030000
</pre>
</div></details><h2 id="pic-hashing"><a href="#pic-hashing" aria-label="pic hashing permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>PIC Hashing</h2><p>This problem is the motivation for few different types of hashing that we&#39;ll
talk about in this blog post, including <em>PIC hashing</em> and <em>fuzzy hashing</em>.  The
PIC in <em>PIC hashing</em> stands for <em>Position Independent Code</em>.  At a high level,
the goal of PIC hashing is to compute a hash or signature of code, but do so in
a way that relocating the code will not change the hash. This is important
because, as we just saw, modifying a program often results in small changes to
addresses and offsets and we don&#39;t want these changes to modify the hash!. The
intuition behind PIC hashing is <em>very</em> straight-forward: identify offsets and
addresses that are likely to change if the program is recompiled, such as <code>bb fe ff ff</code>,
and simply set them to zero before hashing the bytes.  That way if they
change because the function is relocated, the function&#39;s PIC hash won&#39;t change.</p><p>The following visual diff shows the differences between the exact bytes and the
PIC bytes on <code>myfunc</code> in oo.gcc. Red represents bytes that are only in the PIC
bytes, and green represents the exact bytes.  As expected, the first
change we can see is the byte sequence <code>bb fe ff ff</code>, which is changed to zeros.</p><details open="">
<summary>Byte difference between PIC bytes (red) and exact bytes (green)</summary>
<div>
<pre>4156BF6000000041554154554883EC08E8<span>00000000</span><span>BBFEFFFF</span>BF6000000048C700<span>000000</span><span>F02040</span>004889C548C74010<span>000000</span><span>102140</span>00C740582A000000E8<span>00000000</span><span>98FEFFFF</span>BF1000000048C700<span>000000</span><span>F02040</span>004989C448C74010<span>000000</span><span>102140</span>00C740582A000000E8<span>00000000</span><span>75FEFFFF</span>BA0D000000BE<span>000000</span><span>482040</span>00BF<span>000000</span><span>804040</span>00C74008000000004989C5C6400C0048C700<span>000000</span><span>D82040</span>00E8<span>00000000</span><span>2CFEFFFF</span>488B05<span>0000</span><span>F52D</span>0000488B40E84C8BB0<span>000000</span><span>704140</span>004D85F60F842803000041807E38000F84160200004C89F7E8<span>00000000</span><span>98FBFFFF</span>498B06BE0A000000488B4030483D<span>000000</span><span>D01540</span>000F84CFFDFFFF4C89F7FFD00FBEF0E9C2FDFFFF410FBE7643BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>27FEFFFF</span>4889C7E8<span>00000000</span><span>FFFDFFFF</span>488B4500488B00483D<span>000000</span><span>E01740</span>000F85AC0200004889EFFFD0488B4500488B4008483D<span>000000</span><span>601640</span>000F84A0FDFFFFBA0D000000BE<span>000000</span><span>3A2040</span>00BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>C8FDFFFF</span>488B05<span>0000</span><span>912D</span>0000488B40E84C8BB0<span>000000</span><span>704140</span>004D85F60F84C402000041807E38000F84820100004C89F7E8<span>00000000</span><span>C8FBFFFF</span>498B06BE0A000000488B4030483D<span>000000</span><span>D01540</span>000F8463FEFFFF4C89F7FFD00FBEF0E956FEFFFF410FBE7643BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>C3FDFFFF</span>4889C7E8<span>00000000</span><span>9BFDFFFF</span>488B4500488B4008483D<span>000000</span><span>601640</span>000F85600200004889EFFFD0E9E7FDFFFFBA0D000000BE<span>000000</span><span>1E2040</span>00BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>63FDFFFF</span>488B05<span>0000</span><span>2C2D</span>0000488B40E84C8BB0<span>000000</span><span>704140</span>004D85F60F845F02000041807E38000F847D0100004C89F7E8<span>00000000</span><span>68FBFFFF</span>498B06BE0A000000488B4030483D<span>000000</span><span>D01540</span>000F8468FEFFFF4C89F7FFD00FBEF0E95BFEFFFF410FBE7643BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>5EFDFFFF</span>4889C7E8<span>00000000</span><span>36FDFFFF</span>488B4510488D7D10488B4008483D<span>000000</span><span>E01540</span>000F8506020000FFD0498B0424488B00483D<span>000000</span><span>E01740</span>000F8449FEFFFFBA0D000000BE<span>000000</span><span>102040</span>00BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>FAFCFFFF</span>488B05<span>0000</span><span>C32C</span>0000488B40E84C8BB0<span>000000</span><span>704140</span>004D85F60F84F601000041807E38000F84440100004C89F7E8<span>00000000</span><span>38FBFFFF</span>498B06BE0A000000488B4030483D<span>000000</span><span>D01540</span>000F84A1FEFFFF4C89F7FFD00FBEF0E994FEFFFF410FBE7643BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>F5FCFFFF</span>4889C7E8<span>00000000</span><span>CDFCFFFF</span>498B0424488B00483D<span>000000</span><span>E01740</span>000F85B70100004C89E7FFD0E990FEFFFFBA0D000000BE<span>000000</span><span>3A2040</span>00BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>96FCFFFF</span>488B05<span>0000</span><span>5F2C</span>0000488B40E84C8BB0<span>000000</span><span>704140</span>004D85F60F8492010000E8<span>00000000</span><span>64FAFFFF</span>0F1F400041807E38000F84100100004C89F7E8<span>00000000</span><span>08FBFFFF</span>498B06BE0A000000488B4030483D<span>000000</span><span>D01540</span>000F84D5FEFFFF4C89F7FFD00FBEF0E9C8FEFFFF410FBE7643BF<span>000000</span><span>804040</span>00E8<span>00000000</span><span>91FCFFFF</span>4889C7E8<span>00000000</span><span>69FCFFFF</span>4889EFBE60000000E8<span>0000</span><span>FC03</span>00004C89E7BE10000000E8<span>0000</span><span>EF03</span>00004883C4084C89EFBE100000005D415C415D415EE9<span>0000</span><span>D703</span>0000
</pre>
</div></details><p>If we hash the PIC bytes, we get the <em>PIC hash</em>
EA4256ECB85EDCF3F1515EACFA734E17. And, as we would hope, we get the <em>same</em> PIC
hash for <code>myfunc</code> in the slightly modified oo2.gcc.</p><p>The primary motivation behind PIC hashing is to detect identical code that is
moved to a different location. But what if two pieces of code are compiled with
different compilers or different compiler flags?  What if two functions are very
similar, but one has a line of code removed? Because these changes would modify
the non-offset bytes that are used in the PIC hash, it would change the PIC hash
of the code. Since we know that PIC hashing will not always work, in this
section we&#39;ll discuss how we can measure the performance of PIC hashing and
compare it to other code comparison techniques.</p><p>Before we can define the accuracy of any code comparison technique, we&#39;ll
need some ground truth that tells us which functions are equivalent.  For this
blog post, we&#39;ll use compiler debug symbols to map function addresses to their
names.  This will provide us with a ground truth set of functions <em>and</em> their
names. For the purposes of this blog post, and general expediency, we&#39;ll assume
that if two functions have the same name, they are &#34;the same&#34;.  (This obviously
is not true in general!)</p><h2 id="confusion-matrices"><a href="#confusion-matrices" aria-label="confusion matrices permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Confusion Matrices</h2><p>So, let&#39;s say we have two similar executables, and we want to evaluate how well
PIC hashing can identify equivalent functions across both executables.  We&#39;ll
start by considering all possible pairs of functions, where each pair contains a
function from each executable.  If we&#39;re being mathy, this is called the
cartesian product (between the functions in the first executable and the
functions in the second executable).  For each function pair, we&#39;ll use the
ground truth to determine if the functions are the same by seeing if they have
the same name.  Then we&#39;ll use PIC hashing to predict whether the functions are
the same by computing their hashes and seeing if they are identical.  There are
two outcomes for each determination, so there are four possibilities in total:</p><ul>
<li><span>True Positive (TP)</span>: PIC hashing
correctly predicted the functions are equivalent.</li>
<li><span>True Negative (TN)</span>: PIC hashing
correctly predicted the functions are different.</li>
<li><span>False Positive (FP)</span>: PIC hashing
incorrectly predicted the functions are equivalent, but they are not.</li>
<li><span>False Negative (FN)</span>: PIC hashing
incorrectly predicted the functions are different, but they are equivalent.</li>
</ul><p>To make it a little easier to interpret, we color the good outcomes <span>green</span> and the bad outcomes <span>red</span>.</p><p>We can represent these in what is called a <em>confusion matrix</em>:</p>



















<table><thead><tr><th></th><th>Hashing says same</th><th>Hashing says different</th></tr></thead><tbody><tr><td>Ground truth says same</td><td>TP</td><td>FN</td></tr><tr><td>Ground truth says different</td><td>FP</td><td>TN</td></tr></tbody></table><p>For example, here is a confusion matrix from an
<a href="#experiment-2d-openssl-111v-vs-111w">experiment</a> where I use PIC hashing to
compare openssl versions 1.1.1w and 1.1.1v when they are both compiled in the
same manner.  These two versions of openssl are very similar, so we would expect
that PIC hashing would do well because a lot of functions will be identical but
shifted to different addresses.  And, indeed, it does:</p>



















<table><thead><tr><th></th><th>Hashing says same</th><th>Hashing says different</th></tr></thead><tbody><tr><td>Ground truth says same</td><td>344</td><td>1</td></tr><tr><td>Ground truth says different</td><td>78</td><td>118,602</td></tr></tbody></table><h2 id="metrics-accuracy-precision-and-recall"><a href="#metrics-accuracy-precision-and-recall" aria-label="metrics accuracy precision and recall permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Metrics: Accuracy, Precision, and Recall</h2><p>So when does PIC hashing work well, and when does it not? In order to answer
these questions, we&#39;re going to need an easier way to evaluate the quality of a
confusion matrix as a single number.  At first glance, accuracy seems like the
most natural metric, which tell us: <em>How many pairs did hashing predict
correctly</em>? This is equal to</p><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mrow><mi>T</mi><mi>P</mi></mrow><mo>+</mo><mrow><mi>T</mi><mi>N</mi></mrow><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mrow><mi>T</mi><mi>P</mi></mrow><mo>+</mo><mrow><mi>T</mi><mi>N</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>N</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>T</mi></mrow><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">(\mathit{TP} + \mathit{TN}) / (\mathit{TP} + \mathit{TN} + \mathit{FN} + \mathit{FT}).</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>(</span><span><span>T</span><span>P</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>T</span><span>N</span></span><span>)</span><span>/</span><span>(</span><span><span>T</span><span>P</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>T</span><span>N</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>N</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>T</span></span><span>)</span><span>.</span></span></span></span></span></p><p>For the above example, PIC hashing achieved an accuracy of</p><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mn>344</mn><mo>+</mo><mn>118602</mn><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>344</mn><mo>+</mo><mn>118602</mn><mo>+</mo><mn>1</mn><mo>+</mo><mn>78</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.99</mn></mrow><annotation encoding="application/x-tex">(344 + 118602) / (344 + 118602 + 1 + 78) =
0.99</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>(</span><span>3</span><span>4</span><span>4</span><span></span><span>+</span><span></span></span><span><span></span><span>1</span><span>1</span><span>8</span><span>6</span><span>0</span><span>2</span><span>)</span><span>/</span><span>(</span><span>3</span><span>4</span><span>4</span><span></span><span>+</span><span></span></span><span><span></span><span>1</span><span>1</span><span>8</span><span>6</span><span>0</span><span>2</span><span></span><span>+</span><span></span></span><span><span></span><span>1</span><span></span><span>+</span><span></span></span><span><span></span><span>7</span><span>8</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>9</span><span>9</span></span></span></span></span></p><p>99.9% accuracy.  Pretty good, right?</p><p>But if you look closely, there&#39;s a subtle problem.  Most function pairs are
<em>not</em> equivalent.  According to the ground truth, there are <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>T</mi><mi>P</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>N</mi></mrow><mo>=</mo><mn>344</mn><mo>+</mo><mn>1</mn><mo>=</mo><mn>345</mn></mrow><annotation encoding="application/x-tex">\mathit{TP} +
\mathit{FN} = 344 + 1 = 345</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>T</span><span>P</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>N</span></span><span></span><span>=</span><span></span></span><span><span></span><span>3</span><span>4</span><span>4</span><span></span><span>+</span><span></span></span><span><span></span><span>1</span><span></span><span>=</span><span></span></span><span><span></span><span>3</span><span>4</span><span>5</span></span></span></span></span> equivalent function pairs, and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>T</mi><mi>N</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>P</mi></mrow><mo>=</mo><mn>118</mn><mo separator="true">,</mo><mn>602</mn><mo>+</mo><mn>78</mn><mo>=</mo><mn>118</mn><mo separator="true">,</mo><mn>680</mn></mrow><annotation encoding="application/x-tex">\mathit{TN} +
\mathit{FP} = 118,602 + 78 = 118,680</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>T</span><span>N</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>P</span></span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>1</span><span>8</span><span>,</span><span></span><span>6</span><span>0</span><span>2</span><span></span><span>+</span><span></span></span><span><span></span><span>7</span><span>8</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>1</span><span>8</span><span>,</span><span></span><span>6</span><span>8</span><span>0</span></span></span></span></span> non-equivalent function pairs.  So, if we
just guessed that all function pairs  were non-equivalent, we would still be
right <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>118680</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>118680</mn><mo>+</mo><mn>345</mn><mo stretchy="false">)</mo><mo>=</mo><mn>99.9</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">118680 / (118680 + 345) = 99.9\%</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>1</span><span>1</span><span>8</span><span>6</span><span>8</span><span>0</span><span>/</span><span>(</span><span>1</span><span>1</span><span>8</span><span>6</span><span>8</span><span>0</span><span></span><span>+</span><span></span></span><span><span></span><span>3</span><span>4</span><span>5</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>9</span><span>9</span><span>.</span><span>9</span><span>%</span></span></span></span></span> of the time.  Since accuracy weights
all function pairs equally, it is not the best metric here.</p><p>Instead, we want a metric that emphasizes positive results, which in this case
are equivalent function pairs.  This is consistent with our goal in reverse
engineering, because knowing that two functions are equivalent allows a reverse
engineer to transfer knowledge from one executable to another and save time!</p><p>Three metrics that focus more on <em>positive cases</em> (i.e., equivalent
functions) are <em>precision</em>, <em>recall</em>, and <em>F1 score</em>:</p><ul>
<li>Precision: <em>Of the function pairs hashing declared equivalent, how many
were actually equivalent?</em>  This is equal to <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>T</mi><mi>P</mi></mrow><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mrow><mi>T</mi><mi>P</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>P</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathit{TP} / (\mathit{TP} + \mathit{FP})</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>T</span><span>P</span></span><span>/</span><span>(</span><span><span>T</span><span>P</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>P</span></span><span>)</span></span></span></span></span>.</li>
<li>Recall: <em>Of the equivalent function pairs, how many did hashing correctly
declare as equivalent?</em>  This is equal to <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>T</mi><mi>P</mi></mrow><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mrow><mi>T</mi><mi>P</mi></mrow><mo>+</mo><mrow><mi>F</mi><mi>N</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathit{TP} / (\mathit{TP} + \mathit{FN})</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>T</span><span>P</span></span><span>/</span><span>(</span><span><span>T</span><span>P</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>F</span><span>N</span></span><span>)</span></span></span></span></span>.</li>
<li>F1 score: This is a single metric that reflects both the Precision and
Recall.  Specifically, it is the harmonic mean of the Precision and Recall,
or <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo>∗</mo><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mo>∗</mo><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mo>+</mo><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(2*\mathit{Recall}*\mathit{Precision}) /
(\mathit{Recall}+\mathit{Precision})</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>(</span><span>2</span><span></span><span>∗</span><span></span></span><span><span></span><span><span>R</span><span>e</span><span>c</span><span>a</span><span>l</span><span>l</span></span><span></span><span>∗</span><span></span></span><span><span></span><span><span>P</span><span>r</span><span>e</span><span>c</span><span>i</span><span>s</span><span>i</span><span>o</span><span>n</span></span><span>)</span><span>/</span><span>(</span><span><span>R</span><span>e</span><span>c</span><span>a</span><span>l</span><span>l</span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>P</span><span>r</span><span>e</span><span>c</span><span>i</span><span>s</span><span>i</span><span>o</span><span>n</span></span><span>)</span></span></span></span></span>.  Compared to the arithmetic mean, the
harmonic mean is more sensitive to low values. This means that if either
Precision or Recall is low, the F1 score will also be low.</li>
</ul><p>So, looking at the above example, we can compute the precision, recall, and F1
score.  The precision is <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>344</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>344</mn><mo>+</mo><mn>78</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.81</mn></mrow><annotation encoding="application/x-tex">344 / (344 + 78) = 0.81</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>3</span><span>4</span><span>4</span><span>/</span><span>(</span><span>3</span><span>4</span><span>4</span><span></span><span>+</span><span></span></span><span><span></span><span>7</span><span>8</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>8</span><span>1</span></span></span></span></span>, the recall is
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>344</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>344</mn><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.997</mn></mrow><annotation encoding="application/x-tex">344 / (344 + 1) = 0.997</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>3</span><span>4</span><span>4</span><span>/</span><span>(</span><span>3</span><span>4</span><span>4</span><span></span><span>+</span><span></span></span><span><span></span><span>1</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>9</span><span>9</span><span>7</span></span></span></span></span>, and the F1 score is <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>∗</mo><mn>0.81</mn><mo>∗</mo><mn>0.997</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>0.81</mn><mo>+</mo><mn>0.997</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.89</mn></mrow><annotation encoding="application/x-tex">2 * 0.81 * 0.997 / (0.81 + 0.997) = 0.89</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>2</span><span></span><span>∗</span><span></span></span><span><span></span><span>0</span><span>.</span><span>8</span><span>1</span><span></span><span>∗</span><span></span></span><span><span></span><span>0</span><span>.</span><span>9</span><span>9</span><span>7</span><span>/</span><span>(</span><span>0</span><span>.</span><span>8</span><span>1</span><span></span><span>+</span><span></span></span><span><span></span><span>0</span><span>.</span><span>9</span><span>9</span><span>7</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>8</span><span>9</span></span></span></span></span>.
So, PIC hashing is able to identify 81% of equivalent function pairs, and when
it does declare a pair is equivalent, it is correct 99.7% of the time.  This
corresponds to a F1 score of 0.89 out of 1.0, which is pretty good!</p><p>Now, you might be wondering how well PIC hashing performs when the differences
between executables are larger.</p><p>Let&#39;s look at another
<a href="#experiment-1a-openssl111w-compiled-with-different-compilers">experiment</a>.  In
this one, I compare an openssl executable compiled with gcc to one compiled with
clang.  Because gcc and clang generate assembly code differently, we would
expect there to be a lot more differences.</p><p>Here is a confusion matrix from this experiment:</p>



















<table><thead><tr><th></th><th>Hashing says same</th><th>Hashing says different</th></tr></thead><tbody><tr><td>Ground truth says same</td><td>23</td><td>301</td></tr><tr><td>Ground truth says different</td><td>31</td><td>117,635</td></tr></tbody></table><p>In this example, PIC hashing achieved a recall of <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>23</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>23</mn><mo>+</mo><mn>301</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.07</mn></mrow><annotation encoding="application/x-tex">23 / (23 + 301) = 0.07</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>2</span><span>3</span><span>/</span><span>(</span><span>2</span><span>3</span><span></span><span>+</span><span></span></span><span><span></span><span>3</span><span>0</span><span>1</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>0</span><span>7</span></span></span></span></span>, and
a precision of <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>23</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>23</mn><mo>+</mo><mn>31</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.43</mn></mrow><annotation encoding="application/x-tex">23 / (23 + 31) = 0.43</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>2</span><span>3</span><span>/</span><span>(</span><span>2</span><span>3</span><span></span><span>+</span><span></span></span><span><span></span><span>3</span><span>1</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>4</span><span>3</span></span></span></span></span>.  So, hashing is only able to identify 7%
of equivalent function pairs, but when it does declare a pair is equivalent, it
is correct 43% of the time.  This corresponds to a F1 score of 0.12 out of 1.0,
which is pretty bad. Imagine that you spent hours reverse engineering the 324
functions in one of the executables, only to find that PIC hashing was only able
to identify 23 of them in the other executable, so you would be forced to
needlessly reverse engineer the other functions from scratch.  That would be
pretty frustrating!  Can we do better?</p><p>There&#39;s a very different type of hashing called <em>fuzzy hashing</em>.  Like regular
hashing, there is a <code>hash</code> function that reads a sequence of bytes and produces a hash.
Unlike regular hashing, though, you don&#39;t compare fuzzy hashes with equality.
Instead, there is a <code>similarity</code> function which takes two fuzzy hashes as input,
and returns a number between 0 and 1, where 0 means completely dissimilar, and 1
means completely similar.</p><p>My colleague, Cory Cohen, and I, actually debated whether there is utility in
applying fuzzy hashes to instruction bytes, and our debate motivated this blog
post. I thought there would be a benefit, but Cory felt there would not.  Hence
these experiments!  For this blog post, I&#39;ll be using the <a href="https://arxiv.org/abs/1708.03346">Lempel-Ziv Jaccard
Distance</a> fuzzy hash, or just LZJD for short,
because it&#39;s very fast.  Most fuzzy hash algorithms are pretty slow.  In fact,
learning about LZJD is what motivated our debate.  The possibility of a fast
fuzzy hashing algorithm opens up the possibility of using fuzzy hashes to search
for similar functions in a large database and other interesting possibilities.</p><p>I&#39;ll also be using <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein
distance</a> as a baseline.
Levenshtein distance is a measure of how many changes you need to make to one
string to transform it to another.  For example, the Levenshtein distance between &#34;cat&#34;
and &#34;bat&#34; is 1, because you only need to change the first letter.  Levenshtein
distance allows us to define an optimal notion of similarity at the instruction
byte level. The trade-off is that it&#39;s <strong>really</strong> slow, so it&#39;s only really
useful as a baseline in our experiments.</p><p>To test the accuracy of PIC hashing under various scenarios, I defined a few
experiments.  Each experiment takes a similar (or identical) piece of source
code and compiles it, sometimes with different compilers or flags.</p><h2 id="experiment-1-openssl-111w"><a href="#experiment-1-openssl-111w" aria-label="experiment 1 openssl 111w permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 1: openssl 1.1.1w</h2><p>In this experiment, I compiled openssl 1.1.1w in a few different ways.  In each
case, I examined the resulting <code>openssl</code> executable.</p><h3 id="experiment-1a-openssl111w-compiled-with-different-compilers"><a href="#experiment-1a-openssl111w-compiled-with-different-compilers" aria-label="experiment 1a openssl111w compiled with different compilers permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 1a: openssl1.1.1w Compiled With Different Compilers</h3><p>In this first experiment, I compiled openssl 1.1.1w with <code>gcc -O3 -g</code> and <code>clang
-O3 -g</code> and compared the results.  We&#39;ll start with the confusion matrix for PIC
hashing:</p>



















<table><thead><tr><th></th><th>Hashing says same</th><th>Hashing says different</th></tr></thead><tbody><tr><td>Ground truth says same</td><td>23</td><td>301</td></tr><tr><td>Ground truth says different</td><td>31</td><td>117,635</td></tr></tbody></table><p>As we saw earlier, this results in a recall of 0.07, a precision of 0.45, and a
F1 score of 0.12. To summarize: pretty bad.</p><p>How do LZJD and LEV do?  Well, that&#39;s a bit harder to quantify, because we have
to pick a similarity threshold at which we consider the function to be &#34;the
same&#34;. For example, at a threshold of 0.8, we&#39;d consider a pair of functions to
be the same if they had a similarity score of 0.8 or higher. To communicate this
information, we could output a confusion matrix for each possible threshold.
Instead of doing this, I&#39;ll plot the results for a range of thresholds below:</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/14502b9ba903c60cc9e33793f3f5809e/29114/openssl-bycompiler.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/14502b9ba903c60cc9e33793f3f5809e/e46ac/openssl-bycompiler.avif 450w /static/14502b9ba903c60cc9e33793f3f5809e/9b8d4/openssl-bycompiler.avif 900w /static/14502b9ba903c60cc9e33793f3f5809e/2eb22/openssl-bycompiler.avif 1800w /static/14502b9ba903c60cc9e33793f3f5809e/f696c/openssl-bycompiler.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/14502b9ba903c60cc9e33793f3f5809e/8626f/openssl-bycompiler.webp 450w /static/14502b9ba903c60cc9e33793f3f5809e/131f1/openssl-bycompiler.webp 900w /static/14502b9ba903c60cc9e33793f3f5809e/62ed8/openssl-bycompiler.webp 1800w /static/14502b9ba903c60cc9e33793f3f5809e/882b9/openssl-bycompiler.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/14502b9ba903c60cc9e33793f3f5809e/fc2a6/openssl-bycompiler.png 450w /static/14502b9ba903c60cc9e33793f3f5809e/1cfc2/openssl-bycompiler.png 900w /static/14502b9ba903c60cc9e33793f3f5809e/d61c2/openssl-bycompiler.png 1800w /static/14502b9ba903c60cc9e33793f3f5809e/29114/openssl-bycompiler.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/14502b9ba903c60cc9e33793f3f5809e/d61c2/openssl-bycompiler.png" alt="Precision vs. Recall plot for &#34;openssl gcc vs clang&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl gcc vs clang&#34;</figcaption>
  </figure></div></div><p>The red triangle represents the precision and recall of PIC hashing: 0.45 and
0.07 respectively, just like we got above. The solid line represents the
performance of LZJD, and the dashed line represents the performance of LEV
(Levenshtein distance).  The color tells us what threshold is being used for
LZJD and LEV.  On this graph, the ideal result would be at the top right (100%
recall and precision).  So, for LZJD and LEV to have an advantage, it should be
above or to the right of PIC hashing.  But we can see that both LZJD and LEV go
sharply to the left before moving up, which indicates that a substantial
decrease in precision is needed to improve recall.</p><p>Below is what I call the <em>violin plot</em>.  You may want to click on it to zoom in,
since it&#39;s pretty wide and my blog layout is not.
<a href="https://edmcman.github.io/blog/2023-11-25--click-for-full-screen">I also spent a long time getting that to work!</a>
There are three panels: the leftmost is for LEV, the
middle is for PIC hashing, and the rightmost is for LZJD.  On each panel, there
is a True column, which shows the distribution of similarity scores for
equivalent pairs of functions.  There is also a False column, which shows the
distribution scores for non-equivalent pairs of functions.  Since PIC hashing
does not provide a similarity score, we consider every pair to be either
equivalent (1.0) or not (0.0).  A horizontal dashed line is plotted to show the
threshold that has the highest F1 score (i.e., a good combination of both
precision and recall).  Green points indicate function pairs that are correctly
predicted as equivalent or not, whereas red points indicate mistakes.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/456b40ac56848e5ae88869bfb01e8b20/5d957/openssl-bycompiler-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/456b40ac56848e5ae88869bfb01e8b20/e46ac/openssl-bycompiler-violin.avif 450w /static/456b40ac56848e5ae88869bfb01e8b20/9b8d4/openssl-bycompiler-violin.avif 900w /static/456b40ac56848e5ae88869bfb01e8b20/2eb22/openssl-bycompiler-violin.avif 1800w /static/456b40ac56848e5ae88869bfb01e8b20/6123d/openssl-bycompiler-violin.avif 2700w /static/456b40ac56848e5ae88869bfb01e8b20/a27a0/openssl-bycompiler-violin.avif 3600w /static/456b40ac56848e5ae88869bfb01e8b20/ccf74/openssl-bycompiler-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/456b40ac56848e5ae88869bfb01e8b20/8626f/openssl-bycompiler-violin.webp 450w /static/456b40ac56848e5ae88869bfb01e8b20/131f1/openssl-bycompiler-violin.webp 900w /static/456b40ac56848e5ae88869bfb01e8b20/62ed8/openssl-bycompiler-violin.webp 1800w /static/456b40ac56848e5ae88869bfb01e8b20/a8ede/openssl-bycompiler-violin.webp 2700w /static/456b40ac56848e5ae88869bfb01e8b20/6f7c8/openssl-bycompiler-violin.webp 3600w /static/456b40ac56848e5ae88869bfb01e8b20/3bac0/openssl-bycompiler-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/456b40ac56848e5ae88869bfb01e8b20/fc2a6/openssl-bycompiler-violin.png 450w /static/456b40ac56848e5ae88869bfb01e8b20/1cfc2/openssl-bycompiler-violin.png 900w /static/456b40ac56848e5ae88869bfb01e8b20/d61c2/openssl-bycompiler-violin.png 1800w /static/456b40ac56848e5ae88869bfb01e8b20/b2313/openssl-bycompiler-violin.png 2700w /static/456b40ac56848e5ae88869bfb01e8b20/75ac7/openssl-bycompiler-violin.png 3600w /static/456b40ac56848e5ae88869bfb01e8b20/5d957/openssl-bycompiler-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/456b40ac56848e5ae88869bfb01e8b20/d61c2/openssl-bycompiler-violin.png" alt="Violin plot for &#34;openssl gcc vs clang&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl gcc vs clang&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>I like this visualization because it shows how well each similarity metric
differentiates the similarity distributions of equivalent and non-equivalent
function pairs.  Obviously, the hallmark of a good similarity metric is that the
distribution of equivalent functions should be higher than non-equivalent
functions!  Ideally, the similarity metric should produce distributions that do
not overlap at all, so we could draw a line between them.  In practice, the
distributions usually intersect, and so instead we&#39;re forced to make a trade-off
between precision and recall, as can be seen in the above Precision vs. Recall
graph.</p><p>Overall, we can see from the violin plot that LEV and LZJD have a slightly
higher F1 score (reported at the bottom of the violin plot), but none of these
techniques are doing a great job.  This implies that <code>gcc</code> and <code>clang</code> produce
code that is quite different syntactically.</p><h3 id="experiment-1b-openssl-111w-compiled-with-different-optimization-levels"><a href="#experiment-1b-openssl-111w-compiled-with-different-optimization-levels" aria-label="experiment 1b openssl 111w compiled with different optimization levels permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 1b: openssl 1.1.1w Compiled With Different Optimization Levels</h3><p>The next comparison I did was to compile openssl 1.1.1w with <code>gcc -g</code> and
optimization levels <code>-O0</code>, <code>-O1</code>, <code>-O2</code>, <code>-O3</code>.</p><h4 id="-o0-and--o3"><a href="#-o0-and--o3" aria-label=" o0 and  o3 permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>-O0</code> and <code>-O3</code></h4><p>Let&#39;s start with one of the extremes, comparing <code>-O0</code> and <code>-O3</code>:</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/842f997f8b57d9223b49a24605aaffd7/29114/openssl-byopt-O0-O3.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/842f997f8b57d9223b49a24605aaffd7/e46ac/openssl-byopt-O0-O3.avif 450w /static/842f997f8b57d9223b49a24605aaffd7/9b8d4/openssl-byopt-O0-O3.avif 900w /static/842f997f8b57d9223b49a24605aaffd7/2eb22/openssl-byopt-O0-O3.avif 1800w /static/842f997f8b57d9223b49a24605aaffd7/f696c/openssl-byopt-O0-O3.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/842f997f8b57d9223b49a24605aaffd7/8626f/openssl-byopt-O0-O3.webp 450w /static/842f997f8b57d9223b49a24605aaffd7/131f1/openssl-byopt-O0-O3.webp 900w /static/842f997f8b57d9223b49a24605aaffd7/62ed8/openssl-byopt-O0-O3.webp 1800w /static/842f997f8b57d9223b49a24605aaffd7/882b9/openssl-byopt-O0-O3.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/842f997f8b57d9223b49a24605aaffd7/fc2a6/openssl-byopt-O0-O3.png 450w /static/842f997f8b57d9223b49a24605aaffd7/1cfc2/openssl-byopt-O0-O3.png 900w /static/842f997f8b57d9223b49a24605aaffd7/d61c2/openssl-byopt-O0-O3.png 1800w /static/842f997f8b57d9223b49a24605aaffd7/29114/openssl-byopt-O0-O3.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/842f997f8b57d9223b49a24605aaffd7/d61c2/openssl-byopt-O0-O3.png" alt="Precision vs. Recall plot for &#34;openssl -O0 vs -O3&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl -O0 vs -O3&#34;</figcaption>
  </figure></div></div><p>The first thing you might be wondering about in this graph is <em>Where is PIC
hashing?</em>  Well, it&#39;s there at (0, 0) if you look closely.  The violin plot
gives us a little more information about what is going on.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/a22d64e185a2ae09f86df943bc03f819/5d957/openssl-byopt-O0-O3-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/a22d64e185a2ae09f86df943bc03f819/e46ac/openssl-byopt-O0-O3-violin.avif 450w /static/a22d64e185a2ae09f86df943bc03f819/9b8d4/openssl-byopt-O0-O3-violin.avif 900w /static/a22d64e185a2ae09f86df943bc03f819/2eb22/openssl-byopt-O0-O3-violin.avif 1800w /static/a22d64e185a2ae09f86df943bc03f819/6123d/openssl-byopt-O0-O3-violin.avif 2700w /static/a22d64e185a2ae09f86df943bc03f819/a27a0/openssl-byopt-O0-O3-violin.avif 3600w /static/a22d64e185a2ae09f86df943bc03f819/ccf74/openssl-byopt-O0-O3-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/a22d64e185a2ae09f86df943bc03f819/8626f/openssl-byopt-O0-O3-violin.webp 450w /static/a22d64e185a2ae09f86df943bc03f819/131f1/openssl-byopt-O0-O3-violin.webp 900w /static/a22d64e185a2ae09f86df943bc03f819/62ed8/openssl-byopt-O0-O3-violin.webp 1800w /static/a22d64e185a2ae09f86df943bc03f819/a8ede/openssl-byopt-O0-O3-violin.webp 2700w /static/a22d64e185a2ae09f86df943bc03f819/6f7c8/openssl-byopt-O0-O3-violin.webp 3600w /static/a22d64e185a2ae09f86df943bc03f819/3bac0/openssl-byopt-O0-O3-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/a22d64e185a2ae09f86df943bc03f819/fc2a6/openssl-byopt-O0-O3-violin.png 450w /static/a22d64e185a2ae09f86df943bc03f819/1cfc2/openssl-byopt-O0-O3-violin.png 900w /static/a22d64e185a2ae09f86df943bc03f819/d61c2/openssl-byopt-O0-O3-violin.png 1800w /static/a22d64e185a2ae09f86df943bc03f819/b2313/openssl-byopt-O0-O3-violin.png 2700w /static/a22d64e185a2ae09f86df943bc03f819/75ac7/openssl-byopt-O0-O3-violin.png 3600w /static/a22d64e185a2ae09f86df943bc03f819/5d957/openssl-byopt-O0-O3-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/a22d64e185a2ae09f86df943bc03f819/d61c2/openssl-byopt-O0-O3-violin.png" alt="Violin plot for &#34;openssl -O0 vs -O3&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl -O0 vs -O3&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>Here we can see that <em>PIC hashing made no positive predictions</em>.  In other
words, none of the PIC hashes from the <code>-O0</code> binary matched any of the PIC
hashes from the <code>-O3</code> binary.  I included this problem because I thought it
would be very challenging for PIC hashing, and I was right!  But after some
discussion with Cory, we realized something fishy was going on.  To achieve a
precision of 0.0, PIC hashing can&#39;t find <em>any</em> functions equivalent.  That
includes trivially simple functions.  If your function is just a <code>ret</code>
there&#39;s not much optimization to do.</p><p>Eventually, I guessed that the <code>-O0</code> binary did not use the
<code>-fomit-frame-pointer</code> option, whereas all other optimization levels do. This
matters because this option changes the prologue and epilogue of <em>every</em>
function, which is why PIC hashing does so poorly here.</p><p>LEV and LZJD do <em>slightly</em> better again, achieving low (but non-zero) F1 scores.
But to be fair, none of the techniques do very well here.  It&#39;s a difficult
problem.</p><h4 id="-o2-and--o3"><a href="#-o2-and--o3" aria-label=" o2 and  o3 permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>-O2</code> and <code>-O3</code></h4><p>On the much easier extreme, let&#39;s look at <code>-O2</code> and <code>-O3</code>.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/7c7778b06fa3a8200b090e1cf90b5a94/29114/openssl-byopt-O2-O3.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/7c7778b06fa3a8200b090e1cf90b5a94/e46ac/openssl-byopt-O2-O3.avif 450w /static/7c7778b06fa3a8200b090e1cf90b5a94/9b8d4/openssl-byopt-O2-O3.avif 900w /static/7c7778b06fa3a8200b090e1cf90b5a94/2eb22/openssl-byopt-O2-O3.avif 1800w /static/7c7778b06fa3a8200b090e1cf90b5a94/f696c/openssl-byopt-O2-O3.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/7c7778b06fa3a8200b090e1cf90b5a94/8626f/openssl-byopt-O2-O3.webp 450w /static/7c7778b06fa3a8200b090e1cf90b5a94/131f1/openssl-byopt-O2-O3.webp 900w /static/7c7778b06fa3a8200b090e1cf90b5a94/62ed8/openssl-byopt-O2-O3.webp 1800w /static/7c7778b06fa3a8200b090e1cf90b5a94/882b9/openssl-byopt-O2-O3.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/7c7778b06fa3a8200b090e1cf90b5a94/fc2a6/openssl-byopt-O2-O3.png 450w /static/7c7778b06fa3a8200b090e1cf90b5a94/1cfc2/openssl-byopt-O2-O3.png 900w /static/7c7778b06fa3a8200b090e1cf90b5a94/d61c2/openssl-byopt-O2-O3.png 1800w /static/7c7778b06fa3a8200b090e1cf90b5a94/29114/openssl-byopt-O2-O3.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/7c7778b06fa3a8200b090e1cf90b5a94/d61c2/openssl-byopt-O2-O3.png" alt="Precision vs. Recall plot for &#34;openssl -O2 vs -O3&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl -O2 vs -O3&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/7404d09ebe925eb6391003bd97963b47/5d957/openssl-byopt-O2-O3-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/7404d09ebe925eb6391003bd97963b47/e46ac/openssl-byopt-O2-O3-violin.avif 450w /static/7404d09ebe925eb6391003bd97963b47/9b8d4/openssl-byopt-O2-O3-violin.avif 900w /static/7404d09ebe925eb6391003bd97963b47/2eb22/openssl-byopt-O2-O3-violin.avif 1800w /static/7404d09ebe925eb6391003bd97963b47/6123d/openssl-byopt-O2-O3-violin.avif 2700w /static/7404d09ebe925eb6391003bd97963b47/a27a0/openssl-byopt-O2-O3-violin.avif 3600w /static/7404d09ebe925eb6391003bd97963b47/ccf74/openssl-byopt-O2-O3-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/7404d09ebe925eb6391003bd97963b47/8626f/openssl-byopt-O2-O3-violin.webp 450w /static/7404d09ebe925eb6391003bd97963b47/131f1/openssl-byopt-O2-O3-violin.webp 900w /static/7404d09ebe925eb6391003bd97963b47/62ed8/openssl-byopt-O2-O3-violin.webp 1800w /static/7404d09ebe925eb6391003bd97963b47/a8ede/openssl-byopt-O2-O3-violin.webp 2700w /static/7404d09ebe925eb6391003bd97963b47/6f7c8/openssl-byopt-O2-O3-violin.webp 3600w /static/7404d09ebe925eb6391003bd97963b47/3bac0/openssl-byopt-O2-O3-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/7404d09ebe925eb6391003bd97963b47/fc2a6/openssl-byopt-O2-O3-violin.png 450w /static/7404d09ebe925eb6391003bd97963b47/1cfc2/openssl-byopt-O2-O3-violin.png 900w /static/7404d09ebe925eb6391003bd97963b47/d61c2/openssl-byopt-O2-O3-violin.png 1800w /static/7404d09ebe925eb6391003bd97963b47/b2313/openssl-byopt-O2-O3-violin.png 2700w /static/7404d09ebe925eb6391003bd97963b47/75ac7/openssl-byopt-O2-O3-violin.png 3600w /static/7404d09ebe925eb6391003bd97963b47/5d957/openssl-byopt-O2-O3-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/7404d09ebe925eb6391003bd97963b47/d61c2/openssl-byopt-O2-O3-violin.png" alt="Violin plot for &#34;openssl -O2 vs -O3&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl -O2 vs -O3&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>Nice!  PIC hashing does pretty well here, achieving a recall of 0.79 and a
precision of 0.78.  LEV and LZJD do about the same.  However, the Precision vs.
Recall graph for LEV shows a much more appealing trade-off line.  LZJD&#39;s
trade-off line is not nearly as appealing, as it&#39;s more horizontal.</p><p>You can start to see more of a difference between the distributions in the
violin plots here in the LEV and LZJD panels.</p><p>I&#39;ll call this one a tie.</p><h4 id="-o1-and--o2"><a href="#-o1-and--o2" aria-label=" o1 and  o2 permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>-O1</code> and <code>-O2</code></h4><p>I would also expect <code>-O1</code> and <code>-O2</code> to be fairly similar, but not as similar as
<code>-O2</code> and <code>-O3</code>.  Let&#39;s see:</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/a8d24c0467b93fb21b0d548fcbe10eed/29114/openssl-byopt-O1-O2.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/a8d24c0467b93fb21b0d548fcbe10eed/e46ac/openssl-byopt-O1-O2.avif 450w /static/a8d24c0467b93fb21b0d548fcbe10eed/9b8d4/openssl-byopt-O1-O2.avif 900w /static/a8d24c0467b93fb21b0d548fcbe10eed/2eb22/openssl-byopt-O1-O2.avif 1800w /static/a8d24c0467b93fb21b0d548fcbe10eed/f696c/openssl-byopt-O1-O2.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/a8d24c0467b93fb21b0d548fcbe10eed/8626f/openssl-byopt-O1-O2.webp 450w /static/a8d24c0467b93fb21b0d548fcbe10eed/131f1/openssl-byopt-O1-O2.webp 900w /static/a8d24c0467b93fb21b0d548fcbe10eed/62ed8/openssl-byopt-O1-O2.webp 1800w /static/a8d24c0467b93fb21b0d548fcbe10eed/882b9/openssl-byopt-O1-O2.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/a8d24c0467b93fb21b0d548fcbe10eed/fc2a6/openssl-byopt-O1-O2.png 450w /static/a8d24c0467b93fb21b0d548fcbe10eed/1cfc2/openssl-byopt-O1-O2.png 900w /static/a8d24c0467b93fb21b0d548fcbe10eed/d61c2/openssl-byopt-O1-O2.png 1800w /static/a8d24c0467b93fb21b0d548fcbe10eed/29114/openssl-byopt-O1-O2.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/a8d24c0467b93fb21b0d548fcbe10eed/d61c2/openssl-byopt-O1-O2.png" alt="Precision vs. Recall plot for &#34;openssl -O1 vs -O2&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl -O1 vs -O2&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/053cce80a635e225a0af1a8018ed5dcc/5d957/openssl-byopt-O1-O2-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/053cce80a635e225a0af1a8018ed5dcc/e46ac/openssl-byopt-O1-O2-violin.avif 450w /static/053cce80a635e225a0af1a8018ed5dcc/9b8d4/openssl-byopt-O1-O2-violin.avif 900w /static/053cce80a635e225a0af1a8018ed5dcc/2eb22/openssl-byopt-O1-O2-violin.avif 1800w /static/053cce80a635e225a0af1a8018ed5dcc/6123d/openssl-byopt-O1-O2-violin.avif 2700w /static/053cce80a635e225a0af1a8018ed5dcc/a27a0/openssl-byopt-O1-O2-violin.avif 3600w /static/053cce80a635e225a0af1a8018ed5dcc/ccf74/openssl-byopt-O1-O2-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/053cce80a635e225a0af1a8018ed5dcc/8626f/openssl-byopt-O1-O2-violin.webp 450w /static/053cce80a635e225a0af1a8018ed5dcc/131f1/openssl-byopt-O1-O2-violin.webp 900w /static/053cce80a635e225a0af1a8018ed5dcc/62ed8/openssl-byopt-O1-O2-violin.webp 1800w /static/053cce80a635e225a0af1a8018ed5dcc/a8ede/openssl-byopt-O1-O2-violin.webp 2700w /static/053cce80a635e225a0af1a8018ed5dcc/6f7c8/openssl-byopt-O1-O2-violin.webp 3600w /static/053cce80a635e225a0af1a8018ed5dcc/3bac0/openssl-byopt-O1-O2-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/053cce80a635e225a0af1a8018ed5dcc/fc2a6/openssl-byopt-O1-O2-violin.png 450w /static/053cce80a635e225a0af1a8018ed5dcc/1cfc2/openssl-byopt-O1-O2-violin.png 900w /static/053cce80a635e225a0af1a8018ed5dcc/d61c2/openssl-byopt-O1-O2-violin.png 1800w /static/053cce80a635e225a0af1a8018ed5dcc/b2313/openssl-byopt-O1-O2-violin.png 2700w /static/053cce80a635e225a0af1a8018ed5dcc/75ac7/openssl-byopt-O1-O2-violin.png 3600w /static/053cce80a635e225a0af1a8018ed5dcc/5d957/openssl-byopt-O1-O2-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/053cce80a635e225a0af1a8018ed5dcc/d61c2/openssl-byopt-O1-O2-violin.png" alt="Violin plot for &#34;openssl -O1 vs -O2&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl -O1 vs -O2&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>The Precision vs. Recall graph is very interesting.  PIC hashing starts at a
precision of 0.54 and a recall of 0.043.  LEV in particular shoots straight up,
indicating that by lowering the threshold, it is possible to increase recall
substantially without losing much precision.  A particularly attractive
trade-off might be a precision of 0.43 and a recall of 0.51.  This is the type
of trade-off I was hoping for in fuzzy hashing.</p><p>Unfortunately, LZJD&#39;s trade-off line is again not nearly as appealing, as it
curves in the wrong direction.</p><p>We&#39;ll say this is a pretty clear win for LEV.</p><h4 id="-o1-and--o3"><a href="#-o1-and--o3" aria-label=" o1 and  o3 permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>-O1</code> and <code>-O3</code></h4><p>Finally, let&#39;s compare <code>-O1</code> and <code>-O3</code>, which are different, but both have the
<code>-fomit-frame-pointer</code> option enabled by default.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/a2a316f79852d88bf7ece13dd44a4b7e/29114/openssl-byopt-O1-O3.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/a2a316f79852d88bf7ece13dd44a4b7e/e46ac/openssl-byopt-O1-O3.avif 450w /static/a2a316f79852d88bf7ece13dd44a4b7e/9b8d4/openssl-byopt-O1-O3.avif 900w /static/a2a316f79852d88bf7ece13dd44a4b7e/2eb22/openssl-byopt-O1-O3.avif 1800w /static/a2a316f79852d88bf7ece13dd44a4b7e/f696c/openssl-byopt-O1-O3.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/a2a316f79852d88bf7ece13dd44a4b7e/8626f/openssl-byopt-O1-O3.webp 450w /static/a2a316f79852d88bf7ece13dd44a4b7e/131f1/openssl-byopt-O1-O3.webp 900w /static/a2a316f79852d88bf7ece13dd44a4b7e/62ed8/openssl-byopt-O1-O3.webp 1800w /static/a2a316f79852d88bf7ece13dd44a4b7e/882b9/openssl-byopt-O1-O3.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/a2a316f79852d88bf7ece13dd44a4b7e/fc2a6/openssl-byopt-O1-O3.png 450w /static/a2a316f79852d88bf7ece13dd44a4b7e/1cfc2/openssl-byopt-O1-O3.png 900w /static/a2a316f79852d88bf7ece13dd44a4b7e/d61c2/openssl-byopt-O1-O3.png 1800w /static/a2a316f79852d88bf7ece13dd44a4b7e/29114/openssl-byopt-O1-O3.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/a2a316f79852d88bf7ece13dd44a4b7e/d61c2/openssl-byopt-O1-O3.png" alt="Precision vs. Recall plot for &#34;openssl -O1 vs -O3&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl -O1 vs -O3&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/24a53939842d3999d222259b862bff7c/5d957/openssl-byopt-O1-O3-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/24a53939842d3999d222259b862bff7c/e46ac/openssl-byopt-O1-O3-violin.avif 450w /static/24a53939842d3999d222259b862bff7c/9b8d4/openssl-byopt-O1-O3-violin.avif 900w /static/24a53939842d3999d222259b862bff7c/2eb22/openssl-byopt-O1-O3-violin.avif 1800w /static/24a53939842d3999d222259b862bff7c/6123d/openssl-byopt-O1-O3-violin.avif 2700w /static/24a53939842d3999d222259b862bff7c/a27a0/openssl-byopt-O1-O3-violin.avif 3600w /static/24a53939842d3999d222259b862bff7c/ccf74/openssl-byopt-O1-O3-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/24a53939842d3999d222259b862bff7c/8626f/openssl-byopt-O1-O3-violin.webp 450w /static/24a53939842d3999d222259b862bff7c/131f1/openssl-byopt-O1-O3-violin.webp 900w /static/24a53939842d3999d222259b862bff7c/62ed8/openssl-byopt-O1-O3-violin.webp 1800w /static/24a53939842d3999d222259b862bff7c/a8ede/openssl-byopt-O1-O3-violin.webp 2700w /static/24a53939842d3999d222259b862bff7c/6f7c8/openssl-byopt-O1-O3-violin.webp 3600w /static/24a53939842d3999d222259b862bff7c/3bac0/openssl-byopt-O1-O3-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/24a53939842d3999d222259b862bff7c/fc2a6/openssl-byopt-O1-O3-violin.png 450w /static/24a53939842d3999d222259b862bff7c/1cfc2/openssl-byopt-O1-O3-violin.png 900w /static/24a53939842d3999d222259b862bff7c/d61c2/openssl-byopt-O1-O3-violin.png 1800w /static/24a53939842d3999d222259b862bff7c/b2313/openssl-byopt-O1-O3-violin.png 2700w /static/24a53939842d3999d222259b862bff7c/75ac7/openssl-byopt-O1-O3-violin.png 3600w /static/24a53939842d3999d222259b862bff7c/5d957/openssl-byopt-O1-O3-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/24a53939842d3999d222259b862bff7c/d61c2/openssl-byopt-O1-O3-violin.png" alt="Violin plot for &#34;openssl -O1 vs -O3&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl -O1 vs -O3&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>These graphs look almost identical to comparing <code>-O1</code> and <code>-O2</code>; I guess the
difference between <code>-O2</code> and <code>-O3</code> is really pretty minor.  So it&#39;s again a win for LEV.</p><h2 id="experiment-2-different-openssl-versions"><a href="#experiment-2-different-openssl-versions" aria-label="experiment 2 different openssl versions permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 2: Different openssl Versions</h2><p>The final experiment I did was to compare various versions of openssl.  This
experiment was suggested by Cory, who thought it was reflective of typical
malware RE scenarios.  The idea is that the malware author released Malware 1.0,
which you RE.  Later, the malware changes a few things and releases Malware 1.1,
and you want to detect which functions <em>did not change</em> so that you can <em>avoid</em>
REing them again.</p><p>We looked at a few different versions of openssl:</p>


































<table><thead><tr><th>Version</th><th>Release Date</th><th>Months In Between</th></tr></thead><tbody><tr><td>1.0.2u</td><td>Dec 20, 2019</td><td>N/A</td></tr><tr><td>1.1.1</td><td>Sep 11, 2018</td><td>N/A</td></tr><tr><td>1.1.1q</td><td>Oct 12, 2022</td><td>49</td></tr><tr><td>1.1.1v</td><td>Aug 1, 2023</td><td>9</td></tr><tr><td>1.1.1w</td><td>Sep 11, 2023</td><td>1</td></tr></tbody></table><p>For each version, I compiled them using <code>gcc -g -O2</code>.</p><p>openssl 1.0 and 1.1 are different <em>minor</em> versions of openssl.  As explained <a href="https://wiki.openssl.org/index.php/Versioning">here</a>,</p><blockquote>
<p>Letter releases, such as 1.0.2a, exclusively contain bug and security fixes and no new features.</p>
</blockquote><p>So, we would expect that openssl 1.0.2u is fairly different than any 1.1.1
version.  And we would expect that in the same minor version, 1.1.1 would be
similar to 1.1.1q, but would be more different than 1.1.1w.</p><h3 id="experiment-2a-openssl-102u-vs-111w"><a href="#experiment-2a-openssl-102u-vs-111w" aria-label="experiment 2a openssl 102u vs 111w permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 2a: openssl 1.0.2u vs 1.1.1w</h3><p>As before, let&#39;s start with the most extreme comparison: 1.0.2u vs 1.1.1w.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/b51563590831977f10015b59507b142f/29114/openssl-byversion-1.1.1w-vs-1.0.2u.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/b51563590831977f10015b59507b142f/e46ac/openssl-byversion-1.1.1w-vs-1.0.2u.avif 450w /static/b51563590831977f10015b59507b142f/9b8d4/openssl-byversion-1.1.1w-vs-1.0.2u.avif 900w /static/b51563590831977f10015b59507b142f/2eb22/openssl-byversion-1.1.1w-vs-1.0.2u.avif 1800w /static/b51563590831977f10015b59507b142f/f696c/openssl-byversion-1.1.1w-vs-1.0.2u.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/b51563590831977f10015b59507b142f/8626f/openssl-byversion-1.1.1w-vs-1.0.2u.webp 450w /static/b51563590831977f10015b59507b142f/131f1/openssl-byversion-1.1.1w-vs-1.0.2u.webp 900w /static/b51563590831977f10015b59507b142f/62ed8/openssl-byversion-1.1.1w-vs-1.0.2u.webp 1800w /static/b51563590831977f10015b59507b142f/882b9/openssl-byversion-1.1.1w-vs-1.0.2u.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/b51563590831977f10015b59507b142f/fc2a6/openssl-byversion-1.1.1w-vs-1.0.2u.png 450w /static/b51563590831977f10015b59507b142f/1cfc2/openssl-byversion-1.1.1w-vs-1.0.2u.png 900w /static/b51563590831977f10015b59507b142f/d61c2/openssl-byversion-1.1.1w-vs-1.0.2u.png 1800w /static/b51563590831977f10015b59507b142f/29114/openssl-byversion-1.1.1w-vs-1.0.2u.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/b51563590831977f10015b59507b142f/d61c2/openssl-byversion-1.1.1w-vs-1.0.2u.png" alt="Precision vs. Recall plot for &#34;openssl 1.0.2u vs 1.1.1w&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl 1.0.2u vs 1.1.1w&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/32ef2ccd5de8d405e2cacdaa01557d3e/5d957/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/32ef2ccd5de8d405e2cacdaa01557d3e/e46ac/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 450w /static/32ef2ccd5de8d405e2cacdaa01557d3e/9b8d4/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 900w /static/32ef2ccd5de8d405e2cacdaa01557d3e/2eb22/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 1800w /static/32ef2ccd5de8d405e2cacdaa01557d3e/6123d/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 2700w /static/32ef2ccd5de8d405e2cacdaa01557d3e/a27a0/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 3600w /static/32ef2ccd5de8d405e2cacdaa01557d3e/ccf74/openssl-byversion-1.1.1w-vs-1.0.2u-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/32ef2ccd5de8d405e2cacdaa01557d3e/8626f/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 450w /static/32ef2ccd5de8d405e2cacdaa01557d3e/131f1/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 900w /static/32ef2ccd5de8d405e2cacdaa01557d3e/62ed8/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 1800w /static/32ef2ccd5de8d405e2cacdaa01557d3e/a8ede/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 2700w /static/32ef2ccd5de8d405e2cacdaa01557d3e/6f7c8/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 3600w /static/32ef2ccd5de8d405e2cacdaa01557d3e/3bac0/openssl-byversion-1.1.1w-vs-1.0.2u-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/32ef2ccd5de8d405e2cacdaa01557d3e/fc2a6/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 450w /static/32ef2ccd5de8d405e2cacdaa01557d3e/1cfc2/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 900w /static/32ef2ccd5de8d405e2cacdaa01557d3e/d61c2/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 1800w /static/32ef2ccd5de8d405e2cacdaa01557d3e/b2313/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 2700w /static/32ef2ccd5de8d405e2cacdaa01557d3e/75ac7/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 3600w /static/32ef2ccd5de8d405e2cacdaa01557d3e/5d957/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/32ef2ccd5de8d405e2cacdaa01557d3e/d61c2/openssl-byversion-1.1.1w-vs-1.0.2u-violin.png" alt="Violin plot for &#34;openssl 1.0.2u vs 1.1.1w&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl 1.0.2u vs 1.1.1w&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>Perhaps not too surprisingly, because the two binaries are quite different, all
three techniques struggle.  We&#39;ll say this is a three way tie.</p><h3 id="experiment-2b-openssl-111-vs-111w"><a href="#experiment-2b-openssl-111-vs-111w" aria-label="experiment 2b openssl 111 vs 111w permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 2b: openssl 1.1.1 vs 1.1.1w</h3><p>Now let&#39;s look at the original 1.1.1 release from September 2018, and compare to
the 1.1.1w bugfix release from September 2023.  Although a lot of time has
passed between the releases, the only differences should be bug and security
fixes.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/8ddee30451bff05a6a8b3ae6f3af1e0e/29114/openssl-byversion-1.1.1w-vs-1.1.1.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/8ddee30451bff05a6a8b3ae6f3af1e0e/e46ac/openssl-byversion-1.1.1w-vs-1.1.1.avif 450w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1.avif 900w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/2eb22/openssl-byversion-1.1.1w-vs-1.1.1.avif 1800w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/f696c/openssl-byversion-1.1.1w-vs-1.1.1.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/8ddee30451bff05a6a8b3ae6f3af1e0e/8626f/openssl-byversion-1.1.1w-vs-1.1.1.webp 450w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/131f1/openssl-byversion-1.1.1w-vs-1.1.1.webp 900w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/62ed8/openssl-byversion-1.1.1w-vs-1.1.1.webp 1800w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/882b9/openssl-byversion-1.1.1w-vs-1.1.1.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/8ddee30451bff05a6a8b3ae6f3af1e0e/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1.png 450w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1.png 900w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1.png 1800w /static/8ddee30451bff05a6a8b3ae6f3af1e0e/29114/openssl-byversion-1.1.1w-vs-1.1.1.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/8ddee30451bff05a6a8b3ae6f3af1e0e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1.png" alt="Precision vs. Recall plot for &#34;openssl 1.1.1 vs 1.1.1w&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl 1.1.1 vs 1.1.1w&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/e351ca7abb73aa7904196c28392e967e/5d957/openssl-byversion-1.1.1w-vs-1.1.1-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/e351ca7abb73aa7904196c28392e967e/e46ac/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 450w /static/e351ca7abb73aa7904196c28392e967e/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 900w /static/e351ca7abb73aa7904196c28392e967e/2eb22/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 1800w /static/e351ca7abb73aa7904196c28392e967e/6123d/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 2700w /static/e351ca7abb73aa7904196c28392e967e/a27a0/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 3600w /static/e351ca7abb73aa7904196c28392e967e/ccf74/openssl-byversion-1.1.1w-vs-1.1.1-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/e351ca7abb73aa7904196c28392e967e/8626f/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 450w /static/e351ca7abb73aa7904196c28392e967e/131f1/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 900w /static/e351ca7abb73aa7904196c28392e967e/62ed8/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 1800w /static/e351ca7abb73aa7904196c28392e967e/a8ede/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 2700w /static/e351ca7abb73aa7904196c28392e967e/6f7c8/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 3600w /static/e351ca7abb73aa7904196c28392e967e/3bac0/openssl-byversion-1.1.1w-vs-1.1.1-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/e351ca7abb73aa7904196c28392e967e/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 450w /static/e351ca7abb73aa7904196c28392e967e/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 900w /static/e351ca7abb73aa7904196c28392e967e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 1800w /static/e351ca7abb73aa7904196c28392e967e/b2313/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 2700w /static/e351ca7abb73aa7904196c28392e967e/75ac7/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 3600w /static/e351ca7abb73aa7904196c28392e967e/5d957/openssl-byversion-1.1.1w-vs-1.1.1-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/e351ca7abb73aa7904196c28392e967e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1-violin.png" alt="Violin plot for &#34;openssl 1.1.1 vs 1.1.1w&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl 1.1.1 vs 1.1.1w&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>All three techniques do much better on this experiment, presumably because there
are far fewer changes.  PIC hashing achieves a precision of 0.75 and a recall of
0.71.  LEV and LZJD go almost straight up, indicating an improvement in recall
with minimal trade-off in precision.  At roughly the same precision (0.75), LZJD
achieves a recall of 0.82, and LEV improves it to 0.89.</p><p>LEV is the clear winner, with LZJD also showing a clear advantage over PIC.</p><h3 id="experiment-2c-openssl-111q-vs-111w"><a href="#experiment-2c-openssl-111q-vs-111w" aria-label="experiment 2c openssl 111q vs 111w permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 2c: openssl 1.1.1q vs 1.1.1w</h3><p>Let&#39;s continue looking at more similar releases.  Now we&#39;ll compare 1.1.1q from
July 2022 to 1.1.1w from September 2023.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/bb738c8bea3337d40bfa23818e8f028d/29114/openssl-byversion-1.1.1w-vs-1.1.1q.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/bb738c8bea3337d40bfa23818e8f028d/e46ac/openssl-byversion-1.1.1w-vs-1.1.1q.avif 450w /static/bb738c8bea3337d40bfa23818e8f028d/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1q.avif 900w /static/bb738c8bea3337d40bfa23818e8f028d/2eb22/openssl-byversion-1.1.1w-vs-1.1.1q.avif 1800w /static/bb738c8bea3337d40bfa23818e8f028d/f696c/openssl-byversion-1.1.1w-vs-1.1.1q.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/bb738c8bea3337d40bfa23818e8f028d/8626f/openssl-byversion-1.1.1w-vs-1.1.1q.webp 450w /static/bb738c8bea3337d40bfa23818e8f028d/131f1/openssl-byversion-1.1.1w-vs-1.1.1q.webp 900w /static/bb738c8bea3337d40bfa23818e8f028d/62ed8/openssl-byversion-1.1.1w-vs-1.1.1q.webp 1800w /static/bb738c8bea3337d40bfa23818e8f028d/882b9/openssl-byversion-1.1.1w-vs-1.1.1q.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/bb738c8bea3337d40bfa23818e8f028d/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1q.png 450w /static/bb738c8bea3337d40bfa23818e8f028d/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1q.png 900w /static/bb738c8bea3337d40bfa23818e8f028d/d61c2/openssl-byversion-1.1.1w-vs-1.1.1q.png 1800w /static/bb738c8bea3337d40bfa23818e8f028d/29114/openssl-byversion-1.1.1w-vs-1.1.1q.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/bb738c8bea3337d40bfa23818e8f028d/d61c2/openssl-byversion-1.1.1w-vs-1.1.1q.png" alt="Precision vs. Recall plot for &#34;openssl 1.1.1q vs 1.1.1w&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl 1.1.1q vs 1.1.1w&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/a496d101247924fa2c7506465637ae21/5d957/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/a496d101247924fa2c7506465637ae21/e46ac/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 450w /static/a496d101247924fa2c7506465637ae21/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 900w /static/a496d101247924fa2c7506465637ae21/2eb22/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 1800w /static/a496d101247924fa2c7506465637ae21/6123d/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 2700w /static/a496d101247924fa2c7506465637ae21/a27a0/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 3600w /static/a496d101247924fa2c7506465637ae21/ccf74/openssl-byversion-1.1.1w-vs-1.1.1q-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/a496d101247924fa2c7506465637ae21/8626f/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 450w /static/a496d101247924fa2c7506465637ae21/131f1/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 900w /static/a496d101247924fa2c7506465637ae21/62ed8/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 1800w /static/a496d101247924fa2c7506465637ae21/a8ede/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 2700w /static/a496d101247924fa2c7506465637ae21/6f7c8/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 3600w /static/a496d101247924fa2c7506465637ae21/3bac0/openssl-byversion-1.1.1w-vs-1.1.1q-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/a496d101247924fa2c7506465637ae21/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 450w /static/a496d101247924fa2c7506465637ae21/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 900w /static/a496d101247924fa2c7506465637ae21/d61c2/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 1800w /static/a496d101247924fa2c7506465637ae21/b2313/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 2700w /static/a496d101247924fa2c7506465637ae21/75ac7/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 3600w /static/a496d101247924fa2c7506465637ae21/5d957/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/a496d101247924fa2c7506465637ae21/d61c2/openssl-byversion-1.1.1w-vs-1.1.1q-violin.png" alt="Violin plot for &#34;openssl 1.1.1q vs 1.1.1w&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl 1.1.1q vs 1.1.1w&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>As can be seen in the Precision vs. Recall graph, PIC hashing starts at an
impressive precision of 0.81 and a recall of 0.94.  There simply isn&#39;t a lot of
room for LZJD or LEV to make an improvement.</p><p>This is a three way tie.</p><h3 id="experiment-2d-openssl-111v-vs-111w"><a href="#experiment-2d-openssl-111v-vs-111w" aria-label="experiment 2d openssl 111v vs 111w permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiment 2d: openssl 1.1.1v vs 1.1.1w</h3><p>Finally, we&#39;ll look at 1.1.1v and 1.1.1w, which were released only a month
apart.</p><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/63272d163b630c1d6d492d461100de82/29114/openssl-byversion-1.1.1w-vs-1.1.1v.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/63272d163b630c1d6d492d461100de82/e46ac/openssl-byversion-1.1.1w-vs-1.1.1v.avif 450w /static/63272d163b630c1d6d492d461100de82/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1v.avif 900w /static/63272d163b630c1d6d492d461100de82/2eb22/openssl-byversion-1.1.1w-vs-1.1.1v.avif 1800w /static/63272d163b630c1d6d492d461100de82/f696c/openssl-byversion-1.1.1w-vs-1.1.1v.avif 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/63272d163b630c1d6d492d461100de82/8626f/openssl-byversion-1.1.1w-vs-1.1.1v.webp 450w /static/63272d163b630c1d6d492d461100de82/131f1/openssl-byversion-1.1.1w-vs-1.1.1v.webp 900w /static/63272d163b630c1d6d492d461100de82/62ed8/openssl-byversion-1.1.1w-vs-1.1.1v.webp 1800w /static/63272d163b630c1d6d492d461100de82/882b9/openssl-byversion-1.1.1w-vs-1.1.1v.webp 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/63272d163b630c1d6d492d461100de82/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1v.png 450w /static/63272d163b630c1d6d492d461100de82/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1v.png 900w /static/63272d163b630c1d6d492d461100de82/d61c2/openssl-byversion-1.1.1w-vs-1.1.1v.png 1800w /static/63272d163b630c1d6d492d461100de82/29114/openssl-byversion-1.1.1w-vs-1.1.1v.png 1920w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/63272d163b630c1d6d492d461100de82/d61c2/openssl-byversion-1.1.1w-vs-1.1.1v.png" alt="Precision vs. Recall plot for &#34;openssl 1.1.1v vs 1.1.1w&#34;" title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Precision vs. Recall plot for &#34;openssl 1.1.1v vs 1.1.1w&#34;</figcaption>
  </figure></div></div><div><div><figure>
    <span>
      <a href="https://edmcman.github.io/static/7a6d110a2593d17f71e4d08a3654cb4e/5d957/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="/static/7a6d110a2593d17f71e4d08a3654cb4e/e46ac/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 450w /static/7a6d110a2593d17f71e4d08a3654cb4e/9b8d4/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 900w /static/7a6d110a2593d17f71e4d08a3654cb4e/2eb22/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 1800w /static/7a6d110a2593d17f71e4d08a3654cb4e/6123d/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 2700w /static/7a6d110a2593d17f71e4d08a3654cb4e/a27a0/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 3600w /static/7a6d110a2593d17f71e4d08a3654cb4e/ccf74/openssl-byversion-1.1.1w-vs-1.1.1v-violin.avif 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/avif"/><source srcset="/static/7a6d110a2593d17f71e4d08a3654cb4e/8626f/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 450w /static/7a6d110a2593d17f71e4d08a3654cb4e/131f1/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 900w /static/7a6d110a2593d17f71e4d08a3654cb4e/62ed8/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 1800w /static/7a6d110a2593d17f71e4d08a3654cb4e/a8ede/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 2700w /static/7a6d110a2593d17f71e4d08a3654cb4e/6f7c8/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 3600w /static/7a6d110a2593d17f71e4d08a3654cb4e/3bac0/openssl-byversion-1.1.1w-vs-1.1.1v-violin.webp 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/webp"/>
          <source srcset="/static/7a6d110a2593d17f71e4d08a3654cb4e/fc2a6/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 450w /static/7a6d110a2593d17f71e4d08a3654cb4e/1cfc2/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 900w /static/7a6d110a2593d17f71e4d08a3654cb4e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 1800w /static/7a6d110a2593d17f71e4d08a3654cb4e/b2313/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 2700w /static/7a6d110a2593d17f71e4d08a3654cb4e/75ac7/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 3600w /static/7a6d110a2593d17f71e4d08a3654cb4e/5d957/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png 5400w" sizes="(max-width: 1800px) 100vw, 1800px" type="image/png"/>
          <img src="https://edmcman.github.io/static/7a6d110a2593d17f71e4d08a3654cb4e/d61c2/openssl-byversion-1.1.1w-vs-1.1.1v-violin.png" alt="Violin plot for &#34;openssl 1.1.1v vs 1.1.1w&#34;. Click to zoom in." title="" loading="lazy" decoding="async"/>
        </picture>
  </a>
    </span>
    <figcaption>Violin plot for &#34;openssl 1.1.1v vs 1.1.1w&#34;. Click to zoom in.</figcaption>
  </figure></div></div><p>Unsurprisingly, PIC hashing does even better here, with a precision of 0.82 and
a recall of 1.0 (after rounding)!  Again, there&#39;s basically no room for LZJD or
LEV to improve.</p><p>This is another three way tie.</p><h2 id="thresholds-in-practice"><a href="#thresholds-in-practice" aria-label="thresholds in practice permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Thresholds in Practice</h2><p>We saw some scenarios where LEV and LZJD outperformed PIC hashing.  But it&#39;s
important to realize that we are conducting these experiments with ground truth,
and we&#39;re using the ground truth to select the optimal threshold.  You can see
these thresholds listed at the bottom of each violin plot.  Unfortunately, if
you look carefully, you&#39;ll also notice that the optimal thresholds are not
always the same.  For example, the optimal threshold for LZJD in the &#34;openssl
1.0.2u vs 1.1.1w&#34; experiment was 0.95, but it was 0.75 in the &#34;openssl 1.1.1q vs
1.1.1w&#34; experiment.</p><p>In the real world, to use LZJD or LEV, you need to select a threshold. Unlike in
these experiments, you could not select the optimal one, because you would have
no way of knowing if your threshold was working well or not!  If you choose a
poor threshold, you might get substantially worse results than PIC hashing!</p><h2 id="pic-hashing-is-pretty-good"><a href="#pic-hashing-is-pretty-good" aria-label="pic hashing is pretty good permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>PIC Hashing is Pretty Good</h2><p>I think we learned that PIC hashing is pretty good.  It&#39;s not perfect, but it
generally provides excellent precision.  In theory, LZJD and LEV can perform
better in terms of recall, which is nice, but in practice, it&#39;s not clear that
they would because you would not know which threshold to use.</p><p>And although we didn&#39;t talk much about performance, PIC hashing is very fast.
Although LZJD is <em>much</em> faster than LEV, it&#39;s still not nearly as fast as PIC.</p><p>Imagine you have a database of a million malware function samples, and you have
a function that you want to look up in the database.  For PIC hashing, this is
just a standard database lookup, which can benefit from indexes and other
precomputation techniques.  For fuzzy hash approaches, we would need to invoke
the similarity function a million times each time we wanted to do a database lookup.</p><h2 id="theres-a-limit-to-syntactic-similarity"><a href="#theres-a-limit-to-syntactic-similarity" aria-label="theres a limit to syntactic similarity permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>There&#39;s a Limit to Syntactic Similarity</h2><p>Remember that we used LEV to represent the optimal similarity based on the edit
distance of instruction bytes.  That LEV did not blow PIC out of the water is
very telling, and suggests that there is a fundamental limit to how well
syntactic similarity based on instruction bytes can perform.  And surprisingly
to me, PIC hashing appears to be pretty close to that limit. We saw a striking
example of this limit <a href="#experiment-1b-openssl-111w-compiled-with-different-optimization-levels">when the frame pointer was accidentally
omitted</a>,
and more generally, all syntactic techniques struggle when the differences
become too great.</p><p>I wonder if any variants, like computing similarities over assembly code instead
of executable code bytes, would perform any better.</p><h2 id="where-do-we-go-from-here"><a href="#where-do-we-go-from-here" aria-label="where do we go from here permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Where Do We Go From Here?</h2><p>There are of course other strategies for comparing similarity, such as
incorporating <em>semantic</em> information.  Many researchers have studied this.  The
general downside to semantic techniques is that they are substantially more
expensive than syntactic techniques.  But if you&#39;re willing to pay the price,
you can get better results.  Maybe in a future blog post we&#39;ll try one of these
techniques out, such as the one my contemporary and friend Wesley Jin proposed
in <a href="https://kilthub.cmu.edu/articles/thesis/Practical_Large-Scale_Detection_of_Obfuscated_Malware_Code_Via_Flow_Dependency_Indexing/6721106">his
dissertation</a>.</p><p>While I was writing this blog post, Ghidra 11.0 also introduced BSim:</p><blockquote>
<p>A major new feature called BSim has been added. BSim can find structurally
similar functions in (potentially large) collections of binaries or object
files. BSim is based on Ghidra&#39;s decompiler and can find matches across
compilers used, architectures, and/or small changes to source code.</p>
</blockquote><p>Another interesting question is whether we can use neural learning to help
compute similarity.  For example, we might be able to train a model to
understand that omitting the frame pointer does not change the meaning of a
function, and so shouldn&#39;t be counted as a difference.</p></div></div></div>
  </body>
</html>
