<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://olano.dev/blog/from-rss-to-my-kindle">Original</a>
    <h1>From RSS to My Kindle</h1>
    
    <div id="readability-page-1" class="page"><div lang="en">
      <header>
          
          <h3>Building website EPUBs with Python</h3>
          
          

      </header>

      
      <p>
Last year <a href="https://olano.dev/blog/reclaiming-the-web-with-a-personal-reader">I wrote</a> about how I built <a href="https://github.com/facundoolano/feedi">feedi</a>, a personal feed reader, and started using it as my front page to the web. In the months since I published that post, I continued to tweak the app, observing my reading habits, experimenting with new features, and discarding the ones I didn’t need. I now got it to a place where I can count on seeing fresh and interesting content a couple of times a day, and the interface conveniently lets me keep what I plan to read and discard the rest.</p>
<p>
But while I’m an avid reader on paper, I struggle with lack of concentration and eye strain when trying to read  on a laptop or a desktop monitor —and it only gets worse on the phone. In practice, I use feedi as a mix of news feed,  content finder, and organizer; I prefer to send longer blog posts or essays to my Kindle, so I can get back to them when I’m offline: in bed, in the bathroom, at a cafe or on the bus.</p>
<p>
So a Kindle integration was a natural extension to feedi. Not only because it streamlined my reading workflow but because Amazon’s Chrome extension and iOS app do a poor job of extracting  content from most websites. I was already getting better results with the <a href="https://github.com/mozilla/readability">readability library</a> in feedi’s embedded article view, so I just needed to figure out how to send that cleaned-up HTML over to my Kindle. I learned a couple of things to get that working, so it seemed interesting to document the implementation process here.</p>
<hr/>
<p>
My first instinct was to try to get away with a Kindle integration that didn’t require sending emails from my app. I found a <a href="https://github.com/maxdjohnson/stkclient">Python library</a> that “impersonated” an Amazon client and wrote my first implementation around it, but it turned out to be brittle: it required storing device credentials in the database and manually authenticating every few days, which hurt the user experience, ultimately discouraging me from using the feature at all.</p>
<p>
So a few months later I took another stab at it, opting to send articles via email. At a high level, I needed to: fetch the HTML from the website, extract the cleaned-up article content from it, package it into an EPUB file, and attach it to an email to my Kindle device. This is what it looked like from the Flask route:</p>
<div>
<div>
<pre><code><span><span><span># feedi/routes.py</span>
</span></span><span><span>
</span></span><span><span><span>import</span> <span>flask</span>
</span></span><span><span>
</span></span><span><span><span>from</span> <span>flask</span> <span>import</span> current_app <span>as</span> app
</span></span><span><span><span>from</span> <span>flask_login</span> <span>import</span> current_user, login_required
</span></span><span><span>
</span></span><span><span><span>@app.post</span>(<span>&#34;/entries/kindle&#34;</span>)
</span></span><span><span><span>@login_required</span>
</span></span><span><span><span>def</span> <span>send_to_kindle</span>():
</span></span><span><span>    url <span>=</span> flask<span>.</span>request<span>.</span>args[<span>&#39;url&#39;</span>]
</span></span><span><span>    article <span>=</span> scraping<span>.</span>extract(url)
</span></span><span><span>    attach_data <span>=</span> scraping<span>.</span>package_epub(url, article)
</span></span><span><span>    email<span>.</span>send(current_user<span>.</span>kindle_email, attach_data, filename<span>=</span>article[<span>&#39;title&#39;</span>])
</span></span><span><span>    <span>return</span> <span>&#39;&#39;</span>, <span>204</span></span></span></code></pre>
</div>
</div>
<p>
Let’s go through each of these steps. For the extraction, I tried every Python library I could find, but none seemed to do as good of a job as Firefox’s reader view, so I decided to use the <a href="https://github.com/mozilla/readability">JavaScript library</a> that powers it through a little Node.js script:</p>
<div>
<div>
<pre><code><span><span><span>#!/usr/bin/env node
</span></span></span><span><span><span></span><span>// feedi/extract_article.js
</span></span></span><span><span><span></span>
</span></span><span><span><span>const</span> { JSDOM } <span>=</span> require(<span>&#34;jsdom&#34;</span>);
</span></span><span><span><span>const</span> { Readability } <span>=</span> require(<span>&#39;@mozilla/readability&#39;</span>);
</span></span><span><span>
</span></span><span><span><span>const</span> url <span>=</span> process.argv[<span>2</span>];
</span></span><span><span>
</span></span><span><span>JSDOM.fromURL(url).then(<span>function</span> (dom) {
</span></span><span><span>  <span>let</span> reader <span>=</span> <span>new</span> Readability(dom.<span>window</span>.<span>document</span>);
</span></span><span><span>  <span>let</span> article <span>=</span> reader.parse();
</span></span><span><span>  process.stdout.write(JSON.stringify(article), process.exit);
</span></span><span><span>});</span></span></code></pre>
</div>
</div>
<p>
The script’s output looks like this:</p>
<div>
<div>
<pre><code><span><span>{
</span></span><span><span>  <span>&#34;title&#34;</span>: <span>&#34;From RSS to my Kindle&#34;</span>,
</span></span><span><span>  <span>&#34;byline&#34;</span>: <span>&#34;Facundo Olano&#34;</span>,
</span></span><span><span>  <span>&#34;content&#34;</span>: <span>&#34;&lt;div id=\&#34;readability-page-1\&#34; class=\&#34;page\&#34;&gt;&lt;div lang=\&#34;en\&#34;&gt;&lt;header&gt;&lt;h3&gt;Building website EPUBs with Python&lt;/h3&gt;&lt;/header&gt;&lt;p&gt;Last year I wrote about &lt;a href=\&#34;https://olano.dev/blog/reclaiming-the-web-with-a-personal-reader\&#34;&gt;how I built feedi&lt;/a&gt;, a personal feed reader, and started using it as my front page to the web. (...)&#34;</span>,
</span></span><span><span>  <span>&#34;textContent&#34;</span>: <span>&#34;Building website EPUBs with Python\n\nLast year I wrote about how I built feedi, a personal feed reader, and started using it as my front page to the web. (...)&#34;</span>,
</span></span><span><span>  <span>&#34;length&#34;</span>: <span>2793</span>,
</span></span><span><span>  <span>&#34;excerpt&#34;</span>: <span>&#34;A Kindle integration was a natural extension to my feed reader. I had to learn some subtleties to get it working, so it seemed interesting to document the implementation process.&#34;</span>,
</span></span><span><span>  <span>&#34;siteName&#34;</span>: <span>&#34;olano.dev&#34;</span>
</span></span><span><span>}</span></span></code></pre>
</div>
</div>
<p>
And this is how I call it from Python:</p>
<div>
<div>
<pre><code><span><span><span># feedi/scraping.py</span>
</span></span><span><span><span>import</span> <span>json</span>
</span></span><span><span><span>import</span> <span>subprocess</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>extract</span>(url):
</span></span><span><span>    r <span>=</span> subprocess<span>.</span>run([<span>&#34;feedi/extract_article.js&#34;</span>, url],
</span></span><span><span>                       capture_output<span>=</span><span>True</span>, text<span>=</span><span>True</span>, check<span>=</span><span>True</span>)
</span></span><span><span>
</span></span><span><span>    article <span>=</span> json<span>.</span>loads(r<span>.</span>stdout)
</span></span><span><span>    <span>return</span> article</span></span></code></pre>
</div>
</div>
<p>
I found that some websites rely on JavaScript to load images lazily, so I rewrote the tags to force them to render (both in the app and in Kindle):</p>
<div>
<div>
<pre><code><span><span> import json
</span></span><span><span> import subprocess
</span></span><span><span>
</span></span><span><span><span>+from bs4 import BeautifulSoup
</span></span></span><span><span><span></span>
</span></span><span><span> def extract_article(url):
</span></span><span><span>     r = subprocess.run([&#34;feedi/extract_article.js&#34;, url],
</span></span><span><span>                        capture_output=True, text=True, check=True)
</span></span><span><span>
</span></span><span><span>     article = json.loads(r.stdout)
</span></span><span><span>
</span></span><span><span><span>+    # load lazy images by setting data-src into src
</span></span></span><span><span><span>+    soup = BeautifulSoup(article[&#39;content&#39;], &#39;lxml&#39;)
</span></span></span><span><span><span>+    LAZY_DATA_ATTRS = [&#39;data-src&#39;, &#39;data-lazy-src&#39;, &#39;data-srcset&#39;,
</span></span></span><span><span><span>+                       &#39;data-td-src-property&#39;]
</span></span></span><span><span><span>+    for data_attr in LAZY_DATA_ATTRS:
</span></span></span><span><span><span>+        for img in soup.findAll(&#39;img&#39;, attrs={data_attr: True}):
</span></span></span><span><span><span>+            img.attrs = {&#39;src&#39;: img[data_attr]}
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    article[&#39;content&#39;] = str(soup)
</span></span></span><span><span><span></span>
</span></span><span><span>     return article
</span></span></code></pre>
</div>
</div>
<p>
Next, I needed to put together a valid EPUB file from this HTML content. A very superficial research revealed that EPUB files are just zips with a few metadata files. So I zipping the article into a bytes sequence:</p>
<div>
<div>
<pre><code><span><span><span># feedi/scraping.py</span>
</span></span><span><span><span>import</span> <span>io</span>
</span></span><span><span><span>import</span> <span>zipfile</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>package_epub</span>(url, article):
</span></span><span><span>    output_buffer <span>=</span> io<span>.</span>BytesIO()
</span></span><span><span>    <span>with</span> zipfile<span>.</span>ZipFile(output_buffer, <span>&#39;w&#39;</span>, compression<span>=</span>zipfile<span>.</span>ZIP_DEFLATED) <span>as</span> <span>zip</span>:
</span></span><span><span>        <span>zip</span><span>.</span>writestr(<span>&#39;article.html&#39;</span>, article[<span>&#39;content&#39;</span>])
</span></span><span><span>
</span></span><span><span>    <span>return</span> output_buffer<span>.</span>getvalue()</span></span></code></pre>
</div>
</div>
<p>
Based on <a href="https://github.com/thansen0/sample-epub-minimal">this sample repository</a> I added mimetype, container, and content files pointing to the single article.html file, to turn it into an EPUB:</p>
<div>
<div>
<pre><code><span><span><span>zip</span><span>.</span>writestr(<span>&#39;mimetype&#39;</span>, <span>&#34;application/epub+zip&#34;</span>)
</span></span><span><span><span>zip</span><span>.</span>writestr(<span>&#39;META-INF/container.xml&#39;</span>, <span>&#34;&#34;&#34;&lt;?xml version=&#34;1.0&#34;?&gt;
</span></span></span><span><span><span>&lt;container version=&#34;1.0&#34; xmlns=&#34;urn:oasis:names:tc:opendocument:xmlns:container&#34;&gt;
</span></span></span><span><span><span>&lt;rootfiles&gt;
</span></span></span><span><span><span>&lt;rootfile full-path=&#34;content.opf&#34; media-type=&#34;application/oebps-package+xml&#34;/&gt;
</span></span></span><span><span><span>&lt;/rootfiles&gt;
</span></span></span><span><span><span>&lt;/container&gt;&#34;&#34;&#34;</span>)
</span></span><span><span>
</span></span><span><span>author <span>=</span> article[<span>&#39;byline&#39;</span>] <span>or</span> article[<span>&#39;siteName&#39;</span>]
</span></span><span><span><span>if</span> <span>not</span> author:
</span></span><span><span>    <span># if no explicit author in the website, use the domain</span>
</span></span><span><span>    author <span>=</span> urllib<span>.</span>parse<span>.</span>urlparse(url)<span>.</span>netloc<span>.</span>replace(<span>&#39;www.&#39;</span>, <span>&#39;&#39;</span>)
</span></span><span><span>
</span></span><span><span><span>zip</span><span>.</span>writestr(<span>&#39;content.opf&#39;</span>, <span>f</span><span>&#34;&#34;&#34;&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
</span></span></span><span><span><span>&lt;package xmlns=&#34;http://www.idpf.org/2007/opf&#34; version=&#34;3.0&#34; xml:lang=&#34;en&#34; unique-identifier=&#34;uid&#34; prefix=&#34;cc: http://creativecommons.org/ns#&#34;&gt;
</span></span></span><span><span><span>&lt;metadata xmlns:dc=&#34;http://purl.org/dc/elements/1.1/&#34;&gt;
</span></span></span><span><span><span>&lt;dc:title id=&#34;title&#34;&gt;</span><span>{</span>article[<span>&#39;title&#39;</span>]<span>}</span><span>&lt;/dc:title&gt;
</span></span></span><span><span><span>&lt;dc:creator&gt;</span><span>{</span>author<span>}</span><span>&lt;/dc:creator&gt;
</span></span></span><span><span><span>&lt;dc:language&gt;</span><span>{</span>article<span>.</span>get(<span>&#39;lang&#39;</span>, <span>&#39;&#39;</span>)<span>}</span><span>&lt;/dc:language&gt;
</span></span></span><span><span><span>&lt;/metadata&gt;
</span></span></span><span><span><span>&lt;manifest&gt;
</span></span></span><span><span><span>&lt;item id=&#34;article&#34; href=&#34;article.html&#34; media-type=&#34;text/html&#34; /&gt;
</span></span></span><span><span><span>&lt;/manifest&gt;
</span></span></span><span><span><span>&lt;spine toc=&#34;ncx&#34;&gt;
</span></span></span><span><span><span>&lt;itemref idref=&#34;article&#34; /&gt;
</span></span></span><span><span><span>&lt;/spine&gt;
</span></span></span><span><span><span>&lt;/package&gt;&#34;&#34;&#34;</span>)</span></span></code></pre>
</div>
</div>
<p>
This was enough to get the text working, but I needed to download the images if wanted them to show up on the Kindle:</p>
<div>
<div>
<pre><code><span><span> import io
</span></span><span><span> import zipfile
</span></span><span><span>
</span></span><span><span><span>+from bs4 import BeautifulSoup
</span></span></span><span><span><span></span>
</span></span><span><span> def package_epub(url, article):
</span></span><span><span>     output_buffer = io.BytesIO()
</span></span><span><span>     with zipfile.ZipFile(output_buffer, &#39;w&#39;, compression=zipfile.ZIP_DEFLATED) as zip:
</span></span><span><span><span>-        zip.writestr(&#39;article.html&#39;, article[&#39;content&#39;])
</span></span></span><span><span><span></span><span>+        soup = BeautifulSoup(article[&#39;content&#39;], &#39;lxml&#39;)
</span></span></span><span><span><span>+        for img in soup.findAll(&#39;img&#39;):
</span></span></span><span><span><span>+            img_url = img[&#39;src&#39;]
</span></span></span><span><span><span>+            img_filename = &#39;article_files/&#39; + img[&#39;src&#39;].split(&#39;/&#39;)[-1].split(&#39;?&#39;)[0]
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+            # update each img src url to point to the local copy of the file
</span></span></span><span><span><span>+            img[&#39;src&#39;] = img_filename
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+            # download the image and save into the files subdir of the zip
</span></span></span><span><span><span>+            response = requests.get(img_url)
</span></span></span><span><span><span>+            if not response.ok:
</span></span></span><span><span><span>+                continue
</span></span></span><span><span><span>+            zip.writestr(img_filename, response.content)
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+        zip.writestr(&#39;article.html&#39;, str(soup))
</span></span></span><span><span><span></span>     return output_buffer.getvalue()
</span></span></code></pre>
</div>
</div>
<p>
Note how I also rewrite the <code>img src</code> attributes so they point to the local files instead of online ones (much like the browser does when downloading a page). Since the Kindle can’t render WebP images, my next step was to convert those to JPEGs:</p>
<div>
<div>
<pre><code><span><span> import io
</span></span><span><span> import zipfile
</span></span><span><span>
</span></span><span><span> from bs4 import BeautifulSoup
</span></span><span><span><span>+from PIL import Image
</span></span></span><span><span><span></span>
</span></span><span><span> def package_epub(url, article):
</span></span><span><span>     output_buffer = io.BytesIO()
</span></span><span><span>     with zipfile.ZipFile(output_buffer, &#39;w&#39;, compression=zipfile.ZIP_DEFLATED) as zip:
</span></span><span><span>         soup = BeautifulSoup(article[&#39;content&#39;], &#39;lxml&#39;)
</span></span><span><span>         for img in soup.findAll(&#39;img&#39;):
</span></span><span><span>             img_url = img[&#39;src&#39;]
</span></span><span><span>             img_filename = &#39;article_files/&#39; + img[&#39;src&#39;].split(&#39;/&#39;)[-1].split(&#39;?&#39;)[0]
</span></span><span><span><span>+            img_filename = img_filename.replace(&#39;.webp&#39;, &#39;.jpg&#39;)
</span></span></span><span><span><span></span>
</span></span><span><span>             # update each img src url to point to the local copy of the file
</span></span><span><span>             img[&#39;src&#39;] = img_filename
</span></span><span><span>
</span></span><span><span>             # download the image and save into the files subdir of the zip
</span></span><span><span>             response = requests.get(img_url)
</span></span><span><span>             if not response.ok:
</span></span><span><span>                 continue
</span></span><span><span>
</span></span><span><span><span>-            zip.writestr(img_filename, response.content)
</span></span></span><span><span><span></span><span>+            with zip.open(img_filename, &#39;w&#39;) as dest_file:
</span></span></span><span><span><span>+                if img_url.endswith(&#39;.webp&#39;):
</span></span></span><span><span><span>+                    jpg_img = Image.open(io.BytesIO(response.content)).convert(&#34;RGB&#34;)
</span></span></span><span><span><span>+                    jpg_img.save(dest_file, &#34;JPEG&#34;)
</span></span></span><span><span><span>+                else:
</span></span></span><span><span><span>+                    dest_file.write(response.content)
</span></span></span><span><span><span></span>
</span></span><span><span>         zip.writestr(&#39;article.html&#39;, str(soup))
</span></span></code></pre>
</div>
</div>
<p>
Now I just needed to email this zip file. I didn’t want to depend on a paid service and remembered from my old web developer days that a regular Gmail account did the trick to send a few emails from a web app. Things had changed since the last time I’d tried this, though: I had to enable two-factor authentication and generate an “app password” (at <code>https://myaccount.google.com/apppasswords</code>) for Google to accept my SMTP requests. This is what the email boilerplate looked like:</p>
<div>
<div>
<pre><code><span><span><span># feedi/email.py</span>
</span></span><span><span><span>import</span> <span>smtplib</span>
</span></span><span><span><span>import</span> <span>urllib.parse</span>
</span></span><span><span><span>from</span> <span>email</span> <span>import</span> encoders
</span></span><span><span><span>from</span> <span>email.mime.base</span> <span>import</span> MIMEBase
</span></span><span><span><span>from</span> <span>email.mime.multipart</span> <span>import</span> MIMEMultipart
</span></span><span><span>
</span></span><span><span><span>def</span> <span>send</span>(recipient, attach_data, filename):
</span></span><span><span>    server <span>=</span> <span>&#34;smtp.gmail.com&#34;</span>
</span></span><span><span>    port <span>=</span> <span>587</span>
</span></span><span><span>    sender <span>=</span> <span>&#34;my.reader.email@gmail.com&#34;</span>
</span></span><span><span>    password <span>=</span> <span>&#34;some gmail app pass&#34;</span>
</span></span><span><span>
</span></span><span><span>    msg <span>=</span> MIMEMultipart()
</span></span><span><span>    msg[<span>&#39;From&#39;</span>] <span>=</span> sender
</span></span><span><span>    msg[<span>&#39;To&#39;</span>] <span>=</span> recipient
</span></span><span><span>    msg[<span>&#39;Subject&#39;</span>] <span>=</span> <span>f</span><span>&#39;feedi - </span><span>{</span>filename<span>}</span><span>&#39;</span>
</span></span><span><span>
</span></span><span><span>    part <span>=</span> MIMEBase(<span>&#39;application&#39;</span>, <span>&#39;epub&#39;</span>)
</span></span><span><span>    part<span>.</span>set_payload(attach_data)
</span></span><span><span>    encoders<span>.</span>encode_base64(part)</span></span></code></pre>
</div>
</div>
<p>
Where <code>attach_data</code> is the EPUB zip byte sequence.</p>
<p>
The Kindle uses the filename from the <code>Content-Disposition</code> header as the title displayed in the device library; this is a problem when the title contains spaces or non-ASCII characters —as is the case for Spanish articles. I got that working after a few tries with the escaping syntax suggested by this <a href="https://stackoverflow.com/questions/93551/how-to-encode-the-filename-parameter-of-content-disposition-header-in-http/216777#216777">StackOverflow answer</a>:</p>
<div>
<div>
<pre><code><span><span>filename <span>=</span> urllib<span>.</span>parse<span>.</span>quote(filename)
</span></span><span><span>part<span>.</span>add_header(<span>&#39;Content-Disposition&#39;</span>, <span>f</span><span>&#34;attachment; filename*=UTF-8&#39;&#39;</span><span>{</span>filename<span>}</span><span>.epub&#34;</span>)
</span></span><span><span>msg<span>.</span>attach(part)</span></span></code></pre>
</div>
</div>
<p>
Finally, the email is sent like this:</p>
<div>
<div>
<pre><code><span><span>smtp <span>=</span> smtplib<span>.</span>SMTP(server, port)
</span></span><span><span>smtp<span>.</span>ehlo()
</span></span><span><span>smtp<span>.</span>starttls()
</span></span><span><span>smtp<span>.</span>login(sender, password)
</span></span><span><span>smtp<span>.</span>sendmail(sender, recipient, msg<span>.</span>as_string())
</span></span><span><span>smtp<span>.</span>quit()</span></span></code></pre>
</div>
</div>
<p>
Of course, for the Kindle to accept it, I had to whitelist the reader email address in my Amazon device settings.</p>
<hr/>
<p>This implementation works well enough for my needs, but there’s still room for improvement:</p>
<ul>
<li>Some websites regrettably rely on JavaScript to load their HTML, so it’s not picked up by the readability package. I experimented with a headless browser to fetch the content, but that made the app slow and brittle, so I just choose not to read content from JavaScript-centric websites. (A similar rule applies to paywalls).</li>
<li>This Kindle integration feature is very convenient when using feedi, but I’d also want to use it from the browser. Right now I need to copy the URL and paste it into feedi, but I’m toying with the idea of a Firefox extension that would work similarly to Amazon’s one —and that could also be used for other URL operations, like RSS feed discovery.</li>
<li>Similarly, I’d like feedi, which is already a Progressive Web App, to work as a share target in my phone, so it  can receive URLs from other applications. Unfortunately, this feature is <a href="https://developer.mozilla.org/en-US/docs/Web/Manifest/share_target">not supported in iOS</a>.</li>
</ul>
<h2 id="notes">
Notes
</h2>


      

      </div></div>
  </body>
</html>
