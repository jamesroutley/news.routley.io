<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://twitter.com/svpino/status/1681614284613099520">Original</a>
    <h1>GPT-4 is getting worse over time, not better</h1>
    
    <div id="readability-page-1" class="page"><div role="main"><div><div><div><div data-testid="primaryColumn"><div aria-label="Home timeline" tabindex="0"><div itemscope="" itemtype="https://schema.org/Collection"><meta content="Tweet with replies" itemprop="name"/><section aria-labelledby="accessible-list-34672" role="region"><div aria-label="Timeline: Conversation"><div><div><div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1681614284613099520" itemprop="identifier"/><meta content="1" itemprop="position"/><meta content="502" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-07-19T10:37:42.000Z" itemprop="dateCreated"/><meta content="2023-07-19T10:37:42.000Z" itemprop="datePublished"/><meta content="https://twitter.com/svpino/status/1681614284613099520" itemprop="url"/><meta content="https://twitter.com/svpino/status/1681614284613099520" itemprop="mainEntityOfPage"/><article aria-labelledby="id__j85ur3m7eo id__4tgcdp3zgb6 id__7gl0mgrh1pa id__9ibh0aim7vj id__78vn625m4mw id__i4tgj97qnzh id__oyg70gl7xxj id__czqd8ddfkdc id__isuugp8w7u id__o7a26gdcs1o id__p8tlhttxw5p id__lqcmdbdhzs id__s6nrt98y3rj id__gwmxu112848 id__lw32c0zhadh id__ntaj7t0o3t id__l7pfw142888 id__xbkq9ktvsp id__uybaw4ysxse" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-svpino"><div><div><div><div><a href="https://twitter.com/svpino" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1581385027757264898/j5GjtUiq_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div><div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>GPT-4 is getting worse over time, not better.

Many people have reported noticing a significant degradation in the quality of the model responses, but so far, it was all anecdotal.

But now we know.

At least one study shows how the June version of GPT-4 is objectively worse than the version released in March on a few tasks.

The team evaluated the models using a dataset of 500 problems where the models had to figure out whether a given integer was prime. In March, GPT-4 answered correctly 488 of these questions. In June, it only got 12 correct answers.

From 97.6% success rate down to 2.4%!

But it gets worse!

The team used Chain-of-Thought to help the model reason: 

&#34;Is 17077 a prime number? Think step by step.&#34; 

Chain-of-Thought is a popular technique that significantly improves answers. Unfortunately, the latest version of GPT-4 did not generate intermediate steps and instead answered incorrectly with a simple &#34;No.&#34;

Code generation has also gotten worse.

The team built a dataset with 50 easy problems from LeetCode and measured how many GPT-4 answers ran without any changes. 

The March version succeeded in 52% of the problems, but this dropped to a pale 10% using the model from June.

Why is this happening?

We assume that OpenAI pushes changes continuously, but we don&#39;t know how the process works and how they evaluate whether the models are improving or regressing.

Rumors suggest they are using several smaller and specialized GPT-4 models that act similarly to a large model but are less expensive to run. When a user asks a question, the system decides which model to send the query to. 

Cheaper and faster, but could this new approach be the problem behind the degradation in quality?

In my opinion, this is a red flag for anyone building applications that rely on GPT-4. Having the behavior of an LLM change over time is not acceptable.

Have you noticed any issues when using GPT-4 and ChatGPT lately? Do you think these problems are overblown?</span></p></div></div></div><div><div aria-labelledby="id__mto2toa34og id__a1091r1pm96" id="id__s6nrt98y3rj"><div><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Accuracy comparison between the March version of GPT-4 with the June version on the problem of determining whether a number is prime. In March, GPT-4 solved 97.6% of problems accurately, while in June, it solved only 2.4% of the problems." data-testid="tweetPhoto"><p><img alt="Accuracy comparison between the March version of GPT-4 with the June version on the problem of determining whether a number is prime. In March, GPT-4 solved 97.6% of problems accurately, while in June, it solved only 2.4% of the problems." draggable="true" src="https://pbs.twimg.com/media/F1ZIOibXoAANvL0?format=png&amp;name=4096x4096"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div></div></div></section></div></div></div></div></div></div></div></div>
  </body>
</html>
