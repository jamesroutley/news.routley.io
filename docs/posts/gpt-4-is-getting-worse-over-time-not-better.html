<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://twitter.com/svpino/status/1681614284613099520">Original</a>
    <h1>GPT-4 is getting worse over time, not better</h1>
    
    <div id="readability-page-1" class="page"><div role="main"><div><div><div><div data-testid="primaryColumn"><div aria-label="Home timeline" tabindex="0"><div itemscope="" itemtype="https://schema.org/Collection"><meta content="Tweet with replies" itemprop="name"/><section aria-labelledby="accessible-list-1893" role="region"><div aria-label="Timeline: Conversation"><div><div><div><div><div itemprop="hasPart" itemscope="" itemtype="https://schema.org/SocialMediaPosting"><meta content="1681614284613099520" itemprop="identifier"/><meta content="1" itemprop="position"/><meta content="407" itemprop="commentCount"/><meta content="" itemprop="contentRating"/><meta content="2023-07-19T10:37:42.000Z" itemprop="dateCreated"/><meta content="2023-07-19T10:37:42.000Z" itemprop="datePublished"/><meta content="https://twitter.com/svpino/status/1681614284613099520" itemprop="url"/><meta content="https://twitter.com/svpino/status/1681614284613099520" itemprop="mainEntityOfPage"/><article aria-labelledby="id__7k523gtepsn id__bdm0o273hc id__qasbww6re3a id__nrebgo4ifh id__72j4ct8ouu id__ldomjdlb3zr id__o3kzekyilok id__uyemlv7k45a id__mc437d2xjya id__vx6iao0l61 id__acxxdll6xe7 id__rvmngm7cli id__t3r9u1m15d id__si1q1lx4t7h id__kdpb1teb97 id__3maabaj5pbf id__9r73ve6s8m id__g62guvx21vd id__6r88no7qs4k" role="article" tabindex="-1" data-testid="tweet"><div><div><div><div><div data-testid="Tweet-User-Avatar"><div><div><div data-testid="UserAvatar-Container-svpino"><div><div><div><div><a href="https://twitter.com/svpino" aria-hidden="true" role="link" tabindex="-1"><div><div><div><div aria-label=""><p><img alt="" draggable="true" src="https://pbs.twimg.com/profile_images/1581385027757264898/j5GjtUiq_400x400.jpg"/></p></div></div></div></div></a></div></div></div></div></div></div></div></div></div></div><div><div><div itemprop="articleBody" data-testid="tweetTextAnnotations"><div><p><span>GPT-4 is getting worse over time, not better.

Many people have reported noticing a significant degradation in the quality of the model responses, but so far, it was all anecdotal.

But now we know.

At least one study shows how the June version of GPT-4 is objectively worse than the version released in March on a few tasks.

The team evaluated the models using a dataset of 500 problems where the models had to figure out whether a given integer was prime. In March, GPT-4 answered correctly 488 of these questions. In June, it only got 12 correct answers.

From 97.6% success rate down to 2.4%!

But it gets worse!

The team used Chain-of-Thought to help the model reason: 

&#34;Is 17077 a prime number? Think step by step.&#34; 

Chain-of-Thought is a popular technique that significantly improves answers. Unfortunately, the latest version of GPT-4 did not generate intermediate steps and instead answered incorrectly with a simple &#34;No.&#34;

Code generation has also gotten worse.

The team built a dataset with 50 easy problems from LeetCode and measured how many GPT-4 answers ran without any changes. 

The March version succeeded in 52% of the problems, but this dropped to a pale 10% using the model from June.

Why is this happening?

We assume that OpenAI pushes changes continuously, but we don&#39;t know how the process works and how they evaluate whether the models are improving or regressing.

Rumors suggest they are using several smaller and specialized GPT-4 models that act similarly to a large model but are less expensive to run. When a user asks a question, the system decides which model to send the query to. 

Cheaper and faster, but could this new approach be the problem behind the degradation in quality?

In my opinion, this is a red flag for anyone building applications that rely on GPT-4. Having the behavior of an LLM change over time is not acceptable.

Have you noticed any issues when using GPT-4 and ChatGPT lately? Do you think these problems are overblown?</span></p></div></div></div><div><div aria-labelledby="id__2dldy0ritvu id__0njkjcr8mhzj" id="id__t3r9u1m15d"><div><div><div><div><div><div><div role="button" tabindex="0"><div><div><div aria-label="Accuracy comparison between the March version of GPT-4 with the June version on the problem of determining whether a number is prime. In March, GPT-4 solved 97.6% of problems accurately, while in June, it solved only 2.4% of the problems." data-testid="tweetPhoto"><p><img alt="Accuracy comparison between the March version of GPT-4 with the June version on the problem of determining whether a number is prime. In March, GPT-4 solved 97.6% of problems accurately, while in June, it solved only 2.4% of the problems." draggable="true" src="https://pbs.twimg.com/media/F1ZIOibXoAANvL0?format=png&amp;name=4096x4096"/></p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div></div></div></section></div></div></div></div></div></div></div></div>
  </body>
</html>
