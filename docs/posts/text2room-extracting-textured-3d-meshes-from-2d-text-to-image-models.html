<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lukashoel.github.io/text-to-room/">Original</a>
    <h1>Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models</h1>
    
    <div id="readability-page-1" class="page">

<nav role="navigation" aria-label="main navigation">
  
  
</nav>


<section>
  <div>
    <div>
      <div>
        <div>
          
          

          <p><span><sup>1</sup>Technical University of Munich,</span>
            <span><sup>2</sup>University of Michigan</span>
          </p>
          <p><span><sup>*</sup>joint first authorship</span>
          </p>

          
        </div>
      </div>
    </div>
  </div>
</section>

<section>
  <div>
    <div>
      <p><img src="https://lukashoel.github.io/text-to-room/static/images/teaser-min.jpg" alt="Text2Room Teaser"/></p><h2>
        <span>Text2Room</span> generates textured 3D meshes from a given text prompt using 2D text-to-image models.
      </h2>
    </div>
  </div>
</section>


<section>
  <div>
    <div>
      <div id="results-carousel">
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/living_room.mp4" type="video/mp4"/>
          </video>
          <h2>
            A living room with a lit furnace, couch, and cozy curtains, bright lamps that make the room look well-lit.
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/living_room_wood.mp4" type="video/mp4"/>
          </video>
          <h2>
            Editorial Style Photo, Rustic Farmhouse, Living Room, Stone Fireplace, Wood, Leather, Wool
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/bathroom.mp4" type="video/mp4"/>
          </video>
          <h2>
            Editorial Style Photo, Eye Level, Coastal Bathroom, Clawfoot Tub, Seashell, Wicker, Blue and White
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/library.mp4" type="video/mp4"/>
          </video>
          <h2>
            A library with tall bookshelves, tables, chairs, and reading lamps
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/nursery.mp4" type="video/mp4"/>
          </video>
          <h2>
            Editorial Style Photo, Wide Shot, Modern Nursery, Table Lamp, Rocking Chair, Tree Wall Decal, Wood
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/office.mp4" type="video/mp4"/>
          </video>
          <h2>
            a small office with a chair, desk, and monitors
          </h2>
        </p>
        <p>
          <video autoplay="" controls="" muted="" loop="" height="100%">
            <source src="static/images/living_room_bookshelves.mp4" type="video/mp4"/>
          </video>
          <h2>
            A living room with lots of bookshelves, couches, and small tables
          </h2>
        </p>
      </div>
    </div>
  </div>
</section>


<section>
  <div>
    <!-- Abstract. -->
    <div>
      <div>
        <h2>Abstract</h2>
        <p>
            We present Text2Room, a method for generating room-scale textured 3D meshes from a given text prompt as input.
            To this end, we leverage pre-trained 2D text-to-image models to synthesize a sequence of images from different poses.
            In order to lift these outputs into a consistent 3D scene representation, we combine monocular depth estimation with a text-conditioned inpainting model.
            The core idea of our approach is a tailored viewpoint selection such that the content of each image can be fused into a seamless, textured 3D mesh.
            More specifically, we propose a continuous alignment strategy that iteratively fuses scene frames with the existing geometry to create a seamless mesh.
            Unlike existing works that focus on generating single objects or zoom-out trajectories from text, our method generates complete 3D scenes with multiple objects and explicit 3D geometry.
            We evaluate our approach using qualitative and quantitative metrics, demonstrating it as the first method to generate room-scale 3D geometry with compelling textures from only text as input.
          </p>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div>
      <div>
        <h2>Video</h2>
        <p>
          <iframe src="https://www.youtube.com/embed/fjRnFL91EZc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
        </p>
      </div>
    </div>
    <!--/ Paper video. -->


    <!-- Iterative Scene Buildup. -->
    <div>
        <div>
            <h2>Iterative Scene Generation</h2>
            <div>
            <p>
                We iteratively create a textured 3D mesh from a sequence of camera poses.
                For each new pose, we render the current mesh to obtain partial RGB and depth renderings.
                We complete both, utilizing respective inpainting models and the text prompt.
                Next, we perform depth alignment and mesh filtering to obtain an optimal next mesh patch, that is finally fused with the existing geometry.
            </p>
            <p><img src="https://lukashoel.github.io/text-to-room/static/images/iterative-gen-min.jpg" alt="Text2Room Iterative Scene Generation"/>
            </p></div>
        </div>
    </div>
    <!--/ Iterative Scene Buildup. -->

    <!-- Two-Stage Viewpoint Selection. -->
    <div>
        <div>
            <h2>Two-Stage Viewpoint Selection</h2>
            <div>
            <p>
                A key part of our method is the choice of text prompts and camera poses from which the scene is synthesized.
                We propose a two-stage viewpoint selection strategy, that samples each next camera pose from optimal positions and refines empty regions subsequently.
            </p>
            <p><img src="https://lukashoel.github.io/text-to-room/static/images/pipeline-min.jpg" alt="Text2Room Pipeline"/>
            </p></div>
        </div>
    </div>
    <!--/ Two-Stage Viewpoint Selection. -->

    <!-- Generation Stage. -->
    <div>
        <div>
            <h2>Generation Stage</h2>
            <div>
            <p>
                In the first stage, we create the main parts of the scene, including the general layout and furniture.
                For that, we subsequently render multiple predefined trajectories in different directions that eventually cover the whole room.
            </p>
            <video autoplay="" controls="" muted="" loop="" height="100%">
                <source src="static/images/iterative_scene_generation.mp4" type="video/mp4"/>
            </video>
            </div>
        </div>
    </div>
    <!--/ Generation Stage. -->

    <!-- Completion Stage. -->
    <div>
        <div>
            <h2>Completion Stage</h2>
            <div>
            <p>
                After the first stage, the scene layout and furniture is defined. 
                Since the scene is generated on-the-fly, the mesh contains holes that were not observed by any camera.
                We complete the scene by sampling additional poses a-posteriori, looking at those holes.
            </p>
            <video autoplay="" controls="" muted="" loop="" height="100%">
                <source src="static/images/completion.mp4" type="video/mp4"/>
            </video>
            </div>
        </div>
    </div>
    <!--/ Completion Stage. -->

    <!-- Mesh Viewer. -->
    <div>
      <div>
        <h2>Interactive 3D Mesh Viewer - Use Your Mouse to Navigate the Scene</h2>
        <div>
          
          <!-- use unique asset to ensure lazy loading -->
          <model-viewer id="lazy-load" camera-controls="" touch-action="pan-y" reveal="manual" crossorigin="anonymous" src="https://kaldir.vc.in.tum.de/hoellein/model_compressed.glb" alt="A 3D model" exposure="2.5">
            
            <p>Load 3D Model (400 MB)</p>
          </model-viewer>

          <p>
            A living room with a lit furnace, couch, and cozy curtains, bright lamps that make the room look well-lit.
          </p>
          
          

        </div>
      </div>
    </div>
    <!--/ Mesh Viewer. -->
  </div>

  <!-- Loads <model-viewer> for modern browsers: -->
  
</section>

<section id="BibTeX">
  <div>
    <h2>BibTeX</h2>
    <pre><code>@preprint{hoellein2023text2room,
        title={Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models},
        author={H{\&#34;o}llein, Lukas and Cao, Ang and Owens, Andrew and Johnson, Justin and Nie{\ss}ner, Matthias},
        journal={arXiv preprint arXiv:2303.11989},
        year={2023}
}</code></pre>
  </div>
</section>






</div>
  </body>
</html>
