<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.fredrb.com/2025/06/02/futex-fun/">Original</a>
    <h1>Fun with Futex</h1>
    
    <div id="readability-page-1" class="page"><div>
  
<p>Implementing an optimized lock in Linux requires some Operating System help. You can only get so far by doing everything in user-land. We are going to take a look how one can implement a simple spin lock in C (just like the <a href="https://blog.fredrb.com/2022/10/16/go-concurrency-simple-lock-impl">spin lock in Go</a> I implemented a while back) and then a slightly more elaborate lock using operating system’s primitives. The idea behind a mutex (mutual exclusion) is straightforward: we want some part of the code to be accessed only by a single thread at a time. If the resource a thread is trying to access (the critical zone) is already being accessed by something else: wait. The trick about implementing them is <em>how</em> you to do wait part!</p>
<blockquote>
<p>As usual, for the ones allergic to rambling, you can jump directly to the <a href="https://github.com/fredrb/funtex">final code on GitHub</a>.</p></blockquote>
<h2 id="behold-the-spin-lock">Behold the spin lock!</h2>
<p>The simplest way to wait in a mutex to “spin”. in other words: retry until your condition is met. Here’s a first pass implementation of our mutex in C:</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>	atomic_bool locked;
</span></span><span><span>} <span>spin_lock_t</span>;
</span></span><span><span>
</span></span><span><span><span>void</span> <span>lock</span>(<span>spin_lock_t</span> <span>*</span>lock) {
</span></span><span><span>	<span>while</span> (<span>atomic_exchange</span>(<span>&amp;</span>lock<span>-&gt;</span>locked, true)) {
</span></span><span><span>		<span>// spin!
</span></span></span><span><span><span></span>	}
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>void</span> <span>unlock</span>(<span>spin_lock_t</span> <span>*</span>lock) {
</span></span><span><span>	<span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>locked, false);
</span></span><span><span>}
</span></span></code></pre></div><p>You don’t really need more than that for a simple spin lock. And it probably won’t differ too much in implementation in other programming languages with similar tomic constructs. <code>atomic_exchange</code> returns the old value from <code>locked</code>. If that value was <code>false</code>, it means that the lock was free, and the caller thread can claim it. If the value was <code>true</code>, then the lock is already in use by another thread, thus the caller must wait!</p>
<p>To test this out, I wrote the following test harness. We start three threads, and each thread tries to increment the counter, acquiring the lock for each increment.</p>
<blockquote>
<p>Note that this is not a great example for locks, in a real scenario you will likely use an atomic for the increment. This is just a simple example and shouldn’t be a distraction from the actual implementation I’m interested in: the mutex!</p></blockquote>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>unsigned</span> <span>int</span> counter <span>=</span> <span>0</span>;
</span></span><span><span><span>spin_lock_t</span> spin_lock;
</span></span><span><span>
</span></span><span><span><span>void</span><span>*</span> <span>counter_thread</span>(<span>void</span><span>*</span> arg) {
</span></span><span><span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>1000000</span>; i<span>++</span>) {
</span></span><span><span>		<span>lock</span>(<span>&amp;</span>spin_lock);
</span></span><span><span>		counter<span>++</span>;
</span></span><span><span>		<span>unlock</span>(<span>&amp;</span>spin_lock);
</span></span><span><span>	}
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>	<span>pthread_t</span> threads[NUM_THREADS];
</span></span><span><span>
</span></span><span><span>	<span>init_lock</span>(<span>&amp;</span>spin_lock);
</span></span><span><span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>5</span>; i<span>++</span>) {
</span></span><span><span>		<span>if</span> (<span>pthread_create</span>(<span>&amp;</span>threads[i], NULL, counter_thread, NULL) <span>!=</span> <span>0</span>) {
</span></span><span><span>			<span>perror</span>(<span>&#34;Failed to create thread&#34;</span>);
</span></span><span><span>			<span>return</span> <span>1</span>;
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> NUM_THREADS; i<span>++</span>) {
</span></span><span><span>		<span>pthread_join</span>(threads[i], NULL);
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>printf</span>(<span>&#34;Final counter value: %d</span><span>\n</span><span>&#34;</span>, counter);
</span></span><span><span>
</span></span><span><span>	<span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>The problem with this implementation is that your CPU consumption will be pretty high, specially if you spun up as many threads as available cores (can be noticed by room temperature going up). To exacerbate the problem let’s sleep for a second in the critical zone (please don’t ever do this)</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span><span>@@ -91,6 +91,7 @@ spin_lock counter_lock;
</span></span></span><span><span><span></span> void* counter_thread(void* arg) {
</span></span><span><span>        for (int i = 0; i &lt; 1000000; i++) {
</span></span><span><span>                lock(&amp;spin_lock);
</span></span><span><span><span>+               sleep(1);
</span></span></span><span><span><span></span>                counter++;
</span></span><span><span>                unlock(&amp;spin_lock);
</span></span><span><span>        }
</span></span><span><span>}
</span></span></code></pre></div><p>No fun!</p>
<p><img src="https://blog.fredrb.com/htop.jpg" alt="htop"/></p>
<blockquote>
<p><strong>htop</strong> showing 9 of my cores begging for help</p></blockquote>
<p>Clearly only one thread is doing the work at a time (incrementing the counter) while the others are burning through my CPU in a while loop.</p>
<h2 id="enter-futex">Enter futex!</h2>
<p>The <code>futex</code> syscall from Linux is a secret weapon to deal better with the “wait” part of the lock. Instead of mindlessly spinning, let’s put the thread to sleep if the lock is not available, and wake them up when another thread releases it.</p>
<p>Futex offers a few different operations, but in order to implement our basic lock we only need two: <code>FUTEX_WAIT</code> to put threads to sleep and <code>FUTEX_WAKE</code> to wake them up. They are counter intuitive at first. When waiting on a futex, we tell the API the following:</p>
<blockquote>
<p>don’t wake this thread up while the value is still X</p></blockquote>
<p>However, this does not mean that once the value changed, the thread will be woken up. We still need another operation to actually change the value to something other than X and then call <code>FUTEX_WAKE</code>.</p>
<p>Here are a few scenarios I’ve played around with futex to better understand how they behave:</p>
<p><strong>Case 1: bread and butter case</strong></p>
<p>The most important thing to understand about futexes is that putting to sleep and waking up works around the integer value of the underlying futex 32bit integer. When you sleep, you sleep as long as the value is set to some <code>A</code>. If you want to wake a thread up, you have to make sure the futex value is not <code>A</code>, and then call the <code>FUTEX_WAIT</code> syscall.</p>
<p><img src="https://blog.fredrb.com/futex_1.svg" alt="futex_1"/></p>
<p><strong>Case 2: Thread is not put to sleep because condition isn’t met</strong></p>
<p>When you wait on a value, the kernel will first atomically check that value to avoid risking putting this thread to sleep if the value was updated between the previous atomic read and the calling of futex. In such cases the futex call fails with <code>EAGAIN</code>.</p>
<p><img src="https://blog.fredrb.com/futex_2.svg" alt="futex_2"/></p>
<p><strong>Case 3: Calling wake without changing the value won’t do anything</strong></p>
<p>If you call futex wait and the value is unchanged, the sleeping thread will not wake up! Likewise, just changing the value has no effect on the waiters if it’s not followed by a <code>FUTEX_WAKE</code> syscall.</p>
<p><img src="https://blog.fredrb.com/futex_3.svg" alt="futex_3"/></p>
<h2 id="mutex-implementation-using-futex">Mutex implementation using futex</h2>
<p>Let’s start building our new mutex! The struct will look pretty similar to the previous one, but we will now use a 32bit integer rather than a boolean. This is required by the futex API.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>	<span>uint32_t</span> ftx;
</span></span><span><span>} futex_lock; 
</span></span></code></pre></div><p>We first are going to implement a wrapper around the syscall (as suggested in <code>futex</code> man pages):</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>int</span> <span>futex</span>(<span>uint32_t</span> <span>*</span>uaddr, <span>int</span> futex_op, <span>uint32_t</span> val,
</span></span><span><span>	<span>const</span> <span>struct</span> timespec <span>*</span>timeout, <span>uint32_t</span> <span>*</span>uaddr2, <span>uint32_t</span> val3) {
</span></span><span><span>	<span>return</span> <span>syscall</span>(SYS_futex, uaddr, futex_op, val,
</span></span><span><span>			timeout, uaddr2, val3);
</span></span><span><span>}
</span></span></code></pre></div><p>We still need the operation in a <code>while</code> loop, so the condition to check if the lock is available is virtually the same. We can’t guarantee that another thread didn’t call <code>lock</code> after the present one was woken up. So we need to repeat the compare and swap operation.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>lock</span>(futex_lock <span>*</span>lock) {
</span></span><span><span>	<span>uint32_t</span> unlocked <span>=</span> <span>0</span>;
</span></span><span><span>	<span>// fast-path: atomic is set without entering the loop
</span></span></span><span><span><span></span>	<span>while</span> (<span>!</span><span>atomic_compare_exchange_weak</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, <span>&amp;</span>unlocked, <span>1</span>)) {
</span></span><span><span>		<span>// C11 atomic API: since we pass &amp;unlocked by reference
</span></span></span><span><span><span></span>		<span>// it sets the actual value if comparison failed
</span></span></span><span><span><span></span>		unlocked <span>=</span> <span>0</span>;
</span></span><span><span>		<span>const</span> <span>unsigned</span> <span>int</span> wait_condition <span>=</span> <span>1</span>;
</span></span><span><span>		<span>// call futex with `wait_condition=1`. Remeber that
</span></span></span><span><span><span></span>		<span>// the kernel will first atomically check the condition
</span></span></span><span><span><span></span>		<span>// and exit early without putting the thread to sleep if
</span></span></span><span><span><span></span>		<span>// `lock-&gt;ftx != wait_condition`
</span></span></span><span><span><span></span>		<span>long</span> s <span>=</span> <span>futex</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, FUTEX_WAIT,
</span></span><span><span>				wait_condition,
</span></span><span><span>				NULL,
</span></span><span><span>				NULL,
</span></span><span><span>				<span>0</span>);
</span></span><span><span>		<span>// we get EAGAIN here if thread was _not_ put to sleep
</span></span></span><span><span><span></span>		<span>if</span> (s <span>==</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> errno <span>!=</span> EAGAIN)
</span></span><span><span>			<span>err</span>(EXIT_FAILURE, <span>&#34;futex-FUTEX_WAIT&#34;</span>);
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>When calling <code>FUTEX_WAKE</code>, we need to specify at most how many threads should be woken up. Because we are using this in a mutex implementation and there is no priority logic implemented here, we only wake up one thread and let that thread take the lock.</p>
<blockquote>
<p>Technically, you could pass <code>INT_MAX</code> and wake up every thread that is waiting on that address. The implementation makes no guarantees on which threads gets picked up first.</p></blockquote>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>unlock</span>(futex_lock <span>*</span>self) {
</span></span><span><span>	<span>uint32_t</span> locked <span>=</span> <span>1</span>;
</span></span><span><span>	<span>if</span> (<span>atomic_compare_exchange_strong</span>(<span>&amp;</span>self<span>-&gt;</span>ftx, <span>&amp;</span>locked, <span>0</span>)) {
</span></span><span><span>		<span>const</span> <span>unsigned</span> <span>int</span> callers_to_awake <span>=</span> <span>1</span>;
</span></span><span><span>		<span>// wakes up at most one caller that is put sleep at a 
</span></span></span><span><span><span></span>		<span>// different value than 0 (unlocked)
</span></span></span><span><span><span></span>		<span>long</span> s <span>=</span> <span>futex</span>(<span>&amp;</span>self<span>-&gt;</span>ftx, FUTEX_WAKE,
</span></span><span><span>				callers_to_awake,
</span></span><span><span>				NULL,
</span></span><span><span>				NULL,
</span></span><span><span>				<span>0</span>);
</span></span><span><span>		<span>if</span> (s <span>==</span> <span>-</span><span>1</span>)
</span></span><span><span>			<span>err</span>(EXIT_FAILURE, <span>&#34;futex-FUTEX_WAKE&#34;</span>);
</span></span><span><span>	}
</span></span><span><span>	<span>// for safety, we shouldn&#39;t be able to call unlock twice
</span></span></span><span><span><span></span>	<span>assert</span>(locked <span>==</span> <span>1</span>);
</span></span><span><span>}
</span></span></code></pre></div><h2 id="so-futex-are-always-better-right">So, futex are always better… right?</h2>
<p>Well, not quite. With the unbounded spin lock, the futex implementation is definetly faster and uses less resources. However, a very simple change to the spin lock can make it significantly better than our futex version:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span>diff --git a/main.c b/main.c
</span></span><span><span>index 86c0141..414d4f0 100644
</span></span><span><span><span>--- a/main.c
</span></span></span><span><span><span></span><span>+++ b/main.c
</span></span></span><span><span><span></span><span>@@ -11,8 +11,7 @@
</span></span></span><span><span><span></span><span>+#include &lt;sched.h&gt;
</span></span></span><span><span><span></span>
</span></span><span><span> void lock(spin_lock *lock) {
</span></span><span><span><span>-       while (atomic_exchange(&amp;lock-&gt;locked, true)) {}
</span></span></span><span><span><span></span><span>+       while (atomic_exchange(&amp;lock-&gt;locked, true)) {
</span></span></span><span><span><span>+               sched_yield();
</span></span></span><span><span><span>+       }
</span></span></span><span><span><span></span> }
</span></span></code></pre></div><p>This will make our spin be a little more efficient, by yielding the CPU in this thread, allowing the CPU to go to a thread that could do some work to unlock our mutex. This is the poor man’s wait!</p>
<pre tabindex="0"><code>❯ perf stat ./futex-lock-count
Final counter value: 1000000

 Performance counter stats for &#39;./futex-lock-count&#39;:
	692.93 msec task-clock:u           #    8.577 CPUs utilized
	&lt;REDACTED&gt;
	0.080790594 seconds time elapsed

	0.100786000 seconds user
    0.575473000 seconds sys

❯ perf stat ./spin-lock-count
Final counter value: 1000000

 Performance counter stats for &#39;./spin-lock-count&#39;:
	133.78 msec task-clock:u           #    8.654 CPUs utilized
	&lt;REDACTED&gt;
	0.015458606 seconds time elapsed

    0.028445000 seconds user
    0.105634000 seconds sys
</code></pre><blockquote>
<p>Note that this benchmark is very fragile and results will vary depending on other workloads on my machine. But for my silly little exercise this is enough to give me a ballpark of the how they compare</p></blockquote>
<p>Our spin lock solution is at least 5x faster than with futex! Notice that the amount of CPU was utilized, but we used much more CPU time (<code>task-clok</code>) on the futex implementation. One important thing to notice here, is that the time spent on <code>system</code> (kernel) is significantly larger in the futex solution. This could give us some hints into what needs to be improved.</p>
<h2 id="improved-futex-lock-avoid-syscalls">Improved futex lock (avoid syscalls)</h2>
<p>Let’s take the reference implementation from the paper “Futexes Are Tricky” and take it for a spin (or no spin) in our test harness.</p>
<p>It turns out that one expensive operation that we have to do here is calling wake on the futex <strong>even when there are no threads in the queue</strong>. This can be quite expensive due to having to unnecessarily dip into kernel land. The main thing that this approach from the paper will do different, is to avoid this extra kernel space context switch, and only call wake if we <em>believe</em> that there is a thread waiting.</p>
<blockquote>
<p>As we will see below, we might still call wake when there are no threads. But in scenarios we are certain there are no threads waiting, no syscalls are made.</p></blockquote>
<p>The first thing we need, is a distinction in the mutex if:</p>
<ol>
<li>It’s available;</li>
<li>It’s locked and there are no waiters; or</li>
<li>It’s locked and there are waiters</li>
</ol>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>const</span> <span>uint32_t</span> AVAILABLE <span>=</span> <span>0</span>;
</span></span><span><span><span>const</span> <span>uint32_t</span> LOCKED <span>=</span> <span>1</span>;
</span></span><span><span><span>const</span> <span>uint32_t</span> LOCKED_WAITERS <span>=</span> <span>2</span>;
</span></span></code></pre></div><p>The lock function now has to deal with the case where we try to lock, and the lock is not available but also there are already a thread waiting.</p>
<blockquote>
<p>I strongly suggest that you read the paper to understand how they arrived at this algorithm. It’s not long and very informative on futexes.</p></blockquote>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>lock</span>(futex_lock <span>*</span>lock) {
</span></span><span><span>	<span>uint32_t</span> c <span>=</span> AVAILABLE;
</span></span><span><span>	<span>if</span> (<span>!</span><span>atomic_compare_exchange_weak</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, <span>&amp;</span>c, LOCKED)) {
</span></span><span><span>		<span>if</span> (c <span>!=</span> LOCKED_WAITERS)
</span></span><span><span>			c <span>=</span> <span>atomic_exchange</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, LOCKED_WAITERS);
</span></span><span><span>		<span>while</span> (c <span>!=</span> AVAILABLE) {
</span></span><span><span>			<span>long</span> s <span>=</span> <span>futex</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, FUTEX_WAIT,
</span></span><span><span>					LOCKED_WAITERS,
</span></span><span><span>					NULL,
</span></span><span><span>					NULL,
</span></span><span><span>					<span>0</span>);
</span></span><span><span>			<span>if</span> (s <span>==</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> errno <span>!=</span> EAGAIN)
</span></span><span><span>				<span>err</span>(EXIT_FAILURE, <span>&#34;futex-FUTEX_WAIT&#34;</span>);
</span></span><span><span>			c <span>=</span> <span>atomic_exchange</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, LOCKED_WAITERS);
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>The important difference happens in the <code>unlock</code> function. We want to make sure that if we are confident that there were no waiters, then the <code>FUTEX_WAKE</code> should not be called!</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>unlock</span>(futex_lock <span>*</span>lock) {
</span></span><span><span>	<span>if</span> (<span>atomic_fetch_sub</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, <span>1</span>) <span>!=</span> LOCKED) {
</span></span><span><span>		<span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, <span>0</span>);
</span></span><span><span>		<span>unsigned</span> <span>int</span> callers_to_awake <span>=</span> <span>1</span>;
</span></span><span><span>		<span>long</span> s <span>=</span> <span>futex</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, FUTEX_WAKE,
</span></span><span><span>				callers_to_awake,
</span></span><span><span>				NULL,
</span></span><span><span>				NULL,
</span></span><span><span>				<span>0</span>);
</span></span><span><span>		<span>if</span> (s <span>==</span> <span>-</span><span>1</span>)
</span></span><span><span>			<span>err</span>(EXIT_FAILURE, <span>&#34;futex-FUTEX_WAKE&#34;</span>);
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>Can you spot why we might still call <code>FUTEX_WAKE</code> even if there are no waiters in the queue? Take a closer look at this line in the <code>lock</code> function:</p>
<div><pre tabindex="0"><code data-lang="c"><span><span>c <span>=</span> <span>atomic_exchange</span>(<span>&amp;</span>lock<span>-&gt;</span>ftx, LOCKED_WAITERS);
</span></span></code></pre></div><p>When a thread awakes, it will try again to take the lock, and it will swap the value for a <code>LOCKED_WAITERS</code>
There are two possibilities here:</p>
<ol>
<li>There were multiple threads asleep, so the value is correct</li>
<li>The thread that was woken up was the only thread in the queue. So we will incorrectly set the value.</li>
</ol>
<p>Incorrectly setting the value will cause the <code>unlock</code> function to unnecessarily call <code>FUTEX_WAKE</code>. However, that’s a small price to pay compared to the correctness issue of assuming that the thread was the only one asleep and risking the next unlock to <strong>incorrectly</strong> not call <code>FUTEX_WAKE</code>!</p>
<p>For sure there must be implementations that will further optimize this, but for now let’s see how our new mutex fares against the spin lock:</p>
<pre tabindex="0"><code>❯ perf stat ./futex-lock2-count
Final counter value: 1000000

 Performance counter stats for &#39;./futex-lock2-count&#39;:
	158.13 msec task-clock:u          #    6.908 CPUs utilized
    &lt;REDACTED&gt;
    0.022890447 seconds time elapsed

    0.031259000 seconds user
    0.119167000 seconds sys
</code></pre><p>Sadly, spin locks are still faster.</p>
<h2 id="counting-is-a-bad-example">Counting is a bad example</h2>
<p>However this might not be entirely due to our implementation. Counting integers is hardly a good example for mutexes. I’ve picked it since it’s an easy exercise to illustrate the concepts, but if we want to validate the performance of our implementation, we probably wouldn’t even solve this problem with a mutex! If all we need to do is count, then simply incrementing an atomic variable would be sufficient.</p>
<p>I propose that we see the performance of our two mutex implementation in an example that would yield higher contention. Meaning that we need more waiting time. A good way to exemplify that, would be adding an operation in the critical zone that requires a little more than a single CPU instruction and therefore would make threads hold onto the lock for a while longer. We should also add another expensive computation outside the lock so at least the example is realistic where some of the work can be parallelized and some can’t.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>const</span> <span>unsigned</span> <span>int</span> FIB_VALUE <span>=</span> <span>30</span>;
</span></span><span><span>
</span></span><span><span><span>void</span><span>*</span> <span>fib_thread</span>(<span>void</span><span>*</span> arg) {
</span></span><span><span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>100</span>; <span>++</span>i) {
</span></span><span><span>		<span>fib</span>(FIB_VALUE);
</span></span><span><span>		<span>lock</span>(<span>&amp;</span>external_lock);
</span></span><span><span>		<span>fib</span>(FIB_VALUE);
</span></span><span><span>		<span>unlock</span>(<span>&amp;</span>external_lock);
</span></span><span><span>		<span>fib</span>(FIB_VALUE);
</span></span><span><span>	}
</span></span><span><span>	<span>return</span> NULL;
</span></span><span><span>}
</span></span></code></pre></div><p>Let’s now run our harness using this new thread and see the results!</p>
<pre tabindex="0"><code> Performance counter stats for &#39;./output/spin_lock.out 2&#39;:
	 37,905.51 msec task-clock:u           #    8.582 CPUs utilized
	&lt;REDACTED&gt;
       4.416729782 seconds time elapsed

      16.072219000 seconds user
      21.731787000 seconds sys

 Performance counter stats for &#39;./output/futex_lock2.out 2&#39;:
	  9,588.06 msec task-clock:u           #    2.681 CPUs utilized
	&lt;REDACTED&gt;
       3.576809001 seconds time elapsed

       9.537161000 seconds user
       0.020920000 seconds sys
</code></pre><p>Nice! Now not only our the total elapsed time of our futex lock implementation is lower, we’ve used much less CPU time. The spin lock implementation took a lot of time spinning rather than doing useful work, even if the elapsed time was not too much longer, ouir program hogged the CPU that could be used by other processes.</p>
<blockquote>
<p>The fun part is that it was even audibly noticeable since the CPU fans went crazy while running the example on spin lock!</p></blockquote>
<h2 id="whats-next">What’s next?</h2>
<p>There are many other aspects of locks and futexes that I would like to explore, but this article is large enough as it is, so I will leave it at that.</p>
<ul>
<li>The <strong>best of both worlds</strong> would be to implement a lock that spins for a little bit, making sure that if the lock gets freed up fast, we can benefit from the low overhead approach.</li>
<li>I’ve read some code from Rust standard library and Go’s runtime to understand how they tackled the mutex implementation. It would be nice to dig a little deeper and fully understand their implementation and trade-offs. As a matter of fact, both Rust and Go implementation use a hybrid approach of spin locks and futexes (in Linux, at least)!</li>
<li><strong>Fairness</strong>: our mutex implementation is not exactly fair. If a thread swoops in and grabs the atomic before a sleeping thread is awaken it will very impolitely cut the queue.</li>
<li><strong>Memory ordering:</strong> I’ve written one implementation of futex lock in C that uses acquire ordering for locks and release for unlock. This sort of makes sense intuitively after reading some reference code and explanation on memory ordering. However I don’t fully understand that to write about it so we skipped it in this article.</li>
</ul>
<h2 id="references">References</h2>
<p>Here are some good references I read in preparation to writing this article:</p>
<ul>
<li><a href="https://www.man7.org/linux/man-pages/man2/futex.2.html">futex(2)</a> syscall man page
<ul>
<li>The best source of text for understanding what the syscall does</li>
</ul>
</li>
<li><a href="https://cis.temple.edu/~giorgio/cis307/readings/futex.pdf">Futexes Are Ticky</a> (2005) paper by Ulrich Drepper
<ul>
<li>This paper is a must read for understanding the weird parts of futexes. It walks through from a simple (and buggy) implementation of a mutex using futex to a more complicated but correct implementation.</li>
</ul>
</li>
<li><a href="https://marabos.nl/atomics/os-primitives.html#futex">Chapter 8: Operating System Primitives</a> from Mara Bos’ Rust Atomics and Locks book.
<ul>
<li>Her whole book is worth a read on the topic. More specifically, chapters 4 and 9 also cover lock implementations.</li>
</ul>
</li>
<li><a href="https://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks.pdf">Chapter 28: Thread Locks</a> from Operating Systems Three Easy Pieces
<ul>
<li>This chapter is quite condensed and covers the needs for locks, the OS API, as well as more complex implementations, like queue locks, which I won’t cover in this article.</li>
</ul>
</li>
<li>Eli Bendersky’s <a href="https://eli.thegreenplace.net/2018/basics-of-futexes/">Basic of Futexes</a> article</li>
<li>Chapter 7 on Spin Locks and Contention from The Art of Multiprocessor Programming</li>
<li><a href="https://doc.rust-lang.org/src/std/sys/sync/mutex/futex.rs.html">Rust’s Mutex implementation</a> for Linux using futex</li>
</ul>

</div><p>
If you hated this post, and can&#39;t keep it to yourself, consider sending me an e-mail at <a href="mailto:fred.rbittencourt@gmail.com">fred.rbittencourt@gmail.com</a>. I&#39;m more responsive to positive comments though.
</p></div>
  </body>
</html>
