<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/">Original</a>
    <h1>Gemini Embedding: Powering RAG and context engineering</h1>
    
    <div id="readability-page-1" class="page"><div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          
        
          
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <p data-block-key="a6fas">Since announcing the <a href="https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/">general availability of our Gemini Embedding text model</a>, we&#39;ve seen developers rapidly adopt it to build advanced AI applications. Beyond traditional use cases like classification, semantic search, and retrieval-augmented generation (RAG), many are now using a technique called <a href="https://www.philschmid.de/context-engineering">context engineering</a> to provide AI agents with complete operational context. Embeddings are crucial here, as they efficiently identify and integrate vital information—like documents, conversation history, and tool definitions—directly into a model&#39;s working memory.</p><p data-block-key="1ltlh">The following examples showcase how organizations across industries are already leveraging the Gemini Embedding model to power sophisticated systems.</p><h2 data-block-key="iym27" id="gemini-embedding-in-action"></h2><h3 data-block-key="9rn4y" id=""><b></b></h3><p data-block-key="et70a"><a href="https://www.box.com/home">Box</a>, an intelligent content management platform, is integrating Gemini Embedding to enable a critical use case: answering questions and extracting insights from complex documents. During their evaluations, <code>gemini-embedding-001</code> found the <b>correct answer over 81% of the time</b>, exhibiting a <b>3.6% increase in recall</b> compared to other embedding models. Beyond this performance boost, our model&#39;s built-in multilingual support is a promising advancement for their global users, enabling Box AI to unlock insights from content across different languages and regions.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Box-AI-Gemini-Embedding.original.png" alt="Box AI - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="t12q1" id=""><b>Improving accuracy in financial data analysis</b></h3><p data-block-key="bsric">Financial technology company <a href="https://www.re-cap.com/">re:cap</a> uses embeddings to classify high volumes of B2B bank transactions. They measured the impact of <code>gemini-embedding-001</code> by benchmarking against previous Google models (<code>text-embedding-004</code> and <code>text-embedding-005</code>) on a dataset of 21,500 transactions, finding an <b>increase in</b> <a href="https://en.wikipedia.org/wiki/F-score"><b>F1 score</b></a><b> by 1.9% and 1.45%</b> respectively. The F1 score, which balances a model&#39;s precision and recall, is crucial for classification tasks. This demonstrates how a capable model like Gemini Embedding directly drives significant performance gains, helping re:cap deliver sharper liquidity insights to its customers.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/re-cap.original.png" alt="re:cap - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="3qs84" id=""><b>Achieving semantic precision in legal discovery</b></h3><p data-block-key="31r7j"><a href="https://www.everlaw.com/">Everlaw</a>, a platform providing verifiable RAG to help legal professionals analyze large volumes of discovery documents, requires precise semantic matching across millions of specialized texts. Through internal benchmarks, Everlaw found <code>gemini-embedding-001</code> to be the best, achieving <b>87% accuracy</b> in surfacing relevant answers from 1.4 million documents filled with industry-specific and complex legal terms, surpassing Voyage (84%) and OpenAI (73%) models. Furthermore, Gemini Embedding&#39;s Matryoshka property enables Everlaw to use compact representations, focusing essential information in fewer dimensions. This leads to minimal performance loss, reduced storage costs, and more efficient retrieval and search.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/everlaw.original.png" alt="Everlaw - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="an6vt" id=""><b>Leveling up codebase search for developers</b></h3><p data-block-key="c1cvc"><a href="https://roocode.com/">Roo Code</a>, an open-source AI coding assistant, uses the Gemini Embedding model to power its codebase indexing and semantic search. Developers using Roo Code need a search that helps understand intent, not just syntax, as the assistant interacts across multiple files like a human teammate. By pairing <code>gemini-embedding-001</code> with Tree-sitter for logical code splitting, Roo Code delivers highly relevant results, even for imprecise queries. After initial testing, they found Gemini Embedding significantly improved their LLM-driven code search, making it more flexible, accurate, and aligned with developer workflows.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ROOCode.original.png" alt="ROO Code - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="84dhp" id=""><b>Delivering personalized mental wellness support</b></h3><p data-block-key="ohq4"><a href="https://mindlid.com/">Mindlid&#39;s</a> AI wellness companion leverages <code>gemini-embedding-001</code> to understand conversational history, enabling context-aware and meaningful insights that adapt in real time to users. They documented impressive performance: consistent<b> sub-second latency</b> (median: 420ms) and a measurable <b>82% top-3 recall rate, a 4% recall lift</b> over OpenAI&#39;s <code>text-embedding-3-small</code>. This shows how Gemini Embedding improves the relevance and speed of their AI&#39;s support by delivering the most pertinent information.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Mindlid.original.png" alt="Mindlid - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="6jr1b" id=""><b>Enhancing context and efficiency of AI assistants</b></h3><p data-block-key="2u1b2">Interaction Co. is building <a href="https://poke.com/">Poke</a>, an AI email assistant that automates tasks and extracts information from Gmail. Poke uses Gemini Embedding for two key functions: retrieving user &#34;memories&#34; and identifying relevant emails for enhanced context. By integrating <code>gemini-embedding-001</code>, Poke&#39;s language model retrieves data with greater speed and precision. They&#39;ve reported a significant <b>90.4% reduction in the average time</b> to embed 100 emails compared to Voyage-2, completing the task in just 21.45 seconds.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Poke.original.png" alt="Poke - Gemini Embedding"/>
            
            
        </p>
    </div>
  <div>
    <h2 data-block-key="zv45a" id="the-foundation-for-future-agents">The foundation for future agents</h2><p data-block-key="e2r1o">As AI systems become more autonomous, their effectiveness will be determined by the quality of the context we provide them. High-performance embedding models like <code>gemini-embedding-001</code> are a fundamental component for building the next generation of agents that can reason, retrieve information, and act on our behalf.</p><p data-block-key="3gjcp">To get started with embeddings, visit the <a href="https://ai.google.dev/gemini-api/docs/embeddings">Gemini API documentation</a>.</p><p data-block-key="8rmbe"><i><br/></i><i><sub>Performance metrics were provided by developers and not independently confirmed by Google.</sub></i></p>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div></div>
  </body>
</html>
