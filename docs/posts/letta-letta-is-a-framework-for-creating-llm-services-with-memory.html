<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/letta-ai/letta">Original</a>
    <h1>Letta: Letta is a framework for creating LLM services with memory</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_GreyonTransparent_cropped_small.png"/>
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_OffBlackonTransparent_cropped_small.png"/>
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_GreyonOffBlack_cropped_small.png" width="500"/>
  </picture></themed-picture>
</p>
<div dir="auto">

<p dir="auto"><strong>‚òÑÔ∏è New release: Letta Agent Development Environment (<em>read more <a href="#-access-the-ade-agent-development-environment">here</a></em>) ‚òÑÔ∏è</strong></p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png"/>
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_light.png"/>
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png" width="800"/>
  </picture></themed-picture>
</p>
<hr/>

<p dir="auto"><strong>üëæ Letta</strong> is an open source framework for building stateful LLM applications. You can use Letta to build <strong>stateful agents</strong> with advanced reasoning capabilities and transparent long-term memory. The Letta framework is white box and model-agnostic.</p>
<p dir="auto"><a href="https://discord.gg/letta" rel="nofollow"><img src="https://camo.githubusercontent.com/0a4c715eec8377e6695e904295b465ab9e37b7e6f332d37ac3846e37a3f07b79/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313136313733363234333334303634303431393f6c6162656c3d446973636f7264266c6f676f3d646973636f7264266c6f676f436f6c6f723d353836354632267374796c653d666c61742d73717561726526636f6c6f723d353836354632" alt="Discord" data-canonical-src="https://img.shields.io/discord/1161736243340640419?label=Discord&amp;logo=discord&amp;logoColor=5865F2&amp;style=flat-square&amp;color=5865F2"/></a>
<a href="https://twitter.com/Letta_AI" rel="nofollow"><img src="https://camo.githubusercontent.com/da01994075ea1dbd944cf0883cee51ee589f9c87889d55b3b34386d20ba770c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772d2534304c657474615f5f41492d3144413146323f7374796c653d666c61742d737175617265266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Twitter Follow" data-canonical-src="https://img.shields.io/badge/Follow-%40Letta__AI-1DA1F2?style=flat-square&amp;logo=x&amp;logoColor=white"/></a>
<a href="https://arxiv.org/abs/2310.08560" rel="nofollow"><img src="https://camo.githubusercontent.com/0b3330583e437415c64ad9a738d8fa22746ffc83971ddab5713b407915e86589/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52657365617263682d323331302e30383536302d4233314231423f6c6f676f3d6172786976267374796c653d666c61742d737175617265" alt="arxiv 2310.08560" data-canonical-src="https://img.shields.io/badge/Research-2310.08560-B31B1B?logo=arxiv&amp;style=flat-square"/></a></p>
<p dir="auto"><a href="https://github.com/letta-ai/letta/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/4dbaf2f6e74c99a9f7bc9100254cb9b95d49de1c27161fa5a9a8def2256c54f8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d73696c7665723f7374796c653d666c61742d737175617265" alt="Apache 2.0" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-silver?style=flat-square"/></a>
<a href="https://github.com/cpacker/MemGPT/releases"><img src="https://camo.githubusercontent.com/30b28a2d55b2469371f8905f8bb91d19a44dadb64a5ee4af76afa9059c6c724f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f637061636b65722f4d656d4750543f7374796c653d666c61742d737175617265266c6162656c3d52656c6561736526636f6c6f723d6c696d65677265656e" alt="Release" data-canonical-src="https://img.shields.io/github/v/release/cpacker/MemGPT?style=flat-square&amp;label=Release&amp;color=limegreen"/></a>
<a href="https://hub.docker.com/r/letta/letta" rel="nofollow"><img src="https://camo.githubusercontent.com/e0472f1ed32798e5bd4f58a36591f199297aad9cc2cfb4d645d3079a7ec1d778/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f762f6c657474612f6c657474613f7374796c653d666c61742d737175617265266c6f676f3d646f636b6572266c6162656c3d446f636b657226636f6c6f723d306462376564" alt="Docker" data-canonical-src="https://img.shields.io/docker/v/letta/letta?style=flat-square&amp;logo=docker&amp;label=Docker&amp;color=0db7ed"/></a>
<a href="https://github.com/cpacker/MemGPT"><img src="https://camo.githubusercontent.com/a9532a1704444323339a5ecfb6fb8b6a721dfca412d9a22ba58aeb67ab157837/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637061636b65722f4d656d4750543f7374796c653d666c61742d737175617265266c6f676f3d676974687562266c6162656c3d537461727326636f6c6f723d676f6c64" alt="GitHub" data-canonical-src="https://img.shields.io/github/stars/cpacker/MemGPT?style=flat-square&amp;logo=github&amp;label=Stars&amp;color=gold"/></a></p>
<p dir="auto"><a href="https://trendshift.io/repositories/3612" rel="nofollow"><img src="https://camo.githubusercontent.com/8757a96b2ad45cda1a5a5ce0de645d8a50d697bf9e17483e7298200f03c82127/68747470733a2f2f7472656e6473686966742e696f2f6170692f62616467652f7265706f7369746f726965732f33363132" alt="cpacker%2FMemGPT | Trendshift" width="250" height="55" data-canonical-src="https://trendshift.io/api/badge/repositories/3612"/></a></p>
</div>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Important</p><p dir="auto"><strong>Looking for MemGPT?</strong> You&#39;re in the right place!</p>
<p dir="auto">The MemGPT package and Docker image have been renamed to <code>letta</code> to clarify the distinction between MemGPT <em>agents</em> and the Letta API <em>server</em> / <em>runtime</em> that runs LLM agents as <em>services</em>. Read more about the relationship between MemGPT and Letta <a href="https://www.letta.com/blog/memgpt-and-letta" rel="nofollow">here</a>.</p>
</div>
<hr/>

<p dir="auto"><em>The recommended way to use Letta is to run use Docker. To install Docker, see <a href="https://docs.docker.com/get-docker/" rel="nofollow">Docker&#39;s installation guide</a>. For issues with installing Docker, see <a href="https://docs.docker.com/desktop/troubleshoot-and-support/troubleshoot/" rel="nofollow">Docker&#39;s troubleshooting guide</a>. You can also install Letta using <code>pip</code> (see instructions <a href="#-quickstart-pip">below</a>).</em></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">üåñ Run the Letta server</h3><a id="user-content--run-the-letta-server" aria-label="Permalink: üåñ Run the Letta server" href="#-run-the-letta-server"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">Letta agents live inside the Letta server, which persists them to a database. You can interact with the Letta agents inside your Letta server via the <a href="https://docs.letta.com/api-reference" rel="nofollow">REST API</a> + Python / Typescript SDKs, and the <a href="https://app.letta.com" rel="nofollow">Agent Development Environment</a> (a graphical interface).</p>
</div>
<p dir="auto">The Letta server can be connected to various LLM API backends (<a href="https://docs.letta.com/models/openai" rel="nofollow">OpenAI</a>, <a href="https://docs.letta.com/models/anthropic" rel="nofollow">Anthropic</a>, <a href="https://docs.letta.com/models/vllm" rel="nofollow">vLLM</a>, <a href="https://docs.letta.com/models/ollama" rel="nofollow">Ollama</a>, etc.). To enable access to these LLM API providers, set the appropriate environment variables when you use <code>docker run</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# replace `~/.letta/.persist/pgdata` with wherever you want to store your agent data
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  -e OPENAI_API_KEY=&#34;your_openai_api_key&#34; \
  letta/letta:latest"><pre><span><span>#</span> replace `~/.letta/.persist/pgdata` with wherever you want to store your agent data</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  -e OPENAI_API_KEY=<span><span>&#34;</span>your_openai_api_key<span>&#34;</span></span> \
  letta/letta:latest</pre></div>
<p dir="auto">If you have many different LLM API keys, you can also set up a <code>.env</code> file instead and pass that to <code>docker run</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# using a .env file instead of passing environment variables
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  letta/letta:latest"><pre><span><span>#</span> using a .env file instead of passing environment variables</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  letta/letta:latest</pre></div>
<p dir="auto">Once the Letta server is running, you can access it via port <code>8283</code> (e.g. sending REST API requests to <code>http://localhost:8283/v1</code>). You can also connect your server to the Letta ADE to access and manage your agents in a web interface.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">üëæ Access the ADE (Agent Development Environment)</h3><a id="user-content--access-the-ade-agent-development-environment" aria-label="Permalink: üëæ Access the ADE (Agent Development Environment)" href="#-access-the-ade-agent-development-environment"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">The Letta ADE is a graphical user interface for creating, deploying, interacting and observing with your Letta agents. For example, if you&#39;re running a Letta server to power an end-user application (such as a customer support chatbot), you can use the ADE to test, debug, and observe the agents in your server. You can also use the ADE as a general chat interface to interact with your Letta agents.</p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png"/>
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_light.png"/>
    <img alt="ADE screenshot" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png" width="800"/>
  </picture></themed-picture>
</p>
<p dir="auto">The ADE can connect to self-hosted Letta servers (e.g. a Letta server running on your laptop), as well as the Letta Cloud service. When connected to a self-hosted / private server, the ADE uses the Letta REST API to communicate with your server.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">üñ•Ô∏è Connecting the ADE to your local Letta server</h4><a id="user-content-Ô∏è-connecting-the-ade-to-your-local-letta-server" aria-label="Permalink: üñ•Ô∏è Connecting the ADE to your local Letta server" href="#Ô∏è-connecting-the-ade-to-your-local-letta-server"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To connect the ADE with your local Letta server, simply:</p>
<ol dir="auto">
<li>Start your Letta server (<code>docker run ...</code>)</li>
<li>Visit <a href="https://app.letta.com" rel="nofollow">https://app.letta.com</a> and you will see &#34;Local server&#34; as an option in the left panel</li>
</ol>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents.png"/>
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents_light.png"/>
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents.png" width="800"/>
  </picture></themed-picture>
</p>
<p dir="auto">üîê To password protect your server, include <code>SECURE=true</code> and <code>LETTA_SERVER_PASSWORD=yourpassword</code> in your <code>docker run</code> command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# If LETTA_SERVER_PASSWORD isn&#39;t set, the server will autogenerate a password
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  -e SECURE=true \
  -e LETTA_SERVER_PASSWORD=yourpassword \
  letta/letta:latest"><pre><span><span>#</span> If LETTA_SERVER_PASSWORD isn&#39;t set, the server will autogenerate a password</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  -e SECURE=true \
  -e LETTA_SERVER_PASSWORD=yourpassword \
  letta/letta:latest</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">üåê Connecting the ADE to an external (self-hosted) Letta server</h4><a id="user-content--connecting-the-ade-to-an-external-self-hosted-letta-server" aria-label="Permalink: üåê Connecting the ADE to an external (self-hosted) Letta server" href="#-connecting-the-ade-to-an-external-self-hosted-letta-server"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If your Letta server isn&#39;t running on <code>localhost</code> (for example, you deployed it on an external service like EC2):</p>
<ol dir="auto">
<li>Click &#34;Add remote server&#34;</li>
<li>Enter your desired server name, the IP address of the server, and the server password (if set)</li>
</ol>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">üßë‚ÄçüöÄ Frequently asked questions (FAQ)</h2><a id="user-content--frequently-asked-questions-faq" aria-label="Permalink: üßë‚ÄçüöÄ Frequently asked questions (FAQ)" href="#-frequently-asked-questions-faq"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<blockquote>
<p dir="auto"><em>&#34;Do I need to install Docker to use Letta?&#34;</em></p>
</blockquote>
<p dir="auto">No, you can install Letta using <code>pip</code> (via <code>pip install -U letta</code>), as well as from source (via <code>poetry install</code>). See instructions below.</p>
<blockquote>
<p dir="auto"><em>&#34;What&#39;s the difference between installing with <code>pip</code> vs <code>Docker</code>?&#34;</em></p>
</blockquote>
<p dir="auto">Letta gives your agents persistence (they live indefinitely) by storing all your agent data in a database. Letta is designed to be used with a <a href="https://en.wikipedia.org/wiki/PostgreSQL" rel="nofollow">PostgreSQL</a> (the world&#39;s most popular database), however, it is not possible to install PostgreSQL via <code>pip</code>, so the <code>pip</code> install of Letta defaults to using <a href="https://www.sqlite.org/" rel="nofollow">SQLite</a>. If you have a PostgreSQL instance running on your own computer, you can still connect Letta (installed via <code>pip</code>) to PostgreSQL by setting the environment variable <code>LETTA_PG_URI</code>.</p>
<p dir="auto"><strong>Database migrations are not officially supported for Letta when using SQLite</strong>, so if you would like to ensure that you&#39;re able to upgrade to the latest Letta version and migrate your Letta agents data, make sure that you&#39;re using PostgreSQL as your Letta database backend. Full compatability table below:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Installation method</th>
<th>Start server command</th>
<th>Database backend</th>
<th>Data migrations supported?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pip install letta</code></td>
<td><code>letta server</code></td>
<td>SQLite</td>
<td>‚ùå</td>
</tr>
<tr>
<td><code>pip install letta</code></td>
<td><code>export LETTA_PG_URI=...</code> + <code>letta server</code></td>
<td>PostgreSQL</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><em><a href="https://www.docker.com/get-started/" rel="nofollow">Install Docker</a></em></td>
<td><code>docker run ...</code> (<a href="#-run-the-letta-server">full command</a>)</td>
<td>PostgreSQL</td>
<td>‚úÖ</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><em>&#34;How do I use the ADE locally?&#34;</em></p>
</blockquote>
<p dir="auto">To connect the ADE to your local Letta server, simply run your Letta server (make sure you can access <code>localhost:8283</code>) and go to <a href="https://app.letta.com" rel="nofollow">https://app.letta.com</a>. If you would like to use the old version of the ADE (that runs on <code>localhost</code>), downgrade to Letta version <code>&lt;=0.5.0</code>.</p>
<blockquote>
<p dir="auto"><em>&#34;If I connect the ADE to my local server, does my agent data get uploaded to letta.com?&#34;</em></p>
</blockquote>
<p dir="auto">No, the data in your Letta server database stays on your machine. The Letta ADE web application simply connects to your local Letta server (via the REST API) and provides a graphical interface on top of it to visualize your local Letta data in your browser&#39;s local state.</p>
<blockquote>
<p dir="auto"><em>&#34;Do I have to use your ADE? Can I build my own?&#34;</em></p>
</blockquote>
<p dir="auto">The ADE is built on top of the (fully open source) Letta server and Letta Agents API. You can build your own application like the ADE on top of the REST API (view the documention <a href="https://docs.letta.com/api-reference" rel="nofollow">here</a>).</p>
<blockquote>
<p dir="auto"><em>&#34;Can I interact with Letta agents via the CLI?&#34;</em></p>
</blockquote>
<p dir="auto">The recommended way to use Letta is via the REST API and ADE, however you can also access your agents via the CLI.</p>
<details>
<summary>View instructions for running the Letta CLI</summary>
<p dir="auto">You can chat with your agents via the Letta CLI tool (<code>letta run</code>). If you have a Letta Docker container running, you can use <code>docker exec</code> to run the Letta CLI inside the container:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# replace `&lt;letta_container_id&gt;` with the ID of your Letta container, found via `docker ps`
docker exec -it &lt;letta_container_id&gt; letta run"><pre><span><span>#</span> replace `&lt;letta_container_id&gt;` with the ID of your Letta container, found via `docker ps`</span>
docker <span>exec</span> -it <span>&lt;</span>letta_container_id<span>&gt;</span> letta run</pre></div>
<p dir="auto">You can also use <code>docker ps</code> within the command to automatically find the ID of your Letta container:</p>
<div data-snippet-clipboard-copy-content="docker exec -it $(docker ps -q -f ancestor=letta/letta) letta run"><pre><code>docker exec -it $(docker ps -q -f ancestor=letta/letta) letta run
</code></pre></div>
<p dir="auto">In the CLI tool, you&#39;ll be able to create new agents, or load existing agents:</p>
<div data-snippet-clipboard-copy-content="üß¨ Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  ü§ñ Using persona profile: &#39;sam_pov&#39;
-&gt;  üßë Using human profile: &#39;basic&#39;
-&gt;  üõ†Ô∏è  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

üéâ Created new agent &#39;InspiringSpinach&#39;

Hit enter to begin (will request first Letta message)

üí≠ User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
ü§ñ Hello, Chad. It&#39;s nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

üí≠ A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
‚ö°üß† [function] updating memory with core_memory_replace
         First name: Chad
        ‚Üí First name: Brad
üí≠ Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
ü§ñ I apologize for the oversight, Brad. Let&#39;s restart. It&#39;s a pleasure to meet you, Brad. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message:"><pre><code>üß¨ Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  ü§ñ Using persona profile: &#39;sam_pov&#39;
-&gt;  üßë Using human profile: &#39;basic&#39;
-&gt;  üõ†Ô∏è  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

üéâ Created new agent &#39;InspiringSpinach&#39;

Hit enter to begin (will request first Letta message)

üí≠ User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
ü§ñ Hello, Chad. It&#39;s nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

üí≠ A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
‚ö°üß† [function] updating memory with core_memory_replace
         First name: Chad
        ‚Üí First name: Brad
üí≠ Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
ü§ñ I apologize for the oversight, Brad. Let&#39;s restart. It&#39;s a pleasure to meet you, Brad. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message:
</code></pre></div>
</details>
<hr/>

<div dir="auto"><p dir="auto"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Warning</p><p dir="auto"><strong>Database migrations are not officially supported with <code>SQLite</code></strong></p>
<p dir="auto">When you install Letta with <code>pip</code>, the default database backend is <code>SQLite</code> (you can still use an external <code>postgres</code> service with your <code>pip</code> install of Letta by setting <code>LETTA_PG_URI</code>).</p>
<p dir="auto">We do not officially support migrations between Letta versions with <code>SQLite</code> backends, only <code>postgres</code>. If you would like to keep your agent data across multiple Letta versions we highly recommend using the Docker install method which is the easiest way to use <code>postgres</code> with Letta.</p>
</div>
<details>
<summary>View instructions for installing with pip</summary>
<p dir="auto">You can also install Letta with <code>pip</code>, which will default to using <code>SQLite</code> for the database backends (whereas Docker will default to using <code>postgres</code>).</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Step 1 - Install Letta using <code>pip</code></h3><a id="user-content-step-1---install-letta-using-pip" aria-label="Permalink: Step 1 - Install Letta using pip" href="#step-1---install-letta-using-pip"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<div dir="auto"><h3 tabindex="-1" dir="auto">Step 2 - Set your environment variables for your chosen LLM / embedding providers</h3><a id="user-content-step-2---set-your-environment-variables-for-your-chosen-llm--embedding-providers" aria-label="Permalink: Step 2 - Set your environment variables for your chosen LLM / embedding providers" href="#step-2---set-your-environment-variables-for-your-chosen-llm--embedding-providers"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=sk-..."><pre><span>export</span> OPENAI_API_KEY=sk-...</pre></div>
<p dir="auto">For Ollama (see our full <a href="https://docs.letta.com/install" rel="nofollow">documentation</a> for examples of how to set up various providers):</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OLLAMA_BASE_URL=http://localhost:11434"><pre><span>export</span> OLLAMA_BASE_URL=http://localhost:11434</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Step 3 - Run the Letta CLI</h3><a id="user-content-step-3---run-the-letta-cli" aria-label="Permalink: Step 3 - Run the Letta CLI" href="#step-3---run-the-letta-cli"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can create agents and chat with them via the Letta CLI tool (<code>letta run</code>):</p>

<div data-snippet-clipboard-copy-content="üß¨ Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  ü§ñ Using persona profile: &#39;sam_pov&#39;
-&gt;  üßë Using human profile: &#39;basic&#39;
-&gt;  üõ†Ô∏è  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

üéâ Created new agent &#39;InspiringSpinach&#39;

Hit enter to begin (will request first Letta message)

üí≠ User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
ü§ñ Hello, Chad. It&#39;s nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

üí≠ A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
‚ö°üß† [function] updating memory with core_memory_replace
         First name: Chad
        ‚Üí First name: Brad
üí≠ Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
ü§ñ I apologize for the oversight, Brad. Let&#39;s restart. It&#39;s a pleasure to meet you, Brad. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message:"><pre><code>üß¨ Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  ü§ñ Using persona profile: &#39;sam_pov&#39;
-&gt;  üßë Using human profile: &#39;basic&#39;
-&gt;  üõ†Ô∏è  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

üéâ Created new agent &#39;InspiringSpinach&#39;

Hit enter to begin (will request first Letta message)

üí≠ User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
ü§ñ Hello, Chad. It&#39;s nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

üí≠ A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
‚ö°üß† [function] updating memory with core_memory_replace
         First name: Chad
        ‚Üí First name: Brad
üí≠ Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
ü§ñ I apologize for the oversight, Brad. Let&#39;s restart. It&#39;s a pleasure to meet you, Brad. Is there a specific topic you&#39;d like to discuss today?

&gt; Enter your message:
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Step 4 - Run the Letta server</h3><a id="user-content-step-4---run-the-letta-server" aria-label="Permalink: Step 4 - Run the Letta server" href="#step-4---run-the-letta-server"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can start the Letta API server with <code>letta server</code> (see the full API reference <a href="https://docs.letta.com/api-reference" rel="nofollow">here</a>):</p>

<div data-snippet-clipboard-copy-content="Initializing database...
Running: uvicorn server:app --host localhost --port 8283
INFO:     Started server process [47750]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8283 (Press CTRL+C to quit)"><pre><code>Initializing database...
Running: uvicorn server:app --host localhost --port 8283
INFO:     Started server process [47750]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8283 (Press CTRL+C to quit)
</code></pre></div>
</details>
<hr/>

<p dir="auto">Letta is an open source project built by over a hundred contributors. There are many ways to get involved in the Letta OSS project!</p>
<ul dir="auto">
<li><strong>Contribute to the project</strong>: Interested in contributing? Start by reading our <a href="https://github.com/cpacker/MemGPT/tree/main/CONTRIBUTING.md">Contribution Guidelines</a>.</li>
<li><strong>Ask a question</strong>: Join our community on <a href="https://discord.gg/letta" rel="nofollow">Discord</a> and direct your questions to the <code>#support</code> channel.</li>
<li><strong>Report issues or suggest features</strong>: Have an issue or a feature request? Please submit them through our <a href="https://github.com/cpacker/MemGPT/issues">GitHub Issues page</a>.</li>
<li><strong>Explore the roadmap</strong>: Curious about future developments? View and comment on our <a href="https://github.com/cpacker/MemGPT/issues/1533" data-hovercard-type="issue" data-hovercard-url="/letta-ai/letta/issues/1533/hovercard">project roadmap</a>.</li>
<li><strong>Join community events</strong>: Stay updated with the <a href="https://lu.ma/berkeley-llm-meetup" rel="nofollow">event calendar</a> or follow our <a href="https://twitter.com/Letta_AI" rel="nofollow">Twitter account</a>.</li>
</ul>
<hr/>
<p dir="auto"><em><strong>Legal notices</strong>: By using Letta and related Letta services (such as the Letta endpoint or hosted service), you are agreeing to our <a href="https://www.letta.com/privacy-policy" rel="nofollow">privacy policy</a> and <a href="https://www.letta.com/terms-of-service" rel="nofollow">terms of service</a>.</em></p>
</article></div></div>
  </body>
</html>
