<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/libAudioFlux/audioFlux">Original</a>
    <h1>AudioFlux: A C/C&#43;&#43; library for audio and music analysis</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/image/logo.png"><img src="https://ntietz.com/libAudioFlux/audioFlux/raw/master/image/logo.png" width="400"/></a></p> 


<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4dc3a92d0d86cda0fef58ebe5c7ef0c675ab9601210334da0cccbd6c2c9a5494/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6c6962417564696f466c75782f617564696f466c75782f6275696c642e796d6c3f6272616e63683d6d6173746572"><img src="https://camo.githubusercontent.com/4dc3a92d0d86cda0fef58ebe5c7ef0c675ab9601210334da0cccbd6c2c9a5494/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6c6962417564696f466c75782f617564696f466c75782f6275696c642e796d6c3f6272616e63683d6d6173746572" alt="GitHub Workflow Status (with branch)" data-canonical-src="https://img.shields.io/github/actions/workflow/status/libAudioFlux/audioFlux/build.yml?branch=master"/></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/libAudioFlux/audioFlux/actions/workflows/build.yml/badge.svg?branch=master"><img src="https://github.com/libAudioFlux/audioFlux/actions/workflows/build.yml/badge.svg?branch=master" alt="example branch parameter"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/646a031f23b7ac1250d4edabb5ad7c20449a0d08894cc89b40497c1b01718bea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d43253230253743253230507974686f6e2532302d626c75652e737667"><img src="https://camo.githubusercontent.com/646a031f23b7ac1250d4edabb5ad7c20449a0d08894cc89b40497c1b01718bea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d43253230253743253230507974686f6e2532302d626c75652e737667" alt="language" data-canonical-src="https://img.shields.io/badge/language-C%20%7C%20Python%20-blue.svg"/></a>
<a href="https://pypi.org/project/audioflux/" rel="nofollow"><img src="https://camo.githubusercontent.com/f192d1be4502fda24a4edac908c1f4db58445065cc87d51038e00ea7405a6462/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f617564696f666c7578" alt="PyPI - Version" data-canonical-src="https://img.shields.io/pypi/v/audioflux"/></a>
<a href="https://pypi.org/project/audioflux/" rel="nofollow"><img src="https://camo.githubusercontent.com/12b6641aeaf9744d0529f12414c489ea9432bdbac24339a9ff62088f39daeb77/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d253345253344332e362d627269676874677265656e" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/badge/python-%3E%3D3.6-brightgreen"/></a>
<a href="https://audioflux.top/index.html" rel="nofollow"><img src="https://camo.githubusercontent.com/e5c7a5d4270e5b9a2748b041243f94793f1d415a8d11431f87f8c4e2893f4a29/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63732d70617373696e672d627269676874677265656e" alt="Docs" data-canonical-src="https://img.shields.io/badge/Docs-passing-brightgreen"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c8fcc2972b3f7afeb1bb8d2f1236e07402344b85c53eddaa5855c72f359ee625/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c6962417564696f466c75782f617564696f466c7578"><img src="https://camo.githubusercontent.com/c8fcc2972b3f7afeb1bb8d2f1236e07402344b85c53eddaa5855c72f359ee625/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c6962417564696f466c75782f617564696f466c7578" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/libAudioFlux/audioFlux"/></a></p>

<p dir="auto"><a href="https://doi.org/10.5281/zenodo.7548288" rel="nofollow"><img src="https://camo.githubusercontent.com/1f081cad557bc3b49d8c1a4bf71f5e49358b5bcb9e23e47ddba7a7571fdab753/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e373534383238382e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.7548288.svg"/></a></p>

<p dir="auto"><strong><code>audioflux</code></strong> is a deep learning tool library for audio and music analysis, feature extraction. It supports dozens of
time-frequency analysis transformation methods and hundreds of corresponding time-domain and frequency-domain feature
combinations. It can be provided to deep learning networks for training, and is used to study various tasks in the audio
field such as Classification, Separation, Music Information Retrieval(MIR) and ASR etc.</p>


<ul dir="auto">
<li>v0.1.8
<ul dir="auto">
<li>Add a variety of Pitch algorithms: <code>YIN</code>, <code>CEP</code>, <code>PEF</code>, <code>NCF</code>, <code>HPS</code>, <code>LHS</code>, <code>STFT</code> and <code>FFP</code>.</li>
<li>Add <code>PitchShift</code> and <code>TimeStretch</code> algorithms.</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#python-package-install">Python Package Install</a></li>
<li><a href="#other-build">Other Build</a></li>
</ul>
</li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#benchmark">Benchmark</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#citing">Citing</a></li>
<li><a href="#license">License</a></li>
</ul>

<p dir="auto"><strong><code>audioFlux</code></strong> is based on data stream design. It decouples each algorithm module in structure, and can quickly and
efficiently extract features of multiple dimensions. The following is the main feature architecture diagram.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/image/feature_all.png"><img src="https://ntietz.com/libAudioFlux/audioFlux/raw/master/image/feature_all.png"/></a></p>

<p dir="auto">You can use multiple dimensional feature combinations, select different deep learning networks training, study various
tasks in the audio field such as Classification, Separation, MIR etc.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/image/flow.png"><img src="https://ntietz.com/libAudioFlux/audioFlux/raw/master/image/flow.png"/></a></p>
<p dir="auto">The main functions of <strong><code>audioFlux</code></strong> include <strong>transform</strong>, <strong>feature</strong> and <strong>mir</strong> modules.</p>

<p dir="auto">In the time–frequency representation, main transform algorithm:</p>
<ul dir="auto">
<li><strong><code>BFT</code></strong>   -   Based Fourier Transform, similar short-time Fourier transform.</li>
<li><strong><code>NSGT</code></strong> -   Non-Stationary Gabor Transform.</li>
<li><strong><code>CWT</code></strong>   -   Continuous Wavelet Transform.</li>
<li><strong><code>PWT</code></strong>   -   Pseudo Wavelet Transform.</li>
</ul>

<p dir="auto">The above transform supports all the following frequency scale types:</p>
<ul dir="auto">
<li>Linear - Short-time Fourier transform spectrogram.</li>
<li>Linspace - Linspace-scale spectrogram.</li>
<li>Mel - Mel-scale spectrogram.</li>
<li>Bark - Bark-scale spectrogram.</li>
<li>Erb - Erb-scale spectrogram.</li>
<li>Octave - Octave-scale spectrogram.</li>
<li>Log - Logarithmic-scale spectrogram.</li>
</ul>
<p dir="auto">The following transform are not supports multiple frequency scale types, only used as independent transform:</p>
<ul dir="auto">
<li><strong><code>CQT</code></strong> -   Constant-Q Transform.</li>
<li><strong><code>VQT</code></strong> -   Variable-Q Transform.</li>
<li><strong><code>ST</code></strong>   -   S-Transform/Stockwell Transform.</li>
<li><strong><code>FST</code></strong> -   Fast S-Transform.</li>
<li><strong><code>DWT</code></strong> -   Discrete Wavelet Transform.</li>
<li><strong><code>WPT</code></strong> -   Wave Packet Transform.</li>
<li><strong><code>SWT</code></strong> -   Stationary Wavelet Transform.</li>
</ul>
<p dir="auto">Detailed transform function, description, and use view the documentation.</p>
<p dir="auto">The <em><em>synchrosqueezing</em></em> or <em><em>reassignment</em></em> is a technique for sharpening a time-frequency representation, contains the
following algorithms:</p>
<ul dir="auto">
<li><strong><code>reassign</code></strong> - reassign transform for <code>STFT</code>.</li>
<li><strong><code>synsq</code></strong> - reassign data use <code>CWT</code> data.</li>
<li><strong><code>wsst</code></strong> - reassign transform for <code>CWT</code>.</li>
</ul>

<p dir="auto">The feature module contains the following algorithms:</p>
<ul dir="auto">
<li><strong><code>spectral</code></strong> - Spectrum feature, supports all spectrum types.</li>
<li><strong><code>xxcc</code></strong> - Cepstrum coefficients, supports all spectrum types.</li>
<li><strong><code>deconv</code></strong> - Deconvolution for spectrum, supports all spectrum types.</li>
<li><strong><code>chroma</code></strong> - Chroma feature, only supports <code>CQT</code> spectrum, Linear/Octave spectrum based on <code>BFT</code>.</li>
</ul>


<p dir="auto">The mir module contains the following algorithms:</p>
<ul dir="auto">
<li><strong><code>pitch</code></strong> - YIN, STFT, etc algorithm.</li>
<li><strong><code>onset</code></strong> - Spectrum flux, novelty, etc algorithm.</li>
<li><strong><code>hpss</code></strong> - Median filtering, NMF algorithm.</li>
</ul>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/25c8cbe0feb4b33d8afb811cc30e8ccf30858800e21016894192addbe8184154/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d2532304c696e75782532302537432532306d61634f5325323025374325323057696e646f7773253230253743253230694f53253230253743253230416e64726f69642532302d6c79656c6c6f772e737667"><img src="https://camo.githubusercontent.com/25c8cbe0feb4b33d8afb811cc30e8ccf30858800e21016894192addbe8184154/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d2532304c696e75782532302537432532306d61634f5325323025374325323057696e646f7773253230253743253230694f53253230253743253230416e64726f69642532302d6c79656c6c6f772e737667" alt="language" data-canonical-src="https://img.shields.io/badge/platform-%20Linux%20%7C%20macOS%20%7C%20Windows%20%7C%20iOS%20%7C%20Android%20-lyellow.svg"/></a></p>
<p dir="auto">The library is cross-platform and currently supports Linux, macOS, Windows, iOS and Android systems.</p>

<p dir="auto">To install the <strong>audioFlux</strong> package, Python &gt;=3.6, using the released python package.</p>
<p dir="auto">Using PyPI:</p>

<p dir="auto">Using Anaconda:</p>
<div data-snippet-clipboard-copy-content="$ conda install -c tanky25 -c conda-forge audioflux"><pre><code>$ conda install -c tanky25 -c conda-forge audioflux
</code></pre></div>


<ul dir="auto">
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/installing.md#ios-build">iOS build</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/installing.md#android-build">Android build</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/installing.md#building-from-source">Building from source</a></li>
</ul>

<ul dir="auto">
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#mel--mfcc">Mel &amp; MFCC</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#cwt--synchrosqueezing">CWT &amp; Synchrosqueezing</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#cqt--chroma">CQT &amp; Chroma</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#different-wavelet-type">Different Wavelet Type</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#spectral-features">Spectral Features</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#pitch-estimate">Pitch Estimate</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#onset-detection">Onset Detection</a></li>
<li><a href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/examples.md#harmonic-percussive-source-separation">Harmonic Percussive Source Separation</a></li>
</ul>
<p dir="auto">More example scripts are provided in the <a href="https://audioflux.top/" rel="nofollow">Documentation</a> section.</p>

<p dir="auto">server hardware:</p>
<div data-snippet-clipboard-copy-content="- CPU: AMD Ryzen Threadripper 3970X 32-Core Processor"><pre><code>- CPU: AMD Ryzen Threadripper 3970X 32-Core Processor
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://ntietz.com/libAudioFlux/audioFlux/blob/master/docs/image/benchmark/linux_amd_1.png"><img src="https://ntietz.com/libAudioFlux/audioFlux/raw/master/docs/image/benchmark/linux_amd_1.png" width="800"/></a></p>
<p dir="auto">More detailed performance benchmark are provided in the <a href="https://github.com/libAudioFlux/audioFlux/tree/master/benchmark">Benchmark</a> module.</p>

<p dir="auto">Documentation of the package can be found online:</p>
<p dir="auto"><a href="https://audioflux.top/" rel="nofollow">https://audioflux.top</a></p>

<p dir="auto">We are more than happy to collaborate and receive your contributions to <strong><code>audioFlux</code></strong>. If you want to contribute,
please fork the latest git repository and create a feature branch. Submitted requests should pass all continuous
integration tests.</p>
<p dir="auto">You are also more than welcome to suggest any improvements, including proposals for need help, find a bug, have a
feature request, ask a general question, new algorithms. <a href="https://github.com/libAudioFlux/audioFlux/issues/new">
Open an issue</a></p>

<p dir="auto">If you want to cite <strong><code>audioFlux</code></strong> in a scholarly work, please use the following ways:</p>
<ul dir="auto">
<li>
<p dir="auto">If you are using the library for your work, for the sake of reproducibility, please cite the version you used as
indexed at Zenodo:</p>
<p dir="auto"><a href="https://doi.org/10.5281/zenodo.7548288" rel="nofollow"><img src="https://camo.githubusercontent.com/1f081cad557bc3b49d8c1a4bf71f5e49358b5bcb9e23e47ddba7a7571fdab753/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e373534383238382e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.7548288.svg"/></a></p>
</li>
</ul>

<p dir="auto">audioFlux project is available MIT License.</p>
</article></div></div>
  </body>
</html>
