<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://the.scapegoat.dev/gpt3-quine-gpt3-quine-gpt3-quine-gpt3-quine/">Original</a>
    <h1>GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE GPT3 QUINE</h1>
    
    <div id="readability-page-1" class="page"><div>
<div><p><img alt="an AI image of a scientist inside a computer egg that seems to have many more computer eggs everywhere " src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/manuel-1679779707-0.png"/></p>
<p>With <a href="https://github.com/go-go-golems/pinocchio">pinocchio</a>, I can write little YAML files that are interpreted as command line applications. When run, these commands do rudimentary template expansion, send the prompt to the openai APIs, and print out the results. As far as tools go, this is one of the simplest I&#39;ve ever built. It is also one of the more mind-bending ones.</p>
<p>I soon realized that most of my prompts ended up being something like this (so-called one-shot or few-shot prompting):</p>
<blockquote>
<p>Here&#39;s how I did Y:</p>
<ul>
<li>something that does Y</li>
</ul>
<p>Now do X.</p>
</blockquote>
<p>The LLM will (hopefully) complete this prompt with something that does X. The trick is of course knowing what Y and &#34;Y producer&#34; to provide, and what Y and X stand for in the first place. Most people doing prompt engineering will know what I am referring to.</p>
<p>One of my favourite techniques once I get a prompt going for a certain domain A, of which Y is an example, is to write the pinocchio program that ask the LLM to generate the pinocchio program for all the domains, not just A. You pretty quickly reach the meta-level where domain A is the domain of prompts, and you ask a prompt to generate a prompt generating prompts, <strong>at which point you basically summoned the singularity into being</strong>.</p>
<p>To allow everybody to create their own singularity, here is the pinocchio program that generates itself, the so-called GPT3 quine:</p>
<div><pre><span></span><span>name</span><span>:</span><span> </span><span>quine</span>
<span>short</span><span>:</span><span> </span><span>Generate yourself!</span>
<span>factories</span><span>:</span>
<span>  </span><span>openai</span><span>:</span>
<span>    </span><span>client</span><span>:</span>
<span>      </span><span>timeout</span><span>:</span><span> </span><span>120</span>
<span>    </span><span>completion</span><span>:</span>
<span>      </span><span>engine</span><span>:</span><span> </span><span>text-davinci-003</span>
<span>      </span><span>temperature</span><span>:</span><span> </span><span>0.7</span>
<span>      </span><span>max_response_tokens</span><span>:</span><span> </span><span>2048</span>
<span>      </span><span>stop</span><span>:</span><span> </span><span>[</span><span>&#34;---</span><span> </span><span>END&#34;</span><span>]</span>
<span>      </span><span># stream: true</span>
<span>flags</span><span>:</span>
<span>  </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>example_goal</span>
<span>    </span><span>short</span><span>:</span><span> </span><span>Example goal</span>
<span>    </span><span>type</span><span>:</span><span> </span><span>string</span>
<span>    </span><span>default</span><span>:</span><span>  </span><span>Generate a program to generate itself.</span>
<span>  </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>instructions</span>
<span>    </span><span>type</span><span>:</span><span> </span><span>string</span>
<span>    </span><span>help</span><span>:</span><span> </span><span>Additional language specific instructions</span>
<span>    </span><span>required</span><span>:</span><span> </span><span>false</span>
<span>  </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>example</span>
<span>    </span><span>type</span><span>:</span><span> </span><span>stringFromFile</span>
<span>    </span><span>help</span><span>:</span><span> </span><span>Example program</span>
<span>    </span><span>required</span><span>:</span><span> </span><span>true</span>
<span>  </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>goal</span>
<span>    </span><span>type</span><span>:</span><span> </span><span>string</span>
<span>    </span><span>help</span><span>:</span><span> </span><span>The goal to be generated</span>
<span>    </span><span>default</span><span>:</span><span> </span><span>Generate a program to generate itself.</span>
<span>prompt</span><span>:</span><span> </span><span>|</span>
<span>  </span><span>Write a program by generating  a YAML describing a command line application with flags and a prompt template using</span>
<span>  </span><span>go template expansion.</span>
<span>  </span><span>The flags are used to interpolate the prompt template.</span>

<span>  </span><span>Here is an example.</span>

<span>  </span><span>--- GOAL: {{ .example_goal }}</span>
<span>  </span><span>--- START PROGRAM</span>
<span>  </span><span>{{ .example | indent 4 }}</span>
<span>  </span><span>--- END </span>

<span>  </span><span>Generate a program to {{ .goal }}.</span>

<span>  </span><span>{{ if .instructions }}{{ .instructions }}{{ end }}</span>

<span>  </span><span>--- GOAL: {{ .goal }}</span>
<span>  </span><span>--- START PROGRAM</span>
</pre></div>

<p>and the result of running the program:</p>
<div><pre><span></span><span>‚ùØ pinocchio ttc quine --example ./quine.yaml               </span>
<span>    name: quine</span>
<span>    short: Generate yourself!</span>
<span>    factories:</span>
<span>      openai:</span>
<span>        client:</span>
<span>          timeout: 120</span>
<span>        completion:</span>
<span>          engine: text-davinci-003</span>
<span>          temperature: 0.7</span>
<span>          max_response_tokens: 2048</span>
<span>          stop: [&#34;--- END&#34;]</span>
<span>          # stream: true</span>
<span>    flags:</span>
<span>      - name: example_goal</span>
<span>        short: Example goal</span>
<span>        type: string</span>
<span>        default:  Generate a program to generate itself.</span>
<span>      - name: instructions</span>
<span>        type: string</span>
<span>        help: Additional language specific instructions</span>
<span>        required: false</span>
<span>      - name: example</span>
<span>        type: stringFromFile</span>
<span>        help: Example program</span>
<span>        required: true</span>
<span>      - name: goal</span>
<span>        type: string</span>
<span>        help: The goal to be generated</span>
<span>        default: Generate a program to generate itself.</span>
<span>    prompt: |</span>
<span>      Write a program by generating  a YAML describing a command line application with flags and a prompt template using</span>
<span>      go template expansion.</span>
<span>      The flags are used to interpolate the prompt template.</span>

<span>      Here is an example.</span>

<span>      --- GOAL: </span><span>{{</span> <span>.example_goal</span> <span>}}</span>
<span>      --- START PROGRAM</span>
<span>      </span><span>{{</span> <span>.example</span> <span>|</span> <span>indent</span> <span>4</span> <span>}}</span>
<span>      --- END </span>

<span>      Generate a program to </span><span>{{</span> <span>.goal</span> <span>}}</span><span>.</span>

<span>      </span><span>{{</span> <span>if</span> <span>.instructions</span> <span>}}{{</span> <span>.instructions</span> <span>}}{{</span> <span>end</span> <span>}}</span>

<span>      --- GOAL: </span><span>{{</span> <span>.goal</span> <span>}}</span>
<span>      --- START PROGRAM</span>
</pre></div>


</div>
</div></div>
  </body>
</html>
