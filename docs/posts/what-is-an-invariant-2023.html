<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://matklad.github.io/2023/10/06/what-is-an-invariant.html">Original</a>
    <h1>What is an invariant? (2023)</h1>
    
    <div id="readability-page-1" class="page"><div>
  <article>


<p><span>I extolled the benefits of programming with invariants in a couple of recent posts.</span>
<span>Naturally, I didn</span>’<span>t explain what I think when I write </span>“<span>invariant</span>”<span>. This post fixes that.</span></p>
<p><span>There are at least three different concepts I label with </span>“<span>invariant</span>”<span>:</span></p>
<ul>
<li>
<span>a general </span>“<span>math</span>”<span> mode of thinking, where you distinguish between fuzzy, imprecise thoughts and</span>
<span>precise statements with logical meaning.</span>
</li>
<li>
<span>a specific technique for writing correct code when programming in the small.</span>
</li>
<li>
<span>when programming in the large, compact, viral, descriptive properties of the systems.</span>
</li>
</ul>
<p><span>I wouldn</span>’<span>t discuss the first point here </span>—<span> I don</span>’<span>t know how to describe this better than </span>“<span>that</span>
<span>thing that you do when you solve non-trivial math puzzler</span>”<span>. The bulk of the post describes the</span>
<span>second bullet point, for which I think I have a perfect litmus test to explain exactly what I am</span>
<span>thinking here. I also touch a bit on the last point in the end.</span></p>
<p><span>So let</span>’<span>s start with a </span><a href="https://research.swtch.com/hwmm"><span>litmus test program</span></a><span> to show invariants in</span>
<span>the small in action:</span></p>


  <p><span>You might want to write one yourself before proceeding. Here</span>’<span>s an </span><a href="https://matklad.github.io/2021/11/07/generate-all-the-things.html"><span>exhaustive</span>
<span>test</span></a><span> for this functionality,</span>
<span>using </span><a href="https://crates.io/crates/exhaustigen"><span>exhaustigen crate</span></a><span>:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>main</span>() {</span>
<span>  <span>let</span> <span>N</span> = <span>5</span>;</span>
<span>  <span>let</span> <span>M</span> = <span>5</span>;</span>
<span></span>
<span>  <span>let</span> <span>mut </span><span>g</span> = exhaustigen::Gen::<span>new</span>();</span>
<span>  <span>while</span> !g.<span>done</span>() {</span>
<span>    </span>
<span>    <span>let</span> <span>mut </span><span>xs</span> =</span>
<span>      (<span>0</span>..g.<span>gen</span>(N)).<span>map</span>(|_| g.<span>gen</span>(M) <span>as</span> <span>i32</span>).collect::&lt;<span>Vec</span>&lt;_&gt;&gt;();</span>
<span>    xs.<span>sort</span>();</span>
<span></span>
<span>    <span>let</span> <span>x</span> = g.<span>gen</span>(M) <span>as</span> <span>i32</span>;</span>
<span></span>
<span>    <span>let</span> <span>i</span> = <span>insertion_point</span>(&amp;xs, x);</span>
<span>    <span>if</span> i &gt; <span>0</span>        { <span>assert!</span>(xs[i - <span>1</span>] &lt; x) }</span>
<span>    <span>if</span> i &lt; xs.<span>len</span>() { <span>assert!</span>(x &lt;= xs[i]) }</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
<p><span>Here</span>’<span>s how I would naively write this function. First, I start with defining the boundaries for the</span>
<span>binary search:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>insertion_point</span>(xs: &amp;[<span>i32</span>], x: <span>i32</span>) <span>-&gt;</span> <span>usize</span> {</span>
<span>    <span>let</span> <span>mut </span><span>lo</span> = <span>0</span>;</span>
<span>    <span>let</span> <span>mut </span><span>hi</span> = xs.<span>len</span>();</span>
<span>    ...</span>
<span>}</span></code></pre>

</figure>
<p><span>Then, repeatedly cut the interval in half until it vanishes</span></p>

<figure>


<pre><code><span>    <span>while</span> hi &gt; lo {</span>
<span>        <span>let</span> <span>mid</span> = lo + (hi - lo) / <span>2</span>;</span>
<span>        ...</span>
<span>    }</span></code></pre>

</figure>
<p><span>and recur into the left or the right half accordingly:</span></p>

<figure>


<pre><code><span>        <span>if</span> x &lt; xs[mid] {</span>
<span>            lo = mid;</span>
<span>        } <span>else</span> {</span>
<span>            hi = mid;</span>
<span>        }</span></code></pre>

</figure>
<p><span>Altogether:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>insertion_point</span>(xs: &amp;[<span>i32</span>], x: <span>i32</span>) <span>-&gt;</span> <span>usize</span> {</span>
<span>  <span>let</span> <span>mut </span><span>lo</span> = <span>0</span>;</span>
<span>  <span>let</span> <span>mut </span><span>hi</span> = xs.<span>len</span>();</span>
<span></span>
<span>  <span>while</span> lo &lt; hi {</span>
<span>    <span>let</span> <span>mid</span> = lo + (hi - lo) / <span>2</span>;</span>
<span>    <span>if</span> x &lt; xs[mid] {</span>
<span>      hi = mid;</span>
<span>    } <span>else</span> {</span>
<span>      lo = mid;</span>
<span>    }</span>
<span>  }</span>
<span></span>
<span>  lo</span>
<span>}</span></code></pre>

</figure>
<p><span>I love this code! It has so many details right!</span></p>
<ul>
<li>
<span>The </span><code>insertion_point</code><span> interface compactly compresses usually messy result of a binary search to</span>
<span>just one index.</span>
</li>
<li>
<code>xs / x</code><span> pair of names for the sequence and its element crisply describes abstract algorithm on</span>
<span>sequencies.</span>
</li>
<li>
<span>Similarly, </span><code>lo / hi</code><span> name pair is symmetric, expressing the relation between the two indexes.</span>
</li>
<li>
<span>Half-open intervals are used for indexing.</span>
</li>
<li>
<span>There are no special casing anywhere, the natural </span><code>lo &lt; hi</code><span> condition handles empty slice.</span>
</li>
<li>
<span>We even dodge Java</span>’<span>s binary search bug by computing midpoint without overflow.</span>
</li>
</ul>
<p><span>There</span>’<span>s only one problem with this code </span>—<span> it doesn</span>’<span>t work. Just blindly following rules-of-thumb</span>
<span>gives you working code surprisingly often, but this particular algorithm is an exception.</span></p>
<p><span>The question is, how do we fix this overwise great code? And here</span>’<span>s where thinking invariants helps.</span>
<span>Before I internalized invariants, my approach would be to find a failing example, and to fumble with</span>
<span>some plus or minus ones here and there and other special casing to make it work. That is, find a</span>
<span>concrete problem, solve it. This works, but is slow, and doesn</span>’<span>t allow discovering the problem</span>
<span>before running the code.</span></p>
<p><span>The alternative is to actually make an effort and spell out, explicitly, what the code is supposed</span>
<span>to do. In this case, we want </span><code>lo</code><span> and </span><code>hi</code><span> to bound the result. That is,</span>
<code>lo &lt;= insertion_point &lt;= hi</code>
<span>should hold on every iteration. It clearly holds before we enter the loop. On each iteration, we</span>
<span>would like to shorten this interval, cutting away the part that definitely does not contain</span>
<span>insertion point.</span></p>
<p><span>Elaborating the invariant, all elements to the left of </span><code>lo</code><span> should be less than the target.</span>
<span>Conversely, all elements to the right of </span><code>hi</code><span> should be at least as large as the target.</span></p>

<figure>


<pre><code><span><span>for</span> <span>i</span> <span>in</span> <span>0</span>..lo: xs[i] &lt; x</span>
<span><span>for</span> <span>i</span> <span>in</span> hi..:  x &lt;= xs[i]</span></code></pre>

</figure>
<p><span>Let</span>’<span>s now take a second look at the branching condition:</span></p>

<figure>


<pre><code><span>x &lt; xs[mid]</span></code></pre>

</figure>
<p><span>It matches neither invariant prong exactly: </span><code>x</code><span> is on the left, but inequality is strict. We can</span>
<span>rearrange the code to follow the invariant more closely:</span></p>

<figure>


<pre><code><span><span>if</span> xs[mid] &lt; x {</span>
<span>    lo = mid + <span>1</span>;</span>
<span>} <span>else</span> {</span>
<span>    hi = mid;</span>
<span>}</span></code></pre>

</figure>
<ul>
<li>
<span>we flip the condition and if-branches, so that </span><code>xs[mid] &lt; x</code><span> matches </span><code>xs[i] &lt; x</code><span> from the</span>
<span>invariant for </span><code>lo</code>
</li>
<li>
<span>to make the invariant tight, we add </span><code>mid + 1</code><span> (if </span><code>xs[mid]</code><span> is less than </span><code>x</code><span>, we know that the</span>
<span>insertion point is at least </span><code>mid + 1</code><span>)</span>
</li>
</ul>
<p><span>The code now works. So what went wrong with the original version with </span><code>x &lt; xs[mid]</code><span>? In the else</span>
<span>case, when </span><code>x &gt;= xs[mid]</code><span> we set </span><code>lo = mid</code><span>, but that</span>’<span>s wrong! It might be the case that </span><code>x ==
xs[mid]</code><span> and </span><code>x == xs[mid - 1]</code><span>, which would break the invariant for </span><code>lo</code><span>.</span></p>
<p><span>The point isn</span>’<span>t in this </span><em><span>particular</span></em><span> invariant or this particular algorithm. It</span>’<span>s the general</span>
<span>pattern that  it</span>’<span>s easy to write the code which implements the right algorithm, and sort-of works,</span>
<span>but is wrong in details. To get the details right for the right reason, you need to understand</span>
<em><span>precisely</span></em><span> what the result should be, and formulating this as a (loop or recursion) invariant</span>
<span>helps.</span></p>
<hr/>
<p><span>Perhaps it</span>’<span>s time to answer the title question: invariant is some property which holds at all times</span>
<span>during dynamic evolution of the system. In the above example, the evolution is the program</span>
<span>progressing through subsequent loop iterations. The invariant, the condition binding </span><code>lo</code><span> and </span><code>hi</code><span>,</span>
<span>holds on every iteration. Invariants are powerful, because they are </span><em><span>compressed</span></em><span> descriptions of</span>
<span>the system, they collapse away the time dimension, which is a huge simplification. Reasoning about</span>
<span>each particular path the program could take is hard, because there are so many different paths.</span>
<span>Reasoning about invariants is easy, because they capture properties shared by </span><em><span>all</span></em><span> execution paths.</span></p>
<p><span>The same idea applies when programming in the large. In the small, we looked at how the state of a</span>
<span>running program evolves over time. In the large, we will look at how the source code of the program</span>
<span>itself evolves, as it is being refactored and extended to support new features. Here are some</span>
<span>systems invariants from the systems I</span>’<span>ve worked with:</span></p>
<p><strong><span>Cargo:</span></strong></p>
<p><span>File system paths entered by users are preserved exactly. If the user types</span>
<span><code>cargo frob ../some/dir</code><span>,</span></span>
<span>Cargo doesn</span>’<span>t attempt to resolve </span><code>../some/dir</code><span> to an absolute path and passes the path</span>
<span>to the underlying OS as is. The reason for that is that file systems are very finicky. Although it</span>
<span>might look as if two paths are equivalent, there are bound to be cases where they are not. If the</span>
<span>user typed a particular form of a path, they believe that it</span>’<span>ll work, and any changes can mess</span>
<span>things up easily.</span></p>
<p><span>This is a relatively compact invariant </span>—<span> basically, code is just forbidden from calling</span>
<code>fs::canonicalize</code><span>.</span></p>
<p><strong><span>rust-analyzer:</span></strong></p>
<p><span>Syntax trees are identity-less value types. That is, if you take an object representing an </span><code>if</code>
<span>expression, that object doesn</span>’<span>t have any knowledge of where in the larger program the </span><code>if</code>
<span>expression is. The thinking about this invariant was that it simplifies refactors </span>—<span> while in the</span>
<span>static program it</span>’<span>s natural to talk about </span>“<code>if</code><span> on the line X in file Y</span>”<span>, when you start modifying</span>
<span>code, identity becomes much more fluid.</span></p>
<p><span>This is an invariant with far reaching consequences </span>—<span> that means that literally everything in</span>
<span>rust-analyzer needs to track identities of things explicitly. You don</span>’<span>t just pass around syntax</span>
<span>nodes, you pass nodes with extra breadcrumbs describing their origin. I think this might have been a</span>
<span>mistake </span>—<span> while it does make refactoring APIs more principled, refactoring is not the common case!</span>
<span>Most of the work of a language server consists of read-only analysis of existing code, and the</span>
<span>actual refactor is just a cherry on top. So perhaps it</span>’<span>s better to try to bind identity mode tightly</span>
<span>into the core data structure, and just use fake identities for temporary trees that arise during</span>
<span>refactors.</span></p>
<p><span>A more successful invariant from rust-analyzer is that the IDE has a full, frozen view of a snapshot</span>
<span>of the world. There</span>’<span>s no API for inferring the types, rather, the API looks as if all the types are</span>
<span>computed at all times. Similarly, there</span>’<span>s no explicit API for changing the code or talking about</span>
<span>different historical versions of the code </span>—<span> the IDE sees a single </span>“<span>current</span>”<span> snapshot with all</span>
<span>derived data computed. Underneath, there</span>’<span>s a smart system to secretly compute the information on</span>
<span>demand and re-use previous results, but this is all hidden from the API.</span></p>
<p><span>This is a great, simple mental model, and it provides for a nice boundary between the compiler</span>
<span>proper and IDE fluff like refactors and code completion. Long term, I</span>’<span>d love to see several</span>
<span>implementations of the </span>“<span>compiler parts</span>”<span>.</span></p>
<p><strong><span>TigerBeetle:</span></strong></p>
<p><span>A </span><em><span>lot</span></em><span> of thoughtful invariants here! To touch only a few:</span></p>
<p><span>TigerBeetle doesn</span>’<span>t allocate memory after startup. This simple invariant affects every bit of code</span>
—<span> whatever you do, you must manage with existing, pre-allocated data structures. You can</span>’<span>t just</span>
<code>memcpy</code><span> stuff around, there</span>’<span>s no ambient available space to </span><code>memcpy</code><span> to! As a consequence (and,</span>
<span>historically, as a motivation for the design)</span>
<a href="https://github.com/tigerbeetle/tigerbeetle/blob/cfb46eff4e001bb6b33f5e48924a2de44db20e8f/src/constants.zig#L417-L418"><span>everything</span></a>
<span>has a specific numeric limit.</span></p>
<p><span>Another fun one is that transaction logic can</span>’<span>t read from disk. Every object which could be touched</span>
<span>by a transaction needs to be explicitly prefetched into memory before transaction begins. Because</span>
<span>disk IO happens separately from the execution, it is possible to parallelize IO for a whole batch of</span>
<span>transactions. The actual transaction execution is then a very tight serial CPU loop without any</span>
<span>locks.</span></p>
<p><span>Speaking of disk IO, in TigerBeetle </span>“<span>reading from disk</span>”<span> can</span>’<span>t fail. The central API for reading</span>
<span>takes a data block address, a checksum, and invokes the callback with data with a matching checksum.</span>
<span>Everything built on top doesn</span>’<span>t need to worry about error handling. The way this works internally is</span>
<span>that reads that fail on a local disk are repaired through other replicas in the cluster. It</span>’<span>s just</span>
<span>that the repair happens transparently to the caller. If the block of data of interest isn</span>’<span>t found on</span>
<span>the set of reachable replicas, the cluster correctly gets stuck until it is found.</span></p>
<hr/>
<p><span>Summing up: invariants are helpful for describing systems that evolve over time. There</span>’<span>s a</span>
<span>combinatorial explosion of trajectories that a system </span><em><span>could</span></em><span> take. Invariants compactly describe</span>
<span>properties shared by an infinite amount of trajectories.</span></p>
<p><span>In the small, formulating invariants about program state helps to wire correct code.</span></p>
<p><span>In the large, formulating invariants about the code itself helps to go from a small, simple system</span>
<span>that works to a large system which is used in production.</span></p>
</article>
  </div></div>
  </body>
</html>
