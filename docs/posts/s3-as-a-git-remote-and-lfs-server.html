<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/awslabs/git-remote-s3">Original</a>
    <h1>S3 as a Git remote and LFS server</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">This library enables to use Amazon S3 as a git remote and LFS server.</p>
<p dir="auto">It provides an implementation of a <a href="https://git-scm.com/docs/gitremote-helpers" rel="nofollow">git remote helper</a> to use S3 as a serverless Git server.</p>
<p dir="auto">It also provide an implementation of the <a href="https://github.com/git-lfs/git-lfs/blob/main/docs/custom-transfers.md">git-lfs custom transfer</a> to enable pushing LFS managed files to the same S3 bucket used as remote.</p>

<p dir="auto"><code>git-remote-s3</code> is a Python script and works with any Python version &gt;= 3.9.</p>
<p dir="auto">Run:</p>
<div data-snippet-clipboard-copy-content="pip install git-remote-s3"><pre><code>pip install git-remote-s3
</code></pre></div>

<p dir="auto">Before you can use <code>git-remote-s3</code>, you must:</p>
<ul dir="auto">
<li>
<p dir="auto">Complete initial configuration:</p>
<ul dir="auto">
<li>Creating an AWS account</li>
<li>Configuring an IAM user or role</li>
</ul>
</li>
<li>
<p dir="auto">Create an AWS S3 bucket (or have one already) in your AWS account.</p>
</li>
<li>
<p dir="auto">Attach a minimal policy to that user/role that allows the to the S3 bucket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &#34;Sid&#34;: &#34;S3Access&#34;,
  &#34;Effect&#34;: &#34;Allow&#34;,
  &#34;Action&#34;: [&#34;s3:PutObject&#34;, &#34;s3:GetObject&#34;, &#34;s3:ListBucket&#34;],
  &#34;Resource&#34;: [&#34;arn:aws:s3:::&lt;BUCKET&gt;&#34;, &#34;arn:aws:s3:::*/*&#34;]
}"><pre>{
  <span>&#34;Sid&#34;</span>: <span><span>&#34;</span>S3Access<span>&#34;</span></span>,
  <span>&#34;Effect&#34;</span>: <span><span>&#34;</span>Allow<span>&#34;</span></span>,
  <span>&#34;Action&#34;</span>: [<span><span>&#34;</span>s3:PutObject<span>&#34;</span></span>, <span><span>&#34;</span>s3:GetObject<span>&#34;</span></span>, <span><span>&#34;</span>s3:ListBucket<span>&#34;</span></span>],
  <span>&#34;Resource&#34;</span>: [<span><span>&#34;</span>arn:aws:s3:::&lt;BUCKET&gt;<span>&#34;</span></span>, <span><span>&#34;</span>arn:aws:s3:::*/*<span>&#34;</span></span>]
}</pre></div>
</li>
<li>
<p dir="auto">Optional (but recommended) - use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">SSE-KMS Bucket keys to encrypt the content of the bucket</a>, ensure the user/role create previously has the permission to access and use the key.</p>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &#34;Sid&#34;: &#34;KMSAccess&#34;,
  &#34;Effect&#34;: &#34;Allow&#34;,
  &#34;Action&#34;: [&#34;kms:Decrypt&#34;, &#34;kms:GenerateDataKey&#34;],
  &#34;Resource&#34;: [&#34;arn:aws:kms:&lt;REGION&gt;:&lt;ACCOUNT&gt;:key/&lt;KEY_ID&gt;&#34;]
}"><pre>{
  <span>&#34;Sid&#34;</span>: <span><span>&#34;</span>KMSAccess<span>&#34;</span></span>,
  <span>&#34;Effect&#34;</span>: <span><span>&#34;</span>Allow<span>&#34;</span></span>,
  <span>&#34;Action&#34;</span>: [<span><span>&#34;</span>kms:Decrypt<span>&#34;</span></span>, <span><span>&#34;</span>kms:GenerateDataKey<span>&#34;</span></span>],
  <span>&#34;Resource&#34;</span>: [<span><span>&#34;</span>arn:aws:kms:&lt;REGION&gt;:&lt;ACCOUNT&gt;:key/&lt;KEY_ID&gt;<span>&#34;</span></span>]
}</pre></div>
<ul dir="auto">
<li>Install Python and its package manager, pip, if they are not already installed. To download and install the latest version of Python, <a href="https://www.python.org/" rel="nofollow">visit the Python website</a>.</li>
<li>Install Git on your Linux, macOS, Windows, or Unix computer.</li>
<li>Install the latest version of the AWS CLI on your Linux, macOS, Windows, or Unix computer. You can find instructions <a href="https://docs.aws.amazon.com/cli/latest/userguide/installing.html" rel="nofollow">here</a>.</li>
</ul>


<p dir="auto">All data is encrypted at rest and in transit by default. To add an additional layer of security you can use customer managed KMS keys to encrypt the data at rest on the S3 bucket. We recommend to use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">Bucket keys</a> to minimize the KMS costs.</p>

<p dir="auto">Access control to the remote is ensured via IAM permissions, and can be controlled at:</p>
<ul dir="auto">
<li>bucket level</li>
<li>prefix level (you can use prefixes to store multiple repos in the same S3 bucket thus minimizing the setup effort)</li>
<li>KMS key level</li>
</ul>


<p dir="auto">S3 remotes are identified by the prefix <code>s3://</code> and at the bare minimum specify the name of the bucket. You can also provide a key prefix as in <code>s3://my-git-bucket/my-repo</code> and a profile <code>s3://my-profile@my-git-bucket/myrepo</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir my-repo
cd my-repo
git init
git remote add origin s3://my-git-bucket/my-repo"><pre>mkdir my-repo
<span>cd</span> my-repo
git init
git remote add origin s3://my-git-bucket/my-repo</pre></div>
<p dir="auto">You can then add a file, commit and push the changes to the remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &#34;Hello&#34; &gt; hello.txt
git add -A
git commit -a -m &#34;hello&#34;
git push --set-upstream origin main"><pre><span>echo</span> <span><span>&#34;</span>Hello<span>&#34;</span></span> <span>&gt;</span> hello.txt
git add -A
git commit -a -m <span><span>&#34;</span>hello<span>&#34;</span></span>
git push --set-upstream origin main</pre></div>
<p dir="auto">The remote HEAD is set to track the branch that has been pushed first to the remote repo. To change the remote HEAD branch, delete the HEAD object <code>s3://&lt;bucket&gt;/&lt;prefix&gt;/HEAD</code> and then run <code>git-remote-s3 doctor s3://&lt;bucket&gt;/&lt;prefix&gt;</code>.</p>

<p dir="auto">To clone the repo to another folder just use the normal git syntax using the s3 URI as remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone s3://my-git-bucket/my-repo my-repo-clone"><pre>git clone s3://my-git-bucket/my-repo my-repo-clone</pre></div>

<p dir="auto">Creating branches and pushing them works as normal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m &#34;new file&#34;
git push origin new_branch"><pre><span>cd</span> my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m <span><span>&#34;</span>new file<span>&#34;</span></span>
git push origin new_branch</pre></div>
<p dir="auto">All git operations that do not rely on communication with the server should work as usual (eg <code>git merge</code>)</p>

<p dir="auto">To use LFS you need to first install git-lfs. You can refer to the [official documentation]((<a href="https://git-lfs.com/" rel="nofollow">https://git-lfs.com/</a>) on how to do this on your system.</p>
<p dir="auto">Next, you need enable the S3 integration by running the following command in the repo folder:</p>

<p dir="auto">which is a short cut for:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py"><pre>git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py</pre></div>

<div dir="auto"><h3 tabindex="-1" dir="auto">Creating the repo and pushing</h3><a id="user-content-creating-the-repo-and-pushing" aria-label="Permalink: Creating the repo and pushing" href="#creating-the-repo-and-pushing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Let&#39;s assume we want to store TIFF file in LFS.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir lfs-repo
cd lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track &#34;*.tiff&#34;
git add .gitattributes
&lt;put file.tiff in the repo&gt;
git add file.tiff
git commit -a -m &#34;my first tiff file&#34;
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main"><pre>mkdir lfs-repo
<span>cd</span> lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track <span><span>&#34;</span>*.tiff<span>&#34;</span></span>
git add .gitattributes
<span>&lt;</span>put file.tiff <span>in</span> the repo<span>&gt;</span>
git add file.tiff
git commit -a -m <span><span>&#34;</span>my first tiff file<span>&#34;</span></span>
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Notes about specific behaviors of Amazon S3 remotes</h2><a id="user-content-notes-about-specific-behaviors-of-amazon-s3-remotes" aria-label="Permalink: Notes about specific behaviors of Amazon S3 remotes" href="#notes-about-specific-behaviors-of-amazon-s3-remotes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">An Amazon S3 URI for an valid bucket and an arbitrary prefix which does not contain the right structure under it, is considered valid.</p>
<p dir="auto"><code>git ls-remote</code> returns an empty list and <code>git clone</code> clones an empty repository for which the S3 URI is set as remote origin.</p>
<div data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into &#39;this-is-a-new-repo&#39;...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)"><pre><code>% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into &#39;this-is-a-new-repo&#39;...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)
</code></pre></div>
<p dir="auto"><strong>Tip</strong>: This behavior can be used to quickly create a new git repo.</p>

<p dir="auto">Due to the distributed nature of <code>git</code>, there might be cases (albeit rare) where 2 or more <code>git push</code> are executed at the same time by different user with their own modification of the same branch.</p>
<p dir="auto">The git command executes the push in 2 steps:</p>
<ol dir="auto">
<li>first it checks if the remote reference is the correct ancestor for the commit being pushed</li>
<li>if that is correct it invokes the <code>git-remote-s3</code> command which writes the bundle to the S3 bucket at the <code>refs/heads/&lt;branch&gt;</code> path</li>
</ol>
<p dir="auto">In case two (or more) <code>git push</code> command are executed at the same time from different clients, at step 1 the same valid ref is fetched, hence both clients proceed with step 2, resulting in multiple bundles being stored in S3.</p>
<p dir="auto">The branch has now multiple head references, and any subsequent <code>git push</code> fails with the error:</p>
<div data-snippet-clipboard-copy-content="error: dst refspec refs/heads/&lt;branch&gt;&gt; matches more than one
error: failed to push some refs to &#39;s3://&lt;bucket&gt;/&lt;prefix&gt;&#39;"><pre><code>error: dst refspec refs/heads/&lt;branch&gt;&gt; matches more than one
error: failed to push some refs to &#39;s3://&lt;bucket&gt;/&lt;prefix&gt;&#39;
</code></pre></div>
<p dir="auto">To fix this issue, run the <code>git-remote-s3 doctor &lt;s3-uri&gt;</code> command. By default it will create a new branch for every bundle that should not be retained. The user can then checkout the branch locally and merge it to the original branch. If you want instead to remove the bundle, specify <code>--delete-bundle</code>.</p>

<p dir="auto">When cloning a repo using the S3 remote for LFS, <code>git-lfs</code> can&#39;t know how to fetch the files since we have yet to add the configuration.</p>
<p dir="auto">It involves 2 extra steps.</p>
<div dir="auto" data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: exit status 255
..."><pre>% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: <span>exit</span> status 255
...</pre></div>
<p dir="auto">To fix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd lfs-repo-clone
lfs-s3-py install
git reset --hard main"><pre><span>cd</span> lfs-repo-clone
lfs-s3-py install
git reset --hard main</pre></div>


<p dir="auto">To remove remote branches that are not used anymore you can use the <code>git-s3 delete-branch &lt;s3uri&gt; -b &lt;branch_name&gt;</code> command. This command deletes the bundle object(s) from Amazon S3 under the branch path.</p>

<p dir="auto">To protect/unprotect a branch run <code>git s3 protect &lt;remote&gt; &lt;branch-name&gt;</code> respectively <code>git s3 unprotect &lt;remote&gt; &lt;branch-name&gt;</code>.</p>


<p dir="auto">Bundles are stored in the S3 bucket as <code>&lt;prefix&gt;/&lt;ref&gt;/&lt;sha&gt;.bundle</code>.</p>
<p dir="auto">When listing remote ref (eg explicitly via <code>git ls-remote</code>) we list all the keys present under the given .</p>
<p dir="auto">When pushing a new ref (eg a commit), we get the sha of the ref, we bundle the ref via <code>git bundle create &lt;sha&gt;.bundle &lt;ref&gt;</code> and store it to S3 according the schema above.</p>
<p dir="auto">If the push is successful, the code removes the previous bundle associated to the ref.</p>
<p dir="auto">If two user concurrently push a commit based on the same current branch head to the remote both bundles would be written to the repo and the current bundle removed. No data is lost, but no further push will be possible until all bundles but one are removed.
For this you can use the <code>git s3 doctor &lt;remote&gt;</code> command.</p>

<p dir="auto">The LFS integration stores the file in the bucket defined by the remote URI, under a key <code>&lt;prefix&gt;/lfs/&lt;oid&gt;</code>, where oid is the unique identifier assigned by git-lfs to the file.</p>
<p dir="auto">If an object with the same key already exists, git-lfs-s3 does not upload it again.</p>

<p dir="auto">Use <code>--verbose</code> flag to print some debug information when performing git operations. Logs will be put to stderr.</p>
<p dir="auto">For LFS operations you can enable and disable debug logging via <code>git-lfs-s3 enable-debug</code> and <code>git-lfs-s3 disable-debug</code> respectively. Logs are put in <code>.git/lfs/tmp/git-lfs-s3.log</code> in the repo.</p>

<p dir="auto">The git S3 integration was inspired by the work of Bryan Gahagan on <a href="https://github.com/bgahagan/git-remote-s3">git-remote-s3</a>.</p>
<p dir="auto">The LFS implementation benefitted from <a href="https://github.com/nicolas-graves/lfs-s3">lfs-s3</a> by <a href="https://github.com/nicolas-graves">@nicolas-graves</a>. If you do not need to use the git-remote-s3 transport you are should use that project.</p>
</article></div></div>
  </body>
</html>
