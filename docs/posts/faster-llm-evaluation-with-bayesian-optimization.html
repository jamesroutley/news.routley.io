<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/rentruewang/bocoel">Original</a>
    <h1>Show HN: Faster LLM evaluation with Bayesian optimization</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<h2 tabindex="-1" dir="auto"><a id="user-content-bayesian-optimization-as-a-coverage-tool-for-evaluating-large-language-models" aria-hidden="true" tabindex="-1" href="#bayesian-optimization-as-a-coverage-tool-for-evaluating-large-language-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Bayesian Optimization as a Coverage Tool for Evaluating Large Language Models</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rentruewang/bocoel/blob/main/assets/logo-full.svg"><img src="https://github.com/rentruewang/bocoel/raw/main/assets/logo-full.svg" alt="Logo"/></a></p>
<p dir="auto"><a href="https://github.com/rentruewang/bocoel/actions/workflows/release.yaml"><img src="https://github.com/rentruewang/bocoel/actions/workflows/release.yaml/badge.svg" alt="Publish"/></a>
<a href="https://github.com/rentruewang/bocoel/actions/workflows/build.yaml"><img src="https://github.com/rentruewang/bocoel/actions/workflows/build.yaml/badge.svg" alt="Build Pages"/></a>
<a href="https://github.com/rentruewang/bocoel/actions/workflows/format.yaml"><img src="https://github.com/rentruewang/bocoel/actions/workflows/format.yaml/badge.svg" alt="Formatting"/></a>
<a href="https://github.com/rentruewang/bocoel/actions/workflows/typecheck.yaml"><img src="https://github.com/rentruewang/bocoel/actions/workflows/typecheck.yaml/badge.svg" alt="Type Checking"/></a>
<a href="https://github.com/rentruewang/bocoel/actions/workflows/unittest.yaml"><img src="https://github.com/rentruewang/bocoel/actions/workflows/unittest.yaml/badge.svg" alt="Unit Testing"/></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/89cd2a83ed7bcb995067a12daf222e823d89b9ed30382eb08ae2ad55276597ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f72656e7472756577616e672f626f636f656c"><img src="https://camo.githubusercontent.com/89cd2a83ed7bcb995067a12daf222e823d89b9ed30382eb08ae2ad55276597ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f72656e7472756577616e672f626f636f656c" alt="GitHub License" data-canonical-src="https://img.shields.io/github/license/rentruewang/bocoel"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/97815b129861e23d0df267399e0002fe0dff4b3193440b14db8653e00adb5779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302d626c7565"><img src="https://camo.githubusercontent.com/97815b129861e23d0df267399e0002fe0dff4b3193440b14db8653e00adb5779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302d626c7565" alt="Python 3.10" data-canonical-src="https://img.shields.io/badge/python-3.10-blue"/></a>
<a href="https://squidfunk.github.io/mkdocs-material/" rel="nofollow"><img src="https://camo.githubusercontent.com/2d2df95a82d6c83f3a9152eb7b9c936b9fedfe049c08167d4e12fca5df712733/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d6174657269616c5f666f725f4d6b446f63732d3532364346453f7374796c653d666f722d7468652d6261646765266c6f676f3d4d6174657269616c466f724d6b446f6373266c6f676f436f6c6f723d7768697465" alt="Built with Material for MkDocs" data-canonical-src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?style=for-the-badge&amp;logo=MaterialForMkDocs&amp;logoColor=white"/></a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content--why-bocoel" aria-hidden="true" tabindex="-1" href="#-why-bocoel"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸ¤” Why BoCoEL?</h2>
<p dir="auto">Large language models are expensive and slow behemoths, and evaluating them on gigantic modern datasets only makes it worse.</p>
<p dir="auto">If only there is a way to just select a meaningful (<em>and small</em>) subset of the corpus and obtain a highly accurate evaluation.....</p>
<p dir="auto">Wait, sounds like <a href="#bo">Bayesian Optimization</a>!</p>
<p dir="auto">Bocoel works in the following steps:</p>
<ol dir="auto">
<li>Encode individual entry into embeddings (way cheaper / faster than LLM and reusable).</li>
<li>Use Bayesian optimization to select queries to evaluate.</li>
<li>Use the queries to retrieve from our corpus (with the encoded embeddings).</li>
<li>Profit.</li>
</ol>
<p dir="auto">The evaluations generated are easily managed by the provided manager utility.</p>
<p dir="auto">To our knowledge, this is the first work aiming to reduce computation costs during evaluation (benchmarking) with a (possibly dynamic) budget.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content--features" aria-hidden="true" tabindex="-1" href="#-features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸš€ Features</h2>
<ul dir="auto">
<li>ğŸ¯ Accurately evaluate large language models with just tens of samples from your selected corpus.</li>
<li>ğŸ’‚â€â™‚ï¸ Uses the power of Bayesian optimization to select an optimal set of samples for language model to evaluate.</li>
<li>ğŸ’¯ Evalutes the corpus on the model in addition to evaluating the model on corpus.</li>
<li>ğŸ¤— Support for <code>GPT2</code>, <code>Pythia</code>, <code>LLAMA</code> and more through integration with huggingface <a href="https://huggingface.co/docs/transformers/en/index" rel="nofollow">transformers</a> and <a href="https://huggingface.co/docs/datasets/en/index" rel="nofollow">datasets</a></li>
<li>ğŸ§© Modular design.</li>
<li>ğŸ” Efficient representation of the corpus / dataset such as N-sphere representation or whitening of the latent space to agument evaluation quality.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content--give-us-a-star" aria-hidden="true" tabindex="-1" href="#-give-us-a-star"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>â­ Give us a star!</h2>
<p dir="auto">Like what you see? Please consider giving this a star (â˜…)!</p>
<h2 tabindex="-1" dir="auto"><a id="user-content--ï¸-bayesian-optimization" aria-hidden="true" tabindex="-1" href="#-ï¸-bayesian-optimization"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a id="user-content-bo"></a> â™¾ï¸ Bayesian Optimization</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d2dc6433e129869f91fc84f5e4b19daace2bf99722f23266fc064ddbf7f012c5/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30322f47705061724261796573416e696d6174696f6e536d616c6c2e676966"><img src="https://camo.githubusercontent.com/d2dc6433e129869f91fc84f5e4b19daace2bf99722f23266fc064ddbf7f012c5/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30322f47705061724261796573416e696d6174696f6e536d616c6c2e676966" width="30%" data-animated-image="" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif"/></a></p>
<p dir="auto">Simply put, Bayesian optimization aims to optimize either the exploration objective (the purple area in the image) or the exploitation object (the height of the black dots). It uses Gaussian processes as a backbone for inference, and uses an <strong>acquisition function</strong> to decide where to sample next. See <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" rel="nofollow">here</a> for an a more in-depth introduction.</p>
<p dir="auto">Since <em>Bayesian optimization works well with expensive-to-evaluate black-box model (paraphrase: LLM)</em>, it is perfect for this particular use case. Bocoel uses Bayesian optimization as a backbone for exploring the embedding space given by our corpus, which allows it to select a good subset acting as a mini snapshot of the corpus.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-ï¸-performance-implications" aria-hidden="true" tabindex="-1" href="#ï¸-performance-implications"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸï¸ Performance Implications</h2>
<p dir="auto">LLMs are painfully slow, especially generative ones (which is what is usually referred to as LLM), since sequence generation is sequential by nature.</p>
<p dir="auto">Despite <code>bocoel</code>&#39;s requirement to use an embedder to encode the entire corpus, embedders are faster than LLMs by orders of magnitude and the time is gained back by practically any savings in evaluating LLMs.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-ï¸-installation" aria-hidden="true" tabindex="-1" href="#ï¸-installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>â¬‡ï¸ Installation</h2>
<p dir="auto">I don&#39;t want optional dependencies:</p>

<p dir="auto">Give me the full experience (all optional dependencies):</p>
<div data-snippet-clipboard-copy-content="pip install &#34;bocoel[all]&#34;"><pre><code>pip install &#34;bocoel[all]&#34;
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content--usage" aria-hidden="true" tabindex="-1" href="#-usage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸ”¬ Usage</h2>
<p dir="auto">See the folder <a href="https://github.com/rentruewang/bocoel/tree/main/examples/getting_started">examples/getting_started</a> for a simplistic usage of the library to get started with just a few lines of code.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-ï¸-develop-with-bocoel" aria-hidden="true" tabindex="-1" href="#ï¸-develop-with-bocoel"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>âœï¸ Develop with BoCoEL</h2>
<p dir="auto">Usage examples are under the folder <a href="https://github.com/rentruewang/bocoel/tree/main/examples"><code>examples</code></a>. API reference can be found <a href="https://rentruewang.github.io/bocoel/references/overview/" rel="nofollow">here</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content--contributing" aria-hidden="true" tabindex="-1" href="#-contributing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸ¥° Contributing</h2>
<p dir="auto">Contributors wanted! Don&#39;t be shy. Feel free to file issues and PRs. For PRs, please follow the guide on <a href="https://github.com/rentruewang/bocoel/blob/main/CONTRIBUTING.md">contributing</a> and the <a href="https://github.com/rentruewang/bocoel/blob/main/CODE_OF_CONDUCT.md">code of conduct</a>. Openness and inclusiveness are taken very seriously.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-ï¸-roadmap-work-in-progress" aria-hidden="true" tabindex="-1" href="#ï¸-roadmap-work-in-progress"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸ—ºï¸ Roadmap: work in progress</h2>
<ul dir="auto">
<li>ğŸª‘ Simpler usage. I should provide a high level wrapper for the entire library s.t. evaluations can be run in one line.</li>
<li>ğŸ“Š Visualization module of the evaluation.</li>
<li>ğŸ² Integration of alternative methods (random, kmedoids...) with Gaussian process.</li>
<li>ğŸ¥¨ Integration with more backends such as <a href="https://github.com/vllm-project/vllm">VLLM</a> and <a href="https://github.com/openai/openai-python">OpenAI&#39;s API</a>.</li>
<li>ğŸ†• Support for Python 3.11+</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-ï¸-license-and-citation" aria-hidden="true" tabindex="-1" href="#ï¸-license-and-citation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ğŸ·ï¸ License and Citation</h2>
<p dir="auto">The code is available under <a href="https://github.com/rentruewang/bocoel/blob/main/LICENSE.md">Apache License</a>.</p>
<p dir="auto">If you find this project helpful in your research, please cite this work at</p>
<div data-snippet-clipboard-copy-content="@misc{bocoel2024,
    title = {BoCoEL: Bayesian Optimization as a Coverage Tool for Evaluating Large Language Models},
    url = {https://rentruewang.github.io/bocoel/research/},
    author = {Wang, RenChu and Chuang, Yung-Sung},
    month = {January},
    year = {2024}
}"><pre><code>@misc{bocoel2024,
    title = {BoCoEL: Bayesian Optimization as a Coverage Tool for Evaluating Large Language Models},
    url = {https://rentruewang.github.io/bocoel/research/},
    author = {Wang, RenChu and Chuang, Yung-Sung},
    month = {January},
    year = {2024}
}
</code></pre></div>
</article></div></div>
  </body>
</html>
