<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://erikarow.land/notes/count-unique-unix">Original</a>
    <h1>How to Count Unique Lines Using Unix Pipes</h1>
    
    <div id="readability-page-1" class="page"><section id="How-to-Count-Unique-Lines-Using-Unix-Pipes">

<p>Sometimes I want to take a command line output and count the unique lines from that output. I can do this with a combination of standard unix tools and pipes:<label for="fn1"></label><span></span><label for="fn2"></label><span></span></p>
<pre><code>&lt;output&gt; | sort | uniq -c | sort -nr | head -n 5
</code></pre>
<p>By using the long flag names, we can get a better sense of what’s going on:<label for="fn3"></label><span></span></p>
<pre><code>&lt;output&gt; | sort \ 
  | uniq --count \ 
  | sort --numeric-sort --reverse \
  | head --lines 5
</code></pre>
<p>Step by step:</p>
<p>First, we sort the output alphabetically with <code>sort</code>.</p>
<p>Then, <code>uniq --count</code> merges matching lines while prepending the count to each line.<label for="fn4"></label><span></span></p>
<p>Then, <code>sort --numeric-sort --reverse</code> sorts these lines by the prepended count, in descending order.</p>
<p>Finally, we use <code>head --lines 5</code> to only get the top 5 counts.<label for="fn5"></label><span></span></p>
<section id="Applications">
<h2>Applications</h2>
<p>I wanted to share a few places where I’ve found this useful recently. This technique combines well with other command line “power tools”, such as <code>awk</code> and <code>jq</code>:</p>
<section id="Cut---Aggregate-a-CSV-Column">
<h3>Cut - Aggregate a CSV Column</h3>
<p>If I have a csv like this:</p>
<pre><code>hi,1,a
hello,2,a
world,3,b
</code></pre>
<p>I can use <code>cut</code> to select just a single column:<label for="fn6"></label><span></span><label for="fn7"></label><span></span><label for="fn8"></label><span></span></p>
<pre><code>cat my.csv \
  | cut --delimiter &#39;,&#39; --field 3 
</code></pre>
<p>Then, I can combine this output with our aggregation:</p>
<pre><code>&lt;previous&gt;  | sort | uniq -c | sort -nr | head -n 5
</code></pre>
<p>To get our aggregated count:</p>
<pre><code>      2 a
      1 b
</code></pre>
</section>
<section id="jq---Aggregating-the-Web">
<h3>jq - Aggregating the Web</h3>
<p>Our count unique aggregation works well with <code>jq</code> for counting API output.<label for="fn9"></label><span></span></p>
<p>For example, Codeberg’s Forgejo instance exposes a public API with information about the repos hosted there:<label for="fn10"></label><span></span></p>
<pre><code>curl &#34;https://codeberg.org/api/v1/repos/search&#34;
</code></pre>
<p>I can use <code>jq</code> to turn the resulting JSON into a list of primary languages used on each repo:<label for="fn11"></label><span></span></p>
<pre><code>&lt;previous&gt; | jq &#39;.data[].language&#39;
</code></pre>
<p>Here, I use <code>jq</code> to access the <code>data</code> key, operate over a list of objects, and then select the <code>language</code> key from each one.</p>
<p>Finally, we can aggregate to see what languages are most used:</p>
<pre><code>&lt;previous&gt;  | sort | uniq -c | sort -nr | head -n 15
</code></pre>
<p>For me that looks like:</p>
<pre><code>      9 &#34;&#34;
      4 &#34;Shell&#34;
      4 &#34;Lua&#34;
      2 &#34;Python&#34;
      2 &#34;Markdown&#34;
      1 &#34;Kotlin&#34;
      1 &#34;HTML&#34;
      1 &#34;GDScript&#34;
      1 &#34;Emacs Lisp&#34;
</code></pre>
<p>It looks like a fair number of repos don’t have their <code>language</code> field set in the Forgejo API response.</p>
</section>
</section>
</section></div>
  </body>
</html>
