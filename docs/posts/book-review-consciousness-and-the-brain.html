<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://astralcodexten.substack.com/p/your-book-review-consciousness-and">Original</a>
    <h1>Book Review: Consciousness and the Brain</h1>
    
    <div id="readability-page-1" class="page"><div><div><article><div class=""><div><div dir="auto"><p>[<em>This is one of the finalists in the 2022 book review contest. It’s not by me - it’s by an ACX reader who will remain anonymous until after voting is done, to prevent their identity from influencing your decisions. I’ll be posting about one of these a week for several months. When you’ve read them all, I’ll ask you to vote for a favorite, so remember which ones you liked - SA</em>]</p><p>Imagine that there was a generally acknowledged test for artificial intelligence, to find out whether a computer program is truly intelligent. And imagine that a computer program passed this test for the first time. How would you feel about it?</p><p>The most likely answer is: disappointed.</p><p>We know this because it happened several times. The first time was in 1966, when ELIZA passed the Turing test. ELIZA was a chatbot who could fool some people to believe that they talk with a real human. Before ELIZA, people assumed that only an intelligent machine could do that, but it just turned out that it is <em>really easy</em> to fool others. Other tests for intelligence were playing chess, playing <a href="https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark" rel="">a whole variety of games</a>, or recognizing cat images. Machines can do all this by now, and this is awesome. And yet, every success sparked new disappointment, because we didn&#39;t find any magic ingredient, some quality that would make a difference between intelligent and non-intelligent. When the groundbreaking <a href="https://slatestarcodex.com/2020/06/10/the-obligatory-gpt-3-post/" rel="">GPT-3</a> and <a href="https://openai.com/blog/dall-e/" rel="">DALL-E</a> suddenly could write news articles or poetry, or could dream up <a href="https://rossdawson.com/wp-content/uploads/2021/03/snail_made_of_harp.jpg" rel="">snails made of harp</a>... the main improvement was that they used more raw computation power than the previous versions.</p><p>If you find this disappointing, then you will also be disappointed by &#34;Consciousness and the Brain&#34; by Stanislas Dehaene. The book is the condensed wisdom of three decades of cognitive research, and it tells you what consciousness is, how it operates, and why we have it. The book actually <em>answers</em> these questions. But if you were hoping that the book would Resolve Philosophy, tell you What Makes Humankind Unique, or whether Free Will exists, it doesn&#39;t do that.</p><p>It only tells you what consciousness is.</p><h3>Consciousness: What is it Not?</h3><p>In order to study consciousness, we first need to recognize it. Dehaene&#39;s approach to this is simple and bold: a perception or a thought is conscious if you can report on it. If a test subject sees the word &#34;range&#34; on a screen, and you ask her to report what word she has seen, then the answer might be</p><p>1) &#34;I have seen the word range&#34;, or</p><p>2) &#34;What word? There was no word!?&#34;</p><p>In the first case, she has seen the word consciously, in the second not. This approach is more radical than it seems. Researchers are very cautious to take introspection at face value. And rightfully so, since our introspection is often wrong. The beauty of Dehaene&#39;s approach is that he only extracts a single bit of information (yes or no). It turns out that there are experiments which differ only in a minimal aspect (e.g., a slightly longer or shorter time delay), and which trigger either 1) or 2) reliably across many trials and many test subjects. I&#39;ll describe a few such setups later, but the point is that you can trust the reports because different people consistently give the same answer in the same situation.</p><p>It is important to understand that Dehaene&#39;s book is <em>only</em> about this definition of consciousness. It is not about cognition (in the sense of abstract reasoning) or meta-cognition (the ability to reflect about your own thoughts). It is not about self-consciousness (being aware of oneself). And of course, there are other definitions of consciousness. The <a href="https://www.nyu.edu/gsas/dept/philo/faculty/block/papers/consc.BRAIN.8.pdf" rel="">most compelling alternative</a> calls Dehaene&#39;s concept <em>conscious access</em> and distinguishes it from <em>conscious perception</em>. But for this review, I will stick with Dehaene&#39;s definition.</p><p>Another different, though related concept is attention. For Dehaene, attention is the gating mechanism that decides which information is allowed to enter consciousness. But this process itself is unconscious: we are not aware of all the options that were considered and discarded, only of the winner. This notion of attention is broadly <a href="http://www.scholarpedia.org/article/Attention_and_consciousness" rel="">in line with the mainstream of the field</a>, though the exact definition varies.</p><h3>Controlling Consciousness</h3><p>To understand consciousness, the first step is to understand how <em>un</em>conscious processing works. Some glimpses come from <a href="https://en.wikipedia.org/wiki/Blindsight" rel="">blindsight patients</a>, who lose the ability to see consciously due to brain damage. This can affect their whole field of vision, or just one hemisphere, or even just specific forms like lines. But they remain able to unconsciously process what they see. They will automatically walk around objects in their way, even though they swear that they don&#39;t see them. The effect can also be artificially produced in monkeys.</p><p>Fortunately, there are also ways to make perception unconscious in ordinary people:</p><p>- You don&#39;t always perceive images consciously if they are presented with a low contrast, or for a short time.</p><p>- <em>Binocular rivalry</em> occurs if your two eyes are presented with different images. In this case, most of the time you don&#39;t see a weird overlay of the two images, but instead your conscious perception flips between seeing either one or the other. It&#39;s a bit like staring at <a href="https://en.wikipedia.org/wiki/Ambiguous_image" rel="">ambiguous images</a>, but more consistent. So at any point in time, you perceive one of the images consciously and the other unconsciously.</p><p>- <em>Attentional blinking</em> describes the effect that after a conscious perception, you are consciously blind for anything that you see in the next 200-300ms. Let&#39;s say you watch a fast stream of digits, each only visible for 100ms, and occasionally the stream contains a letter instead of a number. You are supposed to detect the letters. When you see an &#34;M&#34;, this enters your consciousness, and you detect it. But if 300ms (three images later), there is another letter &#34;S&#34;, you will not see it consciously. Actually, you will be sure that there was no &#34;S&#34; in the stream.</p><p>- With <em>Transcranial Magnetic Stimulation</em> (TMS) we can stimulate specific brain regions. By stimulating sensory areas, we can induce hallucinations, and we can either make them conscious or unconscious by regulating the strength of TMS. By interfering with the right region at the right time, we can also prevent real perceptions from entering consciousness.</p><p>All these setups are useful, but they are not 100% reliable, more like 80% at best. For example, binocular rivalry is different <a href="https://www.nature.com/articles/nrn.2017.112" rel="">in autistic people</a>. But there is one setup which works always, for everyone, and that is <em>masking</em>. In masking you see some shapes (the &#34;mask&#34;), then very briefly an image, and then the shapes again. If the image is shown for 30ms, then people do not consciously see it, while for 60ms they do. This works with almost 100% accuracy, and has become the main workhorse for consciousness studies. You can even mask only a part of the screen if you want. While subjects are presented with masked words, numbers, and images, the researchers can measure the brain activity with EEG, MEG, fMRI, or even implanted electrodes (for epileptic patients who have the electrodes for unrelated medical reasons). They measure how the skin starts to sweat and the body tenses up from the unconscious perception. And mostly easily, they measure how it affects the performance in a subsequent, conscious task. For example, seeing the word &#34;bank&#34; unconsciously will make you react faster to a related word like &#34;money&#34;, an effect known as <em>priming</em>.</p><h3>Should I Believe This?</h3><p>Wait a moment, priming? Aren&#39;t those the wrong conclusions that were wiped out by the big <a href="https://en.wikipedia.org/wiki/Replication_crisis" rel="">replication crisis</a> in psychology? Should I really believe these things?</p><p>I think yes. It is hard to convey in a review how painstakingly pedantic the field apparently is. There are a lot of different opinions on consciousness, and the experiments are scrupulously examined for any possible flaw or alternative interpretation, both from insiders and outsiders of the field. Just to give one example, in the priming study with &#34;bank&#34; and &#34;money&#34;, the conclusion was that the words are processed *semantically*, not just as a bunch of characters. Dehaene mentions not one paper getting this result, but four. Then he describes how critics were not satisfied, and gives five more papers which addressed the critics. But for reasons going deep into the precise setups, it was still not settled whether this actually proves the claim that the meaning is processed. Which made the original authors re-examine their results and publish a follow-up paper proving that <em>indeed, the critics were right, and their setup was no proof</em>. Which triggered an avalanche of follow-up work until it was waterproof beyond doubt. Dehaene cites 44 papers <em>just on this debate</em>. And there was never any doubt on whether the raw results were reproducible, the debate was about whether the experiments left room for alternative interpretations. I wish my own fields of research would be just half as rigorous as what I read in this book. </p><p>I have read one other scientific book which breathes the same positive pedantry, and that is <a href="https://astralcodexten.substack.com/p/your-book-review-are-we-smart-enough" rel="">Are we Smart Enough to Know How Smart Animals Are?</a> by Frans de Waal. I think there is a pattern. It helps that both fields treat a topic on which everyone has their own opinion, so they get a lot of know-alls from outside the field interfering with the discussion. But more importantly, they are based on methods which used to be tabooed inside their scientific community. De Waal treated his animals as personalities and even bonded with them instead of keeping neutral distance, and he took wildlife observations seriously. All of this was considered totally unscientific, so he was forced to be extra scrupulous in his experiments. For Dehaene and his colleagues, it was the paradigm that “<em>subjective reports can and should be believed</em>” -- as a source of raw data, without making the mistake of conflating the subjective belief with reality. When patients tell you after surgery that they had the impression to leave their body and float at the ceiling, then you should <em>not</em> believe that they actually floated. You should believe that &#34;floating&#34; was their true feeling, and that probably there is a neuroscientific cause for this feeling. Taking it seriously eventually enabled researchers to <em>induce</em> the feeling of leaving your body in any person, by using the right neural stimulation. But until the 90s, it was scientifically taboo to take subjective feelings into account, so experiments with low standards would have been torn apart.</p><p>I find these examples encouraging, because they show that even strong taboos can be overcome if your science is just good enough.</p><p>Not surprisingly, the replication crisis hit cognitive psychology much less hard than other fields like social sciences. Of nine key findings of cognitive psychology, <a href="https://digest.bps.org.uk/2017/06/05/these-nine-cognitive-psychology-findings-all-passed-a-stringent-test-of-their-replicability/" rel="">all nine could be reproduced</a>, including three that are core to the book. Yes, a lot of priming experiments were not replicable, and only a hard core survived. But this book is about the hard core. Of course, some of the ~1300 papers cited by Dehaene will be wrong, but I have a lot of trust in the general picture.</p><h3>What We Can Do Without Consciousness</h3><p>Ok, let us believe that the results on unconscious processes are real. What can the brain do with unconscious information?</p><p>A lot. The experiments fill a big chunk of the book, and I can&#39;t go into detail. I have already mentioned that your unconscious brain does not just process the letters of a word, it also deciphers the meaning. For example, a masked &#34;four&#34; primes you not just for recognizing &#34;four&#34;, but also for &#34;4&#34;, &#34;FOUR&#34;, a spoken &#34;four&#34;, and even for &#34;three&#34;. In fact, it primes you better for &#34;three&#34; than for &#34;two&#34;: the priming is stronger the closer the numbers are.</p><p>Unconscious perceptions can induce negative emotions, and you can unconsciously distinguish faces and abstract categories like &#34;object&#34; and &#34;animal&#34;. You can unconsciously estimate averages. Unconscious perceptions can control your attention. An unconscious &#34;stop signal&#34; will activate your executive control center in the brain. Sometimes this prevents you from pressing a button that you were supposed to press, which seems like a mysterious mistake to you. You can also unconsciously detect errors: when you make a mistake in an eye-tracking task, your error control system will flash even if the signal never reaches your consciousness (in which case you don&#39;t notice that you have made a mistake).</p><p>You can even learn new things unconsciously. If you get a reward after each unconscious presentation, and you get more reward after image A than after image B, then you learn that A is worth more -- even if you never consciously see any images at all! For you, it seems like you look at a screen where nothing interesting happens, and you get completely random rewards.</p><h3>What We Can <strong>NOT</strong> Do Without Consciousness</h3><p>So if we can do so many things unconsciously, what do we even need consciousness for? What is the effect of a conscious perception?</p><p>Traces of unconscious perceptions are spurious. They are almost completely gone after a second. This means that tasks which require <em>working memory</em> can not be performed unconsciously. For example, in order to compute 12x13 we need to perform several subsequent steps, and use the intermediate result of one step as an input for the next one. This task can not be performed unconsciously. It seems that the unconscious traces are too weak to be used as an input for a second step. Dehaene tries to pinpoint the exact point of complexity that can be performed unconsciously, and it seems to be very low. After seeing a number n unconsciously, test persons are well above chance for the tasks of naming n (&#34;But I haven&#39;t seen anything!&#34; &#34;Don&#39;t worry, just take a random guess.&#34;), naming n+2, or deciding whether n&lt;5. But deciding whether n+2 is smaller than 5 is already at chance level. Dehaene suspects that complex language (conversation with others) also falls into this category of processes that require working memory. It is not mentioned in the book, but the same probably holds for trains of thought, including cognition.  </p><p>Consciousness has a <em>coordination effect</em>. Imagine you see some line moving in a diagonal direction over the screen. We know very well what happens in the low-level visual areas. The neurons there cannot &#34;see&#34; the whole picture, they have only a limited <em>perceptive field</em>. For them, the image is ambiguous: it is impossible to decide from their local information whether the line moves upwards, or to the right, or diagonally. Some neurons will decide for &#34;upwards&#34;, and encode that. Others will decide for &#34;right&#34; or for &#34;diagonally&#34;. If the image remains unconscious, then these mismatches are never resolved. However, if the image enters consciousness, then after 120-140 ms all neurons in the lower layers suddenly start to encode &#34;diagonally&#34;. Now they agree on the same interpretation of the world.</p><p>Dehaene phrases this in a way that ACX readers will love. For him, the unconscious (or pre-conscious) neural activity encodes a probability distribution over the possible states of the world. If we see the word &#34;bank&#34;, then the meaning &#34;credit institute&#34; and &#34;sitting bench&#34; are both represented by some neurons, so they both occur in this probability distribution. When the word reaches consciousness, then the brain *<em>samples</em>* from this distribution. So it decides for one of the possible options, and all neurons are overwritten with this meaning. For example, in binocular rivalry (when your two eyes see incompatible images) you will sometimes see option A, sometimes option B, but usually not both. Once you have drawn a sample, this is not a final decision. In binocular rivalry, your perception switches every few seconds between A and B. Some researchers even claim that the brain <a href="https://www.pnas.org/content/early/2011/07/07/1101430108" rel="">gets the Bayesian math right</a>: if you present an image that is ambiguous in a very clever way, such that there is an objective underlying probability of 70% for A and 30% for B, then you will see A for 70% of the time and B for 30% of the time. Others claim that you can play <a href="https://journals.sagepub.com/doi/10.1111/j.1467-9280.2008.02136.x" rel="">&#34;Wisdom of the Crowd&#34; in single-player modus</a>. Say you want to know the weight of a cow. Then take a guess. Now throw your guess out of the window, and take <em>another</em> guess. Finally, compute the average of your two guesses. The claim is that this average is better than your individual guesses.</p><p>Such sampling has obvious benefits. If I have to walk around a tree, then choosing either &#34;left&#34; or &#34;right&#34; is fine, but my whole brain and body should stick to this decision. So conscious sampling is very important for decision-making. But it goes beyond that. The way how we perceive the world in a conscious moment is already a selection, as the <a href="https://www.youtube.com/watch?v=sKa0eaKsdA0" rel="">rotating mask illusion</a> nicely illustrates.</p><p>There is another interesting effect of consciousness that Dehaene only mentions casually a few times: it enables us to gauge our confidence. So test subjects can say &#34;I am certain&#34; or &#34;this was just a guess&#34;. We can test these self-assessments with <a href="http://www.scholarpedia.org/article/Attention_and_consciousness#Post-decision_wagering" rel="">betting systems</a>. And we are good at this, but <em>only</em> if the task was based on conscious perception. If it is based on unconscious perception, then we may still be good at the task itself, but our self-assessment is inaccurate. Often we underestimate our performance. By the way, simple betting systems (consisting essentially of the options &#34;Yes&#34;, &#34;No&#34; and &#34;Not Sure&#34;) also show that <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1861845/" rel="">mice</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/15105996/" rel="">monkeys</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/8530911/" rel="">dolphins</a> know how confident they are. We&#39;ll have to wait a bit for results on how consciousness affects self-assessment in animals, but researchers have <a href="https://psycnet.apa.org/record/2015-20745-072" rel="">speculated that the results should be similar</a>, suggesting that a <a href="https://www.metaculus.com/questions/" rel="">prediction market</a> of unconscious mice may work poorly.</p><h3>Consciousness and Learning</h3><p>In this section, I will go a bit beyond the book, so this might be a bit less reliable than the rest. I have worked on research of neural plasticity and learning, so the ideas do not come entirely out of thin air. To understand the effect of consciousness on learning, you should first know that there are two different types of long-term memory, <em>procedural</em> and <em>episodic</em> memory. Procedural memory allows us to walk, ride a bike, or play the piano. For this review, I will pool it together with <em>semantic memory</em>: the knowledge that birds can fly, or things that you have learned by heart, like a song or the multiplication table. We can use procedural memory in automatic mode, and we can acquire and access it unconsciously. Acquiring procedural memory often requires a lot of practice and repetition. This type of learning is usually slow and decentral in the brain: only the regions which are directly relevant to the task are involved in this type of learning. It shares many similarities with modern machine learning systems.</p><p>On the other hand, episodic memory refers to specific moments of your life, for example remembering what you had for breakfast or what your conversation partner said five minutes ago. This memory is <em>one-shot</em>, so the memory is instantaneously formed and does not require any repetition. Aspects of episodic memory can be transferred into procedural memory: when you learn the name of your new colleague, then this stays an episodic memory for a while, but it becomes procedural/semantic memory after a few repetitions. Sometimes we don&#39;t even need repetition, for example when we recognize a face after a single meeting, or when a child acquires new words. But this relies on complicated interaction between the two types of memory that I won&#39;t get into here. Usually, we can make a clear distinction. It seems that episodic memory without consciousness is plainly impossible, and I will come back to that.</p><p>But consciousness also helps for procedural memory, even though it can be formed from purely unconscious perceptions. First, think of consciousness as giving a boost to the learning rate. I have mentioned before that episodic memory (which requires consciousness) can be transferred into procedural memory during sleep, and this is stronger than the effect of the direct experience alone. You will still not be able to learn the piano in a week, but consciousness probably makes learning faster. Second, as Dehaene explains in his book, you only connect unconscious events with each other if they are simultaneous. This makes sense because unconscious neural activity fades away so quickly. Dehaene describes some classical conditioning experiments similar to Pawlow&#39;s dog, where the sound of a bell is associated with receiving food. But if (to stay in the picture) the bell is perceived unconsciously, then the connection is only made if the bell rings <em>while</em> the reward comes (plus/minus at most one second), not if the bell rings a few seconds earlier.</p><p>For episodic memory, I think that it is even more closely entangled with consciousness. I believe that the coherent activity of consciousness is exactly the form of neural patterns that can be stored in episodic memory. Thus a conscious perception <em>creates</em> a memory item that can be stored and retrieved later. Let me explain why. A crucial property of memory is <em>pattern completion</em>: that you can retrieve the whole memory pattern from activation of a small part. So the word &#34;croissant&#34; may trigger the image of a croissant, the smell of it, the taste, the texture, and so on. But the same works vice versa. The smell of a croissant also triggers the rest. There is no core of the concept &#34;croissant&#34; that needs to be present in order to trigger the whole concept. For procedural memory, this is not a big deal. Since this memory is formed slowly, there is enough time to nicely embed it into existing structures. But episodic memory is one-shot learning, it needs to be formed in a second. (There is some long-term consolidation later during sleep, but this only shifts the problem: the brain still needs to maintain traces of the pattern for 16 hours.) And it&#39;s really hard to embed a complex concept so deep into an existing network that you still have pattern completion. Mind that every change in the brain needs to be cautious, because you have a lot of systems that should still be working after the change. In machine learning, in case of doubt you set your learning rates <em>really low</em>, and that is for the same reason: you don&#39;t want to overwrite all the existing functions of your network. And the task is more difficult for more complex patterns. If each neuron represented its own interpretation of reality, then it would be pretty hopeless to encode all this into a retrievable pattern in just one second. But it gets a lot easier if the activity of all neurons throughout your whole brain are highly consistent with each other, and that is <em>precisely</em> what consciousness seems to achieve. This is why I believe that consciousness might <em>create</em> the items that we can store in our episodic memory.</p><h3>Properties of Consciousness</h3><p>For an unconscious perception, the main brain activity is in perceptual regions (visual regions for images, auditory regions for sounds, and so on). The signal can travel further into the brain, but only reaches a few regions, and gets weaker and weaker. A <em>conscious</em> perception does not get weaker, it gets stronger as it travels. Dehaene compares unconscious perception with a wave that runs out at the shore, while a conscious perception is like an avalanche that gains momentum. After 400ms, the conscious avalanche has activated large parts of the brain, which Dehaene calls <em>global ignition</em>. Moreover, all the brain parts synchronize, and information flows from all parts into each other. This is not a metaphor, &#34;flow of information&#34; is a well-defined quantity, measured by so-called <a href="https://en.wikipedia.org/wiki/Granger_causality#In_neuroscience" rel="">Granger causality</a>. Granger causality is a useful concept with a terrible name, since it is about a complex form of correlation, and not about causality. Whatever it is, it suggests strongly (without being a proof) that all parts of the brain talk intensively with each other.</p><p>Dehaene goes into a lot of details on the exact form of these signals and exchange, but I will cut it short. It all fits very well with the assumption that in a conscious moment, the brain creates a coherent worldview, which we may call &#34;sampling&#34;, &#34;coordination&#34;, or &#34;creating a memory item&#34;. Dehaene compares it with a memo that the CIA prepares for the president: it does not contain all the details of hundreds of subreports, but is a highly condensed summary of the worldview of the CIA. This metaphor expresses nicely how the information is compressed, but mind that it leaves out two aspects. In a conscious moment, information also flows <em>downwards</em> to the low-level areas, and they change their activation patterns to make them compatible. So it is as if all CIA members would read the presidential memo, and start to rewrite their own local reports to match this worldview. (I <em>hope</em> that the CIA doesn&#39;t work this way.) Second, in the brain there is no single president to make decisions. There are regions that we call &#34;executive control regions&#34;, but they are notoriously hard to pinpoint, and there is no region which is <em>always</em> involved in decisions. It might be more accurate to think of a committee meeting of all brain regions, who discuss and decide on a topic.</p><p>Consciousness has a severe disadvantage: it is really slow. A conscious perception takes about half a second, 500ms. This is <em>ages</em> compared to neural transmission speed. If you are shown two images, and you are supposed to pick out the one with the animal, then your eyes start moving to the <em>correct</em> image after 70-100ms. Not with 100% accuracy, but far above chance. In a 100m sprint, you really don&#39;t want to wait for 500ms before you start running. Or imagine playing computer games with 2 frames per second, which is NOT FUNNY. So a lot of our everyday life runs on autopilot. This is also the reason why predictions are so important for the brain. Some cool experiments show that when we are shown a surprising image, the time <em>we believe</em> the image to appear is 300ms after it <em>actually</em> appears. But if we can predict the image, there is no such delay, and we perceive the timing correctly.</p><p>Consciousness is also <em>exclusive</em>. While a conscious perception is processed (which may consist of several components, like an image and a compatible sound), the activity blocks off other perceptions. They are either missed completely, or can only be processed after the 500ms are over. There is something like a buffer in which a perception can be stored until consciousness is ready again, but it will not be processed before that. (Again, there are cool time perception experiments which show that quite convincingly.) So our consciousness runs at most at 2 perceptions per second, and other than unconscious operations, it can not be parallelized.</p><h3>Insights Into the Inside</h3><p>Now that we understand consciousness, we have quite a lot of tests to tell apart conscious from unconscious processing. Indirect clues come from abilities. It seems that working memory requires consciousness, and Dehaene has developed some very detailed tests to decide whether someone is conscious. Not just for fun; he works with patients in long-time coma (more precisely, in vegetative state). Some of them are fully conscious locked-in patients, but this is quite hard to detect. Dehaene has developed tools for detecting traces of consciousness in such patients, and they can predict (to some extent) whether the patients will eventually recover. They are also useful for developing communication devices for locked-in patients. But we can also apply the tests to healthy individuals and see what we get. We are not conscious during anesthesia (what a surprise), but sleeping is already more complicated. Most sleep phases are unconscious. In dream phases (REM sleep), external stimulation usually does not spark consciousness. However, the brain <em>does</em> react like a conscious brain if the stimulus is directly implanted into the brain via magnetic stimulation (TMS). So perhaps we <em>are</em> conscious in dreams, and we are only cut off from outside perception. But it is too early to be certain. Also, although the book does not discuss this point, I wonder whether we are conscious all of our daytime. Probably we don&#39;t use the full bandwidth of two conscious perceptions per second the whole day. How conscious are we when we enter the &#34;flow&#34; during a marathon? Can meditation suppress consciousness? I don&#39;t know.</p><p>A part that really made me think is Dehaene&#39;s theory of schizophrenia. I have heard a lot of explanations for schizophrenia, and most of them sound superficially compelling, but collapse pretty quickly when you dig into them. This one... has not collapsed yet, at least not for me. Deahene believes that schizophrenia is what you get if you (partially) lose conscious perceptions. This sounds ridiculous at first, but as always, Dehaene makes it really hard to shrug this off as obvious nonsense. He claims that in order to reach consciousness, a masked signal needs to last &#34;much longer&#34; for schizophrenic patients. I expected that &#34;much longer&#34; means &#34;whatever passes your p-value test&#34;, but I looked into the study. It was 90ms versus 59ms. That’s a lot. The <em>maximum</em> of the control group (n=28) was roughly the same as the average of schizophrenic patients (n=28)! And of course, it doesn&#39;t stop there. Also for other effects of consciousness, <a href="https://www.pnas.org/content/pnas/100/23/13722/F2.large.jpg" rel="">schizophrenics really stick out</a>. (The link is worth clicking!) Dehaene describes how the other neural signatures of consciousness are disturbed or even plainly missing. He describes how schizophrenia can be caused by certain neuro-anatomic damage (in terms of regions and neuron types), which happen to be exactly the type of damage that would impair consciousness. He tells compelling stories on how consciousness would explain the <a href="https://en.wikipedia.org/wiki/Schizophrenia#Positive_symptoms" rel="">positive</a> <em>and</em> the <a href="https://en.wikipedia.org/wiki/Schizophrenia#Negative_symptoms" rel="">negative </a>symptoms of schizophrenia. He mentions some <a href="https://en.wikipedia.org/wiki/Anti-NMDA_receptor_encephalitis" rel="">weird autoimmune disease</a> which gives you super-strong schizophrenic effects (from hallucinations to paranoia) until you spontaneously lose your consciousness after three weeks and possibly never regain it. I am still cautious about the story, simply because I have a really low prior that we ever find a theory of schizophrenia. But if you hope for such a theory, you should know this candidate.</p><h3>Conclusion</h3><p>So consciousness has upsides and downsides. It is really slow, it is exclusive, and it simplifies the world into a highly compressed sample. This can be useful in its own right, for example to make a decision. A lot of information is lost in this process, but apparently the resulting pattern is so simple that it can be processed further. Since all parts of the brain participate in a conscious event, it is also universally available in the brain. Dehaene calls this function the *Global Neuronal Workspace*. Propagating something to consciousness is similar to loading something into a register of a computer, so that it can be processed further. I believe that consciousness is even more, it <em>creates</em> the item in the first place. The item can then be stored and retrieved, and it can be used as input for mental algorithms. Of course, a conscious thought does not need to be triggered from the outside. It can also be the next step of a mental algorithm, like the next thought in a train of thoughts, and it can come (fully or partially) from episodic memory or mental associations. Dehaene adds that due to its simplicity, these memory items can often be expressed in language, and thus they can be transmitted to others. Thus consciousness is probably a necessary factor for the complex language and culture of humans. Necessary, but not sufficient: many animals around us are conscious, too. Humans are special in many ways, but being conscious is not among them.</p><p>After reading this long review, does it still make sense to read the book? Yes, absolutely! It describes tons of really fascinating experiments that I had to skip, and it is really pleasant to read. As are other books by Dehaene, especially &#34;Reading in the Brain&#34; and &#34;The Number Sense&#34;, which discuss how the brain processes texts and numbers.</p><p><strong>Appendix A: The Hard Problem of Consciousness</strong></p><p>Do you feel disappointed by the book? At least some people did. When the program ELIZA passed the Turing test, a common reaction was “This is not what we had meant”. Some reactions to this book were similar. Dehaene’s concept of consciousness is much more mundane than the lofty associations that we commonly attach to the word consciousness. But if we actually want to nail it down and get a more substantial definition than “whatever elevates me above mere animal”, then “the thing that happens during conscious perceptions and does not happen during unconscious perceptions” sounds pretty convincing to me. </p><p>But other people think differently. Dehaene was accused of dodging the <a href="https://en.wikipedia.org/wiki/Hard_problem_of_consciousness" rel="">hard problem of consciousness</a>. This is &#34;the problem of explaining why and how we have qualia or phenomenal experiences. That is to say, it is the problem of why we have personal, first-person experiences, often described as experiences that feel &#34;like something&#34;&#34; (wikipedia link above). Dehaene has been criticized for &#34;<a href="https://web.archive.org/web/20140717224102/http://www.funjournal.org/images/stories/downloads/2014_Volume_12_Issue_2/june-12-r5.pdf" rel="">dismissing the hard problem in barely over a page of text</a>&#34;. For Dehaene, as for other renowned researchers, the problem does not exist, and I share their opinion. But there are equally renowned researchers <a href="https://en.wikipedia.org/wiki/Hard_problem_of_consciousness" rel="">who accept the problem</a>. Even though the book hardly discusses the topic, I believe that it has implications for the question, and I will explain my point of view below. If you believe in the hard problem of consciousness, then my perspective will probably not convince you otherwise, but it may help to pinpoint further <em>where exactly</em> we disagree.</p><p>A sensory input like the color &#34;red&#34; leads to some neural activity. While the neural activity is active, there is some perception of it. There are at least two different ways of phrasing what happens.</p><p>- Classically, we would say that &#34;I&#34; or &#34;the brain&#34; <em>experiences</em> the color red. This is also called a <em>quale</em>, plural qualia. The hard problem of consciousness assumes that this experience is something that goes beyond neural activity. So even if an outsider perfectly knows the neural activity, then this does not give experience. A crucial point of this perspective is that there is an <em>observer</em>, which is usually called &#34;I&#34;, and sometimes &#34;my mind&#34; or &#34;my brain&#34;.</p><p>- In the book <a href="https://en.wikipedia.org/wiki/Consciousness_Explained" rel="">Consciousness Explained</a>, Daniel Dennett argues that a more appropriate description is the <em>multiple drafts model</em> (also called <em>Cartesian theater</em>): the brain is a collection of many different regions, all of which follow their natural task of observing the surrounding neural activity. Each region acts like a little agent with its own perception. The experience is then just the collection of these local experiences.</p><p>Critics like <a href="https://www.nybooks.com/articles/1995/12/21/the-mystery-of-consciousness-an-exchange/" rel="">John Searle find</a> that the multiple drafts model can&#39;t explain why experiences are first-person, i.e., where the &#34;I&#34; comes from. And I think this is precisely the point that Dehaenes&#39;s book helps us to understand. My claim is:</p><p><em>Given what we know about consciousness, if we assume the multiple drafts model, then we should naturally expect the subjective perception of a first-person observer.</em></p><p>To explain the claim as clearly as possible, let me take a small detour.</p><p>The brain is very good at decomposing the world into units that make sense. For example, when I look out of the window, I automatically decompose the image into several houses, a few people, a dog, and so on. The units can be nested, like a window that is part of a house, and can even overlap. In general, the brain tries to find neat and clean units if possible. An example is our own body. We have a very clear body schema, i.e., we consider our own body as a unit (with various sub-units, of course). My hand is part of my body, the cup of tea in my hand is not. And that makes a lot of sense. On the other hand, qualitatively the difference is not so fundamental. Both the hand and the cup are objects outside of your brain. We can control the hand by sending signals to our joints, and we can control the cup by grasping it, which is also achieved by sending signals to our joints. So it is the same sort of control on a fundamental level. But on any practical level, the difference is huge. Even an alien observer would agree that the decomposition into &#34;your body&#34; versus &#34;not your body&#34; is sensible. However, simple tricks like the <a href="https://en.wikipedia.org/wiki/Body_transfer_illusion" rel="">rubber hand illusion</a> show that this body schema can be re-learned. So the body schema is a construct that is shared by almost all people (<a href="https://en.wikipedia.org/wiki/Somatoparaphrenia" rel="">some get it wrong</a>), because it makes so much sense, both to us and to alien observers.</p><p>What would an alien observer say about the neural activity in our brain? There are a lot of different brain areas with different functional rules. Sometimes a few areas interact with each other, and our visual system may activate our motor control system without much other brain areas involved. A lot of neurons plainly contradict each other. Perhaps the alien would conclude that the subunits have a lot more descriptive power than just the coarse category &#34;brain&#34;. So it might decide to describe it as Cartesian theater. But now imagine that the alien is only allowed to observe the brain *<em>in conscious moments</em>*. As we have learned, in these moments all regions of the brain have agreed on the same interpretation of the world. In the theater picture, the alien would only observe the actors at times when they all speak in a perfect chorus. In this case, it might conclude that the sub-units are not so important, and that the chorus is much more important than its part.</p><p>I think this is precisely where our concept of &#34;my mind&#34; comes from. Remember that our episodic memory might be exclusively formed from conscious moments, and also implicit learning gets a strong boost from consciousness. So when &#34;we&#34; (our brain, or the actors in the Cartesian theater) learn a &#34;mind schema&#34;, then this is based on the conscious moments, not on the activities in between. On this basis, it makes sense to merge all our neural activity into a single unit, which we call &#34;I&#34; or &#34;my mind&#34;. Just as we form the concept of &#34;my body&#34;, but even stronger, since we never &#34;observe&#34; different parts of our mind to be incoherent or even independent. Once the concept of &#34;I&#34; is formed, any conscious perception is connected with the &#34;I&#34; unit, so a conscious perception of the color red is translated into &#34;The neural activity of the myself-unit represents the color red&#34;, which in common terms is &#34;I experience the color red&#34;.</p><p><strong>Appendix B: Are Robots Conscious?</strong></p><p>Are babies, animals, or robots conscious? For babies, yes, they are conscious. Their consciousness is 3 times slower than that of adults, which probably has purely physical reasons. The cables in the baby brain are not isolated. The isolation just doesn&#39;t fit into the baby skull. Unisolated fibers have lower transmission speed. The isolation is added later in several surges, the last and most drastic of which happens during puberty. Be patient with your babies and kids, and yes, even with your teens.</p><p>A lot of animals are conscious, too. For mammals, it looks like a universal Yes. We have pretty clear evidence of consciousness from apes, monkeys, dolphins, rats and mice, some of which came after Dehaene&#39;s book. The question becomes trickier as animals become more different from humans, since the brains become more different, and we are more and more forced to rely on indirect clues. For an octopus, where most of its neural power is dispersed over its arms, the behavior suggests that the answer is still yes, but neural signatures can no longer be taken as confirmation, and a lot of tests don&#39;t work anymore. And for robots, neural signatures don&#39;t help at all. Dehaene has no doubt that we can eventually build robots which are conscious in exactly the same way as humans are, but even if true, that doesn&#39;t tell us whether my laptop, GPT-3, or R2-D2 are conscious.</p><p>But do we have to rely on neural signatures? Can&#39;t we generalize and define it by the all-parts-talk-to-each-other-and-there-is-great-coherence-and-Granger-causality-thingy? So if a robot satisfies this criteria, is it/s/he conscious? The book only touches this question lightly, but I&#39;ll add a few of my own thoughts. Since the question about robots can become confusing, let me instead discuss the obvious alternative question <em>if and when the Swiss canton of Glarus is conscious</em>.</p><p>Switzerland is a successful little country in Europe, and it may have <a href="https://www.lesswrong.com/posts/x6hpkYyzMG6Bf8T3W/swiss-political-system-more-than-you-ever-wanted-to-know-i" rel="">the weirdest political system</a> that you have ever heard of. After each election, the government is formed from all parties in the parliament, more or less proportional to the number of seats. (It has only seven members, so small parties are left out.) Currently, the government consists of two members from the social democrats, two from the liberal party, one from the moderate rights, and two from the far right party.</p><p>Switzerland is an egalitarian society. It doesn&#39;t have a capital city because the Swiss didn&#39;t want to single out a city. Bern is the seat of government, close enough. Switzerland also doesn&#39;t have a head of state like the Queen, which is slightly awkward since the country can&#39;t make official state visits. (But the Swiss prefer anyway not to interact too much with other countries. They pondered 50 years before <a href="https://www.eda.admin.ch/eda/en/home/news/dossiers/alle-dossiers/15-jahre-uno-mitgliedschaft-der-schweiz/haeufige-fragen--die-schweiz-und-die-uno.html" rel="">joining the UNO</a> in 2002.) Switzerland also doesn&#39;t have a <em>head of government</em>. The closest thing is the mostly empty title &#34;Bundespräsident&#34;, which rotates annually among the members of government. The title always goes to the member who hasn&#39;t held it for the longest time. (There are tie-breaking rules in case several members of the government never had it.) But the Bundespräsident doesn&#39;t really have additional power.</p><p>For such an egalitarian country, it is not surprising that Switzerland is federal, it consists of 26 <em>cantons</em> (similar to US states, just smaller). Of course, every canton can make its own laws, and most cantons have parliaments for that. But the canton Glarus, with a tiny population of 12,000, does not have a parliament. Instead, they have a <em><a href="https://en.wikipedia.org/wiki/Landsgemeinde" rel="">Landsgemeinde</a></em>: once a year, the citizens of Glarus assemble at a big open space, and decide jointly on new laws, the tax rates for the next year, and important offices like judges. Every citizen can rise to speak on any of the discussed items, and can propose changes (which even go through sometimes).</p><p>I hope you see the analogy to consciousness. Once a year, the Landsgemeinde creates a coherent state among its citizens. Communication is open from everyone to everyone, until a common ground is found, and a decision is made which is compulsory for everyone. You could even say that the Landsgemeinde creates a permanent and consistent &#34;memory&#34; since its decisions become codified law.</p><p>So should we say that the canton of Glarus becomes conscious once a year? Probably... not. There are similarities, and after reading this review you might understand what I mean if I call the Landsgemeinde a conscious event of Glarus. But in any other context, I would just cause utter confusion. More importantly, it goes against the intuitive meaning of consciousness for 99% of the people. So if we want to describe the concept of &#34;all-parts-communicate-and-are-coherent-and-Granger-causal&#34;, then we should better invent a new name for it. Actually, there have been attempts to formalize and measure this, most famously the <em>Integrated Information Theory</em> (IIT) by Giulio Tononi. But the hope that this could give a formal definition of consciousness has the same problem as the idea that the Landsgemeinde is conscious. <a href="https://www.scottaaronson.com/blog/?p=1799" rel="">In a great rebuttal</a>, Scott Aaronson has discussed the idea that IIT captures consciousness, and concluded that it &#34;is wrong — demonstrably wrong, for reasons that go to its core. [This] puts it in something like the top 2% of all mathematical theories of consciousness ever proposed. Almost all competing theories of consciousness, it seems to me, have been so vague, fluffy, and malleable that they can only aspire to wrongness.&#34;</p><p>So we have little hope to capture consciousness in a nice mathematical theory. But why would we even want this? One motivation comes from the idea that conscious beings are qualitatively different from others, and deserve human rights, or robot rights. But consciousness is a terrible indicator for that. There is no magic ingredient, no godly spark in consciousness. It’s nothing special. Or at least it is much more widespread among species than generally assumed, and it means a lot less than philosophers often make out of it. (To be fair, they might be talking about a different concept than “having conscious perceptions”. But I think Dehaene has the better claim on the term consciousness.) At least for me, this approach to ethics seems to be a dead end, and the question of consciousness of robots has become a lot more boring after reading this book. Robots won&#39;t be conscious in the exact same way as we are. They might be “conscious” in a fascinating different way, but that seems to become a matter of definition and taste, not a matter of insight. So we should not base our treatment of robots on the question whether they are conscious. </p><p>I would guess that the same problems will arise with other concepts like meta-cognition or self-consciousness, once we properly understand them. I don&#39;t have an alternative solution, but just a prediction: in the end, these discussions will not matter, because whether robots will be granted robot rights (assuming they don&#39;t just seize it) depends on whether and how people will subjectively perceive them as intelligent personalities. I doubt that any theory on this issue can win a political fight against the feelings of people.</p><div><figure><a target="_blank" rel="nofollow" href="https://amzn.to/3l7Zr7d"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 424w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 848w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png" width="630" height="435" data-attrs="{&#34;src&#34;:&#34;https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:435,&#34;width&#34;:630,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:84249,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:&#34;https://amzn.to/3l7Zr7d&#34;}" alt="" srcset="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 424w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 848w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3258c9bf-27df-46e3-a1d1-451d0bcc5baa_630x435.png 1456w" sizes="100vw"/></picture></a></figure></div></div></div></div></article></div></div></div>
  </body>
</html>
