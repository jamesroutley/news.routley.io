<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2403.00801">Original</a>
    <h1>Self-Retrieval: Building an information retrieval system with one LLM</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+Q">Qiaoyu Tang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J">Jiawei Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+B">Bowen Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y">Yaojie Lu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+C">Cheng Fu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H">Haiyang Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+H">Hongyu Lin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+F">Fei Huang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He,+B">Ben He</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+X">Xianpei Han</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+L">Le Sun</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y">Yongbin Li</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2403.00801">Download PDF</a>
    <a href="https://arxiv.org/html/2403.00801v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The rise of large language models (LLMs) has transformed the role of information retrieval (IR) systems in the way to humans accessing information. Due to the isolated architecture and the limited interaction, existing IR systems are unable to fully accommodate the shift from directly providing information to humans to indirectly serving large language models. In this paper, we propose Self-Retrieval, an end-to-end, LLM-driven information retrieval architecture that can fully internalize the required abilities of IR systems into a single LLM and deeply leverage the capabilities of LLMs during IR process. Specifically, Self-retrieval internalizes the corpus to retrieve into a LLM via a natural language indexing architecture. Then the entire retrieval process is redefined as a procedure of document generation and self-assessment, which can be end-to-end executed using a single large language model. Experimental results demonstrate that Self-Retrieval not only significantly outperforms previous retrieval approaches by a large margin, but also can significantly boost the performance of LLM-driven downstream applications like retrieval augumented generation.
    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Qiaoyu Tang [<a href="https://arxiv.org/show-email/677958a1/2403.00801">view email</a>]      </p></div></div>
  </body>
</html>
