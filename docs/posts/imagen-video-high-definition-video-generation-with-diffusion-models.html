<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://imagen.research.google/video/">Original</a>
    <h1>Imagen Video: high definition video generation with diffusion models</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        
        <p>We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding.</p>
        
      </div>
    </div><div>
      <p>Generative modeling has made tremendous progress, especially in recent text-to-image models. Imagen Video is another step forward in generative modelling capabilities, advancing text-to-video AI systems. Video generative models can be used to positively impact society, for example by amplifying and augmenting human creativity. However, these generative models may also be misused, for example to generate fake, hateful, explicit or harmful content. We have taken multiple steps to minimize these concerns, for example in internal trials, we apply input text prompt filtering, and output video content filtering. However, there are several important safety and ethical challenges remaining. Imagen Video and its frozen T5-XXL text encoder were trained on problematic data. While our internal testing suggest much of explicit and violent content can be filtered out, there still exists social biases and stereotypes which are challenging to detect and filter. We have decided not to release the Imagen Video model or its source code until these concerns are mitigated.</p>
    </div><div>
      
      <p>Jonathan Ho*, William Chan*, Chitwan Saharia*, Jay Whang*, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David Fleet, Tim Salimans*</p>
      <p>*Equal Contribution.</p>
      
      <p>We give special thanks to Jordi Pont-Tuset and Shai Noy for engineering support. We also give thanks to our artist friends, Alexander Chen, Irina Blok, Ian Muldoon, Daniel Smith, and Pedro Vergani for helping us test Imagen Video and lending us their amazing creativity. We are extremely grateful for the support from Erica Moreira for compute resources. Finally, we give thanks to Elizabeth Adkison, James Bradbury, Nicole Brichtova, Tom Duerig, Douglas Eck, Dumitru Erhan, Zoubin Ghahramani, Kamyar Ghasemipour, Victor Gomes, Blake Hechtman, Jonathan Heek, Yash Katariya, Sarah Laszlo, Sara Mahdavi, Anusha Ramesh, Tom Small, and Tris Warkentin for their support.</p>
    </div></div>
  </body>
</html>
